{"info": {"author": "Angelos Katharopoulos", "author_email": "angelos.katharopoulos@idiap.ch", "bugtrack_url": null, "classifiers": ["Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Programming Language :: Python", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Topic :: Scientific/Engineering"], "description": "Importance Sampling\n====================\n\nThis python package provides a library that accelerates the training of\narbitrary neural networks created with `Keras <http://keras.io>`__ using\n**importance sampling**.\n\n.. code:: python\n\n    # Keras imports\n\n    from importance_sampling.training import ImportanceTraining\n\n    x_train, y_train, x_val, y_val = load_data()\n    model = create_keras_model()\n    model.compile(\n        optimizer=\"adam\",\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n\n    ImportanceTraining(model).fit(\n        x_train, y_train,\n        batch_size=32,\n        epochs=10,\n        verbose=1,\n        validation_data=(x_val, y_val)\n    )\n\n    model.evaluate(x_val, y_val)\n\nImportance sampling for Deep Learning is an active research field and this\nlibrary is undergoing development so your mileage may vary.\n\nRelevant Research\n-----------------\n\n**Ours**\n\n* Not All Samples Are Created Equal: Deep Learning with Importance Sampling [`preprint <https://arxiv.org/abs/1803.00942>`__]\n* Biased Importance Sampling for Deep Neural Network Training [`preprint <https://arxiv.org/abs/1706.00043>`__]\n\n**By others**\n\n* Stochastic optimization with importance sampling for regularized loss\n  minimization [`pdf <http://www.jmlr.org/proceedings/papers/v37/zhaoa15.pdf>`__]\n* Variance reduction in SGD by distributed importance sampling [`pdf <https://arxiv.org/pdf/1511.06481>`__]\n\nDependencies & Installation\n---------------------------\n\nNormally if you already have a functional Keras installation you just need to\n``pip install keras-importance-sampling``.\n\n* ``Keras`` > 2\n* A Keras backend among *Tensorflow*, *Theano* and *CNTK*\n* ``blinker``\n* ``numpy``\n* ``matplotlib``, ``seaborn``, ``scikit-learn`` are optional (used by the plot\n  scripts)\n\nDocumentation\n-------------\n\nThe module has a dedicated `documentation site\n<http://idiap.ch/~katharas/importance-sampling/>`__ but you can also read the\n`source code <https://github.com/idiap/importance-sampling>`__ and the `examples\n<https://github.com/idiap/importance-sampling/tree/master/examples>`__ to get an\nidea of how the library should be used and extended.\n\nExamples\n---------\n\nIn the ``examples`` folder you can find some Keras examples that have been edited\nto use importance sampling.\n\nCode examples\n*************\n\nIn this section we will showcase part of the API that can be used to train\nneural networks with importance sampling.\n\n.. code:: python\n\n    # Import what is needed to build the Keras model\n    from keras import backend as K\n    from keras.layers import Dense, Activation, Flatten\n    from keras.models import Sequential\n\n    # Import a toy dataset and the importance training\n    from importance_sampling.datasets import MNIST\n    from importance_sampling.training import ImportanceTraining\n\n\n    def create_nn():\n        \"\"\"Build a simple fully connected NN\"\"\"\n        model = Sequential([\n            Flatten(input_shape=(28, 28, 1)),\n            Dense(40, activation=\"tanh\"),\n            Dense(40, activation=\"tanh\"),\n            Dense(10),\n            Activation(\"softmax\") # Needs to be separate to automatically\n                                  # get the preactivation outputs\n        ])\n\n        model.compile(\n            optimizer=\"adam\",\n            loss=\"categorical_crossentropy\",\n            metrics=[\"accuracy\"]\n        )\n\n        return model\n\n\n    if __name__ == \"__main__\":\n        # Load the data\n        dataset = MNIST()\n        x_train, y_train = dataset.train_data[:]\n        x_test, y_test = dataset.test_data[:]\n\n        # Create the NN and keep the initial weights\n        model = create_nn()\n        weights = model.get_weights()\n\n        # Train with uniform sampling\n        K.set_value(model.optimizer.lr, 0.01)\n        model.fit(\n            x_train, y_train,\n            batch_size=64, epochs=10,\n            validation_data=(x_test, y_test)\n        )\n\n        # Train with importance sampling\n        model.set_weights(weights)\n        K.set_value(model.optimizer.lr, 0.01)\n        ImportanceTraining(model).fit(\n            x_train, y_train,\n            batch_size=64, epochs=2,\n            validation_data=(x_test, y_test)\n        )\n\nUsing the script\n****************\n\nThe following terminal commands train a small VGG-like network to ~0.65% error\non MNIST (the numbers are from a CPU).\n.. code::\n\n    $ # Train a small cnn with mnist for 500 mini-batches using importance\n    $ # sampling with bias to achieve ~ 0.65% error (on the CPU).\n    $ time ./importance_sampling.py \\\n    >   small_cnn \\\n    >   oracle-gnorm \\\n    >   model \\\n    >   predicted \\\n    >   mnist \\\n    >   /tmp/is \\\n    >   --hyperparams 'batch_size=i128;lr=f0.003;lr_reductions=I10000' \\\n    >   --train_for 500 --validate_every 500\n    real    1m41.985s\n    user    8m14.400s\n    sys     0m35.900s\n    $\n    $ # And with uniform sampling to achieve ~ 0.9% error.\n    $ time ./importance_sampling.py \\\n    >   small_cnn \\\n    >   oracle-loss \\\n    >   uniform \\\n    >   unweighted \\\n    >   mnist \\\n    >   /tmp/uniform \\\n    >   --hyperparams 'batch_size=i128;lr=f0.003;lr_reductions=I10000' \\\n    >   --train_for 3000 --validate_every 3000\n    real    9m23.971s\n    user    47m32.600s\n    sys     3m4.188s\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://www.idiap.ch/~katharas/importance-sampling/", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "keras-importance-sampling", "package_url": "https://pypi.org/project/keras-importance-sampling/", "platform": "", "project_url": "https://pypi.org/project/keras-importance-sampling/", "project_urls": {"Homepage": "http://www.idiap.ch/~katharas/importance-sampling/"}, "release_url": "https://pypi.org/project/keras-importance-sampling/0.9/", "requires_dist": null, "requires_python": "", "summary": "Accelerate training of neural networks using importance sampling.", "version": "0.9", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>This python package provides a library that accelerates the training of\narbitrary neural networks created with <a href=\"http://keras.io\" rel=\"nofollow\">Keras</a> using\n<strong>importance sampling</strong>.</p>\n<pre><span class=\"c1\"># Keras imports</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">importance_sampling.training</span> <span class=\"kn\">import</span> <span class=\"n\">ImportanceTraining</span>\n\n<span class=\"n\">x_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">x_val</span><span class=\"p\">,</span> <span class=\"n\">y_val</span> <span class=\"o\">=</span> <span class=\"n\">load_data</span><span class=\"p\">()</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">create_keras_model</span><span class=\"p\">()</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span>\n    <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"s2\">\"adam\"</span><span class=\"p\">,</span>\n    <span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"s2\">\"categorical_crossentropy\"</span><span class=\"p\">,</span>\n    <span class=\"n\">metrics</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"accuracy\"</span><span class=\"p\">]</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">ImportanceTraining</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span>\n    <span class=\"n\">x_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span>\n    <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">32</span><span class=\"p\">,</span>\n    <span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span>\n    <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"n\">validation_data</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">x_val</span><span class=\"p\">,</span> <span class=\"n\">y_val</span><span class=\"p\">)</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">evaluate</span><span class=\"p\">(</span><span class=\"n\">x_val</span><span class=\"p\">,</span> <span class=\"n\">y_val</span><span class=\"p\">)</span>\n</pre>\n<p>Importance sampling for Deep Learning is an active research field and this\nlibrary is undergoing development so your mileage may vary.</p>\n<div id=\"relevant-research\">\n<h2>Relevant Research</h2>\n<p><strong>Ours</strong></p>\n<ul>\n<li>Not All Samples Are Created Equal: Deep Learning with Importance Sampling [<a href=\"https://arxiv.org/abs/1803.00942\" rel=\"nofollow\">preprint</a>]</li>\n<li>Biased Importance Sampling for Deep Neural Network Training [<a href=\"https://arxiv.org/abs/1706.00043\" rel=\"nofollow\">preprint</a>]</li>\n</ul>\n<p><strong>By others</strong></p>\n<ul>\n<li>Stochastic optimization with importance sampling for regularized loss\nminimization [<a href=\"http://www.jmlr.org/proceedings/papers/v37/zhaoa15.pdf\" rel=\"nofollow\">pdf</a>]</li>\n<li>Variance reduction in SGD by distributed importance sampling [<a href=\"https://arxiv.org/pdf/1511.06481\" rel=\"nofollow\">pdf</a>]</li>\n</ul>\n</div>\n<div id=\"dependencies-installation\">\n<h2>Dependencies &amp; Installation</h2>\n<p>Normally if you already have a functional Keras installation you just need to\n<tt>pip install <span class=\"pre\">keras-importance-sampling</span></tt>.</p>\n<ul>\n<li><tt>Keras</tt> &gt; 2</li>\n<li>A Keras backend among <em>Tensorflow</em>, <em>Theano</em> and <em>CNTK</em></li>\n<li><tt>blinker</tt></li>\n<li><tt>numpy</tt></li>\n<li><tt>matplotlib</tt>, <tt>seaborn</tt>, <tt><span class=\"pre\">scikit-learn</span></tt> are optional (used by the plot\nscripts)</li>\n</ul>\n</div>\n<div id=\"documentation\">\n<h2>Documentation</h2>\n<p>The module has a dedicated <a href=\"http://idiap.ch/~katharas/importance-sampling/\" rel=\"nofollow\">documentation site</a> but you can also read the\n<a href=\"https://github.com/idiap/importance-sampling\" rel=\"nofollow\">source code</a> and the <a href=\"https://github.com/idiap/importance-sampling/tree/master/examples\" rel=\"nofollow\">examples</a> to get an\nidea of how the library should be used and extended.</p>\n</div>\n<div id=\"examples\">\n<h2>Examples</h2>\n<p>In the <tt>examples</tt> folder you can find some Keras examples that have been edited\nto use importance sampling.</p>\n<div id=\"code-examples\">\n<h3>Code examples</h3>\n<p>In this section we will showcase part of the API that can be used to train\nneural networks with importance sampling.</p>\n<pre><span class=\"c1\"># Import what is needed to build the Keras model</span>\n<span class=\"kn\">from</span> <span class=\"nn\">keras</span> <span class=\"kn\">import</span> <span class=\"n\">backend</span> <span class=\"k\">as</span> <span class=\"n\">K</span>\n<span class=\"kn\">from</span> <span class=\"nn\">keras.layers</span> <span class=\"kn\">import</span> <span class=\"n\">Dense</span><span class=\"p\">,</span> <span class=\"n\">Activation</span><span class=\"p\">,</span> <span class=\"n\">Flatten</span>\n<span class=\"kn\">from</span> <span class=\"nn\">keras.models</span> <span class=\"kn\">import</span> <span class=\"n\">Sequential</span>\n\n<span class=\"c1\"># Import a toy dataset and the importance training</span>\n<span class=\"kn\">from</span> <span class=\"nn\">importance_sampling.datasets</span> <span class=\"kn\">import</span> <span class=\"n\">MNIST</span>\n<span class=\"kn\">from</span> <span class=\"nn\">importance_sampling.training</span> <span class=\"kn\">import</span> <span class=\"n\">ImportanceTraining</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">create_nn</span><span class=\"p\">():</span>\n    <span class=\"sd\">\"\"\"Build a simple fully connected NN\"\"\"</span>\n    <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Sequential</span><span class=\"p\">([</span>\n        <span class=\"n\">Flatten</span><span class=\"p\">(</span><span class=\"n\">input_shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)),</span>\n        <span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">40</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s2\">\"tanh\"</span><span class=\"p\">),</span>\n        <span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">40</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s2\">\"tanh\"</span><span class=\"p\">),</span>\n        <span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">),</span>\n        <span class=\"n\">Activation</span><span class=\"p\">(</span><span class=\"s2\">\"softmax\"</span><span class=\"p\">)</span> <span class=\"c1\"># Needs to be separate to automatically</span>\n                              <span class=\"c1\"># get the preactivation outputs</span>\n    <span class=\"p\">])</span>\n\n    <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span>\n        <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"s2\">\"adam\"</span><span class=\"p\">,</span>\n        <span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"s2\">\"categorical_crossentropy\"</span><span class=\"p\">,</span>\n        <span class=\"n\">metrics</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"accuracy\"</span><span class=\"p\">]</span>\n    <span class=\"p\">)</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">model</span>\n\n\n<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s2\">\"__main__\"</span><span class=\"p\">:</span>\n    <span class=\"c1\"># Load the data</span>\n    <span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">MNIST</span><span class=\"p\">()</span>\n    <span class=\"n\">x_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">train_data</span><span class=\"p\">[:]</span>\n    <span class=\"n\">x_test</span><span class=\"p\">,</span> <span class=\"n\">y_test</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">test_data</span><span class=\"p\">[:]</span>\n\n    <span class=\"c1\"># Create the NN and keep the initial weights</span>\n    <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">create_nn</span><span class=\"p\">()</span>\n    <span class=\"n\">weights</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">get_weights</span><span class=\"p\">()</span>\n\n    <span class=\"c1\"># Train with uniform sampling</span>\n    <span class=\"n\">K</span><span class=\"o\">.</span><span class=\"n\">set_value</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">lr</span><span class=\"p\">,</span> <span class=\"mf\">0.01</span><span class=\"p\">)</span>\n    <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span>\n        <span class=\"n\">x_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span>\n        <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span>\n        <span class=\"n\">validation_data</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">x_test</span><span class=\"p\">,</span> <span class=\"n\">y_test</span><span class=\"p\">)</span>\n    <span class=\"p\">)</span>\n\n    <span class=\"c1\"># Train with importance sampling</span>\n    <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">set_weights</span><span class=\"p\">(</span><span class=\"n\">weights</span><span class=\"p\">)</span>\n    <span class=\"n\">K</span><span class=\"o\">.</span><span class=\"n\">set_value</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">lr</span><span class=\"p\">,</span> <span class=\"mf\">0.01</span><span class=\"p\">)</span>\n    <span class=\"n\">ImportanceTraining</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span>\n        <span class=\"n\">x_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span>\n        <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span>\n        <span class=\"n\">validation_data</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">x_test</span><span class=\"p\">,</span> <span class=\"n\">y_test</span><span class=\"p\">)</span>\n    <span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"using-the-script\">\n<h3>Using the script</h3>\n<p>The following terminal commands train a small VGG-like network to ~0.65% error\non MNIST (the numbers are from a CPU).\n.. code:</p>\n<pre>$ # Train a small cnn with mnist for 500 mini-batches using importance\n$ # sampling with bias to achieve ~ 0.65% error (on the CPU).\n$ time ./importance_sampling.py \\\n&gt;   small_cnn \\\n&gt;   oracle-gnorm \\\n&gt;   model \\\n&gt;   predicted \\\n&gt;   mnist \\\n&gt;   /tmp/is \\\n&gt;   --hyperparams 'batch_size=i128;lr=f0.003;lr_reductions=I10000' \\\n&gt;   --train_for 500 --validate_every 500\nreal    1m41.985s\nuser    8m14.400s\nsys     0m35.900s\n$\n$ # And with uniform sampling to achieve ~ 0.9% error.\n$ time ./importance_sampling.py \\\n&gt;   small_cnn \\\n&gt;   oracle-loss \\\n&gt;   uniform \\\n&gt;   unweighted \\\n&gt;   mnist \\\n&gt;   /tmp/uniform \\\n&gt;   --hyperparams 'batch_size=i128;lr=f0.003;lr_reductions=I10000' \\\n&gt;   --train_for 3000 --validate_every 3000\nreal    9m23.971s\nuser    47m32.600s\nsys     3m4.188s\n</pre>\n</div>\n</div>\n\n          </div>"}, "last_serial": 6024206, "releases": {"0.1.1": [{"comment_text": "", "digests": {"md5": "e430e0be7bf91fc4bfb4f3ae49b5763c", "sha256": "64d6d84339cc4b0f2e6d4c4a0a9a062a0015813a877529a4564ca25d7aa73fa7"}, "downloads": -1, "filename": "keras-importance-sampling-0.1.1.tar.gz", "has_sig": false, "md5_digest": "e430e0be7bf91fc4bfb4f3ae49b5763c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22878, "upload_time": "2017-07-31T14:20:10", "upload_time_iso_8601": "2017-07-31T14:20:10.487852Z", "url": "https://files.pythonhosted.org/packages/32/21/4fecd3e0b490014f0d75732247a89c4aa0cf6018f82461d84abec75a8917/keras-importance-sampling-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "7a04b7a0865899611b061172a9cb8da5", "sha256": "0d2b598153d96fe4cac1eb26d97c14cda58d5b2bb9eea4129d5809440948b802"}, "downloads": -1, "filename": "keras-importance-sampling-0.1.2.tar.gz", "has_sig": false, "md5_digest": "7a04b7a0865899611b061172a9cb8da5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22878, "upload_time": "2017-07-31T14:21:35", "upload_time_iso_8601": "2017-07-31T14:21:35.418948Z", "url": "https://files.pythonhosted.org/packages/db/d2/de64fbb682fed771ba6959f59c7d755d8a5901c08556ac4fc505c16224b6/keras-importance-sampling-0.1.2.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "958a23cee9b3f07b19ad61e1865c12a9", "sha256": "a10af3952b06d34d80721edf129729cc902916768f566961b284b440cdf6b9f5"}, "downloads": -1, "filename": "keras-importance-sampling-0.2.tar.gz", "has_sig": false, "md5_digest": "958a23cee9b3f07b19ad61e1865c12a9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22920, "upload_time": "2017-08-03T13:30:58", "upload_time_iso_8601": "2017-08-03T13:30:58.438667Z", "url": "https://files.pythonhosted.org/packages/14/4f/618dfd0ca0861563f5b9f7f3d0cfa0e4fb1cd74223cbe845570a852fbdf0/keras-importance-sampling-0.2.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "88295b1f1219c4d82dd95e573affbf01", "sha256": "14d7d191e3a8e0aca4700e4f1f3e4f9ee79ad682a2ca0b7e1c8d083756c1e811"}, "downloads": -1, "filename": "keras-importance-sampling-0.2.1.tar.gz", "has_sig": false, "md5_digest": "88295b1f1219c4d82dd95e573affbf01", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24978, "upload_time": "2017-08-09T13:19:54", "upload_time_iso_8601": "2017-08-09T13:19:54.486419Z", "url": "https://files.pythonhosted.org/packages/6c/82/700d116d40dfd0fcf7c7480c6992012284103e0fa32d83e67092e4ab766f/keras-importance-sampling-0.2.1.tar.gz", "yanked": false}], "0.3": [{"comment_text": "", "digests": {"md5": "f8c1e0432a6cb8751d6769d3ba7e97d3", "sha256": "4617c9ecba024d6daf7820bad0f00a88d3dde739f50e060ac57ebbad6de4a9e2"}, "downloads": -1, "filename": "keras-importance-sampling-0.3.tar.gz", "has_sig": false, "md5_digest": "f8c1e0432a6cb8751d6769d3ba7e97d3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23574, "upload_time": "2017-08-24T14:47:46", "upload_time_iso_8601": "2017-08-24T14:47:46.011498Z", "url": "https://files.pythonhosted.org/packages/58/49/b5d22c7a556a524e008e38c448b4122b586303d2f901bc2f1934894f9276/keras-importance-sampling-0.3.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "4f15e1b60e1c2d49b01800ab32600a4f", "sha256": "82049d516af90fb2d4be03266af726a52fdc67bab5d7647c211a92a586974a58"}, "downloads": -1, "filename": "keras-importance-sampling-0.3.1.tar.gz", "has_sig": false, "md5_digest": "4f15e1b60e1c2d49b01800ab32600a4f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23561, "upload_time": "2017-10-16T16:29:46", "upload_time_iso_8601": "2017-10-16T16:29:46.211337Z", "url": "https://files.pythonhosted.org/packages/c5/18/b124fba5bd73908c9e0e405b1bf056016f0b06701bac7b77b5b627167215/keras-importance-sampling-0.3.1.tar.gz", "yanked": false}], "0.4": [{"comment_text": "", "digests": {"md5": "a4d2ebfe46bef09340d5c459d31220c7", "sha256": "da585c7e7b13ce7473f427b06e9894daa3449a0d20a52c237f67981cccd327da"}, "downloads": -1, "filename": "keras-importance-sampling-0.4.tar.gz", "has_sig": false, "md5_digest": "a4d2ebfe46bef09340d5c459d31220c7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 25372, "upload_time": "2017-11-14T18:48:25", "upload_time_iso_8601": "2017-11-14T18:48:25.094612Z", "url": "https://files.pythonhosted.org/packages/3d/dc/ef6ee5fd14283ddfe119dbc89677c490a3ef9a519d6a418b05f171df7daa/keras-importance-sampling-0.4.tar.gz", "yanked": false}], "0.5": [{"comment_text": "", "digests": {"md5": "e39fa8ac862dd293ee7be0fb081a6bd4", "sha256": "9745534115649d84a584090540d2d9fca29fcd67b5d70cd343c619bc53d2aa20"}, "downloads": -1, "filename": "keras-importance-sampling-0.5.tar.gz", "has_sig": false, "md5_digest": "e39fa8ac862dd293ee7be0fb081a6bd4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24567, "upload_time": "2017-11-24T16:55:19", "upload_time_iso_8601": "2017-11-24T16:55:19.195815Z", "url": "https://files.pythonhosted.org/packages/32/2d/e299dd50bac4979550d5f40df7bbfa11f6e7f7274434f1824cc73226a37a/keras-importance-sampling-0.5.tar.gz", "yanked": false}], "0.6": [{"comment_text": "", "digests": {"md5": "c45898cb97e7eef715d9287cc9be3bd8", "sha256": "d07ddc363fce02672041af58af2173639c420cffce23fbe3fc842b745d3afca2"}, "downloads": -1, "filename": "keras-importance-sampling-0.6.tar.gz", "has_sig": false, "md5_digest": "c45898cb97e7eef715d9287cc9be3bd8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 37457, "upload_time": "2018-04-03T22:14:58", "upload_time_iso_8601": "2018-04-03T22:14:58.045330Z", "url": "https://files.pythonhosted.org/packages/7a/e8/60c4fbc2ffd4388962a835c0186cb2359740f06044d349cf17ae5e3777a0/keras-importance-sampling-0.6.tar.gz", "yanked": false}], "0.7": [{"comment_text": "", "digests": {"md5": "b1f56c3aa16461c9fbdefd350f2e36ae", "sha256": "2e4edcf03d2c75338d7c1fc0f6f3ab03baf6717faa589c12245743445b576c67"}, "downloads": -1, "filename": "keras-importance-sampling-0.7.tar.gz", "has_sig": false, "md5_digest": "b1f56c3aa16461c9fbdefd350f2e36ae", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 39959, "upload_time": "2018-06-11T16:41:49", "upload_time_iso_8601": "2018-06-11T16:41:49.705711Z", "url": "https://files.pythonhosted.org/packages/ac/00/19d060bc3db400883a54e1b4dc70ea5dd374c262e913db68d7b7feff4619/keras-importance-sampling-0.7.tar.gz", "yanked": false}], "0.8": [{"comment_text": "", "digests": {"md5": "4eb783707c5da79a547dd946a9e1c4f4", "sha256": "2cb538114903dfb69130af5b0da707682213974486a950b846e87ec58723ca16"}, "downloads": -1, "filename": "keras-importance-sampling-0.8.tar.gz", "has_sig": false, "md5_digest": "4eb783707c5da79a547dd946a9e1c4f4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 40514, "upload_time": "2018-11-15T21:50:00", "upload_time_iso_8601": "2018-11-15T21:50:00.586510Z", "url": "https://files.pythonhosted.org/packages/b2/ac/f79031d912e993f7d43500ef964ea43eb83795ffcf23a36b66e5057676b8/keras-importance-sampling-0.8.tar.gz", "yanked": false}], "0.9": [{"comment_text": "", "digests": {"md5": "a09c40c9a604d230f3fc6451ab3fd804", "sha256": "f200a6e95d555bb650fddf4e07f32ff4d2aabcc3328be984ed37ee322cfaee6b"}, "downloads": -1, "filename": "keras-importance-sampling-0.9.tar.gz", "has_sig": false, "md5_digest": "a09c40c9a604d230f3fc6451ab3fd804", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 42857, "upload_time": "2019-10-24T14:34:15", "upload_time_iso_8601": "2019-10-24T14:34:15.895521Z", "url": "https://files.pythonhosted.org/packages/1d/55/378531f5c6e880434a73bcdb4be1af5be589b114176c410fb673b4a2ea48/keras-importance-sampling-0.9.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "a09c40c9a604d230f3fc6451ab3fd804", "sha256": "f200a6e95d555bb650fddf4e07f32ff4d2aabcc3328be984ed37ee322cfaee6b"}, "downloads": -1, "filename": "keras-importance-sampling-0.9.tar.gz", "has_sig": false, "md5_digest": "a09c40c9a604d230f3fc6451ab3fd804", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 42857, "upload_time": "2019-10-24T14:34:15", "upload_time_iso_8601": "2019-10-24T14:34:15.895521Z", "url": "https://files.pythonhosted.org/packages/1d/55/378531f5c6e880434a73bcdb4be1af5be589b114176c410fb673b4a2ea48/keras-importance-sampling-0.9.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:50:12 2020"}