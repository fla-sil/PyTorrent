{"info": {"author": "Roland Zimmermann", "author_email": "rzrolandzimmermann@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: Implementation :: CPython", "Programming Language :: Python :: Implementation :: PyPy"], "description": "\n# Keras Utility & Layer Collection [WIP]\nCollection of custom layers for Keras which are missing in the main framework. These layers might be useful to reproduce current state-of-the-art deep learning papers using Keras.\n\n## Applications\n\nUsing this library the following research papers have been reimplemented in Keras:\n\n- [Attention is all you need](https://github.com/FlashTek/attention-is-all-you-need-keras)\n- [Show, attend and tell](https://github.com/FlashTek/show-attend-and-tell-keras)\n\n## Overview of implemented Layers\n\nAt the moment the `Keras Layer Collection` offers the following layers/features:\n\n- [Scaled Dot-Product Attention](#sdpattention)\n- [Multi-Head Attention](#mhatn)\n- [Layer Normalization](#layernorm)\n- [Sequencewise Attention](#seqatn)\n- [Attention Wrapper](#atnwrapper)\n\n### Scaled Dot-Product Attention <a name=\"sdpattention\"></a>\n\nImplementation as described in [Attention Is All You Need](https://arxiv.org/abs/1706.03762). Performs a non-linear transformation on the values `V` by comparing the queries `Q` with the keys `K`. The illustration below is taken from the paper cited above.\n\n<img src=\"https://i.imgur.com/7zDGedN.jpg\" height=250>\n\n### Multi-Head Attention <a name=\"mhatn\"></a>\nImplementation as described in [Attention Is All You Need](https://arxiv.org/abs/1706.03762). This is basically just a bunch a [Scaled Dot-Product Attention](#sdpattention) blocks whose output is combined with a linear transformation. The illustration below is taken from the paper cited above.\n\n<img src=\"https://i.imgur.com/c0xLAfS.jpg\" height=250>\n\n### Layer Normalization <a name=\"layernorm\"></a>\n\n\n### Sequencewise Attention <a name=\"seqatn\"></a>\nThis layer applies various attention transformations on data. It needs a time-series of queries and a time-series of values to calculate the attention and the final linear transformation to obtain the output. This is a faster version of the general attention technique. It is similar to the `global attention` method described in [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025)\n\n### Attention Wrapper <a name=\"atnwrapper\"></a>\nThe idea of the implementation is based on the paper [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025). This layer can be wrapped around any `RNN` in `Keras`. It calculates for each time step of the `RNN` the attention vector between the previous output and all input steps. This way, a new attention-based input for the `RNN` is constructed. This input is finally fed into the `RNN`. This technique is similar to the `input-feeding` method described in the paper cited. The illustration below is taken from the paper cited above.\n\n<img src=\"https://i.imgur.com/AZKWSd2.png\" height=300>\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/FlashTek/keras-layer-collection", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "kulc", "package_url": "https://pypi.org/project/kulc/", "platform": "", "project_url": "https://pypi.org/project/kulc/", "project_urls": {"Homepage": "https://github.com/FlashTek/keras-layer-collection"}, "release_url": "https://pypi.org/project/kulc/0.0.9/", "requires_dist": null, "requires_python": ">=3.6.0", "summary": "Keras Utility & Layer Collection.", "version": "0.0.9", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Keras Utility &amp; Layer Collection [WIP]</h1>\n<p>Collection of custom layers for Keras which are missing in the main framework. These layers might be useful to reproduce current state-of-the-art deep learning papers using Keras.</p>\n<h2>Applications</h2>\n<p>Using this library the following research papers have been reimplemented in Keras:</p>\n<ul>\n<li><a href=\"https://github.com/FlashTek/attention-is-all-you-need-keras\" rel=\"nofollow\">Attention is all you need</a></li>\n<li><a href=\"https://github.com/FlashTek/show-attend-and-tell-keras\" rel=\"nofollow\">Show, attend and tell</a></li>\n</ul>\n<h2>Overview of implemented Layers</h2>\n<p>At the moment the <code>Keras Layer Collection</code> offers the following layers/features:</p>\n<ul>\n<li><a href=\"#sdpattention\" rel=\"nofollow\">Scaled Dot-Product Attention</a></li>\n<li><a href=\"#mhatn\" rel=\"nofollow\">Multi-Head Attention</a></li>\n<li><a href=\"#layernorm\" rel=\"nofollow\">Layer Normalization</a></li>\n<li><a href=\"#seqatn\" rel=\"nofollow\">Sequencewise Attention</a></li>\n<li><a href=\"#atnwrapper\" rel=\"nofollow\">Attention Wrapper</a></li>\n</ul>\n<h3>Scaled Dot-Product Attention <a></a></h3>\n<p>Implementation as described in <a href=\"https://arxiv.org/abs/1706.03762\" rel=\"nofollow\">Attention Is All You Need</a>. Performs a non-linear transformation on the values <code>V</code> by comparing the queries <code>Q</code> with the keys <code>K</code>. The illustration below is taken from the paper cited above.</p>\n<img height=\"250\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f9632f611c44324e7c58374eb4a09211f68b51e0/68747470733a2f2f692e696d6775722e636f6d2f377a444765644e2e6a7067\">\n<h3>Multi-Head Attention <a></a></h3>\n<p>Implementation as described in <a href=\"https://arxiv.org/abs/1706.03762\" rel=\"nofollow\">Attention Is All You Need</a>. This is basically just a bunch a <a href=\"#sdpattention\" rel=\"nofollow\">Scaled Dot-Product Attention</a> blocks whose output is combined with a linear transformation. The illustration below is taken from the paper cited above.</p>\n<img height=\"250\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4094ed83696e013a3059daecffe60bbf3eb0898a/68747470733a2f2f692e696d6775722e636f6d2f6330784c4166532e6a7067\">\n<h3>Layer Normalization <a></a></h3>\n<h3>Sequencewise Attention <a></a></h3>\n<p>This layer applies various attention transformations on data. It needs a time-series of queries and a time-series of values to calculate the attention and the final linear transformation to obtain the output. This is a faster version of the general attention technique. It is similar to the <code>global attention</code> method described in <a href=\"https://arxiv.org/abs/1508.04025\" rel=\"nofollow\">Effective Approaches to Attention-based Neural Machine Translation</a></p>\n<h3>Attention Wrapper <a></a></h3>\n<p>The idea of the implementation is based on the paper <a href=\"https://arxiv.org/abs/1508.04025\" rel=\"nofollow\">Effective Approaches to Attention-based Neural Machine Translation</a>. This layer can be wrapped around any <code>RNN</code> in <code>Keras</code>. It calculates for each time step of the <code>RNN</code> the attention vector between the previous output and all input steps. This way, a new attention-based input for the <code>RNN</code> is constructed. This input is finally fed into the <code>RNN</code>. This technique is similar to the <code>input-feeding</code> method described in the paper cited. The illustration below is taken from the paper cited above.</p>\n<img height=\"300\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fa91dfc40917b5596db7d26c71e4c102046692ae/68747470733a2f2f692e696d6775722e636f6d2f415a4b575364322e706e67\">\n\n          </div>"}, "last_serial": 4231363, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "4143e685254962b13784b9476a5761e1", "sha256": "839d24a283ea21f84cf030f341f3265972829b45c62a5f76bcd38947663c9589"}, "downloads": -1, "filename": "kulc-0.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "4143e685254962b13784b9476a5761e1", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6.0", "size": 23646, "upload_time": "2018-06-28T04:16:43", "upload_time_iso_8601": "2018-06-28T04:16:43.557323Z", "url": "https://files.pythonhosted.org/packages/e9/46/0e2a21243979675ebf7e4c64eb0e0a26dfda92852056b018afb9a7f1e881/kulc-0.0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6a9e44ac291172fc4ac11c1f398587d3", "sha256": "ea32299d17040e9744ed611cb4ab5a6ef61779d225619d9065166751958aa5f6"}, "downloads": -1, "filename": "kulc-0.0.1.tar.gz", "has_sig": false, "md5_digest": "6a9e44ac291172fc4ac11c1f398587d3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 10921, "upload_time": "2018-06-28T04:16:44", "upload_time_iso_8601": "2018-06-28T04:16:44.764825Z", "url": "https://files.pythonhosted.org/packages/74/29/322601c17dda93bb9a6e0bc5c0cbd23b8cc31970814e8a63564ce358a100/kulc-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "4a6fe1e4b022c27ee2d8be0d2c85b024", "sha256": "c4053d9f9635062107a1595ee6a942a0bce3977e56ffd267697dcbbc6add0f16"}, "downloads": -1, "filename": "kulc-0.0.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "4a6fe1e4b022c27ee2d8be0d2c85b024", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6.0", "size": 24975, "upload_time": "2018-07-03T17:44:05", "upload_time_iso_8601": "2018-07-03T17:44:05.566759Z", "url": "https://files.pythonhosted.org/packages/40/34/45f4ed858763d37e3ae2be5565cb04e9ce7c62301a925be3501399e5c338/kulc-0.0.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2fc90010b2daf6c63a2301f7f295bca1", "sha256": "b47280c300143fa0f41956c07694522f03ef136eb424b3acc2f9ee003cfbcaa8"}, "downloads": -1, "filename": "kulc-0.0.2.tar.gz", "has_sig": false, "md5_digest": "2fc90010b2daf6c63a2301f7f295bca1", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 12110, "upload_time": "2018-07-03T17:44:06", "upload_time_iso_8601": "2018-07-03T17:44:06.767921Z", "url": "https://files.pythonhosted.org/packages/10/49/62fb3ec86c25526c8e4c24727b184dd3c98d994b9e26003ee7118f544775/kulc-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "336ac711042b9a8b423923c4c68fde4a", "sha256": "124e25628630c24baec7fce2f7211e7a1f5f16a5f92c77dce058b22775fa5d90"}, "downloads": -1, "filename": "kulc-0.0.3-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "336ac711042b9a8b423923c4c68fde4a", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6.0", "size": 24993, "upload_time": "2018-07-03T22:26:29", "upload_time_iso_8601": "2018-07-03T22:26:29.457575Z", "url": "https://files.pythonhosted.org/packages/9f/22/ca4a5628072f728d741c380eaddb8463dc433f4a9a37af59549354dc17a7/kulc-0.0.3-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "acec847e8c04651248154dba56a4570d", "sha256": "2c6f24de708d036cb98b07f42d38ea6537c1c555d95e0773562aa5fff72f6fba"}, "downloads": -1, "filename": "kulc-0.0.3.tar.gz", "has_sig": false, "md5_digest": "acec847e8c04651248154dba56a4570d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 12127, "upload_time": "2018-07-03T22:26:30", "upload_time_iso_8601": "2018-07-03T22:26:30.928385Z", "url": "https://files.pythonhosted.org/packages/cf/5a/b21fc7a77f336bc50ed567c02fcaecc10eb01bf6e52f8f6dcfda3ec79962/kulc-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "c58db5ee8175d7116af040df3578cb5b", "sha256": "6c07757a7519a4cc22c385872e18fbdcfc6a928109db1e01a7f5d083b306d449"}, "downloads": -1, "filename": "kulc-0.0.4-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "c58db5ee8175d7116af040df3578cb5b", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6.0", "size": 25052, "upload_time": "2018-07-05T21:26:25", "upload_time_iso_8601": "2018-07-05T21:26:25.642007Z", "url": "https://files.pythonhosted.org/packages/0a/b0/8c7a5458f1d547dd66e622f89909bdd38c8655b5238ecc35fab060bbe2fe/kulc-0.0.4-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1091e3f34c8172eb43b4bc31424ac8c5", "sha256": "5bafe95c921c85d54871a5a2f7e5f34282e1160a1ee8bd587807da1e8d4799a6"}, "downloads": -1, "filename": "kulc-0.0.4.tar.gz", "has_sig": false, "md5_digest": "1091e3f34c8172eb43b4bc31424ac8c5", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 12211, "upload_time": "2018-07-05T21:26:26", "upload_time_iso_8601": "2018-07-05T21:26:26.845911Z", "url": "https://files.pythonhosted.org/packages/30/04/888f7e63a5419ba2d4f3667911403e8af2f0bf3636e969dabc22b07cf337/kulc-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "32cd426107970ad2ee9f760724f7bec3", "sha256": "b5c6a0788eec9ded2872edf5ca1e3c633563fc5beef23c0cd36d353461769559"}, "downloads": -1, "filename": "kulc-0.0.5-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "32cd426107970ad2ee9f760724f7bec3", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6.0", "size": 25292, "upload_time": "2018-07-07T08:27:48", "upload_time_iso_8601": "2018-07-07T08:27:48.666885Z", "url": "https://files.pythonhosted.org/packages/6f/f4/6cd3358e4132301931c5482feb285bd60fcf578ba8990064bc4574908981/kulc-0.0.5-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2766ea644756f4e52786d8ea0bd43ee4", "sha256": "b3cec8ba8d5bca3d2a06b411415b4bbe82f341ebec212fe8630e79415f09cb5b"}, "downloads": -1, "filename": "kulc-0.0.5.tar.gz", "has_sig": false, "md5_digest": "2766ea644756f4e52786d8ea0bd43ee4", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 12302, "upload_time": "2018-07-07T08:27:49", "upload_time_iso_8601": "2018-07-07T08:27:49.934932Z", "url": "https://files.pythonhosted.org/packages/1c/4a/4f58f69c2134c44853e4b70da3c66e4897c0043c5c9fbd4dce4902bd845e/kulc-0.0.5.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "d7f225b12d288ef8f2e5df0fbb2c61e5", "sha256": "ba56409f624354ed03822af2de2e4c927cf86a42634c1face24a1283e179f37e"}, "downloads": -1, "filename": "kulc-0.0.6-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "d7f225b12d288ef8f2e5df0fbb2c61e5", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6.0", "size": 25622, "upload_time": "2018-07-11T17:19:58", "upload_time_iso_8601": "2018-07-11T17:19:58.850891Z", "url": "https://files.pythonhosted.org/packages/03/15/1938a7e9651d51fc1327a1e3664bb1315a309848cd730c7d6cebbe86e49a/kulc-0.0.6-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "58c39b219d6cb7b280ba9d2915469623", "sha256": "5b75efc0c0b8f679135d06ef829165403263a402ff1984e855cc4a6b77832ec4"}, "downloads": -1, "filename": "kulc-0.0.6.tar.gz", "has_sig": false, "md5_digest": "58c39b219d6cb7b280ba9d2915469623", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 12816, "upload_time": "2018-07-11T17:20:00", "upload_time_iso_8601": "2018-07-11T17:20:00.015666Z", "url": "https://files.pythonhosted.org/packages/73/64/6468242bec06f29103b4f16153df605deb3171963610b7bd888b2b99426e/kulc-0.0.6.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "32ddd6e43a3f7a542051ce8382023a06", "sha256": "7ccd59dd6944f73d3ab4bc5f7e14cbfb63bb05434da0f4aa7ed34a9bd6b50350"}, "downloads": -1, "filename": "kulc-0.0.7-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "32ddd6e43a3f7a542051ce8382023a06", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6.0", "size": 13517, "upload_time": "2018-08-29T15:16:33", "upload_time_iso_8601": "2018-08-29T15:16:33.187454Z", "url": "https://files.pythonhosted.org/packages/3d/d0/13846105a3284e7ce9744da2d4ecd562a182dd61b5129ff7aa2860573b05/kulc-0.0.7-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f7b67ea523c5b37bdb730ae4de9a893d", "sha256": "8467a80058f3dc2b0dfdd5f98c498d9cbcef0e084e556b5fb30f0a85ff581c52"}, "downloads": -1, "filename": "kulc-0.0.7.tar.gz", "has_sig": false, "md5_digest": "f7b67ea523c5b37bdb730ae4de9a893d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 12510, "upload_time": "2018-08-29T15:16:34", "upload_time_iso_8601": "2018-08-29T15:16:34.524112Z", "url": "https://files.pythonhosted.org/packages/d9/3e/b6737d2e2d189fbb3874f13d2a1de4781e88cc18d0e974539363837b3d6e/kulc-0.0.7.tar.gz", "yanked": false}], "0.0.8": [{"comment_text": "", "digests": {"md5": "ae0de9fc06400e0caa0361cd66cd87cb", "sha256": "28be67c6fbc864c29a121e49cc71c55b75d128f6bf8a6547b2ef163004dd2c0f"}, "downloads": -1, "filename": "kulc-0.0.8-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "ae0de9fc06400e0caa0361cd66cd87cb", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6.0", "size": 13516, "upload_time": "2018-08-30T15:44:17", "upload_time_iso_8601": "2018-08-30T15:44:17.594362Z", "url": "https://files.pythonhosted.org/packages/55/cc/785b583f59768f5e5629dce2a8dc6e37d625136858454646867bfdf7353c/kulc-0.0.8-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7ab7d8d7fe3dfd53f0561c454344498d", "sha256": "d56e432a7cdbf28e57d914ac269da343517c5ab64cc53f072be8446203a50793"}, "downloads": -1, "filename": "kulc-0.0.8.tar.gz", "has_sig": false, "md5_digest": "7ab7d8d7fe3dfd53f0561c454344498d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 12524, "upload_time": "2018-08-30T15:44:18", "upload_time_iso_8601": "2018-08-30T15:44:18.713188Z", "url": "https://files.pythonhosted.org/packages/f4/7c/dc624cbe1f2509b00441b501ef9a9fe16440f82a848df8874f80459c112f/kulc-0.0.8.tar.gz", "yanked": false}], "0.0.9": [{"comment_text": "", "digests": {"md5": "c05f18a1bec89308ee4ae7e43dc01e4e", "sha256": "bdcc5b01a1b53f05fb8928f83fdb8ed1c69c42aad8a7737cec1abc22bcd1064f"}, "downloads": -1, "filename": "kulc-0.0.9-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "c05f18a1bec89308ee4ae7e43dc01e4e", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6.0", "size": 13545, "upload_time": "2018-09-02T15:22:00", "upload_time_iso_8601": "2018-09-02T15:22:00.131881Z", "url": "https://files.pythonhosted.org/packages/2c/09/dd1fadedf4d563de31530cdd7d8bbfc6b717d9ba0ccb653a285070e577bc/kulc-0.0.9-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3d9b93311964e6c5761375e7781a0c4c", "sha256": "7286bbac48ed16d124621f4924d62d21eb34b763da91bb6ca3432db5730dd0f0"}, "downloads": -1, "filename": "kulc-0.0.9.tar.gz", "has_sig": false, "md5_digest": "3d9b93311964e6c5761375e7781a0c4c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 12548, "upload_time": "2018-09-02T15:22:01", "upload_time_iso_8601": "2018-09-02T15:22:01.569449Z", "url": "https://files.pythonhosted.org/packages/32/8e/0d900e8b0ddec62c92e7023808f1f7943fff9c1f374edeb3190dbc5ab683/kulc-0.0.9.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "c05f18a1bec89308ee4ae7e43dc01e4e", "sha256": "bdcc5b01a1b53f05fb8928f83fdb8ed1c69c42aad8a7737cec1abc22bcd1064f"}, "downloads": -1, "filename": "kulc-0.0.9-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "c05f18a1bec89308ee4ae7e43dc01e4e", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6.0", "size": 13545, "upload_time": "2018-09-02T15:22:00", "upload_time_iso_8601": "2018-09-02T15:22:00.131881Z", "url": "https://files.pythonhosted.org/packages/2c/09/dd1fadedf4d563de31530cdd7d8bbfc6b717d9ba0ccb653a285070e577bc/kulc-0.0.9-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3d9b93311964e6c5761375e7781a0c4c", "sha256": "7286bbac48ed16d124621f4924d62d21eb34b763da91bb6ca3432db5730dd0f0"}, "downloads": -1, "filename": "kulc-0.0.9.tar.gz", "has_sig": false, "md5_digest": "3d9b93311964e6c5761375e7781a0c4c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 12548, "upload_time": "2018-09-02T15:22:01", "upload_time_iso_8601": "2018-09-02T15:22:01.569449Z", "url": "https://files.pythonhosted.org/packages/32/8e/0d900e8b0ddec62c92e7023808f1f7943fff9c1f374edeb3190dbc5ab683/kulc-0.0.9.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:48:35 2020"}