{"info": {"author": "Amit Sharma, Emre Kiciman", "author_email": "", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "|BuildStatus|_ |PyPiVersion|_ |PythonSupport|_\n\n.. |PyPiVersion| image:: https://img.shields.io/pypi/v/dowhy.svg\n.. _PyPiVersion: https://pypi.org/project/dowhy/\n\n.. |PythonSupport| image:: https://img.shields.io/pypi/pyversions/dowhy.svg\n.. _PythonSupport: https://pypi.org/project/dowhy/\n\n.. |BuildStatus| image:: https://dev.azure.com/ms/dowhy/_apis/build/status/microsoft.dowhy?branchName=master\n.. _BuildStatus: https://dev.azure.com/ms/dowhy/_build/latest?definitionId=179&branchName=master\n\nDoWhy | Making causal inference easy\n====================================\n\n`Amit Sharma <http://www.amitsharma.in>`_,\n`Emre Kiciman <http://www.kiciman.org>`_\n\n Read the `docs <https://microsoft.github.io/dowhy/>`_ | Try it online! |AzureNotebooks|_ |Binder|_ \n\n.. |AzureNotebooks| image:: https://notebooks.azure.com/launch.svg\n.. _AzureNotebooks: https://notebooks.azure.com/amshar/projects/dowhy/tree/docs/source\n\n.. |Binder| image:: https://mybinder.org/badge_logo.svg\n.. _Binder: https://mybinder.org/v2/gh/microsoft/dowhy/master?filepath=docs%2Fsource%2F\n\n Blog Posts: `Introducing DoWhy <https://www.microsoft.com/en-us/research/blog/dowhy-a-library-for-causal-inference/>`_ | `Using the Do-sampler <https://medium.com/@akelleh/introducing-the-do-sampler-for-causal-inference-a3296ea9e78d>`_\n\nAs computing systems are more frequently and more actively intervening in societally critical domains such as healthcare, education, and governance, it is critical to correctly predict and understand the causal effects of these interventions. Without an A/B test, conventional machine learning methods, built on pattern recognition and correlational analyses, are insufficient for causal reasoning. \n\nMuch like machine learning libraries have done for prediction, **\"DoWhy\" is a Python library that aims to spark causal thinking and analysis**. DoWhy provides a unified interface for causal inference methods and automatically tests many assumptions, thus making inference accessible to non-experts.\n\nFor a quick introduction to causal inference, check out `amit-sharma/causal-inference-tutorial <https://github.com/amit-sharma/causal-inference-tutorial/>`_. We also gave a more comprehensive tutorial at the ACM Knowledge Discovery and Data Mining (`KDD 2018 <http://www.kdd.org/kdd2018/>`_) conference: `causalinference.gitlab.io/kdd-tutorial <http://causalinference.gitlab.io/kdd-tutorial/>`_.\n\nDocumentation for DoWhy is available at `microsoft.github.io/dowhy <https://microsoft.github.io/dowhy/>`_.\n\n.. i here comment toctree::\n.. i here comment   :maxdepth: 4\n.. i here comment   :caption: Contents:\n.. contents:: Contents\n\nThe need for causal inference\n----------------------------------\n\nPredictive models uncover patterns that connect the inputs and outcome in observed data. To intervene, however, we need to estimate the effect of changing an input from its current value, for which no data exists. Such questions, involving estimating a *counterfactual*, are common in decision-making scenarios.\n\n* Will it work?\n    * Does a proposed change to a system improve people's outcomes?\n* Why did it work?\n    * What led to a change in a system's outcome?\n* What should we do?\n    * What changes to a system are likely to improve outcomes for people?\n* What are the overall effects?\n    * How does the system interact with human behavior?\n    * What is the effect of a system's recommendations on people's activity?\n\nAnswering these questions requires causal reasoning. While many methods exist\nfor causal inference, it is hard to compare their assumptions and robustness of results. DoWhy makes three contributions,\n\n1. Provides a principled way of modeling a given problem as a causal graph so\n   that all assumptions are explicit.\n2. Provides a unified interface for many popular causal inference methods, combining the two major frameworks of graphical models and potential outcomes.\n3. Automatically tests for the validity of assumptions if possible and assesses\n   the robustness of the estimate to violations.\n\nInstallation\n-------------\n\n**Requirements**\n\nDoWhy support Python 3+. It requires the following packages:\n\n* numpy\n* scipy\n* scikit-learn\n* pandas\n* networkx  (for analyzing causal graphs)\n* matplotlib (for general plotting)\n* sympy (for rendering symbolic expressions)\n\nInstall the latest release using pip. \n\n.. code:: shell\n\n   pip install dowhy\n\nIf you prefer the latest dev version, clone this repository and run the following command from the top-most folder of\nthe repository.\n\n.. code:: shell\n\n    python setup.py install\n\nIf you face any problems, try installing dependencies manually.\n\n.. code:: shell\n\n    pip install -r requirements.txt\n\nOptionally, if you wish to input graphs in the dot format, then install pydot (or pygraphviz).\n\n\nFor better-looking graphs, you can optionally install pygraphviz. To proceed,\nfirst install graphviz and then pygraphviz (on Ubuntu and Ubuntu WSL).\n\n.. code:: shell\n\n    sudo apt install graphviz libgraphviz-dev graphviz-dev pkg-config\n    ## from https://github.com/pygraphviz/pygraphviz/issues/71\n    pip install pygraphviz --install-option=\"--include-path=/usr/include/graphviz\" \\\n    --install-option=\"--library-path=/usr/lib/graphviz/\"\n\nKeep in mind that pygraphviz installation can be problematic on the latest versions of Python3. Tested to work with Python 3.5.\n\nSample causal inference analysis in DoWhy\n-------------------------------------------\nMost DoWhy\nanalyses for causal inference take 4 lines to write, assuming a\npandas dataframe df that contains the data:\n\n.. code:: python\n\n    from dowhy import CausalModel\n    import dowhy.datasets\n\n    # Load some sample data\n    data = dowhy.datasets.linear_dataset(\n        beta=10,\n        num_common_causes=5,\n        num_instruments=2,\n        num_samples=10000,\n        treatment_is_binary=True)\n\nDoWhy supports two formats for providing the causal graph: `gml <https://github.com/GunterMueller/UNI_PASSAU_FMI_Graph_Drawing>`_ (preferred) and `dot <http://www.graphviz.org/documentation/>`_. After loading in the data, we use the four main operations in DoWhy: *model*,\n*estimate*, *identify* and *refute*:\n\n.. code:: python\n\n    # Create a causal model from the data and given graph.\n    model = CausalModel(\n        data=data[\"df\"],\n        treatment=data[\"treatment_name\"],\n        outcome=data[\"outcome_name\"],\n        graph=data[\"gml_graph\"])\n\n    # Identify causal effect and return target estimands\n    identified_estimand = model.identify_effect()\n\n    # Estimate the target estimand using a statistical method.\n    estimate = model.estimate_effect(identified_estimand,\n                                     method_name=\"backdoor.propensity_score_matching\")\n\n    # Refute the obtained estimate using multiple robustness checks.\n    refute_results = model.refute_estimate(identified_estimand, estimate,\n                                           method_name=\"random_common_cause\")\n\nDoWhy stresses on the interpretability of its output. At any point in the analysis,\nyou can inspect the untested assumptions, identified estimands (if any) and the\nestimate (if any). Here's a sample output of the linear regression estimator.\n\n.. image:: https://raw.githubusercontent.com/microsoft/dowhy/master/docs/images/regression_output.png\n\nFor detailed code examples, check out the Jupyter notebooks in `docs/source/example_notebooks <https://github.com/microsoft/dowhy/tree/master/docs/source/example_notebooks/>`_, or try them online at `Binder <https://mybinder.org/v2/gh/microsoft/dowhy/master?filepath=docs%2Fsource%2F>`_.\n\n\nA High-level Pandas API\n-----------------------\n\nWe've made an even simpler API for dowhy which is a light layer on top of the standard one. The goal\nwas to make causal analysis much more like regular exploratory analysis. To use this API, simply\nimport :code:`dowhy.api`. This will magically add the :code:`causal` namespace to your\n:code:`pandas.DataFrame` s. Then,\nyou can use the namespace as follows.\n\n.. code:: python\n\n    import dowhy.api\n    import dowhy.datasets\n\n    data = dowhy.datasets.linear_dataset(beta=5,\n        num_common_causes=1,\n        num_instruments = 0,\n        num_samples=1000,\n        treatment_is_binary=True)\n\n    # data['df'] is just a regular pandas.DataFrame\n    data['df'].causal.do(x='v0', # name of treatment variable\n                         variable_types={'v0': 'b', 'y': 'c', 'W0': 'c'},\n                         outcome='y',\n                         common_causes=['W0']).groupby('v0').mean().plot(y='y', kind='bar')\n\n.. image:: https://raw.githubusercontent.com/microsoft/dowhy/master/docs/images/do_barplot.png\n\nThe :code:`do` method in the causal namespace generates a random sample from $P(outcome|do(X=x))$ of the\nsame length as your data set, and returns this outcome as a new :code:`DataFrame`. You can continue to perform\nthe usual :code:`DataFrame` operations with this sample, and so you can compute statistics and create plots\nfor causal outcomes!\n\nThe :code:`do` method is built on top of the lower-level :code:`dowhy` objects, so can still take a graph and perform\nidentification automatically when you provide a graph instead of :code:`common_causes`.\n\nGraphical Models and Potential Outcomes: Best of both worlds\n------------------------------------------------------------\nDoWhy builds on two of the most powerful frameworks for causal inference:\ngraphical models and potential outcomes. It uses graph-based criteria and\ndo-calculus for modeling assumptions and identifying a non-parametric causal effect.\nFor estimation, it switches to methods based primarily on potential outcomes.\n\nA unifying language for causal inference\n----------------------------------------\n\nDoWhy is based on a simple unifying language for causal inference. Causal\ninference may seem tricky, but almost all methods follow four key steps:\n\n1. Model a causal inference problem using assumptions.\n2. Identify an expression for the causal effect under these assumptions (\"causal estimand\").\n3. Estimate the expression using statistical methods such as matching or instrumental variables.\n4. Finally, verify the validity of the estimate using a variety of robustness checks.\n\nThis workflow can be captured by four key verbs in DoWhy:\n\n- model\n- identify\n- estimate\n- refute\n\nUsing these verbs, DoWhy implements a causal inference engine that can support \na variety of methods. *model* encodes prior knowledge as a formal causal graph, *identify* uses \ngraph-based methods to identify the causal effect, *estimate* uses  \nstatistical methods for estimating the identified estimand, and finally *refute* \ntries to refute the obtained estimate by testing robustness to assumptions.\n\nDoWhy brings three key differences compared to available software for causal inference:\n\n**Explicit identifying assumptions**\n    Assumptions are first-class citizens in DoWhy.\n\n    Each analysis starts with a\n    building a causal model. The assumptions can be viewed graphically or in terms\n    of conditional independence statements. Wherever possible, DoWhy can also\n    automatically test for stated assumptions using observed data.\n\n**Separation between identification and estimation**\n    Identification is the causal problem. Estimation is simply a statistical problem.\n\n    DoWhy\n    respects this boundary and treats them separately. This focuses the causal\n    inference effort on identification, and frees up estimation using any\n    available statistical estimator for a target estimand. In addition, multiple\n    estimation methods can be used for a single identified_estimand and\n    vice-versa.\n\n**Automated robustness checks**\n    What happens when key identifying assumptions may not be satisfied?\n\n    The most critical, and often skipped, part of causal analysis is checking the\n    robustness of an estimate to unverified assumptions. DoWhy makes it easy to\n    automatically run sensitivity and robustness checks on the obtained estimate.\n\nFinally, DoWhy is easily extensible, allowing other implementations of the\nfour verbs to co-exist (we hope to integrate with external\nimplementations in the future). The four verbs are mutually independent, so their\nimplementations can be combined in any way.\n\n\n\nBelow are more details about the current implementation of each of these verbs.\n\nFour steps of causal inference\n------------------------------\n\nI. **Model a causal problem**\n\nDoWhy creates an underlying causal graphical model for each problem. This\nserves to make each causal assumption explicit. This graph need not be\ncomplete---you can provide a partial graph, representing prior\nknowledge about some of the variables. DoWhy automatically considers the rest\nof the variables as potential confounders.\n\nCurrently, DoWhy supports two formats for graph input: `gml <https://github.com/GunterMueller/UNI_PASSAU_FMI_Graph_Drawing>`_ (preferred) and\n`dot <http://www.graphviz.org/documentation/>`_. We strongly suggest to use gml as the input format, as it works well with networkx. You can provide the graph either as a .gml file or as a string. If you prefer to use dot format, you will need to install additional packages (pydot or pygraphviz, see the installation section above). Both .dot files and string format are supported. \n\nWhile not recommended, you can also specify common causes and/or instruments directly\ninstead of providing a graph.\n\n\n.. i comment image:: causal_model.png\n\nII. **Identify a target estimand under the model**\n\nBased on the causal graph, DoWhy finds all possible ways of identifying a desired causal effect based on\nthe graphical model. It uses graph-based criteria and do-calculus to find\npotential ways find expressions that can identify the causal effect.\n\nIII. **Estimate causal effect based on the identified estimand**\n\nDoWhy supports methods based on both back-door criterion and instrumental\nvariables. It also provides a non-parametric permutation test for testing\nthe statistical significance of obtained estimate. \n\nCurrently supported back-door criterion methods.\n\n* Methods based on estimating the treatment assignment\n    * Propensity-based Stratification\n    * Propensity Score Matching\n    * Inverse Propensity Weighting\n\n* Methods based on estimating the response surface\n    * Regression\n\nCurrently supported methods based on instrumental variables.\n\n* Binary Instrument/Wald Estimator\n* Regression discontinuity\n\n\nIV. **Refute the obtained estimate**\n\nHaving access to multiple refutation methods to verify a causal inference is\na key benefit of using DoWhy.\n\nDoWhy supports the following refutation methods.\n\n* Placebo Treatment\n* Irrelevant Additional Confounder\n* Subset validation\n\nCiting this package\n-------------------\nIf you find DoWhy useful for your research work, please cite us as follows:\n\nAmit Sharma, Emre Kiciman, et al. DoWhy: A Python package for causal inference. 2019. https://github.com/microsoft/dowhy\n\nBibtex::\n\n  @misc{dowhy,\n  authors={Sharma, Amit and Kiciman, Emre and others},\n  title={Do{W}hy: {A Python package for causal inference}},\n  howpublished={https://github.com/microsoft/dowhy}\n  year={2019}\n  }\n\n\nRoadmap \n-----------\nThe `projects <https://github.com/microsoft/dowhy/projects>`_ page lists the next steps for DoWhy. If you would like to contribute, have a look at the current projects. If you have a specific request for DoWhy, please raise an issue `here <https://github.com/microsoft/dowhy/issues>`_.\n\nContributing\n-------------\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the `Microsoft Open Source Code of Conduct <https://opensource.microsoft.com/codeofconduct/>`_.\nFor more information see the `Code of Conduct FAQ <https://opensource.microsoft.com/codeofconduct/faq/>`_ or\ncontact `opencode@microsoft.com <mailto:opencode@microsoft.com>`_ with any additional questions or comments.\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "https://github.com/microsoft/dowhy/archive/v0.2.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/microsoft/dowhy", "keywords": "causality machine-learning causal-inference statistics graphical-model", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "dowhy", "package_url": "https://pypi.org/project/dowhy/", "platform": "", "project_url": "https://pypi.org/project/dowhy/", "project_urls": {"Download": "https://github.com/microsoft/dowhy/archive/v0.2.tar.gz", "Homepage": "https://github.com/microsoft/dowhy"}, "release_url": "https://pypi.org/project/dowhy/0.2/", "requires_dist": ["econml (>=0.5)", "matplotlib", "networkx (>=2.0)", "numpy (>=1.15)", "pandas (>=0.24)", "pydot (>=1.4)", "scikit-learn", "scipy", "statsmodels", "sympy (>=1.4)"], "requires_python": ">=3.4", "summary": "DoWhy is a Python library for causal inference that supports explicit modeling and testing of causal assumptions.", "version": "0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://dev.azure.com/ms/dowhy/_build/latest?definitionId=179&amp;branchName=master\" rel=\"nofollow\"><img alt=\"BuildStatus\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8f6511e8250f3036fa34fce2c8f6a7deb4c5d012/68747470733a2f2f6465762e617a7572652e636f6d2f6d732f646f7768792f5f617069732f6275696c642f7374617475732f6d6963726f736f66742e646f7768793f6272616e63684e616d653d6d6173746572\"></a> <a href=\"https://pypi.org/project/dowhy/\" rel=\"nofollow\"><img alt=\"PyPiVersion\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/789f0253725bb93d254ba0696e37f413a9621631/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f646f7768792e737667\"></a> <a href=\"https://pypi.org/project/dowhy/\" rel=\"nofollow\"><img alt=\"PythonSupport\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d718f770b5f102cfba896e9eba107d38e734cb59/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f646f7768792e737667\"></a></p>\n<div id=\"dowhy-making-causal-inference-easy\">\n<h2><a href=\"#id4\" rel=\"nofollow\">DoWhy | Making causal inference easy</a></h2>\n<p><a href=\"http://www.amitsharma.in\" rel=\"nofollow\">Amit Sharma</a>,\n<a href=\"http://www.kiciman.org\" rel=\"nofollow\">Emre Kiciman</a></p>\n<blockquote>\nRead the <a href=\"https://microsoft.github.io/dowhy/\" rel=\"nofollow\">docs</a> | Try it online! <a href=\"https://notebooks.azure.com/amshar/projects/dowhy/tree/docs/source\" rel=\"nofollow\"><img alt=\"AzureNotebooks\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5783c779efd87ccd9514b4dc9d6b2ce8daf9a140/68747470733a2f2f6e6f7465626f6f6b732e617a7572652e636f6d2f6c61756e63682e737667\"></a> <a href=\"https://mybinder.org/v2/gh/microsoft/dowhy/master?filepath=docs%2Fsource%2F\" rel=\"nofollow\"><img alt=\"Binder\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/85e91bbb928104e4ce317951541520c6b9c170e1/68747470733a2f2f6d7962696e6465722e6f72672f62616467655f6c6f676f2e737667\"></a></blockquote>\n<blockquote>\nBlog Posts: <a href=\"https://www.microsoft.com/en-us/research/blog/dowhy-a-library-for-causal-inference/\" rel=\"nofollow\">Introducing DoWhy</a> | <a href=\"https://medium.com/@akelleh/introducing-the-do-sampler-for-causal-inference-a3296ea9e78d\" rel=\"nofollow\">Using the Do-sampler</a></blockquote>\n<p>As computing systems are more frequently and more actively intervening in societally critical domains such as healthcare, education, and governance, it is critical to correctly predict and understand the causal effects of these interventions. Without an A/B test, conventional machine learning methods, built on pattern recognition and correlational analyses, are insufficient for causal reasoning.</p>\n<p>Much like machine learning libraries have done for prediction, <strong>\u201cDoWhy\u201d is a Python library that aims to spark causal thinking and analysis</strong>. DoWhy provides a unified interface for causal inference methods and automatically tests many assumptions, thus making inference accessible to non-experts.</p>\n<p>For a quick introduction to causal inference, check out <a href=\"https://github.com/amit-sharma/causal-inference-tutorial/\" rel=\"nofollow\">amit-sharma/causal-inference-tutorial</a>. We also gave a more comprehensive tutorial at the ACM Knowledge Discovery and Data Mining (<a href=\"http://www.kdd.org/kdd2018/\" rel=\"nofollow\">KDD 2018</a>) conference: <a href=\"http://causalinference.gitlab.io/kdd-tutorial/\" rel=\"nofollow\">causalinference.gitlab.io/kdd-tutorial</a>.</p>\n<p>Documentation for DoWhy is available at <a href=\"https://microsoft.github.io/dowhy/\" rel=\"nofollow\">microsoft.github.io/dowhy</a>.</p>\n<div id=\"contents\">\n<p>Contents</p>\n<ul>\n<li><a href=\"#dowhy-making-causal-inference-easy\" id=\"id4\" rel=\"nofollow\">DoWhy | Making causal inference easy</a><ul>\n<li><a href=\"#the-need-for-causal-inference\" id=\"id5\" rel=\"nofollow\">The need for causal inference</a></li>\n<li><a href=\"#installation\" id=\"id6\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#sample-causal-inference-analysis-in-dowhy\" id=\"id7\" rel=\"nofollow\">Sample causal inference analysis in DoWhy</a></li>\n<li><a href=\"#a-high-level-pandas-api\" id=\"id8\" rel=\"nofollow\">A High-level Pandas API</a></li>\n<li><a href=\"#graphical-models-and-potential-outcomes-best-of-both-worlds\" id=\"id9\" rel=\"nofollow\">Graphical Models and Potential Outcomes: Best of both worlds</a></li>\n<li><a href=\"#a-unifying-language-for-causal-inference\" id=\"id10\" rel=\"nofollow\">A unifying language for causal inference</a></li>\n<li><a href=\"#four-steps-of-causal-inference\" id=\"id11\" rel=\"nofollow\">Four steps of causal inference</a></li>\n<li><a href=\"#citing-this-package\" id=\"id12\" rel=\"nofollow\">Citing this package</a></li>\n<li><a href=\"#roadmap\" id=\"id13\" rel=\"nofollow\">Roadmap</a></li>\n<li><a href=\"#contributing\" id=\"id14\" rel=\"nofollow\">Contributing</a></li>\n</ul>\n</li>\n</ul>\n</div>\n<div id=\"the-need-for-causal-inference\">\n<h3><a href=\"#id5\" rel=\"nofollow\">The need for causal inference</a></h3>\n<p>Predictive models uncover patterns that connect the inputs and outcome in observed data. To intervene, however, we need to estimate the effect of changing an input from its current value, for which no data exists. Such questions, involving estimating a <em>counterfactual</em>, are common in decision-making scenarios.</p>\n<ul>\n<li><dl>\n<dt>Will it work?</dt>\n<dd><ul>\n<li>Does a proposed change to a system improve people\u2019s outcomes?</li>\n</ul>\n</dd>\n</dl>\n</li>\n<li><dl>\n<dt>Why did it work?</dt>\n<dd><ul>\n<li>What led to a change in a system\u2019s outcome?</li>\n</ul>\n</dd>\n</dl>\n</li>\n<li><dl>\n<dt>What should we do?</dt>\n<dd><ul>\n<li>What changes to a system are likely to improve outcomes for people?</li>\n</ul>\n</dd>\n</dl>\n</li>\n<li><dl>\n<dt>What are the overall effects?</dt>\n<dd><ul>\n<li>How does the system interact with human behavior?</li>\n<li>What is the effect of a system\u2019s recommendations on people\u2019s activity?</li>\n</ul>\n</dd>\n</dl>\n</li>\n</ul>\n<p>Answering these questions requires causal reasoning. While many methods exist\nfor causal inference, it is hard to compare their assumptions and robustness of results. DoWhy makes three contributions,</p>\n<ol>\n<li>Provides a principled way of modeling a given problem as a causal graph so\nthat all assumptions are explicit.</li>\n<li>Provides a unified interface for many popular causal inference methods, combining the two major frameworks of graphical models and potential outcomes.</li>\n<li>Automatically tests for the validity of assumptions if possible and assesses\nthe robustness of the estimate to violations.</li>\n</ol>\n</div>\n<div id=\"installation\">\n<h3><a href=\"#id6\" rel=\"nofollow\">Installation</a></h3>\n<p><strong>Requirements</strong></p>\n<p>DoWhy support Python 3+. It requires the following packages:</p>\n<ul>\n<li>numpy</li>\n<li>scipy</li>\n<li>scikit-learn</li>\n<li>pandas</li>\n<li>networkx  (for analyzing causal graphs)</li>\n<li>matplotlib (for general plotting)</li>\n<li>sympy (for rendering symbolic expressions)</li>\n</ul>\n<p>Install the latest release using pip.</p>\n<pre>pip install dowhy\n</pre>\n<p>If you prefer the latest dev version, clone this repository and run the following command from the top-most folder of\nthe repository.</p>\n<pre>python setup.py install\n</pre>\n<p>If you face any problems, try installing dependencies manually.</p>\n<pre>pip install -r requirements.txt\n</pre>\n<p>Optionally, if you wish to input graphs in the dot format, then install pydot (or pygraphviz).</p>\n<p>For better-looking graphs, you can optionally install pygraphviz. To proceed,\nfirst install graphviz and then pygraphviz (on Ubuntu and Ubuntu WSL).</p>\n<pre>sudo apt install graphviz libgraphviz-dev graphviz-dev pkg-config\n<span class=\"c1\">## from https://github.com/pygraphviz/pygraphviz/issues/71\n</span>pip install pygraphviz --install-option<span class=\"o\">=</span><span class=\"s2\">\"--include-path=/usr/include/graphviz\"</span> <span class=\"se\">\\\n</span>--install-option<span class=\"o\">=</span><span class=\"s2\">\"--library-path=/usr/lib/graphviz/\"</span>\n</pre>\n<p>Keep in mind that pygraphviz installation can be problematic on the latest versions of Python3. Tested to work with Python 3.5.</p>\n</div>\n<div id=\"sample-causal-inference-analysis-in-dowhy\">\n<h3><a href=\"#id7\" rel=\"nofollow\">Sample causal inference analysis in DoWhy</a></h3>\n<p>Most DoWhy\nanalyses for causal inference take 4 lines to write, assuming a\npandas dataframe df that contains the data:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">dowhy</span> <span class=\"kn\">import</span> <span class=\"n\">CausalModel</span>\n<span class=\"kn\">import</span> <span class=\"nn\">dowhy.datasets</span>\n\n<span class=\"c1\"># Load some sample data</span>\n<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">dowhy</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">linear_dataset</span><span class=\"p\">(</span>\n    <span class=\"n\">beta</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span>\n    <span class=\"n\">num_common_causes</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span>\n    <span class=\"n\">num_instruments</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span>\n    <span class=\"n\">num_samples</span><span class=\"o\">=</span><span class=\"mi\">10000</span><span class=\"p\">,</span>\n    <span class=\"n\">treatment_is_binary</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<p>DoWhy supports two formats for providing the causal graph: <a href=\"https://github.com/GunterMueller/UNI_PASSAU_FMI_Graph_Drawing\" rel=\"nofollow\">gml</a> (preferred) and <a href=\"http://www.graphviz.org/documentation/\" rel=\"nofollow\">dot</a>. After loading in the data, we use the four main operations in DoWhy: <em>model</em>,\n<em>estimate</em>, <em>identify</em> and <em>refute</em>:</p>\n<pre><span class=\"c1\"># Create a causal model from the data and given graph.</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">CausalModel</span><span class=\"p\">(</span>\n    <span class=\"n\">data</span><span class=\"o\">=</span><span class=\"n\">data</span><span class=\"p\">[</span><span class=\"s2\">\"df\"</span><span class=\"p\">],</span>\n    <span class=\"n\">treatment</span><span class=\"o\">=</span><span class=\"n\">data</span><span class=\"p\">[</span><span class=\"s2\">\"treatment_name\"</span><span class=\"p\">],</span>\n    <span class=\"n\">outcome</span><span class=\"o\">=</span><span class=\"n\">data</span><span class=\"p\">[</span><span class=\"s2\">\"outcome_name\"</span><span class=\"p\">],</span>\n    <span class=\"n\">graph</span><span class=\"o\">=</span><span class=\"n\">data</span><span class=\"p\">[</span><span class=\"s2\">\"gml_graph\"</span><span class=\"p\">])</span>\n\n<span class=\"c1\"># Identify causal effect and return target estimands</span>\n<span class=\"n\">identified_estimand</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">identify_effect</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># Estimate the target estimand using a statistical method.</span>\n<span class=\"n\">estimate</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">estimate_effect</span><span class=\"p\">(</span><span class=\"n\">identified_estimand</span><span class=\"p\">,</span>\n                                 <span class=\"n\">method_name</span><span class=\"o\">=</span><span class=\"s2\">\"backdoor.propensity_score_matching\"</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Refute the obtained estimate using multiple robustness checks.</span>\n<span class=\"n\">refute_results</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">refute_estimate</span><span class=\"p\">(</span><span class=\"n\">identified_estimand</span><span class=\"p\">,</span> <span class=\"n\">estimate</span><span class=\"p\">,</span>\n                                       <span class=\"n\">method_name</span><span class=\"o\">=</span><span class=\"s2\">\"random_common_cause\"</span><span class=\"p\">)</span>\n</pre>\n<p>DoWhy stresses on the interpretability of its output. At any point in the analysis,\nyou can inspect the untested assumptions, identified estimands (if any) and the\nestimate (if any). Here\u2019s a sample output of the linear regression estimator.</p>\n<img alt=\"https://raw.githubusercontent.com/microsoft/dowhy/master/docs/images/regression_output.png\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/138286662f642e7b2fa378e76f52fe667b69cb4e/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6d6963726f736f66742f646f7768792f6d61737465722f646f63732f696d616765732f72656772657373696f6e5f6f75747075742e706e67\">\n<p>For detailed code examples, check out the Jupyter notebooks in <a href=\"https://github.com/microsoft/dowhy/tree/master/docs/source/example_notebooks/\" rel=\"nofollow\">docs/source/example_notebooks</a>, or try them online at <a href=\"https://mybinder.org/v2/gh/microsoft/dowhy/master?filepath=docs%2Fsource%2F\" rel=\"nofollow\">Binder</a>.</p>\n</div>\n<div id=\"a-high-level-pandas-api\">\n<h3><a href=\"#id8\" rel=\"nofollow\">A High-level Pandas API</a></h3>\n<p>We\u2019ve made an even simpler API for dowhy which is a light layer on top of the standard one. The goal\nwas to make causal analysis much more like regular exploratory analysis. To use this API, simply\nimport <code>dowhy.api</code>. This will magically add the <code>causal</code> namespace to your\n<code>pandas.DataFrame</code> s. Then,\nyou can use the namespace as follows.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">dowhy.api</span>\n<span class=\"kn\">import</span> <span class=\"nn\">dowhy.datasets</span>\n\n<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">dowhy</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">linear_dataset</span><span class=\"p\">(</span><span class=\"n\">beta</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span>\n    <span class=\"n\">num_common_causes</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"n\">num_instruments</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"n\">num_samples</span><span class=\"o\">=</span><span class=\"mi\">1000</span><span class=\"p\">,</span>\n    <span class=\"n\">treatment_is_binary</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># data['df'] is just a regular pandas.DataFrame</span>\n<span class=\"n\">data</span><span class=\"p\">[</span><span class=\"s1\">'df'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">causal</span><span class=\"o\">.</span><span class=\"n\">do</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">=</span><span class=\"s1\">'v0'</span><span class=\"p\">,</span> <span class=\"c1\"># name of treatment variable</span>\n                     <span class=\"n\">variable_types</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'v0'</span><span class=\"p\">:</span> <span class=\"s1\">'b'</span><span class=\"p\">,</span> <span class=\"s1\">'y'</span><span class=\"p\">:</span> <span class=\"s1\">'c'</span><span class=\"p\">,</span> <span class=\"s1\">'W0'</span><span class=\"p\">:</span> <span class=\"s1\">'c'</span><span class=\"p\">},</span>\n                     <span class=\"n\">outcome</span><span class=\"o\">=</span><span class=\"s1\">'y'</span><span class=\"p\">,</span>\n                     <span class=\"n\">common_causes</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'W0'</span><span class=\"p\">])</span><span class=\"o\">.</span><span class=\"n\">groupby</span><span class=\"p\">(</span><span class=\"s1\">'v0'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"o\">=</span><span class=\"s1\">'y'</span><span class=\"p\">,</span> <span class=\"n\">kind</span><span class=\"o\">=</span><span class=\"s1\">'bar'</span><span class=\"p\">)</span>\n</pre>\n<img alt=\"https://raw.githubusercontent.com/microsoft/dowhy/master/docs/images/do_barplot.png\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b740e329500ca8c52d5363e67f79acc66ce2bfca/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6d6963726f736f66742f646f7768792f6d61737465722f646f63732f696d616765732f646f5f626172706c6f742e706e67\">\n<p>The <code>do</code> method in the causal namespace generates a random sample from $P(outcome|do(X=x))$ of the\nsame length as your data set, and returns this outcome as a new <code>DataFrame</code>. You can continue to perform\nthe usual <code>DataFrame</code> operations with this sample, and so you can compute statistics and create plots\nfor causal outcomes!</p>\n<p>The <code>do</code> method is built on top of the lower-level <code>dowhy</code> objects, so can still take a graph and perform\nidentification automatically when you provide a graph instead of <code>common_causes</code>.</p>\n</div>\n<div id=\"graphical-models-and-potential-outcomes-best-of-both-worlds\">\n<h3><a href=\"#id9\" rel=\"nofollow\">Graphical Models and Potential Outcomes: Best of both worlds</a></h3>\n<p>DoWhy builds on two of the most powerful frameworks for causal inference:\ngraphical models and potential outcomes. It uses graph-based criteria and\ndo-calculus for modeling assumptions and identifying a non-parametric causal effect.\nFor estimation, it switches to methods based primarily on potential outcomes.</p>\n</div>\n<div id=\"a-unifying-language-for-causal-inference\">\n<h3><a href=\"#id10\" rel=\"nofollow\">A unifying language for causal inference</a></h3>\n<p>DoWhy is based on a simple unifying language for causal inference. Causal\ninference may seem tricky, but almost all methods follow four key steps:</p>\n<ol>\n<li>Model a causal inference problem using assumptions.</li>\n<li>Identify an expression for the causal effect under these assumptions (\u201ccausal estimand\u201d).</li>\n<li>Estimate the expression using statistical methods such as matching or instrumental variables.</li>\n<li>Finally, verify the validity of the estimate using a variety of robustness checks.</li>\n</ol>\n<p>This workflow can be captured by four key verbs in DoWhy:</p>\n<ul>\n<li>model</li>\n<li>identify</li>\n<li>estimate</li>\n<li>refute</li>\n</ul>\n<p>Using these verbs, DoWhy implements a causal inference engine that can support\na variety of methods. <em>model</em> encodes prior knowledge as a formal causal graph, <em>identify</em> uses\ngraph-based methods to identify the causal effect, <em>estimate</em> uses\nstatistical methods for estimating the identified estimand, and finally <em>refute</em>\ntries to refute the obtained estimate by testing robustness to assumptions.</p>\n<p>DoWhy brings three key differences compared to available software for causal inference:</p>\n<dl>\n<dt><strong>Explicit identifying assumptions</strong></dt>\n<dd><p>Assumptions are first-class citizens in DoWhy.</p>\n<p>Each analysis starts with a\nbuilding a causal model. The assumptions can be viewed graphically or in terms\nof conditional independence statements. Wherever possible, DoWhy can also\nautomatically test for stated assumptions using observed data.</p>\n</dd>\n<dt><strong>Separation between identification and estimation</strong></dt>\n<dd><p>Identification is the causal problem. Estimation is simply a statistical problem.</p>\n<p>DoWhy\nrespects this boundary and treats them separately. This focuses the causal\ninference effort on identification, and frees up estimation using any\navailable statistical estimator for a target estimand. In addition, multiple\nestimation methods can be used for a single identified_estimand and\nvice-versa.</p>\n</dd>\n<dt><strong>Automated robustness checks</strong></dt>\n<dd><p>What happens when key identifying assumptions may not be satisfied?</p>\n<p>The most critical, and often skipped, part of causal analysis is checking the\nrobustness of an estimate to unverified assumptions. DoWhy makes it easy to\nautomatically run sensitivity and robustness checks on the obtained estimate.</p>\n</dd>\n</dl>\n<p>Finally, DoWhy is easily extensible, allowing other implementations of the\nfour verbs to co-exist (we hope to integrate with external\nimplementations in the future). The four verbs are mutually independent, so their\nimplementations can be combined in any way.</p>\n<p>Below are more details about the current implementation of each of these verbs.</p>\n</div>\n<div id=\"four-steps-of-causal-inference\">\n<h3><a href=\"#id11\" rel=\"nofollow\">Four steps of causal inference</a></h3>\n<ol>\n<li><strong>Model a causal problem</strong></li>\n</ol>\n<p>DoWhy creates an underlying causal graphical model for each problem. This\nserves to make each causal assumption explicit. This graph need not be\ncomplete\u2014you can provide a partial graph, representing prior\nknowledge about some of the variables. DoWhy automatically considers the rest\nof the variables as potential confounders.</p>\n<p>Currently, DoWhy supports two formats for graph input: <a href=\"https://github.com/GunterMueller/UNI_PASSAU_FMI_Graph_Drawing\" rel=\"nofollow\">gml</a> (preferred) and\n<a href=\"http://www.graphviz.org/documentation/\" rel=\"nofollow\">dot</a>. We strongly suggest to use gml as the input format, as it works well with networkx. You can provide the graph either as a .gml file or as a string. If you prefer to use dot format, you will need to install additional packages (pydot or pygraphviz, see the installation section above). Both .dot files and string format are supported.</p>\n<p>While not recommended, you can also specify common causes and/or instruments directly\ninstead of providing a graph.</p>\n<ol>\n<li><strong>Identify a target estimand under the model</strong></li>\n</ol>\n<p>Based on the causal graph, DoWhy finds all possible ways of identifying a desired causal effect based on\nthe graphical model. It uses graph-based criteria and do-calculus to find\npotential ways find expressions that can identify the causal effect.</p>\n<ol>\n<li><strong>Estimate causal effect based on the identified estimand</strong></li>\n</ol>\n<p>DoWhy supports methods based on both back-door criterion and instrumental\nvariables. It also provides a non-parametric permutation test for testing\nthe statistical significance of obtained estimate.</p>\n<p>Currently supported back-door criterion methods.</p>\n<ul>\n<li><dl>\n<dt>Methods based on estimating the treatment assignment</dt>\n<dd><ul>\n<li>Propensity-based Stratification</li>\n<li>Propensity Score Matching</li>\n<li>Inverse Propensity Weighting</li>\n</ul>\n</dd>\n</dl>\n</li>\n<li><dl>\n<dt>Methods based on estimating the response surface</dt>\n<dd><ul>\n<li>Regression</li>\n</ul>\n</dd>\n</dl>\n</li>\n</ul>\n<p>Currently supported methods based on instrumental variables.</p>\n<ul>\n<li>Binary Instrument/Wald Estimator</li>\n<li>Regression discontinuity</li>\n</ul>\n<ol>\n<li><strong>Refute the obtained estimate</strong></li>\n</ol>\n<p>Having access to multiple refutation methods to verify a causal inference is\na key benefit of using DoWhy.</p>\n<p>DoWhy supports the following refutation methods.</p>\n<ul>\n<li>Placebo Treatment</li>\n<li>Irrelevant Additional Confounder</li>\n<li>Subset validation</li>\n</ul>\n</div>\n<div id=\"citing-this-package\">\n<h3><a href=\"#id12\" rel=\"nofollow\">Citing this package</a></h3>\n<p>If you find DoWhy useful for your research work, please cite us as follows:</p>\n<p>Amit Sharma, Emre Kiciman, et al. DoWhy: A Python package for causal inference. 2019. <a href=\"https://github.com/microsoft/dowhy\" rel=\"nofollow\">https://github.com/microsoft/dowhy</a></p>\n<p>Bibtex:</p>\n<pre>@misc{dowhy,\nauthors={Sharma, Amit and Kiciman, Emre and others},\ntitle={Do{W}hy: {A Python package for causal inference}},\nhowpublished={https://github.com/microsoft/dowhy}\nyear={2019}\n}\n</pre>\n</div>\n<div id=\"roadmap\">\n<h3><a href=\"#id13\" rel=\"nofollow\">Roadmap</a></h3>\n<p>The <a href=\"https://github.com/microsoft/dowhy/projects\" rel=\"nofollow\">projects</a> page lists the next steps for DoWhy. If you would like to contribute, have a look at the current projects. If you have a specific request for DoWhy, please raise an issue <a href=\"https://github.com/microsoft/dowhy/issues\" rel=\"nofollow\">here</a>.</p>\n</div>\n<div id=\"contributing\">\n<h3><a href=\"#id14\" rel=\"nofollow\">Contributing</a></h3>\n<p>This project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit <a href=\"https://cla.microsoft.com\" rel=\"nofollow\">https://cla.microsoft.com</a>.</p>\n<p>When you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.</p>\n<p>This project has adopted the <a href=\"https://opensource.microsoft.com/codeofconduct/\" rel=\"nofollow\">Microsoft Open Source Code of Conduct</a>.\nFor more information see the <a href=\"https://opensource.microsoft.com/codeofconduct/faq/\" rel=\"nofollow\">Code of Conduct FAQ</a> or\ncontact <a href=\"mailto:opencode%40microsoft.com\">opencode<span>@</span>microsoft<span>.</span>com</a> with any additional questions or comments.</p>\n</div>\n</div>\n\n          </div>"}, "last_serial": 6435190, "releases": {"0.1.1": [{"comment_text": "", "digests": {"md5": "0d530080cf915fc49474976abab38d5a", "sha256": "b322fdda2f43677e37ce44bcb1e413c5e54239e718a5b8616e98fb7b87138d5b"}, "downloads": -1, "filename": "dowhy-0.1.1.tar.gz", "has_sig": false, "md5_digest": "0d530080cf915fc49474976abab38d5a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.0", "size": 459272, "upload_time": "2019-07-15T13:12:59", "upload_time_iso_8601": "2019-07-15T13:12:59.508285Z", "url": "https://files.pythonhosted.org/packages/ec/24/1909fc4098920682e91d10a317186d11190c87be67319328fee0953d480d/dowhy-0.1.1.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "f98154a914f3d689fd8e485aec4e7e42", "sha256": "5f87eb595f7107cf726e99ef2ae112d17f2f496baec87b42ccd98e7d717311a1"}, "downloads": -1, "filename": "dowhy-0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "f98154a914f3d689fd8e485aec4e7e42", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.4", "size": 64663, "upload_time": "2020-01-11T06:22:20", "upload_time_iso_8601": "2020-01-11T06:22:20.433781Z", "url": "https://files.pythonhosted.org/packages/58/a9/a1d1a173d6b44a4c61656c102729da1d4408d972085dda48ed0517eb13b7/dowhy-0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fc543cc677adf815703855f98c56bf6b", "sha256": "99d58f0098cf37f2b69073f9b47253cafe13f1136d694cd972bec98e9c6ee484"}, "downloads": -1, "filename": "dowhy-0.2.tar.gz", "has_sig": false, "md5_digest": "fc543cc677adf815703855f98c56bf6b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.4", "size": 1040878, "upload_time": "2020-01-11T06:22:24", "upload_time_iso_8601": "2020-01-11T06:22:24.012846Z", "url": "https://files.pythonhosted.org/packages/e2/e2/ebf4e39b363109afebf6a14c70be354479c60879692eee8c38fe9967d30f/dowhy-0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "f98154a914f3d689fd8e485aec4e7e42", "sha256": "5f87eb595f7107cf726e99ef2ae112d17f2f496baec87b42ccd98e7d717311a1"}, "downloads": -1, "filename": "dowhy-0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "f98154a914f3d689fd8e485aec4e7e42", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.4", "size": 64663, "upload_time": "2020-01-11T06:22:20", "upload_time_iso_8601": "2020-01-11T06:22:20.433781Z", "url": "https://files.pythonhosted.org/packages/58/a9/a1d1a173d6b44a4c61656c102729da1d4408d972085dda48ed0517eb13b7/dowhy-0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fc543cc677adf815703855f98c56bf6b", "sha256": "99d58f0098cf37f2b69073f9b47253cafe13f1136d694cd972bec98e9c6ee484"}, "downloads": -1, "filename": "dowhy-0.2.tar.gz", "has_sig": false, "md5_digest": "fc543cc677adf815703855f98c56bf6b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.4", "size": 1040878, "upload_time": "2020-01-11T06:22:24", "upload_time_iso_8601": "2020-01-11T06:22:24.012846Z", "url": "https://files.pythonhosted.org/packages/e2/e2/ebf4e39b363109afebf6a14c70be354479c60879692eee8c38fe9967d30f/dowhy-0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:50:07 2020"}