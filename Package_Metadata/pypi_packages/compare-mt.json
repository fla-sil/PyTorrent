{"info": {"author": "Graham Neubig", "author_email": "", "bugtrack_url": null, "classifiers": ["Intended Audience :: Developers", "License :: OSI Approved :: BSD License", "Programming Language :: Python :: 3", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Text Processing"], "description": "# compare-mt\nby [NeuLab](http://www.cs.cmu.edu/~neulab/) @ [CMU LTI](https://lti.cs.cmu.edu), and other contributors\n\n[![Build Status](https://travis-ci.org/neulab/compare-mt.svg?branch=master)](https://travis-ci.org/neulab/compare-mt)\n\n`compare-mt` (for \"compare my text\") is a program to compare the output of multiple systems for language generation,\nincluding machine translation, summarization, dialog response generation, etc. \nTo use it you need to have, in text format, a \"correct\" reference, and the output of two different systems.\nBased on this, `compare-mt` will run a number of analyses that attempt to pick out salient differences between\nthe systems, which will make it easier for you to figure out what things one system is doing better than another.\n\n## Basic Usage\n\nFirst, you need to install the package:\n\n```bash\n# Requirements\npip install -r requirements.txt\n# Install the package\npython setup.py install\n```\n\nThen, as an example, you can run this over two included system outputs.\n\n```bash\ncompare-mt example/ted.ref.eng example/ted.sys1.eng example/ted.sys2.eng\n```\n\nHere, system 1 and system 2 are the baseline phrase-based and neural Slovak-English systems from our\n[EMNLP 2018 paper](http://aclweb.org/anthology/D18-1103). This will print out a number of statistics including:\n\n* **Aggregate Scores:** A report on overall BLEU scores and length ratios\n* **Word Accuracy Analysis:** A report on the F-measure of words by frequency bucket\n* **Sentence Bucket Analysis:** Bucket sentences by various statistics (e.g. sentence BLEU, length difference with the\n  reference, overall length), and calculate statistics by bucket (e.g. number of sentences, BLEU score per bucket)\n* **N-gram Difference Analysis:** Calculate which n-grams one system is consistently translating better\n* **Sentence Examples:** Find sentences where one system is doing better than the other according to sentence BLEU\n\nYou can see an example of running this analysis (as well as the more advanced analysis below) either through a\n[generated HTML report here](http://phontron.com/compare-mt/output/), or in the following narrated video:\n\n[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/K-MNPOGKnDQ/0.jpg)](https://www.youtube.com/watch?v=K-MNPOGKnDQ)\n\nTo summarize the results that immediately stick out from the basic analysis:\n\n* From the *aggregate scores* we can see that the BLEU of neural MT is higher, but its sentences are slightly shorter.\n* From the *word accuracy analysis* we can see that phrase-based MT is better at low-frequency words.\n* From the *sentence bucket analysis* we can see that neural seems to be better at translating shorter sentences.\n* From the *n-gram difference analysis* we can see that there are a few words that neural MT is not good at\n  but phrase based MT gets right (e.g. \"phantom\"), while there are a few long phrases that neural MT does better with\n  (e.g. \"going to show you\").\n\nIf you run on your own data, you might be able to find more interesting things about your own systems. Try comparing\nyour modified system with your baseline and seeing what you find! \n\n## Other Options\n\nThere are many options that can be used to do different types of analysis.\nIf you want to find all the different types of analysis supported, the most comprehensive way to do so is by\ntaking a look at `compare-mt`, which is documented relatively well and should give examples.\nWe do highlight a few particularly useful and common types of analysis below:\n\n### Significance Tests\n\nThe script allows you to perform statistical significance tests for scores based on bootstrap resampling. You can set\nthe number of samplings manually. Here is an example using the example data:\n\n\n```bash\ncompare-mt example/ted.ref.eng example/ted.sys1.eng example/ted.sys2.eng --compare_scores score_type=bleu,bootstrap=1000,prob_thresh=0.05\n```\n\n### Using Training Set Frequency\n\nOne useful piece of analysis is the \"word accuracy by frequency\" analysis. By default this frequency is the frequency\nin the *test set*, but arguably it is more informative to know accuracy by frequency in the *training set* as this\ndemonstrates the models' robustness to words they haven't seen much, or at all, in the training data. To change the\ncorpus used to calculate word frequency and use the training set (or some other set), you can set the `freq_corpus_file`\noption to the appropriate corpus.\n\n\n```bash\ncompare-mt example/ted.ref.eng example/ted.sys1.eng example/ted.sys2.eng\n        --compare_word_accuracies bucket_type=freq,freq_corpus_file=example/ted.train.eng\n```\n\nIn addition, because training sets may be very big, you can also calculate the counts on the file beforehand,\n\n```bash\npython scripts/count.py < example/ted.train.eng > example/ted.train.counts\n```\n\nand then use these counts directly to improve efficiency.\n\n```bash\ncompare-mt example/ted.ref.eng example/ted.sys1.eng example/ted.sys2.eng\n        --compare_word_accuracies bucket_type=freq,freq_count_file=example/ted.train.counts\n```\n\n\n### Incorporating Word/Sentence Labels\n\nIf you're interested in performing aggregate analysis over labels for each word/sentence instead of the words/sentences themselves, it\nis possible to do so. As an example, we've included POS tags for each of the example outputs. You can use these in\naggregate analysis, or n-gram-based analysis. The following gives an example:\n\n\n```bash\ncompare-mt example/ted.ref.eng example/ted.sys1.eng example/ted.sys2.eng \n    --compare_word_accuracies bucket_type=label,ref_labels=example/ted.ref.eng.tag,out_labels=\"example/ted.sys1.eng.tag;example/ted.sys2.eng.tag\",label_set=CC+DT+IN+JJ+NN+NNP+NNS+PRP+RB+TO+VB+VBP+VBZ \n    --compare_ngrams compare_type=match,ref_labels=example/ted.ref.eng.tag,out_labels=\"example/ted.sys1.eng.tag;example/ted.sys2.eng.tag\"\n```\n\nThis will calculate word accuracies and n-gram matches by POS bucket, and allows you to see things like the fact\nthat the phrase-based MT system is better at translating content words such as nouns and verbs, while neural MT\nis doing better at translating function words.\n\nIt also is possible to create labels that represent numberical values. For example, `scripts/relativepositiontag.py` calculates the relative position of words in the sentence, where 0 is the first word in the sentence, 0.5 is the word in the middle, and 1.0 is the word in the end. These numerical values can then be bucketed. Here is an example:\n\n```bash\ncompare-mt example/ted.ref.eng example/ted.sys1.eng example/ted.sys2.eng \n    --compare_word_accuracies bucket_type=numlabel,ref_labels=example/ted.ref.eng.rptag,out_labels=\"example/ted.sys1.eng.rptag;example/ted.sys2.eng.rptag\"\n```\n\nFrom this particular analysis we can discover that NMT does worse than PBMT at the end of the sentence, and of course other varieties of numerical labels could be used to measure different properties of words.\n\nYou can also perform analysis over labels for sentences. Here is an example:\n\n```bash\ncompare-mt example/ted.ref.eng example/ted.sys1.eng example/ted.sys2.eng \n    --compare_sentence_buckets 'bucket_type=label,out_labels=example/ted.sys1.eng.senttag;example/ted.sys2.eng.senttag,label_set=0+10+20+30+40+50+60+70+80+90+100,statistic_type=score,score_measure=bleu'\n```\n\n\n### Analyzing Source Words\n\nIf you have a source corpus that is aligned to the target, you can also analyze accuracies according to features of the\nsource language words, which would allow you to examine whether, for example, infrequent words on the source side are\nhard to output properly. Here is an example using the example data:\n\n```bash\ncompare-mt example/ted.ref.eng example/ted.sys1.eng example/ted.sys2.eng --src_file example/ted.orig.slk --compare_src_word_accuracies ref_align_file=example/ted.ref.align\n```\n\n### Analyzing Word Likelihoods\n\nIf you wish to analyze the word log likelihoods by two systems on the target corpus, you can use the following\n\n```bash\ncompare-ll --ref example/ll_test.txt --ll-files example/ll_test.sys1.likelihood example/ll_test.sys2.likelihood --compare-word-likelihoods bucket_type=freq,freq_corpus_file=example/ll_test.txt\n```\n\nYou can analyze the word log likelihoods over labels for each word instead of the words themselves:\n\n```bash\ncompare-ll --ref example/ll_test.txt --ll-files example/ll_test.sys1.likelihood example/ll_test.sys2.likelihood --compare-word-likelihoods bucket_type=label,label_corpus=example/ll_test.tag,label_set=CC+DT+IN+JJ+NN+NNP+NNS+PRP+RB+TO+VB+VBP+VBZ\n```\n\nNOTE: You can also use the above to also analyze the word likelihoods produced by two language models.\n\n### Analyzing Other Language Generation Systems\n\nYou can also analyze other language generation systems using the script. Here is an example of comparing two text summarization systems. \n\n```bash\ncompare-mt example/sum.ref.eng example/sum.sys1.eng example/sum.sys2.eng --compare_scores 'score_type=rouge1' 'score_type=rouge2' 'score_type=rougeL'\n```\n\n## Citation/References\n\nIf you use compare-mt, we'd appreciate if you cite the [paper](http://arxiv.org/abs/1903.07926) about it!\n\n    @article{DBLP:journals/corr/abs-1903-07926,\n      author    = {Graham Neubig and Zi{-}Yi Dou and Junjie Hu and Paul Michel and Danish Pruthi and Xinyi Wang and John Wieting},\n      title     = {compare-mt: {A} Tool for Holistic Comparison of Language Generation Systems},\n      journal   = {CoRR},\n      volume    = {abs/1903.07926},\n      year      = {2019},\n      url       = {http://arxiv.org/abs/1903.07926},\n    }\n\nThere is an extensive literature review included in the paper above, but some key papers that it borrows ideas from are below:\n\n* **Automatic Error Analysis:**\n  Popovic and Ney \"[Towards Automatic Error Analysis of Machine Translation Output](https://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00072)\" Computational Linguistics 2011.\n* **POS-based Analysis:**\n  Chiang et al. \"[The Hiero Machine Translation System](http://aclweb.org/anthology/H05-1098)\" EMNLP 2005.\n* **n-gram Difference Analysis**\n  Akabe et al. \"[Discriminative Language Models as a Tool for Machine Translation Error Analysis](http://www.phontron.com/paper/akabe14coling.pdf)\" COLING 2014.\n\nThere is also other good software for automatic comparison or error analysis of MT systems:\n\n* **[MT-ComparEval](https://github.com/choko/MT-ComparEval):** Very nice for visualization of individual examples, but\n  not as focused on aggregate analysis as `compare-mt`. Also has more software dependencies and requires using a web\n  browser, while `compare-mt` can be used as a command-line tool.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/neulab/compare-mt", "keywords": "", "license": "BSD 3-Clause", "maintainer": "", "maintainer_email": "", "name": "compare-mt", "package_url": "https://pypi.org/project/compare-mt/", "platform": "", "project_url": "https://pypi.org/project/compare-mt/", "project_urls": {"Homepage": "https://github.com/neulab/compare-mt"}, "release_url": "https://pypi.org/project/compare-mt/0.2.8/", "requires_dist": null, "requires_python": "", "summary": "Holistic comparison of the output of text generation models", "version": "0.2.8", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>compare-mt</h1>\n<p>by <a href=\"http://www.cs.cmu.edu/%7Eneulab/\" rel=\"nofollow\">NeuLab</a> @ <a href=\"https://lti.cs.cmu.edu\" rel=\"nofollow\">CMU LTI</a>, and other contributors</p>\n<p><a href=\"https://travis-ci.org/neulab/compare-mt\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/159501543e2f237e88bb457d405a8e6bb9f5c357/68747470733a2f2f7472617669732d63692e6f72672f6e65756c61622f636f6d706172652d6d742e7376673f6272616e63683d6d6173746572\"></a></p>\n<p><code>compare-mt</code> (for \"compare my text\") is a program to compare the output of multiple systems for language generation,\nincluding machine translation, summarization, dialog response generation, etc.\nTo use it you need to have, in text format, a \"correct\" reference, and the output of two different systems.\nBased on this, <code>compare-mt</code> will run a number of analyses that attempt to pick out salient differences between\nthe systems, which will make it easier for you to figure out what things one system is doing better than another.</p>\n<h2>Basic Usage</h2>\n<p>First, you need to install the package:</p>\n<pre><span class=\"c1\"># Requirements</span>\npip install -r requirements.txt\n<span class=\"c1\"># Install the package</span>\npython setup.py install\n</pre>\n<p>Then, as an example, you can run this over two included system outputs.</p>\n<pre>compare-mt example/ted.ref.eng example/ted.sys1.eng example/ted.sys2.eng\n</pre>\n<p>Here, system 1 and system 2 are the baseline phrase-based and neural Slovak-English systems from our\n<a href=\"http://aclweb.org/anthology/D18-1103\" rel=\"nofollow\">EMNLP 2018 paper</a>. This will print out a number of statistics including:</p>\n<ul>\n<li><strong>Aggregate Scores:</strong> A report on overall BLEU scores and length ratios</li>\n<li><strong>Word Accuracy Analysis:</strong> A report on the F-measure of words by frequency bucket</li>\n<li><strong>Sentence Bucket Analysis:</strong> Bucket sentences by various statistics (e.g. sentence BLEU, length difference with the\nreference, overall length), and calculate statistics by bucket (e.g. number of sentences, BLEU score per bucket)</li>\n<li><strong>N-gram Difference Analysis:</strong> Calculate which n-grams one system is consistently translating better</li>\n<li><strong>Sentence Examples:</strong> Find sentences where one system is doing better than the other according to sentence BLEU</li>\n</ul>\n<p>You can see an example of running this analysis (as well as the more advanced analysis below) either through a\n<a href=\"http://phontron.com/compare-mt/output/\" rel=\"nofollow\">generated HTML report here</a>, or in the following narrated video:</p>\n<p><a href=\"https://www.youtube.com/watch?v=K-MNPOGKnDQ\" rel=\"nofollow\"><img alt=\"IMAGE ALT TEXT HERE\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/13a228315daad4682a883b904c2679c3c62fe629/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f4b2d4d4e504f474b6e44512f302e6a7067\"></a></p>\n<p>To summarize the results that immediately stick out from the basic analysis:</p>\n<ul>\n<li>From the <em>aggregate scores</em> we can see that the BLEU of neural MT is higher, but its sentences are slightly shorter.</li>\n<li>From the <em>word accuracy analysis</em> we can see that phrase-based MT is better at low-frequency words.</li>\n<li>From the <em>sentence bucket analysis</em> we can see that neural seems to be better at translating shorter sentences.</li>\n<li>From the <em>n-gram difference analysis</em> we can see that there are a few words that neural MT is not good at\nbut phrase based MT gets right (e.g. \"phantom\"), while there are a few long phrases that neural MT does better with\n(e.g. \"going to show you\").</li>\n</ul>\n<p>If you run on your own data, you might be able to find more interesting things about your own systems. Try comparing\nyour modified system with your baseline and seeing what you find!</p>\n<h2>Other Options</h2>\n<p>There are many options that can be used to do different types of analysis.\nIf you want to find all the different types of analysis supported, the most comprehensive way to do so is by\ntaking a look at <code>compare-mt</code>, which is documented relatively well and should give examples.\nWe do highlight a few particularly useful and common types of analysis below:</p>\n<h3>Significance Tests</h3>\n<p>The script allows you to perform statistical significance tests for scores based on bootstrap resampling. You can set\nthe number of samplings manually. Here is an example using the example data:</p>\n<pre>compare-mt example/ted.ref.eng example/ted.sys1.eng example/ted.sys2.eng --compare_scores <span class=\"nv\">score_type</span><span class=\"o\">=</span>bleu,bootstrap<span class=\"o\">=</span><span class=\"m\">1000</span>,prob_thresh<span class=\"o\">=</span><span class=\"m\">0</span>.05\n</pre>\n<h3>Using Training Set Frequency</h3>\n<p>One useful piece of analysis is the \"word accuracy by frequency\" analysis. By default this frequency is the frequency\nin the <em>test set</em>, but arguably it is more informative to know accuracy by frequency in the <em>training set</em> as this\ndemonstrates the models' robustness to words they haven't seen much, or at all, in the training data. To change the\ncorpus used to calculate word frequency and use the training set (or some other set), you can set the <code>freq_corpus_file</code>\noption to the appropriate corpus.</p>\n<pre>compare-mt example/ted.ref.eng example/ted.sys1.eng example/ted.sys2.eng\n        --compare_word_accuracies <span class=\"nv\">bucket_type</span><span class=\"o\">=</span>freq,freq_corpus_file<span class=\"o\">=</span>example/ted.train.eng\n</pre>\n<p>In addition, because training sets may be very big, you can also calculate the counts on the file beforehand,</p>\n<pre>python scripts/count.py &lt; example/ted.train.eng &gt; example/ted.train.counts\n</pre>\n<p>and then use these counts directly to improve efficiency.</p>\n<pre>compare-mt example/ted.ref.eng example/ted.sys1.eng example/ted.sys2.eng\n        --compare_word_accuracies <span class=\"nv\">bucket_type</span><span class=\"o\">=</span>freq,freq_count_file<span class=\"o\">=</span>example/ted.train.counts\n</pre>\n<h3>Incorporating Word/Sentence Labels</h3>\n<p>If you're interested in performing aggregate analysis over labels for each word/sentence instead of the words/sentences themselves, it\nis possible to do so. As an example, we've included POS tags for each of the example outputs. You can use these in\naggregate analysis, or n-gram-based analysis. The following gives an example:</p>\n<pre>compare-mt example/ted.ref.eng example/ted.sys1.eng example/ted.sys2.eng \n    --compare_word_accuracies <span class=\"nv\">bucket_type</span><span class=\"o\">=</span>label,ref_labels<span class=\"o\">=</span>example/ted.ref.eng.tag,out_labels<span class=\"o\">=</span><span class=\"s2\">\"example/ted.sys1.eng.tag;example/ted.sys2.eng.tag\"</span>,label_set<span class=\"o\">=</span>CC+DT+IN+JJ+NN+NNP+NNS+PRP+RB+TO+VB+VBP+VBZ \n    --compare_ngrams <span class=\"nv\">compare_type</span><span class=\"o\">=</span>match,ref_labels<span class=\"o\">=</span>example/ted.ref.eng.tag,out_labels<span class=\"o\">=</span><span class=\"s2\">\"example/ted.sys1.eng.tag;example/ted.sys2.eng.tag\"</span>\n</pre>\n<p>This will calculate word accuracies and n-gram matches by POS bucket, and allows you to see things like the fact\nthat the phrase-based MT system is better at translating content words such as nouns and verbs, while neural MT\nis doing better at translating function words.</p>\n<p>It also is possible to create labels that represent numberical values. For example, <code>scripts/relativepositiontag.py</code> calculates the relative position of words in the sentence, where 0 is the first word in the sentence, 0.5 is the word in the middle, and 1.0 is the word in the end. These numerical values can then be bucketed. Here is an example:</p>\n<pre>compare-mt example/ted.ref.eng example/ted.sys1.eng example/ted.sys2.eng \n    --compare_word_accuracies <span class=\"nv\">bucket_type</span><span class=\"o\">=</span>numlabel,ref_labels<span class=\"o\">=</span>example/ted.ref.eng.rptag,out_labels<span class=\"o\">=</span><span class=\"s2\">\"example/ted.sys1.eng.rptag;example/ted.sys2.eng.rptag\"</span>\n</pre>\n<p>From this particular analysis we can discover that NMT does worse than PBMT at the end of the sentence, and of course other varieties of numerical labels could be used to measure different properties of words.</p>\n<p>You can also perform analysis over labels for sentences. Here is an example:</p>\n<pre>compare-mt example/ted.ref.eng example/ted.sys1.eng example/ted.sys2.eng \n    --compare_sentence_buckets <span class=\"s1\">'bucket_type=label,out_labels=example/ted.sys1.eng.senttag;example/ted.sys2.eng.senttag,label_set=0+10+20+30+40+50+60+70+80+90+100,statistic_type=score,score_measure=bleu'</span>\n</pre>\n<h3>Analyzing Source Words</h3>\n<p>If you have a source corpus that is aligned to the target, you can also analyze accuracies according to features of the\nsource language words, which would allow you to examine whether, for example, infrequent words on the source side are\nhard to output properly. Here is an example using the example data:</p>\n<pre>compare-mt example/ted.ref.eng example/ted.sys1.eng example/ted.sys2.eng --src_file example/ted.orig.slk --compare_src_word_accuracies <span class=\"nv\">ref_align_file</span><span class=\"o\">=</span>example/ted.ref.align\n</pre>\n<h3>Analyzing Word Likelihoods</h3>\n<p>If you wish to analyze the word log likelihoods by two systems on the target corpus, you can use the following</p>\n<pre>compare-ll --ref example/ll_test.txt --ll-files example/ll_test.sys1.likelihood example/ll_test.sys2.likelihood --compare-word-likelihoods <span class=\"nv\">bucket_type</span><span class=\"o\">=</span>freq,freq_corpus_file<span class=\"o\">=</span>example/ll_test.txt\n</pre>\n<p>You can analyze the word log likelihoods over labels for each word instead of the words themselves:</p>\n<pre>compare-ll --ref example/ll_test.txt --ll-files example/ll_test.sys1.likelihood example/ll_test.sys2.likelihood --compare-word-likelihoods <span class=\"nv\">bucket_type</span><span class=\"o\">=</span>label,label_corpus<span class=\"o\">=</span>example/ll_test.tag,label_set<span class=\"o\">=</span>CC+DT+IN+JJ+NN+NNP+NNS+PRP+RB+TO+VB+VBP+VBZ\n</pre>\n<p>NOTE: You can also use the above to also analyze the word likelihoods produced by two language models.</p>\n<h3>Analyzing Other Language Generation Systems</h3>\n<p>You can also analyze other language generation systems using the script. Here is an example of comparing two text summarization systems.</p>\n<pre>compare-mt example/sum.ref.eng example/sum.sys1.eng example/sum.sys2.eng --compare_scores <span class=\"s1\">'score_type=rouge1'</span> <span class=\"s1\">'score_type=rouge2'</span> <span class=\"s1\">'score_type=rougeL'</span>\n</pre>\n<h2>Citation/References</h2>\n<p>If you use compare-mt, we'd appreciate if you cite the <a href=\"http://arxiv.org/abs/1903.07926\" rel=\"nofollow\">paper</a> about it!</p>\n<pre><code>@article{DBLP:journals/corr/abs-1903-07926,\n  author    = {Graham Neubig and Zi{-}Yi Dou and Junjie Hu and Paul Michel and Danish Pruthi and Xinyi Wang and John Wieting},\n  title     = {compare-mt: {A} Tool for Holistic Comparison of Language Generation Systems},\n  journal   = {CoRR},\n  volume    = {abs/1903.07926},\n  year      = {2019},\n  url       = {http://arxiv.org/abs/1903.07926},\n}\n</code></pre>\n<p>There is an extensive literature review included in the paper above, but some key papers that it borrows ideas from are below:</p>\n<ul>\n<li><strong>Automatic Error Analysis:</strong>\nPopovic and Ney \"<a href=\"https://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00072\" rel=\"nofollow\">Towards Automatic Error Analysis of Machine Translation Output</a>\" Computational Linguistics 2011.</li>\n<li><strong>POS-based Analysis:</strong>\nChiang et al. \"<a href=\"http://aclweb.org/anthology/H05-1098\" rel=\"nofollow\">The Hiero Machine Translation System</a>\" EMNLP 2005.</li>\n<li><strong>n-gram Difference Analysis</strong>\nAkabe et al. \"<a href=\"http://www.phontron.com/paper/akabe14coling.pdf\" rel=\"nofollow\">Discriminative Language Models as a Tool for Machine Translation Error Analysis</a>\" COLING 2014.</li>\n</ul>\n<p>There is also other good software for automatic comparison or error analysis of MT systems:</p>\n<ul>\n<li><strong><a href=\"https://github.com/choko/MT-ComparEval\" rel=\"nofollow\">MT-ComparEval</a>:</strong> Very nice for visualization of individual examples, but\nnot as focused on aggregate analysis as <code>compare-mt</code>. Also has more software dependencies and requires using a web\nbrowser, while <code>compare-mt</code> can be used as a command-line tool.</li>\n</ul>\n\n          </div>"}, "last_serial": 6739851, "releases": {"0.2": [{"comment_text": "", "digests": {"md5": "bfe581b92a6bfccd2cf48c0f67df91c3", "sha256": "10d1e0a87f134544364aaaf0bee80947b6e7f8b5e43f6b2b49c00ee521a978d7"}, "downloads": -1, "filename": "compare_mt-0.2.tar.gz", "has_sig": false, "md5_digest": "bfe581b92a6bfccd2cf48c0f67df91c3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 31527, "upload_time": "2019-02-11T00:30:35", "upload_time_iso_8601": "2019-02-11T00:30:35.981066Z", "url": "https://files.pythonhosted.org/packages/37/17/c2e0651e6df64da1c4b796da4a61c7c0fb87f85561622b6b813b2305cb39/compare_mt-0.2.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "25516892e8c1de6ba11f18912da9e35a", "sha256": "25a1684cc2a07cf4d1db288067ae7785797478e083b5071a6fa6b65044488480"}, "downloads": -1, "filename": "compare_mt-0.2.1.tar.gz", "has_sig": false, "md5_digest": "25516892e8c1de6ba11f18912da9e35a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 31617, "upload_time": "2019-02-11T15:59:53", "upload_time_iso_8601": "2019-02-11T15:59:53.895598Z", "url": "https://files.pythonhosted.org/packages/ac/97/60c8782726b224b1fa9bdf823f6ac2dbd8f1a6c6e63d2653e3c69d715179/compare_mt-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "66923abe2e7e200d36d5278e0effc9f8", "sha256": "366ac175fd42cea3340bc81035fa4f13e89a5b484bd2abd526b4cf10266a044a"}, "downloads": -1, "filename": "compare_mt-0.2.2.tar.gz", "has_sig": false, "md5_digest": "66923abe2e7e200d36d5278e0effc9f8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 34752, "upload_time": "2019-06-11T22:11:57", "upload_time_iso_8601": "2019-06-11T22:11:57.295308Z", "url": "https://files.pythonhosted.org/packages/14/94/25f5f79d2305a8437c969d98bc79f190d2b05736ec5e3c015120e02fadd6/compare_mt-0.2.2.tar.gz", "yanked": false}], "0.2.3": [{"comment_text": "", "digests": {"md5": "c732630de37bf5eb6daed90b66afbdf3", "sha256": "08249b346f0613f1ca8cc5296fbd70a116d8e5e0493692e31ebf187718333a87"}, "downloads": -1, "filename": "compare_mt-0.2.3.tar.gz", "has_sig": false, "md5_digest": "c732630de37bf5eb6daed90b66afbdf3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 37211, "upload_time": "2019-07-02T17:31:56", "upload_time_iso_8601": "2019-07-02T17:31:56.429451Z", "url": "https://files.pythonhosted.org/packages/86/bb/c24f0185b78c20d8827bc1038f8f51dd645284d8657ba2384b5c38e7940c/compare_mt-0.2.3.tar.gz", "yanked": false}], "0.2.4": [{"comment_text": "", "digests": {"md5": "e84b6f678ef034bc1bd088936bbc390e", "sha256": "52b07d611e799af2da6c5a60c5243f8bdc0db65c32ce92a96b33ed3feb5d3f10"}, "downloads": -1, "filename": "compare_mt-0.2.4.tar.gz", "has_sig": false, "md5_digest": "e84b6f678ef034bc1bd088936bbc390e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 37804, "upload_time": "2019-07-03T21:16:46", "upload_time_iso_8601": "2019-07-03T21:16:46.812060Z", "url": "https://files.pythonhosted.org/packages/f1/54/872de9ecba0371ac5daaa280df7357dfd19e8f1c02a2a7d7a61a3a6b338c/compare_mt-0.2.4.tar.gz", "yanked": false}], "0.2.5": [{"comment_text": "", "digests": {"md5": "8fadf016a57384654110a6be14454abc", "sha256": "fda4beb9fa0a1f9070ef316b764e23afda529dd4ded074d9dd4846df1c72af3e"}, "downloads": -1, "filename": "compare_mt-0.2.5.tar.gz", "has_sig": false, "md5_digest": "8fadf016a57384654110a6be14454abc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 37874, "upload_time": "2019-07-20T00:52:00", "upload_time_iso_8601": "2019-07-20T00:52:00.706806Z", "url": "https://files.pythonhosted.org/packages/64/29/0f04eec25e0ad7f88696e0cd8db72f5d7ba5da25cd2bb743a1cb2fead312/compare_mt-0.2.5.tar.gz", "yanked": false}], "0.2.6": [{"comment_text": "", "digests": {"md5": "cef393105baa3db1fea5d56dd6e559dd", "sha256": "cefc400964a1374c058b9212645e3f76d06e1a24ad0975e79f3414134921a727"}, "downloads": -1, "filename": "compare_mt-0.2.6.tar.gz", "has_sig": false, "md5_digest": "cef393105baa3db1fea5d56dd6e559dd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 40154, "upload_time": "2019-08-07T14:31:08", "upload_time_iso_8601": "2019-08-07T14:31:08.942790Z", "url": "https://files.pythonhosted.org/packages/2e/95/ca3f56d29c8e2180098ba381f0a63c10fb5eb341251be846e631808a5694/compare_mt-0.2.6.tar.gz", "yanked": false}], "0.2.7": [{"comment_text": "", "digests": {"md5": "452fff7ef817d6f391710c9c96869b1f", "sha256": "5d338aba0e8dfc2ffb9a0905620b2ccb26e8390896343b81caf9fc8fccaa747b"}, "downloads": -1, "filename": "compare_mt-0.2.7.tar.gz", "has_sig": false, "md5_digest": "452fff7ef817d6f391710c9c96869b1f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 41437, "upload_time": "2019-09-19T00:01:58", "upload_time_iso_8601": "2019-09-19T00:01:58.238919Z", "url": "https://files.pythonhosted.org/packages/14/6c/6b9866a00a977e2375a20310334df2767aed5e26bf8e8aa803441ea282a5/compare_mt-0.2.7.tar.gz", "yanked": false}], "0.2.8": [{"comment_text": "", "digests": {"md5": "62f00dfa1561655982b873a8d75f3dc6", "sha256": "5aca950d5fe44f351fe81d10737dd7b58fd957a7e938e322e120aed3f3c696ca"}, "downloads": -1, "filename": "compare_mt-0.2.8.tar.gz", "has_sig": false, "md5_digest": "62f00dfa1561655982b873a8d75f3dc6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 43232, "upload_time": "2020-03-03T12:24:48", "upload_time_iso_8601": "2020-03-03T12:24:48.261138Z", "url": "https://files.pythonhosted.org/packages/e9/4c/e18ea230d656e273a1dd8a0fcea74154ebb343ea471dce7e95a6cd74ed7d/compare_mt-0.2.8.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "62f00dfa1561655982b873a8d75f3dc6", "sha256": "5aca950d5fe44f351fe81d10737dd7b58fd957a7e938e322e120aed3f3c696ca"}, "downloads": -1, "filename": "compare_mt-0.2.8.tar.gz", "has_sig": false, "md5_digest": "62f00dfa1561655982b873a8d75f3dc6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 43232, "upload_time": "2020-03-03T12:24:48", "upload_time_iso_8601": "2020-03-03T12:24:48.261138Z", "url": "https://files.pythonhosted.org/packages/e9/4c/e18ea230d656e273a1dd8a0fcea74154ebb343ea471dce7e95a6cd74ed7d/compare_mt-0.2.8.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:44:17 2020"}