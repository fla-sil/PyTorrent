{"info": {"author": "Roland Puntaier", "author_email": "roland.puntaier@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Environment :: Console", "Intended Audience :: End Users/Desktop", "Intended Audience :: Information Technology", "Intended Audience :: System Administrators", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Operating System :: OS Independent", "Operating System :: POSIX", "Programming Language :: Python :: 3.6", "Topic :: System :: Archiving", "Topic :: System :: Systems Administration", "Topic :: Utilities"], "description": "================================\nremdups - remove duplicate files\n================================\n\n:Author: Roland Puntaier\n:Homepage: https://github.com/rpuntaie/remdups\n:License: See LICENSE file\n\nremdups\n=======\n\n``remdups`` generates a script to\n\n- remove duplicate files\n\n- copy files from another directory to this one, ignoring duplicates\n\n- move files from another directory to this one, ignoring duplicates\n\nThe resulting script should be further inspected before executing it in your shell.\n\nUsage\n=====\n\n0) Optional. You can choose one or more source+hashing methods, via e.g.::\n\n      cat > .remdups_c.sha512\n      cat > .remdups_e.md5\n\n   All of .remdups_{c,b,d,e,n}.{sha512, sha384, sha256, sha224, sha1, md5} \n   contribute to the final hash. If you don't make such a file, the default is::\n\n     .remdups_c.sha256\n\n   {'c': 'content', 'b': 'block', 'd': 'date', 'e': 'exif', 'n': 'name'}\n\n1. Create the hash file by either of (can take a long time)::\n\n     remdups\n     remdups update\n     remdups update <fromdir>\n\n   The hashes are added to all .remdups_x.y. To rehash all files::\n\n     rm .remdups_*\n\n2. Make a script with rm, mv, cp commands.\n   It can be repeated with different options until the script is good.\n\n   $remdups rm -s script.sh\n   $remdups cp -s script.bat #if you used <fromdir>\n   $remdups mv -s script.py  #if you used <fromdir>\n\n   If the file ends in .sh, cp is used and the file names are in linux format.\n   This is usable also on Windows with MSYS, MSYS2 and CYGWIN.\n\n   If the file ends in .bat, Windows commands are used.\n\n   If the file ends in .py, python functions are used.\n\n3. Inspect the script and go back to 2., if necessary.\n   Changes to the script can also be done with the editor.\n\n4. execute script\n\n   $./script.sh\n\n\nAlternatively you can use remdups from your own python script, or interactively from a python prompt.\n\nInstall\n=======\n\n\n- Directly from PyPi:\n\n.. code:: console\n\n  $ pip install remdups\n\n\n- From `github`_: Clone, change to the directory and do\n\n.. code:: console\n\n  $ python setup.py install\n\n- If you plan to extend this tool\n\n  - fork on `github`_\n  - clone from your fork to you PC\n  - do an editable install\n\n  .. code:: console\n\n    $ pip install -e .\n\n  - test after change and bring coverage to 100%\n\n  .. code:: console\n\n    $ py.test --cov remdups.py --cov-report term-missing\n\n  - consider sharing changes useful for others (`github`_ pull request).\n\n.. hint:: \n\n    For more advanced file selection ``find`` can be used.\n    The following example ignores directory ``old`` and produces a hash for all JPEG files:\n\n    .. code:: console\n\n       $ find . -path \"old\" -prune -or -not -type d -and -iname \"\\*.jpg\" -exec sha256sum {} \\; > .remdups_c.sha256\n\nCommand Line\n============\n\nThe following is in addition to the help given with::\n\n  remdups --help\n\nThe sources for the hashes can be::\n\n   {'c': 'content', 'b': 'block', 'd': 'date', 'e': 'exif', 'n': 'name'}\n\nDon't include ``n``, because same files with different names cannot be found. ``c`` is the best.\n\nDo e.g::\n\n      cat > .remdups_b.sha512\n      cat > .remdups_c.sha256\n\nFill the hash files from the current directory::\n\n  remdups update\n\nOr fill the hash files from another directory::\n\n  remdups update <fromdir>\n\nIn the latter case the paths in the hash files will have a ``//`` or ``\\\\``\nto mark the start for the new relatives paths in a subsequent ``mv`` or ``cp`` command.\n\nOnce the hash files are filled create the script. It depend on the extension used::\n\n  remdups <command> -s script.sh <options>\n  remdups <command> -s script.bat <options>\n  remdups <command> -s script.py <options>\n\n``command`` can be ``rm``, ``cp``, ``mv``.\nThere is also ``dupsof`` and ``dupsoftail``, but they don't take a ``--script``, but print the output.\n\n``--keep-in``, ``--keep-out`` and ``--comment-out`` will remove different files of a duplicate group.\n``--safe`` will do a byte-wise comparison, before creating the script. That takes longer.\n\n``cp`` and ``mv`` also take ``--sort``: In this case the tree is not recreated, but the files are sorted\nto the provided tree structure using the file modification date. See https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior.\n\nAPI\n===\n\nWith your own python script you can load the file for hashing and use the\nloaded content immediately to create the new file, if not duplicate.\n\n.. code:: python\n\n  from remdups import *\n  hasher = Hasher()\n  allduplicates = []\n  for filename,duplicates,content in hasher.foreachcontent('.'):\n    if duplicates:\n      allduplicates.append(f)\n    else:\n      assert content!=[] #some .remdups_ must be with (c)ontent\n      nfilename = 'afilehere'\n      with open(nfilename,'wb') as nf:\n        for buf in content:\n          nf.write(buf)\n      shutil.copystat(filename, nfilename)\n\n``foreachcontent()`` uses ``scandir()``, but does not add duplicate files to the ``.remdup_`` files.\n\n.. code:: python\n\n   for f in hasher.scandir(otherdir,filter=['*.jpg'],exclude=['**/old/*']):\n      duplicates = hasher.duplicates(f)\n      yield (f,duplicates,kw['content'])\n      if duplicates:\n         hasher.clear(f)\n      else:\n         hasher.update_hashfiles()\n\nIf you don't want to keep the content, don't provide a ``[]`` for ``content`` in ``scandir``.\n``scandir()`` will hash all files not yet in the ``.remdup_`` files and will return the file name.\n\nThis code resorts a tree by hashing and creating a copy, if not duplicate.\n\n.. code:: python\n\n   import os\n   import remdups\n   os.chdir('dir/to/resort/to')\n   with open('.remdups_c.sha256','w'): pass\n   remdups.resort('../some/dir/here',\"%y%m/%d_%H%M%S\")\n\n\n.. _`github`: https://github.com/rpuntaie/remdups\n\n\n", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/rpuntaie/remdups", "keywords": "Duplicate, File", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "remdups", "package_url": "https://pypi.org/project/remdups/", "platform": "", "project_url": "https://pypi.org/project/remdups/", "project_urls": {"Homepage": "https://github.com/rpuntaie/remdups"}, "release_url": "https://pypi.org/project/remdups/1.3.1/", "requires_dist": ["pillow", "pillow; extra == 'develop'", "piexif; extra == 'develop'", "pytest-toolbox; extra == 'develop'", "pytest-coverage; extra == 'develop'"], "requires_python": "", "summary": "remdups - remove duplicate files", "version": "1.3.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <table>\n<col>\n<col>\n<tbody>\n<tr><th>Author:</th>\n<td>Roland Puntaier</td></tr>\n<tr><th>Homepage:</th><td><a href=\"https://github.com/rpuntaie/remdups\" rel=\"nofollow\">https://github.com/rpuntaie/remdups</a></td>\n</tr>\n<tr><th>License:</th><td>See LICENSE file</td>\n</tr>\n</tbody>\n</table>\n<div id=\"remdups\">\n<h2>remdups</h2>\n<p><tt>remdups</tt> generates a script to</p>\n<ul>\n<li>remove duplicate files</li>\n<li>copy files from another directory to this one, ignoring duplicates</li>\n<li>move files from another directory to this one, ignoring duplicates</li>\n</ul>\n<p>The resulting script should be further inspected before executing it in your shell.</p>\n</div>\n<div id=\"usage\">\n<h2>Usage</h2>\n<ol>\n<li><p>Optional. You can choose one or more source+hashing methods, via e.g.:</p>\n<pre>cat &gt; .remdups_c.sha512\ncat &gt; .remdups_e.md5\n</pre>\n<p>All of .remdups_{c,b,d,e,n}.{sha512, sha384, sha256, sha224, sha1, md5}\ncontribute to the final hash. If you don\u2019t make such a file, the default is:</p>\n<pre>.remdups_c.sha256\n</pre>\n<p>{\u2018c\u2019: \u2018content\u2019, \u2018b\u2019: \u2018block\u2019, \u2018d\u2019: \u2018date\u2019, \u2018e\u2019: \u2018exif\u2019, \u2018n\u2019: \u2018name\u2019}</p>\n</li>\n</ol>\n<ol>\n<li><p>Create the hash file by either of (can take a long time):</p>\n<pre>remdups\nremdups update\nremdups update &lt;fromdir&gt;\n</pre>\n<p>The hashes are added to all .remdups_x.y. To rehash all files:</p>\n<pre>rm .remdups_*\n</pre>\n</li>\n<li><p>Make a script with rm, mv, cp commands.\nIt can be repeated with different options until the script is good.</p>\n<p>$remdups rm -s script.sh\n$remdups cp -s script.bat #if you used &lt;fromdir&gt;\n$remdups mv -s script.py  #if you used &lt;fromdir&gt;</p>\n<p>If the file ends in .sh, cp is used and the file names are in linux format.\nThis is usable also on Windows with MSYS, MSYS2 and CYGWIN.</p>\n<p>If the file ends in .bat, Windows commands are used.</p>\n<p>If the file ends in .py, python functions are used.</p>\n</li>\n<li><p>Inspect the script and go back to 2., if necessary.\nChanges to the script can also be done with the editor.</p>\n</li>\n<li><p>execute script</p>\n<p>$./script.sh</p>\n</li>\n</ol>\n<p>Alternatively you can use remdups from your own python script, or interactively from a python prompt.</p>\n</div>\n<div id=\"install\">\n<h2>Install</h2>\n<ul>\n<li>Directly from PyPi:</li>\n</ul>\n<pre><span class=\"gp\">$</span> pip install remdups\n</pre>\n<ul>\n<li>From <a href=\"https://github.com/rpuntaie/remdups\" rel=\"nofollow\">github</a>: Clone, change to the directory and do</li>\n</ul>\n<pre><span class=\"gp\">$</span> python setup.py install\n</pre>\n<ul>\n<li><p>If you plan to extend this tool</p>\n<ul>\n<li>fork on <a href=\"https://github.com/rpuntaie/remdups\" rel=\"nofollow\">github</a></li>\n<li>clone from your fork to you PC</li>\n<li>do an editable install</li>\n</ul>\n<pre><span class=\"gp\">$</span> pip install -e .\n</pre>\n<ul>\n<li>test after change and bring coverage to 100%</li>\n</ul>\n<pre><span class=\"gp\">$</span> py.test --cov remdups.py --cov-report term-missing\n</pre>\n<ul>\n<li>consider sharing changes useful for others (<a href=\"https://github.com/rpuntaie/remdups\" rel=\"nofollow\">github</a> pull request).</li>\n</ul>\n</li>\n</ul>\n<div>\n<p>Hint</p>\n<p>For more advanced file selection <tt>find</tt> can be used.\nThe following example ignores directory <tt>old</tt> and produces a hash for all JPEG files:</p>\n<pre><span class=\"gp\">$</span> find . -path <span class=\"s2\">\"old\"</span> -prune -or -not -type d -and -iname <span class=\"s2\">\"\\*.jpg\"</span> -exec sha256sum <span class=\"o\">{}</span> <span class=\"se\">\\;</span> &gt; .remdups_c.sha256\n</pre>\n</div>\n</div>\n<div id=\"command-line\">\n<h2>Command Line</h2>\n<p>The following is in addition to the help given with:</p>\n<pre>remdups --help\n</pre>\n<p>The sources for the hashes can be:</p>\n<pre>{'c': 'content', 'b': 'block', 'd': 'date', 'e': 'exif', 'n': 'name'}\n</pre>\n<p>Don\u2019t include <tt>n</tt>, because same files with different names cannot be found. <tt>c</tt> is the best.</p>\n<p>Do e.g:</p>\n<pre>cat &gt; .remdups_b.sha512\ncat &gt; .remdups_c.sha256\n</pre>\n<p>Fill the hash files from the current directory:</p>\n<pre>remdups update\n</pre>\n<p>Or fill the hash files from another directory:</p>\n<pre>remdups update &lt;fromdir&gt;\n</pre>\n<p>In the latter case the paths in the hash files will have a <tt>//</tt> or <tt>\\\\</tt>\nto mark the start for the new relatives paths in a subsequent <tt>mv</tt> or <tt>cp</tt> command.</p>\n<p>Once the hash files are filled create the script. It depend on the extension used:</p>\n<pre>remdups &lt;command&gt; -s script.sh &lt;options&gt;\nremdups &lt;command&gt; -s script.bat &lt;options&gt;\nremdups &lt;command&gt; -s script.py &lt;options&gt;\n</pre>\n<p><tt>command</tt> can be <tt>rm</tt>, <tt>cp</tt>, <tt>mv</tt>.\nThere is also <tt>dupsof</tt> and <tt>dupsoftail</tt>, but they don\u2019t take a <tt><span class=\"pre\">--script</span></tt>, but print the output.</p>\n<p><tt><span class=\"pre\">--keep-in</span></tt>, <tt><span class=\"pre\">--keep-out</span></tt> and <tt><span class=\"pre\">--comment-out</span></tt> will remove different files of a duplicate group.\n<tt><span class=\"pre\">--safe</span></tt> will do a byte-wise comparison, before creating the script. That takes longer.</p>\n<p><tt>cp</tt> and <tt>mv</tt> also take <tt><span class=\"pre\">--sort</span></tt>: In this case the tree is not recreated, but the files are sorted\nto the provided tree structure using the file modification date. See <a href=\"https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior\" rel=\"nofollow\">https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior</a>.</p>\n</div>\n<div id=\"api\">\n<h2>API</h2>\n<p>With your own python script you can load the file for hashing and use the\nloaded content immediately to create the new file, if not duplicate.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">remdups</span> <span class=\"kn\">import</span> <span class=\"o\">*</span>\n<span class=\"n\">hasher</span> <span class=\"o\">=</span> <span class=\"n\">Hasher</span><span class=\"p\">()</span>\n<span class=\"n\">allduplicates</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n<span class=\"k\">for</span> <span class=\"n\">filename</span><span class=\"p\">,</span><span class=\"n\">duplicates</span><span class=\"p\">,</span><span class=\"n\">content</span> <span class=\"ow\">in</span> <span class=\"n\">hasher</span><span class=\"o\">.</span><span class=\"n\">foreachcontent</span><span class=\"p\">(</span><span class=\"s1\">'.'</span><span class=\"p\">):</span>\n  <span class=\"k\">if</span> <span class=\"n\">duplicates</span><span class=\"p\">:</span>\n    <span class=\"n\">allduplicates</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">f</span><span class=\"p\">)</span>\n  <span class=\"k\">else</span><span class=\"p\">:</span>\n    <span class=\"k\">assert</span> <span class=\"n\">content</span><span class=\"o\">!=</span><span class=\"p\">[]</span> <span class=\"c1\">#some .remdups_ must be with (c)ontent</span>\n    <span class=\"n\">nfilename</span> <span class=\"o\">=</span> <span class=\"s1\">'afilehere'</span>\n    <span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">nfilename</span><span class=\"p\">,</span><span class=\"s1\">'wb'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">nf</span><span class=\"p\">:</span>\n      <span class=\"k\">for</span> <span class=\"n\">buf</span> <span class=\"ow\">in</span> <span class=\"n\">content</span><span class=\"p\">:</span>\n        <span class=\"n\">nf</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"n\">buf</span><span class=\"p\">)</span>\n    <span class=\"n\">shutil</span><span class=\"o\">.</span><span class=\"n\">copystat</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">,</span> <span class=\"n\">nfilename</span><span class=\"p\">)</span>\n</pre>\n<p><tt>foreachcontent()</tt> uses <tt>scandir()</tt>, but does not add duplicate files to the <tt>.remdup_</tt> files.</p>\n<pre><span class=\"k\">for</span> <span class=\"n\">f</span> <span class=\"ow\">in</span> <span class=\"n\">hasher</span><span class=\"o\">.</span><span class=\"n\">scandir</span><span class=\"p\">(</span><span class=\"n\">otherdir</span><span class=\"p\">,</span><span class=\"nb\">filter</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'*.jpg'</span><span class=\"p\">],</span><span class=\"n\">exclude</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'**/old/*'</span><span class=\"p\">]):</span>\n   <span class=\"n\">duplicates</span> <span class=\"o\">=</span> <span class=\"n\">hasher</span><span class=\"o\">.</span><span class=\"n\">duplicates</span><span class=\"p\">(</span><span class=\"n\">f</span><span class=\"p\">)</span>\n   <span class=\"k\">yield</span> <span class=\"p\">(</span><span class=\"n\">f</span><span class=\"p\">,</span><span class=\"n\">duplicates</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"p\">[</span><span class=\"s1\">'content'</span><span class=\"p\">])</span>\n   <span class=\"k\">if</span> <span class=\"n\">duplicates</span><span class=\"p\">:</span>\n      <span class=\"n\">hasher</span><span class=\"o\">.</span><span class=\"n\">clear</span><span class=\"p\">(</span><span class=\"n\">f</span><span class=\"p\">)</span>\n   <span class=\"k\">else</span><span class=\"p\">:</span>\n      <span class=\"n\">hasher</span><span class=\"o\">.</span><span class=\"n\">update_hashfiles</span><span class=\"p\">()</span>\n</pre>\n<p>If you don\u2019t want to keep the content, don\u2019t provide a <tt>[]</tt> for <tt>content</tt> in <tt>scandir</tt>.\n<tt>scandir()</tt> will hash all files not yet in the <tt>.remdup_</tt> files and will return the file name.</p>\n<p>This code resorts a tree by hashing and creating a copy, if not duplicate.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">os</span>\n<span class=\"kn\">import</span> <span class=\"nn\">remdups</span>\n<span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">chdir</span><span class=\"p\">(</span><span class=\"s1\">'dir/to/resort/to'</span><span class=\"p\">)</span>\n<span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s1\">'.remdups_c.sha256'</span><span class=\"p\">,</span><span class=\"s1\">'w'</span><span class=\"p\">):</span> <span class=\"k\">pass</span>\n<span class=\"n\">remdups</span><span class=\"o\">.</span><span class=\"n\">resort</span><span class=\"p\">(</span><span class=\"s1\">'../some/dir/here'</span><span class=\"p\">,</span><span class=\"s2\">\"%y%m/</span><span class=\"si\">%d</span><span class=\"s2\">_%H%M%S\"</span><span class=\"p\">)</span>\n</pre>\n</div>\n\n          </div>"}, "last_serial": 3558588, "releases": {"1.0": [{"comment_text": "", "digests": {"md5": "8e02e5fd7a4d41c3130ec9ec5d340a18", "sha256": "acf2fd657b7fd4a254789e92d66783c029794262c238564e2c48821f447109f0"}, "downloads": -1, "filename": "remdups-1.0.tar.gz", "has_sig": false, "md5_digest": "8e02e5fd7a4d41c3130ec9ec5d340a18", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3895, "upload_time": "2013-10-08T10:24:20", "upload_time_iso_8601": "2013-10-08T10:24:20.433020Z", "url": "https://files.pythonhosted.org/packages/08/be/8912e897c99280538d1ed73510016525eedef326f5e11b2062278ed9306c/remdups-1.0.tar.gz", "yanked": false}], "1.1": [{"comment_text": "", "digests": {"md5": "31cf96c5c385e142c36c08ec0fae6797", "sha256": "29fcd20f2f903a734d51411fe1f775229eb4db62edc154dc336bc794c2dfa298"}, "downloads": -1, "filename": "remdups-1.1.tar.gz", "has_sig": false, "md5_digest": "31cf96c5c385e142c36c08ec0fae6797", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4070, "upload_time": "2013-10-31T21:53:51", "upload_time_iso_8601": "2013-10-31T21:53:51.394428Z", "url": "https://files.pythonhosted.org/packages/29/89/d2836b4264c37e4d73471fdcafdbda6a2f8363293c1452515d9f34b7b363/remdups-1.1.tar.gz", "yanked": false}], "1.2": [{"comment_text": "", "digests": {"md5": "9c53d5d3778e3c78a4ac40e25e3490d7", "sha256": "1952452038bdc3e1e6fd1febd0cf303809be609292636063e67a4fecea622169"}, "downloads": -1, "filename": "remdups-1.2.tar.gz", "has_sig": false, "md5_digest": "9c53d5d3778e3c78a4ac40e25e3490d7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8395, "upload_time": "2016-05-29T19:04:04", "upload_time_iso_8601": "2016-05-29T19:04:04.326004Z", "url": "https://files.pythonhosted.org/packages/d4/f1/deadc508057f6e9fe53a73a74bfdd7d7fc312e74f3d5073b7651c68d37ec/remdups-1.2.tar.gz", "yanked": false}], "1.3": [{"comment_text": "", "digests": {"md5": "e7eab5ece295ddd056ef6c283a46388f", "sha256": "9082be17fade2de3dab3d07e4eb9ab3f8c001d87891a8173598a9b404f5fe564"}, "downloads": -1, "filename": "remdups-1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "e7eab5ece295ddd056ef6c283a46388f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 16197, "upload_time": "2018-01-30T20:56:44", "upload_time_iso_8601": "2018-01-30T20:56:44.941018Z", "url": "https://files.pythonhosted.org/packages/62/9e/b469c50482abd8cbc035019f1230d366cd56f84e34093f615870aca22282/remdups-1.3-py3-none-any.whl", "yanked": false}], "1.3.1": [{"comment_text": "", "digests": {"md5": "3bcd90bdb68469874d900424efad24f2", "sha256": "26004255b0e51033f47e96bf79e600d73db32fed729ace970ebffa079f7f2c86"}, "downloads": -1, "filename": "remdups-1.3.1-py3-none-any.whl", "has_sig": false, "md5_digest": "3bcd90bdb68469874d900424efad24f2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 16613, "upload_time": "2018-02-06T22:10:49", "upload_time_iso_8601": "2018-02-06T22:10:49.953089Z", "url": "https://files.pythonhosted.org/packages/28/60/ffc7d1388800ae5f50ca18e7699a70dde40eb97545543988e1099355520e/remdups-1.3.1-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "3bcd90bdb68469874d900424efad24f2", "sha256": "26004255b0e51033f47e96bf79e600d73db32fed729ace970ebffa079f7f2c86"}, "downloads": -1, "filename": "remdups-1.3.1-py3-none-any.whl", "has_sig": false, "md5_digest": "3bcd90bdb68469874d900424efad24f2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 16613, "upload_time": "2018-02-06T22:10:49", "upload_time_iso_8601": "2018-02-06T22:10:49.953089Z", "url": "https://files.pythonhosted.org/packages/28/60/ffc7d1388800ae5f50ca18e7699a70dde40eb97545543988e1099355520e/remdups-1.3.1-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 03:04:55 2020"}