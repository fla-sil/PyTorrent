{"info": {"author": "", "author_email": "justheuristic@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Scientific/Engineering"], "description": "# as_a_service\n\nA simple package that transforms a batch function {inputs->results} into a service that\n- groups inputs into batches - you specify max batch size and time waiting\n- processes them - and returns results back to whoever was asking\n\n### Usage:\n__[notebook version](https://github.com/justheuristic/as_a_service/blob/master/example.ipynb)__\n\nHere's how it feels\n```python\n@as_batched_service(batch_size=3, max_delay=0.1)\ndef square(batch_xs):\n    print(\"processing...\", batch_xs)\n    return [x_i ** 2 for x_i in batch_xs]\n\n# submit many queries\nfutures = square.submit_many(range(10))\nprint([f.result() for f in futures])\n```\nThis will print\n```\nprocessing... [0, 1, 2]\nprocessing... [3, 4, 5]\nprocessing... [6, 7, 8]\nprocessing... [9]\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n```\n\nYou can also use it as a drop-in replacement for a function that processes one input at a time\n * `square(2.0)` will return 4.0 as if a normal function\n * Under the hood, it submits a request and waits for it to finish\n\nThis package contains three objects\n - BatchedService(batch_process_func, batch_size, max_delay) - main object\n - @as_batched_service(batch_size, max_delay) - same thing as a decorator\n - @as_service(max_delay) - decorator for a function without batches (single input/output)\n\nUse help(BatchedService) and \"Why should I care?\" for more details.\n\n### Install:\n *  ```pip install as_a_service```\n *  No dependencies apart from standard libraries\n *  Works with both python2 and python3 (pip3 install)\n\n\n### Why should I care?\n\nThis primitive is useful for a number of scenarios like:\n1) You are building a web-based demo around your neural network. You want your network to process\n    a stream of user queries, but doing so one query at a time is slow. Batch-parallel processing is way better.\n\n```python\n@as_batched_service(batch_size=32, max_delay=1.0)\ndef service_predict(input_images_list):\n    predictions_list = my_network_predict_batch(input_images_list)\n    return predictions_list\n\n@my_web_framework.run_as_a_thread_for_every_query\ndef handle_user_query(query):\n    input_image = get_image(query)\n    return service_predict(input_image)\n```\n\n2) You are experimenting with a reinforcement learning agent. The agent itself is a neural network\n    that predicts actions. You want to play 100 parallel game sessions to train on.\n    Playing one session at a time is slow. If only we could run multiple sessions on one GPU\n\n```python\nmy_network = make_keras_network_on_gpu()\nservice = BatchedService(my_network.predict, batch_size=32, max_delay=1.0)\nthreads = [\n    GamePlayingThread(predict_action=lambda x: service(x)) for i in range(100)\n]\nfor thread in threads:\n    thread.start()\nfor thread in threads:\n    thread.join()\nservice.stop()\n```\n\nAnd many other scenarios where you want to use a single resource\n(GPU / device /DB) concurrently and utilize batch-parallelism", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/justheuristic/as_a_service", "keywords": "service,background service,batched executor,parallel executor,background executor,background,deep learning,reinforcement learning", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "as-a-service", "package_url": "https://pypi.org/project/as-a-service/", "platform": "", "project_url": "https://pypi.org/project/as-a-service/", "project_urls": {"Homepage": "https://github.com/justheuristic/as_a_service"}, "release_url": "https://pypi.org/project/as-a-service/1.0.3/", "requires_dist": null, "requires_python": "", "summary": "a simple tool to turn your function into a background service", "version": "1.0.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            # as_a_service<br><br>A simple package that transforms a batch function {inputs-&gt;results} into a service that<br>- groups inputs into batches - you specify max batch size and time waiting<br>- processes them - and returns results back to whoever was asking<br><br>### Usage:<br>__[notebook version](https://github.com/justheuristic/as_a_service/blob/master/example.ipynb)__<br><br>Here's how it feels<br>```python<br>@as_batched_service(batch_size=3, max_delay=0.1)<br>def square(batch_xs):<br>    print(\"processing...\", batch_xs)<br>    return [x_i ** 2 for x_i in batch_xs]<br><br># submit many queries<br>futures = square.submit_many(range(10))<br>print([f.result() for f in futures])<br>```<br>This will print<br>```<br>processing... [0, 1, 2]<br>processing... [3, 4, 5]<br>processing... [6, 7, 8]<br>processing... [9]<br>[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]<br>```<br><br>You can also use it as a drop-in replacement for a function that processes one input at a time<br> * `square(2.0)` will return 4.0 as if a normal function<br> * Under the hood, it submits a request and waits for it to finish<br><br>This package contains three objects<br> - BatchedService(batch_process_func, batch_size, max_delay) - main object<br> - @as_batched_service(batch_size, max_delay) - same thing as a decorator<br> - @as_service(max_delay) - decorator for a function without batches (single input/output)<br><br>Use help(BatchedService) and \"Why should I care?\" for more details.<br><br>### Install:<br> *  ```pip install as_a_service```<br> *  No dependencies apart from standard libraries<br> *  Works with both python2 and python3 (pip3 install)<br><br><br>### Why should I care?<br><br>This primitive is useful for a number of scenarios like:<br>1) You are building a web-based demo around your neural network. You want your network to process<br>    a stream of user queries, but doing so one query at a time is slow. Batch-parallel processing is way better.<br><br>```python<br>@as_batched_service(batch_size=32, max_delay=1.0)<br>def service_predict(input_images_list):<br>    predictions_list = my_network_predict_batch(input_images_list)<br>    return predictions_list<br><br>@my_web_framework.run_as_a_thread_for_every_query<br>def handle_user_query(query):<br>    input_image = get_image(query)<br>    return service_predict(input_image)<br>```<br><br>2) You are experimenting with a reinforcement learning agent. The agent itself is a neural network<br>    that predicts actions. You want to play 100 parallel game sessions to train on.<br>    Playing one session at a time is slow. If only we could run multiple sessions on one GPU<br><br>```python<br>my_network = make_keras_network_on_gpu()<br>service = BatchedService(my_network.predict, batch_size=32, max_delay=1.0)<br>threads = [<br>    GamePlayingThread(predict_action=lambda x: service(x)) for i in range(100)<br>]<br>for thread in threads:<br>    thread.start()<br>for thread in threads:<br>    thread.join()<br>service.stop()<br>```<br><br>And many other scenarios where you want to use a single resource<br>(GPU / device /DB) concurrently and utilize batch-parallelism\n          </div>"}, "last_serial": 4522138, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "bc8ed0b45bb70786a5643a887c2f96f7", "sha256": "062102451d43a6b253e24ae9df0f55ca3bb03bb209a8c6f828416072652aad88"}, "downloads": -1, "filename": "as_a_service-1.0.0.tar.gz", "has_sig": false, "md5_digest": "bc8ed0b45bb70786a5643a887c2f96f7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5136, "upload_time": "2018-11-24T00:09:48", "upload_time_iso_8601": "2018-11-24T00:09:48.219528Z", "url": "https://files.pythonhosted.org/packages/8a/b0/5799ba57276f69cb9a35b27fc97dba6be9638a325e38071574318610e1e7/as_a_service-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "4b731707442d603bb245609742ea9244", "sha256": "6c7d9d6e6dfde2361aa6ec40ca169e22c3503a1bf0129a7a82ff3c7223ec1123"}, "downloads": -1, "filename": "as_a_service-1.0.1.tar.gz", "has_sig": false, "md5_digest": "4b731707442d603bb245609742ea9244", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5127, "upload_time": "2018-11-24T00:36:24", "upload_time_iso_8601": "2018-11-24T00:36:24.694138Z", "url": "https://files.pythonhosted.org/packages/35/9e/ec161e2ba0b2bd1d7682238d935110e1f9f77eb23e20799f4b04a4c013ce/as_a_service-1.0.1.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "e50a4162bf264ad0a46e3ffa5771f2ab", "sha256": "c2a50cbfebb12ff825b3f30bf1ba34ce059c456d2a2def451d0db3f345535060"}, "downloads": -1, "filename": "as_a_service-1.0.2.tar.gz", "has_sig": false, "md5_digest": "e50a4162bf264ad0a46e3ffa5771f2ab", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5131, "upload_time": "2018-11-24T00:39:03", "upload_time_iso_8601": "2018-11-24T00:39:03.734347Z", "url": "https://files.pythonhosted.org/packages/52/7b/f78b194e198e44fd84a29bb6e003ff3b302708b2a3694d4ca40f43972bcf/as_a_service-1.0.2.tar.gz", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "eabc67ef195a45cb60cc8d20f7c205b3", "sha256": "7dda2cd6ca6079499511f2700d1dc7c6ec87eed83ed3f64cf0a81689b0905cbd"}, "downloads": -1, "filename": "as_a_service-1.0.3.tar.gz", "has_sig": false, "md5_digest": "eabc67ef195a45cb60cc8d20f7c205b3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5183, "upload_time": "2018-11-24T01:10:32", "upload_time_iso_8601": "2018-11-24T01:10:32.028992Z", "url": "https://files.pythonhosted.org/packages/cd/b4/c9572669b430d9db0bbdb4be7ea8684bc234084eb59d0dcb9a1a15a7dc49/as_a_service-1.0.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "eabc67ef195a45cb60cc8d20f7c205b3", "sha256": "7dda2cd6ca6079499511f2700d1dc7c6ec87eed83ed3f64cf0a81689b0905cbd"}, "downloads": -1, "filename": "as_a_service-1.0.3.tar.gz", "has_sig": false, "md5_digest": "eabc67ef195a45cb60cc8d20f7c205b3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5183, "upload_time": "2018-11-24T01:10:32", "upload_time_iso_8601": "2018-11-24T01:10:32.028992Z", "url": "https://files.pythonhosted.org/packages/cd/b4/c9572669b430d9db0bbdb4be7ea8684bc234084eb59d0dcb9a1a15a7dc49/as_a_service-1.0.3.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:17:03 2020"}