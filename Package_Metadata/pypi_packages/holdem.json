{"info": {"author": "Sam Wenke", "author_email": "samwenke@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "# holdem\n\n:warning: **This is an experimental API, it will most definitely contain bugs, but that's why you are here!**\n\n```sh\npip install holdem\n```\n\nAfaik, this is the first [OpenAI Gym](https://github.com/openai/gym) _No-Limit Texas Hold'em_* (NLTH)\nenvironment written in Python. It's an experiment to build a Gym environment that is synchronous and\ncan support any number of players but also appeal to the general public that wants to learn how to\n\"solve\" NLTH.\n\n*Python 3 supports arbitrary length integers :money_with_wings:\n\nRight now, this is a work in progress, but I believe the API is mature enough for some preliminary\nexperiments. Join me in making some interesting progress on multi-agent Gym environments.\n\n# Usage\n\nThere is limited documentation at the moment. I'll try to make this less painful to understand.\n\n## `env = holdem.TexasHoldemEnv(n_seats, max_limit=1e9, debug=False)`\n\nCreates a gym environment representation a NLTH Table from the parameters:\n\n+ `n_seats` - number of available players for the current table. No players are initially allocated\n  to the table. You must call `env.add_player(seat_id, ...)` to populate the table.\n+ `max_limit` - max_limit is used to define the `gym.spaces` API for the class. It does not actually\n  determine any NLTH limits; in support of `gym.spaces.Discrete`.\n+ `debug` - add debug statements to play, will probably be removed in the future.\n\n### `env.add_player(seat_id, stack=2000)`\n\nAdds a player to the table according to the specified seat (`seat_id`) and the initial amount of\nchips allocated to the player's `stack`. If the table does not have enough seats according to the\n`n_seats` used by the constructor, a `gym.error.Error` will be raised.\n\n### `(player_states, community_states) = env.reset()`\n\nCalling `env.reset` resets the NLTH table to a new hand state. It does not reset any of the players\nstacks, or, reset any of the blinds. New behavior is reserved for a special, future portion of the\nAPI that is yet another feature that is not standard in Gym environments and is a work in progress.\n\nThe observation returned is a `tuple` of the following by index:\n\n0. `player_states` - a `tuple` where each entry is `tuple(player_info, player_hand)`, this feature\n   can be used to gather all states and hands by `(player_infos, player_hands) = zip(*player_states)`.\n   + `player_infos` - is a `list` of `int` features describing the individual player. It contains\n     the following by index:\n     0. `[0, 1]` - `0` - seat is empty, `1` - seat is not empty.\n     1. `[0, n_seats - 1]` - player's id, where they are sitting.\n     2. `[0, inf]` - player's current stack.\n     3. `[0, 1]` - player is playing the current hand.\n     4. `[0, inf]` the player's current handrank according to `treys.Evaluator.evaluate(hand, community)`.\n     5. `[0, 1]` - `0` - player has not played this round, `1` - player has played this round.\n     6. `[0, 1]` - `0` - player is currently not betting, `1` - player is betting.\n     7. `[0, 1]` - `0` - player is currently not all-in, `1` - player is all-in.\n     8. `[0, inf]` - player's last sidepot.\n   + `player_hands` - is a `list` of `int` features describing the cards in the player's pocket.\n     The values are encoded based on the `treys.Card` integer representation.\n1. `community_states` - a `tuple(community_infos, community_cards)` where:\n   + `community_infos` - a `list` by index:\n     0. `[0, n_seats - 1]` - location of the dealer button, where big blind is posted.\n     1. `[0, inf]` - the current small blind amount.\n     2. `[0, inf]` - the current big blind amount.\n     3. `[0, inf]` - the current total amount in the community pot.\n     4. `[0, inf]` - the last posted raise amount.\n     5. `[0, inf]` - minimum required raise amount, if above 0.\n     6. `[0, inf]` - the amount required to call.\n     7. `[0, n_seats - 1]` - the current player required to take an action.\n   + `community_cards` - is a `list` of `int` features describing the cards in the community.\n     The values are encoded based on the `treys.Card` integer representation. There are 5 `int` in\n     the list, where `-1` represents that there is no card present.\n\n# Example\n\n```python\nimport gym\nimport holdem\n\ndef play_out_hand(env, n_seats):\n  # reset environment, gather relevant observations\n  (player_states, (community_infos, community_cards)) = env.reset()\n  (player_infos, player_hands) = zip(*player_states)\n\n  # display the table, cards and all\n  env.render(mode='human')\n\n  terminal = False\n  while not terminal:\n    # play safe actions, check when noone else has raised, call when raised.\n    actions = holdem.safe_actions(community_infos, n_seats=n_seats)\n    (player_states, (community_infos, community_cards)), rews, terminal, info = env.step(actions)\n    env.render(mode='human')\n\nenv = gym.make('TexasHoldem-v1') # holdem.TexasHoldemEnv(2)\n\n# start with 2 players\nenv.add_player(0, stack=2000) # add a player to seat 0 with 2000 \"chips\"\nenv.add_player(1, stack=2000) # add another player to seat 1 with 2000 \"chips\"\n# play out a hand\nplay_out_hand(env, env.n_seats)\n\n# add one more player\nenv.add_player(2, stack=2000) # add another player to seat 1 with 2000 \"chips\"\n# play out another hand\nplay_out_hand(env, env.n_seats)\n```", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/wenkesj/holdem", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "holdem", "package_url": "https://pypi.org/project/holdem/", "platform": "any", "project_url": "https://pypi.org/project/holdem/", "project_urls": {"Homepage": "https://github.com/wenkesj/holdem"}, "release_url": "https://pypi.org/project/holdem/1.0.0/", "requires_dist": null, "requires_python": "", "summary": "OpenAI Gym No-Limit Texas Holdem Environment.", "version": "1.0.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            # holdem<br><br>:warning: **This is an experimental API, it will most definitely contain bugs, but that's why you are here!**<br><br>```sh<br>pip install holdem<br>```<br><br>Afaik, this is the first [OpenAI Gym](https://github.com/openai/gym) _No-Limit Texas Hold'em_* (NLTH)<br>environment written in Python. It's an experiment to build a Gym environment that is synchronous and<br>can support any number of players but also appeal to the general public that wants to learn how to<br>\"solve\" NLTH.<br><br>*Python 3 supports arbitrary length integers :money_with_wings:<br><br>Right now, this is a work in progress, but I believe the API is mature enough for some preliminary<br>experiments. Join me in making some interesting progress on multi-agent Gym environments.<br><br># Usage<br><br>There is limited documentation at the moment. I'll try to make this less painful to understand.<br><br>## `env = holdem.TexasHoldemEnv(n_seats, max_limit=1e9, debug=False)`<br><br>Creates a gym environment representation a NLTH Table from the parameters:<br><br>+ `n_seats` - number of available players for the current table. No players are initially allocated<br>  to the table. You must call `env.add_player(seat_id, ...)` to populate the table.<br>+ `max_limit` - max_limit is used to define the `gym.spaces` API for the class. It does not actually<br>  determine any NLTH limits; in support of `gym.spaces.Discrete`.<br>+ `debug` - add debug statements to play, will probably be removed in the future.<br><br>### `env.add_player(seat_id, stack=2000)`<br><br>Adds a player to the table according to the specified seat (`seat_id`) and the initial amount of<br>chips allocated to the player's `stack`. If the table does not have enough seats according to the<br>`n_seats` used by the constructor, a `gym.error.Error` will be raised.<br><br>### `(player_states, community_states) = env.reset()`<br><br>Calling `env.reset` resets the NLTH table to a new hand state. It does not reset any of the players<br>stacks, or, reset any of the blinds. New behavior is reserved for a special, future portion of the<br>API that is yet another feature that is not standard in Gym environments and is a work in progress.<br><br>The observation returned is a `tuple` of the following by index:<br><br>0. `player_states` - a `tuple` where each entry is `tuple(player_info, player_hand)`, this feature<br>   can be used to gather all states and hands by `(player_infos, player_hands) = zip(*player_states)`.<br>   + `player_infos` - is a `list` of `int` features describing the individual player. It contains<br>     the following by index:<br>     0. `[0, 1]` - `0` - seat is empty, `1` - seat is not empty.<br>     1. `[0, n_seats - 1]` - player's id, where they are sitting.<br>     2. `[0, inf]` - player's current stack.<br>     3. `[0, 1]` - player is playing the current hand.<br>     4. `[0, inf]` the player's current handrank according to `treys.Evaluator.evaluate(hand, community)`.<br>     5. `[0, 1]` - `0` - player has not played this round, `1` - player has played this round.<br>     6. `[0, 1]` - `0` - player is currently not betting, `1` - player is betting.<br>     7. `[0, 1]` - `0` - player is currently not all-in, `1` - player is all-in.<br>     8. `[0, inf]` - player's last sidepot.<br>   + `player_hands` - is a `list` of `int` features describing the cards in the player's pocket.<br>     The values are encoded based on the `treys.Card` integer representation.<br>1. `community_states` - a `tuple(community_infos, community_cards)` where:<br>   + `community_infos` - a `list` by index:<br>     0. `[0, n_seats - 1]` - location of the dealer button, where big blind is posted.<br>     1. `[0, inf]` - the current small blind amount.<br>     2. `[0, inf]` - the current big blind amount.<br>     3. `[0, inf]` - the current total amount in the community pot.<br>     4. `[0, inf]` - the last posted raise amount.<br>     5. `[0, inf]` - minimum required raise amount, if above 0.<br>     6. `[0, inf]` - the amount required to call.<br>     7. `[0, n_seats - 1]` - the current player required to take an action.<br>   + `community_cards` - is a `list` of `int` features describing the cards in the community.<br>     The values are encoded based on the `treys.Card` integer representation. There are 5 `int` in<br>     the list, where `-1` represents that there is no card present.<br><br># Example<br><br>```python<br>import gym<br>import holdem<br><br>def play_out_hand(env, n_seats):<br>  # reset environment, gather relevant observations<br>  (player_states, (community_infos, community_cards)) = env.reset()<br>  (player_infos, player_hands) = zip(*player_states)<br><br>  # display the table, cards and all<br>  env.render(mode='human')<br><br>  terminal = False<br>  while not terminal:<br>    # play safe actions, check when noone else has raised, call when raised.<br>    actions = holdem.safe_actions(community_infos, n_seats=n_seats)<br>    (player_states, (community_infos, community_cards)), rews, terminal, info = env.step(actions)<br>    env.render(mode='human')<br><br>env = gym.make('TexasHoldem-v1') # holdem.TexasHoldemEnv(2)<br><br># start with 2 players<br>env.add_player(0, stack=2000) # add a player to seat 0 with 2000 \"chips\"<br>env.add_player(1, stack=2000) # add another player to seat 1 with 2000 \"chips\"<br># play out a hand<br>play_out_hand(env, env.n_seats)<br><br># add one more player<br>env.add_player(2, stack=2000) # add another player to seat 1 with 2000 \"chips\"<br># play out another hand<br>play_out_hand(env, env.n_seats)<br>```\n          </div>"}, "last_serial": 3469395, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "b191798bee5d06ec8ea66a14d0473de7", "sha256": "f01ff881aa2aae83f3ae55db93aaf77662d3ce278c8299806a6bf8fd8ea0df09"}, "downloads": -1, "filename": "holdem-1.0.0-py3.6.egg", "has_sig": false, "md5_digest": "b191798bee5d06ec8ea66a14d0473de7", "packagetype": "bdist_egg", "python_version": "3.6", "requires_python": null, "size": 32268, "upload_time": "2018-01-07T19:53:03", "upload_time_iso_8601": "2018-01-07T19:53:03.980291Z", "url": "https://files.pythonhosted.org/packages/00/83/07fc57676e1e398cf436b3bb0da70509515cde9b334ff5f3868df8844a10/holdem-1.0.0-py3.6.egg", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "b191798bee5d06ec8ea66a14d0473de7", "sha256": "f01ff881aa2aae83f3ae55db93aaf77662d3ce278c8299806a6bf8fd8ea0df09"}, "downloads": -1, "filename": "holdem-1.0.0-py3.6.egg", "has_sig": false, "md5_digest": "b191798bee5d06ec8ea66a14d0473de7", "packagetype": "bdist_egg", "python_version": "3.6", "requires_python": null, "size": 32268, "upload_time": "2018-01-07T19:53:03", "upload_time_iso_8601": "2018-01-07T19:53:03.980291Z", "url": "https://files.pythonhosted.org/packages/00/83/07fc57676e1e398cf436b3bb0da70509515cde9b334ff5f3868df8844a10/holdem-1.0.0-py3.6.egg", "yanked": false}], "timestamp": "Fri May  8 00:50:50 2020"}