{"info": {"author": "Christopher Baker", "author_email": "chriscrewbaker@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "# validclust\n\n> Validate clustering results\n\n[![Linux Build Status](https://travis-ci.org/crew102/validclust.svg?branch=master)](https://travis-ci.org/crew102/validclust) \n[![PyPI version](https://img.shields.io/pypi/v/validclust.svg)](https://pypi.org/project/validclust/)\n\n## Motivation\n\nClustering algorithms often require that the analyst specify the number of clusters that exist in the data, a parameter commonly known as `k`. One approach to determining an appropriate value for `k` is to cluster the data using a range of values for `k`, then evaluate the quality of the resulting clusterings using a cluster validity index (CVI). The value of `k` that results in the best partitioning of the data according to the CVI is then chosen. `validclust` handles this process for the analyst, making it very easy to quickly determine an optimal value for `k`.  \n\n## Installation\n\nYou can get the stable version from PyPI:\n\n```\npip install validclust\n```\n\nOr the development version from GitHub:\n\n```\npip install git+https://github.com/crew102/validclust.git\n```\n\n## Basic usage\n\n<span>1.</span> Load libraries.\n\n```python\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets.samples_generator import make_blobs\nfrom validclust.validclust import ValidClust\n```\n\n<span>2.</span> Create some synthetic data. The data will be clustered around 4 centers.\n\n```python\ndata, _ = make_blobs(n_samples=500, centers=4, n_features=5, random_state=0)\n```\n\n<span>3.</span> Use `ValidClust` to determine the optimal number of clusters. The code below will partition the data into 2-7 clusters using two different clustering algorithms, then calculate various CVIs across the results.\n\n```python\nvclust = ValidClust(\n    k=list(range(2, 8)), \n    methods=['hierarchical', 'kmeans']\n)\ncvi_vals = vclust.fit_predict(data)\nprint(cvi_vals)\n#>                                    2            3            4            5  \\\n#> method       index                                                            \n#> hierarchical silhouette     0.645563     0.633970     0.747064     0.583724   \n#>              calinski    1007.397799  1399.552836  3611.526187  2832.925655   \n#>              davies         0.446861     0.567859     0.361996     1.025296   \n#>              dunn           0.727255     0.475745     0.711415     0.109312   \n#> kmeans       silhouette     0.645563     0.633970     0.747064     0.602562   \n#>              calinski    1007.397799  1399.552836  3611.526187  2845.143428   \n#>              davies         0.446861     0.567859     0.361996     0.988223   \n#>              dunn           0.727255     0.475745     0.711415     0.115113   \n#> \n#>                                    6            7  \n#> method       index                                 \n#> hierarchical silhouette     0.435456     0.289567  \n#>              calinski    2371.222506  2055.323553  \n#>              davies         1.509404     1.902413  \n#>              dunn           0.109312     0.116557  \n#> kmeans       silhouette     0.468945     0.334379  \n#>              calinski    2389.531071  2096.945591  \n#>              davies         1.431102     1.722117  \n#>              dunn           0.098636     0.072423  \n```\n\nIt's hard to see what the optimal value of `k` is from the raw CVI values shown above. Not all of the CVIs are on a 0-1 scale, and lower scores are actually associated with better clusterings for some of the indices. `ValidClust`'s `plot()` method solves this problem by first normalizing the CVIs and then displaying the results in a heatmap.\n\n```python\nvclust.plot()\n```\n\n![](https://i.imgur.com/lh4lROu.png)\n\nFor each row in the above grid (i.e., for each clustering method/CVI pair), darker cells are associated with higher-quality clusterings. From this plot we can see that each method/index pair seems to be pointing to 4 as being an optimal value for `k`.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://validclust.readthedocs.io", "keywords": "", "license": "LICENSE.txt", "maintainer": "", "maintainer_email": "", "name": "validclust", "package_url": "https://pypi.org/project/validclust/", "platform": "", "project_url": "https://pypi.org/project/validclust/", "project_urls": {"Homepage": "https://validclust.readthedocs.io"}, "release_url": "https://pypi.org/project/validclust/0.1.0/", "requires_dist": ["scikit-learn", "pandas", "numpy", "seaborn", "matplotlib"], "requires_python": "", "summary": "Validate clustering results", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>validclust</h1>\n<blockquote>\n<p>Validate clustering results</p>\n</blockquote>\n<p><a href=\"https://travis-ci.org/crew102/validclust\" rel=\"nofollow\"><img alt=\"Linux Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5dacb795a4c9ebb64992bfdabef045ef4b2541d2/68747470733a2f2f7472617669732d63692e6f72672f637265773130322f76616c6964636c7573742e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://pypi.org/project/validclust/\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8bc66fadede32fa5297f6bab950f9c8c1f1e8da5/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f76616c6964636c7573742e737667\"></a></p>\n<h2>Motivation</h2>\n<p>Clustering algorithms often require that the analyst specify the number of clusters that exist in the data, a parameter commonly known as <code>k</code>. One approach to determining an appropriate value for <code>k</code> is to cluster the data using a range of values for <code>k</code>, then evaluate the quality of the resulting clusterings using a cluster validity index (CVI). The value of <code>k</code> that results in the best partitioning of the data according to the CVI is then chosen. <code>validclust</code> handles this process for the analyst, making it very easy to quickly determine an optimal value for <code>k</code>.</p>\n<h2>Installation</h2>\n<p>You can get the stable version from PyPI:</p>\n<pre><code>pip install validclust\n</code></pre>\n<p>Or the development version from GitHub:</p>\n<pre><code>pip install git+https://github.com/crew102/validclust.git\n</code></pre>\n<h2>Basic usage</h2>\n<p><span>1.</span> Load libraries.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"k\">as</span> <span class=\"nn\">plt</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.datasets.samples_generator</span> <span class=\"kn\">import</span> <span class=\"n\">make_blobs</span>\n<span class=\"kn\">from</span> <span class=\"nn\">validclust.validclust</span> <span class=\"kn\">import</span> <span class=\"n\">ValidClust</span>\n</pre>\n<p><span>2.</span> Create some synthetic data. The data will be clustered around 4 centers.</p>\n<pre><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">=</span> <span class=\"n\">make_blobs</span><span class=\"p\">(</span><span class=\"n\">n_samples</span><span class=\"o\">=</span><span class=\"mi\">500</span><span class=\"p\">,</span> <span class=\"n\">centers</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">n_features</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n</pre>\n<p><span>3.</span> Use <code>ValidClust</code> to determine the optimal number of clusters. The code below will partition the data into 2-7 clusters using two different clustering algorithms, then calculate various CVIs across the results.</p>\n<pre><span class=\"n\">vclust</span> <span class=\"o\">=</span> <span class=\"n\">ValidClust</span><span class=\"p\">(</span>\n    <span class=\"n\">k</span><span class=\"o\">=</span><span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">)),</span> \n    <span class=\"n\">methods</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'hierarchical'</span><span class=\"p\">,</span> <span class=\"s1\">'kmeans'</span><span class=\"p\">]</span>\n<span class=\"p\">)</span>\n<span class=\"n\">cvi_vals</span> <span class=\"o\">=</span> <span class=\"n\">vclust</span><span class=\"o\">.</span><span class=\"n\">fit_predict</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">cvi_vals</span><span class=\"p\">)</span>\n<span class=\"c1\">#&gt;                                    2            3            4            5  \\</span>\n<span class=\"c1\">#&gt; method       index                                                            </span>\n<span class=\"c1\">#&gt; hierarchical silhouette     0.645563     0.633970     0.747064     0.583724   </span>\n<span class=\"c1\">#&gt;              calinski    1007.397799  1399.552836  3611.526187  2832.925655   </span>\n<span class=\"c1\">#&gt;              davies         0.446861     0.567859     0.361996     1.025296   </span>\n<span class=\"c1\">#&gt;              dunn           0.727255     0.475745     0.711415     0.109312   </span>\n<span class=\"c1\">#&gt; kmeans       silhouette     0.645563     0.633970     0.747064     0.602562   </span>\n<span class=\"c1\">#&gt;              calinski    1007.397799  1399.552836  3611.526187  2845.143428   </span>\n<span class=\"c1\">#&gt;              davies         0.446861     0.567859     0.361996     0.988223   </span>\n<span class=\"c1\">#&gt;              dunn           0.727255     0.475745     0.711415     0.115113   </span>\n<span class=\"c1\">#&gt; </span>\n<span class=\"c1\">#&gt;                                    6            7  </span>\n<span class=\"c1\">#&gt; method       index                                 </span>\n<span class=\"c1\">#&gt; hierarchical silhouette     0.435456     0.289567  </span>\n<span class=\"c1\">#&gt;              calinski    2371.222506  2055.323553  </span>\n<span class=\"c1\">#&gt;              davies         1.509404     1.902413  </span>\n<span class=\"c1\">#&gt;              dunn           0.109312     0.116557  </span>\n<span class=\"c1\">#&gt; kmeans       silhouette     0.468945     0.334379  </span>\n<span class=\"c1\">#&gt;              calinski    2389.531071  2096.945591  </span>\n<span class=\"c1\">#&gt;              davies         1.431102     1.722117  </span>\n<span class=\"c1\">#&gt;              dunn           0.098636     0.072423  </span>\n</pre>\n<p>It's hard to see what the optimal value of <code>k</code> is from the raw CVI values shown above. Not all of the CVIs are on a 0-1 scale, and lower scores are actually associated with better clusterings for some of the indices. <code>ValidClust</code>'s <code>plot()</code> method solves this problem by first normalizing the CVIs and then displaying the results in a heatmap.</p>\n<pre><span class=\"n\">vclust</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">()</span>\n</pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ab4afe08c2ed8ee99b3c6958b61d99066d6f1829/68747470733a2f2f692e696d6775722e636f6d2f6c68346c524f752e706e67\"></p>\n<p>For each row in the above grid (i.e., for each clustering method/CVI pair), darker cells are associated with higher-quality clusterings. From this plot we can see that each method/index pair seems to be pointing to 4 as being an optimal value for <code>k</code>.</p>\n\n          </div>"}, "last_serial": 4769358, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "4c1f954ae308be5db6c438461a11c4b0", "sha256": "1ed4efd7662d8e57cfc20c4d3606e2250d7020cadd6b12b4269deacd9d7637a9"}, "downloads": -1, "filename": "validclust-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "4c1f954ae308be5db6c438461a11c4b0", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 7009, "upload_time": "2019-02-01T18:03:09", "upload_time_iso_8601": "2019-02-01T18:03:09.308356Z", "url": "https://files.pythonhosted.org/packages/89/01/e4e148d4631bfffba1b20c00130fa959376709e378834c29f50f6ae2a62a/validclust-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "eb5dd95564ca60853095c2daa5295566", "sha256": "2d01d75076ba6cfeb5cec42fd1b3a41af262f4fc21c7df887fcd3f0c6e6dd46f"}, "downloads": -1, "filename": "validclust-0.1.0.tar.gz", "has_sig": false, "md5_digest": "eb5dd95564ca60853095c2daa5295566", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7455, "upload_time": "2019-02-01T18:03:11", "upload_time_iso_8601": "2019-02-01T18:03:11.148537Z", "url": "https://files.pythonhosted.org/packages/ff/34/c91d6351d7cd43a39a75ee086e0c79f15a6693d1b685d52a612d86d2f9eb/validclust-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "4c1f954ae308be5db6c438461a11c4b0", "sha256": "1ed4efd7662d8e57cfc20c4d3606e2250d7020cadd6b12b4269deacd9d7637a9"}, "downloads": -1, "filename": "validclust-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "4c1f954ae308be5db6c438461a11c4b0", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 7009, "upload_time": "2019-02-01T18:03:09", "upload_time_iso_8601": "2019-02-01T18:03:09.308356Z", "url": "https://files.pythonhosted.org/packages/89/01/e4e148d4631bfffba1b20c00130fa959376709e378834c29f50f6ae2a62a/validclust-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "eb5dd95564ca60853095c2daa5295566", "sha256": "2d01d75076ba6cfeb5cec42fd1b3a41af262f4fc21c7df887fcd3f0c6e6dd46f"}, "downloads": -1, "filename": "validclust-0.1.0.tar.gz", "has_sig": false, "md5_digest": "eb5dd95564ca60853095c2daa5295566", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7455, "upload_time": "2019-02-01T18:03:11", "upload_time_iso_8601": "2019-02-01T18:03:11.148537Z", "url": "https://files.pythonhosted.org/packages/ff/34/c91d6351d7cd43a39a75ee086e0c79f15a6693d1b685d52a612d86d2f9eb/validclust-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:38:06 2020"}