{"info": {"author": "Uber AI Labs", "author_email": "npradhan@uber.com", "bugtrack_url": null, "classifiers": ["Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: Science/Research", "License :: OSI Approved :: Apache Software License", "Operating System :: MacOS :: MacOS X", "Operating System :: POSIX :: Linux", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "[![Build Status](https://travis-ci.com/pyro-ppl/numpyro.svg?branch=master)](https://travis-ci.com/pyro-ppl/numpyro)\n[![Documentation Status](https://readthedocs.org/projects/numpyro/badge/?version=latest)](https://numpyro.readthedocs.io/en/latest/?badge=latest)\n[![Latest Version](https://badge.fury.io/py/numpyro.svg)](https://pypi.python.org/pypi/numpyro)\n# NumPyro\n\nProbabilistic programming with NumPy powered by [JAX](https://github.com/google/jax) for autograd and JIT compilation to GPU/TPU/CPU.\n\n[Docs](https://num.pyro.ai) | [Examples](https://pyro.ai/numpyro/) | [Forum](https://forum.pyro.ai/)\n\n----------------------------------------------------------------------------------------------------\n\n## What is NumPyro?\n\nNumPyro is a small probabilistic programming library that provides a NumPy backend for [Pyro](https://github.com/pyro-ppl/pyro). We rely on [JAX](https://github.com/google/jax) for automatic differentiation and JIT compilation to GPU / CPU. This is an alpha release under active development, so beware of brittleness, bugs, and changes to the API as the design evolves.\n\nNumPyro is designed to be *lightweight* and focuses on providing a flexible substrate that users can build on:\n\n - **Pyro Primitives:** NumPyro programs can contain regular Python and NumPy code, in addition to [Pyro primitives](http://pyro.ai/examples/intro_part_i.html) like `sample` and `param`. The model code should look very similar to Pyro except for some minor differences between PyTorch and Numpy's API. See the [example](https://github.com/pyro-ppl/numpyro#a-simple-example---8-schools) below.\n - **Inference algorithms:** NumPyro currently supports Hamiltonian Monte Carlo, including an implementation of the No U-Turn Sampler. One of the motivations for NumPyro was to speed up Hamiltonian Monte Carlo by JIT compiling the verlet integrator that includes multiple gradient computations. With JAX, we can compose `jit` and `grad` to compile the entire integration step into an XLA optimized kernel. We also eliminate Python overhead by JIT compiling the entire tree building stage in NUTS (this is possible using [Iterative NUTS](https://github.com/pyro-ppl/numpyro/wiki/Iterative-NUTS)). There is also a basic Variational Inference implementation for reparameterized distributions.\n - **Distributions:** The [numpyro.distributions](https://numpyro.readthedocs.io/en/latest/distributions.html) module provides distribution classes, constraints and bijective transforms. The distribution classes wrap over samplers implemented to work with JAX's [functional pseudo-random number generator](https://github.com/google/jax#random-numbers-are-different). The design of the distributions module largely follows from [PyTorch](https://pytorch.org/docs/stable/distributions.html). A major subset of the API is implemented, and it contains most of the common distributions that exist in PyTorch. As a result, Pyro and PyTorch users can rely on the same API and batching semantics as in `torch.distributions`. In addition to distributions, `constraints` and `transforms` are very useful when operating on distribution classes with bounded support.\n - **Effect handlers:** Like Pyro, primitives like `sample` and `param` can be provided nonstandard interpretations using effect-handlers from the [numpyro.handlers](https://numpyro.readthedocs.io/en/latest/handlers.html) module, and these can be easily extended to implement custom inference algorithms and inference utilities.\n\n## A Simple Example - 8 Schools\n\nLet us explore NumPyro using a simple example. We will use the eight schools example from Gelman et al., Bayesian Data Analysis: Sec. 5.5, 2003, which studies the effect of coaching on SAT performance in eight schools. \n\nThe data is given by:\n\n```python\n>>> J = 8\n>>> y = np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0])\n>>> sigma = np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0])\n```\n, where `y` are the treatment effects and `sigma` the standard error. We build a hierarchical model for the study where we assume that the group-level parameters `theta` for each school are sampled from a Normal distribution with unknown mean `mu` and standard deviation `tau`, while the observed data are in turn generated from a Normal distribution with mean and standard deviation given by `theta` (true effect) and `sigma`, respectively. This allows us to estimate the population-level parameters `mu` and `tau` by pooling from all the observations, while still allowing for individual variation amongst the schools using the group-level `theta` parameters.\n\n```python\n>>> # Eight Schools example\n... def eight_schools(J, sigma, y=None):\n...     mu = numpyro.sample('mu', dist.Normal(0, 5))\n...     tau = numpyro.sample('tau', dist.HalfCauchy(5))\n...     with numpyro.plate('J', J):\n...         theta = numpyro.sample('theta', dist.Normal(mu, tau))\n...         numpyro.sample('obs', dist.Normal(theta, sigma), obs=y)\n```\n\nLet us infer the values of the unknown parameters in our model by running MCMC using the No-U-Turn Sampler (NUTS). Note the usage of the `extra_fields` argument in [MCMC.run](http://num.pyro.ai/en/latest/mcmc.html#numpyro.infer.mcmc.MCMC.run). By default, we only collect samples from the target (posterior) distribution when we run inference using `MCMC`. However, collecting additional fields like potential energy or the acceptance probability of a sample can be easily achieved by using the `extra_fields` argument. For a list of possible fields that can be collected, see the [HMCState](http://num.pyro.ai/en/latest/mcmc.html#numpyro.infer.mcmc.HMCState) object. In this example, we will additionally collect the `potential_energy` for each sample.\n\n```python\n>>> nuts_kernel = NUTS(eight_schools)\n>>> mcmc = MCMC(nuts_kernel, num_warmup=500, num_samples=1000)\n>>> rng_key = random.PRNGKey(0)\n>>> mcmc.run(rng_key, J, sigma, y=y, extra_fields=('potential_energy',))\n```\n\nWe can print the summary of the MCMC run, and examine if we observed any divergences during inference. Additionally, since we collected the potential energy for each of the samples, we can easily compute the expected log joint density.\n\n```python\n>>> mcmc.print_summary()\n\n                mean       std    median      5.0%     95.0%     n_eff     r_hat\n        mu      3.94      2.81      3.16      0.03      9.28    114.51      1.06\n       tau      3.20      2.97      2.40      0.38      7.28     24.06      1.07\n  theta[0]      5.56      5.26      4.10     -1.67     13.52     63.57      1.05\n  theta[1]      4.48      4.15      3.26     -2.44     11.25    148.63      1.05\n  theta[2]      3.62      4.40      3.26     -3.85     10.75    445.91      1.01\n  theta[3]      4.25      4.24      3.24     -2.99     10.68    366.29      1.04\n  theta[4]      3.25      3.94      3.29     -3.34      9.84    311.03      1.00\n  theta[5]      3.66      4.27      2.77     -2.79     11.06    344.57      1.02\n  theta[6]      5.74      4.67      4.34     -1.92     13.25     58.42      1.05\n  theta[7]      4.29      4.63      3.23     -2.14     12.37    342.50      1.02\n\nNumber of divergences: 139\n\n>>> pe = mcmc.get_extra_fields()['potential_energy']\n>>> print('Expected log joint density: {:.2f}'.format(np.mean(-pe)))\n\nExpected log joint density: -51.42\n```\n\nThe values above 1 for the split Gelman Rubin diagnostic (`r_hat`) indicates that the chain has not fully converged. The low value for the effective sample size (`n_eff`), particularly for `tau`, and the number of divergent transitions looks problematic. Fortunately, this is a common pathology that can be rectified by using a [non-centered paramaterization](https://mc-stan.org/docs/2_18/stan-users-guide/reparameterization-section.html) for `tau` in our model. This is straightforward to do in NumPyro by using a [TransformedDistribution](http://num.pyro.ai/en/latest/distributions.html#transformeddistribution) instance. Let us rewrite the same model but instead of sampling `theta` from a `Normal(mu, tau)`, we will instead sample it from a base `Normal(0, 1)` distribution that is transformed using an [AffineTransform](http://num.pyro.ai/en/latest/distributions.html#affinetransform). Note that by doing so, NumPyro runs HMC by generating samples for the base `Normal(0, 1)` distribution instead. We see that the resulting chain does not suffer from the same pathology \u2014 the Gelman Rubin diagnostic is 1 for all the parameters and the effective sample size looks quite good! \n\n```python\n>>> # Eight Schools example - Non-centered Reparametrization\n... def eight_schools_noncentered(J, sigma, y=None):\n...     mu = numpyro.sample('mu', dist.Normal(0, 5))\n...     tau = numpyro.sample('tau', dist.HalfCauchy(5))\n...     with numpyro.plate('J', J):\n...         theta = numpyro.sample('theta', \n...                                dist.TransformedDistribution(dist.Normal(0., 1.),\n...                                                             dist.transforms.AffineTransform(mu, tau)))\n...         numpyro.sample('obs', dist.Normal(theta, sigma), obs=y)\n\n>>> nuts_kernel = NUTS(eight_schools_noncentered)\n>>> mcmc = MCMC(nuts_kernel, num_warmup=500, num_samples=1000)\n>>> rng_key = random.PRNGKey(0)\n>>> mcmc.run(rng_key, J, sigma, y=y, extra_fields=('potential_energy',))\n>>> mcmc.print_summary()\n\n                mean       std    median      5.0%     95.0%     n_eff     r_hat\n        mu      4.38      3.04      4.50     -0.92      9.05    876.02      1.00\n       tau      3.36      2.89      2.63      0.01      7.56    755.65      1.00\n  theta[0]      5.99      5.42      5.44     -1.33     15.13    825.18      1.00\n  theta[1]      4.80      4.50      4.78     -1.63     13.01   1114.97      1.00\n  theta[2]      3.94      4.63      4.23     -3.41     11.06    914.68      1.00\n  theta[3]      4.76      4.62      4.73     -2.31     12.11    958.40      1.00\n  theta[4]      3.62      4.66      3.75     -3.87     11.17   1091.53      1.00\n  theta[5]      3.92      4.43      4.06     -2.41     11.09   1179.74      1.00\n  theta[6]      5.88      4.84      5.34     -1.45     13.11    881.38      1.00\n  theta[7]      4.63      4.86      4.64     -3.57     11.80   1065.27      1.00\n\nNumber of divergences: 0\n\n>>> pe = mcmc.get_extra_fields()['potential_energy']\n>>> # Compare with the earlier value\n>>> print('Expected log joint density: {:.2f}'.format(np.mean(-pe)))\n\nExpected log joint density: -46.23\n```\n\nNow, let us assume that we have a new school for which we have not observed any test scores, but we would like to generate predictions. NumPyro provides a [Predictive](http://num.pyro.ai/en/latest/utilities.html#numpyro.infer.util.Predictive) class for such a purpose. Note that in the absence of any observed data, we simply use the population-level parameters to generate predictions. The `Predictive` utility conditions the unobserved `mu` and `tau` sites to values drawn from the posterior distribution from our last MCMC run, and runs the model forward to generate predictions. \n\n```python\n>>> # New School\n... def new_school():\n...     mu = numpyro.sample('mu', dist.Normal(0, 5))\n...     tau = numpyro.sample('tau', dist.HalfCauchy(5))\n...     return numpyro.sample('obs', dist.Normal(mu, tau))\n\n\n>>> predictive = Predictive(new_school, mcmc.get_samples())\n>>> samples_predictive = predictive.get_samples(random.PRNGKey(1))\n>>> print(np.mean(samples_predictive['obs']))\n\n4.419043\n```\n\n## More Examples\n\n\nFor some more examples on specifying models and doing inference in NumPyro:\n\n - [Bayesian Regression in NumPyro](https://nbviewer.jupyter.org/github/pyro-ppl/numpyro/blob/master/notebooks/source/bayesian_regression.ipynb) - Start here to get acquainted with writing a simple model in NumPyro, MCMC inference API, effect handlers and writing custom inference utilities.\n - [Time Series Forecasting](https://nbviewer.jupyter.org/github/pyro-ppl/numpyro/blob/master/notebooks/source/time_series_forecasting.ipynb) - Illustrates how to convert for loops in the model to JAX's `lax.scan` primitive for fast inference.\n - [Baseball example](https://github.com/pyro-ppl/numpyro/blob/master/examples/baseball.py) - Using NUTS for a simple hierarchical model. Compare this with the baseball example in [Pyro](https://github.com/pyro-ppl/pyro/blob/dev/examples/baseball.py).\n - [Hidden Markov Model](https://github.com/pyro-ppl/numpyro/blob/master/examples/hmm.py) in NumPyro as compared to [Stan](https://mc-stan.org/docs/2_19/stan-users-guide/hmms-section.html).\n - [Variational Autoencoder](https://github.com/pyro-ppl/numpyro/blob/master/examples/vae.py) - As a simple example that uses Variational Inference with neural networks. [Pyro implementation](https://github.com/pyro-ppl/pyro/blob/dev/examples/vae/vae.py) for comparison.\n - [Gaussian Process](https://github.com/pyro-ppl/numpyro/blob/master/examples/gp.py) - Provides a simple example to use NUTS to sample from the posterior over the hyper-parameters of a Gaussian Process.\n - [Statistical Rethinking with NumPyro](https://github.com/fehiepsi/rethinking-numpyro) - [Notebooks](https://nbviewer.jupyter.org/github/fehiepsi/rethinking-numpyro/tree/master/notebooks/) containing translation of the code in Richard McElreath's [Statistical Rethinking](https://xcelab.net/rm/statistical-rethinking/) book second version, to NumPyro.\n - Other model examples can be found in the [examples](https://github.com/pyro-ppl/numpyro/tree/master/examples) folder.\n\nPyro users will note that the API for model specification and inference is largely the same as Pyro, including the distributions API, by design. However, there are some important core differences (reflected in the internals) that users should be aware of. e.g. in NumPyro, there is no global parameter store or random state, to make it possible for us to leverage JAX's JIT compilation. Also, users may need to write their models in a more *functional* style that works better with JAX. Refer to [FAQs](#frequently-asked-questions) for a list of differences. \n\n\n## Installation\n\n> **Limited Windows Support:** Note that NumPyro is untested on Windows, and will require building jaxlib from source. See this [JAX issue](https://github.com/google/jax/issues/438) for more details.\n\nTo install NumPyro with a CPU version of JAX, you can use pip:\n\n```\npip install numpyro\n```\n\nTo use NumPyro on the GPU, you will need to first [install](https://github.com/google/jax#installation) `jax` and `jaxlib` with CUDA support.\n\nTo run NumPyro on Cloud TPUs, you can use pip to install NumPyro as above and setup the TPU backend as detailed [here](https://github.com/google/jax/tree/master/cloud_tpu_colabs).\n\nYou can also install NumPyro from source:\n\n```\ngit clone https://github.com/pyro-ppl/numpyro.git\n# install jax/jaxlib first for CUDA support\npip install -e .[dev]\n```\n\n## Frequently Asked Questions\n\n1. Unlike in Pyro, `numpyro.sample('x', dist.Normal(0, 1))` does not work. Why?\n\n   You are most likely using a `numpyro.sample` statement outside an inference context. JAX does not have a global random state, and as such, distribution samplers need an explicit random number generator key ([PRNGKey](https://jax.readthedocs.io/en/latest/jax.random.html#jax.random.PRNGKey)) to generate samples from. NumPyro's inference algorithms use the [seed](http://num.pyro.ai/en/latest/handlers.html#seed) handler to thread in a random number generator key, behind the scenes.\n\n   Your options are:\n\n   - Call the distribution directly and provide a `PRNGKey`, e.g. `dist.Normal(0, 1).sample(PRNGKey(0))`\n   - Provide the `rng_key` argument to `numpyro.sample`. e.g. `numpyro.sample('x', dist.Normal(0, 1), rng_key=PRNGKey(0))`. \n   - Wrap the code in a `seed` handler, used either as a context manager or as a function that wraps over the original callable. e.g. \n     ```python\n     with handlers.seed(rng_seed=0):\n         x = numpyro.sample('x', dist.Beta(1, 1))  # random.PRNGKey(0) is used\n         y = numpyro.sample('y', dist.Bernoulli(x))  # uses different PRNGKey split from the last one\n     ```\n     , or as a higher order function:\n\n     ```python\n     def fn():\n         x = numpyro.sample('x', dist.Beta(1, 1))\n         y = numpyro.sample('y', dist.Bernoulli(x))\n         return y\n\n     print(handlers.seed(fn, rng_seed=0)())\n     ```\n\n2. Can I use the same Pyro model for doing inference in NumPyro?\n\n   As you may have noticed from the examples, NumPyro supports all Pyro primitives like `sample`, `param`, `plate` and `module`, and effect handlers. Additionally, we have ensured that the [distributions](https://numpyro.readthedocs.io/en/latest/distributions.html) API is based on `torch.distributions`, and the inference classes like `SVI` and `MCMC` have the same interface. This along with the similarity in the API for NumPy and PyTorch operations ensures that models containing Pyro primitive statements can be used with either backend with some minor changes. Example of some differences along with the changes needed, are noted below:\n\n   - Any `torch` operation in your model will need to be written in terms of the corresponding `jax.numpy` operation. Additionally, not all `torch` operations have a `numpy` counterpart (and vice-versa), and sometimes there are minor differences in the API.\n   - `pyro.sample` statements outside an inference context will need to be wrapped in a `seed` handler, as mentioned above.\n   - There is no global parameter store, and as such using `numpyro.param` outside an inference context will have no effect. To retrieve the optimized parameter values from SVI, use the [SVI.get_params](http://num.pyro.ai/en/latest/svi.html#numpyro.infer.svi.SVI.get_params) method. Note that you can still use `param` statements inside a model and NumPyro will use the [substitute](http://num.pyro.ai/en/latest/handlers.html#substitute) effect handler internally to substitute values from the optimizer when running the model in SVI. \n   - PyTorch neural network modules will need to rewritten as [stax](https://github.com/google/jax#neural-net-building-with-stax) neural networks. See the [VAE](#examples) example for differences in syntax between the two backends.\n   - JAX works best with functional code, particularly if we would like to leverage JIT compilation, which NumPyro does internally for many inference subroutines. As such, if your model has side-effects that are not visible to the JAX tracer, it may need to rewritten in a more functional style.\n\n   For most small models, changes required to run inference in NumPyro should be minor. Additionally, we are working on [pyro-api](https://github.com/pyro-ppl/pyro-api) which allows you to write the same code and dispatch it to multiple backends, including NumPyro. This will necessarily be more restrictive, but has the advantage of being backend agnostic. See the [documentation](https://pyro-api.readthedocs.io/en/latest/dispatch.html#module-pyroapi.dispatch) for an example, and let us know your feedback.\n\n\n3. How can I contribute to the project?\n\n   Thanks for your interest in the project! You can take a look at beginner friendly issues that are marked with the [good first issue](https://github.com/pyro-ppl/numpyro/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) tag on Github. Also, please feel to reach out to us on the [forum](https://forum.pyro.ai/). \n\n\n## Future / Ongoing Work\n\nIn the near term, we plan to work on the following. Please open new issues for feature requests and enhancements:\n\n - Improving robustness of inference on different models, profiling and performance tuning.\n - Supporting more functionality as part of the [pyro-api](https://github.com/pyro-ppl/pyro-api) generic modeling interface.\n - More inference algorithms, particularly those that require second order derivaties or use HMC.\n - Integration with [Funsor](https://github.com/pyro-ppl/funsor) to support inference algorithms with delayed sampling.\n - Other areas motivated by Pyro's research goals and application focus, and interest from the community.\n\n ## Citing NumPyro\n\nThe motivating ideas behind NumPyro and a description of Iterative NUTS can be found in this [paper](https://arxiv.org/abs/1912.11554) that appeared in NeurIPS 2019 Program Transformations for Machine Learning Workshop. \n\nIf you use NumPyro, please consider citing:\n\n```\n@article{phan2019composable,\n  title={Composable Effects for Flexible and Accelerated Probabilistic Programming in NumPyro},\n  author={Phan, Du and Pradhan, Neeraj and Jankowiak, Martin},\n  journal={arXiv preprint arXiv:1912.11554},\n  year={2019}\n}\n```\n\nas well as\n\n```\n@article{bingham2018pyro,\n  author = {Bingham, Eli and Chen, Jonathan P. and Jankowiak, Martin and Obermeyer, Fritz and\n            Pradhan, Neeraj and Karaletsos, Theofanis and Singh, Rohit and Szerlip, Paul and\n            Horsfall, Paul and Goodman, Noah D.},\n  title = {{Pyro: Deep Universal Probabilistic Programming}},\n  journal = {arXiv preprint arXiv:1810.09538},\n  year = {2018}\n}\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/pyro-ppl/numpyro", "keywords": "probabilistic machine learning bayesian statistics", "license": "Apache License 2.0", "maintainer": "", "maintainer_email": "", "name": "numpyro", "package_url": "https://pypi.org/project/numpyro/", "platform": "", "project_url": "https://pypi.org/project/numpyro/", "project_urls": {"Homepage": "https://github.com/pyro-ppl/numpyro"}, "release_url": "https://pypi.org/project/numpyro/0.2.4/", "requires_dist": ["jax (==0.1.57)", "jaxlib (==0.1.37)", "tqdm", "ipython ; extra == 'dev'", "isort ; extra == 'dev'", "sphinx ; extra == 'doc'", "sphinx-rtd-theme ; extra == 'doc'", "sphinx-gallery ; extra == 'doc'", "matplotlib ; extra == 'examples'", "seaborn ; extra == 'examples'", "flake8 ; extra == 'test'", "pytest (>=4.1) ; extra == 'test'", "pyro-api (>=0.1.1) ; extra == 'test'"], "requires_python": "", "summary": "Pyro PPL on NumPy", "version": "0.2.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://travis-ci.com/pyro-ppl/numpyro\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a0f04d00950d3fb17d12123a96e16d6d0732647d/68747470733a2f2f7472617669732d63692e636f6d2f7079726f2d70706c2f6e756d7079726f2e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://numpyro.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/efb3d60ac09d34b1e71c4e059b89ce6ace7b893b/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6e756d7079726f2f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<a href=\"https://pypi.python.org/pypi/numpyro\" rel=\"nofollow\"><img alt=\"Latest Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e5c706bb9b58aff4a9b3390d1f5b555194114145/68747470733a2f2f62616467652e667572792e696f2f70792f6e756d7079726f2e737667\"></a></p>\n<h1>NumPyro</h1>\n<p>Probabilistic programming with NumPy powered by <a href=\"https://github.com/google/jax\" rel=\"nofollow\">JAX</a> for autograd and JIT compilation to GPU/TPU/CPU.</p>\n<p><a href=\"https://num.pyro.ai\" rel=\"nofollow\">Docs</a> | <a href=\"https://pyro.ai/numpyro/\" rel=\"nofollow\">Examples</a> | <a href=\"https://forum.pyro.ai/\" rel=\"nofollow\">Forum</a></p>\n<hr>\n<h2>What is NumPyro?</h2>\n<p>NumPyro is a small probabilistic programming library that provides a NumPy backend for <a href=\"https://github.com/pyro-ppl/pyro\" rel=\"nofollow\">Pyro</a>. We rely on <a href=\"https://github.com/google/jax\" rel=\"nofollow\">JAX</a> for automatic differentiation and JIT compilation to GPU / CPU. This is an alpha release under active development, so beware of brittleness, bugs, and changes to the API as the design evolves.</p>\n<p>NumPyro is designed to be <em>lightweight</em> and focuses on providing a flexible substrate that users can build on:</p>\n<ul>\n<li><strong>Pyro Primitives:</strong> NumPyro programs can contain regular Python and NumPy code, in addition to <a href=\"http://pyro.ai/examples/intro_part_i.html\" rel=\"nofollow\">Pyro primitives</a> like <code>sample</code> and <code>param</code>. The model code should look very similar to Pyro except for some minor differences between PyTorch and Numpy's API. See the <a href=\"https://github.com/pyro-ppl/numpyro#a-simple-example---8-schools\" rel=\"nofollow\">example</a> below.</li>\n<li><strong>Inference algorithms:</strong> NumPyro currently supports Hamiltonian Monte Carlo, including an implementation of the No U-Turn Sampler. One of the motivations for NumPyro was to speed up Hamiltonian Monte Carlo by JIT compiling the verlet integrator that includes multiple gradient computations. With JAX, we can compose <code>jit</code> and <code>grad</code> to compile the entire integration step into an XLA optimized kernel. We also eliminate Python overhead by JIT compiling the entire tree building stage in NUTS (this is possible using <a href=\"https://github.com/pyro-ppl/numpyro/wiki/Iterative-NUTS\" rel=\"nofollow\">Iterative NUTS</a>). There is also a basic Variational Inference implementation for reparameterized distributions.</li>\n<li><strong>Distributions:</strong> The <a href=\"https://numpyro.readthedocs.io/en/latest/distributions.html\" rel=\"nofollow\">numpyro.distributions</a> module provides distribution classes, constraints and bijective transforms. The distribution classes wrap over samplers implemented to work with JAX's <a href=\"https://github.com/google/jax#random-numbers-are-different\" rel=\"nofollow\">functional pseudo-random number generator</a>. The design of the distributions module largely follows from <a href=\"https://pytorch.org/docs/stable/distributions.html\" rel=\"nofollow\">PyTorch</a>. A major subset of the API is implemented, and it contains most of the common distributions that exist in PyTorch. As a result, Pyro and PyTorch users can rely on the same API and batching semantics as in <code>torch.distributions</code>. In addition to distributions, <code>constraints</code> and <code>transforms</code> are very useful when operating on distribution classes with bounded support.</li>\n<li><strong>Effect handlers:</strong> Like Pyro, primitives like <code>sample</code> and <code>param</code> can be provided nonstandard interpretations using effect-handlers from the <a href=\"https://numpyro.readthedocs.io/en/latest/handlers.html\" rel=\"nofollow\">numpyro.handlers</a> module, and these can be easily extended to implement custom inference algorithms and inference utilities.</li>\n</ul>\n<h2>A Simple Example - 8 Schools</h2>\n<p>Let us explore NumPyro using a simple example. We will use the eight schools example from Gelman et al., Bayesian Data Analysis: Sec. 5.5, 2003, which studies the effect of coaching on SAT performance in eight schools.</p>\n<p>The data is given by:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">J</span> <span class=\"o\">=</span> <span class=\"mi\">8</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"mf\">28.0</span><span class=\"p\">,</span> <span class=\"mf\">8.0</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">3.0</span><span class=\"p\">,</span> <span class=\"mf\">7.0</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">1.0</span><span class=\"p\">,</span> <span class=\"mf\">1.0</span><span class=\"p\">,</span> <span class=\"mf\">18.0</span><span class=\"p\">,</span> <span class=\"mf\">12.0</span><span class=\"p\">])</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">sigma</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"mf\">15.0</span><span class=\"p\">,</span> <span class=\"mf\">10.0</span><span class=\"p\">,</span> <span class=\"mf\">16.0</span><span class=\"p\">,</span> <span class=\"mf\">11.0</span><span class=\"p\">,</span> <span class=\"mf\">9.0</span><span class=\"p\">,</span> <span class=\"mf\">11.0</span><span class=\"p\">,</span> <span class=\"mf\">10.0</span><span class=\"p\">,</span> <span class=\"mf\">18.0</span><span class=\"p\">])</span>\n</pre>\n<p>, where <code>y</code> are the treatment effects and <code>sigma</code> the standard error. We build a hierarchical model for the study where we assume that the group-level parameters <code>theta</code> for each school are sampled from a Normal distribution with unknown mean <code>mu</code> and standard deviation <code>tau</code>, while the observed data are in turn generated from a Normal distribution with mean and standard deviation given by <code>theta</code> (true effect) and <code>sigma</code>, respectively. This allows us to estimate the population-level parameters <code>mu</code> and <code>tau</code> by pooling from all the observations, while still allowing for individual variation amongst the schools using the group-level <code>theta</code> parameters.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"c1\"># Eight Schools example</span>\n<span class=\"o\">...</span> <span class=\"k\">def</span> <span class=\"nf\">eight_schools</span><span class=\"p\">(</span><span class=\"n\">J</span><span class=\"p\">,</span> <span class=\"n\">sigma</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n<span class=\"o\">...</span>     <span class=\"n\">mu</span> <span class=\"o\">=</span> <span class=\"n\">numpyro</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"s1\">'mu'</span><span class=\"p\">,</span> <span class=\"n\">dist</span><span class=\"o\">.</span><span class=\"n\">Normal</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">))</span>\n<span class=\"o\">...</span>     <span class=\"n\">tau</span> <span class=\"o\">=</span> <span class=\"n\">numpyro</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"s1\">'tau'</span><span class=\"p\">,</span> <span class=\"n\">dist</span><span class=\"o\">.</span><span class=\"n\">HalfCauchy</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">))</span>\n<span class=\"o\">...</span>     <span class=\"k\">with</span> <span class=\"n\">numpyro</span><span class=\"o\">.</span><span class=\"n\">plate</span><span class=\"p\">(</span><span class=\"s1\">'J'</span><span class=\"p\">,</span> <span class=\"n\">J</span><span class=\"p\">):</span>\n<span class=\"o\">...</span>         <span class=\"n\">theta</span> <span class=\"o\">=</span> <span class=\"n\">numpyro</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"s1\">'theta'</span><span class=\"p\">,</span> <span class=\"n\">dist</span><span class=\"o\">.</span><span class=\"n\">Normal</span><span class=\"p\">(</span><span class=\"n\">mu</span><span class=\"p\">,</span> <span class=\"n\">tau</span><span class=\"p\">))</span>\n<span class=\"o\">...</span>         <span class=\"n\">numpyro</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"s1\">'obs'</span><span class=\"p\">,</span> <span class=\"n\">dist</span><span class=\"o\">.</span><span class=\"n\">Normal</span><span class=\"p\">(</span><span class=\"n\">theta</span><span class=\"p\">,</span> <span class=\"n\">sigma</span><span class=\"p\">),</span> <span class=\"n\">obs</span><span class=\"o\">=</span><span class=\"n\">y</span><span class=\"p\">)</span>\n</pre>\n<p>Let us infer the values of the unknown parameters in our model by running MCMC using the No-U-Turn Sampler (NUTS). Note the usage of the <code>extra_fields</code> argument in <a href=\"http://num.pyro.ai/en/latest/mcmc.html#numpyro.infer.mcmc.MCMC.run\" rel=\"nofollow\">MCMC.run</a>. By default, we only collect samples from the target (posterior) distribution when we run inference using <code>MCMC</code>. However, collecting additional fields like potential energy or the acceptance probability of a sample can be easily achieved by using the <code>extra_fields</code> argument. For a list of possible fields that can be collected, see the <a href=\"http://num.pyro.ai/en/latest/mcmc.html#numpyro.infer.mcmc.HMCState\" rel=\"nofollow\">HMCState</a> object. In this example, we will additionally collect the <code>potential_energy</code> for each sample.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">nuts_kernel</span> <span class=\"o\">=</span> <span class=\"n\">NUTS</span><span class=\"p\">(</span><span class=\"n\">eight_schools</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">mcmc</span> <span class=\"o\">=</span> <span class=\"n\">MCMC</span><span class=\"p\">(</span><span class=\"n\">nuts_kernel</span><span class=\"p\">,</span> <span class=\"n\">num_warmup</span><span class=\"o\">=</span><span class=\"mi\">500</span><span class=\"p\">,</span> <span class=\"n\">num_samples</span><span class=\"o\">=</span><span class=\"mi\">1000</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">rng_key</span> <span class=\"o\">=</span> <span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">PRNGKey</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">mcmc</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">rng_key</span><span class=\"p\">,</span> <span class=\"n\">J</span><span class=\"p\">,</span> <span class=\"n\">sigma</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"o\">=</span><span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">extra_fields</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"s1\">'potential_energy'</span><span class=\"p\">,))</span>\n</pre>\n<p>We can print the summary of the MCMC run, and examine if we observed any divergences during inference. Additionally, since we collected the potential energy for each of the samples, we can easily compute the expected log joint density.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">mcmc</span><span class=\"o\">.</span><span class=\"n\">print_summary</span><span class=\"p\">()</span>\n\n                <span class=\"n\">mean</span>       <span class=\"n\">std</span>    <span class=\"n\">median</span>      <span class=\"mf\">5.0</span><span class=\"o\">%</span>     <span class=\"mf\">95.0</span><span class=\"o\">%</span>     <span class=\"n\">n_eff</span>     <span class=\"n\">r_hat</span>\n        <span class=\"n\">mu</span>      <span class=\"mf\">3.94</span>      <span class=\"mf\">2.81</span>      <span class=\"mf\">3.16</span>      <span class=\"mf\">0.03</span>      <span class=\"mf\">9.28</span>    <span class=\"mf\">114.51</span>      <span class=\"mf\">1.06</span>\n       <span class=\"n\">tau</span>      <span class=\"mf\">3.20</span>      <span class=\"mf\">2.97</span>      <span class=\"mf\">2.40</span>      <span class=\"mf\">0.38</span>      <span class=\"mf\">7.28</span>     <span class=\"mf\">24.06</span>      <span class=\"mf\">1.07</span>\n  <span class=\"n\">theta</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>      <span class=\"mf\">5.56</span>      <span class=\"mf\">5.26</span>      <span class=\"mf\">4.10</span>     <span class=\"o\">-</span><span class=\"mf\">1.67</span>     <span class=\"mf\">13.52</span>     <span class=\"mf\">63.57</span>      <span class=\"mf\">1.05</span>\n  <span class=\"n\">theta</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span>      <span class=\"mf\">4.48</span>      <span class=\"mf\">4.15</span>      <span class=\"mf\">3.26</span>     <span class=\"o\">-</span><span class=\"mf\">2.44</span>     <span class=\"mf\">11.25</span>    <span class=\"mf\">148.63</span>      <span class=\"mf\">1.05</span>\n  <span class=\"n\">theta</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span>      <span class=\"mf\">3.62</span>      <span class=\"mf\">4.40</span>      <span class=\"mf\">3.26</span>     <span class=\"o\">-</span><span class=\"mf\">3.85</span>     <span class=\"mf\">10.75</span>    <span class=\"mf\">445.91</span>      <span class=\"mf\">1.01</span>\n  <span class=\"n\">theta</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]</span>      <span class=\"mf\">4.25</span>      <span class=\"mf\">4.24</span>      <span class=\"mf\">3.24</span>     <span class=\"o\">-</span><span class=\"mf\">2.99</span>     <span class=\"mf\">10.68</span>    <span class=\"mf\">366.29</span>      <span class=\"mf\">1.04</span>\n  <span class=\"n\">theta</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">]</span>      <span class=\"mf\">3.25</span>      <span class=\"mf\">3.94</span>      <span class=\"mf\">3.29</span>     <span class=\"o\">-</span><span class=\"mf\">3.34</span>      <span class=\"mf\">9.84</span>    <span class=\"mf\">311.03</span>      <span class=\"mf\">1.00</span>\n  <span class=\"n\">theta</span><span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">]</span>      <span class=\"mf\">3.66</span>      <span class=\"mf\">4.27</span>      <span class=\"mf\">2.77</span>     <span class=\"o\">-</span><span class=\"mf\">2.79</span>     <span class=\"mf\">11.06</span>    <span class=\"mf\">344.57</span>      <span class=\"mf\">1.02</span>\n  <span class=\"n\">theta</span><span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">]</span>      <span class=\"mf\">5.74</span>      <span class=\"mf\">4.67</span>      <span class=\"mf\">4.34</span>     <span class=\"o\">-</span><span class=\"mf\">1.92</span>     <span class=\"mf\">13.25</span>     <span class=\"mf\">58.42</span>      <span class=\"mf\">1.05</span>\n  <span class=\"n\">theta</span><span class=\"p\">[</span><span class=\"mi\">7</span><span class=\"p\">]</span>      <span class=\"mf\">4.29</span>      <span class=\"mf\">4.63</span>      <span class=\"mf\">3.23</span>     <span class=\"o\">-</span><span class=\"mf\">2.14</span>     <span class=\"mf\">12.37</span>    <span class=\"mf\">342.50</span>      <span class=\"mf\">1.02</span>\n\n<span class=\"n\">Number</span> <span class=\"n\">of</span> <span class=\"n\">divergences</span><span class=\"p\">:</span> <span class=\"mi\">139</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">pe</span> <span class=\"o\">=</span> <span class=\"n\">mcmc</span><span class=\"o\">.</span><span class=\"n\">get_extra_fields</span><span class=\"p\">()[</span><span class=\"s1\">'potential_energy'</span><span class=\"p\">]</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Expected log joint density: </span><span class=\"si\">{:.2f}</span><span class=\"s1\">'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"n\">pe</span><span class=\"p\">)))</span>\n\n<span class=\"n\">Expected</span> <span class=\"n\">log</span> <span class=\"n\">joint</span> <span class=\"n\">density</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">51.42</span>\n</pre>\n<p>The values above 1 for the split Gelman Rubin diagnostic (<code>r_hat</code>) indicates that the chain has not fully converged. The low value for the effective sample size (<code>n_eff</code>), particularly for <code>tau</code>, and the number of divergent transitions looks problematic. Fortunately, this is a common pathology that can be rectified by using a <a href=\"https://mc-stan.org/docs/2_18/stan-users-guide/reparameterization-section.html\" rel=\"nofollow\">non-centered paramaterization</a> for <code>tau</code> in our model. This is straightforward to do in NumPyro by using a <a href=\"http://num.pyro.ai/en/latest/distributions.html#transformeddistribution\" rel=\"nofollow\">TransformedDistribution</a> instance. Let us rewrite the same model but instead of sampling <code>theta</code> from a <code>Normal(mu, tau)</code>, we will instead sample it from a base <code>Normal(0, 1)</code> distribution that is transformed using an <a href=\"http://num.pyro.ai/en/latest/distributions.html#affinetransform\" rel=\"nofollow\">AffineTransform</a>. Note that by doing so, NumPyro runs HMC by generating samples for the base <code>Normal(0, 1)</code> distribution instead. We see that the resulting chain does not suffer from the same pathology \u2014 the Gelman Rubin diagnostic is 1 for all the parameters and the effective sample size looks quite good!</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"c1\"># Eight Schools example - Non-centered Reparametrization</span>\n<span class=\"o\">...</span> <span class=\"k\">def</span> <span class=\"nf\">eight_schools_noncentered</span><span class=\"p\">(</span><span class=\"n\">J</span><span class=\"p\">,</span> <span class=\"n\">sigma</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n<span class=\"o\">...</span>     <span class=\"n\">mu</span> <span class=\"o\">=</span> <span class=\"n\">numpyro</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"s1\">'mu'</span><span class=\"p\">,</span> <span class=\"n\">dist</span><span class=\"o\">.</span><span class=\"n\">Normal</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">))</span>\n<span class=\"o\">...</span>     <span class=\"n\">tau</span> <span class=\"o\">=</span> <span class=\"n\">numpyro</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"s1\">'tau'</span><span class=\"p\">,</span> <span class=\"n\">dist</span><span class=\"o\">.</span><span class=\"n\">HalfCauchy</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">))</span>\n<span class=\"o\">...</span>     <span class=\"k\">with</span> <span class=\"n\">numpyro</span><span class=\"o\">.</span><span class=\"n\">plate</span><span class=\"p\">(</span><span class=\"s1\">'J'</span><span class=\"p\">,</span> <span class=\"n\">J</span><span class=\"p\">):</span>\n<span class=\"o\">...</span>         <span class=\"n\">theta</span> <span class=\"o\">=</span> <span class=\"n\">numpyro</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"s1\">'theta'</span><span class=\"p\">,</span> \n<span class=\"o\">...</span>                                <span class=\"n\">dist</span><span class=\"o\">.</span><span class=\"n\">TransformedDistribution</span><span class=\"p\">(</span><span class=\"n\">dist</span><span class=\"o\">.</span><span class=\"n\">Normal</span><span class=\"p\">(</span><span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">),</span>\n<span class=\"o\">...</span>                                                             <span class=\"n\">dist</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">AffineTransform</span><span class=\"p\">(</span><span class=\"n\">mu</span><span class=\"p\">,</span> <span class=\"n\">tau</span><span class=\"p\">)))</span>\n<span class=\"o\">...</span>         <span class=\"n\">numpyro</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"s1\">'obs'</span><span class=\"p\">,</span> <span class=\"n\">dist</span><span class=\"o\">.</span><span class=\"n\">Normal</span><span class=\"p\">(</span><span class=\"n\">theta</span><span class=\"p\">,</span> <span class=\"n\">sigma</span><span class=\"p\">),</span> <span class=\"n\">obs</span><span class=\"o\">=</span><span class=\"n\">y</span><span class=\"p\">)</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">nuts_kernel</span> <span class=\"o\">=</span> <span class=\"n\">NUTS</span><span class=\"p\">(</span><span class=\"n\">eight_schools_noncentered</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">mcmc</span> <span class=\"o\">=</span> <span class=\"n\">MCMC</span><span class=\"p\">(</span><span class=\"n\">nuts_kernel</span><span class=\"p\">,</span> <span class=\"n\">num_warmup</span><span class=\"o\">=</span><span class=\"mi\">500</span><span class=\"p\">,</span> <span class=\"n\">num_samples</span><span class=\"o\">=</span><span class=\"mi\">1000</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">rng_key</span> <span class=\"o\">=</span> <span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">PRNGKey</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">mcmc</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">rng_key</span><span class=\"p\">,</span> <span class=\"n\">J</span><span class=\"p\">,</span> <span class=\"n\">sigma</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"o\">=</span><span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">extra_fields</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"s1\">'potential_energy'</span><span class=\"p\">,))</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">mcmc</span><span class=\"o\">.</span><span class=\"n\">print_summary</span><span class=\"p\">()</span>\n\n                <span class=\"n\">mean</span>       <span class=\"n\">std</span>    <span class=\"n\">median</span>      <span class=\"mf\">5.0</span><span class=\"o\">%</span>     <span class=\"mf\">95.0</span><span class=\"o\">%</span>     <span class=\"n\">n_eff</span>     <span class=\"n\">r_hat</span>\n        <span class=\"n\">mu</span>      <span class=\"mf\">4.38</span>      <span class=\"mf\">3.04</span>      <span class=\"mf\">4.50</span>     <span class=\"o\">-</span><span class=\"mf\">0.92</span>      <span class=\"mf\">9.05</span>    <span class=\"mf\">876.02</span>      <span class=\"mf\">1.00</span>\n       <span class=\"n\">tau</span>      <span class=\"mf\">3.36</span>      <span class=\"mf\">2.89</span>      <span class=\"mf\">2.63</span>      <span class=\"mf\">0.01</span>      <span class=\"mf\">7.56</span>    <span class=\"mf\">755.65</span>      <span class=\"mf\">1.00</span>\n  <span class=\"n\">theta</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>      <span class=\"mf\">5.99</span>      <span class=\"mf\">5.42</span>      <span class=\"mf\">5.44</span>     <span class=\"o\">-</span><span class=\"mf\">1.33</span>     <span class=\"mf\">15.13</span>    <span class=\"mf\">825.18</span>      <span class=\"mf\">1.00</span>\n  <span class=\"n\">theta</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span>      <span class=\"mf\">4.80</span>      <span class=\"mf\">4.50</span>      <span class=\"mf\">4.78</span>     <span class=\"o\">-</span><span class=\"mf\">1.63</span>     <span class=\"mf\">13.01</span>   <span class=\"mf\">1114.97</span>      <span class=\"mf\">1.00</span>\n  <span class=\"n\">theta</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span>      <span class=\"mf\">3.94</span>      <span class=\"mf\">4.63</span>      <span class=\"mf\">4.23</span>     <span class=\"o\">-</span><span class=\"mf\">3.41</span>     <span class=\"mf\">11.06</span>    <span class=\"mf\">914.68</span>      <span class=\"mf\">1.00</span>\n  <span class=\"n\">theta</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]</span>      <span class=\"mf\">4.76</span>      <span class=\"mf\">4.62</span>      <span class=\"mf\">4.73</span>     <span class=\"o\">-</span><span class=\"mf\">2.31</span>     <span class=\"mf\">12.11</span>    <span class=\"mf\">958.40</span>      <span class=\"mf\">1.00</span>\n  <span class=\"n\">theta</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">]</span>      <span class=\"mf\">3.62</span>      <span class=\"mf\">4.66</span>      <span class=\"mf\">3.75</span>     <span class=\"o\">-</span><span class=\"mf\">3.87</span>     <span class=\"mf\">11.17</span>   <span class=\"mf\">1091.53</span>      <span class=\"mf\">1.00</span>\n  <span class=\"n\">theta</span><span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">]</span>      <span class=\"mf\">3.92</span>      <span class=\"mf\">4.43</span>      <span class=\"mf\">4.06</span>     <span class=\"o\">-</span><span class=\"mf\">2.41</span>     <span class=\"mf\">11.09</span>   <span class=\"mf\">1179.74</span>      <span class=\"mf\">1.00</span>\n  <span class=\"n\">theta</span><span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">]</span>      <span class=\"mf\">5.88</span>      <span class=\"mf\">4.84</span>      <span class=\"mf\">5.34</span>     <span class=\"o\">-</span><span class=\"mf\">1.45</span>     <span class=\"mf\">13.11</span>    <span class=\"mf\">881.38</span>      <span class=\"mf\">1.00</span>\n  <span class=\"n\">theta</span><span class=\"p\">[</span><span class=\"mi\">7</span><span class=\"p\">]</span>      <span class=\"mf\">4.63</span>      <span class=\"mf\">4.86</span>      <span class=\"mf\">4.64</span>     <span class=\"o\">-</span><span class=\"mf\">3.57</span>     <span class=\"mf\">11.80</span>   <span class=\"mf\">1065.27</span>      <span class=\"mf\">1.00</span>\n\n<span class=\"n\">Number</span> <span class=\"n\">of</span> <span class=\"n\">divergences</span><span class=\"p\">:</span> <span class=\"mi\">0</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">pe</span> <span class=\"o\">=</span> <span class=\"n\">mcmc</span><span class=\"o\">.</span><span class=\"n\">get_extra_fields</span><span class=\"p\">()[</span><span class=\"s1\">'potential_energy'</span><span class=\"p\">]</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"c1\"># Compare with the earlier value</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Expected log joint density: </span><span class=\"si\">{:.2f}</span><span class=\"s1\">'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"n\">pe</span><span class=\"p\">)))</span>\n\n<span class=\"n\">Expected</span> <span class=\"n\">log</span> <span class=\"n\">joint</span> <span class=\"n\">density</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mf\">46.23</span>\n</pre>\n<p>Now, let us assume that we have a new school for which we have not observed any test scores, but we would like to generate predictions. NumPyro provides a <a href=\"http://num.pyro.ai/en/latest/utilities.html#numpyro.infer.util.Predictive\" rel=\"nofollow\">Predictive</a> class for such a purpose. Note that in the absence of any observed data, we simply use the population-level parameters to generate predictions. The <code>Predictive</code> utility conditions the unobserved <code>mu</code> and <code>tau</code> sites to values drawn from the posterior distribution from our last MCMC run, and runs the model forward to generate predictions.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"c1\"># New School</span>\n<span class=\"o\">...</span> <span class=\"k\">def</span> <span class=\"nf\">new_school</span><span class=\"p\">():</span>\n<span class=\"o\">...</span>     <span class=\"n\">mu</span> <span class=\"o\">=</span> <span class=\"n\">numpyro</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"s1\">'mu'</span><span class=\"p\">,</span> <span class=\"n\">dist</span><span class=\"o\">.</span><span class=\"n\">Normal</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">))</span>\n<span class=\"o\">...</span>     <span class=\"n\">tau</span> <span class=\"o\">=</span> <span class=\"n\">numpyro</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"s1\">'tau'</span><span class=\"p\">,</span> <span class=\"n\">dist</span><span class=\"o\">.</span><span class=\"n\">HalfCauchy</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">))</span>\n<span class=\"o\">...</span>     <span class=\"k\">return</span> <span class=\"n\">numpyro</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"s1\">'obs'</span><span class=\"p\">,</span> <span class=\"n\">dist</span><span class=\"o\">.</span><span class=\"n\">Normal</span><span class=\"p\">(</span><span class=\"n\">mu</span><span class=\"p\">,</span> <span class=\"n\">tau</span><span class=\"p\">))</span>\n\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">predictive</span> <span class=\"o\">=</span> <span class=\"n\">Predictive</span><span class=\"p\">(</span><span class=\"n\">new_school</span><span class=\"p\">,</span> <span class=\"n\">mcmc</span><span class=\"o\">.</span><span class=\"n\">get_samples</span><span class=\"p\">())</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">samples_predictive</span> <span class=\"o\">=</span> <span class=\"n\">predictive</span><span class=\"o\">.</span><span class=\"n\">get_samples</span><span class=\"p\">(</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">PRNGKey</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">))</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">samples_predictive</span><span class=\"p\">[</span><span class=\"s1\">'obs'</span><span class=\"p\">]))</span>\n\n<span class=\"mf\">4.419043</span>\n</pre>\n<h2>More Examples</h2>\n<p>For some more examples on specifying models and doing inference in NumPyro:</p>\n<ul>\n<li><a href=\"https://nbviewer.jupyter.org/github/pyro-ppl/numpyro/blob/master/notebooks/source/bayesian_regression.ipynb\" rel=\"nofollow\">Bayesian Regression in NumPyro</a> - Start here to get acquainted with writing a simple model in NumPyro, MCMC inference API, effect handlers and writing custom inference utilities.</li>\n<li><a href=\"https://nbviewer.jupyter.org/github/pyro-ppl/numpyro/blob/master/notebooks/source/time_series_forecasting.ipynb\" rel=\"nofollow\">Time Series Forecasting</a> - Illustrates how to convert for loops in the model to JAX's <code>lax.scan</code> primitive for fast inference.</li>\n<li><a href=\"https://github.com/pyro-ppl/numpyro/blob/master/examples/baseball.py\" rel=\"nofollow\">Baseball example</a> - Using NUTS for a simple hierarchical model. Compare this with the baseball example in <a href=\"https://github.com/pyro-ppl/pyro/blob/dev/examples/baseball.py\" rel=\"nofollow\">Pyro</a>.</li>\n<li><a href=\"https://github.com/pyro-ppl/numpyro/blob/master/examples/hmm.py\" rel=\"nofollow\">Hidden Markov Model</a> in NumPyro as compared to <a href=\"https://mc-stan.org/docs/2_19/stan-users-guide/hmms-section.html\" rel=\"nofollow\">Stan</a>.</li>\n<li><a href=\"https://github.com/pyro-ppl/numpyro/blob/master/examples/vae.py\" rel=\"nofollow\">Variational Autoencoder</a> - As a simple example that uses Variational Inference with neural networks. <a href=\"https://github.com/pyro-ppl/pyro/blob/dev/examples/vae/vae.py\" rel=\"nofollow\">Pyro implementation</a> for comparison.</li>\n<li><a href=\"https://github.com/pyro-ppl/numpyro/blob/master/examples/gp.py\" rel=\"nofollow\">Gaussian Process</a> - Provides a simple example to use NUTS to sample from the posterior over the hyper-parameters of a Gaussian Process.</li>\n<li><a href=\"https://github.com/fehiepsi/rethinking-numpyro\" rel=\"nofollow\">Statistical Rethinking with NumPyro</a> - <a href=\"https://nbviewer.jupyter.org/github/fehiepsi/rethinking-numpyro/tree/master/notebooks/\" rel=\"nofollow\">Notebooks</a> containing translation of the code in Richard McElreath's <a href=\"https://xcelab.net/rm/statistical-rethinking/\" rel=\"nofollow\">Statistical Rethinking</a> book second version, to NumPyro.</li>\n<li>Other model examples can be found in the <a href=\"https://github.com/pyro-ppl/numpyro/tree/master/examples\" rel=\"nofollow\">examples</a> folder.</li>\n</ul>\n<p>Pyro users will note that the API for model specification and inference is largely the same as Pyro, including the distributions API, by design. However, there are some important core differences (reflected in the internals) that users should be aware of. e.g. in NumPyro, there is no global parameter store or random state, to make it possible for us to leverage JAX's JIT compilation. Also, users may need to write their models in a more <em>functional</em> style that works better with JAX. Refer to <a href=\"#frequently-asked-questions\" rel=\"nofollow\">FAQs</a> for a list of differences.</p>\n<h2>Installation</h2>\n<blockquote>\n<p><strong>Limited Windows Support:</strong> Note that NumPyro is untested on Windows, and will require building jaxlib from source. See this <a href=\"https://github.com/google/jax/issues/438\" rel=\"nofollow\">JAX issue</a> for more details.</p>\n</blockquote>\n<p>To install NumPyro with a CPU version of JAX, you can use pip:</p>\n<pre><code>pip install numpyro\n</code></pre>\n<p>To use NumPyro on the GPU, you will need to first <a href=\"https://github.com/google/jax#installation\" rel=\"nofollow\">install</a> <code>jax</code> and <code>jaxlib</code> with CUDA support.</p>\n<p>To run NumPyro on Cloud TPUs, you can use pip to install NumPyro as above and setup the TPU backend as detailed <a href=\"https://github.com/google/jax/tree/master/cloud_tpu_colabs\" rel=\"nofollow\">here</a>.</p>\n<p>You can also install NumPyro from source:</p>\n<pre><code>git clone https://github.com/pyro-ppl/numpyro.git\n# install jax/jaxlib first for CUDA support\npip install -e .[dev]\n</code></pre>\n<h2>Frequently Asked Questions</h2>\n<ol>\n<li>\n<p>Unlike in Pyro, <code>numpyro.sample('x', dist.Normal(0, 1))</code> does not work. Why?</p>\n<p>You are most likely using a <code>numpyro.sample</code> statement outside an inference context. JAX does not have a global random state, and as such, distribution samplers need an explicit random number generator key (<a href=\"https://jax.readthedocs.io/en/latest/jax.random.html#jax.random.PRNGKey\" rel=\"nofollow\">PRNGKey</a>) to generate samples from. NumPyro's inference algorithms use the <a href=\"http://num.pyro.ai/en/latest/handlers.html#seed\" rel=\"nofollow\">seed</a> handler to thread in a random number generator key, behind the scenes.</p>\n<p>Your options are:</p>\n<ul>\n<li>\n<p>Call the distribution directly and provide a <code>PRNGKey</code>, e.g. <code>dist.Normal(0, 1).sample(PRNGKey(0))</code></p>\n</li>\n<li>\n<p>Provide the <code>rng_key</code> argument to <code>numpyro.sample</code>. e.g. <code>numpyro.sample('x', dist.Normal(0, 1), rng_key=PRNGKey(0))</code>.</p>\n</li>\n<li>\n<p>Wrap the code in a <code>seed</code> handler, used either as a context manager or as a function that wraps over the original callable. e.g.</p>\n<pre><span class=\"k\">with</span> <span class=\"n\">handlers</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"n\">rng_seed</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">):</span>\n    <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">numpyro</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"s1\">'x'</span><span class=\"p\">,</span> <span class=\"n\">dist</span><span class=\"o\">.</span><span class=\"n\">Beta</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">))</span>  <span class=\"c1\"># random.PRNGKey(0) is used</span>\n    <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">numpyro</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"s1\">'y'</span><span class=\"p\">,</span> <span class=\"n\">dist</span><span class=\"o\">.</span><span class=\"n\">Bernoulli</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">))</span>  <span class=\"c1\"># uses different PRNGKey split from the last one</span>\n</pre>\n<p>, or as a higher order function:</p>\n<pre><span class=\"k\">def</span> <span class=\"nf\">fn</span><span class=\"p\">():</span>\n    <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">numpyro</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"s1\">'x'</span><span class=\"p\">,</span> <span class=\"n\">dist</span><span class=\"o\">.</span><span class=\"n\">Beta</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">))</span>\n    <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">numpyro</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"s1\">'y'</span><span class=\"p\">,</span> <span class=\"n\">dist</span><span class=\"o\">.</span><span class=\"n\">Bernoulli</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">))</span>\n    <span class=\"k\">return</span> <span class=\"n\">y</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">handlers</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"n\">fn</span><span class=\"p\">,</span> <span class=\"n\">rng_seed</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)())</span>\n</pre>\n</li>\n</ul>\n</li>\n<li>\n<p>Can I use the same Pyro model for doing inference in NumPyro?</p>\n<p>As you may have noticed from the examples, NumPyro supports all Pyro primitives like <code>sample</code>, <code>param</code>, <code>plate</code> and <code>module</code>, and effect handlers. Additionally, we have ensured that the <a href=\"https://numpyro.readthedocs.io/en/latest/distributions.html\" rel=\"nofollow\">distributions</a> API is based on <code>torch.distributions</code>, and the inference classes like <code>SVI</code> and <code>MCMC</code> have the same interface. This along with the similarity in the API for NumPy and PyTorch operations ensures that models containing Pyro primitive statements can be used with either backend with some minor changes. Example of some differences along with the changes needed, are noted below:</p>\n<ul>\n<li>Any <code>torch</code> operation in your model will need to be written in terms of the corresponding <code>jax.numpy</code> operation. Additionally, not all <code>torch</code> operations have a <code>numpy</code> counterpart (and vice-versa), and sometimes there are minor differences in the API.</li>\n<li><code>pyro.sample</code> statements outside an inference context will need to be wrapped in a <code>seed</code> handler, as mentioned above.</li>\n<li>There is no global parameter store, and as such using <code>numpyro.param</code> outside an inference context will have no effect. To retrieve the optimized parameter values from SVI, use the <a href=\"http://num.pyro.ai/en/latest/svi.html#numpyro.infer.svi.SVI.get_params\" rel=\"nofollow\">SVI.get_params</a> method. Note that you can still use <code>param</code> statements inside a model and NumPyro will use the <a href=\"http://num.pyro.ai/en/latest/handlers.html#substitute\" rel=\"nofollow\">substitute</a> effect handler internally to substitute values from the optimizer when running the model in SVI.</li>\n<li>PyTorch neural network modules will need to rewritten as <a href=\"https://github.com/google/jax#neural-net-building-with-stax\" rel=\"nofollow\">stax</a> neural networks. See the <a href=\"#examples\" rel=\"nofollow\">VAE</a> example for differences in syntax between the two backends.</li>\n<li>JAX works best with functional code, particularly if we would like to leverage JIT compilation, which NumPyro does internally for many inference subroutines. As such, if your model has side-effects that are not visible to the JAX tracer, it may need to rewritten in a more functional style.</li>\n</ul>\n<p>For most small models, changes required to run inference in NumPyro should be minor. Additionally, we are working on <a href=\"https://github.com/pyro-ppl/pyro-api\" rel=\"nofollow\">pyro-api</a> which allows you to write the same code and dispatch it to multiple backends, including NumPyro. This will necessarily be more restrictive, but has the advantage of being backend agnostic. See the <a href=\"https://pyro-api.readthedocs.io/en/latest/dispatch.html#module-pyroapi.dispatch\" rel=\"nofollow\">documentation</a> for an example, and let us know your feedback.</p>\n</li>\n<li>\n<p>How can I contribute to the project?</p>\n<p>Thanks for your interest in the project! You can take a look at beginner friendly issues that are marked with the <a href=\"https://github.com/pyro-ppl/numpyro/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22\" rel=\"nofollow\">good first issue</a> tag on Github. Also, please feel to reach out to us on the <a href=\"https://forum.pyro.ai/\" rel=\"nofollow\">forum</a>.</p>\n</li>\n</ol>\n<h2>Future / Ongoing Work</h2>\n<p>In the near term, we plan to work on the following. Please open new issues for feature requests and enhancements:</p>\n<ul>\n<li>Improving robustness of inference on different models, profiling and performance tuning.</li>\n<li>Supporting more functionality as part of the <a href=\"https://github.com/pyro-ppl/pyro-api\" rel=\"nofollow\">pyro-api</a> generic modeling interface.</li>\n<li>More inference algorithms, particularly those that require second order derivaties or use HMC.</li>\n<li>Integration with <a href=\"https://github.com/pyro-ppl/funsor\" rel=\"nofollow\">Funsor</a> to support inference algorithms with delayed sampling.</li>\n<li>Other areas motivated by Pyro's research goals and application focus, and interest from the community.</li>\n</ul>\n<h2>Citing NumPyro</h2>\n<p>The motivating ideas behind NumPyro and a description of Iterative NUTS can be found in this <a href=\"https://arxiv.org/abs/1912.11554\" rel=\"nofollow\">paper</a> that appeared in NeurIPS 2019 Program Transformations for Machine Learning Workshop.</p>\n<p>If you use NumPyro, please consider citing:</p>\n<pre><code>@article{phan2019composable,\n  title={Composable Effects for Flexible and Accelerated Probabilistic Programming in NumPyro},\n  author={Phan, Du and Pradhan, Neeraj and Jankowiak, Martin},\n  journal={arXiv preprint arXiv:1912.11554},\n  year={2019}\n}\n</code></pre>\n<p>as well as</p>\n<pre><code>@article{bingham2018pyro,\n  author = {Bingham, Eli and Chen, Jonathan P. and Jankowiak, Martin and Obermeyer, Fritz and\n            Pradhan, Neeraj and Karaletsos, Theofanis and Singh, Rohit and Szerlip, Paul and\n            Horsfall, Paul and Goodman, Noah D.},\n  title = {{Pyro: Deep Universal Probabilistic Programming}},\n  journal = {arXiv preprint arXiv:1810.09538},\n  year = {2018}\n}\n</code></pre>\n\n          </div>"}, "last_serial": 6509688, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "a6cb308c7ccee6f6f3ef329a25888d7a", "sha256": "3df3e54abfa195a51ceadc6d177ff629f79c5fe9c9a8f89547b3b1a73bd49840"}, "downloads": -1, "filename": "numpyro-0.1.0.tar.gz", "has_sig": false, "md5_digest": "a6cb308c7ccee6f6f3ef329a25888d7a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 73756, "upload_time": "2019-06-01T04:15:31", "upload_time_iso_8601": "2019-06-01T04:15:31.748787Z", "url": "https://files.pythonhosted.org/packages/46/b7/e4e0624e9e948b1f1c4176ef01ac8dc3487fdc78f897494bdfe15932e51b/numpyro-0.1.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "93d947398501804cd7e21c5dcccd92fa", "sha256": "4f7ed0d83cca73d67e2368132a5dbbb0f84094942f2468173dc1b6c3770a5769"}, "downloads": -1, "filename": "numpyro-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "93d947398501804cd7e21c5dcccd92fa", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 95162, "upload_time": "2019-09-08T07:22:40", "upload_time_iso_8601": "2019-09-08T07:22:40.068864Z", "url": "https://files.pythonhosted.org/packages/17/7c/323ec59c52d6c49defcba944167843437976cbc7261cff058721e74fc77f/numpyro-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "26e76fef203630d51dfb292ca94b3e29", "sha256": "32b2dc6e0dc1c94a0b6590bfba51f605446162072ab73ca69e272dad1007aaf8"}, "downloads": -1, "filename": "numpyro-0.2.0.tar.gz", "has_sig": false, "md5_digest": "26e76fef203630d51dfb292ca94b3e29", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 101660, "upload_time": "2019-09-08T07:22:41", "upload_time_iso_8601": "2019-09-08T07:22:41.825754Z", "url": "https://files.pythonhosted.org/packages/5a/fa/574b880cb719cd2b2310a6851ff334a2e0cbec1929b3871c16a37988e30f/numpyro-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "594a02918eb0cc76ec09bdec0993242d", "sha256": "539dc587d4fb08516077142f2d60e95f77834aeaef5a7c5ecfaa1c1e59028cec"}, "downloads": -1, "filename": "numpyro-0.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "594a02918eb0cc76ec09bdec0993242d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 141793, "upload_time": "2019-11-01T22:16:23", "upload_time_iso_8601": "2019-11-01T22:16:23.956413Z", "url": "https://files.pythonhosted.org/packages/88/bb/f83e6e4fa6a426f90e834afb1e17bf05549ea2d43a41abe5acb8182dda90/numpyro-0.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7240c470f498c90f588b7176fbf87219", "sha256": "794e938ed186e8ce4b22091018f9c138f698f29196f92c59913bbf109e27eb9e"}, "downloads": -1, "filename": "numpyro-0.2.1.tar.gz", "has_sig": false, "md5_digest": "7240c470f498c90f588b7176fbf87219", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 123523, "upload_time": "2019-11-01T22:16:26", "upload_time_iso_8601": "2019-11-01T22:16:26.423119Z", "url": "https://files.pythonhosted.org/packages/ce/e9/23a5c01c58065ac8a17b3a9014cfcc85074ee6403e62f9bedb82ed729206/numpyro-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "8ef36ac6789eef37a71de904212502d9", "sha256": "caa60045d199f0d17b85d1fbfda778ae82589dab044c412a4b8e5ad2f3f55908"}, "downloads": -1, "filename": "numpyro-0.2.2-py3-none-any.whl", "has_sig": false, "md5_digest": "8ef36ac6789eef37a71de904212502d9", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 145243, "upload_time": "2019-12-04T20:53:38", "upload_time_iso_8601": "2019-12-04T20:53:38.333554Z", "url": "https://files.pythonhosted.org/packages/c2/ee/a6355d9748e16c3d75b84eef97cb43bae2374e969fe9959b03ca4fe4f8a5/numpyro-0.2.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1a8c3d2b2015e1bbd14997e03bb09dfd", "sha256": "af5198fa29f5e31ec3a9e4d7b5ac3d3cc2499476d9db0e6c7b18ea56dae4ee20"}, "downloads": -1, "filename": "numpyro-0.2.2.tar.gz", "has_sig": false, "md5_digest": "1a8c3d2b2015e1bbd14997e03bb09dfd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 128636, "upload_time": "2019-12-04T20:53:40", "upload_time_iso_8601": "2019-12-04T20:53:40.001138Z", "url": "https://files.pythonhosted.org/packages/38/cf/208b731aec339e74ad0ed317a01983a8dca9ce461cf0525988074ae74572/numpyro-0.2.2.tar.gz", "yanked": false}], "0.2.3": [{"comment_text": "", "digests": {"md5": "1753cd329e7b525214938ded32fc1b18", "sha256": "78cd0244738f9c183222f533fda17496bbc78186baec3f57f285020a7b257719"}, "downloads": -1, "filename": "numpyro-0.2.3-py3-none-any.whl", "has_sig": false, "md5_digest": "1753cd329e7b525214938ded32fc1b18", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 145336, "upload_time": "2019-12-05T06:45:06", "upload_time_iso_8601": "2019-12-05T06:45:06.330015Z", "url": "https://files.pythonhosted.org/packages/2f/a1/c88ba97a02b71c6683d0d673c4d01b93023e30f00cda36c8192f1ef98fd8/numpyro-0.2.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d9bb309cb9a4f1bbd241e578519314bf", "sha256": "aa7050a610f278d6600630648787f1dc18152d1c9fbd65a92863c6c37ffaee9f"}, "downloads": -1, "filename": "numpyro-0.2.3.tar.gz", "has_sig": false, "md5_digest": "d9bb309cb9a4f1bbd241e578519314bf", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 128704, "upload_time": "2019-12-05T06:45:08", "upload_time_iso_8601": "2019-12-05T06:45:08.539430Z", "url": "https://files.pythonhosted.org/packages/0a/ca/0ace30608623cfaa40ddd290d1685387d567abbd0687d1e51f8a4f6664c6/numpyro-0.2.3.tar.gz", "yanked": false}], "0.2.4": [{"comment_text": "", "digests": {"md5": "6b4b1e3f0a9cb55b935bd94d690d0c0d", "sha256": "38d97f976205256b66916e3a863cb57a42065bc9cf89615d7bbf047162df2e62"}, "downloads": -1, "filename": "numpyro-0.2.4-py3-none-any.whl", "has_sig": false, "md5_digest": "6b4b1e3f0a9cb55b935bd94d690d0c0d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 159369, "upload_time": "2020-01-23T19:44:41", "upload_time_iso_8601": "2020-01-23T19:44:41.023937Z", "url": "https://files.pythonhosted.org/packages/b8/58/54e914bb6d8ee9196f8dbf28b81057fea81871fc171dbee03b790336d0c5/numpyro-0.2.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5e427dcb5eed1c0cef0323edf1246d0e", "sha256": "a2d29766308c3b0e0254429c57c04538f94f78cb0a6fac574404a59f4b6c1663"}, "downloads": -1, "filename": "numpyro-0.2.4.tar.gz", "has_sig": false, "md5_digest": "5e427dcb5eed1c0cef0323edf1246d0e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 137970, "upload_time": "2020-01-23T19:44:44", "upload_time_iso_8601": "2020-01-23T19:44:44.677808Z", "url": "https://files.pythonhosted.org/packages/17/31/c50530f1492b06f7914251a22dcb78d14aac33ad9cdeb1aaa4c218afa1f2/numpyro-0.2.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "6b4b1e3f0a9cb55b935bd94d690d0c0d", "sha256": "38d97f976205256b66916e3a863cb57a42065bc9cf89615d7bbf047162df2e62"}, "downloads": -1, "filename": "numpyro-0.2.4-py3-none-any.whl", "has_sig": false, "md5_digest": "6b4b1e3f0a9cb55b935bd94d690d0c0d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 159369, "upload_time": "2020-01-23T19:44:41", "upload_time_iso_8601": "2020-01-23T19:44:41.023937Z", "url": "https://files.pythonhosted.org/packages/b8/58/54e914bb6d8ee9196f8dbf28b81057fea81871fc171dbee03b790336d0c5/numpyro-0.2.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5e427dcb5eed1c0cef0323edf1246d0e", "sha256": "a2d29766308c3b0e0254429c57c04538f94f78cb0a6fac574404a59f4b6c1663"}, "downloads": -1, "filename": "numpyro-0.2.4.tar.gz", "has_sig": false, "md5_digest": "5e427dcb5eed1c0cef0323edf1246d0e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 137970, "upload_time": "2020-01-23T19:44:44", "upload_time_iso_8601": "2020-01-23T19:44:44.677808Z", "url": "https://files.pythonhosted.org/packages/17/31/c50530f1492b06f7914251a22dcb78d14aac33ad9cdeb1aaa4c218afa1f2/numpyro-0.2.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:44:10 2020"}