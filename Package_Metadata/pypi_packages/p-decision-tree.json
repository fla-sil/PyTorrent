{"info": {"author": "Majid Rafiei", "author_email": "majid.rafiei@pads.rwth-aachen.de", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# Visual Decision Tree Based on Categorical Attributes \n-------------------\n\nAs you may know \"scikit-learn\" library in python is not able to make a decision tree based on categorical data, and you have to convert categorical data to numerical before passing them to the classifier method. Also, the resulted decision tree is a binary tree while a decision tree does not need to be binary.\n\nHere, we provide a library which is able to make a visual decision tree based on categorical data. You can read more about decision trees [here](https://en.wikipedia.org/wiki/Decision_tree).\n\n## Features\n--------------------\n\nThe main algorithm which is used is ID3 with the following features:\n\n* Information gain based on [entropy](https://en.wikipedia.org/wiki/Decision_tree_learning)\n* Information gain based on [gini](https://en.wikipedia.org/wiki/Decision_tree_learning)\n* Some pruning capabilities like:\n\t* Minimum number of samples\n\t* Minimum information gain\n* The resulted tree is not binary\n\n## Requirements\n--------------------\n\nYou can find all the requirements in \"requirements.txt\" file, and it can be installed easily by the following command:\n\n* pip install -r requirements.txt \n\nAlso to be able to see visual tree, you need to install graphviz package. [Here](https://www.graphviz.org/download/) you can find the right package with respect to your operation system. \n\n\n## Usage\n--------------------\n\n```python\n\nfrom p_decision_tree.DecisionTree import DecisionTree\nimport pandas as pd\n\n#Reading CSV file as data set by Pandas\ndata = pd.read_csv('playtennis.csv')\ncolumns = data.columns\n\n#All columns except the last one are descriptive by default\ndescriptive_features = columns[:-1]\n#The last column is considered as label\nlabel = columns[-1]\n\n#Converting all the columns to string\nfor column in columns:\n    data[column]= data[column].astype(str)\n\ndata_descriptive = data[descriptive_features].values\ndata_label = data[label].values\n\n#Calling DecisionTree constructor (the last parameter is criterion which can also be \"gini\")\ndecisionTree = DecisionTree(data_descriptive.tolist(), descriptive_features.tolist(), data_label.tolist(), \"entropy\")\n\n#Here you can pass pruning features (gain_threshold and minimum_samples)\ndecisionTree.id3(0,0)\n\n#Visualizing decision tree by Graphviz\ndot = decisionTree.print_visualTree( render=True )\n\n# When using Jupyter\n#display( dot )\n\nprint(\"System entropy: \", format(decisionTree.entropy))\nprint(\"System gini: \", format(decisionTree.gini))\n\n\n\n``` \n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/m4jidRafiei/Decision-Tree-Python-", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "p-decision-tree", "package_url": "https://pypi.org/project/p-decision-tree/", "platform": "", "project_url": "https://pypi.org/project/p-decision-tree/", "project_urls": {"Homepage": "https://github.com/m4jidRafiei/Decision-Tree-Python-", "Source": "https://github.com/m4jidRafiei/Decision-Tree-Python-"}, "release_url": "https://pypi.org/project/p-decision-tree/0.0.2/", "requires_dist": ["graphviz (==0.9)", "pandas (==0.24.2)"], "requires_python": "", "summary": "Visual Decision Tree Based on Categorical Attributes Package", "version": "0.0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Visual Decision Tree Based on Categorical Attributes</h1>\n<hr>\n<p>As you may know \"scikit-learn\" library in python is not able to make a decision tree based on categorical data, and you have to convert categorical data to numerical before passing them to the classifier method. Also, the resulted decision tree is a binary tree while a decision tree does not need to be binary.</p>\n<p>Here, we provide a library which is able to make a visual decision tree based on categorical data. You can read more about decision trees <a href=\"https://en.wikipedia.org/wiki/Decision_tree\" rel=\"nofollow\">here</a>.</p>\n<h2>Features</h2>\n<hr>\n<p>The main algorithm which is used is ID3 with the following features:</p>\n<ul>\n<li>Information gain based on <a href=\"https://en.wikipedia.org/wiki/Decision_tree_learning\" rel=\"nofollow\">entropy</a></li>\n<li>Information gain based on <a href=\"https://en.wikipedia.org/wiki/Decision_tree_learning\" rel=\"nofollow\">gini</a></li>\n<li>Some pruning capabilities like:\n<ul>\n<li>Minimum number of samples</li>\n<li>Minimum information gain</li>\n</ul>\n</li>\n<li>The resulted tree is not binary</li>\n</ul>\n<h2>Requirements</h2>\n<hr>\n<p>You can find all the requirements in \"requirements.txt\" file, and it can be installed easily by the following command:</p>\n<ul>\n<li>pip install -r requirements.txt</li>\n</ul>\n<p>Also to be able to see visual tree, you need to install graphviz package. <a href=\"https://www.graphviz.org/download/\" rel=\"nofollow\">Here</a> you can find the right package with respect to your operation system.</p>\n<h2>Usage</h2>\n<hr>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">p_decision_tree.DecisionTree</span> <span class=\"kn\">import</span> <span class=\"n\">DecisionTree</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n\n<span class=\"c1\">#Reading CSV file as data set by Pandas</span>\n<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s1\">'playtennis.csv'</span><span class=\"p\">)</span>\n<span class=\"n\">columns</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">columns</span>\n\n<span class=\"c1\">#All columns except the last one are descriptive by default</span>\n<span class=\"n\">descriptive_features</span> <span class=\"o\">=</span> <span class=\"n\">columns</span><span class=\"p\">[:</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n<span class=\"c1\">#The last column is considered as label</span>\n<span class=\"n\">label</span> <span class=\"o\">=</span> <span class=\"n\">columns</span><span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n\n<span class=\"c1\">#Converting all the columns to string</span>\n<span class=\"k\">for</span> <span class=\"n\">column</span> <span class=\"ow\">in</span> <span class=\"n\">columns</span><span class=\"p\">:</span>\n    <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"n\">column</span><span class=\"p\">]</span><span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"n\">column</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"nb\">str</span><span class=\"p\">)</span>\n\n<span class=\"n\">data_descriptive</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"n\">descriptive_features</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">values</span>\n<span class=\"n\">data_label</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"n\">label</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">values</span>\n\n<span class=\"c1\">#Calling DecisionTree constructor (the last parameter is criterion which can also be \"gini\")</span>\n<span class=\"n\">decisionTree</span> <span class=\"o\">=</span> <span class=\"n\">DecisionTree</span><span class=\"p\">(</span><span class=\"n\">data_descriptive</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">(),</span> <span class=\"n\">descriptive_features</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">(),</span> <span class=\"n\">data_label</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">(),</span> <span class=\"s2\">\"entropy\"</span><span class=\"p\">)</span>\n\n<span class=\"c1\">#Here you can pass pruning features (gain_threshold and minimum_samples)</span>\n<span class=\"n\">decisionTree</span><span class=\"o\">.</span><span class=\"n\">id3</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n\n<span class=\"c1\">#Visualizing decision tree by Graphviz</span>\n<span class=\"n\">dot</span> <span class=\"o\">=</span> <span class=\"n\">decisionTree</span><span class=\"o\">.</span><span class=\"n\">print_visualTree</span><span class=\"p\">(</span> <span class=\"n\">render</span><span class=\"o\">=</span><span class=\"kc\">True</span> <span class=\"p\">)</span>\n\n<span class=\"c1\"># When using Jupyter</span>\n<span class=\"c1\">#display( dot )</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"System entropy: \"</span><span class=\"p\">,</span> <span class=\"nb\">format</span><span class=\"p\">(</span><span class=\"n\">decisionTree</span><span class=\"o\">.</span><span class=\"n\">entropy</span><span class=\"p\">))</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"System gini: \"</span><span class=\"p\">,</span> <span class=\"nb\">format</span><span class=\"p\">(</span><span class=\"n\">decisionTree</span><span class=\"o\">.</span><span class=\"n\">gini</span><span class=\"p\">))</span>\n</pre>\n\n          </div>"}, "last_serial": 5752134, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "a46237529e933cca407bc9ff6c664cda", "sha256": "b0c71b19b3fbe0dedf42fbc1fa9b4a9442a70a7a7ec67ec75b0274df86418ca0"}, "downloads": -1, "filename": "p_decision_tree-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "a46237529e933cca407bc9ff6c664cda", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6112, "upload_time": "2019-08-29T11:56:20", "upload_time_iso_8601": "2019-08-29T11:56:20.915880Z", "url": "https://files.pythonhosted.org/packages/6c/61/c41c65daa96b188bf2511c06cac43de244ef7271622a6fc99f9bb8311201/p_decision_tree-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "06e3d54f43aba8aa0ca2afc3453e329c", "sha256": "e86f8a17860145bca70ebd07c955c41f7f6c10c33c201b60087c20947b05d80d"}, "downloads": -1, "filename": "p_decision_tree-0.0.1.tar.gz", "has_sig": false, "md5_digest": "06e3d54f43aba8aa0ca2afc3453e329c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4683, "upload_time": "2019-08-29T11:56:23", "upload_time_iso_8601": "2019-08-29T11:56:23.403454Z", "url": "https://files.pythonhosted.org/packages/22/53/572b0c14e9a87eda783637fe4bb81676a02bcfa62074a22cc08e2968032b/p_decision_tree-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "10c9b2f947eeef8847a049de0db9608b", "sha256": "15534dbc2aa70829b023623dd2f4eda4517ecb56f88c7b215bf5fbe912879e4d"}, "downloads": -1, "filename": "p_decision_tree-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "10c9b2f947eeef8847a049de0db9608b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6115, "upload_time": "2019-08-29T12:34:37", "upload_time_iso_8601": "2019-08-29T12:34:37.922137Z", "url": "https://files.pythonhosted.org/packages/e2/af/36b82b24bf5527bb6a210cc6d9ab6e6b849a94882f604f8bc845b4a5075e/p_decision_tree-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d786b31495e66256f63e3a7a6c1d1caa", "sha256": "3bf1655ac32acb2c4d0358d9fa4b2e5d3ca4d3388c8718c26068ef4f32cfacac"}, "downloads": -1, "filename": "p_decision_tree-0.0.2.tar.gz", "has_sig": false, "md5_digest": "d786b31495e66256f63e3a7a6c1d1caa", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4675, "upload_time": "2019-08-29T12:34:39", "upload_time_iso_8601": "2019-08-29T12:34:39.290537Z", "url": "https://files.pythonhosted.org/packages/27/0e/827b88637fdec71974dc26f1b1a4179865357ad0a1cf285e9dfb986f2278/p_decision_tree-0.0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "10c9b2f947eeef8847a049de0db9608b", "sha256": "15534dbc2aa70829b023623dd2f4eda4517ecb56f88c7b215bf5fbe912879e4d"}, "downloads": -1, "filename": "p_decision_tree-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "10c9b2f947eeef8847a049de0db9608b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6115, "upload_time": "2019-08-29T12:34:37", "upload_time_iso_8601": "2019-08-29T12:34:37.922137Z", "url": "https://files.pythonhosted.org/packages/e2/af/36b82b24bf5527bb6a210cc6d9ab6e6b849a94882f604f8bc845b4a5075e/p_decision_tree-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d786b31495e66256f63e3a7a6c1d1caa", "sha256": "3bf1655ac32acb2c4d0358d9fa4b2e5d3ca4d3388c8718c26068ef4f32cfacac"}, "downloads": -1, "filename": "p_decision_tree-0.0.2.tar.gz", "has_sig": false, "md5_digest": "d786b31495e66256f63e3a7a6c1d1caa", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4675, "upload_time": "2019-08-29T12:34:39", "upload_time_iso_8601": "2019-08-29T12:34:39.290537Z", "url": "https://files.pythonhosted.org/packages/27/0e/827b88637fdec71974dc26f1b1a4179865357ad0a1cf285e9dfb986f2278/p_decision_tree-0.0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:57:18 2020"}