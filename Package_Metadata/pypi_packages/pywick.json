{"info": {"author": "Achaiah", "author_email": "", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3.6"], "description": "# Pywick\n\n#### High-Level Training framework for Pytorch\n\nPywick is a high-level Pytorch training framework that aims to get you\nup and running quickly with state of the art neural networks. *Does the\nworld need another Pytorch framework?* Probably not. But we started this\nproject when no good frameworks were available and it just kept growing.\nSo here we are.\n\nPywick tries to stay on the bleeding edge of research into neural networks. If you just wish to run a vanilla CNN, this is probably\ngoing to be overkill. However, if you want to get lost in the world of neural networks, fine-tuning and hyperparameter optimization\nfor months on end then this is probably the right place for you :)\n\nAmong other things Pywick includes:\n- State of the art normalization, activation, loss functions and\n  optimizers not included in the standard Pytorch library.\n- A high-level module for training with callbacks, constraints, metrics,\n  conditions and regularizers.\n- Dozens of popular object classification and semantic segmentation models.\n- Comprehensive data loading, augmentation, transforms, and sampling capability.\n- Utility tensor functions.\n- Useful meters.\n- Basic GridSearch (exhaustive and random).\n\n## Docs\nHey, [check this out](https://pywick.readthedocs.io/en/latest/), we now\nhave [docs](https://pywick.readthedocs.io/en/latest/)! They're still a\nwork in progress though so apologies for anything that's broken.\n\n## What's New (highlights)\n- **Jan. 20, 2020**\n  - New release: 0.5.6 (minor fix from 0.5.5 for pypi)\n  - Mish activation function (SoTA)\n  - [rwightman's](https://github.com/rwightman/gen-efficientnet-pytorch) models of pretrained/ported variants for classification (44 total)\n    - efficientnet Tensorflow port b0-b8, with and without AP, el/em/es, cc\n    - mixnet L/M/S\n    - mobilenetv3\n    - mnasnet\n    - spnasnet\n  - Additional loss functions\n- **Aug. 1, 2019**\n  -   New segmentation NNs: BiSeNet, DANet, DenseASPP, DUNet, OCNet, PSANet\n    - New Loss Functions: Focal Tversky Loss, OHEM CrossEntropy Loss, various combination losses\n    - Major restructuring and standardization of NN models and loading functionality\n    - General bug fixes and code improvements \n\n## Install\nPywick requires **pytorch >= 1.0**\n\n`pip install pywick`\n\nor specific version from git:\n\n`pip install git+https://github.com/achaiah/pywick.git@v0.5.6`\n\n## ModuleTrainer\nThe `ModuleTrainer` class provides a high-level training interface which abstracts\naway the training loop while providing callbacks, constraints, initializers, regularizers,\nand more.\n\nExample:\n```python\nfrom pywick.modules import ModuleTrainer\nfrom pywick.initializers import XavierUniform\nfrom pywick.metrics import CategoricalAccuracySingleInput\nimport torch.nn as nn\nimport torch.functional as F\n\n# Define your model EXACTLY as normal\nclass Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.fc1 = nn.Linear(1600, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = x.view(-1, 1600)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x)\n\nmodel = Network()\ntrainer = ModuleTrainer(model)   # optionally supply cuda_devices as a parameter\n\ninitializers = [XavierUniform(bias=False, module_filter='fc*')]\n\n# initialize metrics with top1 and top5 \nmetrics = [CategoricalAccuracySingleInput(top_k=1), CategoricalAccuracySingleInput(top_k=5)]\n\ntrainer.compile(loss='cross_entropy',\n                # callbacks=callbacks,          # define your callbacks here (e.g. model saver, LR scheduler)\n                # regularizers=regularizers,    # define regularizers\n                # constraints=constraints,      # define constraints\n                optimizer='sgd',\n                initializers=initializers,\n                metrics=metrics)\n\ntrainer.fit_loader(train_dataset_loader, \n            val_loader=val_dataset_loader,\n            num_epoch=20,\n            verbose=1)\n```\nYou also have access to the standard evaluation and prediction functions:\n\n```python\nloss = trainer.evaluate(x_train, y_train)\ny_pred = trainer.predict(x_train)\n```\nPyWick provides a wide range of <b>callbacks</b>, generally mimicking the interface\nfound in `Keras`:\n\n- `CSVLogger` - Logs epoch-level metrics to a CSV file\n- [`CyclicLRScheduler`](https://github.com/bckenstler/CLR) - Cycles through min-max learning rate\n- `EarlyStopping` - Provides ability to stop training early based on supplied criteria\n- `History` - Keeps history of metrics etc. during the learning process\n- `LambdaCallback` - Allows you to implement your own callbacks on the fly\n- `LRScheduler` - Simple learning rate scheduler based on function or supplied schedule\n- `ModelCheckpoint` - Comprehensive model saver\n- `ReduceLROnPlateau` - Reduces learning rate (LR) when a plateau has been reached\n- `SimpleModelCheckpoint` - Simple model saver\n- Additionally, a `TensorboardLogger` is incredibly easy to implement\n  via the [TensorboardX](https://github.com/lanpa/tensorboardX) (now\n  part of pytorch 1.1 release!)\n\n\n```python\nfrom pywick.callbacks import EarlyStopping\n\ncallbacks = [EarlyStopping(monitor='val_loss', patience=5)]\ntrainer.set_callbacks(callbacks)\n```\n\nPyWick also provides <b>regularizers</b>:\n\n- `L1Regularizer`\n- `L2Regularizer`\n- `L1L2Regularizer`\n\n\nand <b>constraints</b>:\n- `UnitNorm`\n- `MaxNorm`\n- `NonNeg`\n\nBoth regularizers and constraints can be selectively applied on layers using regular expressions and the `module_filter`\nargument. Constraints can be explicit (hard) constraints applied at an arbitrary batch or\nepoch frequency, or they can be implicit (soft) constraints similar to regularizers\nwhere the the constraint deviation is added as a penalty to the total model loss.\n\n```python\nfrom pywick.constraints import MaxNorm, NonNeg\nfrom pywick.regularizers import L1Regularizer\n\n# hard constraint applied every 5 batches\nhard_constraint = MaxNorm(value=2., frequency=5, unit='batch', module_filter='*fc*')\n# implicit constraint added as a penalty term to model loss\nsoft_constraint = NonNeg(lagrangian=True, scale=1e-3, module_filter='*fc*')\nconstraints = [hard_constraint, soft_constraint]\ntrainer.set_constraints(constraints)\n\nregularizers = [L1Regularizer(scale=1e-4, module_filter='*conv*')]\ntrainer.set_regularizers(regularizers)\n```\n\nYou can also fit directly on a `torch.utils.data.DataLoader` and can have\na validation set as well :\n\n```python\nfrom pywick import TensorDataset\nfrom torch.utils.data import DataLoader\n\ntrain_dataset = TensorDataset(x_train, y_train)\ntrain_loader = DataLoader(train_dataset, batch_size=32)\n\nval_dataset = TensorDataset(x_val, y_val)\nval_loader = DataLoader(val_dataset, batch_size=32)\n\ntrainer.fit_loader(loader, val_loader=val_loader, num_epoch=100)\n```\n\n## Extensive Library of Image Classification Models (most are pretrained!)\n- All standard models from Pytorch:\n  - [**Densenet**](https://arxiv.org/abs/1608.06993)\n  - [**Inception v3**](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.pdf)\n  - [**MobileNet v2**](https://arxiv.org/abs/1801.04381)\n  - [**ResNet**](https://arxiv.org/abs/1512.03385)\n  - [**ShuffleNet v2**](https://arxiv.org/abs/1807.11164)\n  - [**SqueezeNet**](https://arxiv.org/abs/1602.07360)\n  - [**VGG**](https://arxiv.org/abs/1409.1556)\n- [**BatchNorm Inception**](https://arxiv.org/pdf/1502.03167.pdf)\n- [**Dual Path Networks**](https://arxiv.org/abs/1707.01629)\n- [**EfficientNet variants b0-b8**](https://arxiv.org/abs/1905.11946)\n- [**FBResnet**](https://github.com/facebook/fb.resnet.torch)\n- [**FBNet-C**](https://arxiv.org/abs/1812.03443)\n- [**Inception v4**](http://arxiv.org/abs/1602.07261)\n- [**InceptionResnet v2**](https://arxiv.org/abs/1602.07261)\n- [**Mixnet L/M/S**](https://arxiv.org/abs/1907.09595)\n- [**MnasNet**](https://arxiv.org/abs/1807.11626)\n- [**MobileNet V3**](https://arxiv.org/abs/1905.02244)\n- [**NasNet and NasNet Mobile**](https://arxiv.org/abs/1707.07012)\n- [**PNASNet**](https://arxiv.org/abs/1712.00559)\n- [**Polynet**](https://arxiv.org/abs/1611.05725)\n- [**Pyramid Resnet**](https://arxiv.org/abs/1610.02915)\n- **Resnet + Swish**\n- [**ResNext**](https://arxiv.org/abs/1611.05431)\n- [**SE Net**](https://arxiv.org/pdf/1709.01507.pdf)\n- **SE Inception**\n- [**Single-Pass NAS Net**](https://arxiv.org/abs/1904.02877)\n- [**Wide Resnet**](https://arxiv.org/abs/1605.07146)\n- [**XCeption**](https://arxiv.org/pdf/1610.02357.pdf)\n\n## Image Segmentation Models\n- **BiSeNet** ([Bilateral Segmentation Network for Real-time Semantic Segmentation](https://arxiv.org/abs/1808.00897))\n- **DANet** ([Dual Attention Network for Scene Segmentation](https://arxiv.org/abs/1809.02983))\n- **Deeplab v2** ([DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs](https://arxiv.org/abs/1606.00915))\n- **Deeplab v3** ([Rethinking Atrous Convolution for Semantic Image Segmentation](https://arxiv.org/abs/1706.05587))\n- **DenseASPP** ([DenseASPP for Semantic Segmentation in Street Scenes](http://openaccess.thecvf.com/content_cvpr_2018/papers/Yang_DenseASPP_for_Semantic_CVPR_2018_paper.pdf))\n- **DRNNet** ([Dilated Residual Networks](http://openaccess.thecvf.com/content_cvpr_2017/papers/Yu_Dilated_Residual_Networks_CVPR_2017_paper.pdf))\n- **DUC, HDC** ([understanding convolution for semantic segmentation](https://arxiv.org/abs/1702.08502))\n- **DUNet** ([Decoders Matter for Semantic Segmentation](https://arxiv.org/abs/1903.02120))\n- **ENet** ([ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation](https://arxiv.org/abs/1606.02147))\n- **Vanilla FCN:** FCN32, FCN16, FCN8, in the versions of VGG, ResNet\n    and OptDenseNet respectively ([Fully convolutional networks for semantic segmentation](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf))\n- **FRRN** ([Full Resolution Residual Networks for Semantic Segmentation in Street Scenes](https://arxiv.org/abs/1611.08323))\n- **FusionNet** ([FusionNet in Tensorflow by Hyungjoo Andrew Cho](https://github.com/NySunShine/fusion-net))\n- **GCN** ([Large Kernel Matters](https://arxiv.org/pdf/1703.02719))\n- **LinkNet** ([Link-Net](https://codeac29.github.io/projects/linknet/))\n- **OCNet** ([Object Context Network for Scene Parsing](https://arxiv.org/abs/1809.00916))\n- **PSPNet** ([Pyramid scene parsing network](https://arxiv.org/abs/1612.01105))\n- **RefineNet** ([RefineNet](https://arxiv.org/abs/1611.06612))\n- **SegNet** ([Segnet: A deep convolutional encoder-decoder architecture for image segmentation](https://arxiv.org/pdf/1511.00561))\n- **Tiramisu** ([The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic Segmentation](https://arxiv.org/abs/1611.09326))\n- **U-Net** ([U-net: Convolutional networks for biomedical image segmentation](https://arxiv.org/abs/1505.04597))\n- Additional variations of many of the above\n\n###### To load one of these models:\n[Read the docs](https://pywick.readthedocs.io/en/latest/api/pywick.models.html)\nfor useful details! Then dive in:\n```python\n# use the `get_model` utility\nfrom pywick.models.model_utils import get_model, ModelType\n\nmodel = get_model(model_type=ModelType.CLASSIFICATION, model_name='resnet18', num_classes=1000, pretrained=True)\n```\nFor a complete list of models (including many experimental ones) you can call the `get_supported_models` method e.g. \n`pywick.models.model_utils.get_supported_models(ModelType.SEGMENTATION)`\n\n## Data Augmentation and Datasets\nThe PyWick package provides wide variety of good data augmentation and transformation\ntools which can be applied during data loading. The package also provides the flexible\n`TensorDataset`, `FolderDataset` and `MultiFolderDataset` classes to handle most dataset needs.\n\n### Torch Transforms\n##### These transforms work directly on torch tensors\n\n- `AddChannel`\n- `ChannelsFirst`\n- `ChannelsLast`\n- `Compose`\n- `ExpandAxis`\n- `Pad`\n- `PadNumpy`\n- `RandomChoiceCompose`\n- `RandomCrop`\n- `RandomFlip`\n- `RandomOrder`\n- `RangeNormalize`\n- `Slice2D`\n- `SpecialCrop`\n- `StdNormalize`\n- `ToFile`\n- `ToNumpyType`\n- `ToTensor`\n- `Transpose`\n- `TypeCast`\n\n##### Additionally, we provide image-specific manipulations directly on tensors:\n\n- `Brightness`\n- `Contrast`\n- `Gamma`\n- `Grayscale`\n- `RandomBrightness`\n- `RandomChoiceBrightness`\n- `RandomChoiceContrast`\n- `RandomChoiceGamma`\n- `RandomChoiceSaturation`\n- `RandomContrast`\n- `RandomGamma`\n- `RandomGrayscale`\n- `RandomSaturation`\n- `Saturation`\n\n#####  Affine Transforms (perform affine or affine-like transforms on torch tensors)\n\n- `RandomAffine`\n- `RandomChoiceRotate`\n- `RandomChoiceShear`\n- `RandomChoiceTranslate`\n- `RandomChoiceZoom`\n- `RandomRotate`\n- `RandomShear`\n- `RandomSquareZoom`\n- `RandomTranslate`\n- `RandomZoom`\n- `Rotate`\n- `Shear`\n- `Translate`\n- `Zoom`\n\nWe also provide a class for stringing multiple affine transformations together so that only one interpolation takes place:\n\n- `Affine` \n- `AffineCompose`\n\n##### Blur and Scramble transforms (for tensors)\n- `Blur`\n- `RandomChoiceBlur`\n- `RandomChoiceScramble`\n- `Scramble`\n\n### Datasets and Sampling\nWe provide the following datasets which provide general structure and iterators for sampling from and using transforms on in-memory or out-of-memory data. In particular,\nthe [FolderDataset](pywick/datasets/FolderDataset.py) has been designed to fit most of your dataset needs. It has extensive options for data filtering and manipulation.\nIt supports loading images for classification, segmentation and even arbitrary source/target mapping. Take a good look at its documentation for more info.\n\n- `ClonedDataset`\n- `CSVDataset`\n- `FolderDataset`\n- `MultiFolderDataset`\n- `TensorDataset`\n- `tnt.BatchDataset`\n- `tnt.ConcatDataset`\n- `tnt.ListDataset`\n- `tnt.MultiPartitionDataset`\n- `tnt.ResampleDataset`\n- `tnt.ShuffleDataset`\n- `tnt.TensorDataset`\n- `tnt.TransformDataset`\n\n### Imbalanced Datasets\nIn many scenarios it is important to ensure that your traing set is properly balanced,\nhowever, it may not be practical in real life to obtain such a perfect dataset. In these cases \nyou can use the `ImbalancedDatasetSampler` as a drop-in replacement for the basic sampler provided\nby the DataLoader. More information can be found [here](https://github.com/ufoym/imbalanced-dataset-sampler)\n\n```python\nfrom pywick.samplers import ImbalancedDatasetSampler\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, \n    sampler=ImbalancedDatasetSampler(train_dataset),\n    batch_size=args.batch_size, **kwargs)\n```\n\n## Utility Functions\nPyWick provides a few utility functions not commonly found:\n\n### Tensor Functions\n- `th_iterproduct` (mimics itertools.product)\n- `th_gather_nd` (N-dimensional version of torch.gather)\n- `th_random_choice` (mimics np.random.choice)\n- `th_pearsonr` (mimics scipy.stats.pearsonr)\n- `th_corrcoef` (mimics np.corrcoef)\n- `th_affine2d` and `th_affine3d` (affine transforms on torch.Tensors)\n\n\n## Acknowledgements and References\nWe stand on the shoulders of (github?) giants and couldn't have done\nthis without the rich github ecosystem and community. This framework is\nbased in part on the excellent\n[Torchsample](https://github.com/ncullen93/torchsample) framework\noriginally published by @ncullen93. Additionally, many models have been\ngently borrowed/modified from @Cadene pretrained models\n[repo](https://github.com/Cadene/pretrained-models.pytorch) as well as @Tramac segmentation [repo](https://github.com/Tramac/awesome-semantic-segmentation-pytorch).\n\n##### Thank you to the following people and the projects they maintain:\n- @ncullen93\n- @cadene\n- @deallynomore\n- @recastrodiaz\n- @zijundeng\n- @Tramac\n- And many others! (attributions listed in the codebase as they occur)\n\n##### Thank you to the following projects from which we gently borrowed code and models\n- [PyTorchNet](https://github.com/pytorch/tnt)\n- [pretrained-models.pytorch](https://github.com/Cadene/pretrained-models.pytorch)\n- [DeepLab_pytorch](https://github.com/doiken23/DeepLab_pytorch)\n- [Pytorch for Semantic Segmentation](https://github.com/zijundeng/pytorch-semantic-segmentation)\n- [Binseg Pytorch](https://github.com/saeedizadi/binseg_pytoch)\n- [awesome-semantic-segmentation-pytorch](https://github.com/Tramac/awesome-semantic-segmentation-pytorch)\n- And many others! (attributions listed in the codebase as they occur)\n\n\n\n| *Thangs are broken matey! Arrr!!!* |\n|-----------------------|\n| We're working on this project as time permits so you might discover bugs here and there. Feel free to report them, or better yet, to submit a pull request! |\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/achaiah/pywick/archive/v0.5.6.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/achaiah/pywick", "keywords": "pytorch,classification,deep learning,neural networks,semantic-segmentation,framework", "license": "", "maintainer": "", "maintainer_email": "", "name": "pywick", "package_url": "https://pypi.org/project/pywick/", "platform": "", "project_url": "https://pypi.org/project/pywick/", "project_urls": {"Download": "https://github.com/achaiah/pywick/archive/v0.5.6.tar.gz", "Homepage": "https://github.com/achaiah/pywick"}, "release_url": "https://pypi.org/project/pywick/0.5.6/", "requires_dist": ["h5py", "hickle", "numpy", "pandas", "pillow", "six", "torch", "torchvision", "tqdm"], "requires_python": "", "summary": "High-level batteries-included training framework for Pytorch", "version": "0.5.6", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Pywick</h1>\n<h4>High-Level Training framework for Pytorch</h4>\n<p>Pywick is a high-level Pytorch training framework that aims to get you\nup and running quickly with state of the art neural networks. <em>Does the\nworld need another Pytorch framework?</em> Probably not. But we started this\nproject when no good frameworks were available and it just kept growing.\nSo here we are.</p>\n<p>Pywick tries to stay on the bleeding edge of research into neural networks. If you just wish to run a vanilla CNN, this is probably\ngoing to be overkill. However, if you want to get lost in the world of neural networks, fine-tuning and hyperparameter optimization\nfor months on end then this is probably the right place for you :)</p>\n<p>Among other things Pywick includes:</p>\n<ul>\n<li>State of the art normalization, activation, loss functions and\noptimizers not included in the standard Pytorch library.</li>\n<li>A high-level module for training with callbacks, constraints, metrics,\nconditions and regularizers.</li>\n<li>Dozens of popular object classification and semantic segmentation models.</li>\n<li>Comprehensive data loading, augmentation, transforms, and sampling capability.</li>\n<li>Utility tensor functions.</li>\n<li>Useful meters.</li>\n<li>Basic GridSearch (exhaustive and random).</li>\n</ul>\n<h2>Docs</h2>\n<p>Hey, <a href=\"https://pywick.readthedocs.io/en/latest/\" rel=\"nofollow\">check this out</a>, we now\nhave <a href=\"https://pywick.readthedocs.io/en/latest/\" rel=\"nofollow\">docs</a>! They're still a\nwork in progress though so apologies for anything that's broken.</p>\n<h2>What's New (highlights)</h2>\n<ul>\n<li><strong>Jan. 20, 2020</strong>\n<ul>\n<li>New release: 0.5.6 (minor fix from 0.5.5 for pypi)</li>\n<li>Mish activation function (SoTA)</li>\n<li><a href=\"https://github.com/rwightman/gen-efficientnet-pytorch\" rel=\"nofollow\">rwightman's</a> models of pretrained/ported variants for classification (44 total)\n<ul>\n<li>efficientnet Tensorflow port b0-b8, with and without AP, el/em/es, cc</li>\n<li>mixnet L/M/S</li>\n<li>mobilenetv3</li>\n<li>mnasnet</li>\n<li>spnasnet</li>\n</ul>\n</li>\n<li>Additional loss functions</li>\n</ul>\n</li>\n<li><strong>Aug. 1, 2019</strong>\n<ul>\n<li>New segmentation NNs: BiSeNet, DANet, DenseASPP, DUNet, OCNet, PSANet</li>\n<li>New Loss Functions: Focal Tversky Loss, OHEM CrossEntropy Loss, various combination losses</li>\n<li>Major restructuring and standardization of NN models and loading functionality</li>\n<li>General bug fixes and code improvements</li>\n</ul>\n</li>\n</ul>\n<h2>Install</h2>\n<p>Pywick requires <strong>pytorch &gt;= 1.0</strong></p>\n<p><code>pip install pywick</code></p>\n<p>or specific version from git:</p>\n<p><code>pip install git+https://github.com/achaiah/pywick.git@v0.5.6</code></p>\n<h2>ModuleTrainer</h2>\n<p>The <code>ModuleTrainer</code> class provides a high-level training interface which abstracts\naway the training loop while providing callbacks, constraints, initializers, regularizers,\nand more.</p>\n<p>Example:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pywick.modules</span> <span class=\"kn\">import</span> <span class=\"n\">ModuleTrainer</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pywick.initializers</span> <span class=\"kn\">import</span> <span class=\"n\">XavierUniform</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pywick.metrics</span> <span class=\"kn\">import</span> <span class=\"n\">CategoricalAccuracySingleInput</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch.nn</span> <span class=\"k\">as</span> <span class=\"nn\">nn</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch.functional</span> <span class=\"k\">as</span> <span class=\"nn\">F</span>\n\n<span class=\"c1\"># Define your model EXACTLY as normal</span>\n<span class=\"k\">class</span> <span class=\"nc\">Network</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">Network</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv1</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"n\">kernel_size</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv2</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">kernel_size</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc1</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">1600</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc2</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">max_pool2d</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv1</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">),</span> <span class=\"mi\">2</span><span class=\"p\">))</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">max_pool2d</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv2</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">),</span> <span class=\"mi\">2</span><span class=\"p\">))</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">view</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1600</span><span class=\"p\">)</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc1</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">))</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">dropout</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">training</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"p\">)</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc2</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">log_softmax</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Network</span><span class=\"p\">()</span>\n<span class=\"n\">trainer</span> <span class=\"o\">=</span> <span class=\"n\">ModuleTrainer</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">)</span>   <span class=\"c1\"># optionally supply cuda_devices as a parameter</span>\n\n<span class=\"n\">initializers</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">XavierUniform</span><span class=\"p\">(</span><span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">module_filter</span><span class=\"o\">=</span><span class=\"s1\">'fc*'</span><span class=\"p\">)]</span>\n\n<span class=\"c1\"># initialize metrics with top1 and top5 </span>\n<span class=\"n\">metrics</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">CategoricalAccuracySingleInput</span><span class=\"p\">(</span><span class=\"n\">top_k</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">),</span> <span class=\"n\">CategoricalAccuracySingleInput</span><span class=\"p\">(</span><span class=\"n\">top_k</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)]</span>\n\n<span class=\"n\">trainer</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span><span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"s1\">'cross_entropy'</span><span class=\"p\">,</span>\n                <span class=\"c1\"># callbacks=callbacks,          # define your callbacks here (e.g. model saver, LR scheduler)</span>\n                <span class=\"c1\"># regularizers=regularizers,    # define regularizers</span>\n                <span class=\"c1\"># constraints=constraints,      # define constraints</span>\n                <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"s1\">'sgd'</span><span class=\"p\">,</span>\n                <span class=\"n\">initializers</span><span class=\"o\">=</span><span class=\"n\">initializers</span><span class=\"p\">,</span>\n                <span class=\"n\">metrics</span><span class=\"o\">=</span><span class=\"n\">metrics</span><span class=\"p\">)</span>\n\n<span class=\"n\">trainer</span><span class=\"o\">.</span><span class=\"n\">fit_loader</span><span class=\"p\">(</span><span class=\"n\">train_dataset_loader</span><span class=\"p\">,</span> \n            <span class=\"n\">val_loader</span><span class=\"o\">=</span><span class=\"n\">val_dataset_loader</span><span class=\"p\">,</span>\n            <span class=\"n\">num_epoch</span><span class=\"o\">=</span><span class=\"mi\">20</span><span class=\"p\">,</span>\n            <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</pre>\n<p>You also have access to the standard evaluation and prediction functions:</p>\n<pre><span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">trainer</span><span class=\"o\">.</span><span class=\"n\">evaluate</span><span class=\"p\">(</span><span class=\"n\">x_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">)</span>\n<span class=\"n\">y_pred</span> <span class=\"o\">=</span> <span class=\"n\">trainer</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">x_train</span><span class=\"p\">)</span>\n</pre>\n<p>PyWick provides a wide range of <b>callbacks</b>, generally mimicking the interface\nfound in <code>Keras</code>:</p>\n<ul>\n<li><code>CSVLogger</code> - Logs epoch-level metrics to a CSV file</li>\n<li><a href=\"https://github.com/bckenstler/CLR\" rel=\"nofollow\"><code>CyclicLRScheduler</code></a> - Cycles through min-max learning rate</li>\n<li><code>EarlyStopping</code> - Provides ability to stop training early based on supplied criteria</li>\n<li><code>History</code> - Keeps history of metrics etc. during the learning process</li>\n<li><code>LambdaCallback</code> - Allows you to implement your own callbacks on the fly</li>\n<li><code>LRScheduler</code> - Simple learning rate scheduler based on function or supplied schedule</li>\n<li><code>ModelCheckpoint</code> - Comprehensive model saver</li>\n<li><code>ReduceLROnPlateau</code> - Reduces learning rate (LR) when a plateau has been reached</li>\n<li><code>SimpleModelCheckpoint</code> - Simple model saver</li>\n<li>Additionally, a <code>TensorboardLogger</code> is incredibly easy to implement\nvia the <a href=\"https://github.com/lanpa/tensorboardX\" rel=\"nofollow\">TensorboardX</a> (now\npart of pytorch 1.1 release!)</li>\n</ul>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pywick.callbacks</span> <span class=\"kn\">import</span> <span class=\"n\">EarlyStopping</span>\n\n<span class=\"n\">callbacks</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">EarlyStopping</span><span class=\"p\">(</span><span class=\"n\">monitor</span><span class=\"o\">=</span><span class=\"s1\">'val_loss'</span><span class=\"p\">,</span> <span class=\"n\">patience</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)]</span>\n<span class=\"n\">trainer</span><span class=\"o\">.</span><span class=\"n\">set_callbacks</span><span class=\"p\">(</span><span class=\"n\">callbacks</span><span class=\"p\">)</span>\n</pre>\n<p>PyWick also provides <b>regularizers</b>:</p>\n<ul>\n<li><code>L1Regularizer</code></li>\n<li><code>L2Regularizer</code></li>\n<li><code>L1L2Regularizer</code></li>\n</ul>\n<p>and <b>constraints</b>:</p>\n<ul>\n<li><code>UnitNorm</code></li>\n<li><code>MaxNorm</code></li>\n<li><code>NonNeg</code></li>\n</ul>\n<p>Both regularizers and constraints can be selectively applied on layers using regular expressions and the <code>module_filter</code>\nargument. Constraints can be explicit (hard) constraints applied at an arbitrary batch or\nepoch frequency, or they can be implicit (soft) constraints similar to regularizers\nwhere the the constraint deviation is added as a penalty to the total model loss.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pywick.constraints</span> <span class=\"kn\">import</span> <span class=\"n\">MaxNorm</span><span class=\"p\">,</span> <span class=\"n\">NonNeg</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pywick.regularizers</span> <span class=\"kn\">import</span> <span class=\"n\">L1Regularizer</span>\n\n<span class=\"c1\"># hard constraint applied every 5 batches</span>\n<span class=\"n\">hard_constraint</span> <span class=\"o\">=</span> <span class=\"n\">MaxNorm</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"o\">=</span><span class=\"mf\">2.</span><span class=\"p\">,</span> <span class=\"n\">frequency</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">unit</span><span class=\"o\">=</span><span class=\"s1\">'batch'</span><span class=\"p\">,</span> <span class=\"n\">module_filter</span><span class=\"o\">=</span><span class=\"s1\">'*fc*'</span><span class=\"p\">)</span>\n<span class=\"c1\"># implicit constraint added as a penalty term to model loss</span>\n<span class=\"n\">soft_constraint</span> <span class=\"o\">=</span> <span class=\"n\">NonNeg</span><span class=\"p\">(</span><span class=\"n\">lagrangian</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">scale</span><span class=\"o\">=</span><span class=\"mf\">1e-3</span><span class=\"p\">,</span> <span class=\"n\">module_filter</span><span class=\"o\">=</span><span class=\"s1\">'*fc*'</span><span class=\"p\">)</span>\n<span class=\"n\">constraints</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">hard_constraint</span><span class=\"p\">,</span> <span class=\"n\">soft_constraint</span><span class=\"p\">]</span>\n<span class=\"n\">trainer</span><span class=\"o\">.</span><span class=\"n\">set_constraints</span><span class=\"p\">(</span><span class=\"n\">constraints</span><span class=\"p\">)</span>\n\n<span class=\"n\">regularizers</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">L1Regularizer</span><span class=\"p\">(</span><span class=\"n\">scale</span><span class=\"o\">=</span><span class=\"mf\">1e-4</span><span class=\"p\">,</span> <span class=\"n\">module_filter</span><span class=\"o\">=</span><span class=\"s1\">'*conv*'</span><span class=\"p\">)]</span>\n<span class=\"n\">trainer</span><span class=\"o\">.</span><span class=\"n\">set_regularizers</span><span class=\"p\">(</span><span class=\"n\">regularizers</span><span class=\"p\">)</span>\n</pre>\n<p>You can also fit directly on a <code>torch.utils.data.DataLoader</code> and can have\na validation set as well :</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pywick</span> <span class=\"kn\">import</span> <span class=\"n\">TensorDataset</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch.utils.data</span> <span class=\"kn\">import</span> <span class=\"n\">DataLoader</span>\n\n<span class=\"n\">train_dataset</span> <span class=\"o\">=</span> <span class=\"n\">TensorDataset</span><span class=\"p\">(</span><span class=\"n\">x_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">)</span>\n<span class=\"n\">train_loader</span> <span class=\"o\">=</span> <span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"n\">train_dataset</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">32</span><span class=\"p\">)</span>\n\n<span class=\"n\">val_dataset</span> <span class=\"o\">=</span> <span class=\"n\">TensorDataset</span><span class=\"p\">(</span><span class=\"n\">x_val</span><span class=\"p\">,</span> <span class=\"n\">y_val</span><span class=\"p\">)</span>\n<span class=\"n\">val_loader</span> <span class=\"o\">=</span> <span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"n\">val_dataset</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">32</span><span class=\"p\">)</span>\n\n<span class=\"n\">trainer</span><span class=\"o\">.</span><span class=\"n\">fit_loader</span><span class=\"p\">(</span><span class=\"n\">loader</span><span class=\"p\">,</span> <span class=\"n\">val_loader</span><span class=\"o\">=</span><span class=\"n\">val_loader</span><span class=\"p\">,</span> <span class=\"n\">num_epoch</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">)</span>\n</pre>\n<h2>Extensive Library of Image Classification Models (most are pretrained!)</h2>\n<ul>\n<li>All standard models from Pytorch:\n<ul>\n<li><a href=\"https://arxiv.org/abs/1608.06993\" rel=\"nofollow\"><strong>Densenet</strong></a></li>\n<li><a href=\"https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.pdf\" rel=\"nofollow\"><strong>Inception v3</strong></a></li>\n<li><a href=\"https://arxiv.org/abs/1801.04381\" rel=\"nofollow\"><strong>MobileNet v2</strong></a></li>\n<li><a href=\"https://arxiv.org/abs/1512.03385\" rel=\"nofollow\"><strong>ResNet</strong></a></li>\n<li><a href=\"https://arxiv.org/abs/1807.11164\" rel=\"nofollow\"><strong>ShuffleNet v2</strong></a></li>\n<li><a href=\"https://arxiv.org/abs/1602.07360\" rel=\"nofollow\"><strong>SqueezeNet</strong></a></li>\n<li><a href=\"https://arxiv.org/abs/1409.1556\" rel=\"nofollow\"><strong>VGG</strong></a></li>\n</ul>\n</li>\n<li><a href=\"https://arxiv.org/pdf/1502.03167.pdf\" rel=\"nofollow\"><strong>BatchNorm Inception</strong></a></li>\n<li><a href=\"https://arxiv.org/abs/1707.01629\" rel=\"nofollow\"><strong>Dual Path Networks</strong></a></li>\n<li><a href=\"https://arxiv.org/abs/1905.11946\" rel=\"nofollow\"><strong>EfficientNet variants b0-b8</strong></a></li>\n<li><a href=\"https://github.com/facebook/fb.resnet.torch\" rel=\"nofollow\"><strong>FBResnet</strong></a></li>\n<li><a href=\"https://arxiv.org/abs/1812.03443\" rel=\"nofollow\"><strong>FBNet-C</strong></a></li>\n<li><a href=\"http://arxiv.org/abs/1602.07261\" rel=\"nofollow\"><strong>Inception v4</strong></a></li>\n<li><a href=\"https://arxiv.org/abs/1602.07261\" rel=\"nofollow\"><strong>InceptionResnet v2</strong></a></li>\n<li><a href=\"https://arxiv.org/abs/1907.09595\" rel=\"nofollow\"><strong>Mixnet L/M/S</strong></a></li>\n<li><a href=\"https://arxiv.org/abs/1807.11626\" rel=\"nofollow\"><strong>MnasNet</strong></a></li>\n<li><a href=\"https://arxiv.org/abs/1905.02244\" rel=\"nofollow\"><strong>MobileNet V3</strong></a></li>\n<li><a href=\"https://arxiv.org/abs/1707.07012\" rel=\"nofollow\"><strong>NasNet and NasNet Mobile</strong></a></li>\n<li><a href=\"https://arxiv.org/abs/1712.00559\" rel=\"nofollow\"><strong>PNASNet</strong></a></li>\n<li><a href=\"https://arxiv.org/abs/1611.05725\" rel=\"nofollow\"><strong>Polynet</strong></a></li>\n<li><a href=\"https://arxiv.org/abs/1610.02915\" rel=\"nofollow\"><strong>Pyramid Resnet</strong></a></li>\n<li><strong>Resnet + Swish</strong></li>\n<li><a href=\"https://arxiv.org/abs/1611.05431\" rel=\"nofollow\"><strong>ResNext</strong></a></li>\n<li><a href=\"https://arxiv.org/pdf/1709.01507.pdf\" rel=\"nofollow\"><strong>SE Net</strong></a></li>\n<li><strong>SE Inception</strong></li>\n<li><a href=\"https://arxiv.org/abs/1904.02877\" rel=\"nofollow\"><strong>Single-Pass NAS Net</strong></a></li>\n<li><a href=\"https://arxiv.org/abs/1605.07146\" rel=\"nofollow\"><strong>Wide Resnet</strong></a></li>\n<li><a href=\"https://arxiv.org/pdf/1610.02357.pdf\" rel=\"nofollow\"><strong>XCeption</strong></a></li>\n</ul>\n<h2>Image Segmentation Models</h2>\n<ul>\n<li><strong>BiSeNet</strong> (<a href=\"https://arxiv.org/abs/1808.00897\" rel=\"nofollow\">Bilateral Segmentation Network for Real-time Semantic Segmentation</a>)</li>\n<li><strong>DANet</strong> (<a href=\"https://arxiv.org/abs/1809.02983\" rel=\"nofollow\">Dual Attention Network for Scene Segmentation</a>)</li>\n<li><strong>Deeplab v2</strong> (<a href=\"https://arxiv.org/abs/1606.00915\" rel=\"nofollow\">DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs</a>)</li>\n<li><strong>Deeplab v3</strong> (<a href=\"https://arxiv.org/abs/1706.05587\" rel=\"nofollow\">Rethinking Atrous Convolution for Semantic Image Segmentation</a>)</li>\n<li><strong>DenseASPP</strong> (<a href=\"http://openaccess.thecvf.com/content_cvpr_2018/papers/Yang_DenseASPP_for_Semantic_CVPR_2018_paper.pdf\" rel=\"nofollow\">DenseASPP for Semantic Segmentation in Street Scenes</a>)</li>\n<li><strong>DRNNet</strong> (<a href=\"http://openaccess.thecvf.com/content_cvpr_2017/papers/Yu_Dilated_Residual_Networks_CVPR_2017_paper.pdf\" rel=\"nofollow\">Dilated Residual Networks</a>)</li>\n<li><strong>DUC, HDC</strong> (<a href=\"https://arxiv.org/abs/1702.08502\" rel=\"nofollow\">understanding convolution for semantic segmentation</a>)</li>\n<li><strong>DUNet</strong> (<a href=\"https://arxiv.org/abs/1903.02120\" rel=\"nofollow\">Decoders Matter for Semantic Segmentation</a>)</li>\n<li><strong>ENet</strong> (<a href=\"https://arxiv.org/abs/1606.02147\" rel=\"nofollow\">ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation</a>)</li>\n<li><strong>Vanilla FCN:</strong> FCN32, FCN16, FCN8, in the versions of VGG, ResNet\nand OptDenseNet respectively (<a href=\"http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf\" rel=\"nofollow\">Fully convolutional networks for semantic segmentation</a>)</li>\n<li><strong>FRRN</strong> (<a href=\"https://arxiv.org/abs/1611.08323\" rel=\"nofollow\">Full Resolution Residual Networks for Semantic Segmentation in Street Scenes</a>)</li>\n<li><strong>FusionNet</strong> (<a href=\"https://github.com/NySunShine/fusion-net\" rel=\"nofollow\">FusionNet in Tensorflow by Hyungjoo Andrew Cho</a>)</li>\n<li><strong>GCN</strong> (<a href=\"https://arxiv.org/pdf/1703.02719\" rel=\"nofollow\">Large Kernel Matters</a>)</li>\n<li><strong>LinkNet</strong> (<a href=\"https://codeac29.github.io/projects/linknet/\" rel=\"nofollow\">Link-Net</a>)</li>\n<li><strong>OCNet</strong> (<a href=\"https://arxiv.org/abs/1809.00916\" rel=\"nofollow\">Object Context Network for Scene Parsing</a>)</li>\n<li><strong>PSPNet</strong> (<a href=\"https://arxiv.org/abs/1612.01105\" rel=\"nofollow\">Pyramid scene parsing network</a>)</li>\n<li><strong>RefineNet</strong> (<a href=\"https://arxiv.org/abs/1611.06612\" rel=\"nofollow\">RefineNet</a>)</li>\n<li><strong>SegNet</strong> (<a href=\"https://arxiv.org/pdf/1511.00561\" rel=\"nofollow\">Segnet: A deep convolutional encoder-decoder architecture for image segmentation</a>)</li>\n<li><strong>Tiramisu</strong> (<a href=\"https://arxiv.org/abs/1611.09326\" rel=\"nofollow\">The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic Segmentation</a>)</li>\n<li><strong>U-Net</strong> (<a href=\"https://arxiv.org/abs/1505.04597\" rel=\"nofollow\">U-net: Convolutional networks for biomedical image segmentation</a>)</li>\n<li>Additional variations of many of the above</li>\n</ul>\n<h6>To load one of these models:</h6>\n<p><a href=\"https://pywick.readthedocs.io/en/latest/api/pywick.models.html\" rel=\"nofollow\">Read the docs</a>\nfor useful details! Then dive in:</p>\n<pre><span class=\"c1\"># use the `get_model` utility</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pywick.models.model_utils</span> <span class=\"kn\">import</span> <span class=\"n\">get_model</span><span class=\"p\">,</span> <span class=\"n\">ModelType</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">get_model</span><span class=\"p\">(</span><span class=\"n\">model_type</span><span class=\"o\">=</span><span class=\"n\">ModelType</span><span class=\"o\">.</span><span class=\"n\">CLASSIFICATION</span><span class=\"p\">,</span> <span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'resnet18'</span><span class=\"p\">,</span> <span class=\"n\">num_classes</span><span class=\"o\">=</span><span class=\"mi\">1000</span><span class=\"p\">,</span> <span class=\"n\">pretrained</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<p>For a complete list of models (including many experimental ones) you can call the <code>get_supported_models</code> method e.g.\n<code>pywick.models.model_utils.get_supported_models(ModelType.SEGMENTATION)</code></p>\n<h2>Data Augmentation and Datasets</h2>\n<p>The PyWick package provides wide variety of good data augmentation and transformation\ntools which can be applied during data loading. The package also provides the flexible\n<code>TensorDataset</code>, <code>FolderDataset</code> and <code>MultiFolderDataset</code> classes to handle most dataset needs.</p>\n<h3>Torch Transforms</h3>\n<h5>These transforms work directly on torch tensors</h5>\n<ul>\n<li><code>AddChannel</code></li>\n<li><code>ChannelsFirst</code></li>\n<li><code>ChannelsLast</code></li>\n<li><code>Compose</code></li>\n<li><code>ExpandAxis</code></li>\n<li><code>Pad</code></li>\n<li><code>PadNumpy</code></li>\n<li><code>RandomChoiceCompose</code></li>\n<li><code>RandomCrop</code></li>\n<li><code>RandomFlip</code></li>\n<li><code>RandomOrder</code></li>\n<li><code>RangeNormalize</code></li>\n<li><code>Slice2D</code></li>\n<li><code>SpecialCrop</code></li>\n<li><code>StdNormalize</code></li>\n<li><code>ToFile</code></li>\n<li><code>ToNumpyType</code></li>\n<li><code>ToTensor</code></li>\n<li><code>Transpose</code></li>\n<li><code>TypeCast</code></li>\n</ul>\n<h5>Additionally, we provide image-specific manipulations directly on tensors:</h5>\n<ul>\n<li><code>Brightness</code></li>\n<li><code>Contrast</code></li>\n<li><code>Gamma</code></li>\n<li><code>Grayscale</code></li>\n<li><code>RandomBrightness</code></li>\n<li><code>RandomChoiceBrightness</code></li>\n<li><code>RandomChoiceContrast</code></li>\n<li><code>RandomChoiceGamma</code></li>\n<li><code>RandomChoiceSaturation</code></li>\n<li><code>RandomContrast</code></li>\n<li><code>RandomGamma</code></li>\n<li><code>RandomGrayscale</code></li>\n<li><code>RandomSaturation</code></li>\n<li><code>Saturation</code></li>\n</ul>\n<h5>Affine Transforms (perform affine or affine-like transforms on torch tensors)</h5>\n<ul>\n<li><code>RandomAffine</code></li>\n<li><code>RandomChoiceRotate</code></li>\n<li><code>RandomChoiceShear</code></li>\n<li><code>RandomChoiceTranslate</code></li>\n<li><code>RandomChoiceZoom</code></li>\n<li><code>RandomRotate</code></li>\n<li><code>RandomShear</code></li>\n<li><code>RandomSquareZoom</code></li>\n<li><code>RandomTranslate</code></li>\n<li><code>RandomZoom</code></li>\n<li><code>Rotate</code></li>\n<li><code>Shear</code></li>\n<li><code>Translate</code></li>\n<li><code>Zoom</code></li>\n</ul>\n<p>We also provide a class for stringing multiple affine transformations together so that only one interpolation takes place:</p>\n<ul>\n<li><code>Affine</code></li>\n<li><code>AffineCompose</code></li>\n</ul>\n<h5>Blur and Scramble transforms (for tensors)</h5>\n<ul>\n<li><code>Blur</code></li>\n<li><code>RandomChoiceBlur</code></li>\n<li><code>RandomChoiceScramble</code></li>\n<li><code>Scramble</code></li>\n</ul>\n<h3>Datasets and Sampling</h3>\n<p>We provide the following datasets which provide general structure and iterators for sampling from and using transforms on in-memory or out-of-memory data. In particular,\nthe <a href=\"pywick/datasets/FolderDataset.py\" rel=\"nofollow\">FolderDataset</a> has been designed to fit most of your dataset needs. It has extensive options for data filtering and manipulation.\nIt supports loading images for classification, segmentation and even arbitrary source/target mapping. Take a good look at its documentation for more info.</p>\n<ul>\n<li><code>ClonedDataset</code></li>\n<li><code>CSVDataset</code></li>\n<li><code>FolderDataset</code></li>\n<li><code>MultiFolderDataset</code></li>\n<li><code>TensorDataset</code></li>\n<li><code>tnt.BatchDataset</code></li>\n<li><code>tnt.ConcatDataset</code></li>\n<li><code>tnt.ListDataset</code></li>\n<li><code>tnt.MultiPartitionDataset</code></li>\n<li><code>tnt.ResampleDataset</code></li>\n<li><code>tnt.ShuffleDataset</code></li>\n<li><code>tnt.TensorDataset</code></li>\n<li><code>tnt.TransformDataset</code></li>\n</ul>\n<h3>Imbalanced Datasets</h3>\n<p>In many scenarios it is important to ensure that your traing set is properly balanced,\nhowever, it may not be practical in real life to obtain such a perfect dataset. In these cases\nyou can use the <code>ImbalancedDatasetSampler</code> as a drop-in replacement for the basic sampler provided\nby the DataLoader. More information can be found <a href=\"https://github.com/ufoym/imbalanced-dataset-sampler\" rel=\"nofollow\">here</a></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pywick.samplers</span> <span class=\"kn\">import</span> <span class=\"n\">ImbalancedDatasetSampler</span>\n\n<span class=\"n\">train_loader</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"n\">train_dataset</span><span class=\"p\">,</span> \n    <span class=\"n\">sampler</span><span class=\"o\">=</span><span class=\"n\">ImbalancedDatasetSampler</span><span class=\"p\">(</span><span class=\"n\">train_dataset</span><span class=\"p\">),</span>\n    <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"n\">args</span><span class=\"o\">.</span><span class=\"n\">batch_size</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n</pre>\n<h2>Utility Functions</h2>\n<p>PyWick provides a few utility functions not commonly found:</p>\n<h3>Tensor Functions</h3>\n<ul>\n<li><code>th_iterproduct</code> (mimics itertools.product)</li>\n<li><code>th_gather_nd</code> (N-dimensional version of torch.gather)</li>\n<li><code>th_random_choice</code> (mimics np.random.choice)</li>\n<li><code>th_pearsonr</code> (mimics scipy.stats.pearsonr)</li>\n<li><code>th_corrcoef</code> (mimics np.corrcoef)</li>\n<li><code>th_affine2d</code> and <code>th_affine3d</code> (affine transforms on torch.Tensors)</li>\n</ul>\n<h2>Acknowledgements and References</h2>\n<p>We stand on the shoulders of (github?) giants and couldn't have done\nthis without the rich github ecosystem and community. This framework is\nbased in part on the excellent\n<a href=\"https://github.com/ncullen93/torchsample\" rel=\"nofollow\">Torchsample</a> framework\noriginally published by @ncullen93. Additionally, many models have been\ngently borrowed/modified from @Cadene pretrained models\n<a href=\"https://github.com/Cadene/pretrained-models.pytorch\" rel=\"nofollow\">repo</a> as well as @Tramac segmentation <a href=\"https://github.com/Tramac/awesome-semantic-segmentation-pytorch\" rel=\"nofollow\">repo</a>.</p>\n<h5>Thank you to the following people and the projects they maintain:</h5>\n<ul>\n<li>@ncullen93</li>\n<li>@cadene</li>\n<li>@deallynomore</li>\n<li>@recastrodiaz</li>\n<li>@zijundeng</li>\n<li>@Tramac</li>\n<li>And many others! (attributions listed in the codebase as they occur)</li>\n</ul>\n<h5>Thank you to the following projects from which we gently borrowed code and models</h5>\n<ul>\n<li><a href=\"https://github.com/pytorch/tnt\" rel=\"nofollow\">PyTorchNet</a></li>\n<li><a href=\"https://github.com/Cadene/pretrained-models.pytorch\" rel=\"nofollow\">pretrained-models.pytorch</a></li>\n<li><a href=\"https://github.com/doiken23/DeepLab_pytorch\" rel=\"nofollow\">DeepLab_pytorch</a></li>\n<li><a href=\"https://github.com/zijundeng/pytorch-semantic-segmentation\" rel=\"nofollow\">Pytorch for Semantic Segmentation</a></li>\n<li><a href=\"https://github.com/saeedizadi/binseg_pytoch\" rel=\"nofollow\">Binseg Pytorch</a></li>\n<li><a href=\"https://github.com/Tramac/awesome-semantic-segmentation-pytorch\" rel=\"nofollow\">awesome-semantic-segmentation-pytorch</a></li>\n<li>And many others! (attributions listed in the codebase as they occur)</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th><em>Thangs are broken matey! Arrr!!!</em></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>We're working on this project as time permits so you might discover bugs here and there. Feel free to report them, or better yet, to submit a pull request!</td>\n</tr></tbody></table>\n\n          </div>"}, "last_serial": 6490542, "releases": {"0.5.3": [{"comment_text": "", "digests": {"md5": "bfc8174db314b3383dfd340cb75fe392", "sha256": "22cc48a25355d54a38b0b3ef3c775c22803905762209e5f67b7ba46be1838b33"}, "downloads": -1, "filename": "pywick-0.5.3.tar.gz", "has_sig": false, "md5_digest": "bfc8174db314b3383dfd340cb75fe392", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 236313, "upload_time": "2019-05-08T04:58:09", "upload_time_iso_8601": "2019-05-08T04:58:09.984177Z", "url": "https://files.pythonhosted.org/packages/9e/f2/978ee73a54b08ead1f22700af8aa0567ba95c2c81315f8a3f2b0298de7e5/pywick-0.5.3.tar.gz", "yanked": false}], "0.5.5": [{"comment_text": "", "digests": {"md5": "e54cc3ebfee207d9536e6fec2a6b148a", "sha256": "5caa5c0b713b58ca507d46ad7e89d0fff9a8cf09c11fbf3dcb5b624a0d7f132d"}, "downloads": -1, "filename": "pywick-0.5.5.tar.gz", "has_sig": false, "md5_digest": "e54cc3ebfee207d9536e6fec2a6b148a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 277727, "upload_time": "2020-01-15T23:05:10", "upload_time_iso_8601": "2020-01-15T23:05:10.490384Z", "url": "https://files.pythonhosted.org/packages/57/44/a22af85461cd998355d515a68e146cc002b850492268705c92ef2a4b8259/pywick-0.5.5.tar.gz", "yanked": false}], "0.5.6": [{"comment_text": "", "digests": {"md5": "3d9ac89319a1ca070257930dec2baec4", "sha256": "f28cf2e832d22575fb4ad679fe77a3aef9085aa250d70e7108b519053aa5a0de"}, "downloads": -1, "filename": "pywick-0.5.6-py3-none-any.whl", "has_sig": false, "md5_digest": "3d9ac89319a1ca070257930dec2baec4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 403663, "upload_time": "2020-01-20T22:14:21", "upload_time_iso_8601": "2020-01-20T22:14:21.570914Z", "url": "https://files.pythonhosted.org/packages/44/70/ac4f95ba38de4a4926f411e5a840011084743dc58e899c15ee2993363b29/pywick-0.5.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "712bbed4be1f2720404837bc2640d8ef", "sha256": "575f5423a4384877881354ac975b6f37162dcceb89ffbeb0a8041fedcadeabab"}, "downloads": -1, "filename": "pywick-0.5.6.tar.gz", "has_sig": false, "md5_digest": "712bbed4be1f2720404837bc2640d8ef", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 285608, "upload_time": "2020-01-20T22:14:23", "upload_time_iso_8601": "2020-01-20T22:14:23.603656Z", "url": "https://files.pythonhosted.org/packages/d6/13/e3d5473da8fbc64234bda8dbba23e79795dba7163bc4a8840921a0449eb7/pywick-0.5.6.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "3d9ac89319a1ca070257930dec2baec4", "sha256": "f28cf2e832d22575fb4ad679fe77a3aef9085aa250d70e7108b519053aa5a0de"}, "downloads": -1, "filename": "pywick-0.5.6-py3-none-any.whl", "has_sig": false, "md5_digest": "3d9ac89319a1ca070257930dec2baec4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 403663, "upload_time": "2020-01-20T22:14:21", "upload_time_iso_8601": "2020-01-20T22:14:21.570914Z", "url": "https://files.pythonhosted.org/packages/44/70/ac4f95ba38de4a4926f411e5a840011084743dc58e899c15ee2993363b29/pywick-0.5.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "712bbed4be1f2720404837bc2640d8ef", "sha256": "575f5423a4384877881354ac975b6f37162dcceb89ffbeb0a8041fedcadeabab"}, "downloads": -1, "filename": "pywick-0.5.6.tar.gz", "has_sig": false, "md5_digest": "712bbed4be1f2720404837bc2640d8ef", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 285608, "upload_time": "2020-01-20T22:14:23", "upload_time_iso_8601": "2020-01-20T22:14:23.603656Z", "url": "https://files.pythonhosted.org/packages/d6/13/e3d5473da8fbc64234bda8dbba23e79795dba7163bc4a8840921a0449eb7/pywick-0.5.6.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:11:22 2020"}