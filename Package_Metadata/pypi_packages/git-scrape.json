{"info": {"author": "Wayne Werner", "author_email": "wayne@waynewerner.com", "bugtrack_url": null, "classifiers": [], "description": "Git Scraper (this name is rubbish)\n==================================\n\nThe goal of this project is to be able to scrape issues from GitHub to learn\ninteresting things about them. In particular, things like lead time,\nthroughput, cycle time, and capacity. Possibly also bottlenecks? Anyway, here's\na description of what these things mean.\n\n\nLead Time\n=========\n\nThis is the time between when an issue comes in and the issue is closed (if\npossible, the associated PR is merged). Technically the lead time would be when\nthe next release is actually made on the project, but in lieu of that... when\nthe issue is actually closed is close enough.\n\n\nThroughput\n==========\n\nThis is the number of issues that can be closed within a certain time frame.\nFor instance, we'll figure it out for the last 1 month, 6 months, 12 months,\nand all time. Issues with a 'duplicate' label will be excluded from this\nfigure.\n\n\nCycle Time\n==========\n\nThis is basically the Lead Time in our case.\n\n\nCapacity\n========\n\nGiven a unit of time, how many issues can we expect to close? We can look at\nthis as a function of issues across all time, or only issues opened and/or\nclosed within that time period.\n\nWe'll automatically give it to you for the last 1, 6, 12 months, and all time.\n\n\n---\n\n\nQuickstart\n==========\n\nCache the issues (this may take a while):\n\n    git-scrape cache\n\n<!-- might not be accurate to say we'll saturate... -->\nGo make a sammich or a cup of beverage. It may be a while. We'll pretty much\nsaturate your network connection as much as possible. But it'll be a while.\n\n    git-scrape report\n\nThis will print out a report of the above. Maybe we'll also have\n\n    git-scrape report --start=<date> --end=<date>\n\nWhere both start and end are inclusive. :shrug: But not positive about that one\nyet. We'll see how much we get done.\n\n\n---\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/waynew/upgraded-octo-umbrella", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "git-scrape", "package_url": "https://pypi.org/project/git-scrape/", "platform": "", "project_url": "https://pypi.org/project/git-scrape/", "project_urls": {"Homepage": "https://github.com/waynew/upgraded-octo-umbrella"}, "release_url": "https://pypi.org/project/git-scrape/2020.1.31.1/", "requires_dist": ["quiz", "wheel ; extra == 'build'", "pytest ; extra == 'test'"], "requires_python": "", "summary": "", "version": "2020.1.31.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Git Scraper (this name is rubbish)</h1>\n<p>The goal of this project is to be able to scrape issues from GitHub to learn\ninteresting things about them. In particular, things like lead time,\nthroughput, cycle time, and capacity. Possibly also bottlenecks? Anyway, here's\na description of what these things mean.</p>\n<h1>Lead Time</h1>\n<p>This is the time between when an issue comes in and the issue is closed (if\npossible, the associated PR is merged). Technically the lead time would be when\nthe next release is actually made on the project, but in lieu of that... when\nthe issue is actually closed is close enough.</p>\n<h1>Throughput</h1>\n<p>This is the number of issues that can be closed within a certain time frame.\nFor instance, we'll figure it out for the last 1 month, 6 months, 12 months,\nand all time. Issues with a 'duplicate' label will be excluded from this\nfigure.</p>\n<h1>Cycle Time</h1>\n<p>This is basically the Lead Time in our case.</p>\n<h1>Capacity</h1>\n<p>Given a unit of time, how many issues can we expect to close? We can look at\nthis as a function of issues across all time, or only issues opened and/or\nclosed within that time period.</p>\n<p>We'll automatically give it to you for the last 1, 6, 12 months, and all time.</p>\n<hr>\n<h1>Quickstart</h1>\n<p>Cache the issues (this may take a while):</p>\n<pre><code>git-scrape cache\n</code></pre>\n\n<p>Go make a sammich or a cup of beverage. It may be a while. We'll pretty much\nsaturate your network connection as much as possible. But it'll be a while.</p>\n<pre><code>git-scrape report\n</code></pre>\n<p>This will print out a report of the above. Maybe we'll also have</p>\n<pre><code>git-scrape report --start=&lt;date&gt; --end=&lt;date&gt;\n</code></pre>\n<p>Where both start and end are inclusive. :shrug: But not positive about that one\nyet. We'll see how much we get done.</p>\n<hr>\n\n          </div>"}, "last_serial": 6552410, "releases": {"2020.1.31": [{"comment_text": "", "digests": {"md5": "c04922a5715c647e52fe4aaefbce93be", "sha256": "f251c9185f2d1e1c507900eb9a63f002e1eab35fd858c3ebcc41a9acb373694d"}, "downloads": -1, "filename": "git_scrape-2020.1.31-py3-none-any.whl", "has_sig": false, "md5_digest": "c04922a5715c647e52fe4aaefbce93be", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4333, "upload_time": "2020-01-31T23:33:27", "upload_time_iso_8601": "2020-01-31T23:33:27.529673Z", "url": "https://files.pythonhosted.org/packages/a5/e8/cf14e14ca0225ffd2a3e64be67e5bc827df3de9ba02cf666dff6fe994015/git_scrape-2020.1.31-py3-none-any.whl", "yanked": false}], "2020.1.31.1": [{"comment_text": "", "digests": {"md5": "fc97eced7fdd490d313203ad7c78eef5", "sha256": "201bbb89a75500e809a7f06a15761e4e50b067bd1dcee069b96a285c1f86442a"}, "downloads": -1, "filename": "git_scrape-2020.1.31.1-py3-none-any.whl", "has_sig": false, "md5_digest": "fc97eced7fdd490d313203ad7c78eef5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4329, "upload_time": "2020-01-31T23:51:01", "upload_time_iso_8601": "2020-01-31T23:51:01.871962Z", "url": "https://files.pythonhosted.org/packages/80/9e/e41442d2791153eeda00cb65aff60a5a2f88e91f748a6779171817a100d4/git_scrape-2020.1.31.1-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "fc97eced7fdd490d313203ad7c78eef5", "sha256": "201bbb89a75500e809a7f06a15761e4e50b067bd1dcee069b96a285c1f86442a"}, "downloads": -1, "filename": "git_scrape-2020.1.31.1-py3-none-any.whl", "has_sig": false, "md5_digest": "fc97eced7fdd490d313203ad7c78eef5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4329, "upload_time": "2020-01-31T23:51:01", "upload_time_iso_8601": "2020-01-31T23:51:01.871962Z", "url": "https://files.pythonhosted.org/packages/80/9e/e41442d2791153eeda00cb65aff60a5a2f88e91f748a6779171817a100d4/git_scrape-2020.1.31.1-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 00:56:47 2020"}