{"info": {"author": "Quentin Caudron", "author_email": "quentincaudron@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3", "Topic :: Software Development :: Build Tools"], "description": "# ShipIt\n\nEasily deploy your machine learning models to an API in the cloud.\n\n## Quickstart\n\n1. Install and configure awscli\n1. Install terraform\n1. `pip install shipit`\n1. `shipit init`\n1. Edit the newly created `shipit.yml` See [configuration](#configuration)\n1. `shipit deploy`\n\nYou will get an output that tells you the version and what the endpoint is.\n\n```\nProject             : demo\nEndpoint            : production-alb-demo-553835794.us-west-2.elb.amazonaws.com\nVersion             : 2\n```\n\n## How it Works\nShipit wraps tools like docker, awscli, and terraform to make it easy to deploy production ready web APIs for your machine learning models. First a docker image is built based on the configurat\n\n\n## Running Locally\n\nYou can spin up your container locally like this:\n\n```\nshipit build -t yourtagname\ndocker run -p 5000:80 -it yourtagname\n```\n\nYou now have your models being served from a web API. Visit `localhost:5000/` to see the list of available models.\n\n## Commands\n\nshipit deploy -t [yourtag] --verbosity 1\n: Build and deploy the shipit project. All arguments are optional.\n\nshipit destroy\n: Use terraform to destroy \n\nshipit build -t [yourtag] --verbosity 1\n: Build the docker image and tag it. All arguments are optional.\n\n## Usage\n\nGetting predictions requires sending a `POST` to the relevant model's predict endpoint:\n\n```\nhttp://[your-endpoint]/predict/[model-name]\n```\n\nThe payload should be a JSON serialized array or 2d array (for multiple predictions) to the provided model's endpoint. For example, a model that takes three features would look like this:\n\n```\n[33, 4, 10]\n```\n\nIn the case of doing multiple predictions, pass that in as a 2d array.\n\n```\n[\n    [33, 4, 10],\n    [32, 1, 5]\n]\n```\n\nHere's an example using cURL.\n\n```\ncurl -d '[[5, 1, 6], [1, 2, 3]]' -H \"Content-Type: application/json\" -X POST http://[your-endpoint]:5000/predict/[modelname]\n```\n\nThe response will always be a 2d array, so if you send one data point expect a list back with only one row.\n\n## Configuration <a name=\"configuration\"></a>\n\nThe config file `shipit.yml` for your project is broken down into two major sections. \n\n### meta\n\nproject_name\n:  A unique project name, used to namespace the resources created for your project.\n\nrequirements\n:  Path to a requirements.txt file to install dependencies for your models\n\nprovider\n:  For now this is always assumed to be `aws`\n\naws_profile\n:  Name of the profile from your awscli credentials. \n\naws_region\n:  Which aws region to launch your service in.\n\n### models\n\nThis section can contain one or more models you want to include in this API service. See `example/shipit.yml` as a reference.\n\npath\n:  The relative path of the pickled model file e.g. `models/my_model.pkl`\n\nvariety\n:  One of `[\"sklearn\", \"keras\"]`. Eventually we will add more model types.\n\npreprocess\n:  (optional) A python import dot path to a preprocess function. This function can perform manipulations of the API input before sending it to your model.\n\npostprocess\n:  (optional) A python import dot path to a postprocess function. This function can perform manipulations of the model's prediction output before returning it to the user.\n\n\n## Formatting model data\n\nFirst, ensure your features is a `(n_samples, n_features)`-shaped numpy array ( in standard `sklearn` form ). Turn this into a list ( so that we can JSON-serialise it ). \n\n## Saving models\n\nModels from `scikit-learn` should be saved with `joblib`. Models from `keras` should be saved with `model.save()`. See `example/save_model_example.py`.\n\n## To Do\n- Deploy to Private VPN\n- Route53 / private / public DNS\n- Build an \"export\" feature for customization of Docker / terraform setup.\n- Support XGBoost models\n- Figure out why sklearn.linear_model.LinearRegression can't be pickled\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://github.com/qCaudron/shipit/", "keywords": "machine learning scikit keras docker", "license": "", "maintainer": "", "maintainer_email": "", "name": "shipit-ml", "package_url": "https://pypi.org/project/shipit-ml/", "platform": "", "project_url": "https://pypi.org/project/shipit-ml/", "project_urls": {"Homepage": "http://github.com/qCaudron/shipit/", "Source": "http://github.com/qCaudron/shipit/"}, "release_url": "https://pypi.org/project/shipit-ml/0.6.0/", "requires_dist": ["docker (>=3)", "numpy (>=1)", "awscli", "pyyaml (<3.15,>=3.13)", "delegator.py (>=0.1.1)"], "requires_python": "!=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, <4", "summary": "Package machine learning models for the web", "version": "0.6.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>ShipIt</h1>\n<p>Easily deploy your machine learning models to an API in the cloud.</p>\n<h2>Quickstart</h2>\n<ol>\n<li>Install and configure awscli</li>\n<li>Install terraform</li>\n<li><code>pip install shipit</code></li>\n<li><code>shipit init</code></li>\n<li>Edit the newly created <code>shipit.yml</code> See <a href=\"#configuration\" rel=\"nofollow\">configuration</a></li>\n<li><code>shipit deploy</code></li>\n</ol>\n<p>You will get an output that tells you the version and what the endpoint is.</p>\n<pre><code>Project             : demo\nEndpoint            : production-alb-demo-553835794.us-west-2.elb.amazonaws.com\nVersion             : 2\n</code></pre>\n<h2>How it Works</h2>\n<p>Shipit wraps tools like docker, awscli, and terraform to make it easy to deploy production ready web APIs for your machine learning models. First a docker image is built based on the configurat</p>\n<h2>Running Locally</h2>\n<p>You can spin up your container locally like this:</p>\n<pre><code>shipit build -t yourtagname\ndocker run -p 5000:80 -it yourtagname\n</code></pre>\n<p>You now have your models being served from a web API. Visit <code>localhost:5000/</code> to see the list of available models.</p>\n<h2>Commands</h2>\n<p>shipit deploy -t [yourtag] --verbosity 1\n: Build and deploy the shipit project. All arguments are optional.</p>\n<p>shipit destroy\n: Use terraform to destroy</p>\n<p>shipit build -t [yourtag] --verbosity 1\n: Build the docker image and tag it. All arguments are optional.</p>\n<h2>Usage</h2>\n<p>Getting predictions requires sending a <code>POST</code> to the relevant model's predict endpoint:</p>\n<pre><code>http://[your-endpoint]/predict/[model-name]\n</code></pre>\n<p>The payload should be a JSON serialized array or 2d array (for multiple predictions) to the provided model's endpoint. For example, a model that takes three features would look like this:</p>\n<pre><code>[33, 4, 10]\n</code></pre>\n<p>In the case of doing multiple predictions, pass that in as a 2d array.</p>\n<pre><code>[\n    [33, 4, 10],\n    [32, 1, 5]\n]\n</code></pre>\n<p>Here's an example using cURL.</p>\n<pre><code>curl -d '[[5, 1, 6], [1, 2, 3]]' -H \"Content-Type: application/json\" -X POST http://[your-endpoint]:5000/predict/[modelname]\n</code></pre>\n<p>The response will always be a 2d array, so if you send one data point expect a list back with only one row.</p>\n<h2>Configuration <a></a></h2>\n<p>The config file <code>shipit.yml</code> for your project is broken down into two major sections.</p>\n<h3>meta</h3>\n<p>project_name\n:  A unique project name, used to namespace the resources created for your project.</p>\n<p>requirements\n:  Path to a requirements.txt file to install dependencies for your models</p>\n<p>provider\n:  For now this is always assumed to be <code>aws</code></p>\n<p>aws_profile\n:  Name of the profile from your awscli credentials.</p>\n<p>aws_region\n:  Which aws region to launch your service in.</p>\n<h3>models</h3>\n<p>This section can contain one or more models you want to include in this API service. See <code>example/shipit.yml</code> as a reference.</p>\n<p>path\n:  The relative path of the pickled model file e.g. <code>models/my_model.pkl</code></p>\n<p>variety\n:  One of <code>[\"sklearn\", \"keras\"]</code>. Eventually we will add more model types.</p>\n<p>preprocess\n:  (optional) A python import dot path to a preprocess function. This function can perform manipulations of the API input before sending it to your model.</p>\n<p>postprocess\n:  (optional) A python import dot path to a postprocess function. This function can perform manipulations of the model's prediction output before returning it to the user.</p>\n<h2>Formatting model data</h2>\n<p>First, ensure your features is a <code>(n_samples, n_features)</code>-shaped numpy array ( in standard <code>sklearn</code> form ). Turn this into a list ( so that we can JSON-serialise it ).</p>\n<h2>Saving models</h2>\n<p>Models from <code>scikit-learn</code> should be saved with <code>joblib</code>. Models from <code>keras</code> should be saved with <code>model.save()</code>. See <code>example/save_model_example.py</code>.</p>\n<h2>To Do</h2>\n<ul>\n<li>Deploy to Private VPN</li>\n<li>Route53 / private / public DNS</li>\n<li>Build an \"export\" feature for customization of Docker / terraform setup.</li>\n<li>Support XGBoost models</li>\n<li>Figure out why sklearn.linear_model.LinearRegression can't be pickled</li>\n</ul>\n\n          </div>"}, "last_serial": 5269055, "releases": {"0.6.0": [{"comment_text": "", "digests": {"md5": "54d072e155642209959810dce3c6149b", "sha256": "7886f20f968c15921cda6034d0197e1800139810c615f78d12f16c4c44707bf3"}, "downloads": -1, "filename": "shipit_ml-0.6.0-py3-none-any.whl", "has_sig": false, "md5_digest": "54d072e155642209959810dce3c6149b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": "!=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, <4", "size": 10769, "upload_time": "2019-05-14T19:35:41", "upload_time_iso_8601": "2019-05-14T19:35:41.673446Z", "url": "https://files.pythonhosted.org/packages/44/97/b4490ff9e2abcfeef8fc330a8f5a64915d15b6b1ae761903741986be4d22/shipit_ml-0.6.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "212f76e05df002ab5efe148238584a1a", "sha256": "2a0b616edfcd131affbe7086149db6d050106c4ed4cf5911aee0d3620569dbb3"}, "downloads": -1, "filename": "shipit_ml-0.6.0.tar.gz", "has_sig": false, "md5_digest": "212f76e05df002ab5efe148238584a1a", "packagetype": "sdist", "python_version": "source", "requires_python": "!=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, <4", "size": 8128, "upload_time": "2019-05-14T19:35:43", "upload_time_iso_8601": "2019-05-14T19:35:43.903598Z", "url": "https://files.pythonhosted.org/packages/59/6a/a5679efcfeea026669f156db2b97d3df5f5901fbbb203d8e4a43dfe96c42/shipit_ml-0.6.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "54d072e155642209959810dce3c6149b", "sha256": "7886f20f968c15921cda6034d0197e1800139810c615f78d12f16c4c44707bf3"}, "downloads": -1, "filename": "shipit_ml-0.6.0-py3-none-any.whl", "has_sig": false, "md5_digest": "54d072e155642209959810dce3c6149b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": "!=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, <4", "size": 10769, "upload_time": "2019-05-14T19:35:41", "upload_time_iso_8601": "2019-05-14T19:35:41.673446Z", "url": "https://files.pythonhosted.org/packages/44/97/b4490ff9e2abcfeef8fc330a8f5a64915d15b6b1ae761903741986be4d22/shipit_ml-0.6.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "212f76e05df002ab5efe148238584a1a", "sha256": "2a0b616edfcd131affbe7086149db6d050106c4ed4cf5911aee0d3620569dbb3"}, "downloads": -1, "filename": "shipit_ml-0.6.0.tar.gz", "has_sig": false, "md5_digest": "212f76e05df002ab5efe148238584a1a", "packagetype": "sdist", "python_version": "source", "requires_python": "!=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, <4", "size": 8128, "upload_time": "2019-05-14T19:35:43", "upload_time_iso_8601": "2019-05-14T19:35:43.903598Z", "url": "https://files.pythonhosted.org/packages/59/6a/a5679efcfeea026669f156db2b97d3df5f5901fbbb203d8e4a43dfe96c42/shipit_ml-0.6.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:12:57 2020"}