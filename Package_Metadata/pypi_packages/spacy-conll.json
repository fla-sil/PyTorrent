{"info": {"author": "Bram Vanroy, Raquel G. Alhama", "author_email": "bramvanroy@hotmail.com, rgalhama@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "Operating System :: OS Independent", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8", "Topic :: Scientific/Engineering", "Topic :: Text Processing"], "description": "================================================\nParsing to CoNLL with spaCy or spacy-stanfordnlp\n================================================\nThis module allows you to parse a text to `CoNLL-U format`_. You can use it as a command line tool, or embed it in your\nown scripts by adding it as a custom component to a spaCy or spacy-stanfordnlp pipeline.\n\nNote that the module simply takes a parser's output and puts it in a formatted string adhering to the linked ConLL-U\nformat. The output tags depend on the spaCy model used. If you want Universal Depencies tags as output, I advise you to\nuse this library in combination with `spacy_stanfordnlp`_, which is a spaCy interface using :code:`stanfordnlp` and its\nmodels behind the scenes. Those models use the Universal Dependencies formalism. See the remainder README for more\ninformation and usage guidelines.\n\n.. _`CoNLL-U format`: https://universaldependencies.org/format.html\n.. _`spacy_stanfordnlp`: https://github.com/explosion/spacy-stanfordnlp\n\n============\nInstallation\n============\n\nRequires `spaCy`_ and an `installed spaCy language model`_. When using the module from the command line, you also need\nthe :code:`packaging` package. See section `spaCy`_ for usage.\n\nBecause `spaCy's models`_ are not necessarily trained on Universal Dependencies conventions, their output labels are\nnot UD either. By using :code:`spacy-stanfordnlp`, we get the easy-to-use interface of spaCy as a wrapper around\n:code:`stanfordnlp` and its models that *are* trained on UD data. If you want to use the Stanford NLP models, you also\nneed :code:`spacy-stanfordnlp` and `a corresponding model`_. See the section `spacy-stanfordnlp`_ for usage.\n\n**NOTE**: :code:`spacy-stanfordnlp` is not automatically installed as a dependency for this library, because it might be\ntoo much overhead for those who don't need UD. If you wish to use its functionality, you have to install it manually.\nBy default, only :code:`spacy` and :code:`packaging` are installed as dependencies.\n\nTo install the library, simply use pip.\n\n.. code:: bash\n\n  pip install spacy_conll\n\n.. _spaCy: https://spacy.io/usage/models#section-quickstart\n.. _installed spaCy language model: https://spacy.io/usage/models\n.. _`a corresponding model`: https://stanfordnlp.github.io/stanfordnlp/models.html\n\n=====\nUsage\n=====\nCommand line\n------------\n.. code:: bash\n\n    > python -m spacy_conll -h\n    usage: [-h] [-f INPUT_FILE] [-a INPUT_ENCODING] [-b INPUT_STR]\n                       [-o OUTPUT_FILE] [-c OUTPUT_ENCODING] [-m MODEL_OR_LANG]\n                       [-s] [-t] [-d] [-e] [-j N_PROCESS] [-u] [-v]\n\n    Parse an input string or input file to CoNLL-U format.\n\n    optional arguments:\n      -h, --help            show this help message and exit\n      -f INPUT_FILE, --input_file INPUT_FILE\n                            Path to file with sentences to parse. Has precedence\n                            over 'input_str'. (default: None)\n      -a INPUT_ENCODING, --input_encoding INPUT_ENCODING\n                            Encoding of the input file. Default value is system\n                            default.\n      -b INPUT_STR, --input_str INPUT_STR\n                            Input string to parse. (default: None)\n      -o OUTPUT_FILE, --output_file OUTPUT_FILE\n                            Path to output file. If not specified, the output will\n                            be printed on standard output. (default: None)\n      -c OUTPUT_ENCODING, --output_encoding OUTPUT_ENCODING\n                            Encoding of the output file. Default value is system\n                            default.\n      -m MODEL_OR_LANG, --model_or_lang MODEL_OR_LANG\n                            spaCy or stanfordnlp model or language to use (must be\n                            installed). (default: None)\n      -s, --disable_sbd     Disables spaCy automatic sentence boundary detection.\n                            In practice, disabling means that every line will be\n                            parsed as one sentence, regardless of its actual\n                            content. Only works when using spaCy. (default: False)\n      -t, --is_tokenized    Indicates whether your text has already been tokenized\n                            (space-seperated). When used in conjunction with\n                            spacy-stanfordnlp, it will also be assumed that the\n                            text is sentence split by newline. (default: False)\n      -d, --include_headers\n                            To include headers before the output of every\n                            sentence. These headers include the sentence text and\n                            the sentence ID. (default: False)\n      -e, --no_force_counting\n                            To disable force counting the 'sent_id', starting from\n                            1 and increasing for each sentence. Instead, 'sent_id'\n                            will depend on how spaCy returns the sentences. Must\n                            have 'include_headers' enabled. (default: False)\n      -j N_PROCESS, --n_process N_PROCESS\n                            Number of processes to use in nlp.pipe(). -1 will use\n                            as many cores as available. Requires spaCy v2.2.2.\n                            (default: 1)\n      -u, --use_stanfordnlp\n                            Use stanfordnlp models rather than spaCy models.\n                            Requires spacy-stanfordnlp. (default: False)\n      -v, --verbose         To print the output to stdout, regardless of\n                            'output_file'. (default: False)\n\n\nFor example, parsing a single line, multi-sentence string:\n\n.. code:: bash\n\n    >  python -m spacy_conll --input_str \"I like cookies . What about you ?\" --is_tokenized --include_headers\n    # sent_id = 1\n    # text = I like cookies .\n    1       I       -PRON-  PRON    PRP     PronType=prs    2       nsubj   _       _\n    2       like    like    VERB    VBP     VerbForm=fin|Tense=pres 0       ROOT    _       _\n    3       cookies cookie  NOUN    NNS     Number=plur     2       dobj    _       _\n    4       .       .       PUNCT   .       PunctType=peri  2       punct   _       _\n\n    # sent_id = 2\n    # text = What about you ?\n    1       What    what    NOUN    WP      PronType=int|rel        2       dep     _       _\n    2       about   about   ADP     IN      _       0       ROOT    _       _\n    3       you     -PRON-  PRON    PRP     PronType=prs    2       pobj    _       _\n    4       ?       ?       PUNCT   .       PunctType=peri  2       punct   _       _\n\nFor example, parsing a large input file and writing output to output file, using four processes:\n\n.. code:: bash\n\n    > python -m spacy_conll --input_file large-input.txt --output_file large-conll-output.txt --include_headers --disable_sbd -j 4\n\nYou can also use Stanford NLP's models to retrieve UD tags. You can do this by using the :code:`-u` flag. **NOTE**:\nUsing Stanford's models has limited options due to the API of :code:`stanfordnlp`. It is not possible to disable\nsentence segmentation and control the tokenisation at the same time. When using the :code:`-u` flag you can only enable\nthe :code:`--is_tokenized` flag which behaves different when used with spaCy. With spaCy, it will simply not try to\ntokenize the text and use spaces as token separators. When using :code:`spacy-stanfordnlp`, it will also be assumed that\nthe text is sentence split by newline. No further sentence segmentation is done.\n\nIn Python\n---------\nspaCy\n+++++\n\n:code:`spacy_conll` is intended to be used a custom pipeline component in spaCy. Three custom extensions are accessible,\nby default named :code:`conll_str`, :code:`conll_str_headers`, and :code:`conll`.\n\n- :code:`conll_str`: returns the string representation of the CoNLL format\n- :code:`conll_str_headers`: returns the string representation of the CoNLL format including headers. These headers\n  consist of two lines, namely :code:`# sent_id = <i>`, indicating which sentence it is in the overall document, and\n  :code:`# text = <sentence>`, which simply shows the original sentence's text\n- :code:`conll`: returns the output as (a list of) tuple(s) where each line is a tuple of its column values\n\nWhen adding the component to the spaCy pipeline, it is important to insert it *after* the parser, as shown in the\nexample below.\n\n.. code:: python\n\n    import spacy\n    from spacy_conll import ConllFormatter\n\n    nlp = spacy.load('en')\n    conllformatter = ConllFormatter(nlp)\n    nlp.add_pipe(conllformatter, after='parser')\n    doc = nlp('I like cookies. Do you?')\n    print(doc._.conll_str_headers)\n\nThe snippet above will return (and print) the following string:\n\n.. code:: text\n\n    # sent_id = 1\n    # text = I like cookies.\n    1\tI\t-PRON-\tPRON\tPRP\tPronType=prs\t2\tnsubj\t_\t_\n    2\tlike\tlike\tVERB\tVBP\tVerbForm=fin|Tense=pres\t0\tROOT\t_\t_\n    3\tcookies\tcookie\tNOUN\tNNS\tNumber=plur\t2\tdobj\t_\t_\n    4\t.\t.\tPUNCT\t.\tPunctType=peri\t2\tpunct\t_\t_\n\n    # sent_id = 2\n    # text = Do you?\n    1\tDo\tdo\tAUX\tVBP\tVerbForm=fin|Tense=pres\t0\tROOT\t_\t_\n    2\tyou\t-PRON-\tPRON\tPRP\tPronType=prs\t1\tnsubj\t_\t_\n    3\t?\t?\tPUNCT\t.\tPunctType=peri\t1\tpunct\t_\t_\n\n\nAn advanced example, showing the more complex options:\n\n* :code:`ext_names`: changes the attribute names to a custom key by using a dictionary. You can change:\n\n  * :code:`conll_str`: a string representation of the CoNLL format\n  * :code:`conll_str_headers`: the same as :code:`conll_str` but with leading lines containing sentence index\n    and sentence text\n  * :code:`conll`: a dictionary containing the field names and their values. For a :code:`Doc` object, this returns a list\n    of dictionaries where each dictionary is a sentence\n\n* :code:`field_names`: a dictionary containing a mapping of field names so that you can name them as you wish\n* :code:`conversion_maps`: a two-level dictionary that looks like :code:`{field_name: {tag_name: replacement}}`.\n  In other words, you can specify in which field a certain value should be replaced by another. This is especially\n  useful when you are not satisfied with the tagset of a model and wish to change some tags to an alternative\n\nThe example below\n\n* changes the custom attribute :code:`conll` to :code:`connl_for_pd`;\n* changes the :code:`lemma` field to :code:`word_lemma`;\n* converts any :code:`-PRON-` to :code:`PRON`;\n* as a bonus: uses the output dictionary to create a pandas DataFrame.\n\n.. code:: python\n\n    import pandas as pd\n    import spacy\n    from spacy_conll import ConllFormatter\n\n\n    nlp = spacy.load('en')\n    conllformatter = ConllFormatter(nlp,\n                                    ext_names={'conll': 'connl_for_pd'},\n                                    field_names={'lemma': 'word_lemma'},\n                                    conversion_maps={'word_lemma': {'-PRON-': 'PRON'}})\n    nlp.add_pipe(conllformatter, after='parser')\n    doc = nlp('I like cookies.')\n    df = pd.DataFrame.from_dict(doc._.connl_for_pd[0])\n    print(df)\n\nThe snippet above will output a pandas DataFrame:\n\n.. code:: text\n\n       id     form word_lemma upostag  ... head deprel  deps misc\n    0   1        I       PRON    PRON  ...    2  nsubj     _    _\n    1   2     like       like    VERB  ...    0   ROOT     _    _\n    2   3  cookies     cookie    NOUN  ...    2   dobj     _    _\n    3   4        .          .   PUNCT  ...    2  punct     _    _\n\n    [4 rows x 10 columns]\n\nspacy-stanfordnlp\n+++++++++++++++++\n\nUsing :code:`spacy_conll` in conjunction with :code:`spacy-stanfordnlp` is similar to using it with :code:`spacy`:\nin practice we are still simply adding a custom component pipeline to the existing pipeline, but this time that pipeline\nis a Stanford NLP pipeline that is wrapped in spaCy's API.\n\n.. code:: python\n\n    from spacy_stanfordnlp import StanfordNLPLanguage\n    import stanfordnlp\n\n    from spacy_conll import ConllFormatter\n\n\n    snlp = stanfordnlp.Pipeline(lang='en')\n    nlp = StanfordNLPLanguage(snlp)\n    conllformatter = ConllFormatter(nlp)\n    nlp.add_pipe(conllformatter, last=True)\n\n    s = 'A cookie is a baked or cooked food that is typically small, flat and sweet.'\n\n    doc = nlp(s)\n    print(doc._.conll_str)\n\nOutput:\n\n.. code:: text\n\n    1\tA\ta\tDET\tDT\t_\t2\tdet\t_\t_\n    2\tcookie\tcookie\tNOUN\tNN\tNumber=sing\t8\tnsubj\t_\t_\n    3\tis\tbe\tAUX\tVBZ\tVerbForm=fin|Tense=pres|Number=sing|Person=three\t8\tcop\t_\t_\n    4\ta\ta\tDET\tDT\t_\t8\tdet\t_\t_\n    5\tbaked\tbake\tVERB\tVBN\tVerbForm=part|Tense=past|Aspect=perf\t8\tamod\t_\t_\n    6\tor\tor\tCCONJ\tCC\tConjType=comp\t7\tcc\t_\t_\n    7\tcooked\tcook\tVERB\tVBN\tVerbForm=part|Tense=past|Aspect=perf\t5\tconj\t_\t_\n    8\tfood\tfood\tNOUN\tNN\tNumber=sing\t0\troot\t_\t_\n    9\tthat\tthat\tPRON\tWDT\t_\t12\tnsubj\t_\t_\n    10\tis\tbe\tAUX\tVBZ\tVerbForm=fin|Tense=pres|Number=sing|Person=three\t12\tcop\t_\t_\n    11\ttypically\ttypically\tADV\tRB\tDegree=pos\t12\tadvmod\t_\t_\n    12\tsmall\tsmall\tADJ\tJJ\tDegree=pos\t8\tacl:relcl\t_\t_\n    13\t,\t,\tPUNCT\t,\tPunctType=comm\t14\tpunct\t_\t_\n    14\tflat\tflat\tADJ\tJJ\tDegree=pos\t12\tconj\t_\t_\n    15\tand\tand\tCCONJ\tCC\tConjType=comp\t16\tcc\t_\t_\n    16\tsweet\tsweet\tADJ\tJJ\tDegree=pos\t12\tconj\t_\t_\n    17\t.\t.\tPUNCT\t.\tPunctType=peri\t8\tpunct\t_\t_\n\n.. _`spaCy's models`: https://spacy.io/models\n\n----\n\n**DEPRECATED:** :code:`Spacy2ConllParser`\n+++++++++++++++++++++++++++++++++++++++++\n\nThere are two main methods, :code:`parse()` and :code:`parseprint()`. The latter is a convenience method for printing the output of\n:code:`parse()` to stdout (default) or a file.\n\n.. code:: python\n\n    from spacy_conll import Spacy2ConllParser\n    spacyconll = Spacy2ConllParser()\n\n    # `parse` returns a generator of the parsed sentences\n    for parsed_sent in spacyconll.parse(input_str=\"I like cookies.\\nWhat about you?\\nI don't like 'em!\"):\n        do_something_(parsed_sent)\n\n    # `parseprint` prints output to stdout (default) or a file (use `output_file` parameter)\n    # This method is called when using the command line\n    spacyconll.parseprint(input_str='I like cookies.')\n\n\n=======\nCredits\n=======\nBased on the `initial work by rgalhama`_.\n\n.. _initial work by rgalhama: https://github.com/rgalhama/spaCy2CoNLLU\n\n\n", "description_content_type": "text/x-rst", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/BramVanroy/spacy_conll", "keywords": "nlp spacy spacy-extension conll conllu tagging parsing stanfordnlp spacy_stanfordnlp", "license": "BSD 2", "maintainer": "", "maintainer_email": "", "name": "spacy-conll", "package_url": "https://pypi.org/project/spacy-conll/", "platform": "", "project_url": "https://pypi.org/project/spacy-conll/", "project_urls": {"Bug Reports": "https://github.com/BramVanroy/spacy_conll/issues", "Homepage": "https://github.com/BramVanroy/spacy_conll", "Source": "https://github.com/BramVanroy/spacy_conll"}, "release_url": "https://pypi.org/project/spacy-conll/1.3.0/", "requires_dist": ["spacy (>=2.0)", "packaging"], "requires_python": ">=3.6", "summary": "A custom pipeline component for spaCy that can convert any parsed Doc and its sentences into CoNLL-U format. Also provides a command line entry point.", "version": "1.3.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"parsing-to-conll-with-spacy-or-spacy-stanfordnlp\">\n<h2>Parsing to CoNLL with spaCy or spacy-stanfordnlp</h2>\n<p>This module allows you to parse a text to <a href=\"https://universaldependencies.org/format.html\" rel=\"nofollow\">CoNLL-U format</a>. You can use it as a command line tool, or embed it in your\nown scripts by adding it as a custom component to a spaCy or spacy-stanfordnlp pipeline.</p>\n<p>Note that the module simply takes a parser\u2019s output and puts it in a formatted string adhering to the linked ConLL-U\nformat. The output tags depend on the spaCy model used. If you want Universal Depencies tags as output, I advise you to\nuse this library in combination with <a href=\"https://github.com/explosion/spacy-stanfordnlp\" rel=\"nofollow\">spacy_stanfordnlp</a>, which is a spaCy interface using <code>stanfordnlp</code> and its\nmodels behind the scenes. Those models use the Universal Dependencies formalism. See the remainder README for more\ninformation and usage guidelines.</p>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>Requires <a href=\"https://spacy.io/usage/models#section-quickstart\" rel=\"nofollow\">spaCy</a> and an <a href=\"https://spacy.io/usage/models\" rel=\"nofollow\">installed spaCy language model</a>. When using the module from the command line, you also need\nthe <code>packaging</code> package. See section <a href=\"https://spacy.io/usage/models#section-quickstart\" rel=\"nofollow\">spaCy</a> for usage.</p>\n<p>Because <a href=\"https://spacy.io/models\" rel=\"nofollow\">spaCy\u2019s models</a> are not necessarily trained on Universal Dependencies conventions, their output labels are\nnot UD either. By using <code>spacy-stanfordnlp</code>, we get the easy-to-use interface of spaCy as a wrapper around\n<code>stanfordnlp</code> and its models that <em>are</em> trained on UD data. If you want to use the Stanford NLP models, you also\nneed <code>spacy-stanfordnlp</code> and <a href=\"https://stanfordnlp.github.io/stanfordnlp/models.html\" rel=\"nofollow\">a corresponding model</a>. See the section <a href=\"#id2\" rel=\"nofollow\">spacy-stanfordnlp</a> for usage.</p>\n<p><strong>NOTE</strong>: <code>spacy-stanfordnlp</code> is not automatically installed as a dependency for this library, because it might be\ntoo much overhead for those who don\u2019t need UD. If you wish to use its functionality, you have to install it manually.\nBy default, only <code>spacy</code> and <code>packaging</code> are installed as dependencies.</p>\n<p>To install the library, simply use pip.</p>\n<pre>pip install spacy_conll\n</pre>\n</div>\n<div id=\"usage\">\n<h2>Usage</h2>\n<div id=\"command-line\">\n<h3>Command line</h3>\n<pre>&gt; python -m spacy_conll -h\nusage: <span class=\"o\">[</span>-h<span class=\"o\">]</span> <span class=\"o\">[</span>-f INPUT_FILE<span class=\"o\">]</span> <span class=\"o\">[</span>-a INPUT_ENCODING<span class=\"o\">]</span> <span class=\"o\">[</span>-b INPUT_STR<span class=\"o\">]</span>\n                   <span class=\"o\">[</span>-o OUTPUT_FILE<span class=\"o\">]</span> <span class=\"o\">[</span>-c OUTPUT_ENCODING<span class=\"o\">]</span> <span class=\"o\">[</span>-m MODEL_OR_LANG<span class=\"o\">]</span>\n                   <span class=\"o\">[</span>-s<span class=\"o\">]</span> <span class=\"o\">[</span>-t<span class=\"o\">]</span> <span class=\"o\">[</span>-d<span class=\"o\">]</span> <span class=\"o\">[</span>-e<span class=\"o\">]</span> <span class=\"o\">[</span>-j N_PROCESS<span class=\"o\">]</span> <span class=\"o\">[</span>-u<span class=\"o\">]</span> <span class=\"o\">[</span>-v<span class=\"o\">]</span>\n\nParse an input string or input file to CoNLL-U format.\n\noptional arguments:\n  -h, --help            show this <span class=\"nb\">help</span> message and <span class=\"nb\">exit</span>\n  -f INPUT_FILE, --input_file INPUT_FILE\n                        Path to file with sentences to parse. Has precedence\n                        over <span class=\"s1\">'input_str'</span>. <span class=\"o\">(</span>default: None<span class=\"o\">)</span>\n  -a INPUT_ENCODING, --input_encoding INPUT_ENCODING\n                        Encoding of the input file. Default value is system\n                        default.\n  -b INPUT_STR, --input_str INPUT_STR\n                        Input string to parse. <span class=\"o\">(</span>default: None<span class=\"o\">)</span>\n  -o OUTPUT_FILE, --output_file OUTPUT_FILE\n                        Path to output file. If not specified, the output will\n                        be printed on standard output. <span class=\"o\">(</span>default: None<span class=\"o\">)</span>\n  -c OUTPUT_ENCODING, --output_encoding OUTPUT_ENCODING\n                        Encoding of the output file. Default value is system\n                        default.\n  -m MODEL_OR_LANG, --model_or_lang MODEL_OR_LANG\n                        spaCy or stanfordnlp model or language to use <span class=\"o\">(</span>must be\n                        installed<span class=\"o\">)</span>. <span class=\"o\">(</span>default: None<span class=\"o\">)</span>\n  -s, --disable_sbd     Disables spaCy automatic sentence boundary detection.\n                        In practice, disabling means that every line will be\n                        parsed as one sentence, regardless of its actual\n                        content. Only works when using spaCy. <span class=\"o\">(</span>default: False<span class=\"o\">)</span>\n  -t, --is_tokenized    Indicates whether your text has already been tokenized\n                        <span class=\"o\">(</span>space-seperated<span class=\"o\">)</span>. When used in conjunction with\n                        spacy-stanfordnlp, it will also be assumed that the\n                        text is sentence split by newline. <span class=\"o\">(</span>default: False<span class=\"o\">)</span>\n  -d, --include_headers\n                        To include headers before the output of every\n                        sentence. These headers include the sentence text and\n                        the sentence ID. <span class=\"o\">(</span>default: False<span class=\"o\">)</span>\n  -e, --no_force_counting\n                        To disable force counting the <span class=\"s1\">'sent_id'</span>, starting from\n                        <span class=\"m\">1</span> and increasing <span class=\"k\">for</span> each sentence. Instead, <span class=\"s1\">'sent_id'</span>\n                        will depend on how spaCy returns the sentences. Must\n                        have <span class=\"s1\">'include_headers'</span> enabled. <span class=\"o\">(</span>default: False<span class=\"o\">)</span>\n  -j N_PROCESS, --n_process N_PROCESS\n                        Number of processes to use in nlp.pipe<span class=\"o\">()</span>. -1 will use\n                        as many cores as available. Requires spaCy v2.2.2.\n                        <span class=\"o\">(</span>default: <span class=\"m\">1</span><span class=\"o\">)</span>\n  -u, --use_stanfordnlp\n                        Use stanfordnlp models rather than spaCy models.\n                        Requires spacy-stanfordnlp. <span class=\"o\">(</span>default: False<span class=\"o\">)</span>\n  -v, --verbose         To print the output to stdout, regardless of\n                        <span class=\"s1\">'output_file'</span>. <span class=\"o\">(</span>default: False<span class=\"o\">)</span>\n</pre>\n<p>For example, parsing a single line, multi-sentence string:</p>\n<pre>&gt;  python -m spacy_conll --input_str <span class=\"s2\">\"I like cookies . What about you ?\"</span> --is_tokenized --include_headers\n<span class=\"c1\"># sent_id = 1\n# text = I like cookies .\n</span><span class=\"m\">1</span>       I       -PRON-  PRON    PRP     <span class=\"nv\">PronType</span><span class=\"o\">=</span>prs    <span class=\"m\">2</span>       nsubj   _       _\n<span class=\"m\">2</span>       like    like    VERB    VBP     <span class=\"nv\">VerbForm</span><span class=\"o\">=</span>fin<span class=\"p\">|</span><span class=\"nv\">Tense</span><span class=\"o\">=</span>pres <span class=\"m\">0</span>       ROOT    _       _\n<span class=\"m\">3</span>       cookies cookie  NOUN    NNS     <span class=\"nv\">Number</span><span class=\"o\">=</span>plur     <span class=\"m\">2</span>       dobj    _       _\n<span class=\"m\">4</span>       .       .       PUNCT   .       <span class=\"nv\">PunctType</span><span class=\"o\">=</span>peri  <span class=\"m\">2</span>       punct   _       _\n\n<span class=\"c1\"># sent_id = 2\n# text = What about you ?\n</span><span class=\"m\">1</span>       What    what    NOUN    WP      <span class=\"nv\">PronType</span><span class=\"o\">=</span>int<span class=\"p\">|</span>rel        <span class=\"m\">2</span>       dep     _       _\n<span class=\"m\">2</span>       about   about   ADP     IN      _       <span class=\"m\">0</span>       ROOT    _       _\n<span class=\"m\">3</span>       you     -PRON-  PRON    PRP     <span class=\"nv\">PronType</span><span class=\"o\">=</span>prs    <span class=\"m\">2</span>       pobj    _       _\n<span class=\"m\">4</span>       ?       ?       PUNCT   .       <span class=\"nv\">PunctType</span><span class=\"o\">=</span>peri  <span class=\"m\">2</span>       punct   _       _\n</pre>\n<p>For example, parsing a large input file and writing output to output file, using four processes:</p>\n<pre>&gt; python -m spacy_conll --input_file large-input.txt --output_file large-conll-output.txt --include_headers --disable_sbd -j <span class=\"m\">4</span>\n</pre>\n<p>You can also use Stanford NLP\u2019s models to retrieve UD tags. You can do this by using the <code>-u</code> flag. <strong>NOTE</strong>:\nUsing Stanford\u2019s models has limited options due to the API of <code>stanfordnlp</code>. It is not possible to disable\nsentence segmentation and control the tokenisation at the same time. When using the <code>-u</code> flag you can only enable\nthe <code>--is_tokenized</code> flag which behaves different when used with spaCy. With spaCy, it will simply not try to\ntokenize the text and use spaces as token separators. When using <code>spacy-stanfordnlp</code>, it will also be assumed that\nthe text is sentence split by newline. No further sentence segmentation is done.</p>\n</div>\n<div id=\"in-python\">\n<h3>In Python</h3>\n<div id=\"id1\">\n<h4>spaCy</h4>\n<p><code>spacy_conll</code> is intended to be used a custom pipeline component in spaCy. Three custom extensions are accessible,\nby default named <code>conll_str</code>, <code>conll_str_headers</code>, and <code>conll</code>.</p>\n<ul>\n<li><code>conll_str</code>: returns the string representation of the CoNLL format</li>\n<li><code>conll_str_headers</code>: returns the string representation of the CoNLL format including headers. These headers\nconsist of two lines, namely <code># sent_id = &lt;i&gt;</code>, indicating which sentence it is in the overall document, and\n<code># text = &lt;sentence&gt;</code>, which simply shows the original sentence\u2019s text</li>\n<li><code>conll</code>: returns the output as (a list of) tuple(s) where each line is a tuple of its column values</li>\n</ul>\n<p>When adding the component to the spaCy pipeline, it is important to insert it <em>after</em> the parser, as shown in the\nexample below.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">spacy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">spacy_conll</span> <span class=\"kn\">import</span> <span class=\"n\">ConllFormatter</span>\n\n<span class=\"n\">nlp</span> <span class=\"o\">=</span> <span class=\"n\">spacy</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s1\">'en'</span><span class=\"p\">)</span>\n<span class=\"n\">conllformatter</span> <span class=\"o\">=</span> <span class=\"n\">ConllFormatter</span><span class=\"p\">(</span><span class=\"n\">nlp</span><span class=\"p\">)</span>\n<span class=\"n\">nlp</span><span class=\"o\">.</span><span class=\"n\">add_pipe</span><span class=\"p\">(</span><span class=\"n\">conllformatter</span><span class=\"p\">,</span> <span class=\"n\">after</span><span class=\"o\">=</span><span class=\"s1\">'parser'</span><span class=\"p\">)</span>\n<span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"n\">nlp</span><span class=\"p\">(</span><span class=\"s1\">'I like cookies. Do you?'</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">doc</span><span class=\"o\">.</span><span class=\"n\">_</span><span class=\"o\">.</span><span class=\"n\">conll_str_headers</span><span class=\"p\">)</span>\n</pre>\n<p>The snippet above will return (and print) the following string:</p>\n<pre># sent_id = 1\n# text = I like cookies.\n1   I       -PRON-  PRON    PRP     PronType=prs    2       nsubj   _       _\n2   like    like    VERB    VBP     VerbForm=fin|Tense=pres 0       ROOT    _       _\n3   cookies cookie  NOUN    NNS     Number=plur     2       dobj    _       _\n4   .       .       PUNCT   .       PunctType=peri  2       punct   _       _\n\n# sent_id = 2\n# text = Do you?\n1   Do      do      AUX     VBP     VerbForm=fin|Tense=pres 0       ROOT    _       _\n2   you     -PRON-  PRON    PRP     PronType=prs    1       nsubj   _       _\n3   ?       ?       PUNCT   .       PunctType=peri  1       punct   _       _\n</pre>\n<p>An advanced example, showing the more complex options:</p>\n<ul>\n<li><code>ext_names</code>: changes the attribute names to a custom key by using a dictionary. You can change:<ul>\n<li><code>conll_str</code>: a string representation of the CoNLL format</li>\n<li><code>conll_str_headers</code>: the same as <code>conll_str</code> but with leading lines containing sentence index\nand sentence text</li>\n<li><code>conll</code>: a dictionary containing the field names and their values. For a <code>Doc</code> object, this returns a list\nof dictionaries where each dictionary is a sentence</li>\n</ul>\n</li>\n<li><code>field_names</code>: a dictionary containing a mapping of field names so that you can name them as you wish</li>\n<li><code>conversion_maps</code>: a two-level dictionary that looks like <code>{field_name: {tag_name: replacement}}</code>.\nIn other words, you can specify in which field a certain value should be replaced by another. This is especially\nuseful when you are not satisfied with the tagset of a model and wish to change some tags to an alternative</li>\n</ul>\n<p>The example below</p>\n<ul>\n<li>changes the custom attribute <code>conll</code> to <code>connl_for_pd</code>;</li>\n<li>changes the <code>lemma</code> field to <code>word_lemma</code>;</li>\n<li>converts any <code>-PRON-</code> to <code>PRON</code>;</li>\n<li>as a bonus: uses the output dictionary to create a pandas DataFrame.</li>\n</ul>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n<span class=\"kn\">import</span> <span class=\"nn\">spacy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">spacy_conll</span> <span class=\"kn\">import</span> <span class=\"n\">ConllFormatter</span>\n\n\n<span class=\"n\">nlp</span> <span class=\"o\">=</span> <span class=\"n\">spacy</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s1\">'en'</span><span class=\"p\">)</span>\n<span class=\"n\">conllformatter</span> <span class=\"o\">=</span> <span class=\"n\">ConllFormatter</span><span class=\"p\">(</span><span class=\"n\">nlp</span><span class=\"p\">,</span>\n                                <span class=\"n\">ext_names</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'conll'</span><span class=\"p\">:</span> <span class=\"s1\">'connl_for_pd'</span><span class=\"p\">},</span>\n                                <span class=\"n\">field_names</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'lemma'</span><span class=\"p\">:</span> <span class=\"s1\">'word_lemma'</span><span class=\"p\">},</span>\n                                <span class=\"n\">conversion_maps</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'word_lemma'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s1\">'-PRON-'</span><span class=\"p\">:</span> <span class=\"s1\">'PRON'</span><span class=\"p\">}})</span>\n<span class=\"n\">nlp</span><span class=\"o\">.</span><span class=\"n\">add_pipe</span><span class=\"p\">(</span><span class=\"n\">conllformatter</span><span class=\"p\">,</span> <span class=\"n\">after</span><span class=\"o\">=</span><span class=\"s1\">'parser'</span><span class=\"p\">)</span>\n<span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"n\">nlp</span><span class=\"p\">(</span><span class=\"s1\">'I like cookies.'</span><span class=\"p\">)</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"o\">.</span><span class=\"n\">from_dict</span><span class=\"p\">(</span><span class=\"n\">doc</span><span class=\"o\">.</span><span class=\"n\">_</span><span class=\"o\">.</span><span class=\"n\">connl_for_pd</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">)</span>\n</pre>\n<p>The snippet above will output a pandas DataFrame:</p>\n<pre>   id     form word_lemma upostag  ... head deprel  deps misc\n0   1        I       PRON    PRON  ...    2  nsubj     _    _\n1   2     like       like    VERB  ...    0   ROOT     _    _\n2   3  cookies     cookie    NOUN  ...    2   dobj     _    _\n3   4        .          .   PUNCT  ...    2  punct     _    _\n\n[4 rows x 10 columns]\n</pre>\n</div>\n<div id=\"id2\">\n<h4>spacy-stanfordnlp</h4>\n<p>Using <code>spacy_conll</code> in conjunction with <code>spacy-stanfordnlp</code> is similar to using it with <code>spacy</code>:\nin practice we are still simply adding a custom component pipeline to the existing pipeline, but this time that pipeline\nis a Stanford NLP pipeline that is wrapped in spaCy\u2019s API.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">spacy_stanfordnlp</span> <span class=\"kn\">import</span> <span class=\"n\">StanfordNLPLanguage</span>\n<span class=\"kn\">import</span> <span class=\"nn\">stanfordnlp</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">spacy_conll</span> <span class=\"kn\">import</span> <span class=\"n\">ConllFormatter</span>\n\n\n<span class=\"n\">snlp</span> <span class=\"o\">=</span> <span class=\"n\">stanfordnlp</span><span class=\"o\">.</span><span class=\"n\">Pipeline</span><span class=\"p\">(</span><span class=\"n\">lang</span><span class=\"o\">=</span><span class=\"s1\">'en'</span><span class=\"p\">)</span>\n<span class=\"n\">nlp</span> <span class=\"o\">=</span> <span class=\"n\">StanfordNLPLanguage</span><span class=\"p\">(</span><span class=\"n\">snlp</span><span class=\"p\">)</span>\n<span class=\"n\">conllformatter</span> <span class=\"o\">=</span> <span class=\"n\">ConllFormatter</span><span class=\"p\">(</span><span class=\"n\">nlp</span><span class=\"p\">)</span>\n<span class=\"n\">nlp</span><span class=\"o\">.</span><span class=\"n\">add_pipe</span><span class=\"p\">(</span><span class=\"n\">conllformatter</span><span class=\"p\">,</span> <span class=\"n\">last</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n<span class=\"n\">s</span> <span class=\"o\">=</span> <span class=\"s1\">'A cookie is a baked or cooked food that is typically small, flat and sweet.'</span>\n\n<span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"n\">nlp</span><span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">doc</span><span class=\"o\">.</span><span class=\"n\">_</span><span class=\"o\">.</span><span class=\"n\">conll_str</span><span class=\"p\">)</span>\n</pre>\n<p>Output:</p>\n<pre>1   A       a       DET     DT      _       2       det     _       _\n2   cookie  cookie  NOUN    NN      Number=sing     8       nsubj   _       _\n3   is      be      AUX     VBZ     VerbForm=fin|Tense=pres|Number=sing|Person=three        8       cop     _       _\n4   a       a       DET     DT      _       8       det     _       _\n5   baked   bake    VERB    VBN     VerbForm=part|Tense=past|Aspect=perf    8       amod    _       _\n6   or      or      CCONJ   CC      ConjType=comp   7       cc      _       _\n7   cooked  cook    VERB    VBN     VerbForm=part|Tense=past|Aspect=perf    5       conj    _       _\n8   food    food    NOUN    NN      Number=sing     0       root    _       _\n9   that    that    PRON    WDT     _       12      nsubj   _       _\n10  is      be      AUX     VBZ     VerbForm=fin|Tense=pres|Number=sing|Person=three        12      cop     _       _\n11  typically       typically       ADV     RB      Degree=pos      12      advmod  _       _\n12  small   small   ADJ     JJ      Degree=pos      8       acl:relcl       _       _\n13  ,       ,       PUNCT   ,       PunctType=comm  14      punct   _       _\n14  flat    flat    ADJ     JJ      Degree=pos      12      conj    _       _\n15  and     and     CCONJ   CC      ConjType=comp   16      cc      _       _\n16  sweet   sweet   ADJ     JJ      Degree=pos      12      conj    _       _\n17  .       .       PUNCT   .       PunctType=peri  8       punct   _       _\n</pre>\n</div>\n<hr class=\"docutils\">\n<div id=\"deprecated-spacy2conllparser\">\n<h4><strong>DEPRECATED:</strong> <code>Spacy2ConllParser</code></h4>\n<p>There are two main methods, <code>parse()</code> and <code>parseprint()</code>. The latter is a convenience method for printing the output of\n<code>parse()</code> to stdout (default) or a file.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">spacy_conll</span> <span class=\"kn\">import</span> <span class=\"n\">Spacy2ConllParser</span>\n<span class=\"n\">spacyconll</span> <span class=\"o\">=</span> <span class=\"n\">Spacy2ConllParser</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># `parse` returns a generator of the parsed sentences</span>\n<span class=\"k\">for</span> <span class=\"n\">parsed_sent</span> <span class=\"ow\">in</span> <span class=\"n\">spacyconll</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"n\">input_str</span><span class=\"o\">=</span><span class=\"s2\">\"I like cookies.</span><span class=\"se\">\\n</span><span class=\"s2\">What about you?</span><span class=\"se\">\\n</span><span class=\"s2\">I don't like 'em!\"</span><span class=\"p\">):</span>\n    <span class=\"n\">do_something_</span><span class=\"p\">(</span><span class=\"n\">parsed_sent</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># `parseprint` prints output to stdout (default) or a file (use `output_file` parameter)</span>\n<span class=\"c1\"># This method is called when using the command line</span>\n<span class=\"n\">spacyconll</span><span class=\"o\">.</span><span class=\"n\">parseprint</span><span class=\"p\">(</span><span class=\"n\">input_str</span><span class=\"o\">=</span><span class=\"s1\">'I like cookies.'</span><span class=\"p\">)</span>\n</pre>\n</div>\n</div>\n</div>\n<div id=\"credits\">\n<h2>Credits</h2>\n<p>Based on the <a href=\"https://github.com/rgalhama/spaCy2CoNLLU\" rel=\"nofollow\">initial work by rgalhama</a>.</p>\n</div>\n\n          </div>"}, "last_serial": 7118151, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "e158307deb2e713d42e7b95a9fa9b609", "sha256": "a91adcc16844d921a979cd3575e7981fbade471cc1b4cbf02c4c5fff308bdf0b"}, "downloads": -1, "filename": "spacy_conll-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "e158307deb2e713d42e7b95a9fa9b609", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 4945, "upload_time": "2019-01-14T13:44:10", "upload_time_iso_8601": "2019-01-14T13:44:10.614929Z", "url": "https://files.pythonhosted.org/packages/8e/f7/a0338c0cd6992bbe36f3d61194ee7bbe3af6945da5ca7be71d57fc7aad8c/spacy_conll-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3c6ffe6aa1c3d1b23cdec52befa2abe6", "sha256": "634e14766b8f40c87eed55c20396e1af16ebe7403014ae73633d55454c06dd76"}, "downloads": -1, "filename": "spacy_conll-0.0.1.tar.gz", "has_sig": false, "md5_digest": "3c6ffe6aa1c3d1b23cdec52befa2abe6", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 4375, "upload_time": "2019-01-14T13:44:12", "upload_time_iso_8601": "2019-01-14T13:44:12.726931Z", "url": "https://files.pythonhosted.org/packages/79/ef/46367193b227ad010b8b5be2443aa5e0ff30a85e1d980ea0fc7cb530e667/spacy_conll-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "32cdaf2fd85fb405a07e96f9e081eed6", "sha256": "50df09eef65841270c4138f1ca0532e73e4254b276ef2006626df0bf0f786b7b"}, "downloads": -1, "filename": "spacy_conll-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "32cdaf2fd85fb405a07e96f9e081eed6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 4946, "upload_time": "2019-01-14T13:49:00", "upload_time_iso_8601": "2019-01-14T13:49:00.863921Z", "url": "https://files.pythonhosted.org/packages/b5/76/7cae787d45da165e29e8729df9c0b1b0138faf16d60d1e6f1bca82075a1d/spacy_conll-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6306795d7dae5a3a12a606427c764ed3", "sha256": "b461f40d2fa4361cdec0199872ddf6ae4dc283e7192716c4bd4e286cda185ba0"}, "downloads": -1, "filename": "spacy_conll-0.0.2.tar.gz", "has_sig": false, "md5_digest": "6306795d7dae5a3a12a606427c764ed3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 4272, "upload_time": "2019-01-14T13:49:01", "upload_time_iso_8601": "2019-01-14T13:49:01.920883Z", "url": "https://files.pythonhosted.org/packages/29/a8/3c5dab0477f512de3d759c4c0ae40fa1485c993ef1ed3cc641f059e1bf06/spacy_conll-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "f43272da7dab03fc8955d24f57010b62", "sha256": "35b5856eb567a27e82b0755fa66e91f480488bf8fac10c74e30b6b6e6f2bc71b"}, "downloads": -1, "filename": "spacy_conll-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "f43272da7dab03fc8955d24f57010b62", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 4934, "upload_time": "2019-01-14T13:55:48", "upload_time_iso_8601": "2019-01-14T13:55:48.356840Z", "url": "https://files.pythonhosted.org/packages/39/28/bca49c5403e36d8796126d215eb66d61feb92690b582de5237e864de827a/spacy_conll-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0dbab1f937a608162a140df408926b51", "sha256": "d00d91864c8fd28d57df3d3a412301e6bb6940ff48a0425320650bc936feb561"}, "downloads": -1, "filename": "spacy_conll-0.0.3.tar.gz", "has_sig": false, "md5_digest": "0dbab1f937a608162a140df408926b51", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 4335, "upload_time": "2019-01-14T13:55:49", "upload_time_iso_8601": "2019-01-14T13:55:49.388131Z", "url": "https://files.pythonhosted.org/packages/d3/16/f90c377348529eeeff9b0f0507d8caa1b48a7df9fe15348c4f5218daad45/spacy_conll-0.0.3.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "300f5249218a7f55d8661d60eed26f60", "sha256": "d9da7abe97ea2ff86cd29ff66d9ef1f5e04600276773e462a548e084e1f8aaef"}, "downloads": -1, "filename": "spacy_conll-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "300f5249218a7f55d8661d60eed26f60", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 5207, "upload_time": "2019-01-16T09:45:47", "upload_time_iso_8601": "2019-01-16T09:45:47.963659Z", "url": "https://files.pythonhosted.org/packages/2e/9c/24f740f45b2b7b3581c99a4aa1bfeca957dca3abd7617f440730ad366019/spacy_conll-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6102f844d2eaa6db58e471e40e233164", "sha256": "65f9fbf61cebeeae4be3b55add3e60fa9588ccfdd2b0995f49a8f03c8ebb2bad"}, "downloads": -1, "filename": "spacy_conll-0.1.0.tar.gz", "has_sig": false, "md5_digest": "6102f844d2eaa6db58e471e40e233164", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 4617, "upload_time": "2019-01-16T09:45:49", "upload_time_iso_8601": "2019-01-16T09:45:49.640518Z", "url": "https://files.pythonhosted.org/packages/47/81/3aef9e53cced06997a6fbae132cea294af9316d7963b202732b92affff3e/spacy_conll-0.1.0.tar.gz", "yanked": false}], "0.1.5": [{"comment_text": "", "digests": {"md5": "eb6834b45b32eb006846bd25cf9ea20b", "sha256": "883c7c4833536f49bfa9937d3b0e95efde71e17c61377bbf5e61fb347f131970"}, "downloads": -1, "filename": "spacy_conll-0.1.5-py3-none-any.whl", "has_sig": false, "md5_digest": "eb6834b45b32eb006846bd25cf9ea20b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 5470, "upload_time": "2019-01-17T14:59:09", "upload_time_iso_8601": "2019-01-17T14:59:09.694708Z", "url": "https://files.pythonhosted.org/packages/1e/3f/ff4da6cae354b79f0336040d381ea3c532fe1bf9b27382e254e739dad399/spacy_conll-0.1.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "523e78937cd3913963424c478a500d4a", "sha256": "f847b202758994fe7ab277cf82ce87056a0f794334424266fa6f4dccb7c46efa"}, "downloads": -1, "filename": "spacy_conll-0.1.5.tar.gz", "has_sig": false, "md5_digest": "523e78937cd3913963424c478a500d4a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 4892, "upload_time": "2019-01-17T14:59:11", "upload_time_iso_8601": "2019-01-17T14:59:11.199234Z", "url": "https://files.pythonhosted.org/packages/ef/7c/0b03768fe28406f034c26b0694bd9882f81f6b5b75f81bb9683f281ef4af/spacy_conll-0.1.5.tar.gz", "yanked": false}], "0.1.6": [{"comment_text": "", "digests": {"md5": "3c5a0f67f801ebd1b6adda10991a5acd", "sha256": "c60a9ab510ec35b3997fdb9012537514f8d6994ddab1aa315ba821393abf0d9d"}, "downloads": -1, "filename": "spacy_conll-0.1.6-py3-none-any.whl", "has_sig": false, "md5_digest": "3c5a0f67f801ebd1b6adda10991a5acd", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 5523, "upload_time": "2019-01-17T15:33:46", "upload_time_iso_8601": "2019-01-17T15:33:46.969524Z", "url": "https://files.pythonhosted.org/packages/84/a6/18143014967a6a24ee64aac3ea2ca76dccc61432b99c4ef168ecb7da6a4c/spacy_conll-0.1.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0b28e40f8a729b04d861c7389a8a51ad", "sha256": "f7b2512f47b23cabbca06a061a54e287c9c8a2b628dc671dd70ae708ead577f0"}, "downloads": -1, "filename": "spacy_conll-0.1.6.tar.gz", "has_sig": false, "md5_digest": "0b28e40f8a729b04d861c7389a8a51ad", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 4941, "upload_time": "2019-01-17T15:33:48", "upload_time_iso_8601": "2019-01-17T15:33:48.267426Z", "url": "https://files.pythonhosted.org/packages/9f/08/3cb6c6e77222e401d5eac33ae89adfb7cb16be3eb99ee19251b7ff1a8e5b/spacy_conll-0.1.6.tar.gz", "yanked": false}], "1.0.0": [{"comment_text": "", "digests": {"md5": "08426ac167b5f26d669e7488fed0a142", "sha256": "09290b70c8dbc106ab342f38e9efc663088a105569cdf6acdff2ae43750cc250"}, "downloads": -1, "filename": "spacy_conll-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "08426ac167b5f26d669e7488fed0a142", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 8747, "upload_time": "2020-01-15T14:03:45", "upload_time_iso_8601": "2020-01-15T14:03:45.547296Z", "url": "https://files.pythonhosted.org/packages/41/38/a8e2e3c1afcb7dfdd8b9c8442ef48e501096d6a438ed5a70e2399bf15dce/spacy_conll-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a6865ee179c9d082df8ad29845d5cf40", "sha256": "59c428711cee6751d95035e3c5faa48bad9240f118419b5f9c5e2ca0d749e75f"}, "downloads": -1, "filename": "spacy_conll-1.0.0.tar.gz", "has_sig": false, "md5_digest": "a6865ee179c9d082df8ad29845d5cf40", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 8315, "upload_time": "2020-01-15T14:03:46", "upload_time_iso_8601": "2020-01-15T14:03:46.786708Z", "url": "https://files.pythonhosted.org/packages/49/83/c2d7812faa3623d0e0a140a32648fb1799e1f0ec1ed56d17780d3c53ade1/spacy_conll-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "216f1ccc8f238164d3eaf5cd9c05fbcc", "sha256": "5ad8f08ade7ae46a3458b269783529cf84ea2682b4dc9b206e76a35d3a45cd5a"}, "downloads": -1, "filename": "spacy_conll-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "216f1ccc8f238164d3eaf5cd9c05fbcc", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 11135, "upload_time": "2020-01-15T14:11:46", "upload_time_iso_8601": "2020-01-15T14:11:46.498344Z", "url": "https://files.pythonhosted.org/packages/86/e9/62ec030c7a709d220349a04cb22314c40f9a2010ca42fc31360eff7cce98/spacy_conll-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a3834b343c7fd00b264d5aa8b7db6c31", "sha256": "470e820ecc607e66002aaf7ae0ecc537af5a5d8973d0663ade7ec434cae5cef1"}, "downloads": -1, "filename": "spacy_conll-1.0.1.tar.gz", "has_sig": false, "md5_digest": "a3834b343c7fd00b264d5aa8b7db6c31", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 10849, "upload_time": "2020-01-15T14:11:48", "upload_time_iso_8601": "2020-01-15T14:11:48.117340Z", "url": "https://files.pythonhosted.org/packages/0f/cc/b0a446cd38f86d89b2502037cf1cc43da48f2dd9202ee23a81b30f0070da/spacy_conll-1.0.1.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "776f8bf63b3978eb0642180ed70f483e", "sha256": "a4f43a31b780c563fdb3c88b845656248f9333f07ec6871ee4bf77a9f0474fac"}, "downloads": -1, "filename": "spacy_conll-1.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "776f8bf63b3978eb0642180ed70f483e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 11575, "upload_time": "2020-01-21T09:15:03", "upload_time_iso_8601": "2020-01-21T09:15:03.978275Z", "url": "https://files.pythonhosted.org/packages/0f/e0/d3120020701f33befe63cb130082624c718a7d4b31c2824f0ce79d8d9f75/spacy_conll-1.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2b5272daf099293ec63d46097997ffda", "sha256": "912c963bd5f3a0d0ac44a3fc888d2776523eb72c7f23920ca9402bc00da54b09"}, "downloads": -1, "filename": "spacy_conll-1.1.0.tar.gz", "has_sig": false, "md5_digest": "2b5272daf099293ec63d46097997ffda", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 11411, "upload_time": "2020-01-21T09:15:05", "upload_time_iso_8601": "2020-01-21T09:15:05.824349Z", "url": "https://files.pythonhosted.org/packages/27/17/634c507b863610b13b2f808d741e903beaa33e53ca72ea2fcbc9856cdb34/spacy_conll-1.1.0.tar.gz", "yanked": false}], "1.2.0": [{"comment_text": "", "digests": {"md5": "8ad9b1a7967292accc2c9b95ac51f839", "sha256": "502e31ccd1136fd045085a1ec3f20bbceb0b5d35991ce99843491910fc964644"}, "downloads": -1, "filename": "spacy_conll-1.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "8ad9b1a7967292accc2c9b95ac51f839", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 14454, "upload_time": "2020-02-02T13:18:31", "upload_time_iso_8601": "2020-02-02T13:18:31.530828Z", "url": "https://files.pythonhosted.org/packages/86/d7/c320fdeaabeffbfceed8267c16b68c76a01e9f5a8b6214a7b07243a047c4/spacy_conll-1.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "61ef00175c6f00ede2139078ceb35d0b", "sha256": "d2b6d49a3b5f2e2dad871773c733da2fc468c3841cd36b06a23e19471ef46946"}, "downloads": -1, "filename": "spacy_conll-1.2.0.tar.gz", "has_sig": false, "md5_digest": "61ef00175c6f00ede2139078ceb35d0b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 17037, "upload_time": "2020-02-02T13:18:33", "upload_time_iso_8601": "2020-02-02T13:18:33.369563Z", "url": "https://files.pythonhosted.org/packages/d8/8f/afc2f59c82fdf84ca7022182b1ea74a62fcaa8dd5818afbb421c221dd199/spacy_conll-1.2.0.tar.gz", "yanked": false}], "1.3.0": [{"comment_text": "", "digests": {"md5": "aaada7738f2c8ffb26640f44962e393b", "sha256": "4c7b5ea8ef992d180bead8526509945bf8ada99e8689022874ac6b9c4aabf53b"}, "downloads": -1, "filename": "spacy_conll-1.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "aaada7738f2c8ffb26640f44962e393b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 14480, "upload_time": "2020-04-28T08:25:24", "upload_time_iso_8601": "2020-04-28T08:25:24.376826Z", "url": "https://files.pythonhosted.org/packages/16/43/8e979338259a0e8e1881d7cfc01d4fbc16bc43d89a00151a367a1e821be8/spacy_conll-1.3.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6883089533cd398455647fccdc464e00", "sha256": "508d6ddd5eef26dd9e2397e31fb5fd4181010e3e7716da83c81d3df592165161"}, "downloads": -1, "filename": "spacy_conll-1.3.0.tar.gz", "has_sig": false, "md5_digest": "6883089533cd398455647fccdc464e00", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 17077, "upload_time": "2020-04-28T08:25:25", "upload_time_iso_8601": "2020-04-28T08:25:25.796011Z", "url": "https://files.pythonhosted.org/packages/5b/18/b5a36d2c92a02e2d72be3ce93eb8659f013b566e4aac0efcf8d9de56648a/spacy_conll-1.3.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "aaada7738f2c8ffb26640f44962e393b", "sha256": "4c7b5ea8ef992d180bead8526509945bf8ada99e8689022874ac6b9c4aabf53b"}, "downloads": -1, "filename": "spacy_conll-1.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "aaada7738f2c8ffb26640f44962e393b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 14480, "upload_time": "2020-04-28T08:25:24", "upload_time_iso_8601": "2020-04-28T08:25:24.376826Z", "url": "https://files.pythonhosted.org/packages/16/43/8e979338259a0e8e1881d7cfc01d4fbc16bc43d89a00151a367a1e821be8/spacy_conll-1.3.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6883089533cd398455647fccdc464e00", "sha256": "508d6ddd5eef26dd9e2397e31fb5fd4181010e3e7716da83c81d3df592165161"}, "downloads": -1, "filename": "spacy_conll-1.3.0.tar.gz", "has_sig": false, "md5_digest": "6883089533cd398455647fccdc464e00", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 17077, "upload_time": "2020-04-28T08:25:25", "upload_time_iso_8601": "2020-04-28T08:25:25.796011Z", "url": "https://files.pythonhosted.org/packages/5b/18/b5a36d2c92a02e2d72be3ce93eb8659f013b566e4aac0efcf8d9de56648a/spacy_conll-1.3.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:06:05 2020"}