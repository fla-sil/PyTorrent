{"info": {"author": "Babatunde Adewole", "author_email": "adewole63@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "This python library provides corpus in English and various local african languages e.g(Youruba, Hausa, Pidgin), it also does sentiment analysis on brands\n\nUSAGE\n\nBrand Sentiment Analysis\n\nbrand = the name of the brand you will like to perfrom sentiment analysis on e.g \"MTN\"\ncsvFileName = The name of the csv file you will like to save your output to, default is brandNews.csv. (optional parameter)\n<br>\nfrom anjie import brandSentimentAnalysis\n<br>\nbrandSentimentAnalysis.anjie_brands(brand = \"MTN\", csvFileName = 'brandNews')\n<br>\nimport pandas as pd\n<br>\ndf = pd.read_csv(\"brandNews.csv.csv\")\n<br>\n\n\nScraping English Corpus\n\nnoRows = The number of rows of news you want.\ncsvFileName = The name of the csv file you will like to save your output to, default is news.csv. (optional parameter)\nNews categories include ['news', 'sports', 'metro-plus', 'politics', 'business', 'entertainment', 'editorial', 'columnist']\nremoveCategories = [] :as a parameter for news categories you dont want in the scraped corpus. (optional parameter)\ne.g , englishCorpus.scrape(noRows = 150, removeCategories = ['metro-plus', 'politics']) \n\npass onlyCategories = [] : as a parameter for only categories you want in the scraped corpus. (optional parameter)\ne.g , englishCorpus.scrape(noRows = 150, onlyCategories = ['news', 'sports', 'metro-plus', 'entertainment', 'editorial', 'columnist'])\n\n<br>\nfrom anjie import englishCorpus\n<br>\nenglishCorpus.scrape(noRows = 150)\n<br>\ndf = pd.read_csv(\"news.csv\")\n<br>\n\nScraping Hausa Corpus\n<br>\nnoRows = The number of rows of news you want. only 60 rows of hausa corpus is currently available.\ncsvName = The name of the csv file you will like to save your output to, default is hausa_news.csv. (optional parameter) \n\n<br>\nfrom anjie import hausaCorpus\n<br>\nhausaCorpus.scrape(noRows = 10)\n<br>\nimport pandas as pd\n<br>\ndf = pd.read_csv(\"hausa_news.csv\")\n<br>\n\nScraping Pidgin English corpus\n<br>\nnoRows = The number of rows of news you want.\ncsvFileName = The name of the csv file you will like to save your output to, default is pidgin_corpus.csv. (optional parameter)\nNews categories include ['nigeria', 'africa', 'sport', 'entertainment']\nremoveCategories = [] :as a parameter for news categories you dont want in the scraped corpus. (optional parameter)\ne.g , englishCorpus.scrape(noRows = 150, removeCategories = ['entertainment']) \n\npass onlyCategories = [] : as a parameter for only categories you want in the scraped corpus. (optional parameter)\ne.g , englishCorpus.scrape(noRows = 150, onlyCategories = ['nigeria','sport', 'entertainment'])\n<br>\nfrom anjie import pidginCorpus\n<br>\npidginCorpus.scrape(noRows = 20)\n<br>\ndf = pd.read_csv(\"pidgin_corpus.csv\")\n<br>\n\nScraping Yoruba Corpus\n<br>\nnoRows = The number of rows of news you want.\ncsvFileName = The name of the csv file you will like to save your output to, default is yoruba_corpus.csv. (optional parameter)\n\n<br>\nfrom anjie import yorubaCorpus\n<br>\nyorubaCorpus.scrape(noRows = 20)\n<br>\ndf = pd.read_csv(\"yoruba_corpus.csv\")\n<br>\n\n\nGithub link for project - https://github.com/Free-tek/Anjie_local_language_corpus_generator \n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Free-tek/Anjie_local_language_corpus_generator", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "anjie", "package_url": "https://pypi.org/project/anjie/", "platform": "", "project_url": "https://pypi.org/project/anjie/", "project_urls": {"Homepage": "https://github.com/Free-tek/Anjie_local_language_corpus_generator"}, "release_url": "https://pypi.org/project/anjie/1.0.0/", "requires_dist": null, "requires_python": ">=3.6", "summary": "This python library provides corpus in English and various local african languages e.g(Youruba, Hausa, Pidgin), it also does sentiment analysis on brands", "version": "1.0.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>This python library provides corpus in English and various local african languages e.g(Youruba, Hausa, Pidgin), it also does sentiment analysis on brands</p>\n<p>USAGE</p>\n<p>Brand Sentiment Analysis</p>\n<p>brand = the name of the brand you will like to perfrom sentiment analysis on e.g \"MTN\"\ncsvFileName = The name of the csv file you will like to save your output to, default is brandNews.csv. (optional parameter)\n<br>\nfrom anjie import brandSentimentAnalysis\n<br>\nbrandSentimentAnalysis.anjie_brands(brand = \"MTN\", csvFileName = 'brandNews')\n<br>\nimport pandas as pd\n<br>\ndf = pd.read_csv(\"brandNews.csv.csv\")\n<br></p>\n<p>Scraping English Corpus</p>\n<p>noRows = The number of rows of news you want.\ncsvFileName = The name of the csv file you will like to save your output to, default is news.csv. (optional parameter)\nNews categories include ['news', 'sports', 'metro-plus', 'politics', 'business', 'entertainment', 'editorial', 'columnist']\nremoveCategories = [] :as a parameter for news categories you dont want in the scraped corpus. (optional parameter)\ne.g , englishCorpus.scrape(noRows = 150, removeCategories = ['metro-plus', 'politics'])</p>\n<p>pass onlyCategories = [] : as a parameter for only categories you want in the scraped corpus. (optional parameter)\ne.g , englishCorpus.scrape(noRows = 150, onlyCategories = ['news', 'sports', 'metro-plus', 'entertainment', 'editorial', 'columnist'])</p>\n<br>\nfrom anjie import englishCorpus\n<br>\nenglishCorpus.scrape(noRows = 150)\n<br>\ndf = pd.read_csv(\"news.csv\")\n<br>\n<p>Scraping Hausa Corpus\n<br>\nnoRows = The number of rows of news you want. only 60 rows of hausa corpus is currently available.\ncsvName = The name of the csv file you will like to save your output to, default is hausa_news.csv. (optional parameter)</p>\n<br>\nfrom anjie import hausaCorpus\n<br>\nhausaCorpus.scrape(noRows = 10)\n<br>\nimport pandas as pd\n<br>\ndf = pd.read_csv(\"hausa_news.csv\")\n<br>\n<p>Scraping Pidgin English corpus\n<br>\nnoRows = The number of rows of news you want.\ncsvFileName = The name of the csv file you will like to save your output to, default is pidgin_corpus.csv. (optional parameter)\nNews categories include ['nigeria', 'africa', 'sport', 'entertainment']\nremoveCategories = [] :as a parameter for news categories you dont want in the scraped corpus. (optional parameter)\ne.g , englishCorpus.scrape(noRows = 150, removeCategories = ['entertainment'])</p>\n<p>pass onlyCategories = [] : as a parameter for only categories you want in the scraped corpus. (optional parameter)\ne.g , englishCorpus.scrape(noRows = 150, onlyCategories = ['nigeria','sport', 'entertainment'])\n<br>\nfrom anjie import pidginCorpus\n<br>\npidginCorpus.scrape(noRows = 20)\n<br>\ndf = pd.read_csv(\"pidgin_corpus.csv\")\n<br></p>\n<p>Scraping Yoruba Corpus\n<br>\nnoRows = The number of rows of news you want.\ncsvFileName = The name of the csv file you will like to save your output to, default is yoruba_corpus.csv. (optional parameter)</p>\n<br>\nfrom anjie import yorubaCorpus\n<br>\nyorubaCorpus.scrape(noRows = 20)\n<br>\ndf = pd.read_csv(\"yoruba_corpus.csv\")\n<br>\n<p>Github link for project - <a href=\"https://github.com/Free-tek/Anjie_local_language_corpus_generator\" rel=\"nofollow\">https://github.com/Free-tek/Anjie_local_language_corpus_generator</a></p>\n\n          </div>"}, "last_serial": 6343053, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "ae465761cf10ec7e0784c19d4a665ab0", "sha256": "1fb27b2ed5d5025cf890e17f6d1c962d7fa00e034c64a4c99cae6a0870b51162"}, "downloads": -1, "filename": "anjie-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "ae465761cf10ec7e0784c19d4a665ab0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 2691, "upload_time": "2019-12-21T00:25:25", "upload_time_iso_8601": "2019-12-21T00:25:25.873462Z", "url": "https://files.pythonhosted.org/packages/e8/66/12c31b5a45e0e0abb35757aaf6a39b46b323aad5d3a97b7406f8f512551b/anjie-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a902a3a716f07d72a23b913ca41bb5bb", "sha256": "532c736e4e8411ba59647e5193bd5499aeac89fe21fa7a0261f2a2ad0f984f20"}, "downloads": -1, "filename": "anjie-1.0.0.tar.gz", "has_sig": false, "md5_digest": "a902a3a716f07d72a23b913ca41bb5bb", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 1991, "upload_time": "2019-12-21T00:25:28", "upload_time_iso_8601": "2019-12-21T00:25:28.010154Z", "url": "https://files.pythonhosted.org/packages/4f/37/495584ed57eeb20943be430e2a27b91654bd53395f27d443056f7ce52e57/anjie-1.0.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ae465761cf10ec7e0784c19d4a665ab0", "sha256": "1fb27b2ed5d5025cf890e17f6d1c962d7fa00e034c64a4c99cae6a0870b51162"}, "downloads": -1, "filename": "anjie-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "ae465761cf10ec7e0784c19d4a665ab0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 2691, "upload_time": "2019-12-21T00:25:25", "upload_time_iso_8601": "2019-12-21T00:25:25.873462Z", "url": "https://files.pythonhosted.org/packages/e8/66/12c31b5a45e0e0abb35757aaf6a39b46b323aad5d3a97b7406f8f512551b/anjie-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a902a3a716f07d72a23b913ca41bb5bb", "sha256": "532c736e4e8411ba59647e5193bd5499aeac89fe21fa7a0261f2a2ad0f984f20"}, "downloads": -1, "filename": "anjie-1.0.0.tar.gz", "has_sig": false, "md5_digest": "a902a3a716f07d72a23b913ca41bb5bb", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 1991, "upload_time": "2019-12-21T00:25:28", "upload_time_iso_8601": "2019-12-21T00:25:28.010154Z", "url": "https://files.pythonhosted.org/packages/4f/37/495584ed57eeb20943be430e2a27b91654bd53395f27d443056f7ce52e57/anjie-1.0.0.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:18:10 2020"}