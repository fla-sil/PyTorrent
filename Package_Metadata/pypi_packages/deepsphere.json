{"info": {"author": "Arcanite", "author_email": "contact@arcanite.ch", "bugtrack_url": null, "classifiers": [], "description": "# DeepSphere: a graph-based spherical CNN\n\n[![Documentation Status](https://readthedocs.org/projects/deepsphere/badge/?version=latest)](https://deepsphere.readthedocs.io/en/latest/?badge=latest)\n\nThis repository contains the PyTorch implementation of a novel methodology for applying [convolutional networks to spherical data through a graph-based discretization](https://openreview.net/pdf?id=B1e3OlStPB \"This link takes you to the DeepSphere paper which was accepted at ICLR 2020\").\n\n- [Data](#data)\n- [Quick Start](#quick-start)\n- [Mathematical Background](#mathematical-background)\n- [U-Net](#unet)\n- [Temporality](#communication)\n- [Metric](#metric)\n- [Tools](#tools)\n\n# Data\n\nThe data used for the experiments contains a [downsampled](http://island.me.berkeley.edu/ugscnn/data/climate_sphere_l5.zip \"This link lets you download the downsampled dataset (~30 Gb). This can also be done using the script, described further down.\")\nsnapshot of the [Community Atmospheric Model v5 (CAM5)](https://portal.nersc.gov/project/dasrepo/deepcam/segm_h5_v3_reformat/gb_data_readme \"This link takes you to the page where the full dataset can be downloaded and where more information is provided concerning the data.\")\n simulation. The simulation can be thought of as a 16 channel \"image\", where each channel corresponds to a climate related measurement.\nThe task is to learn how to infer the correct class for each pixel given the 16 channels. Each pixel is labelled either as background, as being part of a tropical cyclone or as being part of an atmospheric river.\n\n![alt text](images/AR_TC_image.png \"Background class is visualized in red, tropical cyclones in green and atmospheric rivers in blue.\")\n\n# Quick Start\n\nIn order to reproduce the results obtained, it is necessary to install the PyGSP branch containing the graph processing for equiangular, icosahedron, and healpix samplings. In future versions, PyGSP will be in the requirements. Subsequently, please refer yourself to the [Pytorch Getting Started information page](https://pytorch.org/get-started/locally/) to run the correct `conda install` command corresponding to your operating system, python version and cuda version.\nOnce those requirements are met, you can install the `deepsphere` package in your environment.\n\nOur recommendation for a linux based machine is:\n\n```\nconda create --name deepsphere python=3.7\n\nsource activate deepsphere\n\npip install git+https://github.com/Droxef/pygsp.git@6b216395beae25bf062d13fbf9abc251eeb5bbff#egg=PyGSP\n\nconda install pytorch=1.3.1 torchvision=0.4.2 cudatoolkit=10.0 -c pytorch\n\npip install deepsphere\n```\n\nThe package offers the experiment parameters stored in a [Yaml config file](./scripts/config.example.yml), which can be used by running a [script](./scripts/run_ar_tc_ignite.py) from the command line.\n\nA special note should be made for the pytorch computation device. If nothing is stipulated in the command line, the device is set to CPU. To set the device to GPU (cuda) one can indicate `\u2014gpu` in the command line, with or without the desired GPU device IDs (e.g. `--gpu 1 2`, if the model is supposed to run on the GPU 1 and 2).\n\nTo visualize any icosahedron or equiangular data the package provides a demonstration [Jupyter notebook](./notebooks/demo_visualization.ipynb) for data in 2D or 3D.\n\nUsing the predefined parameters you can train and validate the model using the following command:\n```\npython run_ar_tc.py --config-file config.example.yml --gpu\n```\n\nIf you don't have the data yet, please add create the folder ```/data/climate/``` (or change the file location in the yaml file) and add ```download True``` to the command.\n# Mathematical Background\n\nThe Deepsphere package uses the manifold of the sphere to perform the convolutions on the data. Underlying the application of convolutional networks to spherical data through a graph-based discretization lies the field of Graph Signal Processing (GSP). Graph Signal Processing is a field trying to define classical spectral methods on graphs, similarly to the theories existing in the time domain.\n\nThis section attempts to give the key concepts of the sphere manifold in the form of a graph, and how manipulating the data in the eigenvector space allows an optimal convolution operation on the sphere. For an in-depth introduction to the topic, see for example [Graph Signal Processing: Overview, Challenges and Applications (2017)](https://arxiv.org/abs/1712.00468) or [The Emerging Field of Signal Processing on Graphs (2012)](https://arxiv.org/abs/1211.0053). For simpler introductions to the matter, you may refer to [Chapter 1.2 of J. Paratte's PhD Thesis](https://infoscience.epfl.ch/record/231710?ln=en) or [Chapter 2.1 of L. Martin's PhD Thesis](https://infoscience.epfl.ch/record/234372?ln=en).\nFor an introduction to graph convolutions in the context of neural networks see for example [Convolutional neural networks on graphs with fast localized spectral filtering (2016)](http://papers.nips.cc/paper/6081-convolutional-neural-networks-on-graphs-with-fast-localized-spectral-filtering).\n\nFollowing GSP paradigms, the convolution operator defined on graphs can be computed simply with a multiplication in the correct domain, just like classical signal processing. Indeed, in traditional signal processing, filtering (i.e., convolution) can be carried out by a pointwise multiplication as long as the signal is transformed to the Fourier domain. Thus, given a graph signal, we define its graph Fourier transform as the projection of the signal onto the set of eigenvectors of the graph Laplacian:\n\n![alt text](images/equations/xhat.gif),\n\nwhere *U* and *\u039b* are the results of the eigendecomposition of the Laplacian, i.e. ![alt text](images/equations/L_eq.gif) .\n\nTo bring the data to the spectral domain several Laplacians could be used. We decide here that we select the combinatorial Laplacian,![alt text](images/equations/Lc.gif), which is simply defined as:\n\n![alt text](images/equations/Lc_eq.gif),\n\nwhere *W* is the weighted adjacency matrix of the graph and *D* is the diagonal matrix composed of the degrees, the sum of the weights of all the edges for each node, on its diagonal.\n\nFiltering, the convolution operator, is defined to this end via a graph filter called *g*, a continuous function directly in the graph Fourier domain, enabling the direct multiplication. Based on the definition of the graph Fourier domain, we can then rewrite the graph filtering equation as a vector-matrix operation in the original domain (the graph domain):\n\n![alt text](images/equations/y_eq.gif).\n\nHowever, the filtering equation defined above involves the knowledge of the full set of eigenvectors U. Hence it implies the diagonalization of the Laplacian L which is extremely costly for large graphs. To circumvent this problem, one can represent the filter g as a polynomial approximation: the n-degree Chebyshev polynomials. The relation between the graph filter *g(L)*, the graph signal *x*, and the Chebyshev polynomials lies in the approximation:\n\n![alt text](images/equations/poly_eq.gif),\n\nwhere *c_m* are the coefficients of the approximation and describe entirely the shape of the graph filter *g*.\n\nSince the Chebyshev polynomials of the first-kind are defined with the recurrence relation, the computation of the approximation is very efficient compared to diagonalization of L since it simply requires the computation of:\n\n![alt text](images/equations/Tm_recursive.gif),\n\nwhere ![alt text](images/equations/T0.gif) and ![alt text](images/equations/T1.gif).\n\nThus, learning the weights of the polynomial approximations makes it possible to learn generic graph filters. The convolution on a spherical graph comes down to backpropagating to tune the weights of the Chebyshev polynomials.\n\n# Unet\n\nThe architecture used for the deep learning model is a classic [U-Net](https://arxiv.org/pdf/1505.04597.pdf). The poolings and unpoolings used correspond to three types of possible spherical samplings: [icosahedron](https://git.arcanite.ch/interns/climate/deepsphere/blob/5-temporality/deepsphere/layers/samplings/icosahedron_pool_unpool.py), [healpix](https://git.arcanite.ch/interns/climate/deepsphere/blob/5-temporality/deepsphere/layers/samplings/healpix_pool_unpool.py) and [equiangular](https://git.arcanite.ch/interns/climate/deepsphere/blob/5-temporality/deepsphere/layers/samplings/equiangular_pool_unpool.py).\n\n# Temporality\n\nBeyond reproducing in pytorch the ARTC experiment, we introduced a new dimension to our package: temporality. We did so following two approaches. First, we combined the U-Net with a recurrent neural network ([LSTM](https://en.wikipedia.org/wiki/Long_short-term_memory)) as presented in [Recurrent Fully Convolutional Network for Video Segmentation](https://arxiv.org/pdf/1606.00487v2.pdf).\nSecondly we augmented the feature space of the U-Net, thus taking more than one sample as an input.\n\n# Metric\nThe metric used to evaluate the performance of the model is the mean of the [average precision](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html) of the classes \"Atmospheric River\" and \"Tropical Cyclone\". Only around 2% of the data is labelled as an atmospheric river and 0.1% of the data is labelled as a tropical cyclone. For such unbalanced datasets the average precision is an appropriate metric.\nThe average precision metric allows to circumvent to some extent the trade-off between precision and recall performance. Average precision computes the average precision value for recall values over the interval 0 to 1. In other words it measures the area under the Precision-Recall Curve in a piecewise constant discretization manner. For the model, using average precision over each class/label type gives a sense of how well the model's detection is performed in the case of an unbalanced dataset.\n\n# Tools\n- Ignite\n\nIgnite provides a clean training-valdiation-testing loop. Through ignite, engines corresponding to a trainer, validator and tester for the model can be created. Properties of these engines can be set using Handlers. For example, the trainer can have a handler to print certain information during training, and the validator can have a handler to log the metrics or a handler to change the learning rate based on the metrics of the epoch.\n\n- Tensorboard\n\nTensorboard allows to log metrics, training loss and learning rate rhythms. In the script, one can create a Summary Writer and attach to this object diverse saving options.\n\n- Visualizations\n\nVisualizations are possible in 2D and 3D. The 2D representation is a flattened version of the sphere with a 2D projection of the sampling used (at the moment, this is possible for the icosahedron and equiangular samplings). The 3D gif rendering allows to represent the lables on a turning world sphere. Finally, an interactive plotting notebook is also presented as an inspiration for interactive plots. It allows to plot the metrics at a point in training (for a certain epoch), alongside the predicted labels plotted in 2D. This prediction is opposed to the plot of the ground truths in 2D.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "deepsphere", "package_url": "https://pypi.org/project/deepsphere/", "platform": "", "project_url": "https://pypi.org/project/deepsphere/", "project_urls": null, "release_url": "https://pypi.org/project/deepsphere/0.2.1/", "requires_dist": null, "requires_python": "", "summary": "Deep Sphere package", "version": "0.2.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>DeepSphere: a graph-based spherical CNN</h1>\n<p><a href=\"https://deepsphere.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/370271cbf03ba08d5df49543315f90c4ec859206/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f646565707370686572652f62616467652f3f76657273696f6e3d6c6174657374\"></a></p>\n<p>This repository contains the PyTorch implementation of a novel methodology for applying <a href=\"https://openreview.net/pdf?id=B1e3OlStPB\" rel=\"nofollow\" title=\"This link takes you to the DeepSphere paper which was accepted at ICLR 2020\">convolutional networks to spherical data through a graph-based discretization</a>.</p>\n<ul>\n<li><a href=\"#data\" rel=\"nofollow\">Data</a></li>\n<li><a href=\"#quick-start\" rel=\"nofollow\">Quick Start</a></li>\n<li><a href=\"#mathematical-background\" rel=\"nofollow\">Mathematical Background</a></li>\n<li><a href=\"#unet\" rel=\"nofollow\">U-Net</a></li>\n<li><a href=\"#communication\" rel=\"nofollow\">Temporality</a></li>\n<li><a href=\"#metric\" rel=\"nofollow\">Metric</a></li>\n<li><a href=\"#tools\" rel=\"nofollow\">Tools</a></li>\n</ul>\n<h1>Data</h1>\n<p>The data used for the experiments contains a <a href=\"http://island.me.berkeley.edu/ugscnn/data/climate_sphere_l5.zip\" rel=\"nofollow\" title=\"This link lets you download the downsampled dataset (~30 Gb). This can also be done using the script, described further down.\">downsampled</a>\nsnapshot of the <a href=\"https://portal.nersc.gov/project/dasrepo/deepcam/segm_h5_v3_reformat/gb_data_readme\" rel=\"nofollow\" title=\"This link takes you to the page where the full dataset can be downloaded and where more information is provided concerning the data.\">Community Atmospheric Model v5 (CAM5)</a>\nsimulation. The simulation can be thought of as a 16 channel \"image\", where each channel corresponds to a climate related measurement.\nThe task is to learn how to infer the correct class for each pixel given the 16 channels. Each pixel is labelled either as background, as being part of a tropical cyclone or as being part of an atmospheric river.</p>\n<p><img alt=\"alt text\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2112df15017340c4dc65ad4e491121e543f577b4/696d616765732f41525f54435f696d6167652e706e67\"></p>\n<h1>Quick Start</h1>\n<p>In order to reproduce the results obtained, it is necessary to install the PyGSP branch containing the graph processing for equiangular, icosahedron, and healpix samplings. In future versions, PyGSP will be in the requirements. Subsequently, please refer yourself to the <a href=\"https://pytorch.org/get-started/locally/\" rel=\"nofollow\">Pytorch Getting Started information page</a> to run the correct <code>conda install</code> command corresponding to your operating system, python version and cuda version.\nOnce those requirements are met, you can install the <code>deepsphere</code> package in your environment.</p>\n<p>Our recommendation for a linux based machine is:</p>\n<pre><code>conda create --name deepsphere python=3.7\n\nsource activate deepsphere\n\npip install git+https://github.com/Droxef/pygsp.git@6b216395beae25bf062d13fbf9abc251eeb5bbff#egg=PyGSP\n\nconda install pytorch=1.3.1 torchvision=0.4.2 cudatoolkit=10.0 -c pytorch\n\npip install deepsphere\n</code></pre>\n<p>The package offers the experiment parameters stored in a <a href=\"./scripts/config.example.yml\" rel=\"nofollow\">Yaml config file</a>, which can be used by running a <a href=\"./scripts/run_ar_tc_ignite.py\" rel=\"nofollow\">script</a> from the command line.</p>\n<p>A special note should be made for the pytorch computation device. If nothing is stipulated in the command line, the device is set to CPU. To set the device to GPU (cuda) one can indicate <code>\u2014gpu</code> in the command line, with or without the desired GPU device IDs (e.g. <code>--gpu 1 2</code>, if the model is supposed to run on the GPU 1 and 2).</p>\n<p>To visualize any icosahedron or equiangular data the package provides a demonstration <a href=\"./notebooks/demo_visualization.ipynb\" rel=\"nofollow\">Jupyter notebook</a> for data in 2D or 3D.</p>\n<p>Using the predefined parameters you can train and validate the model using the following command:</p>\n<pre><code>python run_ar_tc.py --config-file config.example.yml --gpu\n</code></pre>\n<p>If you don't have the data yet, please add create the folder <code>/data/climate/</code> (or change the file location in the yaml file) and add <code>download True</code> to the command.</p>\n<h1>Mathematical Background</h1>\n<p>The Deepsphere package uses the manifold of the sphere to perform the convolutions on the data. Underlying the application of convolutional networks to spherical data through a graph-based discretization lies the field of Graph Signal Processing (GSP). Graph Signal Processing is a field trying to define classical spectral methods on graphs, similarly to the theories existing in the time domain.</p>\n<p>This section attempts to give the key concepts of the sphere manifold in the form of a graph, and how manipulating the data in the eigenvector space allows an optimal convolution operation on the sphere. For an in-depth introduction to the topic, see for example <a href=\"https://arxiv.org/abs/1712.00468\" rel=\"nofollow\">Graph Signal Processing: Overview, Challenges and Applications (2017)</a> or <a href=\"https://arxiv.org/abs/1211.0053\" rel=\"nofollow\">The Emerging Field of Signal Processing on Graphs (2012)</a>. For simpler introductions to the matter, you may refer to <a href=\"https://infoscience.epfl.ch/record/231710?ln=en\" rel=\"nofollow\">Chapter 1.2 of J. Paratte's PhD Thesis</a> or <a href=\"https://infoscience.epfl.ch/record/234372?ln=en\" rel=\"nofollow\">Chapter 2.1 of L. Martin's PhD Thesis</a>.\nFor an introduction to graph convolutions in the context of neural networks see for example <a href=\"http://papers.nips.cc/paper/6081-convolutional-neural-networks-on-graphs-with-fast-localized-spectral-filtering\" rel=\"nofollow\">Convolutional neural networks on graphs with fast localized spectral filtering (2016)</a>.</p>\n<p>Following GSP paradigms, the convolution operator defined on graphs can be computed simply with a multiplication in the correct domain, just like classical signal processing. Indeed, in traditional signal processing, filtering (i.e., convolution) can be carried out by a pointwise multiplication as long as the signal is transformed to the Fourier domain. Thus, given a graph signal, we define its graph Fourier transform as the projection of the signal onto the set of eigenvectors of the graph Laplacian:</p>\n<p><img alt=\"alt text\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2097114ff0ca39f956850c831a8b4669b473d78a/696d616765732f6571756174696f6e732f786861742e676966\">,</p>\n<p>where <em>U</em> and <em>\u039b</em> are the results of the eigendecomposition of the Laplacian, i.e. <img alt=\"alt text\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e3ef1fb924d11c512a9a4df78a5e17c408d8385d/696d616765732f6571756174696f6e732f4c5f65712e676966\"> .</p>\n<p>To bring the data to the spectral domain several Laplacians could be used. We decide here that we select the combinatorial Laplacian,<img alt=\"alt text\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/24b1739b6425d09870353872c0414527ad5cb2b9/696d616765732f6571756174696f6e732f4c632e676966\">, which is simply defined as:</p>\n<p><img alt=\"alt text\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/015b2cd5f0f59e538bc0853e7520942e76bab201/696d616765732f6571756174696f6e732f4c635f65712e676966\">,</p>\n<p>where <em>W</em> is the weighted adjacency matrix of the graph and <em>D</em> is the diagonal matrix composed of the degrees, the sum of the weights of all the edges for each node, on its diagonal.</p>\n<p>Filtering, the convolution operator, is defined to this end via a graph filter called <em>g</em>, a continuous function directly in the graph Fourier domain, enabling the direct multiplication. Based on the definition of the graph Fourier domain, we can then rewrite the graph filtering equation as a vector-matrix operation in the original domain (the graph domain):</p>\n<p><img alt=\"alt text\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c4fbbebfeb9fb7e1e5d08bcdb4a4796995d253ac/696d616765732f6571756174696f6e732f795f65712e676966\">.</p>\n<p>However, the filtering equation defined above involves the knowledge of the full set of eigenvectors U. Hence it implies the diagonalization of the Laplacian L which is extremely costly for large graphs. To circumvent this problem, one can represent the filter g as a polynomial approximation: the n-degree Chebyshev polynomials. The relation between the graph filter <em>g(L)</em>, the graph signal <em>x</em>, and the Chebyshev polynomials lies in the approximation:</p>\n<p><img alt=\"alt text\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/885e4b1aa5ae1bee8979f0c7f1e19ffba2c25c9e/696d616765732f6571756174696f6e732f706f6c795f65712e676966\">,</p>\n<p>where <em>c_m</em> are the coefficients of the approximation and describe entirely the shape of the graph filter <em>g</em>.</p>\n<p>Since the Chebyshev polynomials of the first-kind are defined with the recurrence relation, the computation of the approximation is very efficient compared to diagonalization of L since it simply requires the computation of:</p>\n<p><img alt=\"alt text\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/68d6daf6bff2f35e6fc6faa500f001a6df76824b/696d616765732f6571756174696f6e732f546d5f7265637572736976652e676966\">,</p>\n<p>where <img alt=\"alt text\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/250120ed894ddb1c3bb94ab4059ffba4a3514084/696d616765732f6571756174696f6e732f54302e676966\"> and <img alt=\"alt text\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/cb7c247a6b9f244fea1eed68c317f40992581bba/696d616765732f6571756174696f6e732f54312e676966\">.</p>\n<p>Thus, learning the weights of the polynomial approximations makes it possible to learn generic graph filters. The convolution on a spherical graph comes down to backpropagating to tune the weights of the Chebyshev polynomials.</p>\n<h1>Unet</h1>\n<p>The architecture used for the deep learning model is a classic <a href=\"https://arxiv.org/pdf/1505.04597.pdf\" rel=\"nofollow\">U-Net</a>. The poolings and unpoolings used correspond to three types of possible spherical samplings: <a href=\"https://git.arcanite.ch/interns/climate/deepsphere/blob/5-temporality/deepsphere/layers/samplings/icosahedron_pool_unpool.py\" rel=\"nofollow\">icosahedron</a>, <a href=\"https://git.arcanite.ch/interns/climate/deepsphere/blob/5-temporality/deepsphere/layers/samplings/healpix_pool_unpool.py\" rel=\"nofollow\">healpix</a> and <a href=\"https://git.arcanite.ch/interns/climate/deepsphere/blob/5-temporality/deepsphere/layers/samplings/equiangular_pool_unpool.py\" rel=\"nofollow\">equiangular</a>.</p>\n<h1>Temporality</h1>\n<p>Beyond reproducing in pytorch the ARTC experiment, we introduced a new dimension to our package: temporality. We did so following two approaches. First, we combined the U-Net with a recurrent neural network (<a href=\"https://en.wikipedia.org/wiki/Long_short-term_memory\" rel=\"nofollow\">LSTM</a>) as presented in <a href=\"https://arxiv.org/pdf/1606.00487v2.pdf\" rel=\"nofollow\">Recurrent Fully Convolutional Network for Video Segmentation</a>.\nSecondly we augmented the feature space of the U-Net, thus taking more than one sample as an input.</p>\n<h1>Metric</h1>\n<p>The metric used to evaluate the performance of the model is the mean of the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html\" rel=\"nofollow\">average precision</a> of the classes \"Atmospheric River\" and \"Tropical Cyclone\". Only around 2% of the data is labelled as an atmospheric river and 0.1% of the data is labelled as a tropical cyclone. For such unbalanced datasets the average precision is an appropriate metric.\nThe average precision metric allows to circumvent to some extent the trade-off between precision and recall performance. Average precision computes the average precision value for recall values over the interval 0 to 1. In other words it measures the area under the Precision-Recall Curve in a piecewise constant discretization manner. For the model, using average precision over each class/label type gives a sense of how well the model's detection is performed in the case of an unbalanced dataset.</p>\n<h1>Tools</h1>\n<ul>\n<li>Ignite</li>\n</ul>\n<p>Ignite provides a clean training-valdiation-testing loop. Through ignite, engines corresponding to a trainer, validator and tester for the model can be created. Properties of these engines can be set using Handlers. For example, the trainer can have a handler to print certain information during training, and the validator can have a handler to log the metrics or a handler to change the learning rate based on the metrics of the epoch.</p>\n<ul>\n<li>Tensorboard</li>\n</ul>\n<p>Tensorboard allows to log metrics, training loss and learning rate rhythms. In the script, one can create a Summary Writer and attach to this object diverse saving options.</p>\n<ul>\n<li>Visualizations</li>\n</ul>\n<p>Visualizations are possible in 2D and 3D. The 2D representation is a flattened version of the sphere with a 2D projection of the sampling used (at the moment, this is possible for the icosahedron and equiangular samplings). The 3D gif rendering allows to represent the lables on a turning world sphere. Finally, an interactive plotting notebook is also presented as an inspiration for interactive plots. It allows to plot the metrics at a point in training (for a certain epoch), alongside the predicted labels plotted in 2D. This prediction is opposed to the plot of the ground truths in 2D.</p>\n\n          </div>"}, "last_serial": 7076946, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "24b8384c16649614702048cbc7482273", "sha256": "95272d37c9465320ff23956ac1206f818ca137dac9340ef9cf66f770a06e7feb"}, "downloads": -1, "filename": "deepsphere-0.1.0.tar.gz", "has_sig": false, "md5_digest": "24b8384c16649614702048cbc7482273", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27856, "upload_time": "2020-02-13T16:25:48", "upload_time_iso_8601": "2020-02-13T16:25:48.003591Z", "url": "https://files.pythonhosted.org/packages/06/68/895b4970d1b91e9668a2e7b0c7ee30479c57718ad263adc3e9154735a4b4/deepsphere-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "190d929943eb98b8525bb0cbe12d334f", "sha256": "fabeee36e75ad835d165e465a5c7ce8f7846d5daa70b41cec8f844dfe699c860"}, "downloads": -1, "filename": "deepsphere-0.1.1.tar.gz", "has_sig": false, "md5_digest": "190d929943eb98b8525bb0cbe12d334f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7592432, "upload_time": "2020-02-14T13:28:51", "upload_time_iso_8601": "2020-02-14T13:28:51.202574Z", "url": "https://files.pythonhosted.org/packages/3c/3d/45423bebeefd1606d353d94c7fedf9bc220e761929569071cb4720bfc086/deepsphere-0.1.1.tar.gz", "yanked": false}], "0.1.10": [{"comment_text": "", "digests": {"md5": "ea325dba7ed0fe3620939704724b06b0", "sha256": "af72ab074a90c10e121867d4af6d538046605ed38ba06babecbaf207ad04bc2b"}, "downloads": -1, "filename": "deepsphere-0.1.10.tar.gz", "has_sig": false, "md5_digest": "ea325dba7ed0fe3620939704724b06b0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7592438, "upload_time": "2020-02-14T15:54:42", "upload_time_iso_8601": "2020-02-14T15:54:42.315247Z", "url": "https://files.pythonhosted.org/packages/12/77/9e76f8b447dacca22a8174aa4884c564358cb875d54a5c1ac76428ef821e/deepsphere-0.1.10.tar.gz", "yanked": false}], "0.1.11": [{"comment_text": "", "digests": {"md5": "17beda3ac9ebb76efeee4374558538a7", "sha256": "dba4e566739780971b0cd1eeacd8c5e98d13acdb4ee791c576d2b78382136abf"}, "downloads": -1, "filename": "deepsphere-0.1.11.tar.gz", "has_sig": false, "md5_digest": "17beda3ac9ebb76efeee4374558538a7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7597098, "upload_time": "2020-04-10T01:50:27", "upload_time_iso_8601": "2020-04-10T01:50:27.858420Z", "url": "https://files.pythonhosted.org/packages/93/2e/b5831b616a2164870687d4832cbe762987fccb229d7991a46e5a1587372e/deepsphere-0.1.11.tar.gz", "yanked": false}], "0.1.12": [{"comment_text": "", "digests": {"md5": "2c680896d831a7c719bd84814873978f", "sha256": "fe623d6bfcda108f5e025d0f5402ab0791bfaf4c242ba99f86660bc21abbd00d"}, "downloads": -1, "filename": "deepsphere-0.1.12.tar.gz", "has_sig": false, "md5_digest": "2c680896d831a7c719bd84814873978f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7597106, "upload_time": "2020-04-13T14:51:14", "upload_time_iso_8601": "2020-04-13T14:51:14.245243Z", "url": "https://files.pythonhosted.org/packages/2c/b7/305d0c5571c0ec2c7d08fdc624178caa0ddb4a19ea40c71dc7be95b01e14/deepsphere-0.1.12.tar.gz", "yanked": false}], "0.1.13": [{"comment_text": "", "digests": {"md5": "06b5e9af9fa4c9497ebd168d709311c5", "sha256": "34c0d4d384aa41bc97c3529298918fcbfa4430c2af0e6c52d843e310500e42b6"}, "downloads": -1, "filename": "deepsphere-0.1.13.tar.gz", "has_sig": false, "md5_digest": "06b5e9af9fa4c9497ebd168d709311c5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7597291, "upload_time": "2020-04-13T16:07:50", "upload_time_iso_8601": "2020-04-13T16:07:50.615904Z", "url": "https://files.pythonhosted.org/packages/5d/22/05e2593238d5c01720f2a963612048fe0216d171f751a067569fa5f59bed/deepsphere-0.1.13.tar.gz", "yanked": false}], "0.1.5": [{"comment_text": "", "digests": {"md5": "38341d20dd83ef1bb4ac33adb4312eb4", "sha256": "a7f4edc8350996552b3089dc43971fb0c70be9f16cddf8c1aa6bcff19f9c7518"}, "downloads": -1, "filename": "deepsphere-0.1.5.tar.gz", "has_sig": false, "md5_digest": "38341d20dd83ef1bb4ac33adb4312eb4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7592506, "upload_time": "2020-02-14T14:12:07", "upload_time_iso_8601": "2020-02-14T14:12:07.592015Z", "url": "https://files.pythonhosted.org/packages/86/c6/7fc0728005ba90c5bbaed9e71ae715ebc2235f950d25c9b1099170cacbe3/deepsphere-0.1.5.tar.gz", "yanked": false}], "0.1.6": [{"comment_text": "", "digests": {"md5": "f2ab0a91364907d77169c7c0453f1fc5", "sha256": "137de1bbac856cffa1e2e32346d57c07d14dc3534bd080b638ee84573ec57e0f"}, "downloads": -1, "filename": "deepsphere-0.1.6.tar.gz", "has_sig": false, "md5_digest": "f2ab0a91364907d77169c7c0453f1fc5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7592512, "upload_time": "2020-02-14T14:36:01", "upload_time_iso_8601": "2020-02-14T14:36:01.023644Z", "url": "https://files.pythonhosted.org/packages/e1/91/2d3d7031f7468ffceb773f9879c8c9e5e31a91c4a55fe556ea3343cd4e9c/deepsphere-0.1.6.tar.gz", "yanked": false}], "0.1.7": [{"comment_text": "", "digests": {"md5": "caa8fb749b2bfbcb64ab16e17bf8a323", "sha256": "589c5425b2b4b33185ba2fc867b44595c6003f5f60e37bda78e58171bd2e6cf4"}, "downloads": -1, "filename": "deepsphere-0.1.7.tar.gz", "has_sig": false, "md5_digest": "caa8fb749b2bfbcb64ab16e17bf8a323", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7592521, "upload_time": "2020-02-14T14:55:07", "upload_time_iso_8601": "2020-02-14T14:55:07.129999Z", "url": "https://files.pythonhosted.org/packages/48/99/c4c8be9cdf59bdc5b4d3b4df9387966d6f15b68af86a5ff2a7d1efb5f5d1/deepsphere-0.1.7.tar.gz", "yanked": false}], "0.1.8": [{"comment_text": "", "digests": {"md5": "c00caac20557a2e8b932f31bb9276724", "sha256": "068b2e5a8b0dfb428760efff1358d11650ab50550346ad4ebcf842afa1718be3"}, "downloads": -1, "filename": "deepsphere-0.1.8.tar.gz", "has_sig": false, "md5_digest": "c00caac20557a2e8b932f31bb9276724", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7592442, "upload_time": "2020-02-14T15:28:23", "upload_time_iso_8601": "2020-02-14T15:28:23.922577Z", "url": "https://files.pythonhosted.org/packages/64/0d/f63dfedc6b67527ef579e08b9dfd00e8ec1567238a0f4da11a2102f9f1cf/deepsphere-0.1.8.tar.gz", "yanked": false}], "0.1.9": [{"comment_text": "", "digests": {"md5": "202d3b86e07c55603d356d72318059e8", "sha256": "3cabb29fd10795e598a6b609b98b1dde6efcf1a25562d48c6347d38713ffc531"}, "downloads": -1, "filename": "deepsphere-0.1.9.tar.gz", "has_sig": false, "md5_digest": "202d3b86e07c55603d356d72318059e8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7592459, "upload_time": "2020-02-14T15:46:23", "upload_time_iso_8601": "2020-02-14T15:46:23.716028Z", "url": "https://files.pythonhosted.org/packages/36/16/01f8e5a741941b9a1f70b7d159494be18b250a56d34a7d6dd0e889ea28cb/deepsphere-0.1.9.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "7f651c297f7fe003cebb05e1ee93f2fc", "sha256": "d2801c01de0f31db8e95321af6e31560bf0c5769d1de9fc5cd4f1026a59d176c"}, "downloads": -1, "filename": "deepsphere-0.2.0.tar.gz", "has_sig": false, "md5_digest": "7f651c297f7fe003cebb05e1ee93f2fc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7597317, "upload_time": "2020-04-15T09:04:18", "upload_time_iso_8601": "2020-04-15T09:04:18.718661Z", "url": "https://files.pythonhosted.org/packages/25/be/877b445c6d7750dc6521ca824883d4b5b1751371d399a9bcc2768419f621/deepsphere-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "a8d3ba2623bca5fbdcfe0572e3ca5730", "sha256": "afaafab3e6c04d5550c3eda621b098dc0c53de67c27c026537ef2f38739b5bd7"}, "downloads": -1, "filename": "deepsphere-0.2.1.tar.gz", "has_sig": false, "md5_digest": "a8d3ba2623bca5fbdcfe0572e3ca5730", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7597334, "upload_time": "2020-04-22T14:35:18", "upload_time_iso_8601": "2020-04-22T14:35:18.660996Z", "url": "https://files.pythonhosted.org/packages/87/63/46fd47ea87332de6866dacde0c0940ed0342f51227264b42f210ff4c456c/deepsphere-0.2.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "a8d3ba2623bca5fbdcfe0572e3ca5730", "sha256": "afaafab3e6c04d5550c3eda621b098dc0c53de67c27c026537ef2f38739b5bd7"}, "downloads": -1, "filename": "deepsphere-0.2.1.tar.gz", "has_sig": false, "md5_digest": "a8d3ba2623bca5fbdcfe0572e3ca5730", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7597334, "upload_time": "2020-04-22T14:35:18", "upload_time_iso_8601": "2020-04-22T14:35:18.660996Z", "url": "https://files.pythonhosted.org/packages/87/63/46fd47ea87332de6866dacde0c0940ed0342f51227264b42f210ff4c456c/deepsphere-0.2.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:39:19 2020"}