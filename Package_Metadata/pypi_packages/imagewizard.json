{"info": {"author": "Swaroop Padala", "author_email": "soupspring47@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "License :: OSI Approved :: MIT License", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "imagewizard\n-----------\n\nSource hosted at github: https://github.com/PriceSpider-NeuIntel/imagewizard/\n\nimagewizard is a python based library for performing various image manipulations and operations,\n\n1. `Image Hashing <https://github.com/PriceSpider-NeuIntel/imagewizard#image-hashing>`_\n      * `Average Hashing <https://github.com/PriceSpider-NeuIntel/imagewizard#average-hash-a-hash>`_\n      * `Distance Hashing <https://github.com/PriceSpider-NeuIntel/imagewizard#distance-hash-d-hash>`_\n      * `Perception Hashing <https://github.com/PriceSpider-NeuIntel/imagewizard#perception-hash-p-hash>`_\n      * `Wavelet Hashing <https://github.com/PriceSpider-NeuIntel/imagewizard#wavelet-hash-w-hash>`_\n\n2. `Image Similarity (hash distance computation) <https://github.com/PriceSpider-NeuIntel/imagewizard#image-similarity-hash-distance>`_\n      * `Hamming Distance <https://github.com/PriceSpider-NeuIntel/imagewizard#hamming-distance>`_\n      * `Cosine Distance <https://github.com/PriceSpider-NeuIntel/imagewizard#cosine-distance>`_\n      * `Euclidean Distance <https://github.com/PriceSpider-NeuIntel/imagewizard#euclidean-distance>`_\n      * `Manhattan Distance <https://github.com/PriceSpider-NeuIntel/imagewizard#manhattan-distance>`_\n      * `Jaccard Distance <https://github.com/PriceSpider-NeuIntel/imagewizard#jaccard-distance>`_\n      * `Minkowski Distance <https://github.com/PriceSpider-NeuIntel/imagewizard#minkowski-distance>`_\n\n3. `Image Processing and Transformations <https://github.com/PriceSpider-NeuIntel/imagewizard#image-processing--transformations>`_\n      * `Segmentation <https://github.com/PriceSpider-NeuIntel/imagewizard#segmentation>`_\n      * `Resize/scale <https://github.com/PriceSpider-NeuIntel/imagewizard#resize>`_\n      * `Convert to gray scale <https://github.com/PriceSpider-NeuIntel/imagewizard#gray-scale>`_\n      * `Rotate <https://github.com/PriceSpider-NeuIntel/imagewizard#rotate>`_\n      * `Crop <https://github.com/PriceSpider-NeuIntel/imagewizard#crop>`_\n      * `Mirror <https://github.com/PriceSpider-NeuIntel/imagewizard#mirror>`_\n      * `Blur <https://github.com/PriceSpider-NeuIntel/imagewizard#blur>`_\n      * `Luminosity (Brightness) <https://github.com/PriceSpider-NeuIntel/imagewizard#luminosity>`_\n      * `Skew <https://github.com/PriceSpider-NeuIntel/imagewizard#skew---perspective>`_\n         * `Perspective <https://github.com/PriceSpider-NeuIntel/imagewizard#skew---perspective>`_\n         * `Affine <https://github.com/PriceSpider-NeuIntel/imagewizard#skew---affine>`_\n\n4. `Image Analysis <https://github.com/PriceSpider-NeuIntel/imagewizard#image-analysis>`_\n      * `Dominant colors <https://github.com/PriceSpider-NeuIntel/imagewizard#dominant-colors>`_\n      * `Average/Mean Color <https://github.com/PriceSpider-NeuIntel/imagewizard#averagemean-color>`_\n      * `Frequent/Mode Color <https://github.com/PriceSpider-NeuIntel/imagewizard#frequent-color>`_\n      * `Trim/Crop to content <https://github.com/PriceSpider-NeuIntel/imagewizard#trimcrop-to-content>`_\n\nImage Hashing\n=============\n\nIntuition\n_________\n\nGiven an imput image, imagewizard can compute a hash for the image based on it visual appearance. It is understood that images that are perceptually similar must have similar hashes as well. The similarity here is a metric that we can choose to compute on, generally hamming distance is considered, but we can choose other distance metrics too.\nBy utilizing imagewizard we can find near-identical images in constant time, or at worst, O(log n).\n\nimagewizard supports the following hashing techniques:\n\n* average hashing (`a Hash`_)\n* perception hashing (`p Hash`_)\n* difference hashing (`d Hash`_)\n* wavelet hashing (`w Hash`_)\n\nBasic Usage\n___________\n\nLet's take a look at how we can implement image hashing using imagewizard. We will use PIL/Pillow and OpenCv2-python image libraries to read an image and get a 8x8 hash.\n\nStep 1: read an image file\n__________________________\n::\n\n\n>>> import cv2\n>>> from PIL import Image\n>>> pil_image = Image.open('test.png')\n>>> cv2_image = cv2.imread('test.png')\n\nStep 2: perform image hashing\n_____________________________\nRemember, if you are using opencv2 for reading an image file, the order of the color channels are *BGR* while that for a PIL Image its *RGB*. The channel information has to be passed as a parameter to the function while performing hashing. The default value of *order* is *RGB*\n\nimagewizard.Hashing()\n\n* .ahash(image, hash_size, order)\n* .dhash(image, hash_size, order)\n      * hamming distance between 0 - 10, would indicate the images being compared are similar\n* .phash(image, hash_size, order)\n* .whash(image, hash_size, order)\n\nParameters:\n\n* image      - must be a PIL instance image or numpy array in RGB or opencv image in BGR  \n* hash_size  - (integer) default 8 for 64 bit hash  \n* order      - (string) RGB, BGR: defaults to 'RGB' - input order of the colors. If using PIL to read an image, 'order' need not be specified. **If opencv is used to read an image, 'order' must be set to 'BGR'**\n\n>>> import imagewizard as iw\n>>> iw_hash = iw.Hashing()\n\nAverage hash (a hash)\n_____________________\n\n>>> a_hash_pil = iw_hash.ahash(image = pil_image, hash_size = 8, order = 'RGB')\n>>> a_hash_cv2 = iw_hash.ahash(image = cv2_image, hash_size = 8, order = 'BGR')\n\n>>> print(\"PIL a-hash: {}\".format(a_hash_pil))\nPIL a-hash: fefff80000000000\n>>> print(\"cv2 a-hash: {}\".format(a_hash_cv2))\ncv2 a-hash: fefff80000000000\n\nDistance hash (d hash)\n______________________\n\n* hamming distance between 0 - 10, would indicate the images being compared are similar\n\n>>> d_hash_pil = iw_hash.dhash(image = pil_image, hash_size = 8, order = 'RGB')\n>>> d_hash_cv2 = iw_hash.dhash(image = cv2_image, hash_size = 8, order = 'BGR')\n\n>>> print(\"PIL d-hash: {}\".format(a_hash_pil))\nPIL d-hash: 48b09035b16c9ccb\n>>> print(\"cv2 d-hash: {}\".format(a_hash_cv2))\ncv2 d-hash: 48b09035b16c9ccb\n\nPerception hash (p hash)\n________________________\n\n>>> p_hash_pil = iw_hash.phash(image = pil_image, hash_size = 8, order = 'RGB')\n>>> p_hash_cv2 = iw_hash.phash(image = cv2_image, hash_size = 8, order = 'BGR')\n\n>>> print(\"PIL p-hash: {}\".format(p_hash_pil))\nPIL p-hash: d0ddd594473657c0\n>>> print(\"cv2 p-hash: {}\".format(p_hash_cv2))\ncv2 p-hash: d0ddd594473657c0\n\nWavelet hash (w hash)\n_____________________\n\n>>> w_hash_pil = iw_hash.whash(image = pil_image, hash_size = 8, order = 'RGB')\n>>> w_hash_cv2 = iw_hash.whash(image = cv2_image, hash_size = 8, order = 'BGR')\n\n>>> print(\"PIL w-hash: {}\".format(w_hash_pil))\nPIL w-hash: fffffe90100e4420\n>>> print(\"cv2 w-hash: {}\".format(w_hash_cv2))\ncv2 w-hash: fffffe90100e4420\n\nFew other operations\n____________________\n\nTo get the hash value, simply cast the returned object to str,\n\n>>> hash_value1 = str(a_hash_cv2)\n>>> hash_value2 = str(a_hash_pil)\n\nYou can also find the hamming distance (the number of bit positions in which the two bits are different) by simply applying subtraction operation,\n\n>>> hash_diff = a_hash_pil - a_hash_pil\n>>> print(hash_diff)\n0\n\nSince the two hashes are of the same image, the hamming distance is 0. For more information on hamming distance - https://en.wikipedia.org/wiki/Hamming_distance\n\nIf you simply want to check if the two hashes are exact matches, you could do that too,\n\n>>> print(a_hash_pil == a_hash_cv2)\nTrue\n>>> print(a_hash_cv2 == d_hash_cv2)\nFalse\n\n\nImage Similarity (hash distance)\n================================\n\nNow that we have a hash corresponsding to an image, we can find how similar other images are, by comparing the hashes, i.e, finding the hash distances. Lower the values, more similar are the images.\nimagewizard provides various distance algorithms for computing hash distances between two hashes,\n\n>>> imagewizard.Similarity().similarity(hash1, hash2, metric = <metric>)\n\nThe <metric> value can be one of the following-\n\n* hamming\n* cosine\n* euclidean\n* manhattan\n* jaccard\n* minkowski\n\nBasic Usage\n___________\n\n>>> import imagewizard as iw\n>>> import cv2\n>>> iw_hash = iw.Hashing()\n>>> iw_similarity = iw.Similarity()\n\n>>> image1 = cv2.imread('test.png')\n>>> hash1_str = str(iw_hash.dhash(image1, order = 'BGR'))\n>>> image2 = cv2.imread('test2.png')\n>>> hash2_str = str(iw_hash.dhash(image2, order = 'BGR'))\n\nHamming distance\n________________\n>>> print(\"hamming: \", iw_similarity.similarity(hash1_str, hash2_str, metric = 'hamming'))\nhamming: 26\n\nCosine distance\n_______________\n>>> print(\"cosine: \", iw_similarity.similarity(hash1_str, hash2_str, metric = 'cosine'))\ncosine: 0.546\n\nEuclidean distance\n__________________\n>>> print(\"euclidean : {}\".format(iw_similarity.similarity(hash1_str, hash2_str, metric = 'euclidean')))\neuclidean : 5.0\n\nManhattan distance\n__________________\n>>> print(\"manhattan : {}\".format(iw_similarity.similarity(hash1_str, hash2_str, metric = 'manhattan')))\nmanhattan : 26\n\nJaccard distance\n________________\n>>> print(\"jaccard : {}\".format(iw_similarity.similarity(hash1_str, hash2_str, metric = 'jaccard')))\njaccard : 1.0\n\nMinkowski distance\n__________________\np value is set to 3 while computing minkowski distance\n\n>>> print(\"minkowski : {}\".format(iw_similarity.similarity(hash1_str, hash2_str, metric = 'minkowski')))\nminkowski : 2.924\n\nConcise explanation of `distance algorithms`_\n\n\nImage Processing & Transformations\n==================================\n\nimagewizard provides the following image processing and transformations\n\n* `Segmentation <https://github.com/PriceSpider-NeuIntel/imagewizard#segmentation>`_\n* `Resize/scale <https://github.com/PriceSpider-NeuIntel/imagewizard#resize>`_\n* `Convert to gray scale <https://github.com/PriceSpider-NeuIntel/imagewizard#gray-scale>`_\n* `Rotate <https://github.com/PriceSpider-NeuIntel/imagewizard#rotate>`_\n* `Crop <https://github.com/PriceSpider-NeuIntel/imagewizard#crop>`_\n* `Mirror <https://github.com/PriceSpider-NeuIntel/imagewizard#mirror>`_\n* `Blur <https://github.com/PriceSpider-NeuIntel/imagewizard#blur>`_\n* `Luminosity (Brightness) <https://github.com/PriceSpider-NeuIntel/imagewizard#luminosity>`_\n* `Skew <https://github.com/PriceSpider-NeuIntel/imagewizard#skew---perspective>`_\n      * `Perspective <https://github.com/PriceSpider-NeuIntel/imagewizard#skew---perspective>`_\n      * `Affine <https://github.com/PriceSpider-NeuIntel/imagewizard#skew---affine>`_\n\n\nSegmentation\n____________\n\nimagewizard provides methods for image segmentation, i.e, reconstructing a given image with a given set of colors alone. Every pixel in the original image is mapped to its nearest color from the set of colors and reconstructed.\nThe following code demonstrates image segmentation of the famous picture of lenna with three colors (RGB values),\n\n* [224 166 147]\n* [110  34  71]\n* [195  98 100]\n\n>>> imagewizard.Processing().segmentation(img, rgb_list: [[int]], order: str = 'rgb')\n\nParameters:\n\n* img: (numpy.array, PIL.image, cv2.image)\n* rgb_list: 2 dimensional np array with shape (n,3) 3 being the channel values in order RGB, eg: [[224, 166, 147], [110, 34, 71], [195, 98, 100]]\n* order: (RGB, BGR) input order of the colors BGR/RGB. Deafult order: RGB\n      Note: The output will be a numpy.array of the same order\n\n>>> cv_img = cv.imread('data/original_images/lenna.png')\n>>> pil_img = Image.open('data/original_images/lenna.png')\n>>> ip = imagewizard.Processing()\n>>> rgb_colors_list = [[224, 166, 147], [110, 34, 71], [195, 98, 100]]\n\n================ ================ ================\nColor 1          Color 2          Color 3\n================ ================ ================\n|cv_dom_c0|      |cv_dom_c1|      |cv_dom_c2|                        \n================ ================ ================\n\n>>> cv_result = ip.segmentation(cv_img, rgb_colors_list, 'bgr')\n>>> pil_result = ip.segmentation(pil_img, rgb_colors_list, 'rgb')\n>>> pil_res_im = Image.fromarray(pil_res)\n\n>>> cv2.imshow(\"original image\", cv_img)\n>>> cv2.imshow('Segmented Image', cv_result)\n>>> pil_res_im.show()\n\n===============  ===============\nOriginal         Segmented Image\n===============  ===============\n|lenna_org|      |segmented_im| \n===============  ===============\n\n\nResize\n______\n\nimagewizard provides methods to resize/scale an image to desired pixel (width x height),\n\n>>> imagewizard.Processing().resize(img, interpolation_method: str, resize_width: int, resize_height: int, resize_percentage: float, order: str = 'rgb')\n\nParameters:\n\n* img: (numpy.array, PIL.image, cv2.image)  \n* interpolation_method: (s, z) s/shrink or z/zoom; default to shrink  \n* resize_percentage: (0, 100) floating value. to resize image by the specified percentage              \n* resize_width, resize_height: (in pixels) if unspecified, defaults to 50% of original img width & height. If either only width or height is specified, the other dimension is scaled implicitly, to keep the aspect ratio intact.  \n      Note: these will be ignored if resize_percentage is specified  \n* order: (RGB, BGR) input order of the colors. If using PIL to read an image, 'order' need not be specified. **If opencv is used to read an image, 'order' must be set to 'BGR'**  \n      Note: The output will be a numpy.array of the same order  \n\nLets put resize to work on an image of the beautiful view outside Mumbai T2\n\n========  ======================================\nOriginal  50% of original - Aspect Ratio Intact\n========  ======================================\n|t2_img|      |t2_r3|    \n========  ======================================\n\n================ ====================================\n 300px by 300px   height: 200px - Aspect Ratio Intact\n================ ====================================\n |t2_r1|          |t2_r2|                            \n================ ====================================\n\n\n.. |t2_img| image:: tests/data/original_images/street.png \n   :width: 450\n\n\nResize Image to 50% height X width, keeping aspect ratio intact\n\n>>> img = cv2.imread('data/test.png')\n>>> ip = imagewizard.Processing()    \n>>> res = ip.resize(img, resize_percentage = 50, order = 'bgr')\n>>> cv2.imshow('Resized Image', res)\n\n.. |t2_r3| image:: tests/data/processed_images/resize/shrink-50-percent.png\n   :width: 60%\n\n\nResize Image to 300px by 300px\n\n>>> img = cv2.imread('data/test.png')\n>>> ip = imagewizard.Processing()    \n>>> res = ip.resize(img, resize_width=300, resize_height=300, order = 'bgr')\n>>> cv2.imshow('Resized Image', res)\n\n.. |t2_r1| image:: tests/data/processed_images/resize/shrink-300px-300px.png\n   :width: 100px\n   :height: 100px\n\n\nResize Image to height 200px, keeping aspect ratio intact\n\n>>> img = cv2.imread('data/test.png')\n>>> ip = imagewizard.Processing()    \n>>> res = ip.resize(img, resize_height=200, order = 'bgr')\n>>> cv2.imshow('Resized Image', res)\n\n.. |t2_r2| image:: tests/data/processed_images/resize/shrink-200px.png\n   :width: 60%\n\n\nGray scale\n__________\n\nimagewizard provides methods to convert a given color image to gray scale/inverted in various forms such as,\n\n* Inverted Colors\n* To Gray/Gray Inverted\n* To Binary/Binary Inverted\n* To Zero/Zero Inverted\n* To Truncated/Truncated Inverted\n\nimagewizard.Processing().img2grayscale(image, to_binary: bool, to_zero: bool, inverted: bool, trunc: bool, is_gray: bool, order: str)\n\nParameters:\n\n* img: (numpy.array, PIL.image, cv2.image)  \n* thresholding_options\n      * to_binary: (True/False) - defaults to False, converts the image to a complete black and white image without any shade of gray\n      * to_zero: (True/False) - defaults to False, converts an image to zero thresholding if set to True\n      * trunc: (True/False) - defaults to False, converts an image to truncated thresholding if set to True\n      * inverted: (True/False) - defaults to False, this parameter can be used along with any of the above parameter. If set to True, the colorspace will be inverted\n      * is_gray: (True/False) - defaults to True, if set to false and used along with ('inverted' == True) the colorspace of the image will be inverted\n\n      Note: the preference of the parameters follows - truc > to_binary > to_zero. The lower order parameter will be ignored in presence of a parameter with a greater preference. \n\n* order: (RGB, BGR) input order of the colors. If using PIL to read an image, 'order' need not be specified. **If opencv is used to read an image, 'order' must be set to 'BGR'**  \n      Note: The output will be a numpy.array of the same order  \n\nLet us use the famous picture of Lena, to demonstrate gray scaling.\n\n>>> import cv2\n>>> img = cv2.imread('original_image.png')\n>>> ip = imagewizard.Processing()\n\n>>> inverted_img = ip.img2grayscale(img, inverted=True, is_gray=False, order = 'bgr')\n>>> cv.imshow(\"inverted Image\", inverted_img)\n\n================ ================\nOriginal  \t\t Inverted  \t\t\n================ ================\n|lenna_org|      |clr_inv|     \n================ ================\n\n>>> gray_image = ip.img2grayscale(img, order = 'bgr')\n>>> cv2.imshow(\"Gray\", gray_image)\n\n>>> gray_inv_image = ip.img2grayscale(img, inverted=True, order = 'bgr')\n>>> cv.imshow(\"Gray Inverted\", gray_inv_image)\n\n================ ================ \nGray             Gray Inv            \n================ ================ \n|gray|      \t |gray_inv|      \t \n================ ================ \n\n>>> trunc_image = ip.img2grayscale(img, trunc=True, order = 'bgr')\n>>> cv.imshow(\"Trucated Threshold\", trunc_image)\n\n>>> trunc_inv_image = ip.img2grayscale(img, trunc=True, inverted=True, order = 'bgr')\n>>> cv.imshow(\"Trucated Threshold Inv\", trunc_inv_image)\n\n\n================ ================ \nTruncated        Truncated Inv\n================ ================\n|trunc|\t\t     |trunc_inv|\n================ ================\n\n\n>>> binary_image = ip.img2grayscale(img, to_binary=True, order = 'bgr')\n>>> cv2.imshow(\"Binary Threshold\", binary_image)\n\n>>> binary_inv_image = ip.img2grayscale(img, to_binary=True, inverted=True, order = 'bgr')\n>>> cv2.imshow(\"Binary Threshold Inverted\", binary_inv_image)\n\n================ ================  \nBinary           Binary Inv      \n================ ================ \n|bin_img|\t\t |bin_inv|\t  \t \n================ ================ \n\n\n>>> to_zero_image = ip.img2grayscale(img, to_zero=True, order = 'bgr')\n>>> cv2.imshow(\"To Zero\", to_zero_image)\n\n>>> to_zero_inverted = ip.img2grayscale(img, to_zero=True, inverted = True, order = 'bgr')\n>>> cv2.imshow(\"To Zero Inverted\", to_zero_inverted)\n\n================  ================\nTo Zero      \t   To Zero Inv\n================  ================\n|tz|\t \t\t      |tz_inv|\n================  ================\n\n\nRotate\n______\n\nimagewizard provides method to rotate a given image, with or without scaling. \nThe image provided is rotated in anti-clockwise direction by the rotation angle in degree specified.\n\n* ip.Processing().rotate(image, rotation_degree: float, scaling_factor: float, order: str)\n\nParameters:\n\n* image: (numpy.array, PIL.image, cv2.image)\n* rotation_degree: rotation angle (in degrees), the image will be rotate in anti-clockwise direction\n* scaling_factor: scale the image to desired factor. set to 1.0 to maintain the original scale of the image. 0.5 to halve the size of the image, to double the size of the image, use 2.0.\n* order: (RGB, BGR) input order of the colors. If using PIL to read an image, 'order' need not be specified. **If opencv is used to read an image, 'order' must be set to 'BGR'**\n\nFollowing code demonstrates rotation,\n\n>>> import cv2\n>>> img = cv2.imread('original_image.png')\n>>> ip = imagewizard.Processing()\n\n>>> rotate_by_90 = ip.rotate(img, rotation_degree = 90, order='bgr')\n>>> cv2.imshow(\"Rotate by 90 degrees\", rotate_by_90)\n\n>>> rotate_by_180 = ip.rotate(img, rotation_degree = 180, order='bgr')\n>>> cv2.imshow(\"Rotate by 180 degrees\", rotate_by_180)\n\n>>> rotate_by_270 = ip.rotate(img, rotation_degree = 270, order='bgr')\n>>> cv2.imshow(\"Rotate by 270 degrees\", rotate_by_270)\n\n>>> rotate_by_315_scale = ip.rotate(img, rotation_degree = 315, scaling_factor=0.5, order='bgr')\n>>> cv2.imshow(\"Rotate by 315 degrees, scale 0.5x\", rotate_by_315_scale)\n\n>>> rotate_by_45_scale = ip.rotate(img, rotation_degree = 45, scaling_factor=2, order='bgr')\n>>> cv2.imshow(\"Rotate by 45 degrees, scale 2x\", rotate_by_45_scale)    \n\n================  ================  ================\nOriginal      \t   90 deg            180 deg     \n================  ================  ================\n|lenna_org|       |90deg|           |180deg|        \n================  ================  ================\n\n\n================  =================  ===================\n270 deg       \t   45 deg, scale 2x   315 deg, scale 0.5x    \n================  =================  ===================\n|270deg|          |45degs|           |315degs|        \n================  =================  ===================\n\n\nCrop\n____ \n\nimagewizard lets you crop a given image. Provide the starting and ending, X and Y coordinates to crop the image to.\n\n>>> imagewizard.Processing().crop(img: Image, start_x: float, end_x: float, start_y: float, end_y: float, is_percentage: Bool, order: str)\n\nParameters:\n\n* img: (numpy.array, PIL.image, cv2.image)\n* start_x: starting pixel coordinate along the x-axis/width of the image\n* end_x: ending pixel coordinate along the x-axis/width of the image\n* start_y: starting pixle coordinate along the y-axis/height of the image\n* end_y: ending pixle coordinate along the y-axis/height of the image\n* is_percentage: if True, the coordinates will be considered as percentages, default: False\n* order: (RGB, BGR) input order of the colors. If using PIL to read an image, 'order' need not be specified. If opencv is used to read an image, 'order' must be set to 'BGR'\n\n>>> import cv2\n>>> img = cv2.imread('original_image.png')\n>>> ip = imagewizard.Processing()\n\n>>> crop1 = ip.crop(img, start_x = 50, end_x = 100, start_y = 50, end_y = 100, is_percentage = True, order='bgr')\n>>> cv2.imshow(\"Crop % (a)\", crop1)\n\n>>> crop2 = ip.crop(img, start_x = 400, end_x = 1000, start_y = 0, end_y = 500, is_percentage = False, order='bgr')\n>>> cv2.imshow(\"Crop by px\", crop2)\n\n>>> crop3 = ip.crop(img, start_x = 0, end_x = 50, start_y = 0, end_y = 50, is_percentage = True, order='bgr')\n>>> cv2.imshow(\"Crop % (b)\", crop3)\n\n================  =================  =================  ===================\nOriginal      \t   Crop % (a)         Crop by px         Crop % (b)       \n================  =================  =================  ===================\n|t2_img|          |crop1|            |crop2|            |crop3|            \n================  =================  =================  ===================\n\nMirror\n______ \n\nimagewizard provides methods to mirror/flip a given image. The image can be flipped around its X-axis or Y-axis or both X and Y axis by providing the flip_code parameter.\nThe following code demonstrates flipping around various axes.\n\n>>> imagewizard.Processing().mirror(img: Image, flip_code: int, order: str)\n\nParameters:\n\n* img: (numpy.array, PIL.image, cv2.image)\n* flip_code:  \n   * = 0 for flipping the image around the y-axis (vertical flipping);\n   * > 0 for flipping around the x-axis (horizontal flipping);\n   * < 0 for flipping around both axes\n* order: (RGB, BGR) input order of the colors. If using PIL to read an image, 'order' need not be specified. **If opencv is used to read an image, 'order' must be set to 'BGR'**\n\n>>> import cv2\n>>> img = cv2.imread('original_image.png')\n>>> ip = imagewizard.Processing()\n\n>>> mir_x = ip.mirror(img, flip_code=1, order='bgr')\n>>> cv.imshow('Horizontal Mirror (X)', mir_x)\n\n>>> mir_y = ip.mirror(img, flip_code=0, order='bgr')\n>>> cv.imshow('Vertical Mirror (Y)', mir_y)\n\n>>> mir_xy = ip.mirror(img, flip_code=-1, order='bgr')\n>>> cv.imshow('Mirrored both X and Y', mir_xy)\n\n========================  ========================  ========================  ========================\nOriginal      \t            Horizontal Mirror (X)     Vertical Mirror (Y)      Mirrored both X and Y \n========================  ========================  ========================  ========================\n|lenna_org|                |mir_x|                   |mir_y|                  |mir_xy|               \n========================  ========================  ========================  ========================\n\n\nBlur\n____\n\nimagewizard provides methods to blur a given image. The intensity of the blur can be passed as an argument to the function.\nThe following code demonstrates blurring.\n\n>>> imagewizard.Processing().blur(img: Image, blur_level: int, order: str)\n\nParameters:\n\n* img: (numpy.array, PIL.image, cv2.image)\n* blur_level: (int, > 0 and < 100,000) intensity of blur \n* order: (RGB, BGR) input order of the colors. If using PIL to read an image, 'order' need not be specified. **If opencv is used to read an image, 'order' must be set to 'BGR'**\n\n>>> import cv2\n>>> img = cv2.imread('original_image.png')\n>>> ip = imagewizard.Processing()\n\n>>> blur_5 = ip.blur(img, blur_level = 5, order='bgr')\n>>> cv.imshow('Blur level 5', blur_5)\n\n>>> blur_25 = ip.blur(img, blur_level = 25, order='bgr')\n>>> cv.imshow('Blur level 25', blur_25)\n\n>>> blur_50 = ip.blur(img, blur_level = 50, order='bgr')\n>>> cv.imshow('Blur level 50', blur_50)\n\n\n=============  =============  =============  =============\nOriginal       Blur level 5   Blur level 25  Blur level 50\n=============  =============  =============  =============\n|t2_img|       |blur_5|       |blur_25|      |blur_50|    \n=============  =============  =============  =============\n\n\nLuminosity\n__________\n\nimagewizard provides methods to change the luminosity/brightness of a given image. The intensity of the brightness can be passed as an argument to the function. A positive intensity value will brighten the image, whereas a negative value will darken the image.\nThe following code demonstrates changing the brightness levels.\n\n>>> imagewizard.Processing().luminosity(img: Image, intensity_shift: int, order: str)\n\nParameters:\n\n* img: (numpy.array, PIL.image, cv2.image)\n* intensity_shift: -ve value to darken and +ve value to brighten\n* order: (RGB, BGR) input order of the colors. If using PIL to read an image, 'order' need not be specified. **If opencv is used to read an image, 'order' must be set to 'BGR'**\n\n>>> import cv2\n>>> img = cv2.imread('original_image.png')\n>>> ip = imagewizard.Processing()\n\n>>> lum_100 = ip.luminosity(img, intensity_shift = 100, order = 'bgr')\n>>> cv.imshow('Brightness level increased by 100', lum_100)\n\n>>> lum_neg_100 = ip.luminosity(img, intensity_shift = -100, order = 'bgr')\n>>> cv.imshow('Brightness level decreased by 100', lum_neg_100)\n\n\n=================================  =================================  =================================\nBrightness level decreased by 100  Original                           Brightness level increased by 100\n=================================  =================================  =================================\n|lum_neg_100|                      |lenna_org|                        |lum_100|                        \n=================================  =================================  =================================\n\n\nSkew - Perspective\n__________________\n\nimagewizard provides methods to perspective tranform an image. You need to provide 4 points on the input image and corresponding points on the output image. Among these 4 points, 3 of them should not be collinear.\nFollowing code demonstrates Perspective Transformation.\n\n>>> imagewizard.Processing().skew_perspective(img: Image, input_points: np.float32, output_points: np.float32, order: str)\n\nParameters:\n\n* img: (numpy.array, PIL.image, cv2.image)\n* input_points: four points on input image, ex: np.float32([[x1,y1],[x2,y2],[x3,y3],[x4,y4]]), (xi, yi are floating point)\n* output_points: four points on output location correspoinding to input_points' to be transformed, ex: np.float32([[p1,q1],[p2,q2],[p3,q3],[p4,q4]]), (pi, qi are floating point)\n* order: (RGB, BGR) input order of the colors. If using PIL to read an image, 'order' need not be specified. **If opencv is used to read an image, 'order' must be set to 'BGR'**\n\n>>> import cv2\n>>> img = cv2.imread('original_image.png')\n>>> ip = imagewizard.Processing()\n\n>>> input_points = np.float32([(100, 320), (472, 156), (250, 580), (630, 345)])\n>>> output_points = np.float32([[0,0], [500,0], [0,350], [500,350]])\n\n>>> skew_img = ip.skew_perspective(img, input_points = input_points, output_points = output_points, order = 'bgr')\n>>> cv.imshow('Perspective Transformation', skew_img)\n\n\n=================================  =================================\nOriginal                           Perspective Transformation       \n=================================  =================================\n|skew_per_org|                     |skew_per_tf|                        \n=================================  =================================\n\n\n* The green points on the input image specifies the coordinates of the pixels that will be mapped to output points.\n* The coordinates passed in the code above are in the order - TOP LEFT, TOP RIGHT, BOTTOM LEFT, BOTTOM RIGHT\n* The corresponding input pixel coordinates are - TL:(100, 320), TR:(472, 156), BL:(250, 580), BR:(630, 345)]\n* The corresponding output pixel coordinates are - TL:(0, 0), TR:(500, 0), BL:(0, 350), BR:(500, 350)]\n\n\nSkew - Affine\n_____________\n\nimagewizard provides methods to affine transform an image. In affine transformation, all parallel lines in the original image will still be parallel in the output image. Provide three points from input image and their corresponding locations in output image.\nFollowing code demonstrates Affine Transformation.\n\n>>> imagewizard.Processing().affine(img: Image, input_points: np.float32, output_points: np.float32, order: str)\n\nParameters:\n\n* img: (numpy.array, PIL.image, cv2.image)\n* input_points: three points on input image, ex: np.float32([[x1,y1],[x2,y2],[x3,y3]]), (xi, yi are floating point)\n* output_points: three points on output location correspoinding to input_points' to be transformed, np.float32([[p1,q1],[p2,q2],[p3,q3]]), (pi, qi are floating point)\n* order: (RGB, BGR) input order of the colors. If using PIL to read an image, 'order' need not be specified. **If opencv is used to read an image, 'order' must be set to 'BGR'**\n\n>>> import cv2\n>>> img = cv2.imread('original_image.png')\n>>> ip = imagewizard.Processing()\n\n>>> input_points = np.float32([[50,50],[200,50],[50,200]])\n>>> output_points = np.float32([[10,100],[200,50],[100,250]])\n\n>>> skew_img = ip.skew_perspective(img, input_points = input_points, output_points = output_points, order = 'bgr')\n>>> cv.imshow('Affine Transformation', skew_img)\n\n\n=================================  =================================\nOriginal                           Affine Transformation       \n=================================  =================================\n|skew_aff_org|                     |skew_aff_tf|                        \n=================================  =================================\n\n\n* The green points on the input image specifies the coordinates of the pixels that will be mapped to output points.\n* The coordinates passed in the code above are in the order - TOP LEFT, TOP RIGHT, BOTTOM LEFT\n* The corresponding input pixel coordinates are - TL:(50, 50), TR:(200, 50), BL:(50, 200)]\n* The corresponding output pixel coordinates are - TL:(10, 100), TR:(200, 50), BL:(100, 250)]\n\nFor more information check this `documentation <https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_geometric_transformations/py_geometric_transformations.html#affine-transformation>`_\n\n\nImage Analysis\n==============\n\nDominant Colors\n_______________\n\nimagewizard provides methods to find the 'n' dominant colors in an image. \nFollowing code demonstrates using the function to get 'n' dominant colors in an image.\n\n>>> imagewizard.Analysis().dominant_colors(img: Image, no_of_colors: int = 3, order: str = 'rgb')\n\nParameters:\n\n* img: (numpy.array, PIL.image, cv2.image)\n* no_of_colors: (int) no of dominant colors RGB to return\n* order: (RGB, BGR) input order of the colors. If using PIL to read an image, 'order' need not be specified. **If opencv is used to read an image, 'order' must be set to 'BGR'**\n\n>>> import cv2\n>>> from PIL import Image\n>>> img_cv = cv2.imread('original_image.png')\n>>> img_pil = Image.open(\"original_image.png\")\n\n>>> imanalysis = imagewizard.Analysis()\n>>> img_cv_result = imanalysis.dominant_colors(img_pil, 3, 'bgr')\n>>> img_pil_result = imanalysis.dominant_colors(img_cv, 3, 'rgb')\n\n>>> print(\"CV image - dominant colors (RGB) : \", img_cv_result)\nCV image - dominant colors (RGB) : [[224 166 147]\n [110  34  71]\n [195  98 100]]\n\n=============  ================ ================ ================ ================\nOriginal       Clustered Image  Color 1          Color 2          Color 3\n=============  ================ ================ ================ ================\n|lenna_org|    |clustered_im|   |cv_dom_c0|      |cv_dom_c1|      |cv_dom_c2|                        \n=============  ================ ================ ================ ================\n\n* The Clustered Image can be constructed with `Segmentation <https://github.com/PriceSpider-NeuIntel/imagewizard#segmentation>`_ method of imagewizard\n\n>>> print(\"PIL image - dominant colors (RGB) : \", img_pil_result)\nPIL image - dominant colors (RGB) : [[224 166 147]\n [110  34  71]\n [195  98 100]]\n\n=============  ================ ================ ================ ================\nOriginal       Clustered Image  Color 1          Color 2          Color 3\n=============  ================ ================ ================ ================\n|lenna_org|    |clustered_im|   |pil_dom_c0|     |pil_dom_c1|     |pil_dom_c2|                        \n=============  ================ ================ ================ ================\n\n\nAverage/Mean Color\n__________________\n\nimagewizard provides methods that calculates and returns the mean/average color of an image\nFollowing code demonstrates using the function to get the average pixel color in RGB\n\n>>> imagewizard.Analysis().mean_color(img: Image, order: str = 'rgb')\n\nParameters:\n\n* img: (numpy.array, PIL.image, cv2.image)\n* order: (RGB, BGR) input order of the colors. If using PIL to read an image, 'order' need not be specified. **If opencv is used to read an image, 'order' must be set to 'BGR'**\n\nReturns:\n\n* Tuple of RGB values of the mean color calculated\n\n>>> import cv2\n>>> from PIL import Image\n>>> img_cv = cv2.imread('original_image.png')\n>>> img_pil = Image.open(\"original_image.png\")\n\n>>> imanalysis = imagewizard.Analysis()\n>>> img_cv_result = imanalysis.mean_color(img_pil, 'bgr')\n>>> img_pil_result = imanalysis.mean_color(img_cv, 'rgb')\n\n>>> print(\"PIL image - mean color (RGB) :\", img_cv_result)\nPIL image - mean color (RGB) : (180, 99, 105)\n\n>>> print(\"CV image - mean color (RGB) :\", img_cv_result)\nCV image - mean color (RGB) : (180, 99, 105)\n\n===================  ===================\nOriginal             Average/Mean Color    \n===================  ===================     \n|lenna_org_ave|      |lenna_result_ave|\n===================  ===================    \n\n\nFrequent Color\n______________\n\nimagewizard provides methods that calculates and returns the frequent/mode color of an image\nFollowing is the demonstration code,\n\n>>> imagewizard.Analysis().frequent_color(img: Image, order: str = 'rgb')\n\nParameters:\n\n* img: (numpy.array, PIL.image, cv2.image)\n* order: (RGB, BGR) input order of the colors. If using PIL to read an image, 'order' need not be specified. **If opencv is used to read an image, 'order' must be set to 'BGR'**\n\nReturns:\n\n* Tuple of RGB values of the mode color calculated\n\n>>> import cv2\n>>> from PIL import Image\n>>> img_cv = cv2.imread('original_image.png')\n>>> img_pil = Image.open(\"original_image.png\")\n\n>>> imanalysis = imagewizard.Analysis()\n>>> img_cv_result = imanalysis.frequent_color(img_pil, 'bgr')\n>>> img_pil_result = imanalysis.frequent_color(img_cv, 'rgb')\n\n>>> print(\"PIL image - frequent color (RGB) :\", img_cv_result)\nPIL image - frequent color (RGB) : (88, 18, 60)\n\n>>> print(\"CV image - frequent color (RGB) :\", img_cv_result)\nCV image - frequent color (RGB) : (88, 18, 60)\n\n===================  ===================      \nOriginal             Frequent/Mode Color    \n===================  ===================      \n|lenna_org_mode|     |lenna_result_mode|\n===================  ===================  \n\n\nTrim/Crop to Content\n____________________\n\nimagewizard provides methods to Trim/Crop an image to its content (removes uniform color spaced padding around the image) \nFollowing code demonstrates using the function to trim an image\n\n>>> imagewizard.Analysis().trim_to_content(img: Image, order: str = 'rgb')\n\nParameters:\n\n* img: (numpy.array, PIL.image, cv2.image)\n* order: (RGB, BGR) input order of the colors. If using PIL to read an image, 'order' need not be specified. **If opencv is used to read an image, 'order' must be set to 'BGR'**\n\nReturns:\n\n* PIL/numpy.array of the order specified\n\n>>> import cv2\n>>> from PIL import Image\n>>> img_cv = cv2.imread('original_image.png')\n>>> img_pil = Image.open(\"original_image.png\")\n\n>>> imanalysis = imagewizard.Analysis()\n>>> img_cv_result = imanalysis.trim_to_content(img_cv, 'bgr')\n>>> img_pil_result = imanalysis.trim_to_content(img_pil)\n\n>>> cv.imshow(\"original\", img_cv)\n>>> cv.imshow(\"Trimmed Image\", img_cv_result)\n>>> img_pil_result.show()\n\n================  =================\nOriginal          Trimmed Image    \n----------------  -----------------\n|quite_flow_org|  |quite_flow_trim| \n================  =================\n\n================  =================\nOriginal          Trimmed Image    \n----------------  -----------------\n|san_disk_org|    |san_disk_trim|\n================  =================\n\n\n.. _a Hash: http://www.hackerfactor.com/blog/index.php?/archives/432-Looks-Like-It.html\n.. _p Hash: http://www.hackerfactor.com/blog/index.php?/archives/432-Looks-Like-It.html\n.. _d Hash: http://www.hackerfactor.com/blog/index.php?/archives/529-Kind-of-Like-That.html\n.. _w Hash: https://fullstackml.com/2016/07/02/wavelet-image-hash-in-python/\n.. _distance algorithms: https://dataconomy.com/2015/04/implementing-the-five-most-popular-similarity-measures-in-python/\n.. _pypi: https://pypi.python.org/pypi/\n\n.. |lenna_org| image:: tests/data/original_images/lenna.png\n\n.. |clr_inv| image:: tests/data/processed_images/gray/clr_inverted.png\n\n.. |gray| image:: tests/data/processed_images/gray/gray.png\n\n.. |gray_inv| image:: tests/data/processed_images/gray/gray_inverted.png\n\n.. |bin_img| image:: tests/data/processed_images/gray/binary_img.png\n\n.. |bin_inv| image:: tests/data/processed_images/gray/binary_inv_img.png\n\n.. |tz| image:: tests/data/processed_images/gray/to_zero_img.png\n\n.. |tz_inv| image:: tests/data/processed_images/gray/to_zero_inv.png\n\n.. |trunc| image:: tests/data/processed_images/gray/trunc_img.png\n\n.. |trunc_inv| image:: tests/data/processed_images/gray/trunc_inverted.png\n\n\n.. |90deg| image:: tests/data/processed_images/rotate/rotate-90deg.png\n\n.. |180deg| image:: tests/data/processed_images/rotate/rotate-180deg.png\n\n.. |270deg| image:: tests/data/processed_images/rotate/rotate-270deg.png\n\n.. |315degs| image:: tests/data/processed_images/rotate/rotate-315deg-scale.png\n\n.. |45degs| image:: tests/data/processed_images/rotate/rotate-45deg-scale.png\n\n\n.. |crop1| image:: tests/data/processed_images/crop/crop1.png\n\n.. |crop2| image:: tests/data/processed_images/crop/crop2.png\n\n.. |crop3| image:: tests/data/processed_images/crop/crop3.png\n\n\n.. |mir_x| image:: tests/data/processed_images/mirror/flip_x.png\n\n.. |mir_y| image:: tests/data/processed_images/mirror/flip_y.png\n\n.. |mir_xy| image:: tests/data/processed_images/mirror/flip_xy.png\n\n\n.. |blur_5| image:: tests/data/processed_images/blur/blur5.png\n\n.. |blur_25| image:: tests/data/processed_images/blur/blur25.png\n\n.. |blur_50| image:: tests/data/processed_images/blur/blur50.png\n\n\n.. |lum_100| image:: tests/data/processed_images/luminosity/lum_100.png\n\n.. |lum_neg_100| image:: tests/data/processed_images/luminosity/lum_neg_100.png\n\n\n.. |skew_per_org| image:: tests/data/original_images/skew_per_org.png\n\n.. |skew_per_tf| image:: tests/data/processed_images/skew/skew_per.png\n\n\n.. |skew_aff_org| image:: tests/data/original_images/skew_aff_org.png\n\n.. |skew_aff_tf| image:: tests/data/processed_images/skew/skew_aff.png\n\n\n.. ########## dominant colors ###########\n.. |pil_dom_c0| image:: tests/data/analysed_images/dominant/centroid_color_0.jpg\n.. |pil_dom_c1| image:: tests/data/analysed_images/dominant/centroid_color_1.jpg\n.. |pil_dom_c2| image:: tests/data/analysed_images/dominant/centroid_color_2.jpg\n.. |cv_dom_c0| image:: tests/data/analysed_images/dominant/centroid_color_0_cv.jpg\n.. |cv_dom_c1| image:: tests/data/analysed_images/dominant/centroid_color_1_cv.jpg\n.. |cv_dom_c2| image:: tests/data/analysed_images/dominant/centroid_color_2_cv.jpg\n.. |clustered_im| image:: tests/data/analysed_images/dominant/clustered_image.jpg\n\n.. ########## mean colors ###########\n.. |lenna_org_ave| image:: tests/data/analysed_images/mean/lenna-original-ave.jpg\n.. |lenna_result_ave| image:: tests/data/analysed_images/mean/lenna-result-ave.jpg\n\n.. ########## frerquent colors ###########\n.. |lenna_org_mode| image:: tests/data/analysed_images/mode/lenna-original-mode.jpg\n.. |lenna_result_mode| image:: tests/data/analysed_images/mode/lenna-result-mode.jpg\n\n.. ########## crop/trim to content ###########\n.. |quite_flow_trim| image:: tests/data/analysed_images/crop_to_content/trimmed_quite_flow10.png\n.. |san_disk_trim| image:: tests/data/analysed_images/crop_to_content/trimmed_san_disk.png\n\n.. |quite_flow_org| image:: tests/data/original_images/quiet_flow10.png\n.. |san_disk_org| image:: tests/data/original_images/san_disk_white_pad.png\n\n.. |segmented_im| image:: tests/data/processed_images/segmented_image.png\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/PriceSpider-NeuIntel/imagewizard", "keywords": "imagewizard,image hashing,hash,similarity,segmentation,image segmentation,image processing", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "imagewizard", "package_url": "https://pypi.org/project/imagewizard/", "platform": "", "project_url": "https://pypi.org/project/imagewizard/", "project_urls": {"Homepage": "https://github.com/PriceSpider-NeuIntel/imagewizard"}, "release_url": "https://pypi.org/project/imagewizard/1.1.2/", "requires_dist": ["numpy", "opencv-contrib-python", "PyWavelets", "pylint", "scikit-learn", "scipy", "Pillow"], "requires_python": "", "summary": "imagewizard is a python based library for performing various image manipulations and operations", "version": "1.1.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>Source hosted at github: <a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard/\" rel=\"nofollow\">https://github.com/PriceSpider-NeuIntel/imagewizard/</a></p>\n<p>imagewizard is a python based library for performing various image manipulations and operations,</p>\n<ol>\n<li><dl>\n<dt><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#image-hashing\" rel=\"nofollow\">Image Hashing</a></dt>\n<dd><ul>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#average-hash-a-hash\" rel=\"nofollow\">Average Hashing</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#distance-hash-d-hash\" rel=\"nofollow\">Distance Hashing</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#perception-hash-p-hash\" rel=\"nofollow\">Perception Hashing</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#wavelet-hash-w-hash\" rel=\"nofollow\">Wavelet Hashing</a></li>\n</ul>\n</dd>\n</dl>\n</li>\n<li><dl>\n<dt><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#image-similarity-hash-distance\" rel=\"nofollow\">Image Similarity (hash distance computation)</a></dt>\n<dd><ul>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#hamming-distance\" rel=\"nofollow\">Hamming Distance</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#cosine-distance\" rel=\"nofollow\">Cosine Distance</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#euclidean-distance\" rel=\"nofollow\">Euclidean Distance</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#manhattan-distance\" rel=\"nofollow\">Manhattan Distance</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#jaccard-distance\" rel=\"nofollow\">Jaccard Distance</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#minkowski-distance\" rel=\"nofollow\">Minkowski Distance</a></li>\n</ul>\n</dd>\n</dl>\n</li>\n<li><dl>\n<dt><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#image-processing--transformations\" rel=\"nofollow\">Image Processing and Transformations</a></dt>\n<dd><ul>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#segmentation\" rel=\"nofollow\">Segmentation</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#resize\" rel=\"nofollow\">Resize/scale</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#gray-scale\" rel=\"nofollow\">Convert to gray scale</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#rotate\" rel=\"nofollow\">Rotate</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#crop\" rel=\"nofollow\">Crop</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#mirror\" rel=\"nofollow\">Mirror</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#blur\" rel=\"nofollow\">Blur</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#luminosity\" rel=\"nofollow\">Luminosity (Brightness)</a></li>\n<li><dl>\n<dt><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#skew---perspective\" rel=\"nofollow\">Skew</a></dt>\n<dd><ul>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#skew---perspective\" rel=\"nofollow\">Perspective</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#skew---affine\" rel=\"nofollow\">Affine</a></li>\n</ul>\n</dd>\n</dl>\n</li>\n</ul>\n</dd>\n</dl>\n</li>\n<li><dl>\n<dt><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#image-analysis\" rel=\"nofollow\">Image Analysis</a></dt>\n<dd><ul>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#dominant-colors\" rel=\"nofollow\">Dominant colors</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#averagemean-color\" rel=\"nofollow\">Average/Mean Color</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#frequent-color\" rel=\"nofollow\">Frequent/Mode Color</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#trimcrop-to-content\" rel=\"nofollow\">Trim/Crop to content</a></li>\n</ul>\n</dd>\n</dl>\n</li>\n</ol>\n<div id=\"id1\">\n<h2>Image Hashing</h2>\n<div id=\"intuition\">\n<h3>Intuition</h3>\n<p>Given an imput image, imagewizard can compute a hash for the image based on it visual appearance. It is understood that images that are perceptually similar must have similar hashes as well. The similarity here is a metric that we can choose to compute on, generally hamming distance is considered, but we can choose other distance metrics too.\nBy utilizing imagewizard we can find near-identical images in constant time, or at worst, O(log n).</p>\n<p>imagewizard supports the following hashing techniques:</p>\n<ul>\n<li>average hashing (<a href=\"http://www.hackerfactor.com/blog/index.php?/archives/432-Looks-Like-It.html\" rel=\"nofollow\">a Hash</a>)</li>\n<li>perception hashing (<a href=\"http://www.hackerfactor.com/blog/index.php?/archives/432-Looks-Like-It.html\" rel=\"nofollow\">p Hash</a>)</li>\n<li>difference hashing (<a href=\"http://www.hackerfactor.com/blog/index.php?/archives/529-Kind-of-Like-That.html\" rel=\"nofollow\">d Hash</a>)</li>\n<li>wavelet hashing (<a href=\"https://fullstackml.com/2016/07/02/wavelet-image-hash-in-python/\" rel=\"nofollow\">w Hash</a>)</li>\n</ul>\n</div>\n<div id=\"basic-usage\">\n<h3>Basic Usage</h3>\n<p>Let\u2019s take a look at how we can implement image hashing using imagewizard. We will use PIL/Pillow and OpenCv2-python image libraries to read an image and get a 8x8 hash.</p>\n</div>\n<div id=\"step-1-read-an-image-file\">\n<h3>Step 1: read an image file</h3>\n<pre>&gt;&gt;&gt; import cv2\n&gt;&gt;&gt; from PIL import Image\n&gt;&gt;&gt; pil_image = Image.open('test.png')\n&gt;&gt;&gt; cv2_image = cv2.imread('test.png')\n</pre>\n</div>\n<div id=\"step-2-perform-image-hashing\">\n<h3>Step 2: perform image hashing</h3>\n<p>Remember, if you are using opencv2 for reading an image file, the order of the color channels are <em>BGR</em> while that for a PIL Image its <em>RGB</em>. The channel information has to be passed as a parameter to the function while performing hashing. The default value of <em>order</em> is <em>RGB</em></p>\n<p>imagewizard.Hashing()</p>\n<ul>\n<li>.ahash(image, hash_size, order)</li>\n<li><dl>\n<dt>.dhash(image, hash_size, order)</dt>\n<dd><ul>\n<li>hamming distance between 0 - 10, would indicate the images being compared are similar</li>\n</ul>\n</dd>\n</dl>\n</li>\n<li>.phash(image, hash_size, order)</li>\n<li>.whash(image, hash_size, order)</li>\n</ul>\n<p>Parameters:</p>\n<ul>\n<li>image      - must be a PIL instance image or numpy array in RGB or opencv image in BGR</li>\n<li>hash_size  - (integer) default 8 for 64 bit hash</li>\n<li>order      - (string) RGB, BGR: defaults to \u2018RGB\u2019 - input order of the colors. If using PIL to read an image, \u2018order\u2019 need not be specified. <strong>If opencv is used to read an image, \u2018order\u2019 must be set to \u2018BGR\u2019</strong></li>\n</ul>\n<pre>&gt;&gt;&gt; import imagewizard as iw\n&gt;&gt;&gt; iw_hash = iw.Hashing()\n</pre>\n</div>\n<div id=\"average-hash-a-hash\">\n<h3>Average hash (a hash)</h3>\n<pre>&gt;&gt;&gt; a_hash_pil = iw_hash.ahash(image = pil_image, hash_size = 8, order = 'RGB')\n&gt;&gt;&gt; a_hash_cv2 = iw_hash.ahash(image = cv2_image, hash_size = 8, order = 'BGR')\n</pre>\n<pre>&gt;&gt;&gt; print(\"PIL a-hash: {}\".format(a_hash_pil))\nPIL a-hash: fefff80000000000\n&gt;&gt;&gt; print(\"cv2 a-hash: {}\".format(a_hash_cv2))\ncv2 a-hash: fefff80000000000\n</pre>\n</div>\n<div id=\"distance-hash-d-hash\">\n<h3>Distance hash (d hash)</h3>\n<ul>\n<li>hamming distance between 0 - 10, would indicate the images being compared are similar</li>\n</ul>\n<pre>&gt;&gt;&gt; d_hash_pil = iw_hash.dhash(image = pil_image, hash_size = 8, order = 'RGB')\n&gt;&gt;&gt; d_hash_cv2 = iw_hash.dhash(image = cv2_image, hash_size = 8, order = 'BGR')\n</pre>\n<pre>&gt;&gt;&gt; print(\"PIL d-hash: {}\".format(a_hash_pil))\nPIL d-hash: 48b09035b16c9ccb\n&gt;&gt;&gt; print(\"cv2 d-hash: {}\".format(a_hash_cv2))\ncv2 d-hash: 48b09035b16c9ccb\n</pre>\n</div>\n<div id=\"perception-hash-p-hash\">\n<h3>Perception hash (p hash)</h3>\n<pre>&gt;&gt;&gt; p_hash_pil = iw_hash.phash(image = pil_image, hash_size = 8, order = 'RGB')\n&gt;&gt;&gt; p_hash_cv2 = iw_hash.phash(image = cv2_image, hash_size = 8, order = 'BGR')\n</pre>\n<pre>&gt;&gt;&gt; print(\"PIL p-hash: {}\".format(p_hash_pil))\nPIL p-hash: d0ddd594473657c0\n&gt;&gt;&gt; print(\"cv2 p-hash: {}\".format(p_hash_cv2))\ncv2 p-hash: d0ddd594473657c0\n</pre>\n</div>\n<div id=\"wavelet-hash-w-hash\">\n<h3>Wavelet hash (w hash)</h3>\n<pre>&gt;&gt;&gt; w_hash_pil = iw_hash.whash(image = pil_image, hash_size = 8, order = 'RGB')\n&gt;&gt;&gt; w_hash_cv2 = iw_hash.whash(image = cv2_image, hash_size = 8, order = 'BGR')\n</pre>\n<pre>&gt;&gt;&gt; print(\"PIL w-hash: {}\".format(w_hash_pil))\nPIL w-hash: fffffe90100e4420\n&gt;&gt;&gt; print(\"cv2 w-hash: {}\".format(w_hash_cv2))\ncv2 w-hash: fffffe90100e4420\n</pre>\n</div>\n<div id=\"few-other-operations\">\n<h3>Few other operations</h3>\n<p>To get the hash value, simply cast the returned object to str,</p>\n<pre>&gt;&gt;&gt; hash_value1 = str(a_hash_cv2)\n&gt;&gt;&gt; hash_value2 = str(a_hash_pil)\n</pre>\n<p>You can also find the hamming distance (the number of bit positions in which the two bits are different) by simply applying subtraction operation,</p>\n<pre>&gt;&gt;&gt; hash_diff = a_hash_pil - a_hash_pil\n&gt;&gt;&gt; print(hash_diff)\n0\n</pre>\n<p>Since the two hashes are of the same image, the hamming distance is 0. For more information on hamming distance - <a href=\"https://en.wikipedia.org/wiki/Hamming_distance\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Hamming_distance</a></p>\n<p>If you simply want to check if the two hashes are exact matches, you could do that too,</p>\n<pre>&gt;&gt;&gt; print(a_hash_pil == a_hash_cv2)\nTrue\n&gt;&gt;&gt; print(a_hash_cv2 == d_hash_cv2)\nFalse\n</pre>\n</div>\n</div>\n<div id=\"image-similarity-hash-distance\">\n<h2>Image Similarity (hash distance)</h2>\n<p>Now that we have a hash corresponsding to an image, we can find how similar other images are, by comparing the hashes, i.e, finding the hash distances. Lower the values, more similar are the images.\nimagewizard provides various distance algorithms for computing hash distances between two hashes,</p>\n<pre>&gt;&gt;&gt; imagewizard.Similarity().similarity(hash1, hash2, metric = &lt;metric&gt;)\n</pre>\n<p>The &lt;metric&gt; value can be one of the following-</p>\n<ul>\n<li>hamming</li>\n<li>cosine</li>\n<li>euclidean</li>\n<li>manhattan</li>\n<li>jaccard</li>\n<li>minkowski</li>\n</ul>\n<div id=\"id2\">\n<h3>Basic Usage</h3>\n<pre>&gt;&gt;&gt; import imagewizard as iw\n&gt;&gt;&gt; import cv2\n&gt;&gt;&gt; iw_hash = iw.Hashing()\n&gt;&gt;&gt; iw_similarity = iw.Similarity()\n</pre>\n<pre>&gt;&gt;&gt; image1 = cv2.imread('test.png')\n&gt;&gt;&gt; hash1_str = str(iw_hash.dhash(image1, order = 'BGR'))\n&gt;&gt;&gt; image2 = cv2.imread('test2.png')\n&gt;&gt;&gt; hash2_str = str(iw_hash.dhash(image2, order = 'BGR'))\n</pre>\n</div>\n<div id=\"id3\">\n<h3>Hamming distance</h3>\n<pre>&gt;&gt;&gt; print(\"hamming: \", iw_similarity.similarity(hash1_str, hash2_str, metric = 'hamming'))\nhamming: 26\n</pre>\n</div>\n<div id=\"id4\">\n<h3>Cosine distance</h3>\n<pre>&gt;&gt;&gt; print(\"cosine: \", iw_similarity.similarity(hash1_str, hash2_str, metric = 'cosine'))\ncosine: 0.546\n</pre>\n</div>\n<div id=\"id5\">\n<h3>Euclidean distance</h3>\n<pre>&gt;&gt;&gt; print(\"euclidean : {}\".format(iw_similarity.similarity(hash1_str, hash2_str, metric = 'euclidean')))\neuclidean : 5.0\n</pre>\n</div>\n<div id=\"id6\">\n<h3>Manhattan distance</h3>\n<pre>&gt;&gt;&gt; print(\"manhattan : {}\".format(iw_similarity.similarity(hash1_str, hash2_str, metric = 'manhattan')))\nmanhattan : 26\n</pre>\n</div>\n<div id=\"id7\">\n<h3>Jaccard distance</h3>\n<pre>&gt;&gt;&gt; print(\"jaccard : {}\".format(iw_similarity.similarity(hash1_str, hash2_str, metric = 'jaccard')))\njaccard : 1.0\n</pre>\n</div>\n<div id=\"id8\">\n<h3>Minkowski distance</h3>\n<p>p value is set to 3 while computing minkowski distance</p>\n<pre>&gt;&gt;&gt; print(\"minkowski : {}\".format(iw_similarity.similarity(hash1_str, hash2_str, metric = 'minkowski')))\nminkowski : 2.924\n</pre>\n<p>Concise explanation of <a href=\"https://dataconomy.com/2015/04/implementing-the-five-most-popular-similarity-measures-in-python/\" rel=\"nofollow\">distance algorithms</a></p>\n</div>\n</div>\n<div id=\"image-processing-transformations\">\n<h2>Image Processing &amp; Transformations</h2>\n<p>imagewizard provides the following image processing and transformations</p>\n<ul>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#segmentation\" rel=\"nofollow\">Segmentation</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#resize\" rel=\"nofollow\">Resize/scale</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#gray-scale\" rel=\"nofollow\">Convert to gray scale</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#rotate\" rel=\"nofollow\">Rotate</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#crop\" rel=\"nofollow\">Crop</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#mirror\" rel=\"nofollow\">Mirror</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#blur\" rel=\"nofollow\">Blur</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#luminosity\" rel=\"nofollow\">Luminosity (Brightness)</a></li>\n<li><dl>\n<dt><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#skew---perspective\" rel=\"nofollow\">Skew</a></dt>\n<dd><ul>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#skew---perspective\" rel=\"nofollow\">Perspective</a></li>\n<li><a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#skew---affine\" rel=\"nofollow\">Affine</a></li>\n</ul>\n</dd>\n</dl>\n</li>\n</ul>\n<div id=\"id20\">\n<h3>Segmentation</h3>\n<p>imagewizard provides methods for image segmentation, i.e, reconstructing a given image with a given set of colors alone. Every pixel in the original image is mapped to its nearest color from the set of colors and reconstructed.\nThe following code demonstrates image segmentation of the famous picture of lenna with three colors (RGB values),</p>\n<ul>\n<li>[224 166 147]</li>\n<li>[110  34  71]</li>\n<li>[195  98 100]</li>\n</ul>\n<pre>&gt;&gt;&gt; imagewizard.Processing().segmentation(img, rgb_list: [[int]], order: str = 'rgb')\n</pre>\n<p>Parameters:</p>\n<ul>\n<li>img: (numpy.array, PIL.image, cv2.image)</li>\n<li>rgb_list: 2 dimensional np array with shape (n,3) 3 being the channel values in order RGB, eg: [[224, 166, 147], [110, 34, 71], [195, 98, 100]]</li>\n<li><dl>\n<dt>order: (RGB, BGR) input order of the colors BGR/RGB. Deafult order: RGB</dt>\n<dd>Note: The output will be a numpy.array of the same order</dd>\n</dl>\n</li>\n</ul>\n<pre>&gt;&gt;&gt; cv_img = cv.imread('data/original_images/lenna.png')\n&gt;&gt;&gt; pil_img = Image.open('data/original_images/lenna.png')\n&gt;&gt;&gt; ip = imagewizard.Processing()\n&gt;&gt;&gt; rgb_colors_list = [[224, 166, 147], [110, 34, 71], [195, 98, 100]]\n</pre>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Color 1</th>\n<th>Color 2</th>\n<th>Color 3</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><img alt=\"cv_dom_c0\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c99e5e97d5601f7fcab597278dd262ef0afc39fa/74657374732f646174612f616e616c797365645f696d616765732f646f6d696e616e742f63656e74726f69645f636f6c6f725f305f63762e6a7067\"></td>\n<td><img alt=\"cv_dom_c1\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/374c49672aeb5e58e3edd1932c9a1ae6364af8c1/74657374732f646174612f616e616c797365645f696d616765732f646f6d696e616e742f63656e74726f69645f636f6c6f725f315f63762e6a7067\"></td>\n<td><img alt=\"cv_dom_c2\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4e874b46a683c95760da5126547e02b4d8a6f763/74657374732f646174612f616e616c797365645f696d616765732f646f6d696e616e742f63656e74726f69645f636f6c6f725f325f63762e6a7067\"></td>\n</tr>\n</tbody>\n</table>\n<pre>&gt;&gt;&gt; cv_result = ip.segmentation(cv_img, rgb_colors_list, 'bgr')\n&gt;&gt;&gt; pil_result = ip.segmentation(pil_img, rgb_colors_list, 'rgb')\n&gt;&gt;&gt; pil_res_im = Image.fromarray(pil_res)\n</pre>\n<pre>&gt;&gt;&gt; cv2.imshow(\"original image\", cv_img)\n&gt;&gt;&gt; cv2.imshow('Segmented Image', cv_result)\n&gt;&gt;&gt; pil_res_im.show()\n</pre>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Original</th>\n<th>Segmented Image</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><img alt=\"lenna_org\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b2454d65ecd7242f23caa7fc461698baa484b734/74657374732f646174612f6f726967696e616c5f696d616765732f6c656e6e612e706e67\"></td>\n<td><img alt=\"segmented_im\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9164b2596647b9ffe7eccc2beead252eab5f281c/74657374732f646174612f70726f6365737365645f696d616765732f7365676d656e7465645f696d6167652e706e67\"></td>\n</tr>\n</tbody>\n</table>\n</div>\n<div id=\"resize\">\n<h3>Resize</h3>\n<p>imagewizard provides methods to resize/scale an image to desired pixel (width x height),</p>\n<pre>&gt;&gt;&gt; imagewizard.Processing().resize(img, interpolation_method: str, resize_width: int, resize_height: int, resize_percentage: float, order: str = 'rgb')\n</pre>\n<p>Parameters:</p>\n<ul>\n<li>img: (numpy.array, PIL.image, cv2.image)</li>\n<li>interpolation_method: (s, z) s/shrink or z/zoom; default to shrink</li>\n<li>resize_percentage: (0, 100) floating value. to resize image by the specified percentage</li>\n<li><dl>\n<dt>resize_width, resize_height: (in pixels) if unspecified, defaults to 50% of original img width &amp; height. If either only width or height is specified, the other dimension is scaled implicitly, to keep the aspect ratio intact.</dt>\n<dd>Note: these will be ignored if resize_percentage is specified</dd>\n</dl>\n</li>\n<li><dl>\n<dt>order: (RGB, BGR) input order of the colors. If using PIL to read an image, \u2018order\u2019 need not be specified. <strong>If opencv is used to read an image, \u2018order\u2019 must be set to \u2018BGR\u2019</strong></dt>\n<dd>Note: The output will be a numpy.array of the same order</dd>\n</dl>\n</li>\n</ul>\n<p>Lets put resize to work on an image of the beautiful view outside Mumbai T2</p>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Original</th>\n<th>50% of original - Aspect Ratio Intact</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><img alt=\"t2_img\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/49830eeb5cb3d5137dfb5d949ea671c1292a646a/74657374732f646174612f6f726967696e616c5f696d616765732f7374726565742e706e67\" width=\"450\"></td>\n<td><img alt=\"t2_r3\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f3ab09a03eabca113bf45f63c326fca1d6e9787b/74657374732f646174612f70726f6365737365645f696d616765732f726573697a652f736872696e6b2d35302d70657263656e742e706e67\" width=\"60%\"></td>\n</tr>\n</tbody>\n</table>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>300px by 300px</th>\n<th>height: 200px - Aspect Ratio Intact</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><img alt=\"t2_r1\" height=\"100px\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e5827e84d4cc3388842120bdb86c27489dd089c2/74657374732f646174612f70726f6365737365645f696d616765732f726573697a652f736872696e6b2d33303070782d33303070782e706e67\" width=\"100px\"></td>\n<td><img alt=\"t2_r2\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f1730478eb202f639585d37f173b68160c4b7bda/74657374732f646174612f70726f6365737365645f696d616765732f726573697a652f736872696e6b2d32303070782e706e67\" width=\"60%\"></td>\n</tr>\n</tbody>\n</table>\n<p>Resize Image to 50% height X width, keeping aspect ratio intact</p>\n<pre>&gt;&gt;&gt; img = cv2.imread('data/test.png')\n&gt;&gt;&gt; ip = imagewizard.Processing()\n&gt;&gt;&gt; res = ip.resize(img, resize_percentage = 50, order = 'bgr')\n&gt;&gt;&gt; cv2.imshow('Resized Image', res)\n</pre>\n<p>Resize Image to 300px by 300px</p>\n<pre>&gt;&gt;&gt; img = cv2.imread('data/test.png')\n&gt;&gt;&gt; ip = imagewizard.Processing()\n&gt;&gt;&gt; res = ip.resize(img, resize_width=300, resize_height=300, order = 'bgr')\n&gt;&gt;&gt; cv2.imshow('Resized Image', res)\n</pre>\n<p>Resize Image to height 200px, keeping aspect ratio intact</p>\n<pre>&gt;&gt;&gt; img = cv2.imread('data/test.png')\n&gt;&gt;&gt; ip = imagewizard.Processing()\n&gt;&gt;&gt; res = ip.resize(img, resize_height=200, order = 'bgr')\n&gt;&gt;&gt; cv2.imshow('Resized Image', res)\n</pre>\n</div>\n<div id=\"gray-scale\">\n<h3>Gray scale</h3>\n<p>imagewizard provides methods to convert a given color image to gray scale/inverted in various forms such as,</p>\n<ul>\n<li>Inverted Colors</li>\n<li>To Gray/Gray Inverted</li>\n<li>To Binary/Binary Inverted</li>\n<li>To Zero/Zero Inverted</li>\n<li>To Truncated/Truncated Inverted</li>\n</ul>\n<p>imagewizard.Processing().img2grayscale(image, to_binary: bool, to_zero: bool, inverted: bool, trunc: bool, is_gray: bool, order: str)</p>\n<p>Parameters:</p>\n<ul>\n<li><p>img: (numpy.array, PIL.image, cv2.image)</p>\n</li>\n<li><dl>\n<dt>thresholding_options</dt>\n<dd><ul>\n<li>to_binary: (True/False) - defaults to False, converts the image to a complete black and white image without any shade of gray</li>\n<li>to_zero: (True/False) - defaults to False, converts an image to zero thresholding if set to True</li>\n<li>trunc: (True/False) - defaults to False, converts an image to truncated thresholding if set to True</li>\n<li>inverted: (True/False) - defaults to False, this parameter can be used along with any of the above parameter. If set to True, the colorspace will be inverted</li>\n<li>is_gray: (True/False) - defaults to True, if set to false and used along with (\u2018inverted\u2019 == True) the colorspace of the image will be inverted</li>\n</ul>\n<p>Note: the preference of the parameters follows - truc &gt; to_binary &gt; to_zero. The lower order parameter will be ignored in presence of a parameter with a greater preference.</p>\n</dd>\n</dl>\n</li>\n<li><dl>\n<dt>order: (RGB, BGR) input order of the colors. If using PIL to read an image, \u2018order\u2019 need not be specified. <strong>If opencv is used to read an image, \u2018order\u2019 must be set to \u2018BGR\u2019</strong></dt>\n<dd><p>Note: The output will be a numpy.array of the same order</p>\n</dd>\n</dl>\n</li>\n</ul>\n<p>Let us use the famous picture of Lena, to demonstrate gray scaling.</p>\n<pre>&gt;&gt;&gt; import cv2\n&gt;&gt;&gt; img = cv2.imread('original_image.png')\n&gt;&gt;&gt; ip = imagewizard.Processing()\n</pre>\n<pre>&gt;&gt;&gt; inverted_img = ip.img2grayscale(img, inverted=True, is_gray=False, order = 'bgr')\n&gt;&gt;&gt; cv.imshow(\"inverted Image\", inverted_img)\n</pre>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Original</th>\n<th>Inverted</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><img alt=\"lenna_org\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b2454d65ecd7242f23caa7fc461698baa484b734/74657374732f646174612f6f726967696e616c5f696d616765732f6c656e6e612e706e67\"></td>\n<td><img alt=\"clr_inv\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5aeaa412b8cd87516a3e8e7bec15f4131ee9e045/74657374732f646174612f70726f6365737365645f696d616765732f677261792f636c725f696e7665727465642e706e67\"></td>\n</tr>\n</tbody>\n</table>\n<pre>&gt;&gt;&gt; gray_image = ip.img2grayscale(img, order = 'bgr')\n&gt;&gt;&gt; cv2.imshow(\"Gray\", gray_image)\n</pre>\n<pre>&gt;&gt;&gt; gray_inv_image = ip.img2grayscale(img, inverted=True, order = 'bgr')\n&gt;&gt;&gt; cv.imshow(\"Gray Inverted\", gray_inv_image)\n</pre>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Gray</th>\n<th>Gray Inv</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><img alt=\"gray\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/76eea64d593ce70580922831e33e83cb8501295d/74657374732f646174612f70726f6365737365645f696d616765732f677261792f677261792e706e67\"></td>\n<td><img alt=\"gray_inv\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d80404cbebbf40763f3aeeb2ec1549c7676e0995/74657374732f646174612f70726f6365737365645f696d616765732f677261792f677261795f696e7665727465642e706e67\"></td>\n</tr>\n</tbody>\n</table>\n<pre>&gt;&gt;&gt; trunc_image = ip.img2grayscale(img, trunc=True, order = 'bgr')\n&gt;&gt;&gt; cv.imshow(\"Trucated Threshold\", trunc_image)\n</pre>\n<pre>&gt;&gt;&gt; trunc_inv_image = ip.img2grayscale(img, trunc=True, inverted=True, order = 'bgr')\n&gt;&gt;&gt; cv.imshow(\"Trucated Threshold Inv\", trunc_inv_image)\n</pre>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Truncated</th>\n<th>Truncated Inv</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><img alt=\"trunc\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/41fbe5d25146c99d508c17c28f4d80c817c52281/74657374732f646174612f70726f6365737365645f696d616765732f677261792f7472756e635f696d672e706e67\"></td>\n<td><img alt=\"trunc_inv\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3005a03acc6933eee39682eacb09bdf791ca527b/74657374732f646174612f70726f6365737365645f696d616765732f677261792f7472756e635f696e7665727465642e706e67\"></td>\n</tr>\n</tbody>\n</table>\n<pre>&gt;&gt;&gt; binary_image = ip.img2grayscale(img, to_binary=True, order = 'bgr')\n&gt;&gt;&gt; cv2.imshow(\"Binary Threshold\", binary_image)\n</pre>\n<pre>&gt;&gt;&gt; binary_inv_image = ip.img2grayscale(img, to_binary=True, inverted=True, order = 'bgr')\n&gt;&gt;&gt; cv2.imshow(\"Binary Threshold Inverted\", binary_inv_image)\n</pre>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Binary</th>\n<th>Binary Inv</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><img alt=\"bin_img\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c97e35efb2c766d63973546e55b55a9b666a3ee1/74657374732f646174612f70726f6365737365645f696d616765732f677261792f62696e6172795f696d672e706e67\"></td>\n<td><img alt=\"bin_inv\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f2328cd7e0a7850c5c777bce09622873dc062f66/74657374732f646174612f70726f6365737365645f696d616765732f677261792f62696e6172795f696e765f696d672e706e67\"></td>\n</tr>\n</tbody>\n</table>\n<pre>&gt;&gt;&gt; to_zero_image = ip.img2grayscale(img, to_zero=True, order = 'bgr')\n&gt;&gt;&gt; cv2.imshow(\"To Zero\", to_zero_image)\n</pre>\n<pre>&gt;&gt;&gt; to_zero_inverted = ip.img2grayscale(img, to_zero=True, inverted = True, order = 'bgr')\n&gt;&gt;&gt; cv2.imshow(\"To Zero Inverted\", to_zero_inverted)\n</pre>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>To Zero</th>\n<th>To Zero Inv</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><img alt=\"tz\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b0a7e470a2db58963686fcad29e539c0c4d3b8ca/74657374732f646174612f70726f6365737365645f696d616765732f677261792f746f5f7a65726f5f696d672e706e67\"></td>\n<td><img alt=\"tz_inv\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/34b9ccc1520d71d6e575c77efffc8aee8c719ea9/74657374732f646174612f70726f6365737365645f696d616765732f677261792f746f5f7a65726f5f696e762e706e67\"></td>\n</tr>\n</tbody>\n</table>\n</div>\n<div id=\"id21\">\n<h3>Rotate</h3>\n<p>imagewizard provides method to rotate a given image, with or without scaling.\nThe image provided is rotated in anti-clockwise direction by the rotation angle in degree specified.</p>\n<ul>\n<li>ip.Processing().rotate(image, rotation_degree: float, scaling_factor: float, order: str)</li>\n</ul>\n<p>Parameters:</p>\n<ul>\n<li>image: (numpy.array, PIL.image, cv2.image)</li>\n<li>rotation_degree: rotation angle (in degrees), the image will be rotate in anti-clockwise direction</li>\n<li>scaling_factor: scale the image to desired factor. set to 1.0 to maintain the original scale of the image. 0.5 to halve the size of the image, to double the size of the image, use 2.0.</li>\n<li>order: (RGB, BGR) input order of the colors. If using PIL to read an image, \u2018order\u2019 need not be specified. <strong>If opencv is used to read an image, \u2018order\u2019 must be set to \u2018BGR\u2019</strong></li>\n</ul>\n<p>Following code demonstrates rotation,</p>\n<pre>&gt;&gt;&gt; import cv2\n&gt;&gt;&gt; img = cv2.imread('original_image.png')\n&gt;&gt;&gt; ip = imagewizard.Processing()\n</pre>\n<pre>&gt;&gt;&gt; rotate_by_90 = ip.rotate(img, rotation_degree = 90, order='bgr')\n&gt;&gt;&gt; cv2.imshow(\"Rotate by 90 degrees\", rotate_by_90)\n</pre>\n<pre>&gt;&gt;&gt; rotate_by_180 = ip.rotate(img, rotation_degree = 180, order='bgr')\n&gt;&gt;&gt; cv2.imshow(\"Rotate by 180 degrees\", rotate_by_180)\n</pre>\n<pre>&gt;&gt;&gt; rotate_by_270 = ip.rotate(img, rotation_degree = 270, order='bgr')\n&gt;&gt;&gt; cv2.imshow(\"Rotate by 270 degrees\", rotate_by_270)\n</pre>\n<pre>&gt;&gt;&gt; rotate_by_315_scale = ip.rotate(img, rotation_degree = 315, scaling_factor=0.5, order='bgr')\n&gt;&gt;&gt; cv2.imshow(\"Rotate by 315 degrees, scale 0.5x\", rotate_by_315_scale)\n</pre>\n<pre>&gt;&gt;&gt; rotate_by_45_scale = ip.rotate(img, rotation_degree = 45, scaling_factor=2, order='bgr')\n&gt;&gt;&gt; cv2.imshow(\"Rotate by 45 degrees, scale 2x\", rotate_by_45_scale)\n</pre>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Original</th>\n<th>90 deg</th>\n<th>180 deg</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><img alt=\"lenna_org\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b2454d65ecd7242f23caa7fc461698baa484b734/74657374732f646174612f6f726967696e616c5f696d616765732f6c656e6e612e706e67\"></td>\n<td><img alt=\"90deg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1f3f93d2674ffe0f2c2e8acc5d8ef7c3abc0307f/74657374732f646174612f70726f6365737365645f696d616765732f726f746174652f726f746174652d39306465672e706e67\"></td>\n<td><img alt=\"180deg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8f5b086893b75849f5865e2800e3846cafc6a983/74657374732f646174612f70726f6365737365645f696d616765732f726f746174652f726f746174652d3138306465672e706e67\"></td>\n</tr>\n</tbody>\n</table>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>270 deg</th>\n<th>45 deg, scale 2x</th>\n<th>315 deg, scale 0.5x</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><img alt=\"270deg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9ecd7032941d5b0d67d997fdd54b3815277c53f5/74657374732f646174612f70726f6365737365645f696d616765732f726f746174652f726f746174652d3237306465672e706e67\"></td>\n<td><img alt=\"45degs\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/188d960be4463d3ed64b8d56acf280b891c6e350/74657374732f646174612f70726f6365737365645f696d616765732f726f746174652f726f746174652d34356465672d7363616c652e706e67\"></td>\n<td><img alt=\"315degs\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/01fcb32616ddf269d9e6e583897d9b4a33ae3566/74657374732f646174612f70726f6365737365645f696d616765732f726f746174652f726f746174652d3331356465672d7363616c652e706e67\"></td>\n</tr>\n</tbody>\n</table>\n</div>\n<div id=\"id22\">\n<h3>Crop</h3>\n<p>imagewizard lets you crop a given image. Provide the starting and ending, X and Y coordinates to crop the image to.</p>\n<pre>&gt;&gt;&gt; imagewizard.Processing().crop(img: Image, start_x: float, end_x: float, start_y: float, end_y: float, is_percentage: Bool, order: str)\n</pre>\n<p>Parameters:</p>\n<ul>\n<li>img: (numpy.array, PIL.image, cv2.image)</li>\n<li>start_x: starting pixel coordinate along the x-axis/width of the image</li>\n<li>end_x: ending pixel coordinate along the x-axis/width of the image</li>\n<li>start_y: starting pixle coordinate along the y-axis/height of the image</li>\n<li>end_y: ending pixle coordinate along the y-axis/height of the image</li>\n<li>is_percentage: if True, the coordinates will be considered as percentages, default: False</li>\n<li>order: (RGB, BGR) input order of the colors. If using PIL to read an image, \u2018order\u2019 need not be specified. If opencv is used to read an image, \u2018order\u2019 must be set to \u2018BGR\u2019</li>\n</ul>\n<pre>&gt;&gt;&gt; import cv2\n&gt;&gt;&gt; img = cv2.imread('original_image.png')\n&gt;&gt;&gt; ip = imagewizard.Processing()\n</pre>\n<pre>&gt;&gt;&gt; crop1 = ip.crop(img, start_x = 50, end_x = 100, start_y = 50, end_y = 100, is_percentage = True, order='bgr')\n&gt;&gt;&gt; cv2.imshow(\"Crop % (a)\", crop1)\n</pre>\n<pre>&gt;&gt;&gt; crop2 = ip.crop(img, start_x = 400, end_x = 1000, start_y = 0, end_y = 500, is_percentage = False, order='bgr')\n&gt;&gt;&gt; cv2.imshow(\"Crop by px\", crop2)\n</pre>\n<pre>&gt;&gt;&gt; crop3 = ip.crop(img, start_x = 0, end_x = 50, start_y = 0, end_y = 50, is_percentage = True, order='bgr')\n&gt;&gt;&gt; cv2.imshow(\"Crop % (b)\", crop3)\n</pre>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Original</th>\n<th>Crop % (a)</th>\n<th>Crop by px</th>\n<th>Crop % (b)</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><img alt=\"t2_img\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/49830eeb5cb3d5137dfb5d949ea671c1292a646a/74657374732f646174612f6f726967696e616c5f696d616765732f7374726565742e706e67\" width=\"450\"></td>\n<td><img alt=\"crop1\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9fb349e77fa1730cd4615ea07ac55c42251e60c1/74657374732f646174612f70726f6365737365645f696d616765732f63726f702f63726f70312e706e67\"></td>\n<td><img alt=\"crop2\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/02b687f0b005c4e469927e7d7b30780be394a960/74657374732f646174612f70726f6365737365645f696d616765732f63726f702f63726f70322e706e67\"></td>\n<td><img alt=\"crop3\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9d572e0aafa4a609f475b0365b0b35aababd7d79/74657374732f646174612f70726f6365737365645f696d616765732f63726f702f63726f70332e706e67\"></td>\n</tr>\n</tbody>\n</table>\n</div>\n<div id=\"id23\">\n<h3>Mirror</h3>\n<p>imagewizard provides methods to mirror/flip a given image. The image can be flipped around its X-axis or Y-axis or both X and Y axis by providing the flip_code parameter.\nThe following code demonstrates flipping around various axes.</p>\n<pre>&gt;&gt;&gt; imagewizard.Processing().mirror(img: Image, flip_code: int, order: str)\n</pre>\n<p>Parameters:</p>\n<ul>\n<li>img: (numpy.array, PIL.image, cv2.image)</li>\n<li><dl>\n<dt>flip_code:</dt>\n<dd><ul>\n<li>= 0 for flipping the image around the y-axis (vertical flipping);</li>\n<li>&gt; 0 for flipping around the x-axis (horizontal flipping);</li>\n<li>&lt; 0 for flipping around both axes</li>\n</ul>\n</dd>\n</dl>\n</li>\n<li>order: (RGB, BGR) input order of the colors. If using PIL to read an image, \u2018order\u2019 need not be specified. <strong>If opencv is used to read an image, \u2018order\u2019 must be set to \u2018BGR\u2019</strong></li>\n</ul>\n<pre>&gt;&gt;&gt; import cv2\n&gt;&gt;&gt; img = cv2.imread('original_image.png')\n&gt;&gt;&gt; ip = imagewizard.Processing()\n</pre>\n<pre>&gt;&gt;&gt; mir_x = ip.mirror(img, flip_code=1, order='bgr')\n&gt;&gt;&gt; cv.imshow('Horizontal Mirror (X)', mir_x)\n</pre>\n<pre>&gt;&gt;&gt; mir_y = ip.mirror(img, flip_code=0, order='bgr')\n&gt;&gt;&gt; cv.imshow('Vertical Mirror (Y)', mir_y)\n</pre>\n<pre>&gt;&gt;&gt; mir_xy = ip.mirror(img, flip_code=-1, order='bgr')\n&gt;&gt;&gt; cv.imshow('Mirrored both X and Y', mir_xy)\n</pre>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Original</th>\n<th>Horizontal Mirror (X)</th>\n<th>Vertical Mirror (Y)</th>\n<th>Mirrored both X and Y</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><img alt=\"lenna_org\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b2454d65ecd7242f23caa7fc461698baa484b734/74657374732f646174612f6f726967696e616c5f696d616765732f6c656e6e612e706e67\"></td>\n<td><img alt=\"mir_x\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/08396e88c00717ed2064f9055bc57ee21046fc44/74657374732f646174612f70726f6365737365645f696d616765732f6d6972726f722f666c69705f782e706e67\"></td>\n<td><img alt=\"mir_y\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8b831fc4cc1aa788854d9cdf4a2c55b377554f41/74657374732f646174612f70726f6365737365645f696d616765732f6d6972726f722f666c69705f792e706e67\"></td>\n<td><img alt=\"mir_xy\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/cb36fa0d990283a9113301eca9b519f8a8b43bbb/74657374732f646174612f70726f6365737365645f696d616765732f6d6972726f722f666c69705f78792e706e67\"></td>\n</tr>\n</tbody>\n</table>\n</div>\n<div id=\"id24\">\n<h3>Blur</h3>\n<p>imagewizard provides methods to blur a given image. The intensity of the blur can be passed as an argument to the function.\nThe following code demonstrates blurring.</p>\n<pre>&gt;&gt;&gt; imagewizard.Processing().blur(img: Image, blur_level: int, order: str)\n</pre>\n<p>Parameters:</p>\n<ul>\n<li>img: (numpy.array, PIL.image, cv2.image)</li>\n<li>blur_level: (int, &gt; 0 and &lt; 100,000) intensity of blur</li>\n<li>order: (RGB, BGR) input order of the colors. If using PIL to read an image, \u2018order\u2019 need not be specified. <strong>If opencv is used to read an image, \u2018order\u2019 must be set to \u2018BGR\u2019</strong></li>\n</ul>\n<pre>&gt;&gt;&gt; import cv2\n&gt;&gt;&gt; img = cv2.imread('original_image.png')\n&gt;&gt;&gt; ip = imagewizard.Processing()\n</pre>\n<pre>&gt;&gt;&gt; blur_5 = ip.blur(img, blur_level = 5, order='bgr')\n&gt;&gt;&gt; cv.imshow('Blur level 5', blur_5)\n</pre>\n<pre>&gt;&gt;&gt; blur_25 = ip.blur(img, blur_level = 25, order='bgr')\n&gt;&gt;&gt; cv.imshow('Blur level 25', blur_25)\n</pre>\n<pre>&gt;&gt;&gt; blur_50 = ip.blur(img, blur_level = 50, order='bgr')\n&gt;&gt;&gt; cv.imshow('Blur level 50', blur_50)\n</pre>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Original</th>\n<th>Blur level 5</th>\n<th>Blur level 25</th>\n<th>Blur level 50</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><img alt=\"t2_img\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/49830eeb5cb3d5137dfb5d949ea671c1292a646a/74657374732f646174612f6f726967696e616c5f696d616765732f7374726565742e706e67\" width=\"450\"></td>\n<td><img alt=\"blur_5\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/63f56397329bf5d956abc034a40965ccf75136e5/74657374732f646174612f70726f6365737365645f696d616765732f626c75722f626c7572352e706e67\"></td>\n<td><img alt=\"blur_25\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f5786f97c5469bfeb4af2caf25558fbc7566e66c/74657374732f646174612f70726f6365737365645f696d616765732f626c75722f626c757232352e706e67\"></td>\n<td><img alt=\"blur_50\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5fe1c43c585a7733923dbaf5c4eab24efdc09c86/74657374732f646174612f70726f6365737365645f696d616765732f626c75722f626c757235302e706e67\"></td>\n</tr>\n</tbody>\n</table>\n</div>\n<div id=\"luminosity\">\n<h3>Luminosity</h3>\n<p>imagewizard provides methods to change the luminosity/brightness of a given image. The intensity of the brightness can be passed as an argument to the function. A positive intensity value will brighten the image, whereas a negative value will darken the image.\nThe following code demonstrates changing the brightness levels.</p>\n<pre>&gt;&gt;&gt; imagewizard.Processing().luminosity(img: Image, intensity_shift: int, order: str)\n</pre>\n<p>Parameters:</p>\n<ul>\n<li>img: (numpy.array, PIL.image, cv2.image)</li>\n<li>intensity_shift: -ve value to darken and +ve value to brighten</li>\n<li>order: (RGB, BGR) input order of the colors. If using PIL to read an image, \u2018order\u2019 need not be specified. <strong>If opencv is used to read an image, \u2018order\u2019 must be set to \u2018BGR\u2019</strong></li>\n</ul>\n<pre>&gt;&gt;&gt; import cv2\n&gt;&gt;&gt; img = cv2.imread('original_image.png')\n&gt;&gt;&gt; ip = imagewizard.Processing()\n</pre>\n<pre>&gt;&gt;&gt; lum_100 = ip.luminosity(img, intensity_shift = 100, order = 'bgr')\n&gt;&gt;&gt; cv.imshow('Brightness level increased by 100', lum_100)\n</pre>\n<pre>&gt;&gt;&gt; lum_neg_100 = ip.luminosity(img, intensity_shift = -100, order = 'bgr')\n&gt;&gt;&gt; cv.imshow('Brightness level decreased by 100', lum_neg_100)\n</pre>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Brightness level decreased by 100</th>\n<th>Original</th>\n<th>Brightness level increased by 100</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><img alt=\"lum_neg_100\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4ac266877c479af9e77bfb88178caa259e16781e/74657374732f646174612f70726f6365737365645f696d616765732f6c756d696e6f736974792f6c756d5f6e65675f3130302e706e67\"></td>\n<td><img alt=\"lenna_org\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b2454d65ecd7242f23caa7fc461698baa484b734/74657374732f646174612f6f726967696e616c5f696d616765732f6c656e6e612e706e67\"></td>\n<td><img alt=\"lum_100\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2effad6aa7f5683717b1701b98fcb7ab515e9fe8/74657374732f646174612f70726f6365737365645f696d616765732f6c756d696e6f736974792f6c756d5f3130302e706e67\"></td>\n</tr>\n</tbody>\n</table>\n</div>\n<div id=\"skew-perspective\">\n<h3>Skew - Perspective</h3>\n<p>imagewizard provides methods to perspective tranform an image. You need to provide 4 points on the input image and corresponding points on the output image. Among these 4 points, 3 of them should not be collinear.\nFollowing code demonstrates Perspective Transformation.</p>\n<pre>&gt;&gt;&gt; imagewizard.Processing().skew_perspective(img: Image, input_points: np.float32, output_points: np.float32, order: str)\n</pre>\n<p>Parameters:</p>\n<ul>\n<li>img: (numpy.array, PIL.image, cv2.image)</li>\n<li>input_points: four points on input image, ex: np.float32([[x1,y1],[x2,y2],[x3,y3],[x4,y4]]), (xi, yi are floating point)</li>\n<li>output_points: four points on output location correspoinding to input_points\u2019 to be transformed, ex: np.float32([[p1,q1],[p2,q2],[p3,q3],[p4,q4]]), (pi, qi are floating point)</li>\n<li>order: (RGB, BGR) input order of the colors. If using PIL to read an image, \u2018order\u2019 need not be specified. <strong>If opencv is used to read an image, \u2018order\u2019 must be set to \u2018BGR\u2019</strong></li>\n</ul>\n<pre>&gt;&gt;&gt; import cv2\n&gt;&gt;&gt; img = cv2.imread('original_image.png')\n&gt;&gt;&gt; ip = imagewizard.Processing()\n</pre>\n<pre>&gt;&gt;&gt; input_points = np.float32([(100, 320), (472, 156), (250, 580), (630, 345)])\n&gt;&gt;&gt; output_points = np.float32([[0,0], [500,0], [0,350], [500,350]])\n</pre>\n<pre>&gt;&gt;&gt; skew_img = ip.skew_perspective(img, input_points = input_points, output_points = output_points, order = 'bgr')\n&gt;&gt;&gt; cv.imshow('Perspective Transformation', skew_img)\n</pre>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Original</th>\n<th>Perspective Transformation</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><img alt=\"skew_per_org\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/23ac546efee9c7f623baa04d5476f25452367b67/74657374732f646174612f6f726967696e616c5f696d616765732f736b65775f7065725f6f72672e706e67\"></td>\n<td><img alt=\"skew_per_tf\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/140d0639bc5491564b0b250a12a3bfe9392af086/74657374732f646174612f70726f6365737365645f696d616765732f736b65772f736b65775f7065722e706e67\"></td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>The green points on the input image specifies the coordinates of the pixels that will be mapped to output points.</li>\n<li>The coordinates passed in the code above are in the order - TOP LEFT, TOP RIGHT, BOTTOM LEFT, BOTTOM RIGHT</li>\n<li>The corresponding input pixel coordinates are - TL:(100, 320), TR:(472, 156), BL:(250, 580), BR:(630, 345)]</li>\n<li>The corresponding output pixel coordinates are - TL:(0, 0), TR:(500, 0), BL:(0, 350), BR:(500, 350)]</li>\n</ul>\n</div>\n<div id=\"skew-affine\">\n<h3>Skew - Affine</h3>\n<p>imagewizard provides methods to affine transform an image. In affine transformation, all parallel lines in the original image will still be parallel in the output image. Provide three points from input image and their corresponding locations in output image.\nFollowing code demonstrates Affine Transformation.</p>\n<pre>&gt;&gt;&gt; imagewizard.Processing().affine(img: Image, input_points: np.float32, output_points: np.float32, order: str)\n</pre>\n<p>Parameters:</p>\n<ul>\n<li>img: (numpy.array, PIL.image, cv2.image)</li>\n<li>input_points: three points on input image, ex: np.float32([[x1,y1],[x2,y2],[x3,y3]]), (xi, yi are floating point)</li>\n<li>output_points: three points on output location correspoinding to input_points\u2019 to be transformed, np.float32([[p1,q1],[p2,q2],[p3,q3]]), (pi, qi are floating point)</li>\n<li>order: (RGB, BGR) input order of the colors. If using PIL to read an image, \u2018order\u2019 need not be specified. <strong>If opencv is used to read an image, \u2018order\u2019 must be set to \u2018BGR\u2019</strong></li>\n</ul>\n<pre>&gt;&gt;&gt; import cv2\n&gt;&gt;&gt; img = cv2.imread('original_image.png')\n&gt;&gt;&gt; ip = imagewizard.Processing()\n</pre>\n<pre>&gt;&gt;&gt; input_points = np.float32([[50,50],[200,50],[50,200]])\n&gt;&gt;&gt; output_points = np.float32([[10,100],[200,50],[100,250]])\n</pre>\n<pre>&gt;&gt;&gt; skew_img = ip.skew_perspective(img, input_points = input_points, output_points = output_points, order = 'bgr')\n&gt;&gt;&gt; cv.imshow('Affine Transformation', skew_img)\n</pre>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Original</th>\n<th>Affine Transformation</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><img alt=\"skew_aff_org\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d977c78af8dbcd702a29c207c48dd1d778339ed4/74657374732f646174612f6f726967696e616c5f696d616765732f736b65775f6166665f6f72672e706e67\"></td>\n<td><img alt=\"skew_aff_tf\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/59069dd955c5af4c145af451d6fd96cafb0a15d2/74657374732f646174612f70726f6365737365645f696d616765732f736b65772f736b65775f6166662e706e67\"></td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>The green points on the input image specifies the coordinates of the pixels that will be mapped to output points.</li>\n<li>The coordinates passed in the code above are in the order - TOP LEFT, TOP RIGHT, BOTTOM LEFT</li>\n<li>The corresponding input pixel coordinates are - TL:(50, 50), TR:(200, 50), BL:(50, 200)]</li>\n<li>The corresponding output pixel coordinates are - TL:(10, 100), TR:(200, 50), BL:(100, 250)]</li>\n</ul>\n<p>For more information check this <a href=\"https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_geometric_transformations/py_geometric_transformations.html#affine-transformation\" rel=\"nofollow\">documentation</a></p>\n</div>\n</div>\n<div id=\"id25\">\n<h2>Image Analysis</h2>\n<div id=\"id26\">\n<h3>Dominant Colors</h3>\n<p>imagewizard provides methods to find the \u2018n\u2019 dominant colors in an image.\nFollowing code demonstrates using the function to get \u2018n\u2019 dominant colors in an image.</p>\n<pre>&gt;&gt;&gt; imagewizard.Analysis().dominant_colors(img: Image, no_of_colors: int = 3, order: str = 'rgb')\n</pre>\n<p>Parameters:</p>\n<ul>\n<li>img: (numpy.array, PIL.image, cv2.image)</li>\n<li>no_of_colors: (int) no of dominant colors RGB to return</li>\n<li>order: (RGB, BGR) input order of the colors. If using PIL to read an image, \u2018order\u2019 need not be specified. <strong>If opencv is used to read an image, \u2018order\u2019 must be set to \u2018BGR\u2019</strong></li>\n</ul>\n<pre>&gt;&gt;&gt; import cv2\n&gt;&gt;&gt; from PIL import Image\n&gt;&gt;&gt; img_cv = cv2.imread('original_image.png')\n&gt;&gt;&gt; img_pil = Image.open(\"original_image.png\")\n</pre>\n<pre>&gt;&gt;&gt; imanalysis = imagewizard.Analysis()\n&gt;&gt;&gt; img_cv_result = imanalysis.dominant_colors(img_pil, 3, 'bgr')\n&gt;&gt;&gt; img_pil_result = imanalysis.dominant_colors(img_cv, 3, 'rgb')\n</pre>\n<pre>&gt;&gt;&gt; print(\"CV image - dominant colors (RGB) : \", img_cv_result)\nCV image - dominant colors (RGB) : [[224 166 147]\n [110  34  71]\n [195  98 100]]\n</pre>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Original</th>\n<th>Clustered Image</th>\n<th>Color 1</th>\n<th>Color 2</th>\n<th>Color 3</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><img alt=\"lenna_org\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b2454d65ecd7242f23caa7fc461698baa484b734/74657374732f646174612f6f726967696e616c5f696d616765732f6c656e6e612e706e67\"></td>\n<td><img alt=\"clustered_im\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c8163366c836c58c979b956966dc46d650bcd5f6/74657374732f646174612f616e616c797365645f696d616765732f646f6d696e616e742f636c757374657265645f696d6167652e6a7067\"></td>\n<td><img alt=\"cv_dom_c0\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c99e5e97d5601f7fcab597278dd262ef0afc39fa/74657374732f646174612f616e616c797365645f696d616765732f646f6d696e616e742f63656e74726f69645f636f6c6f725f305f63762e6a7067\"></td>\n<td><img alt=\"cv_dom_c1\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/374c49672aeb5e58e3edd1932c9a1ae6364af8c1/74657374732f646174612f616e616c797365645f696d616765732f646f6d696e616e742f63656e74726f69645f636f6c6f725f315f63762e6a7067\"></td>\n<td><img alt=\"cv_dom_c2\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4e874b46a683c95760da5126547e02b4d8a6f763/74657374732f646174612f616e616c797365645f696d616765732f646f6d696e616e742f63656e74726f69645f636f6c6f725f325f63762e6a7067\"></td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>The Clustered Image can be constructed with <a href=\"https://github.com/PriceSpider-NeuIntel/imagewizard#segmentation\" rel=\"nofollow\">Segmentation</a> method of imagewizard</li>\n</ul>\n<pre>&gt;&gt;&gt; print(\"PIL image - dominant colors (RGB) : \", img_pil_result)\nPIL image - dominant colors (RGB) : [[224 166 147]\n [110  34  71]\n [195  98 100]]\n</pre>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Original</th>\n<th>Clustered Image</th>\n<th>Color 1</th>\n<th>Color 2</th>\n<th>Color 3</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><img alt=\"lenna_org\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b2454d65ecd7242f23caa7fc461698baa484b734/74657374732f646174612f6f726967696e616c5f696d616765732f6c656e6e612e706e67\"></td>\n<td><img alt=\"clustered_im\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c8163366c836c58c979b956966dc46d650bcd5f6/74657374732f646174612f616e616c797365645f696d616765732f646f6d696e616e742f636c757374657265645f696d6167652e6a7067\"></td>\n<td><img alt=\"pil_dom_c0\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d4e6a999ce3b2a1c96eceac27277663108a5ee8f/74657374732f646174612f616e616c797365645f696d616765732f646f6d696e616e742f63656e74726f69645f636f6c6f725f302e6a7067\"></td>\n<td><img alt=\"pil_dom_c1\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/eedf571fc0f15b9d06c6cf88c9f0ed404c61af4d/74657374732f646174612f616e616c797365645f696d616765732f646f6d696e616e742f63656e74726f69645f636f6c6f725f312e6a7067\"></td>\n<td><img alt=\"pil_dom_c2\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9a0f063f6112ca6bd7fc47797df37ecc07ef65ff/74657374732f646174612f616e616c797365645f696d616765732f646f6d696e616e742f63656e74726f69645f636f6c6f725f322e6a7067\"></td>\n</tr>\n</tbody>\n</table>\n</div>\n<div id=\"id28\">\n<h3>Average/Mean Color</h3>\n<p>imagewizard provides methods that calculates and returns the mean/average color of an image\nFollowing code demonstrates using the function to get the average pixel color in RGB</p>\n<pre>&gt;&gt;&gt; imagewizard.Analysis().mean_color(img: Image, order: str = 'rgb')\n</pre>\n<p>Parameters:</p>\n<ul>\n<li>img: (numpy.array, PIL.image, cv2.image)</li>\n<li>order: (RGB, BGR) input order of the colors. If using PIL to read an image, \u2018order\u2019 need not be specified. <strong>If opencv is used to read an image, \u2018order\u2019 must be set to \u2018BGR\u2019</strong></li>\n</ul>\n<p>Returns:</p>\n<ul>\n<li>Tuple of RGB values of the mean color calculated</li>\n</ul>\n<pre>&gt;&gt;&gt; import cv2\n&gt;&gt;&gt; from PIL import Image\n&gt;&gt;&gt; img_cv = cv2.imread('original_image.png')\n&gt;&gt;&gt; img_pil = Image.open(\"original_image.png\")\n</pre>\n<pre>&gt;&gt;&gt; imanalysis = imagewizard.Analysis()\n&gt;&gt;&gt; img_cv_result = imanalysis.mean_color(img_pil, 'bgr')\n&gt;&gt;&gt; img_pil_result = imanalysis.mean_color(img_cv, 'rgb')\n</pre>\n<pre>&gt;&gt;&gt; print(\"PIL image - mean color (RGB) :\", img_cv_result)\nPIL image - mean color (RGB) : (180, 99, 105)\n</pre>\n<pre>&gt;&gt;&gt; print(\"CV image - mean color (RGB) :\", img_cv_result)\nCV image - mean color (RGB) : (180, 99, 105)\n</pre>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Original</th>\n<th>Average/Mean Color</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><img alt=\"lenna_org_ave\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3b66b974a9cd4c4f98e3bb357b8cf0bc2892b1c6/74657374732f646174612f616e616c797365645f696d616765732f6d65616e2f6c656e6e612d6f726967696e616c2d6176652e6a7067\"></td>\n<td><img alt=\"lenna_result_ave\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/10588fcf62c347fb774c45eabf6cd7d0e6f73e55/74657374732f646174612f616e616c797365645f696d616765732f6d65616e2f6c656e6e612d726573756c742d6176652e6a7067\"></td>\n</tr>\n</tbody>\n</table>\n</div>\n<div id=\"frequent-color\">\n<h3>Frequent Color</h3>\n<p>imagewizard provides methods that calculates and returns the frequent/mode color of an image\nFollowing is the demonstration code,</p>\n<pre>&gt;&gt;&gt; imagewizard.Analysis().frequent_color(img: Image, order: str = 'rgb')\n</pre>\n<p>Parameters:</p>\n<ul>\n<li>img: (numpy.array, PIL.image, cv2.image)</li>\n<li>order: (RGB, BGR) input order of the colors. If using PIL to read an image, \u2018order\u2019 need not be specified. <strong>If opencv is used to read an image, \u2018order\u2019 must be set to \u2018BGR\u2019</strong></li>\n</ul>\n<p>Returns:</p>\n<ul>\n<li>Tuple of RGB values of the mode color calculated</li>\n</ul>\n<pre>&gt;&gt;&gt; import cv2\n&gt;&gt;&gt; from PIL import Image\n&gt;&gt;&gt; img_cv = cv2.imread('original_image.png')\n&gt;&gt;&gt; img_pil = Image.open(\"original_image.png\")\n</pre>\n<pre>&gt;&gt;&gt; imanalysis = imagewizard.Analysis()\n&gt;&gt;&gt; img_cv_result = imanalysis.frequent_color(img_pil, 'bgr')\n&gt;&gt;&gt; img_pil_result = imanalysis.frequent_color(img_cv, 'rgb')\n</pre>\n<pre>&gt;&gt;&gt; print(\"PIL image - frequent color (RGB) :\", img_cv_result)\nPIL image - frequent color (RGB) : (88, 18, 60)\n</pre>\n<pre>&gt;&gt;&gt; print(\"CV image - frequent color (RGB) :\", img_cv_result)\nCV image - frequent color (RGB) : (88, 18, 60)\n</pre>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Original</th>\n<th>Frequent/Mode Color</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><img alt=\"lenna_org_mode\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fceb0264ff23b336b6593cde3141da7393c2dc4a/74657374732f646174612f616e616c797365645f696d616765732f6d6f64652f6c656e6e612d6f726967696e616c2d6d6f64652e6a7067\"></td>\n<td><img alt=\"lenna_result_mode\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9ced43f0a00a20ab190b1f4543280921c85c0bc8/74657374732f646174612f616e616c797365645f696d616765732f6d6f64652f6c656e6e612d726573756c742d6d6f64652e6a7067\"></td>\n</tr>\n</tbody>\n</table>\n</div>\n<div id=\"id29\">\n<h3>Trim/Crop to Content</h3>\n<p>imagewizard provides methods to Trim/Crop an image to its content (removes uniform color spaced padding around the image)\nFollowing code demonstrates using the function to trim an image</p>\n<pre>&gt;&gt;&gt; imagewizard.Analysis().trim_to_content(img: Image, order: str = 'rgb')\n</pre>\n<p>Parameters:</p>\n<ul>\n<li>img: (numpy.array, PIL.image, cv2.image)</li>\n<li>order: (RGB, BGR) input order of the colors. If using PIL to read an image, \u2018order\u2019 need not be specified. <strong>If opencv is used to read an image, \u2018order\u2019 must be set to \u2018BGR\u2019</strong></li>\n</ul>\n<p>Returns:</p>\n<ul>\n<li>PIL/numpy.array of the order specified</li>\n</ul>\n<pre>&gt;&gt;&gt; import cv2\n&gt;&gt;&gt; from PIL import Image\n&gt;&gt;&gt; img_cv = cv2.imread('original_image.png')\n&gt;&gt;&gt; img_pil = Image.open(\"original_image.png\")\n</pre>\n<pre>&gt;&gt;&gt; imanalysis = imagewizard.Analysis()\n&gt;&gt;&gt; img_cv_result = imanalysis.trim_to_content(img_cv, 'bgr')\n&gt;&gt;&gt; img_pil_result = imanalysis.trim_to_content(img_pil)\n</pre>\n<pre>&gt;&gt;&gt; cv.imshow(\"original\", img_cv)\n&gt;&gt;&gt; cv.imshow(\"Trimmed Image\", img_cv_result)\n&gt;&gt;&gt; img_pil_result.show()\n</pre>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<tbody>\n<tr><td>Original</td>\n<td>Trimmed Image</td>\n</tr>\n<tr><td><img alt=\"quite_flow_org\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6d9096424a89b6705471c4f6d77f6b82122cafb5/74657374732f646174612f6f726967696e616c5f696d616765732f71756965745f666c6f7731302e706e67\"></td>\n<td><img alt=\"quite_flow_trim\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9875878d6af48ac8dec67f55a1bb8813e45ed753/74657374732f646174612f616e616c797365645f696d616765732f63726f705f746f5f636f6e74656e742f7472696d6d65645f71756974655f666c6f7731302e706e67\"></td>\n</tr>\n</tbody>\n</table>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<tbody>\n<tr><td>Original</td>\n<td>Trimmed Image</td>\n</tr>\n<tr><td><img alt=\"san_disk_org\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/957386a66aceeb24c26e923312cbf8dae336192d/74657374732f646174612f6f726967696e616c5f696d616765732f73616e5f6469736b5f77686974655f7061642e706e67\"></td>\n<td><img alt=\"san_disk_trim\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/224e94fd73e442dd7006f1f594a006d11333b5bb/74657374732f646174612f616e616c797365645f696d616765732f63726f705f746f5f636f6e74656e742f7472696d6d65645f73616e5f6469736b2e706e67\"></td>\n</tr>\n</tbody>\n</table>\n</div>\n</div>\n\n          </div>"}, "last_serial": 7147200, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "e6fed9ba12f3ffb1785b86a76c03a16c", "sha256": "eeb54b93d2d2677fe748df0e9b6f0eeb28246cb60001083f8a22aa53318222a8"}, "downloads": -1, "filename": "imagewizard-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "e6fed9ba12f3ffb1785b86a76c03a16c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 31403, "upload_time": "2020-02-14T11:31:08", "upload_time_iso_8601": "2020-02-14T11:31:08.343551Z", "url": "https://files.pythonhosted.org/packages/52/46/91363dff2c18dd0e5648b7b267a22545b4d1e94de836fe041eec1f10ad5f/imagewizard-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0458493ad2829870a6c0c5b63b88eda1", "sha256": "8a4b8ca57344fa941275117b8f32f957466af9b4a13a9ada97c3c7910d490ba0"}, "downloads": -1, "filename": "imagewizard-1.0.0.tar.gz", "has_sig": false, "md5_digest": "0458493ad2829870a6c0c5b63b88eda1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 37804, "upload_time": "2020-02-14T11:31:09", "upload_time_iso_8601": "2020-02-14T11:31:09.941948Z", "url": "https://files.pythonhosted.org/packages/96/71/9b2e49bafcc21dde8f38626864a37c55491332906d5c4315d22cb4f1a2e1/imagewizard-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "4b2975fb78d18175cf953d41550cd607", "sha256": "a241c00095a732f36f2126823e7436bffd788022c211c1c51109d73f4fca5601"}, "downloads": -1, "filename": "imagewizard-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "4b2975fb78d18175cf953d41550cd607", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 31397, "upload_time": "2020-03-09T08:48:38", "upload_time_iso_8601": "2020-03-09T08:48:38.425210Z", "url": "https://files.pythonhosted.org/packages/df/ea/0f92009c23f5b4543d26cf105a8b6342a800221a9283523454d8e056e1b3/imagewizard-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ca2c5654bac87161d7e2dbaef7320328", "sha256": "d88dafb5503239d122a35167d37df11ce3821e0fa6a69cc19236e88ec149c5ba"}, "downloads": -1, "filename": "imagewizard-1.0.1.tar.gz", "has_sig": false, "md5_digest": "ca2c5654bac87161d7e2dbaef7320328", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 37372, "upload_time": "2020-03-09T08:48:39", "upload_time_iso_8601": "2020-03-09T08:48:39.994198Z", "url": "https://files.pythonhosted.org/packages/10/49/c5014d3f4e3c3a85baeb38591a3e808927e3e0e63f360722bd6a4adc3950/imagewizard-1.0.1.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "3c16d5ff21051bf833cf309ac4c3e25f", "sha256": "ac583b276f55eb98f23f59fba888faa7ac22eacadff2c4b6a6095bd857729a88"}, "downloads": -1, "filename": "imagewizard-1.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "3c16d5ff21051bf833cf309ac4c3e25f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 31399, "upload_time": "2020-03-24T13:33:54", "upload_time_iso_8601": "2020-03-24T13:33:54.496414Z", "url": "https://files.pythonhosted.org/packages/af/6e/19ccb0987120e1b5b4aa80769f93f89bbfddc215c24b443a213b77a6424d/imagewizard-1.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4eb390064e0c43bbfd9b7a4a7a228598", "sha256": "ff5297e701f9a28b7ed10e841526a176a888119136655eeaf26873521d30f8d4"}, "downloads": -1, "filename": "imagewizard-1.1.0.tar.gz", "has_sig": false, "md5_digest": "4eb390064e0c43bbfd9b7a4a7a228598", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 37376, "upload_time": "2020-03-24T13:33:55", "upload_time_iso_8601": "2020-03-24T13:33:55.816424Z", "url": "https://files.pythonhosted.org/packages/e4/29/88faf9bdc29dcea92e4309b60e4a930f331244bc7cf53c3a4c5f5f577b87/imagewizard-1.1.0.tar.gz", "yanked": false}], "1.1.1": [{"comment_text": "", "digests": {"md5": "8b4abcdee8f3e2c2f555eac80e0f8b26", "sha256": "f5253b2156830e6826da14ed003885c828da72bf9c24942f501fb7af154d3dc6"}, "downloads": -1, "filename": "imagewizard-1.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "8b4abcdee8f3e2c2f555eac80e0f8b26", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 31426, "upload_time": "2020-04-09T12:51:09", "upload_time_iso_8601": "2020-04-09T12:51:09.404871Z", "url": "https://files.pythonhosted.org/packages/cc/81/4ad0ca3b9bb9b9e9ddc25ce79b97ea15fd2160022e6d6e0902b2ef5fcc8c/imagewizard-1.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "78fde10279c57116679dace90c334f71", "sha256": "9f78f45ba85ffeb1d6d532e7206c8d46046156de76f470b02bd14fd99ee1c13f"}, "downloads": -1, "filename": "imagewizard-1.1.1.tar.gz", "has_sig": false, "md5_digest": "78fde10279c57116679dace90c334f71", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 37942, "upload_time": "2020-04-09T12:51:10", "upload_time_iso_8601": "2020-04-09T12:51:10.796568Z", "url": "https://files.pythonhosted.org/packages/06/f2/591d140a712cf8f8d6fac1a6ee434daa67837a60d02913f3eba0f0952dc1/imagewizard-1.1.1.tar.gz", "yanked": false}], "1.1.2": [{"comment_text": "", "digests": {"md5": "f8df28f5c15b81f6d57eebcaaa83df08", "sha256": "64f61857f4a0b3901c4624493518fe37c3e91a426d9d06323316355d7fa5cb8a"}, "downloads": -1, "filename": "imagewizard-1.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "f8df28f5c15b81f6d57eebcaaa83df08", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 31439, "upload_time": "2020-05-01T19:08:32", "upload_time_iso_8601": "2020-05-01T19:08:32.786810Z", "url": "https://files.pythonhosted.org/packages/e4/f0/3414ba0d8c5c62317d8304554ae0373afe64825fb589f4c4f9113c0e7cbf/imagewizard-1.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f536bee10e27b2f4ddcb07207a00bdca", "sha256": "329934733603a6e54fbb95d1795401af1aac25fb9dbad6c439971b71d83cf353"}, "downloads": -1, "filename": "imagewizard-1.1.2.tar.gz", "has_sig": false, "md5_digest": "f536bee10e27b2f4ddcb07207a00bdca", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 37726, "upload_time": "2020-05-01T19:08:34", "upload_time_iso_8601": "2020-05-01T19:08:34.207681Z", "url": "https://files.pythonhosted.org/packages/1a/6c/264e8329c5c4abe24ac17aa14cc27b023e8c2a1de2e780e984801187ac16/imagewizard-1.1.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "f8df28f5c15b81f6d57eebcaaa83df08", "sha256": "64f61857f4a0b3901c4624493518fe37c3e91a426d9d06323316355d7fa5cb8a"}, "downloads": -1, "filename": "imagewizard-1.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "f8df28f5c15b81f6d57eebcaaa83df08", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 31439, "upload_time": "2020-05-01T19:08:32", "upload_time_iso_8601": "2020-05-01T19:08:32.786810Z", "url": "https://files.pythonhosted.org/packages/e4/f0/3414ba0d8c5c62317d8304554ae0373afe64825fb589f4c4f9113c0e7cbf/imagewizard-1.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f536bee10e27b2f4ddcb07207a00bdca", "sha256": "329934733603a6e54fbb95d1795401af1aac25fb9dbad6c439971b71d83cf353"}, "downloads": -1, "filename": "imagewizard-1.1.2.tar.gz", "has_sig": false, "md5_digest": "f536bee10e27b2f4ddcb07207a00bdca", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 37726, "upload_time": "2020-05-01T19:08:34", "upload_time_iso_8601": "2020-05-01T19:08:34.207681Z", "url": "https://files.pythonhosted.org/packages/1a/6c/264e8329c5c4abe24ac17aa14cc27b023e8c2a1de2e780e984801187ac16/imagewizard-1.1.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:56:48 2020"}