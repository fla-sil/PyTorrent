{"info": {"author": "Amazon Web Services", "author_email": "", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Intended Audience :: Developers", "License :: OSI Approved :: Apache Software License", "Natural Language :: English", "Programming Language :: Python", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.6"], "description": "=================================\nSageMaker MXNet Serving Container\n=================================\n\nSageMaker MXNet Serving Container is an open-source library for making Docker images for serving MXNet on Amazon SageMaker.\n\nThis library provides default pre-processing, predict and postprocessing for certain MXNet model types.\n\nThis library utilizes the `SageMaker Inference Toolkit <https://github.com/aws/sagemaker-inference-toolkit>`__ for starting up the model server, which is responsible for handling inference requests.\n\nOnly MXNet version 1.4 and higher are supported. For previous versions, see `SageMaker MXNet container <https://github.com/aws/sagemaker-mxnet-container>`__.\n\n-----------------\nTable of Contents\n-----------------\n.. contents::\n    :local:\n\nGetting Started\n---------------\n\nPrerequisites\n~~~~~~~~~~~~~\n\nMake sure you have installed all of the following prerequisites on your development machine:\n\n- `Docker <https://www.docker.com/>`__\n- For GPU testing: `nvidia-docker2 <https://github.com/NVIDIA/nvidia-docker>`__\n\nRecommended\n^^^^^^^^^^^\n\n-  A Python environment management tool (e.g. `PyEnv <https://github.com/pyenv/pyenv>`__,\n   `VirtualEnv <https://virtualenv.pypa.io/en/stable/>`__)\n\nBuilding Images\n---------------\n\nThe Dockerfiles in this repository are intended to be used for building Docker images to run inference endpoints on `Amazon SageMaker <https://aws.amazon.com/documentation/sagemaker/>`__.\n\nThe current master branch of this repository contains Dockerfiles and support code for MXNet versions 1.4.0 and higher. For previous versions, see `SageMaker MXNet container <https://github.com/aws/sagemaker-mxnet-container>`__.\nThe instructions in this version of this README are for MXNet 1.4.1 and higher. For MXNet 1.4.0, see `the previous version of this file <https://github.com/aws/sagemaker-mxnet-serving-container/blob/5ec2328c20612c2aa3474c978e459b4bca033f27/README.rst>`__.\n\nThe integration tests expect the Docker images to be tagged as ``preprod-mxnet-serving:<tag>``, where ``<tag>`` looks like <mxnet_version>-<processor>-<python_version> (e.g. 1.4.1-cpu-py3).\n\nExample commands for building images:\n\n::\n\n    # All build instructions assume you're starting from this repository's root directory.\n\n    # MXNet 1.6.0, Python 3, CPU\n    $ cp -r docker/artifacts/* docker/1.6.0/py3\n    $ cd docker/1.6.0/py3\n    $ docker build -t preprod-mxnet-serving:1.6.0-cpu-py3 -f Dockerfile.cpu .\n\n    # MXNet 1.6.0, Python 2, GPU\n    $ cp -r docker/artifacts/* docker/1.6.0/py2\n    $ cd docker/1.6.0/py2\n    $ docker build -t preprod-mxnet-serving:1.6.0-gpu-py2 -f docker/1.6.0/py2/Dockerfile.gpu .\n\nDon't forget the period at the end of the command!\n\nAmazon Elastic Inference with MXNet in SageMaker\n------------------------------------------------\n`Amazon Elastic Inference <https://aws.amazon.com/machine-learning/elastic-inference/>`__ allows you to to attach\nlow-cost GPU-powered acceleration to Amazon EC2 and Amazon SageMaker instances to reduce the cost of running deep\nlearning inference by up to 75%. Currently, Amazon Elastic Inference supports TensorFlow, Apache MXNet, and ONNX\nmodels, with more frameworks coming soon.\n\nSupport for using MXNet with Amazon Elastic Inference in SageMaker is supported in the public SageMaker MXNet containers.\n\n* For information on how to use the Python SDK to create an endpoint with Amazon Elastic Inference and MXNet in SageMaker, see `Deploying MXNet Models <https://sagemaker.readthedocs.io/en/stable/using_mxnet.html#deploying-mxnet-models>`__.\n* For information on how Amazon Elastic Inference works, see `How EI Works <https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html#ei-how-it-works>`__.\n* For more information in regards to using Amazon Elastic Inference in SageMaker, see `Amazon SageMaker Elastic Inference <https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html>`__.\n* For notebook examples on how to use Amazon Elastic Inference with MXNet through the Python SDK in SageMaker, see `EI Sample Notebooks <https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html#ei-intro-sample-nb>`__.\n\nBuilding the SageMaker Elastic Inference MXNet Serving container\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nAmazon Elastic Inference is designed to be used with AWS enhanced versions of TensorFlow serving or Apache MXNet. These enhanced\nversions of the frameworks are automatically built into containers when you use the Amazon SageMaker Python SDK, or you can\ndownload them as binary files and import them into your own Docker containers. The enhanced MXNet binaries are available on Amazon S3 at https://s3.console.aws.amazon.com/s3/buckets/amazonei-apachemxnet.\n\nThe SageMaker MXNet containers with Amazon Elastic Inference support were built utilizing the\nsame instructions listed `above <https://github.com/aws/sagemaker-mxnet-serving-container#building-images>`__ with the\nEIA Dockerfiles, which are all named ``Dockerfile.eia``, and can be found in the same ``docker/`` directory.\n\nExample:\n\n::\n\n    # MXNet 1.4.1, Python 3, EI\n    $ docker build -t preprod-mxnet-serving-eia:1.4.1-cpu-py3 -f docker/1.4.1/py3/Dockerfile.eia .\n\n\n* For information about downloading and installing the enhanced binary for Apache MXNet, see `Install Amazon EI Enabled Apache MXNet <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ei-mxnet.html#ei-apache>`__.\n* For information on which versions of MXNet is supported for Elastic Inference within SageMaker, see `MXNet SageMaker Estimators <https://github.com/aws/sagemaker-python-sdk#mxnet-sagemaker-estimators>`__.\n\nRunning the tests\n-----------------\n\nRunning the tests requires tox.\n\n::\n\n    git clone https://github.com/aws/sagemaker-mxnet-serving-container.git\n    cd sagemaker-mxnet-serving-container\n    tox\n\nTests are defined in `test/ <https://github.com/aws/sagemaker-mxnet-serving-container/tree/master/test>`__ and include unit and integration tests.\nThe integration tests include both running the Docker containers locally and running them on SageMaker.\nThe tests are compatible with only the Docker images built by Dockerfiles in the current branch.\n\nAll test instructions should be run from the top level directory\n\nUnit Tests\n~~~~~~~~~~\n\nTo run unit tests:\n\n::\n\n    tox test/unit\n\nLocal Integration Tests\n~~~~~~~~~~~~~~~~~~~~~~~\n\nRunning local integration tests require `Docker <https://www.docker.com/>`__ and `AWS credentials <https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/setup-credentials.html>`__,\nas the integration tests make calls to a couple AWS services.\nLocal integration tests on GPU require `nvidia-docker2 <https://github.com/NVIDIA/nvidia-docker>`__.\nYou Docker image must also be built in order to run the tests against it.\n\nLocal integration tests use the following pytest arguments:\n\n- ``docker-base-name``: the Docker image's repository. Defaults to 'preprod-mxnet-serving'.\n- ``framework-version``: the MXNet version. Defaults to the latest supported version.\n- ``py-version``: the Python version. Defaults to '3'.\n- ``processor``: CPU or GPU. Defaults to 'cpu'.\n- ``tag``: the Docker image's tag. Defaults to <mxnet_version>-<processor>-py<py-version>\n\nTo run local integration tests:\n\n::\n\n    tox test/integration/local -- --docker-base-name <your_docker_image> \\\n                                  --tag <your_docker_image_tag> \\\n                                  --py-version <2_or_3> \\\n                                  --framework-version <mxnet_version> \\\n                                  --processor <cpu_or_gpu>\n\n::\n\n    # Example\n    tox test/integration/local -- --docker-base-name preprod-mxnet-serving \\\n                                  --tag 1.6.0-cpu-py3 \\\n                                  --py-version 3 \\\n                                  --framework-version 1.6.0 \\\n                                  --processor cpu\n\nSageMaker Integration Tests\n~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nSageMaker integration tests require your Docker image to be within an `Amazon ECR repository <https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ECS_Console_Repositories.html>`__.\nThey also require that you have the setup described under \"Integration Tests\" at https://github.com/aws/sagemaker-python-sdk#running-tests.\n\nSageMaker integration tests use the following pytest arguments:\n\n- ``docker-base-name``: the Docker image's `ECR repository namespace <https://docs.aws.amazon.com/AmazonECR/latest/userguide/Repositories.html>`__.\n- ``framework-version``: the MXNet version. Defaults to the latest supported version.\n- ``py-version``: the Python version. Defaults to '3'.\n- ``processor``: CPU or GPU. Defaults to 'cpu'.\n- ``tag``: the Docker image's tag. Defaults to <mxnet_version>-<processor>-py<py-version>\n- ``aws-id``: your AWS account ID.\n- ``instance-type``: the specified `Amazon SageMaker Instance Type <https://aws.amazon.com/sagemaker/pricing/instance-types/>`__ that the tests will run on.\n  Defaults to 'ml.c4.xlarge' for CPU and 'ml.p2.xlarge' for GPU.\n\nTo run SageMaker integration tests:\n\n::\n\n    tox test/integration/sagmaker -- --aws-id <your_aws_id> \\\n                                     --docker-base-name <your_docker_image> \\\n                                     --instance-type <amazon_sagemaker_instance_type> \\\n                                     --tag <your_docker_image_tag> \\\n\n::\n\n    # Example\n    tox test/integration/sagemaker -- --aws-id 12345678910 \\\n                                      --docker-base-name preprod-mxnet-serving \\\n                                      --instance-type ml.m4.xlarge \\\n                                      --tag 1.6.0-cpu-py3\n\nIf you want to run a SageMaker end to end test for your Elastic Inference container, you will need to provide an ``accelerator_type`` as an additional pytest argument.\n\nThe ``accelerator-type`` is your specified `Amazon Elastic Inference Accelerator <https://aws.amazon.com/sagemaker/pricing/instance-types/>`__ type that will be attached to your instance type.\n\n::\n\n    # Example for running Elastic Inference SageMaker end to end test\n    tox test/integration/sagemaker/test_elastic_inference.py -- --aws-id 12345678910 \\\n                                                                --docker-base-name preprod-mxnet-serving \\\n                                                                --instance-type ml.m4.xlarge \\\n                                                                --accelerator-type ml.eia1.medium \\\n                                                                --tag 1.0\n\nContributing\n------------\n\nPlease read `CONTRIBUTING.md <https://github.com/aws/sagemaker-mxnet-serving-container/blob/master/CONTRIBUTING.md>`__\nfor details on our code of conduct, and the process for submitting pull requests to us.\n\nLicense\n-------\n\nSageMaker MXNet Containers is licensed under the Apache 2.0 License.\nIt is copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\nThe license is available at: http://aws.amazon.com/apache2.0/", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/aws/sagemaker-mxnet-serving-container", "keywords": "", "license": "Apache License 2.0", "maintainer": "", "maintainer_email": "", "name": "sagemaker-mxnet-inference", "package_url": "https://pypi.org/project/sagemaker-mxnet-inference/", "platform": "", "project_url": "https://pypi.org/project/sagemaker-mxnet-inference/", "project_urls": {"Homepage": "https://github.com/aws/sagemaker-mxnet-serving-container"}, "release_url": "https://pypi.org/project/sagemaker-mxnet-inference/1.3.3.post0/", "requires_dist": null, "requires_python": "", "summary": "Open source library for creating MXNet containers for serving on SageMaker.", "version": "1.3.3.post0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>SageMaker MXNet Serving Container is an open-source library for making Docker images for serving MXNet on Amazon SageMaker.</p>\n<p>This library provides default pre-processing, predict and postprocessing for certain MXNet model types.</p>\n<p>This library utilizes the <a href=\"https://github.com/aws/sagemaker-inference-toolkit\" rel=\"nofollow\">SageMaker Inference Toolkit</a> for starting up the model server, which is responsible for handling inference requests.</p>\n<p>Only MXNet version 1.4 and higher are supported. For previous versions, see <a href=\"https://github.com/aws/sagemaker-mxnet-container\" rel=\"nofollow\">SageMaker MXNet container</a>.</p>\n<div id=\"table-of-contents\">\n<h2>Table of Contents</h2>\n<div id=\"contents\">\n<ul>\n<li><a href=\"#getting-started\" id=\"id1\" rel=\"nofollow\">Getting Started</a><ul>\n<li><a href=\"#recommended\" id=\"id2\" rel=\"nofollow\">Recommended</a></li>\n</ul>\n</li>\n<li><a href=\"#building-images\" id=\"id3\" rel=\"nofollow\">Building Images</a></li>\n<li><a href=\"#amazon-elastic-inference-with-mxnet-in-sagemaker\" id=\"id4\" rel=\"nofollow\">Amazon Elastic Inference with MXNet in SageMaker</a><ul>\n<li><a href=\"#building-the-sagemaker-elastic-inference-mxnet-serving-container\" id=\"id5\" rel=\"nofollow\">Building the SageMaker Elastic Inference MXNet Serving container</a></li>\n</ul>\n</li>\n<li><a href=\"#running-the-tests\" id=\"id6\" rel=\"nofollow\">Running the tests</a><ul>\n<li><a href=\"#unit-tests\" id=\"id7\" rel=\"nofollow\">Unit Tests</a></li>\n<li><a href=\"#local-integration-tests\" id=\"id8\" rel=\"nofollow\">Local Integration Tests</a></li>\n<li><a href=\"#sagemaker-integration-tests\" id=\"id9\" rel=\"nofollow\">SageMaker Integration Tests</a></li>\n</ul>\n</li>\n<li><a href=\"#contributing\" id=\"id10\" rel=\"nofollow\">Contributing</a></li>\n<li><a href=\"#license\" id=\"id11\" rel=\"nofollow\">License</a></li>\n</ul>\n</div>\n<div id=\"getting-started\">\n<h3><a href=\"#id1\" rel=\"nofollow\">Getting Started</a></h3>\n<h3 id=\"prerequisites\"><span class=\"section-subtitle\">Prerequisites</span></h3>\n<p>Make sure you have installed all of the following prerequisites on your development machine:</p>\n<ul>\n<li><a href=\"https://www.docker.com/\" rel=\"nofollow\">Docker</a></li>\n<li>For GPU testing: <a href=\"https://github.com/NVIDIA/nvidia-docker\" rel=\"nofollow\">nvidia-docker2</a></li>\n</ul>\n<div id=\"recommended\">\n<h4><a href=\"#id2\" rel=\"nofollow\">Recommended</a></h4>\n<ul>\n<li>A Python environment management tool (e.g. <a href=\"https://github.com/pyenv/pyenv\" rel=\"nofollow\">PyEnv</a>,\n<a href=\"https://virtualenv.pypa.io/en/stable/\" rel=\"nofollow\">VirtualEnv</a>)</li>\n</ul>\n</div>\n</div>\n<div id=\"building-images\">\n<h3><a href=\"#id3\" rel=\"nofollow\">Building Images</a></h3>\n<p>The Dockerfiles in this repository are intended to be used for building Docker images to run inference endpoints on <a href=\"https://aws.amazon.com/documentation/sagemaker/\" rel=\"nofollow\">Amazon SageMaker</a>.</p>\n<p>The current master branch of this repository contains Dockerfiles and support code for MXNet versions 1.4.0 and higher. For previous versions, see <a href=\"https://github.com/aws/sagemaker-mxnet-container\" rel=\"nofollow\">SageMaker MXNet container</a>.\nThe instructions in this version of this README are for MXNet 1.4.1 and higher. For MXNet 1.4.0, see <a href=\"https://github.com/aws/sagemaker-mxnet-serving-container/blob/5ec2328c20612c2aa3474c978e459b4bca033f27/README.rst\" rel=\"nofollow\">the previous version of this file</a>.</p>\n<p>The integration tests expect the Docker images to be tagged as <tt><span class=\"pre\">preprod-mxnet-serving:&lt;tag&gt;</span></tt>, where <tt>&lt;tag&gt;</tt> looks like &lt;mxnet_version&gt;-&lt;processor&gt;-&lt;python_version&gt; (e.g. 1.4.1-cpu-py3).</p>\n<p>Example commands for building images:</p>\n<pre># All build instructions assume you're starting from this repository's root directory.\n\n# MXNet 1.6.0, Python 3, CPU\n$ cp -r docker/artifacts/* docker/1.6.0/py3\n$ cd docker/1.6.0/py3\n$ docker build -t preprod-mxnet-serving:1.6.0-cpu-py3 -f Dockerfile.cpu .\n\n# MXNet 1.6.0, Python 2, GPU\n$ cp -r docker/artifacts/* docker/1.6.0/py2\n$ cd docker/1.6.0/py2\n$ docker build -t preprod-mxnet-serving:1.6.0-gpu-py2 -f docker/1.6.0/py2/Dockerfile.gpu .\n</pre>\n<p>Don\u2019t forget the period at the end of the command!</p>\n</div>\n<div id=\"amazon-elastic-inference-with-mxnet-in-sagemaker\">\n<h3><a href=\"#id4\" rel=\"nofollow\">Amazon Elastic Inference with MXNet in SageMaker</a></h3>\n<p><a href=\"https://aws.amazon.com/machine-learning/elastic-inference/\" rel=\"nofollow\">Amazon Elastic Inference</a> allows you to to attach\nlow-cost GPU-powered acceleration to Amazon EC2 and Amazon SageMaker instances to reduce the cost of running deep\nlearning inference by up to 75%. Currently, Amazon Elastic Inference supports TensorFlow, Apache MXNet, and ONNX\nmodels, with more frameworks coming soon.</p>\n<p>Support for using MXNet with Amazon Elastic Inference in SageMaker is supported in the public SageMaker MXNet containers.</p>\n<ul>\n<li>For information on how to use the Python SDK to create an endpoint with Amazon Elastic Inference and MXNet in SageMaker, see <a href=\"https://sagemaker.readthedocs.io/en/stable/using_mxnet.html#deploying-mxnet-models\" rel=\"nofollow\">Deploying MXNet Models</a>.</li>\n<li>For information on how Amazon Elastic Inference works, see <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html#ei-how-it-works\" rel=\"nofollow\">How EI Works</a>.</li>\n<li>For more information in regards to using Amazon Elastic Inference in SageMaker, see <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html\" rel=\"nofollow\">Amazon SageMaker Elastic Inference</a>.</li>\n<li>For notebook examples on how to use Amazon Elastic Inference with MXNet through the Python SDK in SageMaker, see <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html#ei-intro-sample-nb\" rel=\"nofollow\">EI Sample Notebooks</a>.</li>\n</ul>\n<div id=\"building-the-sagemaker-elastic-inference-mxnet-serving-container\">\n<h4><a href=\"#id5\" rel=\"nofollow\">Building the SageMaker Elastic Inference MXNet Serving container</a></h4>\n<p>Amazon Elastic Inference is designed to be used with AWS enhanced versions of TensorFlow serving or Apache MXNet. These enhanced\nversions of the frameworks are automatically built into containers when you use the Amazon SageMaker Python SDK, or you can\ndownload them as binary files and import them into your own Docker containers. The enhanced MXNet binaries are available on Amazon S3 at <a href=\"https://s3.console.aws.amazon.com/s3/buckets/amazonei-apachemxnet\" rel=\"nofollow\">https://s3.console.aws.amazon.com/s3/buckets/amazonei-apachemxnet</a>.</p>\n<p>The SageMaker MXNet containers with Amazon Elastic Inference support were built utilizing the\nsame instructions listed <a href=\"https://github.com/aws/sagemaker-mxnet-serving-container#building-images\" rel=\"nofollow\">above</a> with the\nEIA Dockerfiles, which are all named <tt>Dockerfile.eia</tt>, and can be found in the same <tt>docker/</tt> directory.</p>\n<p>Example:</p>\n<pre># MXNet 1.4.1, Python 3, EI\n$ docker build -t preprod-mxnet-serving-eia:1.4.1-cpu-py3 -f docker/1.4.1/py3/Dockerfile.eia .\n</pre>\n<ul>\n<li>For information about downloading and installing the enhanced binary for Apache MXNet, see <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ei-mxnet.html#ei-apache\" rel=\"nofollow\">Install Amazon EI Enabled Apache MXNet</a>.</li>\n<li>For information on which versions of MXNet is supported for Elastic Inference within SageMaker, see <a href=\"https://github.com/aws/sagemaker-python-sdk#mxnet-sagemaker-estimators\" rel=\"nofollow\">MXNet SageMaker Estimators</a>.</li>\n</ul>\n</div>\n</div>\n<div id=\"running-the-tests\">\n<h3><a href=\"#id6\" rel=\"nofollow\">Running the tests</a></h3>\n<p>Running the tests requires tox.</p>\n<pre>git clone https://github.com/aws/sagemaker-mxnet-serving-container.git\ncd sagemaker-mxnet-serving-container\ntox\n</pre>\n<p>Tests are defined in <a href=\"https://github.com/aws/sagemaker-mxnet-serving-container/tree/master/test\" rel=\"nofollow\">test/</a> and include unit and integration tests.\nThe integration tests include both running the Docker containers locally and running them on SageMaker.\nThe tests are compatible with only the Docker images built by Dockerfiles in the current branch.</p>\n<p>All test instructions should be run from the top level directory</p>\n<div id=\"unit-tests\">\n<h4><a href=\"#id7\" rel=\"nofollow\">Unit Tests</a></h4>\n<p>To run unit tests:</p>\n<pre>tox test/unit\n</pre>\n</div>\n<div id=\"local-integration-tests\">\n<h4><a href=\"#id8\" rel=\"nofollow\">Local Integration Tests</a></h4>\n<p>Running local integration tests require <a href=\"https://www.docker.com/\" rel=\"nofollow\">Docker</a> and <a href=\"https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/setup-credentials.html\" rel=\"nofollow\">AWS credentials</a>,\nas the integration tests make calls to a couple AWS services.\nLocal integration tests on GPU require <a href=\"https://github.com/NVIDIA/nvidia-docker\" rel=\"nofollow\">nvidia-docker2</a>.\nYou Docker image must also be built in order to run the tests against it.</p>\n<p>Local integration tests use the following pytest arguments:</p>\n<ul>\n<li><tt><span class=\"pre\">docker-base-name</span></tt>: the Docker image\u2019s repository. Defaults to \u2018preprod-mxnet-serving\u2019.</li>\n<li><tt><span class=\"pre\">framework-version</span></tt>: the MXNet version. Defaults to the latest supported version.</li>\n<li><tt><span class=\"pre\">py-version</span></tt>: the Python version. Defaults to \u20183\u2019.</li>\n<li><tt>processor</tt>: CPU or GPU. Defaults to \u2018cpu\u2019.</li>\n<li><tt>tag</tt>: the Docker image\u2019s tag. Defaults to &lt;mxnet_version&gt;-&lt;processor&gt;-py&lt;py-version&gt;</li>\n</ul>\n<p>To run local integration tests:</p>\n<pre>tox test/integration/local -- --docker-base-name &lt;your_docker_image&gt; \\\n                              --tag &lt;your_docker_image_tag&gt; \\\n                              --py-version &lt;2_or_3&gt; \\\n                              --framework-version &lt;mxnet_version&gt; \\\n                              --processor &lt;cpu_or_gpu&gt;\n</pre>\n<pre># Example\ntox test/integration/local -- --docker-base-name preprod-mxnet-serving \\\n                              --tag 1.6.0-cpu-py3 \\\n                              --py-version 3 \\\n                              --framework-version 1.6.0 \\\n                              --processor cpu\n</pre>\n</div>\n<div id=\"sagemaker-integration-tests\">\n<h4><a href=\"#id9\" rel=\"nofollow\">SageMaker Integration Tests</a></h4>\n<p>SageMaker integration tests require your Docker image to be within an <a href=\"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ECS_Console_Repositories.html\" rel=\"nofollow\">Amazon ECR repository</a>.\nThey also require that you have the setup described under \u201cIntegration Tests\u201d at <a href=\"https://github.com/aws/sagemaker-python-sdk#running-tests\" rel=\"nofollow\">https://github.com/aws/sagemaker-python-sdk#running-tests</a>.</p>\n<p>SageMaker integration tests use the following pytest arguments:</p>\n<ul>\n<li><tt><span class=\"pre\">docker-base-name</span></tt>: the Docker image\u2019s <a href=\"https://docs.aws.amazon.com/AmazonECR/latest/userguide/Repositories.html\" rel=\"nofollow\">ECR repository namespace</a>.</li>\n<li><tt><span class=\"pre\">framework-version</span></tt>: the MXNet version. Defaults to the latest supported version.</li>\n<li><tt><span class=\"pre\">py-version</span></tt>: the Python version. Defaults to \u20183\u2019.</li>\n<li><tt>processor</tt>: CPU or GPU. Defaults to \u2018cpu\u2019.</li>\n<li><tt>tag</tt>: the Docker image\u2019s tag. Defaults to &lt;mxnet_version&gt;-&lt;processor&gt;-py&lt;py-version&gt;</li>\n<li><tt><span class=\"pre\">aws-id</span></tt>: your AWS account ID.</li>\n<li><tt><span class=\"pre\">instance-type</span></tt>: the specified <a href=\"https://aws.amazon.com/sagemaker/pricing/instance-types/\" rel=\"nofollow\">Amazon SageMaker Instance Type</a> that the tests will run on.\nDefaults to \u2018ml.c4.xlarge\u2019 for CPU and \u2018ml.p2.xlarge\u2019 for GPU.</li>\n</ul>\n<p>To run SageMaker integration tests:</p>\n<pre>tox test/integration/sagmaker -- --aws-id &lt;your_aws_id&gt; \\\n                                 --docker-base-name &lt;your_docker_image&gt; \\\n                                 --instance-type &lt;amazon_sagemaker_instance_type&gt; \\\n                                 --tag &lt;your_docker_image_tag&gt; \\\n</pre>\n<pre># Example\ntox test/integration/sagemaker -- --aws-id 12345678910 \\\n                                  --docker-base-name preprod-mxnet-serving \\\n                                  --instance-type ml.m4.xlarge \\\n                                  --tag 1.6.0-cpu-py3\n</pre>\n<p>If you want to run a SageMaker end to end test for your Elastic Inference container, you will need to provide an <tt>accelerator_type</tt> as an additional pytest argument.</p>\n<p>The <tt><span class=\"pre\">accelerator-type</span></tt> is your specified <a href=\"https://aws.amazon.com/sagemaker/pricing/instance-types/\" rel=\"nofollow\">Amazon Elastic Inference Accelerator</a> type that will be attached to your instance type.</p>\n<pre># Example for running Elastic Inference SageMaker end to end test\ntox test/integration/sagemaker/test_elastic_inference.py -- --aws-id 12345678910 \\\n                                                            --docker-base-name preprod-mxnet-serving \\\n                                                            --instance-type ml.m4.xlarge \\\n                                                            --accelerator-type ml.eia1.medium \\\n                                                            --tag 1.0\n</pre>\n</div>\n</div>\n<div id=\"contributing\">\n<h3><a href=\"#id10\" rel=\"nofollow\">Contributing</a></h3>\n<p>Please read <a href=\"https://github.com/aws/sagemaker-mxnet-serving-container/blob/master/CONTRIBUTING.md\" rel=\"nofollow\">CONTRIBUTING.md</a>\nfor details on our code of conduct, and the process for submitting pull requests to us.</p>\n</div>\n<div id=\"license\">\n<h3><a href=\"#id11\" rel=\"nofollow\">License</a></h3>\n<p>SageMaker MXNet Containers is licensed under the Apache 2.0 License.\nIt is copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\nThe license is available at: <a href=\"http://aws.amazon.com/apache2.0/\" rel=\"nofollow\">http://aws.amazon.com/apache2.0/</a></p>\n</div>\n</div>\n\n          </div>"}, "last_serial": 7136628, "releases": {"1.2.0": [{"comment_text": "", "digests": {"md5": "81ef348ed9a5bb3d3aaba7aa2235e464", "sha256": "c583af12467ef142c2c1767507927440a68cf1ccec35d5ef3cf7c08558c0ed03"}, "downloads": -1, "filename": "sagemaker_mxnet_inference-1.2.0.tar.gz", "has_sig": true, "md5_digest": "81ef348ed9a5bb3d3aaba7aa2235e464", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17408, "upload_time": "2020-02-12T05:44:32", "upload_time_iso_8601": "2020-02-12T05:44:32.996127Z", "url": "https://files.pythonhosted.org/packages/62/19/82aad55602518a1bf180d3e4f413085016f23500f439e58aca8f15734794/sagemaker_mxnet_inference-1.2.0.tar.gz", "yanked": false}], "1.2.1": [{"comment_text": "", "digests": {"md5": "550bde4ae5e845f00b7a9a78b5499e1e", "sha256": "fd1fb371f3d6e554985118ebb9d4f52e76b9849a6b3742a8fe3c72bac264f8af"}, "downloads": -1, "filename": "sagemaker_mxnet_inference-1.2.1.tar.gz", "has_sig": true, "md5_digest": "550bde4ae5e845f00b7a9a78b5499e1e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17416, "upload_time": "2020-02-17T11:20:22", "upload_time_iso_8601": "2020-02-17T11:20:22.668993Z", "url": "https://files.pythonhosted.org/packages/27/88/8c37ca7bd26ffdc9b301efbffe756d518eb195c7c5ec1a12bc808848f45c/sagemaker_mxnet_inference-1.2.1.tar.gz", "yanked": false}], "1.2.2": [{"comment_text": "", "digests": {"md5": "d2f44d4d0cceb21ae95beca8209036fe", "sha256": "ac52fe6e225b7e0d3f1788c39c1b56579279b5ee2034858be78dd571a3a2fcde"}, "downloads": -1, "filename": "sagemaker_mxnet_inference-1.2.2.tar.gz", "has_sig": true, "md5_digest": "d2f44d4d0cceb21ae95beca8209036fe", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17418, "upload_time": "2020-02-19T11:19:25", "upload_time_iso_8601": "2020-02-19T11:19:25.789380Z", "url": "https://files.pythonhosted.org/packages/39/50/4e29c911621401efc8075d8fe0bddd51a145109838b6445293e91e6ca7f3/sagemaker_mxnet_inference-1.2.2.tar.gz", "yanked": false}], "1.2.3": [{"comment_text": "", "digests": {"md5": "57deb1c461cf62f202b1e1ec435383e5", "sha256": "036ff4a6a299cf40182be978a7832e00db10f2fc4b8aafe1a6ca362ef9ae988b"}, "downloads": -1, "filename": "sagemaker_mxnet_inference-1.2.3.tar.gz", "has_sig": true, "md5_digest": "57deb1c461cf62f202b1e1ec435383e5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17417, "upload_time": "2020-02-20T11:19:58", "upload_time_iso_8601": "2020-02-20T11:19:58.505909Z", "url": "https://files.pythonhosted.org/packages/05/34/c35b74334b21692fde95660578f0a6aec8a30d2807a24df4da3d8b5823ba/sagemaker_mxnet_inference-1.2.3.tar.gz", "yanked": false}], "1.2.4": [{"comment_text": "", "digests": {"md5": "45872de4f3ea4491a3c16b2a2bd45a63", "sha256": "4837446356aa1c56b3fda656e353f62ac401e79996d0a35e51a7105c7b445c87"}, "downloads": -1, "filename": "sagemaker_mxnet_inference-1.2.4.tar.gz", "has_sig": true, "md5_digest": "45872de4f3ea4491a3c16b2a2bd45a63", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17529, "upload_time": "2020-03-04T23:23:02", "upload_time_iso_8601": "2020-03-04T23:23:02.684053Z", "url": "https://files.pythonhosted.org/packages/ef/1b/1c581ec00df1a9dcc598ff26603ab83083fbbb0ae3d29f8e6c1e2027300a/sagemaker_mxnet_inference-1.2.4.tar.gz", "yanked": false}], "1.2.5": [{"comment_text": "", "digests": {"md5": "b0e3c35c6289d1ffd266a6f9cebc0881", "sha256": "7c780b53875caf58e307c958a42cd09440170aec55f6ba9a138000b15df1770a"}, "downloads": -1, "filename": "sagemaker_mxnet_inference-1.2.5.tar.gz", "has_sig": true, "md5_digest": "b0e3c35c6289d1ffd266a6f9cebc0881", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17536, "upload_time": "2020-03-09T11:19:26", "upload_time_iso_8601": "2020-03-09T11:19:26.590785Z", "url": "https://files.pythonhosted.org/packages/ad/69/602abe58d62e0975f8d0d0bfc76aafb1c41012861c01a12fb89d41f993f8/sagemaker_mxnet_inference-1.2.5.tar.gz", "yanked": false}], "1.2.6": [{"comment_text": "", "digests": {"md5": "ce0711847ad62a26f9316d766409b2f6", "sha256": "2d817a0d6e68c14529728fa989542ae81272992bfc56f4378eade688c767ff15"}, "downloads": -1, "filename": "sagemaker_mxnet_inference-1.2.6.tar.gz", "has_sig": true, "md5_digest": "ce0711847ad62a26f9316d766409b2f6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17533, "upload_time": "2020-03-11T11:20:00", "upload_time_iso_8601": "2020-03-11T11:20:00.247156Z", "url": "https://files.pythonhosted.org/packages/f2/1d/0359a5bf3f2d56a57b1d23615918abca583a5990c7e9699d86e9825c05c3/sagemaker_mxnet_inference-1.2.6.tar.gz", "yanked": false}], "1.2.6.post0": [{"comment_text": "", "digests": {"md5": "3c62f70c42b5d1b1ef1cce6095d47e8a", "sha256": "e625db55d088bf7ca524a02a48919f2f10dead008e0f69f35b35ada578384001"}, "downloads": -1, "filename": "sagemaker_mxnet_inference-1.2.6.post0.tar.gz", "has_sig": true, "md5_digest": "3c62f70c42b5d1b1ef1cce6095d47e8a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16846, "upload_time": "2020-03-24T11:19:54", "upload_time_iso_8601": "2020-03-24T11:19:54.028615Z", "url": "https://files.pythonhosted.org/packages/ee/2d/a3e15010653da1e2f67dfaa03be6ae729b59e487cd51dbe3476142aa2bb5/sagemaker_mxnet_inference-1.2.6.post0.tar.gz", "yanked": false}], "1.3.0": [{"comment_text": "", "digests": {"md5": "53bb26505046a19d0be853a3913386fb", "sha256": "78fe20bf6f9f094c29eb7f5d073e21717b846c44c7a80f7ba532b5934a0c1528"}, "downloads": -1, "filename": "sagemaker_mxnet_inference-1.3.0.tar.gz", "has_sig": true, "md5_digest": "53bb26505046a19d0be853a3913386fb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16326, "upload_time": "2020-03-30T11:19:53", "upload_time_iso_8601": "2020-03-30T11:19:53.485429Z", "url": "https://files.pythonhosted.org/packages/d1/5b/88c843fb37f92d6e7a574b0ce8ca26d30837850c10fcd09662d5f82a23be/sagemaker_mxnet_inference-1.3.0.tar.gz", "yanked": false}], "1.3.1": [{"comment_text": "", "digests": {"md5": "a0def71d9d858f64799d18ae707e1034", "sha256": "02247a2b22cd6ab67f33423b9f3ee8b66a052507f9ee143b97baf45219b27711"}, "downloads": -1, "filename": "sagemaker_mxnet_inference-1.3.1.tar.gz", "has_sig": true, "md5_digest": "a0def71d9d858f64799d18ae707e1034", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16412, "upload_time": "2020-04-01T11:19:57", "upload_time_iso_8601": "2020-04-01T11:19:57.458690Z", "url": "https://files.pythonhosted.org/packages/1e/ad/c4e533547684553e94429c666a2ed6c7d0276bbed22c006d599babe37ccc/sagemaker_mxnet_inference-1.3.1.tar.gz", "yanked": false}], "1.3.2": [{"comment_text": "", "digests": {"md5": "0ca57266f473bb0f951fe6276519f42e", "sha256": "bb5bc2451b50362ed70e60d1fa88d6c855f26e2ab702ac92bb8fb072b26721df"}, "downloads": -1, "filename": "sagemaker_mxnet_inference-1.3.2.tar.gz", "has_sig": true, "md5_digest": "0ca57266f473bb0f951fe6276519f42e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16410, "upload_time": "2020-04-01T22:03:22", "upload_time_iso_8601": "2020-04-01T22:03:22.466343Z", "url": "https://files.pythonhosted.org/packages/3a/27/27fa14409a571adbaf555dc90ad4b1ed8544409868ccc0f399bb2834311e/sagemaker_mxnet_inference-1.3.2.tar.gz", "yanked": false}], "1.3.3": [{"comment_text": "", "digests": {"md5": "b506ce309327123ce35ff1b55afa3115", "sha256": "8fa3b590a138f9fd5c3f7f0cc9f4f92ce731654b8f0a633aaf32f7ee877d30e4"}, "downloads": -1, "filename": "sagemaker_mxnet_inference-1.3.3.tar.gz", "has_sig": true, "md5_digest": "b506ce309327123ce35ff1b55afa3115", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16452, "upload_time": "2020-04-28T11:19:56", "upload_time_iso_8601": "2020-04-28T11:19:56.568700Z", "url": "https://files.pythonhosted.org/packages/a3/be/807a8e273489d072cb73f78d3193d1a61ce6236f183388c1f3e7fe71c1f9/sagemaker_mxnet_inference-1.3.3.tar.gz", "yanked": false}], "1.3.3.post0": [{"comment_text": "", "digests": {"md5": "31c5a99a431fddc9ec5049d1537b8326", "sha256": "e350266ace52fc2242761bd57183f3dfd34b2a60563aedc0a88f9d73795685ef"}, "downloads": -1, "filename": "sagemaker_mxnet_inference-1.3.3.post0.tar.gz", "has_sig": true, "md5_digest": "31c5a99a431fddc9ec5049d1537b8326", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16586, "upload_time": "2020-04-30T11:20:40", "upload_time_iso_8601": "2020-04-30T11:20:40.323412Z", "url": "https://files.pythonhosted.org/packages/1a/9a/3fb1a613cbc8f892de4024160996db16d540aa428e6718f9a95d3e0164e1/sagemaker_mxnet_inference-1.3.3.post0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "31c5a99a431fddc9ec5049d1537b8326", "sha256": "e350266ace52fc2242761bd57183f3dfd34b2a60563aedc0a88f9d73795685ef"}, "downloads": -1, "filename": "sagemaker_mxnet_inference-1.3.3.post0.tar.gz", "has_sig": true, "md5_digest": "31c5a99a431fddc9ec5049d1537b8326", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16586, "upload_time": "2020-04-30T11:20:40", "upload_time_iso_8601": "2020-04-30T11:20:40.323412Z", "url": "https://files.pythonhosted.org/packages/1a/9a/3fb1a613cbc8f892de4024160996db16d540aa428e6718f9a95d3e0164e1/sagemaker_mxnet_inference-1.3.3.post0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:59:17 2020"}