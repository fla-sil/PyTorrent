{"info": {"author": "Todd Francis DeLuca", "author_email": "todddeluca@yahoo.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7"], "description": "## Introduction\n\nThe dones module can be used to mark whether a key is \"done\" and check whether\na key has been marked \"done\".  Keys can also be unmarked, so that they are no\nlonger \"done\".  Also, all keys can be unmarked by clearing the Dones.\nKeys are kept in their own namespace to avoid conflicts with other\nsets of other keys and to make it easy to implement clearing.\n\nWhy?  I use `dones` to keep track of what I've already done.  More\nspecifically, I run large computations (a few million tasks) on a large cluster\n(a few thousand cores) with a slow filesystem (Isilon).  When tasks inevitably\nfail, perhaps because the network storage goes offline, or a computer dies, or\nanother user overwhelms the database with connections, I need to resubmit the\ntasks to the batch queuing system (LSF) of the cluster that are not already\ndone.  \n\nThe solution in this module fits my constraints.  It handles the concurrent\nwrites of a thousand jobs marking things done (not all at once).  It is\nreasonably fast for reading and writing up to millions of jobs.  This is\nimportant because or batch queue (LSF) only handles a few thousand jobs at a\ntime gracefully.  Finally, `dones` uses MySQL as a backend, which is important\nbecause I cannot run a key-value server like Redis on the cluster I use.\n\n\n## Contribute\n\nFeel free to make a pull request on github.\n\n\n## Testing\n\nAwkwardly, `dones` is configured with a MySQL database url from the\nenvironment, so to test it, you need to add a url.  For example:\n\n    DONES_DB_URL=mysql://myuser:password@localhost/mydb nosetests\n\n\n## Requirements\n\n- Probably Python 2.7 (since that is the only version it has been tested with.)\n- MySQL-python PyPI package.\n\n\n## Installation\n\n\n### Install from pypi.python.org\n\nDownload and install using pip:\n\n    pip install dones\n\n\n### Install from github.com\n\nUsing github, one can clone and install a specific version of the package:\n\n    cd ~\n    git clone git@github.com:todddeluca/dones.git\n    cd dones\n    python setup.py install\n\nOr use pip:\n\n    pip install git+git://github.com/todddeluca/dones.git#egg=dones\n\n\n## Usage\n\n\n    import dones\n\n    if not dones.get('my_pipeline').done('task1'):\n        dotask('task1')\n        dones.get('my_pipleline').mark('task1')", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/todddeluca/dones", "keywords": "mysql keystore batch queue LSF", "license": "MIT", "maintainer": null, "maintainer_email": null, "name": "dones", "package_url": "https://pypi.org/project/dones/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/dones/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/todddeluca/dones"}, "release_url": "https://pypi.org/project/dones/0.2.0/", "requires_dist": null, "requires_python": null, "summary": "Track what keys are \"done\" using MySQL to implement a simple key-store.", "version": "0.2.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>## Introduction</p>\n<p>The dones module can be used to mark whether a key is \u201cdone\u201d and check whether\na key has been marked \u201cdone\u201d.  Keys can also be unmarked, so that they are no\nlonger \u201cdone\u201d.  Also, all keys can be unmarked by clearing the Dones.\nKeys are kept in their own namespace to avoid conflicts with other\nsets of other keys and to make it easy to implement clearing.</p>\n<p>Why?  I use <cite>dones</cite> to keep track of what I\u2019ve already done.  More\nspecifically, I run large computations (a few million tasks) on a large cluster\n(a few thousand cores) with a slow filesystem (Isilon).  When tasks inevitably\nfail, perhaps because the network storage goes offline, or a computer dies, or\nanother user overwhelms the database with connections, I need to resubmit the\ntasks to the batch queuing system (LSF) of the cluster that are not already\ndone.</p>\n<p>The solution in this module fits my constraints.  It handles the concurrent\nwrites of a thousand jobs marking things done (not all at once).  It is\nreasonably fast for reading and writing up to millions of jobs.  This is\nimportant because or batch queue (LSF) only handles a few thousand jobs at a\ntime gracefully.  Finally, <cite>dones</cite> uses MySQL as a backend, which is important\nbecause I cannot run a key-value server like Redis on the cluster I use.</p>\n<p>## Contribute</p>\n<p>Feel free to make a pull request on github.</p>\n<p>## Testing</p>\n<p>Awkwardly, <cite>dones</cite> is configured with a MySQL database url from the\nenvironment, so to test it, you need to add a url.  For example:</p>\n<blockquote>\nDONES_DB_URL=mysql://myuser:password@localhost/mydb nosetests</blockquote>\n<p>## Requirements</p>\n<ul>\n<li>Probably Python 2.7 (since that is the only version it has been tested with.)</li>\n<li>MySQL-python PyPI package.</li>\n</ul>\n<p>## Installation</p>\n<p>### Install from pypi.python.org</p>\n<p>Download and install using pip:</p>\n<blockquote>\npip install dones</blockquote>\n<p>### Install from github.com</p>\n<p>Using github, one can clone and install a specific version of the package:</p>\n<blockquote>\ncd ~\ngit clone <a href=\"mailto:git%40github.com\">git<span>@</span>github<span>.</span>com</a>:todddeluca/dones.git\ncd dones\npython setup.py install</blockquote>\n<p>Or use pip:</p>\n<blockquote>\npip install git+git://github.com/todddeluca/dones.git#egg=dones</blockquote>\n<p>## Usage</p>\n<blockquote>\n<p>import dones</p>\n<dl>\n<dt>if not dones.get(\u2018my_pipeline\u2019).done(\u2018task1\u2019):</dt>\n<dd>dotask(\u2018task1\u2019)\ndones.get(\u2018my_pipleline\u2019).mark(\u2018task1\u2019)</dd>\n</dl>\n</blockquote>\n\n          </div>"}, "last_serial": 791357, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "907587238cbb92097d31424877425912", "sha256": "888fb3651a768c2112bc2a8fdfbe026bcd1bdcf8c37756ba1bf3ca10253280bd"}, "downloads": -1, "filename": "dones-0.1.0.tar.gz", "has_sig": false, "md5_digest": "907587238cbb92097d31424877425912", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7550, "upload_time": "2013-03-01T18:44:23", "upload_time_iso_8601": "2013-03-01T18:44:23.790358Z", "url": "https://files.pythonhosted.org/packages/cd/1b/521aefa4e7bea3be7b074a3401862a4685119852facee69dbbe3b0ff3f33/dones-0.1.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "24746b17efda00d1d2d6f430f66cbc39", "sha256": "d925311c43f81935fc1c0766d4b486870e996c498a2b0b99b46e3e425abce371"}, "downloads": -1, "filename": "dones-0.2.0.tar.gz", "has_sig": false, "md5_digest": "24746b17efda00d1d2d6f430f66cbc39", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7581, "upload_time": "2013-03-05T17:15:19", "upload_time_iso_8601": "2013-03-05T17:15:19.115890Z", "url": "https://files.pythonhosted.org/packages/c9/e2/5ac61539d6cbc9e3da8f957104900f0a4ae9525422ebb1a6af281ac9c07a/dones-0.2.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "24746b17efda00d1d2d6f430f66cbc39", "sha256": "d925311c43f81935fc1c0766d4b486870e996c498a2b0b99b46e3e425abce371"}, "downloads": -1, "filename": "dones-0.2.0.tar.gz", "has_sig": false, "md5_digest": "24746b17efda00d1d2d6f430f66cbc39", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7581, "upload_time": "2013-03-05T17:15:19", "upload_time_iso_8601": "2013-03-05T17:15:19.115890Z", "url": "https://files.pythonhosted.org/packages/c9/e2/5ac61539d6cbc9e3da8f957104900f0a4ae9525422ebb1a6af281ac9c07a/dones-0.2.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:50:23 2020"}