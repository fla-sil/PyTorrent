{"info": {"author": "masa-su", "author_email": "masa@weblab.t.u-tokyo.ac.jp", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "# Pixyz: A library for developing deep generative models\n\n<img src=\"https://user-images.githubusercontent.com/11865486/58864169-3706a980-86ef-11e9-82f4-18bb0275271b.png\" width=\"800px\">\n\n[![pypi](https://img.shields.io/pypi/v/pixyz.svg)](https://pypi.python.org/pypi/pixyz)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Python Version](https://img.shields.io/pypi/pyversions/Django.svg)](https://github.com/masa-su/pixyz)\n[![Pytorch Version](https://img.shields.io/badge/pytorch-1.0-yellow.svg)](https://github.com/masa-su/pixyz)\n[![Read the Docs](https://readthedocs.org/projects/pixyz/badge/?version=latest)](http://docs.pixyz.io)\n[![TravisCI](https://travis-ci.org/masa-su/pixyz.svg?branch=master)](https://github.com/masa-su/pixyz)\n\n[Docs](https://docs.pixyz.io) | [Examples](https://github.com/masa-su/pixyz/tree/master/examples) | [Pixyzoo](https://github.com/masa-su/pixyzoo)\n\n- [What is Pixyz?](#what-is-pixyz)\n- [Installation](#installation)\n- [Quick Start](#quick-start)\n- [More information](#more-information)\n- [Acknowledgements](#acknowledgements)\n\n## What is Pixyz?\n[**Pixyz**](https://github.com/masa-su/pixyz) is a high-level deep generative modeling library, based on [PyTorch](https://pytorch.org/). It is developed with a focus on enabling easy implementation of various deep generative models.\n\nRecently, many papers about deep generative models have been published. However, its reproduction becomes a hard task, for both specialists and practitioners, because such recent models become more complex and there are no unified tools that bridge mathematical formulation of them and implementation. The vision of our library is to enable both specialists and practitioners to implement such complex deep generative models by **just as if writing the formulas provided in these papers**.\n\nOur library supports the following deep generative models.\n\n* Explicit models (likelihood-based)\n  * Variational autoencoders (variational inference)\n  * Flow-based models\n  * Autoregressive generative models (note: not implemented yet)\n* Implicit models\n  * Generative adversarial networks\n\nMoreover, Pixyz enables you to implement these different models **in the same framework** and **in combination with each other**.\n\nThe overview of Pixyz is as follows. Each API will be discussed below.\n<img src=\"https://user-images.githubusercontent.com/11865486/58321994-a3b1b680-7e5a-11e9-89dd-334086a89525.png\" width=\"600px\">\n\n**Note**: Since this library is under development, there are possibilities to have some bugs.\n\n## Installation\n\nPixyz can be installed by using `pip`.\n```\n$ pip install pixyz\n```\n\nIf installing from source code, execute the following commands.\n```\n$ git clone https://github.com/masa-su/pixyz.git\n$ pip install -e pixyz\n```\n\n## Quick Start\n\nHere, we consider to implement a variational auto-encoder (VAE) which is one of the most well-known deep generative models. VAE is composed of a inference model\n<img src=\"https://latex.codecogs.com/gif.latex?q_{\\phi}(z|x)\" />\nand a generative model\n<img src=\"https://latex.codecogs.com/gif.latex?p_{\\theta}(x,z)=p_{\\theta}(x|z)p(z)\" />\n , each of which is defined by DNN, and this loss function (negative ELBO) is as follows.\n\n<img src=\"https://latex.codecogs.com/gif.latex?\\mathcal{L}(x;\\phi,\\theta)=-E_{q_{\\phi}(z|x)}\\left[\\log{p_{\\theta}(x|z)}\\right]+D_{KL}\\left[q_{\\phi}(z|x)||p_{prior}(z)\\right]\" /> (1)\n\nIn Pixyz, deep generative models are implemented in the following three steps:\n1. [Define distributions(Distribution API\uff09](#1-define-distributionsdistribution-api)\n2. [Set the loss function of a model(Loss API)](#2-set-the-loss-function-of-a-modelloss-api)\n3. [Train the model(Model API)](#3-train-the-modelmodel-api)\n\n### 1. Define distributions(Distribution API)\nFirst, we need to define two distributions (\n<img src=\"https://latex.codecogs.com/gif.latex?q_{\\phi}(z|x)\" />\n,\n<img src=\"https://latex.codecogs.com/gif.latex?p_{\\theta}(x|z)\" />\n) with DNNs. In Pixyz, you can do this by building DNN modules just as you do in PyTorch. The main difference is that you should inherit the `pixyz.distributions.*` class (**Distribution API**), instead of `torch.nn.Module` .\n\nFor example, \n<img src=\"https://latex.codecogs.com/gif.latex?p_{\\theta}(x|z)\" />\n(Bernoulli) \nand\n<img src=\"https://latex.codecogs.com/gif.latex?q_{\\phi}(z|x)\" />\n(normal) are implemented as follows.\n\n```python\n>>> from pixyz.distributions import Bernoulli, Normal\n>>> # inference model (encoder) q(z|x)\n>>> class Inference(Normal):\n...     def __init__(self):\n...         super(Inference, self).__init__(cond_var=[\"x\"], var=[\"z\"], name=\"q\")  # var: variables of this distribution, cond_var: coditional variables.\n...         self.fc1 = nn.Linear(784, 512)\n...         self.fc21 = nn.Linear(512, 64)\n...         self.fc22 = nn.Linear(512, 64)\n... \n...     def forward(self, x):  # the name of this argument should be same as cond_var.\n...         h = F.relu(self.fc1(x))\n...         return {\"loc\": self.fc21(h),\n...                 \"scale\": F.softplus(self.fc22(h))}  # return parameters of the normal distribution\n... \n>>> # generative model (decoder) p(x|z)    \n>>> class Generator(Bernoulli):\n...     def __init__(self):\n...         super(Generator, self).__init__(cond_var=[\"z\"], var=[\"x\"], name=\"p\")\n...         self.fc1 = nn.Linear(64, 512)\n...         self.fc2 = nn.Linear(512, 128)\n... \n...     def forward(self, z):  # the name of this argument should be same as cond_var.\n...         h = F.relu(self.fc1(z))\n...         return {\"probs\": F.sigmoid(self.fc2(h))}    # return a parameter of the Bernoulli distribution\n```\nOnce defined, you can create instances of these classes.\n```python\n>>> p = Generator()\n>>> q = Inference()\n```\n\nIn VAE,\n<img src=\"https://latex.codecogs.com/gif.latex?p(z)\" />\n, a prior of the generative model,  is usually defined as the standard normal distribution, without using DNNs. \nSuch an instance can be created from `pixyz.distributions.*` as\n```python\n>>> prior = Normal(loc=torch.tensor(0.), scale=torch.tensor(1.),\n...                var=[\"z\"], features_shape=[64], name=\"p_prior\")\n```\n\nIf you want to find out what kind of distribution each instance defines and what modules (the network architecture) define it, just `print` them.\n```python\n>>> print(p)\nDistribution:\n  p(x|z)\nNetwork architecture:\n  Generator(\n    name=p, distribution_name=Bernoulli,\n    var=['x'], cond_var=['z'], input_var=['z'], features_shape=torch.Size([])\n    (fc1): Linear(in_features=64, out_features=512, bias=True)\n    (fc2): Linear(in_features=512, out_features=512, bias=True)\n    (fc3): Linear(in_features=512, out_features=784, bias=True)\n  )\n```\nIf you are working on the iPython environment, you can use `print_latex` to display them in the LaTeX compiled format.\n\n![p](https://user-images.githubusercontent.com/11865486/59156055-1c0dae00-8ad0-11e9-9eac-5b9938904a0d.png)\n\nConveniently, each distribution instance can **perform sampling** over given samples, regardless of the form of the internal DNN modules. \n```python\n>>> samples_z = prior.sample(batch_n=1)\n>>> print(samples_z)\n{'z': tensor([[ 0.6084,  1.4716,  0.6413,  1.3184, -0.8930,  0.0603,  1.2254,  0.5910, ..., 0.8389]])}\n>>> samples = p.sample(samples_z)\n>>> print(samples)\n{'z': tensor([[ 1.5377,  0.4713,  0.0354,  0.5013,  1.2584,  0.8908,  0.6323,  1.0844, ..., -0.7603]]),\n 'x': tensor([[0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., ..., 0.]])}\n```\nAs in this example, samples are represented in dictionary forms in which the keys correspond to random variable names and the values are their realized values.\n\nMoreover, the instance of joint distribution\n<img src=\"https://latex.codecogs.com/gif.latex?p_{\\theta}(x,z)=p_{\\theta}(x|z)p(z)\" />\ncan be created by **the product of distribution instances**. \n```python\n>>> p_joint = p * prior\n```\n\nThis instance can be checked as\n```python\n>>> print(p_joint)\nDistribution:\n  p(x,z) = p(x|z)p_{prior}(z)\nNetwork architecture:\n  Normal(\n    name=p_{prior}, distribution_name=Normal,\n    var=['z'], cond_var=[], input_var=[], features_shape=torch.Size([64])\n    (loc): torch.Size([1, 64])\n    (scale): torch.Size([1, 64])\n  )\n  Generator(\n    name=p, distribution_name=Bernoulli,\n    var=['x'], cond_var=['z'], input_var=['z'], features_shape=torch.Size([])\n    (fc1): Linear(in_features=64, out_features=512, bias=True)\n    (fc2): Linear(in_features=512, out_features=512, bias=True)\n    (fc3): Linear(in_features=512, out_features=784, bias=True)\n  )\n```\n![p_joint](https://user-images.githubusercontent.com/11865486/59156030-d81aa900-8acf-11e9-8b8a-ef2d944722b2.png)\n\nAlso, it can perform sampling in the same way. \n```python\n>>> p_joint.sample(batch_n=1)\n{'z': tensor([[ 1.5377,  0.4713,  0.0354,  0.5013,  1.2584,  0.8908,  0.6323,  1.0844, ..., -0.7603]]),\n 'x': tensor([[0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., ..., 0.]])}\n```\nBy constructing the joint distribution in this way, you can easily implement **more complicated generative models**.\n\n### 2. Set the loss function of a model(Loss API)\nNext, we set the objective (loss) function of the model with defined distributions.\n\n**Loss API** (`pixyz.losses.*`) enables you to define such loss function as if just writing mathematic formulas. The loss function of VAE (Eq.(1)) can easily be converted to the code style  as follows.\n```python\n>>> from pixyz.losses import KullbackLeibler, LogProb, Expectation as E\n>>> reconst = -E(q, LogProb(p)) # the reconstruction loss (it can also be written as `-p.log_prob().expectation()`)\n>>> kl = KullbackLeibler(q, prior) # Kullback-Leibler divergence\n>>> loss_cls = (kl + reconst).mean()\n```\n\nLike Distribution API, you can check the formula of the loss function by printing.\n```python\n>>> print(loss_cls)\nmean \\left(D_{KL} \\left[q(z|x)||p_{prior}(z) \\right] - \\mathbb{E}_{q(z|x)} \\left[\\log p(x|z) \\right] \\right) \n```\n![loss](https://user-images.githubusercontent.com/11865486/59156066-3f385d80-8ad0-11e9-9604-ee78a5dd7407.png)\n\nWhen evaluating this loss function given data, use the `eval` method.\n```python\n>>> loss_tensor = loss_cls.eval({\"x\": x_tensor}) # x_tensor: input data\n>>> print(loss_tensor)\ntensor(1.00000e+05 * 1.2587)\n```\n### 3. Train the model(Model API)\nFinally, Model API (`pixyz.models.Model`) can train the loss function given the optimizer, distributions to train, and training data.\n```python\n>>> from pixyz.models import Model\n>>> from torch import optim\n>>> model = Model(loss_cls, distributions=[p, q],\n...               optimizer=optim.Adam, optimizer_params={\"lr\":1e-3}) # initialize a model\n>>> train_loss = model.train({\"x\": x_tensor}) # train the model given training data (x_tensor) \n```\nAfter training the model, you can perform generation and inference on the model by sampling from\n<img src=\"https://latex.codecogs.com/gif.latex?p_{\\theta}(x,z)\" />\nand\n<img src=\"https://latex.codecogs.com/gif.latex?q_{\\phi}(z|x)\" />\n, respectively.\n\n## More information\nThese frameworks of Pixyz allow the implementation of more complex deep generative models.\nSee [sample codes](https://github.com/masa-su/pixyz/tree/master/examples) and the [pixyzoo](https://github.com/masa-su/pixyzoo) repository as examples.\n\nFor more detailed usage, please check the [Pixyz documentation](https://docs.pixyz.io).\n\nIf you encounter some problems in using Pixyz, please let us know.\n\n## Acknowledgements\nThis library is based on results obtained from a project commissioned by the New Energy and Industrial Technology Development Organization (NEDO). \n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/masa-su/pixyz", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "pixyz", "package_url": "https://pypi.org/project/pixyz/", "platform": "", "project_url": "https://pypi.org/project/pixyz/", "project_urls": {"Homepage": "https://github.com/masa-su/pixyz"}, "release_url": "https://pypi.org/project/pixyz/0.1.4/", "requires_dist": ["torch (>=1.0)", "torchvision", "tqdm", "scipy", "sympy (>=1.4)", "ipython", "tensorboardX"], "requires_python": "", "summary": "Deep generative modeling library", "version": "0.1.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Pixyz: A library for developing deep generative models</h1>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/aae087035e43090e6012ac1558b09da9cc744e67/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31313836353438362f35383836343136392d33373036613938302d383665662d313165392d383266342d3138626230323735323731622e706e67\" width=\"800px\">\n<p><a href=\"https://pypi.python.org/pypi/pixyz\" rel=\"nofollow\"><img alt=\"pypi\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6aa413466e252ef44b4e63c30d67a1b7b801cc68/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f706978797a2e737667\"></a>\n<a href=\"https://opensource.org/licenses/MIT\" rel=\"nofollow\"><img alt=\"License: MIT\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8645b002dd7ec1b54275a80574942e7a318e03c6/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d79656c6c6f772e737667\"></a>\n<a href=\"https://github.com/masa-su/pixyz\" rel=\"nofollow\"><img alt=\"Python Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/10dfd3abcb9a0ba765e14beb5116c17f39ed86b2/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f446a616e676f2e737667\"></a>\n<a href=\"https://github.com/masa-su/pixyz\" rel=\"nofollow\"><img alt=\"Pytorch Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8111e61fa1cce070a0193ab474c480471acb1b23/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7079746f7263682d312e302d79656c6c6f772e737667\"></a>\n<a href=\"http://docs.pixyz.io\" rel=\"nofollow\"><img alt=\"Read the Docs\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0e23bcb1f1d30d971b791f1d6d35ac34656157d2/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f706978797a2f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<a href=\"https://github.com/masa-su/pixyz\" rel=\"nofollow\"><img alt=\"TravisCI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5af8d2d166a7a500783ff5e4c6ac507896b42acf/68747470733a2f2f7472617669732d63692e6f72672f6d6173612d73752f706978797a2e7376673f6272616e63683d6d6173746572\"></a></p>\n<p><a href=\"https://docs.pixyz.io\" rel=\"nofollow\">Docs</a> | <a href=\"https://github.com/masa-su/pixyz/tree/master/examples\" rel=\"nofollow\">Examples</a> | <a href=\"https://github.com/masa-su/pixyzoo\" rel=\"nofollow\">Pixyzoo</a></p>\n<ul>\n<li><a href=\"#what-is-pixyz\" rel=\"nofollow\">What is Pixyz?</a></li>\n<li><a href=\"#installation\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#quick-start\" rel=\"nofollow\">Quick Start</a></li>\n<li><a href=\"#more-information\" rel=\"nofollow\">More information</a></li>\n<li><a href=\"#acknowledgements\" rel=\"nofollow\">Acknowledgements</a></li>\n</ul>\n<h2>What is Pixyz?</h2>\n<p><a href=\"https://github.com/masa-su/pixyz\" rel=\"nofollow\"><strong>Pixyz</strong></a> is a high-level deep generative modeling library, based on <a href=\"https://pytorch.org/\" rel=\"nofollow\">PyTorch</a>. It is developed with a focus on enabling easy implementation of various deep generative models.</p>\n<p>Recently, many papers about deep generative models have been published. However, its reproduction becomes a hard task, for both specialists and practitioners, because such recent models become more complex and there are no unified tools that bridge mathematical formulation of them and implementation. The vision of our library is to enable both specialists and practitioners to implement such complex deep generative models by <strong>just as if writing the formulas provided in these papers</strong>.</p>\n<p>Our library supports the following deep generative models.</p>\n<ul>\n<li>Explicit models (likelihood-based)\n<ul>\n<li>Variational autoencoders (variational inference)</li>\n<li>Flow-based models</li>\n<li>Autoregressive generative models (note: not implemented yet)</li>\n</ul>\n</li>\n<li>Implicit models\n<ul>\n<li>Generative adversarial networks</li>\n</ul>\n</li>\n</ul>\n<p>Moreover, Pixyz enables you to implement these different models <strong>in the same framework</strong> and <strong>in combination with each other</strong>.</p>\n<p>The overview of Pixyz is as follows. Each API will be discussed below.\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/52b1e0c3b65f2ccc38b2078282811ebb860f62af/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31313836353438362f35383332313939342d61336231623638302d376535612d313165392d383964642d3333343038366138393532352e706e67\" width=\"600px\"></p>\n<p><strong>Note</strong>: Since this library is under development, there are possibilities to have some bugs.</p>\n<h2>Installation</h2>\n<p>Pixyz can be installed by using <code>pip</code>.</p>\n<pre><code>$ pip install pixyz\n</code></pre>\n<p>If installing from source code, execute the following commands.</p>\n<pre><code>$ git clone https://github.com/masa-su/pixyz.git\n$ pip install -e pixyz\n</code></pre>\n<h2>Quick Start</h2>\n<p>Here, we consider to implement a variational auto-encoder (VAE) which is one of the most well-known deep generative models. VAE is composed of a inference model\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/07d391a7e2122789d928f91fd6948050e886dc0f/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f715f7b5c7068697d287a7c7829\">\nand a generative model\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/920e3813987c6f6454059b11e62432c4a81b9c54/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f705f7b5c74686574617d28782c7a293d705f7b5c74686574617d28787c7a2970287a29\">\n, each of which is defined by DNN, and this loss function (negative ELBO) is as follows.</p>\n<p><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b18b593bce0b2342da6d54d485fe66eee88e278b/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f5c6d61746863616c7b4c7d28783b5c7068692c5c7468657461293d2d455f7b715f7b5c7068697d287a7c78297d5c6c6566745b5c6c6f677b705f7b5c74686574617d28787c7a297d5c72696768745d2b445f7b4b4c7d5c6c6566745b715f7b5c7068697d287a7c78297c7c705f7b7072696f727d287a295c72696768745d\"> (1)</p>\n<p>In Pixyz, deep generative models are implemented in the following three steps:</p>\n<ol>\n<li><a href=\"#1-define-distributionsdistribution-api\" rel=\"nofollow\">Define distributions(Distribution API\uff09</a></li>\n<li><a href=\"#2-set-the-loss-function-of-a-modelloss-api\" rel=\"nofollow\">Set the loss function of a model(Loss API)</a></li>\n<li><a href=\"#3-train-the-modelmodel-api\" rel=\"nofollow\">Train the model(Model API)</a></li>\n</ol>\n<h3>1. Define distributions(Distribution API)</h3>\n<p>First, we need to define two distributions (\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/07d391a7e2122789d928f91fd6948050e886dc0f/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f715f7b5c7068697d287a7c7829\">\n,\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5418228d1231c88497b604802dc41c3d6510442d/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f705f7b5c74686574617d28787c7a29\">\n) with DNNs. In Pixyz, you can do this by building DNN modules just as you do in PyTorch. The main difference is that you should inherit the <code>pixyz.distributions.*</code> class (<strong>Distribution API</strong>), instead of <code>torch.nn.Module</code> .</p>\n<p>For example,\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5418228d1231c88497b604802dc41c3d6510442d/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f705f7b5c74686574617d28787c7a29\">\n(Bernoulli)\nand\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/07d391a7e2122789d928f91fd6948050e886dc0f/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f715f7b5c7068697d287a7c7829\">\n(normal) are implemented as follows.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">pixyz.distributions</span> <span class=\"kn\">import</span> <span class=\"n\">Bernoulli</span><span class=\"p\">,</span> <span class=\"n\">Normal</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"c1\"># inference model (encoder) q(z|x)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">class</span> <span class=\"nc\">Inference</span><span class=\"p\">(</span><span class=\"n\">Normal</span><span class=\"p\">):</span>\n<span class=\"o\">...</span>     <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n<span class=\"o\">...</span>         <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">Inference</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"n\">cond_var</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"x\"</span><span class=\"p\">],</span> <span class=\"n\">var</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"z\"</span><span class=\"p\">],</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">\"q\"</span><span class=\"p\">)</span>  <span class=\"c1\"># var: variables of this distribution, cond_var: coditional variables.</span>\n<span class=\"o\">...</span>         <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc1</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">784</span><span class=\"p\">,</span> <span class=\"mi\">512</span><span class=\"p\">)</span>\n<span class=\"o\">...</span>         <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc21</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">)</span>\n<span class=\"o\">...</span>         <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc22</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">)</span>\n<span class=\"o\">...</span> \n<span class=\"o\">...</span>     <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>  <span class=\"c1\"># the name of this argument should be same as cond_var.</span>\n<span class=\"o\">...</span>         <span class=\"n\">h</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc1</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">))</span>\n<span class=\"o\">...</span>         <span class=\"k\">return</span> <span class=\"p\">{</span><span class=\"s2\">\"loc\"</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc21</span><span class=\"p\">(</span><span class=\"n\">h</span><span class=\"p\">),</span>\n<span class=\"o\">...</span>                 <span class=\"s2\">\"scale\"</span><span class=\"p\">:</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">softplus</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc22</span><span class=\"p\">(</span><span class=\"n\">h</span><span class=\"p\">))}</span>  <span class=\"c1\"># return parameters of the normal distribution</span>\n<span class=\"o\">...</span> \n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"c1\"># generative model (decoder) p(x|z)    </span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">class</span> <span class=\"nc\">Generator</span><span class=\"p\">(</span><span class=\"n\">Bernoulli</span><span class=\"p\">):</span>\n<span class=\"o\">...</span>     <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n<span class=\"o\">...</span>         <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">Generator</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"n\">cond_var</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"z\"</span><span class=\"p\">],</span> <span class=\"n\">var</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"x\"</span><span class=\"p\">],</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">\"p\"</span><span class=\"p\">)</span>\n<span class=\"o\">...</span>         <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc1</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"mi\">512</span><span class=\"p\">)</span>\n<span class=\"o\">...</span>         <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc2</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">)</span>\n<span class=\"o\">...</span> \n<span class=\"o\">...</span>     <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">z</span><span class=\"p\">):</span>  <span class=\"c1\"># the name of this argument should be same as cond_var.</span>\n<span class=\"o\">...</span>         <span class=\"n\">h</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc1</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"p\">))</span>\n<span class=\"o\">...</span>         <span class=\"k\">return</span> <span class=\"p\">{</span><span class=\"s2\">\"probs\"</span><span class=\"p\">:</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">sigmoid</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc2</span><span class=\"p\">(</span><span class=\"n\">h</span><span class=\"p\">))}</span>    <span class=\"c1\"># return a parameter of the Bernoulli distribution</span>\n</pre>\n<p>Once defined, you can create instances of these classes.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"n\">Generator</span><span class=\"p\">()</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">q</span> <span class=\"o\">=</span> <span class=\"n\">Inference</span><span class=\"p\">()</span>\n</pre>\n<p>In VAE,\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1ffa52edd5b44f16ade07e20eddacaaa0c30fa16/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f70287a29\">\n, a prior of the generative model,  is usually defined as the standard normal distribution, without using DNNs.\nSuch an instance can be created from <code>pixyz.distributions.*</code> as</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">prior</span> <span class=\"o\">=</span> <span class=\"n\">Normal</span><span class=\"p\">(</span><span class=\"n\">loc</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"mf\">0.</span><span class=\"p\">),</span> <span class=\"n\">scale</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"mf\">1.</span><span class=\"p\">),</span>\n<span class=\"o\">...</span>                <span class=\"n\">var</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"z\"</span><span class=\"p\">],</span> <span class=\"n\">features_shape</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">64</span><span class=\"p\">],</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">\"p_prior\"</span><span class=\"p\">)</span>\n</pre>\n<p>If you want to find out what kind of distribution each instance defines and what modules (the network architecture) define it, just <code>print</code> them.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"p\">)</span>\n<span class=\"n\">Distribution</span><span class=\"p\">:</span>\n  <span class=\"n\">p</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">|</span><span class=\"n\">z</span><span class=\"p\">)</span>\n<span class=\"n\">Network</span> <span class=\"n\">architecture</span><span class=\"p\">:</span>\n  <span class=\"n\">Generator</span><span class=\"p\">(</span>\n    <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"n\">p</span><span class=\"p\">,</span> <span class=\"n\">distribution_name</span><span class=\"o\">=</span><span class=\"n\">Bernoulli</span><span class=\"p\">,</span>\n    <span class=\"n\">var</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'x'</span><span class=\"p\">],</span> <span class=\"n\">cond_var</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'z'</span><span class=\"p\">],</span> <span class=\"n\">input_var</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'z'</span><span class=\"p\">],</span> <span class=\"n\">features_shape</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Size</span><span class=\"p\">([])</span>\n    <span class=\"p\">(</span><span class=\"n\">fc1</span><span class=\"p\">):</span> <span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">in_features</span><span class=\"o\">=</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">out_features</span><span class=\"o\">=</span><span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"n\">fc2</span><span class=\"p\">):</span> <span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">in_features</span><span class=\"o\">=</span><span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"n\">out_features</span><span class=\"o\">=</span><span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"n\">fc3</span><span class=\"p\">):</span> <span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">in_features</span><span class=\"o\">=</span><span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"n\">out_features</span><span class=\"o\">=</span><span class=\"mi\">784</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n  <span class=\"p\">)</span>\n</pre>\n<p>If you are working on the iPython environment, you can use <code>print_latex</code> to display them in the LaTeX compiled format.</p>\n<p><img alt=\"p\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a67e2e596e2b148542564419b453e9027b0f7073/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31313836353438362f35393135363035352d31633064616530302d386164302d313165392d396561632d3562393933383930346130642e706e67\"></p>\n<p>Conveniently, each distribution instance can <strong>perform sampling</strong> over given samples, regardless of the form of the internal DNN modules.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">samples_z</span> <span class=\"o\">=</span> <span class=\"n\">prior</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"n\">batch_n</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">samples_z</span><span class=\"p\">)</span>\n<span class=\"p\">{</span><span class=\"s1\">'z'</span><span class=\"p\">:</span> <span class=\"n\">tensor</span><span class=\"p\">([[</span> <span class=\"mf\">0.6084</span><span class=\"p\">,</span>  <span class=\"mf\">1.4716</span><span class=\"p\">,</span>  <span class=\"mf\">0.6413</span><span class=\"p\">,</span>  <span class=\"mf\">1.3184</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.8930</span><span class=\"p\">,</span>  <span class=\"mf\">0.0603</span><span class=\"p\">,</span>  <span class=\"mf\">1.2254</span><span class=\"p\">,</span>  <span class=\"mf\">0.5910</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">,</span> <span class=\"mf\">0.8389</span><span class=\"p\">]])}</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">samples</span> <span class=\"o\">=</span> <span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"n\">samples_z</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">samples</span><span class=\"p\">)</span>\n<span class=\"p\">{</span><span class=\"s1\">'z'</span><span class=\"p\">:</span> <span class=\"n\">tensor</span><span class=\"p\">([[</span> <span class=\"mf\">1.5377</span><span class=\"p\">,</span>  <span class=\"mf\">0.4713</span><span class=\"p\">,</span>  <span class=\"mf\">0.0354</span><span class=\"p\">,</span>  <span class=\"mf\">0.5013</span><span class=\"p\">,</span>  <span class=\"mf\">1.2584</span><span class=\"p\">,</span>  <span class=\"mf\">0.8908</span><span class=\"p\">,</span>  <span class=\"mf\">0.6323</span><span class=\"p\">,</span>  <span class=\"mf\">1.0844</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.7603</span><span class=\"p\">]]),</span>\n <span class=\"s1\">'x'</span><span class=\"p\">:</span> <span class=\"n\">tensor</span><span class=\"p\">([[</span><span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">]])}</span>\n</pre>\n<p>As in this example, samples are represented in dictionary forms in which the keys correspond to random variable names and the values are their realized values.</p>\n<p>Moreover, the instance of joint distribution\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/920e3813987c6f6454059b11e62432c4a81b9c54/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f705f7b5c74686574617d28782c7a293d705f7b5c74686574617d28787c7a2970287a29\">\ncan be created by <strong>the product of distribution instances</strong>.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">p_joint</span> <span class=\"o\">=</span> <span class=\"n\">p</span> <span class=\"o\">*</span> <span class=\"n\">prior</span>\n</pre>\n<p>This instance can be checked as</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">p_joint</span><span class=\"p\">)</span>\n<span class=\"n\">Distribution</span><span class=\"p\">:</span>\n  <span class=\"n\">p</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span><span class=\"n\">z</span><span class=\"p\">)</span> <span class=\"o\">=</span> <span class=\"n\">p</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">|</span><span class=\"n\">z</span><span class=\"p\">)</span><span class=\"n\">p_</span><span class=\"p\">{</span><span class=\"n\">prior</span><span class=\"p\">}(</span><span class=\"n\">z</span><span class=\"p\">)</span>\n<span class=\"n\">Network</span> <span class=\"n\">architecture</span><span class=\"p\">:</span>\n  <span class=\"n\">Normal</span><span class=\"p\">(</span>\n    <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"n\">p_</span><span class=\"p\">{</span><span class=\"n\">prior</span><span class=\"p\">},</span> <span class=\"n\">distribution_name</span><span class=\"o\">=</span><span class=\"n\">Normal</span><span class=\"p\">,</span>\n    <span class=\"n\">var</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'z'</span><span class=\"p\">],</span> <span class=\"n\">cond_var</span><span class=\"o\">=</span><span class=\"p\">[],</span> <span class=\"n\">input_var</span><span class=\"o\">=</span><span class=\"p\">[],</span> <span class=\"n\">features_shape</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Size</span><span class=\"p\">([</span><span class=\"mi\">64</span><span class=\"p\">])</span>\n    <span class=\"p\">(</span><span class=\"n\">loc</span><span class=\"p\">):</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Size</span><span class=\"p\">([</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">])</span>\n    <span class=\"p\">(</span><span class=\"n\">scale</span><span class=\"p\">):</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Size</span><span class=\"p\">([</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">])</span>\n  <span class=\"p\">)</span>\n  <span class=\"n\">Generator</span><span class=\"p\">(</span>\n    <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"n\">p</span><span class=\"p\">,</span> <span class=\"n\">distribution_name</span><span class=\"o\">=</span><span class=\"n\">Bernoulli</span><span class=\"p\">,</span>\n    <span class=\"n\">var</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'x'</span><span class=\"p\">],</span> <span class=\"n\">cond_var</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'z'</span><span class=\"p\">],</span> <span class=\"n\">input_var</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'z'</span><span class=\"p\">],</span> <span class=\"n\">features_shape</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Size</span><span class=\"p\">([])</span>\n    <span class=\"p\">(</span><span class=\"n\">fc1</span><span class=\"p\">):</span> <span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">in_features</span><span class=\"o\">=</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">out_features</span><span class=\"o\">=</span><span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"n\">fc2</span><span class=\"p\">):</span> <span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">in_features</span><span class=\"o\">=</span><span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"n\">out_features</span><span class=\"o\">=</span><span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"n\">fc3</span><span class=\"p\">):</span> <span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">in_features</span><span class=\"o\">=</span><span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"n\">out_features</span><span class=\"o\">=</span><span class=\"mi\">784</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n  <span class=\"p\">)</span>\n</pre>\n<p><img alt=\"p_joint\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/64552a08e8bc6d97789eade3244a9de6bea72d44/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31313836353438362f35393135363033302d64383161613930302d386163662d313165392d386238612d6566326439343437323262322e706e67\"></p>\n<p>Also, it can perform sampling in the same way.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">p_joint</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"n\">batch_n</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"p\">{</span><span class=\"s1\">'z'</span><span class=\"p\">:</span> <span class=\"n\">tensor</span><span class=\"p\">([[</span> <span class=\"mf\">1.5377</span><span class=\"p\">,</span>  <span class=\"mf\">0.4713</span><span class=\"p\">,</span>  <span class=\"mf\">0.0354</span><span class=\"p\">,</span>  <span class=\"mf\">0.5013</span><span class=\"p\">,</span>  <span class=\"mf\">1.2584</span><span class=\"p\">,</span>  <span class=\"mf\">0.8908</span><span class=\"p\">,</span>  <span class=\"mf\">0.6323</span><span class=\"p\">,</span>  <span class=\"mf\">1.0844</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.7603</span><span class=\"p\">]]),</span>\n <span class=\"s1\">'x'</span><span class=\"p\">:</span> <span class=\"n\">tensor</span><span class=\"p\">([[</span><span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">]])}</span>\n</pre>\n<p>By constructing the joint distribution in this way, you can easily implement <strong>more complicated generative models</strong>.</p>\n<h3>2. Set the loss function of a model(Loss API)</h3>\n<p>Next, we set the objective (loss) function of the model with defined distributions.</p>\n<p><strong>Loss API</strong> (<code>pixyz.losses.*</code>) enables you to define such loss function as if just writing mathematic formulas. The loss function of VAE (Eq.(1)) can easily be converted to the code style  as follows.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">pixyz.losses</span> <span class=\"kn\">import</span> <span class=\"n\">KullbackLeibler</span><span class=\"p\">,</span> <span class=\"n\">LogProb</span><span class=\"p\">,</span> <span class=\"n\">Expectation</span> <span class=\"k\">as</span> <span class=\"n\">E</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">reconst</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"n\">E</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"p\">,</span> <span class=\"n\">LogProb</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"p\">))</span> <span class=\"c1\"># the reconstruction loss (it can also be written as `-p.log_prob().expectation()`)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">kl</span> <span class=\"o\">=</span> <span class=\"n\">KullbackLeibler</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"p\">,</span> <span class=\"n\">prior</span><span class=\"p\">)</span> <span class=\"c1\"># Kullback-Leibler divergence</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">loss_cls</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">kl</span> <span class=\"o\">+</span> <span class=\"n\">reconst</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span>\n</pre>\n<p>Like Distribution API, you can check the formula of the loss function by printing.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">loss_cls</span><span class=\"p\">)</span>\n<span class=\"n\">mean</span> \\<span class=\"n\">left</span><span class=\"p\">(</span><span class=\"n\">D_</span><span class=\"p\">{</span><span class=\"n\">KL</span><span class=\"p\">}</span> \\<span class=\"n\">left</span><span class=\"p\">[</span><span class=\"n\">q</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"o\">|</span><span class=\"n\">x</span><span class=\"p\">)</span><span class=\"o\">||</span><span class=\"n\">p_</span><span class=\"p\">{</span><span class=\"n\">prior</span><span class=\"p\">}(</span><span class=\"n\">z</span><span class=\"p\">)</span> \\<span class=\"n\">right</span><span class=\"p\">]</span> <span class=\"o\">-</span> \\<span class=\"n\">mathbb</span><span class=\"p\">{</span><span class=\"n\">E</span><span class=\"p\">}</span><span class=\"n\">_</span><span class=\"p\">{</span><span class=\"n\">q</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"o\">|</span><span class=\"n\">x</span><span class=\"p\">)}</span> \\<span class=\"n\">left</span><span class=\"p\">[</span>\\<span class=\"n\">log</span> <span class=\"n\">p</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">|</span><span class=\"n\">z</span><span class=\"p\">)</span> \\<span class=\"n\">right</span><span class=\"p\">]</span> \\<span class=\"n\">right</span><span class=\"p\">)</span> \n</pre>\n<p><img alt=\"loss\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1283c9dfe2eae410f4508fb9a3742e58fb8feaeb/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31313836353438362f35393135363036362d33663338356438302d386164302d313165392d393630342d6565373861356464373430372e706e67\"></p>\n<p>When evaluating this loss function given data, use the <code>eval</code> method.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">loss_tensor</span> <span class=\"o\">=</span> <span class=\"n\">loss_cls</span><span class=\"o\">.</span><span class=\"n\">eval</span><span class=\"p\">({</span><span class=\"s2\">\"x\"</span><span class=\"p\">:</span> <span class=\"n\">x_tensor</span><span class=\"p\">})</span> <span class=\"c1\"># x_tensor: input data</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">loss_tensor</span><span class=\"p\">)</span>\n<span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"mf\">1.00000e+05</span> <span class=\"o\">*</span> <span class=\"mf\">1.2587</span><span class=\"p\">)</span>\n</pre>\n<h3>3. Train the model(Model API)</h3>\n<p>Finally, Model API (<code>pixyz.models.Model</code>) can train the loss function given the optimizer, distributions to train, and training data.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">pixyz.models</span> <span class=\"kn\">import</span> <span class=\"n\">Model</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">torch</span> <span class=\"kn\">import</span> <span class=\"n\">optim</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Model</span><span class=\"p\">(</span><span class=\"n\">loss_cls</span><span class=\"p\">,</span> <span class=\"n\">distributions</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">p</span><span class=\"p\">,</span> <span class=\"n\">q</span><span class=\"p\">],</span>\n<span class=\"o\">...</span>               <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">Adam</span><span class=\"p\">,</span> <span class=\"n\">optimizer_params</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s2\">\"lr\"</span><span class=\"p\">:</span><span class=\"mf\">1e-3</span><span class=\"p\">})</span> <span class=\"c1\"># initialize a model</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">train_loss</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">({</span><span class=\"s2\">\"x\"</span><span class=\"p\">:</span> <span class=\"n\">x_tensor</span><span class=\"p\">})</span> <span class=\"c1\"># train the model given training data (x_tensor) </span>\n</pre>\n<p>After training the model, you can perform generation and inference on the model by sampling from\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5a74f321ddead689118e378c918e214285b5464a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f705f7b5c74686574617d28782c7a29\">\nand\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/07d391a7e2122789d928f91fd6948050e886dc0f/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f715f7b5c7068697d287a7c7829\">\n, respectively.</p>\n<h2>More information</h2>\n<p>These frameworks of Pixyz allow the implementation of more complex deep generative models.\nSee <a href=\"https://github.com/masa-su/pixyz/tree/master/examples\" rel=\"nofollow\">sample codes</a> and the <a href=\"https://github.com/masa-su/pixyzoo\" rel=\"nofollow\">pixyzoo</a> repository as examples.</p>\n<p>For more detailed usage, please check the <a href=\"https://docs.pixyz.io\" rel=\"nofollow\">Pixyz documentation</a>.</p>\n<p>If you encounter some problems in using Pixyz, please let us know.</p>\n<h2>Acknowledgements</h2>\n<p>This library is based on results obtained from a project commissioned by the New Energy and Industrial Technology Development Organization (NEDO).</p>\n\n          </div>"}, "last_serial": 6587805, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "c697ae792c028649dfa9a255496fe7db", "sha256": "61f8b51266d9a79f49889d67b648960126627b661f47d2cbbcab6a998afe6d4e"}, "downloads": -1, "filename": "pixyz-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "c697ae792c028649dfa9a255496fe7db", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 59481, "upload_time": "2019-06-10T04:09:47", "upload_time_iso_8601": "2019-06-10T04:09:47.052000Z", "url": "https://files.pythonhosted.org/packages/c0/9b/13bf99952222e070a775ff12536cafd9967c492c92868fb3c1c4b1062c8c/pixyz-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2a9c0de215905fef1448341d52edd506", "sha256": "6713dc95e67f4b364f3b2181a6bf1ed7d9b53d4e53186826186de8656e8adae0"}, "downloads": -1, "filename": "pixyz-0.1.0.tar.gz", "has_sig": false, "md5_digest": "2a9c0de215905fef1448341d52edd506", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 47055, "upload_time": "2019-06-10T04:09:49", "upload_time_iso_8601": "2019-06-10T04:09:49.607799Z", "url": "https://files.pythonhosted.org/packages/6c/2e/a62aa705d450bcb181a3f944c808cc51ae0b8176d84a6e457533ed53d838/pixyz-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "1886b2281e68abf9054f12dd75dea15e", "sha256": "62816695cc6eb47b5025ff85cf28c076609be4a0ffb4f8a10cdf1475b8ee04ec"}, "downloads": -1, "filename": "pixyz-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "1886b2281e68abf9054f12dd75dea15e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 59479, "upload_time": "2019-06-10T11:31:25", "upload_time_iso_8601": "2019-06-10T11:31:25.494738Z", "url": "https://files.pythonhosted.org/packages/ea/40/3928bd31ba5c56bfe49b07dac47aabcd904f94674b9aa231148e5e68eb0d/pixyz-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9691725a79275b34ad45a6383ad901a7", "sha256": "125374a8f11c95517319795380cf1d09f204c1493d606c98ca297f927f890ce9"}, "downloads": -1, "filename": "pixyz-0.1.1.tar.gz", "has_sig": false, "md5_digest": "9691725a79275b34ad45a6383ad901a7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 47076, "upload_time": "2019-06-10T11:31:27", "upload_time_iso_8601": "2019-06-10T11:31:27.498924Z", "url": "https://files.pythonhosted.org/packages/01/c7/ecd20addcbd1f3b1415bdac02cdff724027f81ef6d6ac35d8f7dd8ab2356/pixyz-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "8988f5565875b94cf60776011f96e11c", "sha256": "3b1061287be04135e6e11925e8cecc622c360ff3662722517c8db5a468cc2e50"}, "downloads": -1, "filename": "pixyz-0.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "8988f5565875b94cf60776011f96e11c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 60318, "upload_time": "2019-08-06T06:11:09", "upload_time_iso_8601": "2019-08-06T06:11:09.944279Z", "url": "https://files.pythonhosted.org/packages/22/fa/68cf75d946ac5301c6e584b87ab9d3933f6db65bbad6024eecf9a3530216/pixyz-0.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6a1fa92861640402f54333c8a88b35ef", "sha256": "336721c0c904251eb520f35a66f80160f7d056c2850923eb3e43fcc82b67a3fc"}, "downloads": -1, "filename": "pixyz-0.1.2.tar.gz", "has_sig": false, "md5_digest": "6a1fa92861640402f54333c8a88b35ef", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 47523, "upload_time": "2019-08-06T06:11:12", "upload_time_iso_8601": "2019-08-06T06:11:12.068512Z", "url": "https://files.pythonhosted.org/packages/2e/94/a6c510c9297127b78cb9db7b8e4250827fa7a7d75ffe439dc2e45d424141/pixyz-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "5e7b329d59a068f192ed6646bf3577af", "sha256": "68fab24b925e4cdcd34c22653f4fb110be7fda0593fd369c815eb19f51712c18"}, "downloads": -1, "filename": "pixyz-0.1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "5e7b329d59a068f192ed6646bf3577af", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 60377, "upload_time": "2019-10-28T04:22:10", "upload_time_iso_8601": "2019-10-28T04:22:10.771293Z", "url": "https://files.pythonhosted.org/packages/d2/f8/af2568c5d30bced87fe4c7779d0d0a46dbf26494c7c154da9ba73eef828f/pixyz-0.1.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cd94c60b0204e4a0e7778eee15b2837d", "sha256": "0d9b8c53b8845736a55ab9c2e9b5b04a8599b447599e754ad3dbbb5b0e24a0a5"}, "downloads": -1, "filename": "pixyz-0.1.3.tar.gz", "has_sig": false, "md5_digest": "cd94c60b0204e4a0e7778eee15b2837d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 47632, "upload_time": "2019-10-28T04:22:12", "upload_time_iso_8601": "2019-10-28T04:22:12.897797Z", "url": "https://files.pythonhosted.org/packages/6d/b6/abb1db8ad3408e1b4aa3944c4afab4d477d13abb6d130a0600033e137e5c/pixyz-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "84193d55ba9860f85802eb2ad680e199", "sha256": "3ab49851e2a8d58f6bcb9caa5e6efff4895ace4bfe3b553444a25ed2677ae963"}, "downloads": -1, "filename": "pixyz-0.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "84193d55ba9860f85802eb2ad680e199", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 60318, "upload_time": "2020-02-03T02:02:06", "upload_time_iso_8601": "2020-02-03T02:02:06.480291Z", "url": "https://files.pythonhosted.org/packages/c6/4f/6ded4e58fafc664019bcb6d70ffa3cc8eb63cefb6debdc532a876e408a36/pixyz-0.1.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9d8a007dabb53cc59339fa814af29ecb", "sha256": "1f61149d1f78aee3a038455f872a05feee6b72bb14f3cd3113a2640a7dc7d0af"}, "downloads": -1, "filename": "pixyz-0.1.4.tar.gz", "has_sig": false, "md5_digest": "9d8a007dabb53cc59339fa814af29ecb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 47209, "upload_time": "2020-02-03T02:02:08", "upload_time_iso_8601": "2020-02-03T02:02:08.375153Z", "url": "https://files.pythonhosted.org/packages/2f/97/fad1ab373f69b4deeda41c22dadee7b9f9fb85d067272b189bb6cfee75e9/pixyz-0.1.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "84193d55ba9860f85802eb2ad680e199", "sha256": "3ab49851e2a8d58f6bcb9caa5e6efff4895ace4bfe3b553444a25ed2677ae963"}, "downloads": -1, "filename": "pixyz-0.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "84193d55ba9860f85802eb2ad680e199", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 60318, "upload_time": "2020-02-03T02:02:06", "upload_time_iso_8601": "2020-02-03T02:02:06.480291Z", "url": "https://files.pythonhosted.org/packages/c6/4f/6ded4e58fafc664019bcb6d70ffa3cc8eb63cefb6debdc532a876e408a36/pixyz-0.1.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9d8a007dabb53cc59339fa814af29ecb", "sha256": "1f61149d1f78aee3a038455f872a05feee6b72bb14f3cd3113a2640a7dc7d0af"}, "downloads": -1, "filename": "pixyz-0.1.4.tar.gz", "has_sig": false, "md5_digest": "9d8a007dabb53cc59339fa814af29ecb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 47209, "upload_time": "2020-02-03T02:02:08", "upload_time_iso_8601": "2020-02-03T02:02:08.375153Z", "url": "https://files.pythonhosted.org/packages/2f/97/fad1ab373f69b4deeda41c22dadee7b9f9fb85d067272b189bb6cfee75e9/pixyz-0.1.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:53:52 2020"}