{"info": {"author": "Jeremie DECOCK", "author_email": "jd.jdhp@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python :: 3", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Application Frameworks", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "===============\n`Web Crawlers`_\n===============\n\nCopyright (c) 2016 Jeremie DECOCK (http://www.jdhp.org)\n\n\n* Web site: http://www.jdhp.org/projects_en.html#web-crawlers\n* Source code: https://github.com/jeremiedecock/web-crawlers\n* Issue tracker: https://github.com/jeremiedecock/web-crawlers/issues\n* Web Crawlers on PyPI: https://pypi.python.org/pypi/webcrawlers\n\n\nDescription\n===========\n\nSome web crawlers written with Python, feedparser and Beautifulsoup.\n\nNote:\n\n    This project is still in beta stage, so the API is not finalized yet.\n\n\nDependencies\n============\n\n-  Python >= 3.0\n-  Beautifulsoup\n-  Feedparser\n-  WaWA\n\n.. _install:\n\nInstallation\n============\n\nGnu/Linux\n---------\n\nYou can install, upgrade, uninstall Web Crawlers with these commands (in a\nterminal)::\n\n    pip install --pre webcrawlers\n    pip install --upgrade webcrawlers\n    pip uninstall webcrawlers\n\nOr, if you have downloaded the Web Crawlers source code::\n\n    python3 setup.py install\n\n.. There's also a package for Debian/Ubuntu::\n.. \n..     sudo apt-get install webcrawlers\n\nWindows\n-------\n\nNote:\n\n    The following installation procedure has been tested to work with Python\n    3.4 under Windows 7.\n    It should also work with recent Windows systems.\n\nYou can install, upgrade, uninstall Web Crawlers with these commands (in a\n`command prompt`_)::\n\n    py -m pip install --pre webcrawlers\n    py -m pip install --upgrade webcrawlers\n    py -m pip uninstall webcrawlers\n\nOr, if you have downloaded the Web Crawlers source code::\n\n    py setup.py install\n\nMacOSX\n-------\n\nNote:\n\n    The following installation procedure has been tested to work with Python\n    3.5 under MacOSX 10.9 (*Mavericks*).\n    It should also work with recent MacOSX systems.\n\nYou can install, upgrade, uninstall Web Crawlers with these commands (in a\nterminal)::\n\n    pip install --pre webcrawlers\n    pip install --upgrade webcrawlers\n    pip uninstall webcrawlers\n\nOr, if you have downloaded the Web Crawlers source code::\n\n    python3 setup.py install\n\n\nBug reports\n===========\n\nTo search for bugs or report them, please use the Web Crawlers Bug Tracker at:\n\n    https://github.com/jeremiedecock/web-crawlers/issues\n\n\nLicense\n=======\n\nThis project is provided under the terms and conditions of the\n`MIT License`_.\n\n\n.. _MIT License: http://opensource.org/licenses/MIT\n\n.. _Web Crawlers: http://www.jdhp.org/projects_en.html#web-crawlers\n", "description_content_type": null, "docs_url": null, "download_url": "http://www.jdhp.org/", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://www.jdhp.org/", "keywords": "web crawler", "license": "", "maintainer": "", "maintainer_email": "", "name": "webcrawlers", "package_url": "https://pypi.org/project/webcrawlers/", "platform": "", "project_url": "https://pypi.org/project/webcrawlers/", "project_urls": {"Download": "http://www.jdhp.org/", "Homepage": "http://www.jdhp.org/"}, "release_url": "https://pypi.org/project/webcrawlers/0.2.dev1/", "requires_dist": null, "requires_python": "", "summary": "A collection of unofficial web APIs for Python", "version": "0.2.dev1", "yanked": false, "html_description": "<div class=\"project-description\">\n            ===============<br>`Web Crawlers`_<br>===============<br><br>Copyright (c) 2016 Jeremie DECOCK (http://www.jdhp.org)<br><br><br>* Web site: http://www.jdhp.org/projects_en.html#web-crawlers<br>* Source code: https://github.com/jeremiedecock/web-crawlers<br>* Issue tracker: https://github.com/jeremiedecock/web-crawlers/issues<br>* Web Crawlers on PyPI: https://pypi.python.org/pypi/webcrawlers<br><br><br>Description<br>===========<br><br>Some web crawlers written with Python, feedparser and Beautifulsoup.<br><br>Note:<br><br>    This project is still in beta stage, so the API is not finalized yet.<br><br><br>Dependencies<br>============<br><br>-  Python &gt;= 3.0<br>-  Beautifulsoup<br>-  Feedparser<br>-  WaWA<br><br>.. _install:<br><br>Installation<br>============<br><br>Gnu/Linux<br>---------<br><br>You can install, upgrade, uninstall Web Crawlers with these commands (in a<br>terminal)::<br><br>    pip install --pre webcrawlers<br>    pip install --upgrade webcrawlers<br>    pip uninstall webcrawlers<br><br>Or, if you have downloaded the Web Crawlers source code::<br><br>    python3 setup.py install<br><br>.. There's also a package for Debian/Ubuntu::<br>.. <br>..     sudo apt-get install webcrawlers<br><br>Windows<br>-------<br><br>Note:<br><br>    The following installation procedure has been tested to work with Python<br>    3.4 under Windows 7.<br>    It should also work with recent Windows systems.<br><br>You can install, upgrade, uninstall Web Crawlers with these commands (in a<br>`command prompt`_)::<br><br>    py -m pip install --pre webcrawlers<br>    py -m pip install --upgrade webcrawlers<br>    py -m pip uninstall webcrawlers<br><br>Or, if you have downloaded the Web Crawlers source code::<br><br>    py setup.py install<br><br>MacOSX<br>-------<br><br>Note:<br><br>    The following installation procedure has been tested to work with Python<br>    3.5 under MacOSX 10.9 (*Mavericks*).<br>    It should also work with recent MacOSX systems.<br><br>You can install, upgrade, uninstall Web Crawlers with these commands (in a<br>terminal)::<br><br>    pip install --pre webcrawlers<br>    pip install --upgrade webcrawlers<br>    pip uninstall webcrawlers<br><br>Or, if you have downloaded the Web Crawlers source code::<br><br>    python3 setup.py install<br><br><br>Bug reports<br>===========<br><br>To search for bugs or report them, please use the Web Crawlers Bug Tracker at:<br><br>    https://github.com/jeremiedecock/web-crawlers/issues<br><br><br>License<br>=======<br><br>This project is provided under the terms and conditions of the<br>`MIT License`_.<br><br><br>.. _MIT License: http://opensource.org/licenses/MIT<br><br>.. _Web Crawlers: http://www.jdhp.org/projects_en.html#web-crawlers<br>\n          </div>"}, "last_serial": 2922949, "releases": {"0.1.dev1": [{"comment_text": "", "digests": {"md5": "dbe761decab4d4a1a96419e7c382abd3", "sha256": "6e6284bfecada0d027144264aa5ef46b9015bad6cba873f25d83a46ca758cbdf"}, "downloads": -1, "filename": "webcrawlers-0.1.dev1.tar.gz", "has_sig": false, "md5_digest": "dbe761decab4d4a1a96419e7c382abd3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6036, "upload_time": "2016-05-16T12:47:20", "upload_time_iso_8601": "2016-05-16T12:47:20.351763Z", "url": "https://files.pythonhosted.org/packages/2e/7f/acd6a64c678d37c58ebc6396055258e697ff6a122c386b758590cd08a475/webcrawlers-0.1.dev1.tar.gz", "yanked": false}], "0.1.dev2": [{"comment_text": "", "digests": {"md5": "17532120c6345cec8266724ccddb28ca", "sha256": "b9fefcfb2e5278ba20d575430d69a4f71769626e389044c8b889ec02d3a6e190"}, "downloads": -1, "filename": "webcrawlers-0.1.dev2.tar.gz", "has_sig": false, "md5_digest": "17532120c6345cec8266724ccddb28ca", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5990, "upload_time": "2016-05-18T08:07:00", "upload_time_iso_8601": "2016-05-18T08:07:00.569925Z", "url": "https://files.pythonhosted.org/packages/3c/be/1f6665244bd117425e59588b957086cf304fc1eea928e0d4e1b4219cf973/webcrawlers-0.1.dev2.tar.gz", "yanked": false}], "0.2.dev1": [{"comment_text": "", "digests": {"md5": "634847077ed07d0eb090611c0d0bbcde", "sha256": "66347f284963afd0f43787a9f65dd0b192dc547eb37b2cee6b92ec20ee8bad4f"}, "downloads": -1, "filename": "webcrawlers-0.2.dev1.tar.gz", "has_sig": false, "md5_digest": "634847077ed07d0eb090611c0d0bbcde", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6106, "upload_time": "2017-06-03T17:45:17", "upload_time_iso_8601": "2017-06-03T17:45:17.385103Z", "url": "https://files.pythonhosted.org/packages/16/e7/2e7b6ebced65ecaf6d31f202f5e83dc4923f7c4f94fb390460806ebc5c79/webcrawlers-0.2.dev1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "634847077ed07d0eb090611c0d0bbcde", "sha256": "66347f284963afd0f43787a9f65dd0b192dc547eb37b2cee6b92ec20ee8bad4f"}, "downloads": -1, "filename": "webcrawlers-0.2.dev1.tar.gz", "has_sig": false, "md5_digest": "634847077ed07d0eb090611c0d0bbcde", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6106, "upload_time": "2017-06-03T17:45:17", "upload_time_iso_8601": "2017-06-03T17:45:17.385103Z", "url": "https://files.pythonhosted.org/packages/16/e7/2e7b6ebced65ecaf6d31f202f5e83dc4923f7c4f94fb390460806ebc5c79/webcrawlers-0.2.dev1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:31:21 2020"}