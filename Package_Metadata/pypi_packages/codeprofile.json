{"info": {"author": "Teemu Kanstr\u00e9n", "author_email": "tkanstren@protonmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8", "Topic :: Software Development", "Topic :: Software Development :: Testing"], "description": "# Python Code Profiler\n\nFor measuring how much time different functions or pieces of code take to execute.\n\n# Installing\n\n## PyPi\n\n`pip install codeprofile`\n\nFor more details, check the [Python Package Index project](https://pypi.org/project/code-profile/).\n\n## Source Code\n\nHosted on [Github](https://github.com/mukatee/python-code-profile). At this time, practically just one file.\n\n# Usage\n\nAdd the provided decorators to the pieces of code / functions you want to profile.\n\nThis document uses the term `trace point`.\nIt refers to part of code that is profiled as a single block.\nIf you profile execution time of a specific function, that function is the trace point.\nIf you profile a specific block of code inside a function, that block is the trace point.\n\n## Functions\n\nTo trace / profile a function:\n\n```python\nfrom codeprofile import profiler\nimport time\n\n@profiler.profile_func\ndef my_func():\n    print(\"hello world\")\n    time.sleep(0.1)\n    x = some_other_func()\n    return int(x)\n```\n\nIn the above, every time the function `my_func` is executed, its execution time is recorded.\nIt becomes a trace point named `my_func`.\n\n## Code snippets\n\nTo trace the performance of a code snippet inside a function / module:\n\n```python\nfrom codeprofile import profiler\n\nfor x in range(100):\n    with profiler.profile(\"block read\"):\n        block = read_block(x)\n    with profiler.profile(\"db insert\"):\n        insert_into_database(block)\n```\n\nIn the above, there are two trace points name `block read` and `db insert`.\nThe code above executes each trace point 100 times,\nresulting in 100 performance measurements for each trace point.\nThe profiler will then provice access to cumulative, average, min, max, and count statistics\nfor each trace point.\nIf configured to keep the raw measurements, those and the median are also available per trace point.\n\nImagine the above `block read` as an example of reading a block of data over the network (e.g., scanning a blockchain).\nAnd writing this to a database in `db insert`. Maybe it seems slow.\nWith the above profiling, you can look at your program and wonder, where does the time go?\nNow there is a question we all would like to know..\n\n## AsyncIO\n\n[AsyncIO](https://docs.python.org/3/library/asyncio.html) is the Python way of making \nuse of inherent processing delays in IO-intensive operations to execute code in parallel.\nFor example, the system might be waiting for some disk or network IO to proceed.\nAt such points, the CPU is just idle.\nSo AsyncIO is intended as a way to execute other code in parallel while waiting on IO.\nSince Python has no true multithreading (the multi-processing module is not quite the same),\nthis can be a nice feature.\n\nAsyncIO uses special keywords (such as `async`) and code-structures to manage all this.\nFunctions used with AsyncIO thus need to be defined with the `async` keyword.\n\nBecause of this, the approach to profile regular functions with `@profiler.profile_func`\ndoes not work with AsyncIO, as the `profile_func` decorator is not `async`.\nA different decorator using the `async` definition is provided for this purpose:\n\n```python\nfrom codeprofile import profiler\nimport asyncio\n\n@profiler.profile_async_func\nasync def a_blocker(self):\n    block = read_block() # <- assume this function uses asyncio to access network / disk\n    await asyncio.sleep(1)\n    insert_into_database(block) # <- again, assume this call uses asyncio access to a database\n\n```\n\nIn the above example, `a_blocker` becomes a trace point measuring the function execution time for AsyncIO.\n\nFor code blocks inside AsyncIO methods / functions, the same approach as for other code blocks should work.\n\n```python\nfrom codeprofile import profiler\n\nasync def hundred_blocks():\n    for x in range(100):\n        with profiler.profile(\"block read\"):\n            block = read_block()\n        with profiler.profile(\"db insert\"):\n            insert_into_database(block)\n```\n\n## Configuration\n\n- `ignore_sleep`: If true, use a performance counter that ignores time spent in sleep mode. Defaults to false.\n- `collect_raw`: If true, keep the raw measurement data for each `trace point`. Takes more memory, but gives access to more detailed profiling information. Defaults to true.\n\nSetting them:\n\n```python\nfrom codeprofile import profiler\n\nprofiler.collect_raw = False #by default this is true\nprofiler.ignore_sleep = True #by default this is false\n```\n\n# Data Analysis\n\nThe performance data collected is stored and available as part of the `profiler` module.\n\n## Access raw results\n\nThe following variables are available as part of the `profiler` module:\n\n- `cumulative_times`: sum of all recorded execution times for a trace point.\n- `max_times`: highest time per trace point\n- `min_times`: minimum time per trace point\n- `counts`: number of times a trace point execution has been recorded.\n- `raw_times`: list of all recorded execution times per trace point.\n\nThe following function can be used if `collect_raw` is enabled:\n\n- `median_times`: median time per trace point.\n\nLike so:\n\n```python\nfrom codeprofile import profiler\n\ncumulative_block_time = profiler.cumulative_times[\"block read\"]\nmax_block_time = profiler.max_times[\"block read\"]\nmin_block_time = profiler.min_times[\"block read\"]\nall_block_times = profiler.raw_times[\"block read\"]\n\nmedian_block_time = profiler.median(\"block read\")\n```\n\nIf you want to reset the statistics while running:\n\n```python\nfrom codeprofile import profiler\n\nprofiler.reset_stats()\n```\n\n## Summary Printouts\n\n- `print_run_stats(*names, file=sys.stdout)`\n\nThe `names` parameter for `print_run_stats` is optional.\nIt defaults to all names.\nA name is simply a reference to name of a trace point.\n\nThe `file` parameter allows writing the results to a file, a string, or elsewhere.\nBy default, it uses the system output, writing the summary to console.\nYou can also use an actual filesystem file as target, or build a string using `io.StringIO`,\nor whatever else the Python filesystem can do.\n\n## Export to CSV and Pandas\n\n- `print_csv(*names, file=sys.stdout)`\n\nThe result of `print_csv` is a CSV file, where each column represents a trace-point.\nThe rows are not synchronized in any way, since only the person who implements the trace-points knows if they are related.\nSo each column is just a list of traced values (performance times) for that trace-point.\nEach column has equal number of values, which is the largest number of points recorded for any trace-point.\nThe ones with fewer values have the last rows left empty (nan in Pandas).\n\n```python\nfrom codeprofile import profiler\nimport pandas as pd\n\nwith open(\"output.csv\", \"wb\") as f:\n    profiler.print_csv(file=f)\n\ndf = pd.read_csv(\"output.csv\")\n```\n\n# Hierarchical profiling\n\nYou can also nest the trace profiling calls.\nFor example:\n\n```python\nfrom codeprofile import profiler\n\nwith profiler.profile(\"loop\"):\n    for x in range(100):\n        with profiler.profile(\"block read\"):\n            block = read_block(x)\n        with profiler.profile(\"db insert\"):\n            insert_into_database(block)\n```\n\nWith the above, you would have the `loop` trace point collecting stats for the read and write operations together,\nand the `block read` and `db insert` trace points for the specific operations.\n\n# License\n\nMIT\n\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/mukatee/python-code-profile", "keywords": "profiling,monitoring,performance,trace", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "codeprofile", "package_url": "https://pypi.org/project/codeprofile/", "platform": "", "project_url": "https://pypi.org/project/codeprofile/", "project_urls": {"Homepage": "https://github.com/mukatee/python-code-profile"}, "release_url": "https://pypi.org/project/codeprofile/1.0.1/", "requires_dist": null, "requires_python": "", "summary": "Profiling performance of blocks of code", "version": "1.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Python Code Profiler</h1>\n<p>For measuring how much time different functions or pieces of code take to execute.</p>\n<h1>Installing</h1>\n<h2>PyPi</h2>\n<p><code>pip install codeprofile</code></p>\n<p>For more details, check the <a href=\"https://pypi.org/project/code-profile/\" rel=\"nofollow\">Python Package Index project</a>.</p>\n<h2>Source Code</h2>\n<p>Hosted on <a href=\"https://github.com/mukatee/python-code-profile\" rel=\"nofollow\">Github</a>. At this time, practically just one file.</p>\n<h1>Usage</h1>\n<p>Add the provided decorators to the pieces of code / functions you want to profile.</p>\n<p>This document uses the term <code>trace point</code>.\nIt refers to part of code that is profiled as a single block.\nIf you profile execution time of a specific function, that function is the trace point.\nIf you profile a specific block of code inside a function, that block is the trace point.</p>\n<h2>Functions</h2>\n<p>To trace / profile a function:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">codeprofile</span> <span class=\"kn\">import</span> <span class=\"n\">profiler</span>\n<span class=\"kn\">import</span> <span class=\"nn\">time</span>\n\n<span class=\"nd\">@profiler</span><span class=\"o\">.</span><span class=\"n\">profile_func</span>\n<span class=\"k\">def</span> <span class=\"nf\">my_func</span><span class=\"p\">():</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"hello world\"</span><span class=\"p\">)</span>\n    <span class=\"n\">time</span><span class=\"o\">.</span><span class=\"n\">sleep</span><span class=\"p\">(</span><span class=\"mf\">0.1</span><span class=\"p\">)</span>\n    <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">some_other_func</span><span class=\"p\">()</span>\n    <span class=\"k\">return</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n</pre>\n<p>In the above, every time the function <code>my_func</code> is executed, its execution time is recorded.\nIt becomes a trace point named <code>my_func</code>.</p>\n<h2>Code snippets</h2>\n<p>To trace the performance of a code snippet inside a function / module:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">codeprofile</span> <span class=\"kn\">import</span> <span class=\"n\">profiler</span>\n\n<span class=\"k\">for</span> <span class=\"n\">x</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">):</span>\n    <span class=\"k\">with</span> <span class=\"n\">profiler</span><span class=\"o\">.</span><span class=\"n\">profile</span><span class=\"p\">(</span><span class=\"s2\">\"block read\"</span><span class=\"p\">):</span>\n        <span class=\"n\">block</span> <span class=\"o\">=</span> <span class=\"n\">read_block</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n    <span class=\"k\">with</span> <span class=\"n\">profiler</span><span class=\"o\">.</span><span class=\"n\">profile</span><span class=\"p\">(</span><span class=\"s2\">\"db insert\"</span><span class=\"p\">):</span>\n        <span class=\"n\">insert_into_database</span><span class=\"p\">(</span><span class=\"n\">block</span><span class=\"p\">)</span>\n</pre>\n<p>In the above, there are two trace points name <code>block read</code> and <code>db insert</code>.\nThe code above executes each trace point 100 times,\nresulting in 100 performance measurements for each trace point.\nThe profiler will then provice access to cumulative, average, min, max, and count statistics\nfor each trace point.\nIf configured to keep the raw measurements, those and the median are also available per trace point.</p>\n<p>Imagine the above <code>block read</code> as an example of reading a block of data over the network (e.g., scanning a blockchain).\nAnd writing this to a database in <code>db insert</code>. Maybe it seems slow.\nWith the above profiling, you can look at your program and wonder, where does the time go?\nNow there is a question we all would like to know..</p>\n<h2>AsyncIO</h2>\n<p><a href=\"https://docs.python.org/3/library/asyncio.html\" rel=\"nofollow\">AsyncIO</a> is the Python way of making\nuse of inherent processing delays in IO-intensive operations to execute code in parallel.\nFor example, the system might be waiting for some disk or network IO to proceed.\nAt such points, the CPU is just idle.\nSo AsyncIO is intended as a way to execute other code in parallel while waiting on IO.\nSince Python has no true multithreading (the multi-processing module is not quite the same),\nthis can be a nice feature.</p>\n<p>AsyncIO uses special keywords (such as <code>async</code>) and code-structures to manage all this.\nFunctions used with AsyncIO thus need to be defined with the <code>async</code> keyword.</p>\n<p>Because of this, the approach to profile regular functions with <code>@profiler.profile_func</code>\ndoes not work with AsyncIO, as the <code>profile_func</code> decorator is not <code>async</code>.\nA different decorator using the <code>async</code> definition is provided for this purpose:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">codeprofile</span> <span class=\"kn\">import</span> <span class=\"n\">profiler</span>\n<span class=\"kn\">import</span> <span class=\"nn\">asyncio</span>\n\n<span class=\"nd\">@profiler</span><span class=\"o\">.</span><span class=\"n\">profile_async_func</span>\n<span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">a_blocker</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n    <span class=\"n\">block</span> <span class=\"o\">=</span> <span class=\"n\">read_block</span><span class=\"p\">()</span> <span class=\"c1\"># &lt;- assume this function uses asyncio to access network / disk</span>\n    <span class=\"k\">await</span> <span class=\"n\">asyncio</span><span class=\"o\">.</span><span class=\"n\">sleep</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n    <span class=\"n\">insert_into_database</span><span class=\"p\">(</span><span class=\"n\">block</span><span class=\"p\">)</span> <span class=\"c1\"># &lt;- again, assume this call uses asyncio access to a database</span>\n</pre>\n<p>In the above example, <code>a_blocker</code> becomes a trace point measuring the function execution time for AsyncIO.</p>\n<p>For code blocks inside AsyncIO methods / functions, the same approach as for other code blocks should work.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">codeprofile</span> <span class=\"kn\">import</span> <span class=\"n\">profiler</span>\n\n<span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">hundred_blocks</span><span class=\"p\">():</span>\n    <span class=\"k\">for</span> <span class=\"n\">x</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">):</span>\n        <span class=\"k\">with</span> <span class=\"n\">profiler</span><span class=\"o\">.</span><span class=\"n\">profile</span><span class=\"p\">(</span><span class=\"s2\">\"block read\"</span><span class=\"p\">):</span>\n            <span class=\"n\">block</span> <span class=\"o\">=</span> <span class=\"n\">read_block</span><span class=\"p\">()</span>\n        <span class=\"k\">with</span> <span class=\"n\">profiler</span><span class=\"o\">.</span><span class=\"n\">profile</span><span class=\"p\">(</span><span class=\"s2\">\"db insert\"</span><span class=\"p\">):</span>\n            <span class=\"n\">insert_into_database</span><span class=\"p\">(</span><span class=\"n\">block</span><span class=\"p\">)</span>\n</pre>\n<h2>Configuration</h2>\n<ul>\n<li><code>ignore_sleep</code>: If true, use a performance counter that ignores time spent in sleep mode. Defaults to false.</li>\n<li><code>collect_raw</code>: If true, keep the raw measurement data for each <code>trace point</code>. Takes more memory, but gives access to more detailed profiling information. Defaults to true.</li>\n</ul>\n<p>Setting them:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">codeprofile</span> <span class=\"kn\">import</span> <span class=\"n\">profiler</span>\n\n<span class=\"n\">profiler</span><span class=\"o\">.</span><span class=\"n\">collect_raw</span> <span class=\"o\">=</span> <span class=\"kc\">False</span> <span class=\"c1\">#by default this is true</span>\n<span class=\"n\">profiler</span><span class=\"o\">.</span><span class=\"n\">ignore_sleep</span> <span class=\"o\">=</span> <span class=\"kc\">True</span> <span class=\"c1\">#by default this is false</span>\n</pre>\n<h1>Data Analysis</h1>\n<p>The performance data collected is stored and available as part of the <code>profiler</code> module.</p>\n<h2>Access raw results</h2>\n<p>The following variables are available as part of the <code>profiler</code> module:</p>\n<ul>\n<li><code>cumulative_times</code>: sum of all recorded execution times for a trace point.</li>\n<li><code>max_times</code>: highest time per trace point</li>\n<li><code>min_times</code>: minimum time per trace point</li>\n<li><code>counts</code>: number of times a trace point execution has been recorded.</li>\n<li><code>raw_times</code>: list of all recorded execution times per trace point.</li>\n</ul>\n<p>The following function can be used if <code>collect_raw</code> is enabled:</p>\n<ul>\n<li><code>median_times</code>: median time per trace point.</li>\n</ul>\n<p>Like so:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">codeprofile</span> <span class=\"kn\">import</span> <span class=\"n\">profiler</span>\n\n<span class=\"n\">cumulative_block_time</span> <span class=\"o\">=</span> <span class=\"n\">profiler</span><span class=\"o\">.</span><span class=\"n\">cumulative_times</span><span class=\"p\">[</span><span class=\"s2\">\"block read\"</span><span class=\"p\">]</span>\n<span class=\"n\">max_block_time</span> <span class=\"o\">=</span> <span class=\"n\">profiler</span><span class=\"o\">.</span><span class=\"n\">max_times</span><span class=\"p\">[</span><span class=\"s2\">\"block read\"</span><span class=\"p\">]</span>\n<span class=\"n\">min_block_time</span> <span class=\"o\">=</span> <span class=\"n\">profiler</span><span class=\"o\">.</span><span class=\"n\">min_times</span><span class=\"p\">[</span><span class=\"s2\">\"block read\"</span><span class=\"p\">]</span>\n<span class=\"n\">all_block_times</span> <span class=\"o\">=</span> <span class=\"n\">profiler</span><span class=\"o\">.</span><span class=\"n\">raw_times</span><span class=\"p\">[</span><span class=\"s2\">\"block read\"</span><span class=\"p\">]</span>\n\n<span class=\"n\">median_block_time</span> <span class=\"o\">=</span> <span class=\"n\">profiler</span><span class=\"o\">.</span><span class=\"n\">median</span><span class=\"p\">(</span><span class=\"s2\">\"block read\"</span><span class=\"p\">)</span>\n</pre>\n<p>If you want to reset the statistics while running:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">codeprofile</span> <span class=\"kn\">import</span> <span class=\"n\">profiler</span>\n\n<span class=\"n\">profiler</span><span class=\"o\">.</span><span class=\"n\">reset_stats</span><span class=\"p\">()</span>\n</pre>\n<h2>Summary Printouts</h2>\n<ul>\n<li><code>print_run_stats(*names, file=sys.stdout)</code></li>\n</ul>\n<p>The <code>names</code> parameter for <code>print_run_stats</code> is optional.\nIt defaults to all names.\nA name is simply a reference to name of a trace point.</p>\n<p>The <code>file</code> parameter allows writing the results to a file, a string, or elsewhere.\nBy default, it uses the system output, writing the summary to console.\nYou can also use an actual filesystem file as target, or build a string using <code>io.StringIO</code>,\nor whatever else the Python filesystem can do.</p>\n<h2>Export to CSV and Pandas</h2>\n<ul>\n<li><code>print_csv(*names, file=sys.stdout)</code></li>\n</ul>\n<p>The result of <code>print_csv</code> is a CSV file, where each column represents a trace-point.\nThe rows are not synchronized in any way, since only the person who implements the trace-points knows if they are related.\nSo each column is just a list of traced values (performance times) for that trace-point.\nEach column has equal number of values, which is the largest number of points recorded for any trace-point.\nThe ones with fewer values have the last rows left empty (nan in Pandas).</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">codeprofile</span> <span class=\"kn\">import</span> <span class=\"n\">profiler</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n\n<span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s2\">\"output.csv\"</span><span class=\"p\">,</span> <span class=\"s2\">\"wb\"</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">f</span><span class=\"p\">:</span>\n    <span class=\"n\">profiler</span><span class=\"o\">.</span><span class=\"n\">print_csv</span><span class=\"p\">(</span><span class=\"n\">file</span><span class=\"o\">=</span><span class=\"n\">f</span><span class=\"p\">)</span>\n\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s2\">\"output.csv\"</span><span class=\"p\">)</span>\n</pre>\n<h1>Hierarchical profiling</h1>\n<p>You can also nest the trace profiling calls.\nFor example:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">codeprofile</span> <span class=\"kn\">import</span> <span class=\"n\">profiler</span>\n\n<span class=\"k\">with</span> <span class=\"n\">profiler</span><span class=\"o\">.</span><span class=\"n\">profile</span><span class=\"p\">(</span><span class=\"s2\">\"loop\"</span><span class=\"p\">):</span>\n    <span class=\"k\">for</span> <span class=\"n\">x</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">):</span>\n        <span class=\"k\">with</span> <span class=\"n\">profiler</span><span class=\"o\">.</span><span class=\"n\">profile</span><span class=\"p\">(</span><span class=\"s2\">\"block read\"</span><span class=\"p\">):</span>\n            <span class=\"n\">block</span> <span class=\"o\">=</span> <span class=\"n\">read_block</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"k\">with</span> <span class=\"n\">profiler</span><span class=\"o\">.</span><span class=\"n\">profile</span><span class=\"p\">(</span><span class=\"s2\">\"db insert\"</span><span class=\"p\">):</span>\n            <span class=\"n\">insert_into_database</span><span class=\"p\">(</span><span class=\"n\">block</span><span class=\"p\">)</span>\n</pre>\n<p>With the above, you would have the <code>loop</code> trace point collecting stats for the read and write operations together,\nand the <code>block read</code> and <code>db insert</code> trace points for the specific operations.</p>\n<h1>License</h1>\n<p>MIT</p>\n\n          </div>"}, "last_serial": 7099869, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "41f9acb901c7fa77b3096ccd8c751744", "sha256": "5dfecd1cf904961a7cf860d16594dd6ccf8c1864a0c9ded4bba06ce20f4e4965"}, "downloads": -1, "filename": "codeprofile-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "41f9acb901c7fa77b3096ccd8c751744", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7093, "upload_time": "2020-03-07T22:35:07", "upload_time_iso_8601": "2020-03-07T22:35:07.434433Z", "url": "https://files.pythonhosted.org/packages/a6/54/7cb1d8b6a75935d9327174e33e01a87a4bf5b0fc2aa177b2ca6a62fae283/codeprofile-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "64d39f2c787b26d55339b222572431d5", "sha256": "141333a1735153a94610682c60cfb7d717f02a22ea31dddf7ffc3335d415d047"}, "downloads": -1, "filename": "codeprofile-1.0.0.tar.gz", "has_sig": false, "md5_digest": "64d39f2c787b26d55339b222572431d5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6027, "upload_time": "2020-03-07T22:35:09", "upload_time_iso_8601": "2020-03-07T22:35:09.808672Z", "url": "https://files.pythonhosted.org/packages/e6/22/c3b38043c62822d6f31329e4e033a9109e9bc3e2d01542b605b0d5f80b47/codeprofile-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "384ca09851c147f24f7dabcb4073bd01", "sha256": "509852f09747ed2dc33cc9d503f5b9ab3ce29b8504f5c2775ee2d083558e5347"}, "downloads": -1, "filename": "codeprofile-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "384ca09851c147f24f7dabcb4073bd01", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7125, "upload_time": "2020-04-25T14:47:50", "upload_time_iso_8601": "2020-04-25T14:47:50.861686Z", "url": "https://files.pythonhosted.org/packages/e0/5e/a594ac85f12be36117bcef997381a817aa744423fcbd862516795fc4afc1/codeprofile-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "de45ae23e1c4a3ae99ba75be46f509db", "sha256": "63241c43c8d8044bb527417a09efe71efab0208c8a65d4a138e6c075600fc6a3"}, "downloads": -1, "filename": "codeprofile-1.0.1.tar.gz", "has_sig": false, "md5_digest": "de45ae23e1c4a3ae99ba75be46f509db", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6079, "upload_time": "2020-04-25T14:47:52", "upload_time_iso_8601": "2020-04-25T14:47:52.232976Z", "url": "https://files.pythonhosted.org/packages/8c/61/0b59da0badca97c0c0825214866fda392a02c6825200469d12c69f9f61f9/codeprofile-1.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "384ca09851c147f24f7dabcb4073bd01", "sha256": "509852f09747ed2dc33cc9d503f5b9ab3ce29b8504f5c2775ee2d083558e5347"}, "downloads": -1, "filename": "codeprofile-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "384ca09851c147f24f7dabcb4073bd01", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7125, "upload_time": "2020-04-25T14:47:50", "upload_time_iso_8601": "2020-04-25T14:47:50.861686Z", "url": "https://files.pythonhosted.org/packages/e0/5e/a594ac85f12be36117bcef997381a817aa744423fcbd862516795fc4afc1/codeprofile-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "de45ae23e1c4a3ae99ba75be46f509db", "sha256": "63241c43c8d8044bb527417a09efe71efab0208c8a65d4a138e6c075600fc6a3"}, "downloads": -1, "filename": "codeprofile-1.0.1.tar.gz", "has_sig": false, "md5_digest": "de45ae23e1c4a3ae99ba75be46f509db", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6079, "upload_time": "2020-04-25T14:47:52", "upload_time_iso_8601": "2020-04-25T14:47:52.232976Z", "url": "https://files.pythonhosted.org/packages/8c/61/0b59da0badca97c0c0825214866fda392a02c6825200469d12c69f9f61f9/codeprofile-1.0.1.tar.gz", "yanked": false}], "timestamp": "Thu May  7 22:18:14 2020"}