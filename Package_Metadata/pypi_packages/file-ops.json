{"info": {"author": "Andrey Melnikov", "author_email": "vafilor@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: GNU General Public License v3 (GPLv3)", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# File Ops\n\nFile Ops is a set of components and basic CLI to get file statistics from a hard drive.\nIt stores this information in a SQLite database, which you can then query to your heart's content.\n\nWith it, you can\n\n* Store all of the files and directories of a drive with\n  * file/directory path\n  * file/directory modified at\n  * file/directory size \n  * file md5 hash\n\nWith that information you can (quickly)\n\n* Find largest files, directories, etc across many external drives.\n* Find duplicate files by comparing hashes\n* Find the largest directories\n\n## Commands\n\nAll commands support a `--time` flag to output how long it took.\n\n### Index File Stats (no hash is calculated for files)\n\nNote: The database file is automatically created if it does not exist and defaults to `files.db`.\n\n```bash\nfileops index path/to/index database_file.db  \n```\n\n### Hash files in database\n\n```bash\nfileops hash database_file.db\n```\n\n### Cleanup\n\nThis removes files that have been deleted, etc. \nIt should be followed by the index command to keep things up to date.\n\n```bash\nfileops cleanup database_file.db\n```\n\n### Calculate Folder Stats\n\nThis updates all folders with their sizes. This is a slow process.\n\n```bash\nfileops folder-stats database_file.db\n```\n\n## Find duplicate files by comparing hashes \n\nUse the following query to find the files with the most duplicates\n\n```sql\nSELECT hash, COUNT(*)\nFROM files\nWHERE is_directory = 0\nGROUP BY hash\nORDER BY COUNT(*) DESC\nLIMIT 10;\n```\n\nThen you can do a query per hash\n\n```sql\nSELECT *\nFROM files\nWHERE hash = '94bd41953ca5233c5efe121c73959af7';\n```\n\n## Tested on\n\n* Mac 10.14.3\n* Windows 10\n* Ubuntu 18\n\n## Project Goals\n\n* Minimal dependencies\n\n## Feature Ideas\n\n### Ignore file settings\n\n* hidden files\n* certain directories\n\n### Command to join database files\n\nI might run multiple copies of the program on several drives, or computers, for speed.\nWhen they are all done, I want to merge the output database files into one for easy querying.\n\n### Calculate Directory size faster\n\nRight now it works, but its rather slow.\n\n### Hash Directories\n\nGiven two directories on different hard drives, I would like to be able to quickly know if they have the same contents.\n\nIf we hash all the files of a directory, can we hash the individual hashes to get a folder hash? Would that work?  \n\n### Uniquely Identifier Hard Drives\n\nGiven a lot of external hard drives, thumb drives, etc, I want to be able to store them \nall in a single database file and be able to uniquely identify them. \n\nSo if I index a thumb drive on my laptop, I want to be able to take it to my PC and update the index\nthere and still know it's for the same thumbdrive.  \n\nIf this is implemented, the file paths should not have the mount path.\nThe hard drive identifier should be a separate column. \n\nE.g. on windows\n\ne:\\projects\\python\\cli.py\n\nshould become\n\nprojects\\python\\cli.py\n\n### Performance Improvements\n\nNeed to see if we can improve the performance. Yep.\n\n## Grand Ideas\n\n### Supplementary UI application\n\nDoing this from the CLI is great, but it would be nice to have a UI application that could instantly show you\n\n* Largest Files\n* Largest Duplicate Files\n* Find files by name (see Everything Search - https://www.voidtools.com/)\n* Status Updates as the indexing happens (particularly for hashing)\n* Re-index command\n* Re-calculate hashes command\n\n### One source for all files, with sym-links everywhere else\n\nOnce you have all of the files indexed for a drive, store them all in a directory and sym-link them everywhere else. \nWith this, remove all duplicates via hash comparison.\n\nThis wouldn't work for auto-generated files of course and may only be useful for relatively static directories.\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Vafilor/file-ops", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "file-ops", "package_url": "https://pypi.org/project/file-ops/", "platform": "", "project_url": "https://pypi.org/project/file-ops/", "project_urls": {"Homepage": "https://github.com/Vafilor/file-ops"}, "release_url": "https://pypi.org/project/file-ops/1.0.4/", "requires_dist": null, "requires_python": "", "summary": "Filesystem operations to index files and hash their contents", "version": "1.0.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>File Ops</h1>\n<p>File Ops is a set of components and basic CLI to get file statistics from a hard drive.\nIt stores this information in a SQLite database, which you can then query to your heart's content.</p>\n<p>With it, you can</p>\n<ul>\n<li>Store all of the files and directories of a drive with\n<ul>\n<li>file/directory path</li>\n<li>file/directory modified at</li>\n<li>file/directory size</li>\n<li>file md5 hash</li>\n</ul>\n</li>\n</ul>\n<p>With that information you can (quickly)</p>\n<ul>\n<li>Find largest files, directories, etc across many external drives.</li>\n<li>Find duplicate files by comparing hashes</li>\n<li>Find the largest directories</li>\n</ul>\n<h2>Commands</h2>\n<p>All commands support a <code>--time</code> flag to output how long it took.</p>\n<h3>Index File Stats (no hash is calculated for files)</h3>\n<p>Note: The database file is automatically created if it does not exist and defaults to <code>files.db</code>.</p>\n<pre>fileops index path/to/index database_file.db  \n</pre>\n<h3>Hash files in database</h3>\n<pre>fileops <span class=\"nb\">hash</span> database_file.db\n</pre>\n<h3>Cleanup</h3>\n<p>This removes files that have been deleted, etc.\nIt should be followed by the index command to keep things up to date.</p>\n<pre>fileops cleanup database_file.db\n</pre>\n<h3>Calculate Folder Stats</h3>\n<p>This updates all folders with their sizes. This is a slow process.</p>\n<pre>fileops folder-stats database_file.db\n</pre>\n<h2>Find duplicate files by comparing hashes</h2>\n<p>Use the following query to find the files with the most duplicates</p>\n<pre><span class=\"k\">SELECT</span> <span class=\"n\">hash</span><span class=\"p\">,</span> <span class=\"k\">COUNT</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"p\">)</span>\n<span class=\"k\">FROM</span> <span class=\"n\">files</span>\n<span class=\"k\">WHERE</span> <span class=\"n\">is_directory</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n<span class=\"k\">GROUP</span> <span class=\"k\">BY</span> <span class=\"n\">hash</span>\n<span class=\"k\">ORDER</span> <span class=\"k\">BY</span> <span class=\"k\">COUNT</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"p\">)</span> <span class=\"k\">DESC</span>\n<span class=\"k\">LIMIT</span> <span class=\"mi\">10</span><span class=\"p\">;</span>\n</pre>\n<p>Then you can do a query per hash</p>\n<pre><span class=\"k\">SELECT</span> <span class=\"o\">*</span>\n<span class=\"k\">FROM</span> <span class=\"n\">files</span>\n<span class=\"k\">WHERE</span> <span class=\"n\">hash</span> <span class=\"o\">=</span> <span class=\"s1\">'94bd41953ca5233c5efe121c73959af7'</span><span class=\"p\">;</span>\n</pre>\n<h2>Tested on</h2>\n<ul>\n<li>Mac 10.14.3</li>\n<li>Windows 10</li>\n<li>Ubuntu 18</li>\n</ul>\n<h2>Project Goals</h2>\n<ul>\n<li>Minimal dependencies</li>\n</ul>\n<h2>Feature Ideas</h2>\n<h3>Ignore file settings</h3>\n<ul>\n<li>hidden files</li>\n<li>certain directories</li>\n</ul>\n<h3>Command to join database files</h3>\n<p>I might run multiple copies of the program on several drives, or computers, for speed.\nWhen they are all done, I want to merge the output database files into one for easy querying.</p>\n<h3>Calculate Directory size faster</h3>\n<p>Right now it works, but its rather slow.</p>\n<h3>Hash Directories</h3>\n<p>Given two directories on different hard drives, I would like to be able to quickly know if they have the same contents.</p>\n<p>If we hash all the files of a directory, can we hash the individual hashes to get a folder hash? Would that work?</p>\n<h3>Uniquely Identifier Hard Drives</h3>\n<p>Given a lot of external hard drives, thumb drives, etc, I want to be able to store them\nall in a single database file and be able to uniquely identify them.</p>\n<p>So if I index a thumb drive on my laptop, I want to be able to take it to my PC and update the index\nthere and still know it's for the same thumbdrive.</p>\n<p>If this is implemented, the file paths should not have the mount path.\nThe hard drive identifier should be a separate column.</p>\n<p>E.g. on windows</p>\n<p>e:\\projects\\python\\cli.py</p>\n<p>should become</p>\n<p>projects\\python\\cli.py</p>\n<h3>Performance Improvements</h3>\n<p>Need to see if we can improve the performance. Yep.</p>\n<h2>Grand Ideas</h2>\n<h3>Supplementary UI application</h3>\n<p>Doing this from the CLI is great, but it would be nice to have a UI application that could instantly show you</p>\n<ul>\n<li>Largest Files</li>\n<li>Largest Duplicate Files</li>\n<li>Find files by name (see Everything Search - <a href=\"https://www.voidtools.com/\" rel=\"nofollow\">https://www.voidtools.com/</a>)</li>\n<li>Status Updates as the indexing happens (particularly for hashing)</li>\n<li>Re-index command</li>\n<li>Re-calculate hashes command</li>\n</ul>\n<h3>One source for all files, with sym-links everywhere else</h3>\n<p>Once you have all of the files indexed for a drive, store them all in a directory and sym-link them everywhere else.\nWith this, remove all duplicates via hash comparison.</p>\n<p>This wouldn't work for auto-generated files of course and may only be useful for relatively static directories.</p>\n\n          </div>"}, "last_serial": 5316747, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "2748a111c2d6ed1259134a63ab2abd1d", "sha256": "b7e1a972f17554a164fc28016f901e49561aa5ea3f5663557c05fdc87f5fb841"}, "downloads": -1, "filename": "file_ops-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "2748a111c2d6ed1259134a63ab2abd1d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 30274, "upload_time": "2019-05-25T04:16:19", "upload_time_iso_8601": "2019-05-25T04:16:19.493502Z", "url": "https://files.pythonhosted.org/packages/f7/a9/b80cdf3e34a276d0810b3d5e30526d2a8fa6df7d071424f83a6b34ecc5f0/file_ops-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b4c2161b0451af5befb02fc40ce24a0d", "sha256": "06b40ea5232f534c22c470b89e65c46af315666786d9f6bde6d89cb3567f809f"}, "downloads": -1, "filename": "file-ops-1.0.0.tar.gz", "has_sig": false, "md5_digest": "b4c2161b0451af5befb02fc40ce24a0d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13063, "upload_time": "2019-05-25T04:16:22", "upload_time_iso_8601": "2019-05-25T04:16:22.381901Z", "url": "https://files.pythonhosted.org/packages/06/1e/c315b591cefa2099df9ed1eac4ebc1d99c304f811a38ecc83d66fcbb7a9a/file-ops-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "71eb32da54b87c07bf2d96a1a1a1f1a3", "sha256": "1c9425bcb57cabf6e32c04dd89290ca39aeff09ec599d7aae811d11b60210e8e"}, "downloads": -1, "filename": "file_ops-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "71eb32da54b87c07bf2d96a1a1a1f1a3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 30806, "upload_time": "2019-05-25T05:00:32", "upload_time_iso_8601": "2019-05-25T05:00:32.286782Z", "url": "https://files.pythonhosted.org/packages/ec/81/0fba2477a9a95578a58309e47a2ff33123280cd24c5ab6c26ea9c35cae40/file_ops-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "30c9b21cc4bda66c487a7f71461fd14e", "sha256": "c59f3a9be5e4ae3b4d3be2add2c251880a233db0ce518ba93b62df81b5e9e957"}, "downloads": -1, "filename": "file-ops-1.0.1.tar.gz", "has_sig": false, "md5_digest": "30c9b21cc4bda66c487a7f71461fd14e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13264, "upload_time": "2019-05-25T05:00:33", "upload_time_iso_8601": "2019-05-25T05:00:33.754303Z", "url": "https://files.pythonhosted.org/packages/07/c1/78407d7984633d388dc9a8f8c9f26a72d5bab182111b1f5edba74e7bfdb0/file-ops-1.0.1.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "650ae0eecc619fb827e869856019780e", "sha256": "1c8ccb6ec3f674a517913463ed98cb935797ffe7b7ce7aa75bfaed5374a748f0"}, "downloads": -1, "filename": "file_ops-1.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "650ae0eecc619fb827e869856019780e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 30629, "upload_time": "2019-05-25T05:13:26", "upload_time_iso_8601": "2019-05-25T05:13:26.762724Z", "url": "https://files.pythonhosted.org/packages/f2/b9/2748fbe14ee6f6e3c967184cbc98730ffa9a52250fe7172154133d208c9c/file_ops-1.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5308d056a6e6a7360b70399e5cee085d", "sha256": "781712e1dba781edad810fc9b2d08248befc9498b9defd473368846699349f81"}, "downloads": -1, "filename": "file-ops-1.0.2.tar.gz", "has_sig": false, "md5_digest": "5308d056a6e6a7360b70399e5cee085d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13145, "upload_time": "2019-05-25T05:13:28", "upload_time_iso_8601": "2019-05-25T05:13:28.068977Z", "url": "https://files.pythonhosted.org/packages/e3/0c/9fce31d99b62f0def07fd6fd75322b3c43e664311331edef9f1a2d0f561d/file-ops-1.0.2.tar.gz", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "30e3ea6147932f2d2f773a0ae3db6ea9", "sha256": "7cde5c51440989b919400fee42e782cadc975db5a084524ba1b78cec687c6caf"}, "downloads": -1, "filename": "file_ops-1.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "30e3ea6147932f2d2f773a0ae3db6ea9", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 30625, "upload_time": "2019-05-25T05:37:01", "upload_time_iso_8601": "2019-05-25T05:37:01.517203Z", "url": "https://files.pythonhosted.org/packages/2f/39/edad92adcf51b578078e4c3eb4411ef92403a4f0293de0d26e7530b61cbc/file_ops-1.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a88b5256ac63a03fade8c5a5c2e4d352", "sha256": "06c2044332d4fe5b0a67a717c3d5188895a2b4ea1cc8d4441dea0b927574288a"}, "downloads": -1, "filename": "file-ops-1.0.3.tar.gz", "has_sig": false, "md5_digest": "a88b5256ac63a03fade8c5a5c2e4d352", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13145, "upload_time": "2019-05-25T05:37:03", "upload_time_iso_8601": "2019-05-25T05:37:03.089305Z", "url": "https://files.pythonhosted.org/packages/77/ed/1c2069954413f53a88ef0237d64dc99fb147e624e79c637f2c06033f1b96/file-ops-1.0.3.tar.gz", "yanked": false}], "1.0.4": [{"comment_text": "", "digests": {"md5": "46cbad0664c13d0b9d151d21c8b860c1", "sha256": "45c75781fd59ddbd10621bfa0bec4cd70bd9d72090dcfca651f237963da25267"}, "downloads": -1, "filename": "file_ops-1.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "46cbad0664c13d0b9d151d21c8b860c1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 30578, "upload_time": "2019-05-25T16:05:47", "upload_time_iso_8601": "2019-05-25T16:05:47.997694Z", "url": "https://files.pythonhosted.org/packages/a2/bf/59a3a804ab6dac17fef932581b5a8c7a5c191280768f22dd8d152e0ba07b/file_ops-1.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a8484217aae17eb75f9382a9b16deb35", "sha256": "4d9ce2fcf7c7edd096ebf2af6cc37a179b06facdb0fe098071a8fea6facc59a0"}, "downloads": -1, "filename": "file-ops-1.0.4.tar.gz", "has_sig": false, "md5_digest": "a8484217aae17eb75f9382a9b16deb35", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13108, "upload_time": "2019-05-25T16:05:49", "upload_time_iso_8601": "2019-05-25T16:05:49.626237Z", "url": "https://files.pythonhosted.org/packages/1c/41/cf13499e5b36dc60662eba20c1647e84a7a9f39e90b3c8ade94aad57958d/file-ops-1.0.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "46cbad0664c13d0b9d151d21c8b860c1", "sha256": "45c75781fd59ddbd10621bfa0bec4cd70bd9d72090dcfca651f237963da25267"}, "downloads": -1, "filename": "file_ops-1.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "46cbad0664c13d0b9d151d21c8b860c1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 30578, "upload_time": "2019-05-25T16:05:47", "upload_time_iso_8601": "2019-05-25T16:05:47.997694Z", "url": "https://files.pythonhosted.org/packages/a2/bf/59a3a804ab6dac17fef932581b5a8c7a5c191280768f22dd8d152e0ba07b/file_ops-1.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a8484217aae17eb75f9382a9b16deb35", "sha256": "4d9ce2fcf7c7edd096ebf2af6cc37a179b06facdb0fe098071a8fea6facc59a0"}, "downloads": -1, "filename": "file-ops-1.0.4.tar.gz", "has_sig": false, "md5_digest": "a8484217aae17eb75f9382a9b16deb35", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13108, "upload_time": "2019-05-25T16:05:49", "upload_time_iso_8601": "2019-05-25T16:05:49.626237Z", "url": "https://files.pythonhosted.org/packages/1c/41/cf13499e5b36dc60662eba20c1647e84a7a9f39e90b3c8ade94aad57958d/file-ops-1.0.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:42:33 2020"}