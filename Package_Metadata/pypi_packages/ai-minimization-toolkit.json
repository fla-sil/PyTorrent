{"info": {"author": "", "author_email": "", "bugtrack_url": null, "classifiers": ["Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved", "Operating System :: MacOS", "Operating System :: Microsoft :: Windows", "Operating System :: Unix", "Programming Language :: Python", "Programming Language :: Python :: 3.7", "Topic :: Scientific/Engineering", "Topic :: Software Development"], "description": ".. -*- mode: rst -*-\n\nminimization-toolkit - A toolkit for performing data minimization for machine learning models\n=============================================================================================\n\nThe EU General Data Protection Regulation (GDPR) mandates the principle of data minimization, which requires that only data necessary to fulfill a certain purpose be collected. However, it can often be difficult to determine the minimal amount of data required, especially in complex machine learning models such as neural networks. \n\nThis toolkit is a first-of-a-kind implementation to help reduce the amount of personal data needed to perform predictions with a machine learning model, by removing or generalizing some of the input features. The type of data minimization this toolkit focuses on is the reduction of the number and/or granularity of features collected for analysis. \n\nThe generalization process basically searches for several similar records and groups them together. Then, for each feature, the individual values for that feature within each group are replaced with a represenataive value that is common across the whole group. This process is done while using knowledge encoded within the model to produce a generalization that has little to no impact on its accuracy. \n\nThe minimization-toolkit is compatible with: ``Python 3.7``.\n\nOfficial `ai-minimization-toolkit documentation <https://ai-minimization-toolkit.readthedocs.io/en/master/>`__\n\nUsing the minimization-toolkit\n------------------------------\n\nThe main class, ``GeneralizeToRepresentative``, is a scikit-learn compatible ``Transformer``, that receives an existing estimator and labeled training data, and learns the generalizations that can be applied to any newly collected data for analysis by the original model. The ``fit()`` method learns the generalizations and the ``transform()`` method applies them to new data.\n\nIt is also possible to export the generalizations as feature ranges.\n\nThe current implementation supports only numeric features, so any categorical features must be transformed to a numeric representation before using this class.\n\nStart by training your machine learning model. In this example, we will use a ``DecisionTreeClassifier``, but any scikit-learn model can be used. We will use the iris dataset in our example.\n\n.. code:: python\n\n  from sklearn import datasets\n  from sklearn.model_selection import train_test_split\n  from sklearn.tree import DecisionTreeClassifier\n\n  dataset = datasets.load_iris()\n  X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.2)\n\n  base_est = DecisionTreeClassifier()\n  base_est.fit(X_train, y_train)\n\nNow create the ``GeneralizeToRepresentative`` transformer and train it. Supply it with the original model and the desired target accuracy. The training process may receive the original labeled training data or the model's predictions on the data.\n\n.. code:: python\n\n  predictions = base_est.predict(X_train)\n  gen = GeneralizeToRepresentative(base_est, target_accuracy=0.9)\n  gen.fit(X_train, predictions)\n\nNow use the transformer to transform new data, for example the test data.\n\n.. code:: python\n\n  transformed = gen.transform(X_test)\n\nThe transformed data has the same columns and formats as the original data, so it can be used directly to derive predictions from the original model.\n\n.. code:: python\n\n  new_predictions = base_est.predict(transformed)\n\nTo export the resulting generalizations, retrieve the ``Transformer``'s ``_generalize`` parameter.\n\n.. code:: python\n\n  generalizations = base_est._generalize\n\nThe returned object has the following structure::\n\n  {\n    ranges: \n    {\n      list of (<feature name>: [<list of values>])\n    }, \n    untouched: [<list of feature names>]\n  }\n\nFor example::\n\n  {\n    ranges: \n    {\n      age: [21.5, 39.0, 51.0, 70.5], \n      education-years: [8.0, 12.0, 14.5]\n    }, \n    untouched: [\"occupation\", \"marital-status\"]\n  }\n\nWhere each value inside the range list represents a cutoff point. For example, for the ``age`` feature, the ranges in this example are: ``<21.5, 21.5-39.0, 39.0-51.0, 51.0-70.5, >70.5``. The ``untouched`` list represents features that were not generalized, i.e., their values should remain unchanged.\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "new BSD", "maintainer": "A. Goldsteen", "maintainer_email": "abigailt@il.ibm.com", "name": "ai-minimization-toolkit", "package_url": "https://pypi.org/project/ai-minimization-toolkit/", "platform": "", "project_url": "https://pypi.org/project/ai-minimization-toolkit/", "project_urls": null, "release_url": "https://pypi.org/project/ai-minimization-toolkit/0.0.1/", "requires_dist": ["numpy", "scipy", "scikit-learn", "pandas", "sphinx ; extra == 'docs'", "sphinx-rtd-theme ; extra == 'docs'", "numpydoc ; extra == 'docs'", "matplotlib ; extra == 'docs'", "pytest ; extra == 'tests'", "pytest-cov ; extra == 'tests'"], "requires_python": "", "summary": "A toolkit for minimizing the data required to apply machine learning", "version": "0.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>The EU General Data Protection Regulation (GDPR) mandates the principle of data minimization, which requires that only data necessary to fulfill a certain purpose be collected. However, it can often be difficult to determine the minimal amount of data required, especially in complex machine learning models such as neural networks.</p>\n<p>This toolkit is a first-of-a-kind implementation to help reduce the amount of personal data needed to perform predictions with a machine learning model, by removing or generalizing some of the input features. The type of data minimization this toolkit focuses on is the reduction of the number and/or granularity of features collected for analysis.</p>\n<p>The generalization process basically searches for several similar records and groups them together. Then, for each feature, the individual values for that feature within each group are replaced with a represenataive value that is common across the whole group. This process is done while using knowledge encoded within the model to produce a generalization that has little to no impact on its accuracy.</p>\n<p>The minimization-toolkit is compatible with: <tt>Python 3.7</tt>.</p>\n<p>Official <a href=\"https://ai-minimization-toolkit.readthedocs.io/en/master/\" rel=\"nofollow\">ai-minimization-toolkit documentation</a></p>\n<div id=\"using-the-minimization-toolkit\">\n<h2>Using the minimization-toolkit</h2>\n<p>The main class, <tt>GeneralizeToRepresentative</tt>, is a scikit-learn compatible <tt>Transformer</tt>, that receives an existing estimator and labeled training data, and learns the generalizations that can be applied to any newly collected data for analysis by the original model. The <tt>fit()</tt> method learns the generalizations and the <tt>transform()</tt> method applies them to new data.</p>\n<p>It is also possible to export the generalizations as feature ranges.</p>\n<p>The current implementation supports only numeric features, so any categorical features must be transformed to a numeric representation before using this class.</p>\n<p>Start by training your machine learning model. In this example, we will use a <tt>DecisionTreeClassifier</tt>, but any scikit-learn model can be used. We will use the iris dataset in our example.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">sklearn</span> <span class=\"kn\">import</span> <span class=\"n\">datasets</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.tree</span> <span class=\"kn\">import</span> <span class=\"n\">DecisionTreeClassifier</span>\n\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">load_iris</span><span class=\"p\">()</span>\n<span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">X_test</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">y_test</span> <span class=\"o\">=</span> <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">target</span><span class=\"p\">,</span> <span class=\"n\">test_size</span><span class=\"o\">=</span><span class=\"mf\">0.2</span><span class=\"p\">)</span>\n\n<span class=\"n\">base_est</span> <span class=\"o\">=</span> <span class=\"n\">DecisionTreeClassifier</span><span class=\"p\">()</span>\n<span class=\"n\">base_est</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">)</span>\n</pre>\n<p>Now create the <tt>GeneralizeToRepresentative</tt> transformer and train it. Supply it with the original model and the desired target accuracy. The training process may receive the original labeled training data or the model\u2019s predictions on the data.</p>\n<pre><span class=\"n\">predictions</span> <span class=\"o\">=</span> <span class=\"n\">base_est</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">X_train</span><span class=\"p\">)</span>\n<span class=\"n\">gen</span> <span class=\"o\">=</span> <span class=\"n\">GeneralizeToRepresentative</span><span class=\"p\">(</span><span class=\"n\">base_est</span><span class=\"p\">,</span> <span class=\"n\">target_accuracy</span><span class=\"o\">=</span><span class=\"mf\">0.9</span><span class=\"p\">)</span>\n<span class=\"n\">gen</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">predictions</span><span class=\"p\">)</span>\n</pre>\n<p>Now use the transformer to transform new data, for example the test data.</p>\n<pre><span class=\"n\">transformed</span> <span class=\"o\">=</span> <span class=\"n\">gen</span><span class=\"o\">.</span><span class=\"n\">transform</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"p\">)</span>\n</pre>\n<p>The transformed data has the same columns and formats as the original data, so it can be used directly to derive predictions from the original model.</p>\n<pre><span class=\"n\">new_predictions</span> <span class=\"o\">=</span> <span class=\"n\">base_est</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">transformed</span><span class=\"p\">)</span>\n</pre>\n<p>To export the resulting generalizations, retrieve the <tt>Transformer</tt>\u2019s <tt>_generalize</tt> parameter.</p>\n<pre><span class=\"n\">generalizations</span> <span class=\"o\">=</span> <span class=\"n\">base_est</span><span class=\"o\">.</span><span class=\"n\">_generalize</span>\n</pre>\n<p>The returned object has the following structure:</p>\n<pre>{\n  ranges:\n  {\n    list of (&lt;feature name&gt;: [&lt;list of values&gt;])\n  },\n  untouched: [&lt;list of feature names&gt;]\n}\n</pre>\n<p>For example:</p>\n<pre>{\n  ranges:\n  {\n    age: [21.5, 39.0, 51.0, 70.5],\n    education-years: [8.0, 12.0, 14.5]\n  },\n  untouched: [\"occupation\", \"marital-status\"]\n}\n</pre>\n<p>Where each value inside the range list represents a cutoff point. For example, for the <tt>age</tt> feature, the ranges in this example are: <tt>&lt;21.5, <span class=\"pre\">21.5-39.0,</span> <span class=\"pre\">39.0-51.0,</span> <span class=\"pre\">51.0-70.5,</span> &gt;70.5</tt>. The <tt>untouched</tt> list represents features that were not generalized, i.e., their values should remain unchanged.</p>\n</div>\n\n          </div>"}, "last_serial": 6644414, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "001b9fcf8cfdd3fcf039b7632d194e35", "sha256": "f57882a16ae5bb0050bb8ff6cf0183ce85494bc42bd33aa5a5cfae5f1b170f27"}, "downloads": -1, "filename": "ai_minimization_toolkit-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "001b9fcf8cfdd3fcf039b7632d194e35", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 12968, "upload_time": "2020-02-17T07:24:08", "upload_time_iso_8601": "2020-02-17T07:24:08.476711Z", "url": "https://files.pythonhosted.org/packages/9b/7a/33ad1ee462149be1a71748312502b723df58d9a5923b0a1d2c09e694447a/ai_minimization_toolkit-0.0.1-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "001b9fcf8cfdd3fcf039b7632d194e35", "sha256": "f57882a16ae5bb0050bb8ff6cf0183ce85494bc42bd33aa5a5cfae5f1b170f27"}, "downloads": -1, "filename": "ai_minimization_toolkit-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "001b9fcf8cfdd3fcf039b7632d194e35", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 12968, "upload_time": "2020-02-17T07:24:08", "upload_time_iso_8601": "2020-02-17T07:24:08.476711Z", "url": "https://files.pythonhosted.org/packages/9b/7a/33ad1ee462149be1a71748312502b723df58d9a5923b0a1d2c09e694447a/ai_minimization_toolkit-0.0.1-py3-none-any.whl", "yanked": false}], "timestamp": "Thu May  7 16:21:55 2020"}