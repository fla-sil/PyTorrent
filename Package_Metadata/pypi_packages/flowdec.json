{"info": {"author": "Eric Czech", "author_email": "eric@hammerlab.org", "bugtrack_url": null, "classifiers": ["Environment :: Console", "Intended Audience :: Science/Research", "License :: OSI Approved :: Apache Software License", "Operating System :: OS Independent", "Programming Language :: Python :: 3.6", "Topic :: Scientific/Engineering :: Bio-Informatics"], "description": "[![Build Status](https://travis-ci.org/hammerlab/flowdec.svg?branch=master)](https://travis-ci.org/hammerlab/flowdec)\n\n# Flowdec\n\n**Flowdec** is a library containing [TensorFlow](https://github.com/tensorflow/tensorflow) (TF) implementations of image and signal deconvolution algorithms.  Currently, only [Richardson-Lucy Deconvolution](https://en.wikipedia.org/wiki/Richardson%E2%80%93Lucy_deconvolution) has been implemented but others may come in the future.\n\nFlowdec is designed to construct and execute TF graphs in python as well as use frozen, exported graphs from other languages (e.g. Java).\n\nHere are a few other features, advantages, and disadvantages of the project currently:\n\n*Highlights*\n\n- **Support for Windows, Mac, and Linux** - Because TensorFlow can run on these platforms, so can Flowdec.\n- **Client Support for Java, Go, C++, and Python** - Using Flowdec graphs from Python and Java has been tested, but theoretically they could also be used by any [TensorFlow API Client Libraries](https://www.tensorflow.org/api_docs/).\n- **Point Spread Functions** - PSFs can be defined as json configuration files to be generated dynamically during the deconvolution process using a [Fast Gibson-Lanni Approximation Model](http://www.ee.cuhk.edu.hk/~jzli/MicroscPSF/) (which can also create Born & Wolf kernels as a degenerate case).\n- **GPU Accleration** - Executing [TensorFlow graphs on GPUs](https://www.tensorflow.org/programmers_guide/using_gpu) is trivial and will happen by default w/ Flowdec if you meet all of the TensorFlow requirements for this (i.e. CUDA Toolkit installed, Nvidia drivers, etc.).\n- **Performance** - There are other open source and commercial deconvolution libraries that run with *partial* GPU acceleration, which generally means that only FFT and iFFT operations run on GPUs while all other operations run on the CPU. For example, on a roughly 1000x1000x11 3D volume with a PSF of the same dimensions this means that execution times look like:\n    - CPU-only solutions: **10 minutes**\n    - Other solutions with FFT/iFFT GPU acceleration: **~40 seconds**\n    - Flowdec/TensorFlow with full GPU acceleration: **~1 second**\n- **Signal Dimensions** - Flowdec can support 1, 2, or 3 dimensional images/signals.\n- **Multi-GPU Usage** - This has yet to be tested, but theoretically this is possible since TF can do it (and this [Multi-GPU Example](java/flowdec/src/main/java/org/hammerlab/flowdec/examples/MultiGPUExample.java) is a start).\n- **Image Preprocessing** - A trickier part of deconvolution implementations is dealing with image padding and cropping necessary to use faster FFT implementations -- in Flowdec, image padding using the reflection of the image along each axis can be specified manually or by letting it automatically round up and pad to the nearest power of 2 (which will enable use of faster Cooley-Tukey algorithm instead of the Bluestein algorithm provided by Nvidia cuFFT used by TF).\n- **Visualizing Iterations** - Another difficulty with iterative deconvolution algorithms is in determining when they should stop.  With Richardson Lucy, this is usually done somewhat subjectively based on visualizing results for different iteration counts and Flowdec at least helps with this by letting ```observer``` functions be given that take intermediate results of the deconvolution process to be written out to image sequences or stacks for manual inspection.  Future work may include using [Tensorboard](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard) to do this instead but for now, it has been difficult to get image summaries working within TF \"while\" loops.\n\n*Disadvantages*\n\n- **No GUIs** - Flowdec is intended for use by those familiar with programming but some future work might include an ImageJ plugin (if there's interest in that).  For those looking for something more interactive, [imagej-ops](https://github.com/imagej/imagej-ops) is likely your best bet which currently supports the same PSF generation model used in Flowdec as well as Richardson Lucy deconvolution.  At the moment it doesn't include full GPU acceleration but that may be on the way as part of [imagej-ops-experiments](https://github.com/imagej/ops-experiments).  See this [github issue](https://github.com/hadim/DeconvolutionLab2/issues/1) for more details.\n- **No Blind Deconvolution** - Currently, nothing in this arena has been attempted but since much recent research on this subject is centered around solutions in deep learning, TensorFlow will hopefully make for a good platform in the future.\n\n## Basic Usage\n\nHere is a basic example demonstrating how Flowdec can be used in a single 3D image deconvolution:\n\n*See full example notebook [here](python/examples/notebooks/Neuron%20-%203D%20Deconvolution.ipynb)*\n\n```python\n%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage import exposure\nfrom scipy import ndimage, signal\nfrom flowdec import data as fd_data\nfrom flowdec import restoration as fd_restoration\n\n# Load \"Purkinje Neuron\" dataset downsampled from 200x1024x1024 to 50x256x256\n# See: http://www.cellimagelibrary.org/images/CCDB_2\nactual = fd_data.neuron_25pct().data\n# actual.shape = (50, 256, 256)\n\n# Create a gaussian kernel that will be used to blur the original acquisition\nkernel = np.zeros_like(actual)\nfor offset in [0, 1]:\n    kernel[tuple((np.array(kernel.shape) - offset) // 2)] = 1\nkernel = ndimage.gaussian_filter(kernel, sigma=1.)\n# kernel.shape = (50, 256, 256)\n\n# Convolve the original image with our fake PSF\ndata = signal.fftconvolve(actual, kernel, mode='same')\n# data.shape = (50, 256, 256)\n\n# Run the deconvolution process and note that deconvolution initialization is best kept separate from \n# execution since the \"initialize\" operation corresponds to creating a TensorFlow graph, which is a \n# relatively expensive operation and should not be repeated across multiple executions\nalgo = fd_restoration.RichardsonLucyDeconvolver(data.ndim).initialize()\nres = algo.run(fd_data.Acquisition(data=data, kernel=kernel), niter=30).data\n\nfig, axs = plt.subplots(1, 3)\naxs = axs.ravel()\nfig.set_size_inches(18, 12)\ncenter = tuple([slice(None), slice(10, -10), slice(10, -10)])\ntitles = ['Original Image', 'Blurred Image', 'Reconstructed Image']\nfor i, d in enumerate([actual, data, res]):\n    img = exposure.adjust_gamma(d[center].max(axis=0), gamma=.2)\n    axs[i].imshow(img, cmap='Spectral_r')\n    axs[i].set_title(titles[i])\n    axs[i].axis('off')\n```\n\n![Neuron Example](docs/images/neuron.png \"Neuron Results\")\n\n\nAs a more realistic use case, here is an example showing how a point spread function configuration can be used in a headless deconvolution:\n\n*See full deconvolution script [here](python/flowdec/cmd/deconvolution.py)*\n\n```bash\n# Generate a configuration file containing PSF parameters (see flowdec.psf module for more details)\necho '{\"na\": 0.75, \"wavelength\": 0.425, \"size_z\": 32, \"size_x\": 64, \"size_y\": 64}' > /tmp/psf.json\n\n# Invoke deconvolution script with the above PSF configuration and an input dataset to deconvolve.\n# If flowdec has been installed, you may run the \u201cdeconvolution\u201d command.\npython examples/scripts/deconvolution.py \\\n--data-path=flowdec/datasets/bars-25pct/data.tif \\\n--psf-config-path=/tmp/psf.json \\\n--output-path=/tmp/result.tif \\\n--n-iter=25 --log-level=DEBUG\n> DEBUG:Loaded data with shape (32, 64, 64) and psf with shape (32, 64, 64)\n> INFO:Beginning deconvolution of data file \"flowdec/datasets/bars-25pct/data.tif\"\n> INFO:Deconvolution complete (in 7.427 seconds)\n> INFO:Result saved to \"/tmp/result.tif\"\n```\n\n## Examples\n\n### Python \n\n- [Neuron](python/examples/notebooks/Neuron%20-%203D%20Deconvolution.ipynb) - Deconvolution of a natural 3D image with synthetic point spread function\n- [C. Elegans](python/examples/notebooks/CElegans%20-%20Multiple%20Channel%20Example.ipynb) - Deconvolution of 712x672x104 acquisition for 3 separate channels\n- [Astronaut](python/examples/notebooks/Astronaut%20-%20Ringing%20Artifacts.ipynb) - Dealing with artifacts in deconvolved images\n- [Monitoring Iterations](python/examples/notebooks/Monitoring%20Iterations.ipynb) - Tracking deconvolution progress by visualizing results at each iteration\n- [Hollow Bars](python/examples/notebooks/Hollow%20Bars%20-%20Synthetic%20Deconvolution.ipynb) - Deconvolution of downsampled 64x64x32 synthetic volume (as a CPU-friendly example)\n- [Hollow Bars GPU Benchmarking](python/examples/notebooks/Hollow%20Bars%20-%20Benchmarking.ipynb) - Testing running times on full 256x256x128 volume with GPU-enabled system\n- [DeconvolutionLab2 Comparison](python/examples/notebooks/DeconvolutionLab2%20-%20Benchmarking.ipynb) - Comparing execution times between [DeconvolutionLab2](http://bigwww.epfl.ch/deconvolution/deconvolutionlab2/) and Flowdec\n- [Graph Export](python/examples/notebooks/Algorithm%20Graph%20Export.ipynb) - Defining and exporting TensorFlow graphs\n- [Command Line Interface](python/flowdec/cmd/deconvolution.py) - CLI for executing single deconvolutions with either a pre-defined or dynamically generated point spread function\n\n### Java\n\n- [Multi-GPU Example](java/flowdec/src/main/java/org/hammerlab/flowdec/examples/MultiGPUExample.java) - Prototype example for how to be able to execute deconvolution against multiple GPUs in parallel (not tested yet -- waiting for the use case to come up though it is very likely possible to do)\n\n## Installation\n\nThe project can be installed, ideally in a python 3.6 environment (though it should work in 3.5 too), by running:\n\n```bash\npip install flowdec[tf_gpu]\n```\n\nThe previous command will install `flowdec`, but also ensure that `tensorflow`\nis installed with GPU support.  For test purposes, you may have the non-GPU\nenabled version of `tensorflow` installed by running:\n\n```bash\npip install flowdec[tf]\n```\n\nIf neither `[tf]` nor `[tf_gpu]` are specified, tensorflow installation is left\nas an externally managed prerequisite.\n\nAlternatively, the project could be installed from source by doing the following:\n\n```bash\ngit clone https://github.com/hammerlab/flowdec.git\ncd flowdec/python\npip install -e .\n``` \n\n### Docker Instructions\n\nA local docker image can be built by running:\n\n```bash\ncd flowdec  # Note: not flowdec/docker, just cd flowdec\n\ndocker build --no-cache -t flowdec -f docker/Dockerfile .\n\n# If on a system that supports nvidia-docker, the GPU-enabled version can be built instead via:\n# nvidia-docker build --no-cache -t flowdec -f docker/Dockerfile.gpu .\n```\n\nThe image can then be run using:\n\n```bash\n# Run in foreground (port mapping is host:container if 8888 is already taken)\ndocker run -ti -p 8888:8888 flowdec\n\n# Run in background\ndocker run -td -p 8888:8888 --name flowdec flowdec\ndocker exec -it flowdec /bin/bash # Connect \n```\n\nThe Flowdec dockerfile extends the [TensorFlow DockerHub Images](https://hub.docker.com/r/tensorflow/tensorflow/) so its usage is similar where running it in the foreground automatically starts jupyter notebook and prints a link to connect to it via a browser on the host system.\n\nThe previous image is built from the current master branch\nof github.com/hammerlab/flowdec.git.  To build an image using\nyour local copy of the source instead, you can use this command:\n\n```bash\ndocker build --no-cache -t flowdec -f docker/Dockerfile.devel .\n```\n\nYou may want to combine this with a bind mount of your local source tree into\nthe running container.  This setup will let you make edits to the source and\nhave them immediately take effect in the running container.\n\n```bash\nLOCAL_SRC=$(pwd)\nDEST_SRC=/repos/flowdec\n\ndocker run -ti -p 8888:8888 -v ${LOCAL_SRC}:${DEST_SRC} flowdec\n```\n\n## Validation\n\nBy in large, the purpose of this project is to attain near equivalence with a subset of the functionality provided by both [DeconvolutionLab2](http://bigwww.epfl.ch/deconvolution/deconvolutionlab2/) and [PSFGenerator](http://bigwww.epfl.ch/algorithms/psfgenerator/) via much faster implementations.\n\nTo validate this much has been accomplished, there are two notebooks in the [python/validation](python/validation) folder demonstrating the following:\n\n- [Deconvolution Validation](python/validation/deconvolution/validation.ipynb) - This notebook aggregates results from Flowdec and DeconvolutionLab2 applied to several reference datasets and verifies that deconvolved volumes are very nearly identical\n- [PSF Generation Validation](python/validation/psfgeneration/validation.ipynb) - This notebook aggregates results from Flowdec and PSFGenerator used to generate PSFs from a variety of different configurations and evaluates their similarity (which is also very high)\n\n## Acknowledgements\n\nThanks to Kyle Douglass for explaining some of the finer aspects of this Python [Gibson-Lanni PSF generator](http://kmdouglass.github.io/posts/implementing-a-fast-gibson-lanni-psf-solver-in-python.html), Jizhou Li for helping to better understand that diffraction model, Hadrien Mary for giving great context on the state of open-source deconvolution libraries, and Brian Northan for lending great advice/context on library performance, blind deconvolution and how point spread functions work in general.\n\n## Citation\n\nTo cite Flowdec, please use this reference:\n\n```\n@article {Czech460980,\n\tauthor = {Czech, Eric and Aksoy, Bulent Arman and Aksoy, Pinar and Hammerbacher, Jeff},\n\ttitle = {Cytokit: A single-cell analysis toolkit for high dimensional fluorescent microscopy imaging},\n\telocation-id = {460980},\n\tyear = {2018},\n\tdoi = {10.1101/460980},\n\tpublisher = {Cold Spring Harbor Laboratory},\n\tURL = {https://www.biorxiv.org/content/early/2018/12/14/460980},\n\teprint = {https://www.biorxiv.org/content/early/2018/12/14/460980.full.pdf},\n\tjournal = {bioRxiv}\n}\n```\n\n## References\n\n- [1] D. Sage, L. Donati, F. Soulez, D. Fortun, G. Schmit, A. Seitz, R. Guiet, C. Vonesch, M. Unser<br>\n    DeconvolutionLab2: An Open-Source Software for Deconvolution Microscopy<br>\n    Methods - Image Processing for Biologists, 115, 2017.<br>\n- [2] J. Li, F. Xue and T. Blu<br>\n    Fast and accurate three-dimensional point spread function computation for fluorescence microscopy<br>\n    J. Opt. Soc. Am. A, vol. 34, no. 6, pp. 1029-1034, 2017.<br>\n- [3] Brandner, D. and Withers, G.<br>\n    The Cell Image Library, CIL: 10106, 10107, and 10108.<br>\n    Available at http://www.cellimagelibrary.org. Accessed December 08, 2010.<br>\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/hammerlab/flowdec", "keywords": "", "license": "http://www.apache.org/licenses/LICENSE-2.0.html", "maintainer": "", "maintainer_email": "", "name": "flowdec", "package_url": "https://pypi.org/project/flowdec/", "platform": "", "project_url": "https://pypi.org/project/flowdec/", "project_urls": {"Homepage": "https://github.com/hammerlab/flowdec"}, "release_url": "https://pypi.org/project/flowdec/1.1.0/", "requires_dist": ["scikit-image (>=0.16.1)", "matplotlib", "requests", "tensorflow (>=1.14.0) ; extra == 'tf'", "tensorflow-gpu (>=1.14.0) ; extra == 'tf_gpu'"], "requires_python": "", "summary": "TensorFlow Implementations of Signal Deconvolution Algorithms", "version": "1.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://travis-ci.org/hammerlab/flowdec\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/57546c627ca8866aa8ad168e84a71b7dba85397a/68747470733a2f2f7472617669732d63692e6f72672f68616d6d65726c61622f666c6f776465632e7376673f6272616e63683d6d6173746572\"></a></p>\n<h1>Flowdec</h1>\n<p><strong>Flowdec</strong> is a library containing <a href=\"https://github.com/tensorflow/tensorflow\" rel=\"nofollow\">TensorFlow</a> (TF) implementations of image and signal deconvolution algorithms.  Currently, only <a href=\"https://en.wikipedia.org/wiki/Richardson%E2%80%93Lucy_deconvolution\" rel=\"nofollow\">Richardson-Lucy Deconvolution</a> has been implemented but others may come in the future.</p>\n<p>Flowdec is designed to construct and execute TF graphs in python as well as use frozen, exported graphs from other languages (e.g. Java).</p>\n<p>Here are a few other features, advantages, and disadvantages of the project currently:</p>\n<p><em>Highlights</em></p>\n<ul>\n<li><strong>Support for Windows, Mac, and Linux</strong> - Because TensorFlow can run on these platforms, so can Flowdec.</li>\n<li><strong>Client Support for Java, Go, C++, and Python</strong> - Using Flowdec graphs from Python and Java has been tested, but theoretically they could also be used by any <a href=\"https://www.tensorflow.org/api_docs/\" rel=\"nofollow\">TensorFlow API Client Libraries</a>.</li>\n<li><strong>Point Spread Functions</strong> - PSFs can be defined as json configuration files to be generated dynamically during the deconvolution process using a <a href=\"http://www.ee.cuhk.edu.hk/%7Ejzli/MicroscPSF/\" rel=\"nofollow\">Fast Gibson-Lanni Approximation Model</a> (which can also create Born &amp; Wolf kernels as a degenerate case).</li>\n<li><strong>GPU Accleration</strong> - Executing <a href=\"https://www.tensorflow.org/programmers_guide/using_gpu\" rel=\"nofollow\">TensorFlow graphs on GPUs</a> is trivial and will happen by default w/ Flowdec if you meet all of the TensorFlow requirements for this (i.e. CUDA Toolkit installed, Nvidia drivers, etc.).</li>\n<li><strong>Performance</strong> - There are other open source and commercial deconvolution libraries that run with <em>partial</em> GPU acceleration, which generally means that only FFT and iFFT operations run on GPUs while all other operations run on the CPU. For example, on a roughly 1000x1000x11 3D volume with a PSF of the same dimensions this means that execution times look like:\n<ul>\n<li>CPU-only solutions: <strong>10 minutes</strong></li>\n<li>Other solutions with FFT/iFFT GPU acceleration: <strong>~40 seconds</strong></li>\n<li>Flowdec/TensorFlow with full GPU acceleration: <strong>~1 second</strong></li>\n</ul>\n</li>\n<li><strong>Signal Dimensions</strong> - Flowdec can support 1, 2, or 3 dimensional images/signals.</li>\n<li><strong>Multi-GPU Usage</strong> - This has yet to be tested, but theoretically this is possible since TF can do it (and this <a href=\"java/flowdec/src/main/java/org/hammerlab/flowdec/examples/MultiGPUExample.java\" rel=\"nofollow\">Multi-GPU Example</a> is a start).</li>\n<li><strong>Image Preprocessing</strong> - A trickier part of deconvolution implementations is dealing with image padding and cropping necessary to use faster FFT implementations -- in Flowdec, image padding using the reflection of the image along each axis can be specified manually or by letting it automatically round up and pad to the nearest power of 2 (which will enable use of faster Cooley-Tukey algorithm instead of the Bluestein algorithm provided by Nvidia cuFFT used by TF).</li>\n<li><strong>Visualizing Iterations</strong> - Another difficulty with iterative deconvolution algorithms is in determining when they should stop.  With Richardson Lucy, this is usually done somewhat subjectively based on visualizing results for different iteration counts and Flowdec at least helps with this by letting <code>observer</code> functions be given that take intermediate results of the deconvolution process to be written out to image sequences or stacks for manual inspection.  Future work may include using <a href=\"https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard\" rel=\"nofollow\">Tensorboard</a> to do this instead but for now, it has been difficult to get image summaries working within TF \"while\" loops.</li>\n</ul>\n<p><em>Disadvantages</em></p>\n<ul>\n<li><strong>No GUIs</strong> - Flowdec is intended for use by those familiar with programming but some future work might include an ImageJ plugin (if there's interest in that).  For those looking for something more interactive, <a href=\"https://github.com/imagej/imagej-ops\" rel=\"nofollow\">imagej-ops</a> is likely your best bet which currently supports the same PSF generation model used in Flowdec as well as Richardson Lucy deconvolution.  At the moment it doesn't include full GPU acceleration but that may be on the way as part of <a href=\"https://github.com/imagej/ops-experiments\" rel=\"nofollow\">imagej-ops-experiments</a>.  See this <a href=\"https://github.com/hadim/DeconvolutionLab2/issues/1\" rel=\"nofollow\">github issue</a> for more details.</li>\n<li><strong>No Blind Deconvolution</strong> - Currently, nothing in this arena has been attempted but since much recent research on this subject is centered around solutions in deep learning, TensorFlow will hopefully make for a good platform in the future.</li>\n</ul>\n<h2>Basic Usage</h2>\n<p>Here is a basic example demonstrating how Flowdec can be used in a single 3D image deconvolution:</p>\n<p><em>See full example notebook <a href=\"python/examples/notebooks/Neuron%20-%203D%20Deconvolution.ipynb\" rel=\"nofollow\">here</a></em></p>\n<pre><span class=\"o\">%</span><span class=\"n\">matplotlib</span> <span class=\"n\">inline</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">import</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"k\">as</span> <span class=\"nn\">plt</span>\n<span class=\"kn\">from</span> <span class=\"nn\">skimage</span> <span class=\"kn\">import</span> <span class=\"n\">exposure</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scipy</span> <span class=\"kn\">import</span> <span class=\"n\">ndimage</span><span class=\"p\">,</span> <span class=\"n\">signal</span>\n<span class=\"kn\">from</span> <span class=\"nn\">flowdec</span> <span class=\"kn\">import</span> <span class=\"n\">data</span> <span class=\"k\">as</span> <span class=\"n\">fd_data</span>\n<span class=\"kn\">from</span> <span class=\"nn\">flowdec</span> <span class=\"kn\">import</span> <span class=\"n\">restoration</span> <span class=\"k\">as</span> <span class=\"n\">fd_restoration</span>\n\n<span class=\"c1\"># Load \"Purkinje Neuron\" dataset downsampled from 200x1024x1024 to 50x256x256</span>\n<span class=\"c1\"># See: http://www.cellimagelibrary.org/images/CCDB_2</span>\n<span class=\"n\">actual</span> <span class=\"o\">=</span> <span class=\"n\">fd_data</span><span class=\"o\">.</span><span class=\"n\">neuron_25pct</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">data</span>\n<span class=\"c1\"># actual.shape = (50, 256, 256)</span>\n\n<span class=\"c1\"># Create a gaussian kernel that will be used to blur the original acquisition</span>\n<span class=\"n\">kernel</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">zeros_like</span><span class=\"p\">(</span><span class=\"n\">actual</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">offset</span> <span class=\"ow\">in</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">]:</span>\n    <span class=\"n\">kernel</span><span class=\"p\">[</span><span class=\"nb\">tuple</span><span class=\"p\">((</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">kernel</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">)</span> <span class=\"o\">-</span> <span class=\"n\">offset</span><span class=\"p\">)</span> <span class=\"o\">//</span> <span class=\"mi\">2</span><span class=\"p\">)]</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>\n<span class=\"n\">kernel</span> <span class=\"o\">=</span> <span class=\"n\">ndimage</span><span class=\"o\">.</span><span class=\"n\">gaussian_filter</span><span class=\"p\">(</span><span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"n\">sigma</span><span class=\"o\">=</span><span class=\"mf\">1.</span><span class=\"p\">)</span>\n<span class=\"c1\"># kernel.shape = (50, 256, 256)</span>\n\n<span class=\"c1\"># Convolve the original image with our fake PSF</span>\n<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">signal</span><span class=\"o\">.</span><span class=\"n\">fftconvolve</span><span class=\"p\">(</span><span class=\"n\">actual</span><span class=\"p\">,</span> <span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"n\">mode</span><span class=\"o\">=</span><span class=\"s1\">'same'</span><span class=\"p\">)</span>\n<span class=\"c1\"># data.shape = (50, 256, 256)</span>\n\n<span class=\"c1\"># Run the deconvolution process and note that deconvolution initialization is best kept separate from </span>\n<span class=\"c1\"># execution since the \"initialize\" operation corresponds to creating a TensorFlow graph, which is a </span>\n<span class=\"c1\"># relatively expensive operation and should not be repeated across multiple executions</span>\n<span class=\"n\">algo</span> <span class=\"o\">=</span> <span class=\"n\">fd_restoration</span><span class=\"o\">.</span><span class=\"n\">RichardsonLucyDeconvolver</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">ndim</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">initialize</span><span class=\"p\">()</span>\n<span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"n\">algo</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">fd_data</span><span class=\"o\">.</span><span class=\"n\">Acquisition</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"o\">=</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">kernel</span><span class=\"o\">=</span><span class=\"n\">kernel</span><span class=\"p\">),</span> <span class=\"n\">niter</span><span class=\"o\">=</span><span class=\"mi\">30</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">data</span>\n\n<span class=\"n\">fig</span><span class=\"p\">,</span> <span class=\"n\">axs</span> <span class=\"o\">=</span> <span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">subplots</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">)</span>\n<span class=\"n\">axs</span> <span class=\"o\">=</span> <span class=\"n\">axs</span><span class=\"o\">.</span><span class=\"n\">ravel</span><span class=\"p\">()</span>\n<span class=\"n\">fig</span><span class=\"o\">.</span><span class=\"n\">set_size_inches</span><span class=\"p\">(</span><span class=\"mi\">18</span><span class=\"p\">,</span> <span class=\"mi\">12</span><span class=\"p\">)</span>\n<span class=\"n\">center</span> <span class=\"o\">=</span> <span class=\"nb\">tuple</span><span class=\"p\">([</span><span class=\"nb\">slice</span><span class=\"p\">(</span><span class=\"kc\">None</span><span class=\"p\">),</span> <span class=\"nb\">slice</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"nb\">slice</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mi\">10</span><span class=\"p\">)])</span>\n<span class=\"n\">titles</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'Original Image'</span><span class=\"p\">,</span> <span class=\"s1\">'Blurred Image'</span><span class=\"p\">,</span> <span class=\"s1\">'Reconstructed Image'</span><span class=\"p\">]</span>\n<span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">d</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">([</span><span class=\"n\">actual</span><span class=\"p\">,</span> <span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">res</span><span class=\"p\">]):</span>\n    <span class=\"n\">img</span> <span class=\"o\">=</span> <span class=\"n\">exposure</span><span class=\"o\">.</span><span class=\"n\">adjust_gamma</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">[</span><span class=\"n\">center</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">),</span> <span class=\"n\">gamma</span><span class=\"o\">=.</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n    <span class=\"n\">axs</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">imshow</span><span class=\"p\">(</span><span class=\"n\">img</span><span class=\"p\">,</span> <span class=\"n\">cmap</span><span class=\"o\">=</span><span class=\"s1\">'Spectral_r'</span><span class=\"p\">)</span>\n    <span class=\"n\">axs</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">set_title</span><span class=\"p\">(</span><span class=\"n\">titles</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">])</span>\n    <span class=\"n\">axs</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"p\">(</span><span class=\"s1\">'off'</span><span class=\"p\">)</span>\n</pre>\n<p><img alt=\"Neuron Example\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f749d68190300fc4b31866d36b1dd02e708da561/646f63732f696d616765732f6e6575726f6e2e706e67\"></p>\n<p>As a more realistic use case, here is an example showing how a point spread function configuration can be used in a headless deconvolution:</p>\n<p><em>See full deconvolution script <a href=\"python/flowdec/cmd/deconvolution.py\" rel=\"nofollow\">here</a></em></p>\n<pre><span class=\"c1\"># Generate a configuration file containing PSF parameters (see flowdec.psf module for more details)</span>\n<span class=\"nb\">echo</span> <span class=\"s1\">'{\"na\": 0.75, \"wavelength\": 0.425, \"size_z\": 32, \"size_x\": 64, \"size_y\": 64}'</span> &gt; /tmp/psf.json\n\n<span class=\"c1\"># Invoke deconvolution script with the above PSF configuration and an input dataset to deconvolve.</span>\n<span class=\"c1\"># If flowdec has been installed, you may run the \u201cdeconvolution\u201d command.</span>\npython examples/scripts/deconvolution.py <span class=\"se\">\\</span>\n--data-path<span class=\"o\">=</span>flowdec/datasets/bars-25pct/data.tif <span class=\"se\">\\</span>\n--psf-config-path<span class=\"o\">=</span>/tmp/psf.json <span class=\"se\">\\</span>\n--output-path<span class=\"o\">=</span>/tmp/result.tif <span class=\"se\">\\</span>\n--n-iter<span class=\"o\">=</span><span class=\"m\">25</span> --log-level<span class=\"o\">=</span>DEBUG\n&gt; DEBUG:Loaded data with shape <span class=\"o\">(</span><span class=\"m\">32</span>, <span class=\"m\">64</span>, <span class=\"m\">64</span><span class=\"o\">)</span> and psf with shape <span class=\"o\">(</span><span class=\"m\">32</span>, <span class=\"m\">64</span>, <span class=\"m\">64</span><span class=\"o\">)</span>\n&gt; INFO:Beginning deconvolution of data file <span class=\"s2\">\"flowdec/datasets/bars-25pct/data.tif\"</span>\n&gt; INFO:Deconvolution <span class=\"nb\">complete</span> <span class=\"o\">(</span>in <span class=\"m\">7</span>.427 seconds<span class=\"o\">)</span>\n&gt; INFO:Result saved to <span class=\"s2\">\"/tmp/result.tif\"</span>\n</pre>\n<h2>Examples</h2>\n<h3>Python</h3>\n<ul>\n<li><a href=\"python/examples/notebooks/Neuron%20-%203D%20Deconvolution.ipynb\" rel=\"nofollow\">Neuron</a> - Deconvolution of a natural 3D image with synthetic point spread function</li>\n<li><a href=\"python/examples/notebooks/CElegans%20-%20Multiple%20Channel%20Example.ipynb\" rel=\"nofollow\">C. Elegans</a> - Deconvolution of 712x672x104 acquisition for 3 separate channels</li>\n<li><a href=\"python/examples/notebooks/Astronaut%20-%20Ringing%20Artifacts.ipynb\" rel=\"nofollow\">Astronaut</a> - Dealing with artifacts in deconvolved images</li>\n<li><a href=\"python/examples/notebooks/Monitoring%20Iterations.ipynb\" rel=\"nofollow\">Monitoring Iterations</a> - Tracking deconvolution progress by visualizing results at each iteration</li>\n<li><a href=\"python/examples/notebooks/Hollow%20Bars%20-%20Synthetic%20Deconvolution.ipynb\" rel=\"nofollow\">Hollow Bars</a> - Deconvolution of downsampled 64x64x32 synthetic volume (as a CPU-friendly example)</li>\n<li><a href=\"python/examples/notebooks/Hollow%20Bars%20-%20Benchmarking.ipynb\" rel=\"nofollow\">Hollow Bars GPU Benchmarking</a> - Testing running times on full 256x256x128 volume with GPU-enabled system</li>\n<li><a href=\"python/examples/notebooks/DeconvolutionLab2%20-%20Benchmarking.ipynb\" rel=\"nofollow\">DeconvolutionLab2 Comparison</a> - Comparing execution times between <a href=\"http://bigwww.epfl.ch/deconvolution/deconvolutionlab2/\" rel=\"nofollow\">DeconvolutionLab2</a> and Flowdec</li>\n<li><a href=\"python/examples/notebooks/Algorithm%20Graph%20Export.ipynb\" rel=\"nofollow\">Graph Export</a> - Defining and exporting TensorFlow graphs</li>\n<li><a href=\"python/flowdec/cmd/deconvolution.py\" rel=\"nofollow\">Command Line Interface</a> - CLI for executing single deconvolutions with either a pre-defined or dynamically generated point spread function</li>\n</ul>\n<h3>Java</h3>\n<ul>\n<li><a href=\"java/flowdec/src/main/java/org/hammerlab/flowdec/examples/MultiGPUExample.java\" rel=\"nofollow\">Multi-GPU Example</a> - Prototype example for how to be able to execute deconvolution against multiple GPUs in parallel (not tested yet -- waiting for the use case to come up though it is very likely possible to do)</li>\n</ul>\n<h2>Installation</h2>\n<p>The project can be installed, ideally in a python 3.6 environment (though it should work in 3.5 too), by running:</p>\n<pre>pip install flowdec<span class=\"o\">[</span>tf_gpu<span class=\"o\">]</span>\n</pre>\n<p>The previous command will install <code>flowdec</code>, but also ensure that <code>tensorflow</code>\nis installed with GPU support.  For test purposes, you may have the non-GPU\nenabled version of <code>tensorflow</code> installed by running:</p>\n<pre>pip install flowdec<span class=\"o\">[</span>tf<span class=\"o\">]</span>\n</pre>\n<p>If neither <code>[tf]</code> nor <code>[tf_gpu]</code> are specified, tensorflow installation is left\nas an externally managed prerequisite.</p>\n<p>Alternatively, the project could be installed from source by doing the following:</p>\n<pre>git clone https://github.com/hammerlab/flowdec.git\n<span class=\"nb\">cd</span> flowdec/python\npip install -e .\n</pre>\n<h3>Docker Instructions</h3>\n<p>A local docker image can be built by running:</p>\n<pre><span class=\"nb\">cd</span> flowdec  <span class=\"c1\"># Note: not flowdec/docker, just cd flowdec</span>\n\ndocker build --no-cache -t flowdec -f docker/Dockerfile .\n\n<span class=\"c1\"># If on a system that supports nvidia-docker, the GPU-enabled version can be built instead via:</span>\n<span class=\"c1\"># nvidia-docker build --no-cache -t flowdec -f docker/Dockerfile.gpu .</span>\n</pre>\n<p>The image can then be run using:</p>\n<pre><span class=\"c1\"># Run in foreground (port mapping is host:container if 8888 is already taken)</span>\ndocker run -ti -p <span class=\"m\">8888</span>:8888 flowdec\n\n<span class=\"c1\"># Run in background</span>\ndocker run -td -p <span class=\"m\">8888</span>:8888 --name flowdec flowdec\ndocker <span class=\"nb\">exec</span> -it flowdec /bin/bash <span class=\"c1\"># Connect </span>\n</pre>\n<p>The Flowdec dockerfile extends the <a href=\"https://hub.docker.com/r/tensorflow/tensorflow/\" rel=\"nofollow\">TensorFlow DockerHub Images</a> so its usage is similar where running it in the foreground automatically starts jupyter notebook and prints a link to connect to it via a browser on the host system.</p>\n<p>The previous image is built from the current master branch\nof github.com/hammerlab/flowdec.git.  To build an image using\nyour local copy of the source instead, you can use this command:</p>\n<pre>docker build --no-cache -t flowdec -f docker/Dockerfile.devel .\n</pre>\n<p>You may want to combine this with a bind mount of your local source tree into\nthe running container.  This setup will let you make edits to the source and\nhave them immediately take effect in the running container.</p>\n<pre><span class=\"nv\">LOCAL_SRC</span><span class=\"o\">=</span><span class=\"k\">$(</span><span class=\"nb\">pwd</span><span class=\"k\">)</span>\n<span class=\"nv\">DEST_SRC</span><span class=\"o\">=</span>/repos/flowdec\n\ndocker run -ti -p <span class=\"m\">8888</span>:8888 -v <span class=\"si\">${</span><span class=\"nv\">LOCAL_SRC</span><span class=\"si\">}</span>:<span class=\"si\">${</span><span class=\"nv\">DEST_SRC</span><span class=\"si\">}</span> flowdec\n</pre>\n<h2>Validation</h2>\n<p>By in large, the purpose of this project is to attain near equivalence with a subset of the functionality provided by both <a href=\"http://bigwww.epfl.ch/deconvolution/deconvolutionlab2/\" rel=\"nofollow\">DeconvolutionLab2</a> and <a href=\"http://bigwww.epfl.ch/algorithms/psfgenerator/\" rel=\"nofollow\">PSFGenerator</a> via much faster implementations.</p>\n<p>To validate this much has been accomplished, there are two notebooks in the <a href=\"python/validation\" rel=\"nofollow\">python/validation</a> folder demonstrating the following:</p>\n<ul>\n<li><a href=\"python/validation/deconvolution/validation.ipynb\" rel=\"nofollow\">Deconvolution Validation</a> - This notebook aggregates results from Flowdec and DeconvolutionLab2 applied to several reference datasets and verifies that deconvolved volumes are very nearly identical</li>\n<li><a href=\"python/validation/psfgeneration/validation.ipynb\" rel=\"nofollow\">PSF Generation Validation</a> - This notebook aggregates results from Flowdec and PSFGenerator used to generate PSFs from a variety of different configurations and evaluates their similarity (which is also very high)</li>\n</ul>\n<h2>Acknowledgements</h2>\n<p>Thanks to Kyle Douglass for explaining some of the finer aspects of this Python <a href=\"http://kmdouglass.github.io/posts/implementing-a-fast-gibson-lanni-psf-solver-in-python.html\" rel=\"nofollow\">Gibson-Lanni PSF generator</a>, Jizhou Li for helping to better understand that diffraction model, Hadrien Mary for giving great context on the state of open-source deconvolution libraries, and Brian Northan for lending great advice/context on library performance, blind deconvolution and how point spread functions work in general.</p>\n<h2>Citation</h2>\n<p>To cite Flowdec, please use this reference:</p>\n<pre><code>@article {Czech460980,\n\tauthor = {Czech, Eric and Aksoy, Bulent Arman and Aksoy, Pinar and Hammerbacher, Jeff},\n\ttitle = {Cytokit: A single-cell analysis toolkit for high dimensional fluorescent microscopy imaging},\n\telocation-id = {460980},\n\tyear = {2018},\n\tdoi = {10.1101/460980},\n\tpublisher = {Cold Spring Harbor Laboratory},\n\tURL = {https://www.biorxiv.org/content/early/2018/12/14/460980},\n\teprint = {https://www.biorxiv.org/content/early/2018/12/14/460980.full.pdf},\n\tjournal = {bioRxiv}\n}\n</code></pre>\n<h2>References</h2>\n<ul>\n<li>[1] D. Sage, L. Donati, F. Soulez, D. Fortun, G. Schmit, A. Seitz, R. Guiet, C. Vonesch, M. Unser<br>\nDeconvolutionLab2: An Open-Source Software for Deconvolution Microscopy<br>\nMethods - Image Processing for Biologists, 115, 2017.<br></li>\n<li>[2] J. Li, F. Xue and T. Blu<br>\nFast and accurate three-dimensional point spread function computation for fluorescence microscopy<br>\nJ. Opt. Soc. Am. A, vol. 34, no. 6, pp. 1029-1034, 2017.<br></li>\n<li>[3] Brandner, D. and Withers, G.<br>\nThe Cell Image Library, CIL: 10106, 10107, and 10108.<br>\nAvailable at <a href=\"http://www.cellimagelibrary.org\" rel=\"nofollow\">http://www.cellimagelibrary.org</a>. Accessed December 08, 2010.<br></li>\n</ul>\n\n          </div>"}, "last_serial": 6401942, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "6ad983a0e244733ace9d72bb7308e03d", "sha256": "e54d2cebdb8f72e759c045d394c097173d25bcdef8c33fcd32f8f46417ff7ae3"}, "downloads": -1, "filename": "flowdec-0.0.1.tar.gz", "has_sig": false, "md5_digest": "6ad983a0e244733ace9d72bb7308e03d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4232632, "upload_time": "2019-01-06T12:35:48", "upload_time_iso_8601": "2019-01-06T12:35:48.261215Z", "url": "https://files.pythonhosted.org/packages/e2/c1/c29ac7d1edcf72ef1cf09a8d6f7533ff058c87274683ca4245d29800ca51/flowdec-0.0.1.tar.gz", "yanked": false}], "1.0.7": [{"comment_text": "", "digests": {"md5": "e327a3647b31067cce33fc14d4f89ab4", "sha256": "c2fdde71d621fdf03df17bef905f9cee12bcc511415e911c5df8ab2bbd47f9e5"}, "downloads": -1, "filename": "flowdec-1.0.7.tar.gz", "has_sig": false, "md5_digest": "e327a3647b31067cce33fc14d4f89ab4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4238276, "upload_time": "2019-02-11T13:06:54", "upload_time_iso_8601": "2019-02-11T13:06:54.606106Z", "url": "https://files.pythonhosted.org/packages/8d/e2/e1b5c50f210ef7a59248b8836ab0be3ce8b2a3f9c9b6c8108a041e7f8923/flowdec-1.0.7.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "772472b39aab2214d10ebf7a218409f4", "sha256": "62c4f338848fcc0acfdda04ecd1c941542a7a235a69bc67109236bafb985c88a"}, "downloads": -1, "filename": "flowdec-1.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "772472b39aab2214d10ebf7a218409f4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4351353, "upload_time": "2020-01-06T11:42:49", "upload_time_iso_8601": "2020-01-06T11:42:49.704051Z", "url": "https://files.pythonhosted.org/packages/36/bf/2c6cd68b80da262c5d6456766ba872436ff49fee50a2408f38fa853e5ba2/flowdec-1.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9a8101b7f961734f775d8e384a498db8", "sha256": "cb4b7d325964f18d867aa57ad233794d297bd7bf42271e97331037bf204ec091"}, "downloads": -1, "filename": "flowdec-1.1.0.tar.gz", "has_sig": false, "md5_digest": "9a8101b7f961734f775d8e384a498db8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4270026, "upload_time": "2020-01-06T11:42:55", "upload_time_iso_8601": "2020-01-06T11:42:55.262253Z", "url": "https://files.pythonhosted.org/packages/60/54/f70faa47eeaa42527259f99c51b09326eb81afb0a11dac7c8814c604a8e2/flowdec-1.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "772472b39aab2214d10ebf7a218409f4", "sha256": "62c4f338848fcc0acfdda04ecd1c941542a7a235a69bc67109236bafb985c88a"}, "downloads": -1, "filename": "flowdec-1.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "772472b39aab2214d10ebf7a218409f4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4351353, "upload_time": "2020-01-06T11:42:49", "upload_time_iso_8601": "2020-01-06T11:42:49.704051Z", "url": "https://files.pythonhosted.org/packages/36/bf/2c6cd68b80da262c5d6456766ba872436ff49fee50a2408f38fa853e5ba2/flowdec-1.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9a8101b7f961734f775d8e384a498db8", "sha256": "cb4b7d325964f18d867aa57ad233794d297bd7bf42271e97331037bf204ec091"}, "downloads": -1, "filename": "flowdec-1.1.0.tar.gz", "has_sig": false, "md5_digest": "9a8101b7f961734f775d8e384a498db8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4270026, "upload_time": "2020-01-06T11:42:55", "upload_time_iso_8601": "2020-01-06T11:42:55.262253Z", "url": "https://files.pythonhosted.org/packages/60/54/f70faa47eeaa42527259f99c51b09326eb81afb0a11dac7c8814c604a8e2/flowdec-1.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 01:01:43 2020"}