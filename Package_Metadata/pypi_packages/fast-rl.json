{"info": {"author": "Josiah Laivins", "author_email": "jlaivins@uncc.edu", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "License :: OSI Approved :: Apache Software License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "[![Build Status](https://dev.azure.com/jokellum/jokellum/_apis/build/status/josiahls.fast-reinforcement-learning?branchName=master)](https://dev.azure.com/jokellum/jokellum/_build/latest?definitionId=1&branchName=master)\n[![pypi fasti_rl version](https://img.shields.io/pypi/v/fast_rl)](https://pypi.python.org/pypi/fast_rl)\n[![github_master version](https://img.shields.io/github/v/release/josiahls/fast-reinforcement-learning?include_prereleases)](https://github.com/josiahls/fast-reinforcement-learning/releases)\n\n# Fast_rl\nThis repo is not affiliated with Jeremy Howard or his course which can be found [here](https://www.fast.ai/about/).\nWe will be using components from the Fastai library for building and training our reinforcement learning (RL) \nagents.\n\nOur goal is for fast_rl to be make benchmarking easier, inference more efficient, and environment compatibility to be\nas decoupled as much as possible. This being version 1.0, we still have a lot of work to make RL training itself faster \nand more efficient. The goals for this repo can be seen in the [RoadMap](#roadmap).\n\n**An important note is that training can use up a lot of RAM. This will likely be resolved as more models are being added. Likely will be resolved by off loading to storage in the next few versions.**\n\nA simple example:\n```python\nfrom fast_rl.agents.dqn import create_dqn_model, dqn_learner\nfrom fast_rl.agents.dqn_models import *\nfrom fast_rl.core.agent_core import ExperienceReplay,  GreedyEpsilon\nfrom fast_rl.core.data_block import MDPDataBunch\nfrom fast_rl.core.metrics import RewardMetric, EpsilonMetric\n\nmemory = ExperienceReplay(memory_size=1000000, reduce_ram=True)\nexplore = GreedyEpsilon(epsilon_start=1, epsilon_end=0.1, decay=0.001)\ndata = MDPDataBunch.from_env('CartPole-v1', render='human', bs=64, add_valid=False)\nmodel = create_dqn_model(data=data, base_arch=FixedTargetDQNModule, lr=0.001, layers=[32,32])\nlearn = dqn_learner(data, model, memory=memory, exploration_method=explore, copy_over_frequency=300,\n                    callback_fns=[RewardMetric, EpsilonMetric])\nlearn.fit(450)\n```\n\nMore complex examples might involve running an RL agent multiple times, generating episode snapshots as gifs, grouping\nreward plots, and finally showing the best and worst runs in a single graph. \n```python\nfrom fastai.basic_data import DatasetType\nfrom fast_rl.agents.dqn import create_dqn_model, dqn_learner\nfrom fast_rl.agents.dqn_models import *\nfrom fast_rl.core.agent_core import ExperienceReplay, GreedyEpsilon\nfrom fast_rl.core.data_block import MDPDataBunch\nfrom fast_rl.core.metrics import RewardMetric, EpsilonMetric\nfrom fast_rl.core.train import GroupAgentInterpretation, AgentInterpretation\n\ngroup_interp = GroupAgentInterpretation()\nfor i in range(5):\n\tmemory = ExperienceReplay(memory_size=1000000, reduce_ram=True)\n\texplore = GreedyEpsilon(epsilon_start=1, epsilon_end=0.1, decay=0.001)\n\tdata = MDPDataBunch.from_env('CartPole-v1', render='human', bs=64, add_valid=False)\n\tmodel = create_dqn_model(data=data, base_arch=FixedTargetDQNModule, lr=0.001, layers=[32,32])\n\tlearn = dqn_learner(data, model, memory=memory, exploration_method=explore, copy_over_frequency=300,\n\t\t\t\t\t\tcallback_fns=[RewardMetric, EpsilonMetric])\n\tlearn.fit(450)\n\n\tinterp=AgentInterpretation(learn, ds_type=DatasetType.Train)\n\tinterp.plot_rewards(cumulative=True, per_episode=True, group_name='cartpole_experience_example')\n\tgroup_interp.add_interpretation(interp)\n\tgroup_interp.to_pickle(f'{learn.model.name.lower()}/', f'{learn.model.name.lower()}')\n\tfor g in interp.generate_gif(): g.write(f'{learn.model.name.lower()}')\ngroup_interp.plot_reward_bounds(per_episode=True, smooth_groups=10)\n```\nMore examples can be found in `docs_src` and the actual code being run for generating gifs can be found in `tests` in \neither `test_dqn.py` or `test_ddpg.py`.\n\nAs a note, here is a run down of existing RL frameworks:\n- [Intel Coach](https://github.com/NervanaSystems/coach) \n- [Tensor Force](https://github.com/tensorforce/tensorforce)\n- [OpenAI Baselines](https://github.com/openai/baselines)\n- [Tensorflow Agents](https://github.com/tensorflow/agents)\n- [KerasRL](https://github.com/keras-rl/keras-rl)\n\nHowever there are also frameworks in PyTorch:\n- [Horizon](https://github.com/facebookresearch/Horizon)\n- [DeepRL](https://github.com/ShangtongZhang/DeepRL)\n- [Spinning Up](https://spinningup.openai.com/en/latest/user/introduction.html)\n\n## Installation\n\n**fastai (semi-optional)**\\\n[Install Fastai](https://github.com/fastai/fastai/blob/master/README.md#installation)\nor if you are using Anaconda (which is a good idea to use Anaconda) you can do: \\\n`conda install -c pytorch -c fastai fastai`\n\n**fast_rl**\\\nFastai will be installed if it does not exist. If it does exist, the versioning should be repaired by the the setup.py.\n`pip install fastai`\n\n## Installation (Optional)\nOpenAI all gyms: \\\n`pip install gym[all]`\n\nMazes: \\\n`git clone https://github.com/MattChanTK/gym-maze.git` \\\n`cd gym-maze` \\\n`python setup.py install`\n\n\n## Installation Dev (Optional)\n`git clone https://github.com/josiahls/fast-reinforcement-learning.git` \\\n`cd fast-reinforcement-learning` \\\n`python setup.py install`\n\n## Installation Issues\nMany issues will likely fall under [fastai installation issues](https://github.com/fastai/fastai/blob/master/README.md#installation-issues).\n\nAny other issues are likely environment related. It is important to note that Python 3.7 is not being tested due to\nan issue with Pyglet and gym do not working. This issue will not stop you from training models, however this might impact using\nOpenAI environments. \n\n## RoadMap\n\n- [ ] **Working on** **1.0.0** Base version is completed with working model visualizations proving performance / expected failure. At \nthis point, all models should have guaranteed environments they should succeed in. \n- [ ] 1.1.0 **Working on**  More Traditional RL models\n    - [ ]  **Working on** Add PPO\n    - [ ]  **Working on** Add TRPO\n    - [ ] Add D4PG\n    - [ ] Add A2C\n    - [ ] Add A3C\n- [ ] 1.2.0 HRL models *Possibly might change version to 2.0 depending on SMDP issues*\n    - [ ] Add SMDP\n    - [ ] Add Goal oriented MDPs. Will Require a new \"Step\"\n    - [ ] Add FeUdal Network\n    - [ ] Add storage based DataBunch memory management. This can prevent RAM from being used up by episode image frames\n    that may or may not serve any use to the agent, but only for logging.\n- [ ] 1.3.0\n    - [ ] Add HAC\n    - [ ] Add MAXQ\n    - [ ] Add HIRO\n- [ ] 1.4.0\n    - [ ] Add h-DQN\n    - [ ] Add Modulated Policy Hierarchies\n    - [ ] Add Meta Learning Shared Hierarchies\n- [ ] 1.5.0\n    - [ ] Add STRategic Attentive Writer (STRAW)\n    - [ ] Add H-DRLN\n    - [ ] Add Abstract Markov Decision Process (AMDP)\n    - [ ] Add conda integration so that installation can be truly one step.\n- [ ] 1.6.0 HRL Options models *Possibly will already be implemented in a previous model*\n    - [ ] Options augmentation to DQN based models\n    - [ ] Options augmentation to actor critic models\n    - [ ] Options augmentation to async actor critic models\n- [ ] 1.8.0 HRL Skills\n    - [ ] Skills augmentation to DQN based models\n    - [ ] Skills augmentation to actor critic models\n    - [ ] Skills augmentation to async actor critic models\n- [ ] 1.9.0\n- [ ] 2.0.0 Add PyBullet Fetch Environments\n    - [ ] 2.0.0 Not part of this repo, however the envs need to subclass the OpenAI `gym.GoalEnv`\n    - [ ] 2.0.0 Add HER\n\n\n## Contribution\nFollowing fastai's guidelines would be desirable: [Guidelines](https://github.com/fastai/fastai/blob/master/README.md#contribution-guidelines)\n\nWhile we hope that model additions will be added smoothly. All models will only be dependent on `core.layers.py`.\nAs time goes on, the model architecture will overall improve (we are and while continue to be still figuring things out).\n\n\n## Style\nSince fastai uses a different style from traditional PEP-8, we will be following [Style](https://docs.fast.ai/dev/style.html) \nand [Abbreviations](https://docs.fast.ai/dev/abbr.html). Also we will use RL specific abbr.\n\n|        | Concept | Abbr. | Combination Examples |\n|:------:|:-------:|:-----:|:--------------------:|\n| **RL** |  State  |  st   |                      |\n|        | Action  |  acn  |                      |\n|        | Bounds  |  bb   | Same as Bounding Box |\n\n## Examples\n\n### Reward Graphs\n\n|                                            |       Model     | \n|:------------------------------------------:|:---------------:|\n| ![01](./res/reward_plots/cartpole_dqn.png) |      DQN     |\n| ![01](./res/reward_plots/cartpole_dueling.png) |  Dueling DQN     |\n| ![01](./res/reward_plots/cartpole_double.png) |  Double DQN     |\n| ![01](./res/reward_plots/cartpole_dddqn.png) |    DDDQN     |\n| ![01](./res/reward_plots/cartpole_fixedtarget.png) |     Fixed Target DQN     |\n| ![01](./res/reward_plots/lunarlander_dqn.png) |      DQN     |\n| ![01](./res/reward_plots/lunarlander_dueling.png) |  Dueling DQN     |\n| ![01](./res/reward_plots/lunarlander_double.png) |  Double DQN     |\n| ![01](./res/reward_plots/lunarlander_dddqn.png) |    DDDQN     |\n| ![01](./res/reward_plots/lunarlander_fixedtarget.png) |     Fixed Target DQN     |\n| ![01](./res/reward_plots/ant_ddpg.png) |    DDPG    |\n| ![01](./res/reward_plots/pendulum_ddpg.png) |    DDPG    |\n| ![01](./res/reward_plots/halfcheetah_ddpg.png) |    DDPG    |\n\n\n### Agent Stages\n\n|      Model    |   Gif(Early)    |   Gif(Mid)    |   Gif(Late)     |\n|:------------:|:------------:|:------------:|:------------:|\n| DDPG+PER | ![](./res/run_gifs/pendulum_PriorityExperienceReplay_DDPGModule_1_episode_35.gif)  | ![](./res/run_gifs/pendulum_PriorityExperienceReplay_DDPGModule_1_episode_222.gif)  | ![](./res/run_gifs/pendulum_PriorityExperienceReplay_DDPGModule_1_episode_431.gif)|\n| DoubleDueling+ER | ![](./res/run_gifs/lunarlander_ExperienceReplay_DoubleDuelingModule_1_episode_114.gif)  | ![](./res/run_gifs/lunarlander_ExperienceReplay_DoubleDuelingModule_1_episode_346.gif)  | ![](./res/run_gifs/lunarlander_ExperienceReplay_DoubleDuelingModule_1_episode_925.gif)|\n| DoubleDQN+ER | ![](./res/run_gifs/lunarlander_ExperienceReplay_DoubleDQNModule_1_episode_88.gif)  | ![](./res/run_gifs/lunarlander_ExperienceReplay_DoubleDQNModule_1_episode_613.gif)  | ![](./res/run_gifs/lunarlander_ExperienceReplay_DoubleDQNModule_1_episode_999.gif)|\n| DuelingDQN+ER | ![](./res/run_gifs/lunarlander_ExperienceReplay_DuelingDQNModule_1_episode_112.gif)  | ![](./res/run_gifs/lunarlander_ExperienceReplay_DuelingDQNModule_1_episode_431.gif)  | ![](./res/run_gifs/lunarlander_ExperienceReplay_DuelingDQNModule_1_episode_980.gif)|\n| DoubleDueling+PER | ![](./res/run_gifs/lunarlander_PriorityExperienceReplay_DoubleDuelingModule_1_episode_151.gif)  | ![](./res/run_gifs/lunarlander_PriorityExperienceReplay_DoubleDuelingModule_1_episode_341.gif)  | ![](./res/run_gifs/lunarlander_PriorityExperienceReplay_DoubleDuelingModule_1_episode_999.gif)|\n| DQN+ER | ![](./res/run_gifs/lunarlander_ExperienceReplay_DQNModule_1_episode_93.gif)  | ![](./res/run_gifs/lunarlander_ExperienceReplay_DQNModule_1_episode_541.gif)  | ![](./res/run_gifs/lunarlander_ExperienceReplay_DQNModule_1_episode_999.gif)|\n| DuelingDQN+PER | ![](./res/run_gifs/lunarlander_PriorityExperienceReplay_DuelingDQNModule_1_episode_21.gif)  | ![](./res/run_gifs/lunarlander_PriorityExperienceReplay_DuelingDQNModule_1_episode_442.gif)  | ![](./res/run_gifs/lunarlander_PriorityExperienceReplay_DuelingDQNModule_1_episode_998.gif)|\n| DQN+PER | ![](./res/run_gifs/lunarlander_PriorityExperienceReplay_DQNModule_1_episode_99.gif)  | ![](./res/run_gifs/lunarlander_PriorityExperienceReplay_DQNModule_1_episode_382.gif)  | ![](./res/run_gifs/lunarlander_PriorityExperienceReplay_DQNModule_1_episode_949.gif)|\n| DoubleDQN+PER | ![](./res/run_gifs/lunarlander_PriorityExperienceReplay_DoubleDQNModule_1_episode_7.gif)  | ![](./res/run_gifs/lunarlander_PriorityExperienceReplay_DoubleDQNModule_1_episode_514.gif)  | ![](./res/run_gifs/lunarlander_PriorityExperienceReplay_DoubleDQNModule_1_episode_999.gif)|\n| DDPG+PER | ![](./res/run_gifs/ant_PriorityExperienceReplay_DDPGModule_1_episode_52.gif)  | ![](./res/run_gifs/ant_PriorityExperienceReplay_DDPGModule_1_episode_596.gif)  | ![](./res/run_gifs/ant_PriorityExperienceReplay_DDPGModule_1_episode_984.gif)|\n| DDPG+ER | ![](./res/run_gifs/ant_ExperienceReplay_DDPGModule_1_episode_54.gif)  | ![](./res/run_gifs/ant_ExperienceReplay_DDPGModule_1_episode_614.gif)  | ![](./res/run_gifs/ant_ExperienceReplay_DDPGModule_1_episode_999.gif)|\n| DQN+PER | ![](./res/run_gifs/cartpole_PriorityExperienceReplay_DQNModule_1_episode_44.gif)  | ![](./res/run_gifs/cartpole_PriorityExperienceReplay_DQNModule_1_episode_216.gif)  | ![](./res/run_gifs/cartpole_PriorityExperienceReplay_DQNModule_1_episode_413.gif)|\n| FixedTargetDQN+ER | ![](./res/run_gifs/cartpole_ExperienceReplay_FixedTargetDQNModule_1_episode_57.gif)  | ![](./res/run_gifs/cartpole_ExperienceReplay_FixedTargetDQNModule_1_episode_309.gif)  | ![](./res/run_gifs/cartpole_ExperienceReplay_FixedTargetDQNModule_1_episode_438.gif)|\n| DQN+ER | ![](./res/run_gifs/cartpole_ExperienceReplay_DQNModule_1_episode_31.gif)  | ![](./res/run_gifs/cartpole_ExperienceReplay_DQNModule_1_episode_207.gif)  | ![](./res/run_gifs/cartpole_ExperienceReplay_DQNModule_1_episode_447.gif)|\n| FixedTargetDQN+PER | ![](./res/run_gifs/cartpole_PriorityExperienceReplay_FixedTargetDQNModule_1_episode_13.gif)  | ![](./res/run_gifs/cartpole_PriorityExperienceReplay_FixedTargetDQNModule_1_episode_265.gif)  | ![](./res/run_gifs/cartpole_PriorityExperienceReplay_FixedTargetDQNModule_1_episode_449.gif)|\n| DoubleDQN+ER | ![](./res/run_gifs/cartpole_ExperienceReplay_DoubleDQNModule_1_episode_60.gif)  | ![](./res/run_gifs/cartpole_ExperienceReplay_DoubleDQNModule_1_episode_268.gif)  | ![](./res/run_gifs/cartpole_ExperienceReplay_DoubleDQNModule_1_episode_438.gif)|\n| DoubleDQN+PER | ![](./res/run_gifs/cartpole_PriorityExperienceReplay_DoubleDQNModule_1_episode_35.gif)  | ![](./res/run_gifs/cartpole_PriorityExperienceReplay_DoubleDQNModule_1_episode_269.gif)  | ![](./res/run_gifs/cartpole_PriorityExperienceReplay_DoubleDQNModule_1_episode_444.gif)|\n| DuelingDQN+ER | ![](./res/run_gifs/cartpole_ExperienceReplay_DuelingDQNModule_1_episode_62.gif)  | ![](./res/run_gifs/cartpole_ExperienceReplay_DuelingDQNModule_1_episode_209.gif)  | ![](./res/run_gifs/cartpole_ExperienceReplay_DuelingDQNModule_1_episode_432.gif)|\n| DoubleDueling+PER | ![](./res/run_gifs/cartpole_PriorityExperienceReplay_DoubleDuelingModule_1_episode_2.gif)  | ![](./res/run_gifs/cartpole_PriorityExperienceReplay_DoubleDuelingModule_1_episode_260.gif)  | ![](./res/run_gifs/cartpole_PriorityExperienceReplay_DoubleDuelingModule_1_episode_438.gif)|\n| DuelingDQN+PER | ![](./res/run_gifs/cartpole_PriorityExperienceReplay_DuelingDQNModule_1_episode_69.gif)  | ![](./res/run_gifs/cartpole_PriorityExperienceReplay_DuelingDQNModule_1_episode_272.gif)  | ![](./res/run_gifs/cartpole_PriorityExperienceReplay_DuelingDQNModule_1_episode_438.gif)|\n| DoubleDueling+ER | ![](./res/run_gifs/cartpole_ExperienceReplay_DoubleDuelingModule_1_episode_43.gif)  | ![](./res/run_gifs/cartpole_ExperienceReplay_DoubleDuelingModule_1_episode_287.gif)  | ![](./res/run_gifs/cartpole_ExperienceReplay_DoubleDuelingModule_1_episode_447.gif)|\n| DDPG+ER | ![](./res/run_gifs/acrobot_ExperienceReplay_DDPGModule_1_episode_69.gif)  | ![](./res/run_gifs/acrobot_ExperienceReplay_DDPGModule_1_episode_197.gif)  | ![](./res/run_gifs/acrobot_ExperienceReplay_DDPGModule_1_episode_438.gif)|\n| DDPG+PER | ![](./res/run_gifs/acrobot_PriorityExperienceReplay_DDPGModule_1_episode_55.gif)  | ![](./res/run_gifs/acrobot_PriorityExperienceReplay_DDPGModule_1_episode_267.gif)  | ![](./res/run_gifs/acrobot_PriorityExperienceReplay_DDPGModule_1_episode_422.gif)|\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/josiahls/fast-reinforcement-learning", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "fast-rl", "package_url": "https://pypi.org/project/fast-rl/", "platform": "", "project_url": "https://pypi.org/project/fast-rl/", "project_urls": {"Homepage": "https://github.com/josiahls/fast-reinforcement-learning"}, "release_url": "https://pypi.org/project/fast-rl/1.0.1/", "requires_dist": ["fastai (>=1.0.59)", "gym[atari,box2d]", "jupyter", "gym-minigrid ; extra == 'all'", "moviepy ; extra == 'all'"], "requires_python": ">=3.6", "summary": "Fastai for computer vision and tabular learning has been amazing. One would wish that this would be the same for RL. The purpose of this repo is to have a framework that is as easy as possible to start, but also designed for testing new agents.", "version": "1.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://dev.azure.com/jokellum/jokellum/_build/latest?definitionId=1&amp;branchName=master\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1eeeb955a343b8682e939d8c3c254b5f4fe45d9b/68747470733a2f2f6465762e617a7572652e636f6d2f6a6f6b656c6c756d2f6a6f6b656c6c756d2f5f617069732f6275696c642f7374617475732f6a6f736961686c732e666173742d7265696e666f7263656d656e742d6c6561726e696e673f6272616e63684e616d653d6d6173746572\"></a>\n<a href=\"https://pypi.python.org/pypi/fast_rl\" rel=\"nofollow\"><img alt=\"pypi fasti_rl version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4d2ec59f10d65d05af301b1192b78bd9c714a8f0/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f666173745f726c\"></a>\n<a href=\"https://github.com/josiahls/fast-reinforcement-learning/releases\" rel=\"nofollow\"><img alt=\"github_master version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/92ba25d2a73b309f011239c3e98c5b8a4a618cda/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f6a6f736961686c732f666173742d7265696e666f7263656d656e742d6c6561726e696e673f696e636c7564655f70726572656c6561736573\"></a></p>\n<h1>Fast_rl</h1>\n<p>This repo is not affiliated with Jeremy Howard or his course which can be found <a href=\"https://www.fast.ai/about/\" rel=\"nofollow\">here</a>.\nWe will be using components from the Fastai library for building and training our reinforcement learning (RL)\nagents.</p>\n<p>Our goal is for fast_rl to be make benchmarking easier, inference more efficient, and environment compatibility to be\nas decoupled as much as possible. This being version 1.0, we still have a lot of work to make RL training itself faster\nand more efficient. The goals for this repo can be seen in the <a href=\"#roadmap\" rel=\"nofollow\">RoadMap</a>.</p>\n<p><strong>An important note is that training can use up a lot of RAM. This will likely be resolved as more models are being added. Likely will be resolved by off loading to storage in the next few versions.</strong></p>\n<p>A simple example:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">fast_rl.agents.dqn</span> <span class=\"kn\">import</span> <span class=\"n\">create_dqn_model</span><span class=\"p\">,</span> <span class=\"n\">dqn_learner</span>\n<span class=\"kn\">from</span> <span class=\"nn\">fast_rl.agents.dqn_models</span> <span class=\"kn\">import</span> <span class=\"o\">*</span>\n<span class=\"kn\">from</span> <span class=\"nn\">fast_rl.core.agent_core</span> <span class=\"kn\">import</span> <span class=\"n\">ExperienceReplay</span><span class=\"p\">,</span>  <span class=\"n\">GreedyEpsilon</span>\n<span class=\"kn\">from</span> <span class=\"nn\">fast_rl.core.data_block</span> <span class=\"kn\">import</span> <span class=\"n\">MDPDataBunch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">fast_rl.core.metrics</span> <span class=\"kn\">import</span> <span class=\"n\">RewardMetric</span><span class=\"p\">,</span> <span class=\"n\">EpsilonMetric</span>\n\n<span class=\"n\">memory</span> <span class=\"o\">=</span> <span class=\"n\">ExperienceReplay</span><span class=\"p\">(</span><span class=\"n\">memory_size</span><span class=\"o\">=</span><span class=\"mi\">1000000</span><span class=\"p\">,</span> <span class=\"n\">reduce_ram</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"n\">explore</span> <span class=\"o\">=</span> <span class=\"n\">GreedyEpsilon</span><span class=\"p\">(</span><span class=\"n\">epsilon_start</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">epsilon_end</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">,</span> <span class=\"n\">decay</span><span class=\"o\">=</span><span class=\"mf\">0.001</span><span class=\"p\">)</span>\n<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">MDPDataBunch</span><span class=\"o\">.</span><span class=\"n\">from_env</span><span class=\"p\">(</span><span class=\"s1\">'CartPole-v1'</span><span class=\"p\">,</span> <span class=\"n\">render</span><span class=\"o\">=</span><span class=\"s1\">'human'</span><span class=\"p\">,</span> <span class=\"n\">bs</span><span class=\"o\">=</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">add_valid</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">create_dqn_model</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"o\">=</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">base_arch</span><span class=\"o\">=</span><span class=\"n\">FixedTargetDQNModule</span><span class=\"p\">,</span> <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">0.001</span><span class=\"p\">,</span> <span class=\"n\">layers</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">32</span><span class=\"p\">,</span><span class=\"mi\">32</span><span class=\"p\">])</span>\n<span class=\"n\">learn</span> <span class=\"o\">=</span> <span class=\"n\">dqn_learner</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">memory</span><span class=\"o\">=</span><span class=\"n\">memory</span><span class=\"p\">,</span> <span class=\"n\">exploration_method</span><span class=\"o\">=</span><span class=\"n\">explore</span><span class=\"p\">,</span> <span class=\"n\">copy_over_frequency</span><span class=\"o\">=</span><span class=\"mi\">300</span><span class=\"p\">,</span>\n                    <span class=\"n\">callback_fns</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">RewardMetric</span><span class=\"p\">,</span> <span class=\"n\">EpsilonMetric</span><span class=\"p\">])</span>\n<span class=\"n\">learn</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"mi\">450</span><span class=\"p\">)</span>\n</pre>\n<p>More complex examples might involve running an RL agent multiple times, generating episode snapshots as gifs, grouping\nreward plots, and finally showing the best and worst runs in a single graph.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">fastai.basic_data</span> <span class=\"kn\">import</span> <span class=\"n\">DatasetType</span>\n<span class=\"kn\">from</span> <span class=\"nn\">fast_rl.agents.dqn</span> <span class=\"kn\">import</span> <span class=\"n\">create_dqn_model</span><span class=\"p\">,</span> <span class=\"n\">dqn_learner</span>\n<span class=\"kn\">from</span> <span class=\"nn\">fast_rl.agents.dqn_models</span> <span class=\"kn\">import</span> <span class=\"o\">*</span>\n<span class=\"kn\">from</span> <span class=\"nn\">fast_rl.core.agent_core</span> <span class=\"kn\">import</span> <span class=\"n\">ExperienceReplay</span><span class=\"p\">,</span> <span class=\"n\">GreedyEpsilon</span>\n<span class=\"kn\">from</span> <span class=\"nn\">fast_rl.core.data_block</span> <span class=\"kn\">import</span> <span class=\"n\">MDPDataBunch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">fast_rl.core.metrics</span> <span class=\"kn\">import</span> <span class=\"n\">RewardMetric</span><span class=\"p\">,</span> <span class=\"n\">EpsilonMetric</span>\n<span class=\"kn\">from</span> <span class=\"nn\">fast_rl.core.train</span> <span class=\"kn\">import</span> <span class=\"n\">GroupAgentInterpretation</span><span class=\"p\">,</span> <span class=\"n\">AgentInterpretation</span>\n\n<span class=\"n\">group_interp</span> <span class=\"o\">=</span> <span class=\"n\">GroupAgentInterpretation</span><span class=\"p\">()</span>\n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">):</span>\n\t<span class=\"n\">memory</span> <span class=\"o\">=</span> <span class=\"n\">ExperienceReplay</span><span class=\"p\">(</span><span class=\"n\">memory_size</span><span class=\"o\">=</span><span class=\"mi\">1000000</span><span class=\"p\">,</span> <span class=\"n\">reduce_ram</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\t<span class=\"n\">explore</span> <span class=\"o\">=</span> <span class=\"n\">GreedyEpsilon</span><span class=\"p\">(</span><span class=\"n\">epsilon_start</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">epsilon_end</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">,</span> <span class=\"n\">decay</span><span class=\"o\">=</span><span class=\"mf\">0.001</span><span class=\"p\">)</span>\n\t<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">MDPDataBunch</span><span class=\"o\">.</span><span class=\"n\">from_env</span><span class=\"p\">(</span><span class=\"s1\">'CartPole-v1'</span><span class=\"p\">,</span> <span class=\"n\">render</span><span class=\"o\">=</span><span class=\"s1\">'human'</span><span class=\"p\">,</span> <span class=\"n\">bs</span><span class=\"o\">=</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">add_valid</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n\t<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">create_dqn_model</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"o\">=</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">base_arch</span><span class=\"o\">=</span><span class=\"n\">FixedTargetDQNModule</span><span class=\"p\">,</span> <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">0.001</span><span class=\"p\">,</span> <span class=\"n\">layers</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">32</span><span class=\"p\">,</span><span class=\"mi\">32</span><span class=\"p\">])</span>\n\t<span class=\"n\">learn</span> <span class=\"o\">=</span> <span class=\"n\">dqn_learner</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">memory</span><span class=\"o\">=</span><span class=\"n\">memory</span><span class=\"p\">,</span> <span class=\"n\">exploration_method</span><span class=\"o\">=</span><span class=\"n\">explore</span><span class=\"p\">,</span> <span class=\"n\">copy_over_frequency</span><span class=\"o\">=</span><span class=\"mi\">300</span><span class=\"p\">,</span>\n\t\t\t\t\t\t<span class=\"n\">callback_fns</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">RewardMetric</span><span class=\"p\">,</span> <span class=\"n\">EpsilonMetric</span><span class=\"p\">])</span>\n\t<span class=\"n\">learn</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"mi\">450</span><span class=\"p\">)</span>\n\n\t<span class=\"n\">interp</span><span class=\"o\">=</span><span class=\"n\">AgentInterpretation</span><span class=\"p\">(</span><span class=\"n\">learn</span><span class=\"p\">,</span> <span class=\"n\">ds_type</span><span class=\"o\">=</span><span class=\"n\">DatasetType</span><span class=\"o\">.</span><span class=\"n\">Train</span><span class=\"p\">)</span>\n\t<span class=\"n\">interp</span><span class=\"o\">.</span><span class=\"n\">plot_rewards</span><span class=\"p\">(</span><span class=\"n\">cumulative</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">per_episode</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">group_name</span><span class=\"o\">=</span><span class=\"s1\">'cartpole_experience_example'</span><span class=\"p\">)</span>\n\t<span class=\"n\">group_interp</span><span class=\"o\">.</span><span class=\"n\">add_interpretation</span><span class=\"p\">(</span><span class=\"n\">interp</span><span class=\"p\">)</span>\n\t<span class=\"n\">group_interp</span><span class=\"o\">.</span><span class=\"n\">to_pickle</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">'</span><span class=\"si\">{</span><span class=\"n\">learn</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"o\">.</span><span class=\"n\">lower</span><span class=\"p\">()</span><span class=\"si\">}</span><span class=\"s1\">/'</span><span class=\"p\">,</span> <span class=\"sa\">f</span><span class=\"s1\">'</span><span class=\"si\">{</span><span class=\"n\">learn</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"o\">.</span><span class=\"n\">lower</span><span class=\"p\">()</span><span class=\"si\">}</span><span class=\"s1\">'</span><span class=\"p\">)</span>\n\t<span class=\"k\">for</span> <span class=\"n\">g</span> <span class=\"ow\">in</span> <span class=\"n\">interp</span><span class=\"o\">.</span><span class=\"n\">generate_gif</span><span class=\"p\">():</span> <span class=\"n\">g</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">'</span><span class=\"si\">{</span><span class=\"n\">learn</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"o\">.</span><span class=\"n\">lower</span><span class=\"p\">()</span><span class=\"si\">}</span><span class=\"s1\">'</span><span class=\"p\">)</span>\n<span class=\"n\">group_interp</span><span class=\"o\">.</span><span class=\"n\">plot_reward_bounds</span><span class=\"p\">(</span><span class=\"n\">per_episode</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">smooth_groups</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n</pre>\n<p>More examples can be found in <code>docs_src</code> and the actual code being run for generating gifs can be found in <code>tests</code> in\neither <code>test_dqn.py</code> or <code>test_ddpg.py</code>.</p>\n<p>As a note, here is a run down of existing RL frameworks:</p>\n<ul>\n<li><a href=\"https://github.com/NervanaSystems/coach\" rel=\"nofollow\">Intel Coach</a></li>\n<li><a href=\"https://github.com/tensorforce/tensorforce\" rel=\"nofollow\">Tensor Force</a></li>\n<li><a href=\"https://github.com/openai/baselines\" rel=\"nofollow\">OpenAI Baselines</a></li>\n<li><a href=\"https://github.com/tensorflow/agents\" rel=\"nofollow\">Tensorflow Agents</a></li>\n<li><a href=\"https://github.com/keras-rl/keras-rl\" rel=\"nofollow\">KerasRL</a></li>\n</ul>\n<p>However there are also frameworks in PyTorch:</p>\n<ul>\n<li><a href=\"https://github.com/facebookresearch/Horizon\" rel=\"nofollow\">Horizon</a></li>\n<li><a href=\"https://github.com/ShangtongZhang/DeepRL\" rel=\"nofollow\">DeepRL</a></li>\n<li><a href=\"https://spinningup.openai.com/en/latest/user/introduction.html\" rel=\"nofollow\">Spinning Up</a></li>\n</ul>\n<h2>Installation</h2>\n<p><strong>fastai (semi-optional)</strong><br>\n<a href=\"https://github.com/fastai/fastai/blob/master/README.md#installation\" rel=\"nofollow\">Install Fastai</a>\nor if you are using Anaconda (which is a good idea to use Anaconda) you can do: <br>\n<code>conda install -c pytorch -c fastai fastai</code></p>\n<p><strong>fast_rl</strong><br>\nFastai will be installed if it does not exist. If it does exist, the versioning should be repaired by the the setup.py.\n<code>pip install fastai</code></p>\n<h2>Installation (Optional)</h2>\n<p>OpenAI all gyms: <br>\n<code>pip install gym[all]</code></p>\n<p>Mazes: <br>\n<code>git clone https://github.com/MattChanTK/gym-maze.git</code> <br>\n<code>cd gym-maze</code> <br>\n<code>python setup.py install</code></p>\n<h2>Installation Dev (Optional)</h2>\n<p><code>git clone https://github.com/josiahls/fast-reinforcement-learning.git</code> <br>\n<code>cd fast-reinforcement-learning</code> <br>\n<code>python setup.py install</code></p>\n<h2>Installation Issues</h2>\n<p>Many issues will likely fall under <a href=\"https://github.com/fastai/fastai/blob/master/README.md#installation-issues\" rel=\"nofollow\">fastai installation issues</a>.</p>\n<p>Any other issues are likely environment related. It is important to note that Python 3.7 is not being tested due to\nan issue with Pyglet and gym do not working. This issue will not stop you from training models, however this might impact using\nOpenAI environments.</p>\n<h2>RoadMap</h2>\n<ul>\n<li>[ ] <strong>Working on</strong> <strong>1.0.0</strong> Base version is completed with working model visualizations proving performance / expected failure. At\nthis point, all models should have guaranteed environments they should succeed in.</li>\n<li>[ ] 1.1.0 <strong>Working on</strong>  More Traditional RL models\n<ul>\n<li>[ ]  <strong>Working on</strong> Add PPO</li>\n<li>[ ]  <strong>Working on</strong> Add TRPO</li>\n<li>[ ] Add D4PG</li>\n<li>[ ] Add A2C</li>\n<li>[ ] Add A3C</li>\n</ul>\n</li>\n<li>[ ] 1.2.0 HRL models <em>Possibly might change version to 2.0 depending on SMDP issues</em>\n<ul>\n<li>[ ] Add SMDP</li>\n<li>[ ] Add Goal oriented MDPs. Will Require a new \"Step\"</li>\n<li>[ ] Add FeUdal Network</li>\n<li>[ ] Add storage based DataBunch memory management. This can prevent RAM from being used up by episode image frames\nthat may or may not serve any use to the agent, but only for logging.</li>\n</ul>\n</li>\n<li>[ ] 1.3.0\n<ul>\n<li>[ ] Add HAC</li>\n<li>[ ] Add MAXQ</li>\n<li>[ ] Add HIRO</li>\n</ul>\n</li>\n<li>[ ] 1.4.0\n<ul>\n<li>[ ] Add h-DQN</li>\n<li>[ ] Add Modulated Policy Hierarchies</li>\n<li>[ ] Add Meta Learning Shared Hierarchies</li>\n</ul>\n</li>\n<li>[ ] 1.5.0\n<ul>\n<li>[ ] Add STRategic Attentive Writer (STRAW)</li>\n<li>[ ] Add H-DRLN</li>\n<li>[ ] Add Abstract Markov Decision Process (AMDP)</li>\n<li>[ ] Add conda integration so that installation can be truly one step.</li>\n</ul>\n</li>\n<li>[ ] 1.6.0 HRL Options models <em>Possibly will already be implemented in a previous model</em>\n<ul>\n<li>[ ] Options augmentation to DQN based models</li>\n<li>[ ] Options augmentation to actor critic models</li>\n<li>[ ] Options augmentation to async actor critic models</li>\n</ul>\n</li>\n<li>[ ] 1.8.0 HRL Skills\n<ul>\n<li>[ ] Skills augmentation to DQN based models</li>\n<li>[ ] Skills augmentation to actor critic models</li>\n<li>[ ] Skills augmentation to async actor critic models</li>\n</ul>\n</li>\n<li>[ ] 1.9.0</li>\n<li>[ ] 2.0.0 Add PyBullet Fetch Environments\n<ul>\n<li>[ ] 2.0.0 Not part of this repo, however the envs need to subclass the OpenAI <code>gym.GoalEnv</code></li>\n<li>[ ] 2.0.0 Add HER</li>\n</ul>\n</li>\n</ul>\n<h2>Contribution</h2>\n<p>Following fastai's guidelines would be desirable: <a href=\"https://github.com/fastai/fastai/blob/master/README.md#contribution-guidelines\" rel=\"nofollow\">Guidelines</a></p>\n<p>While we hope that model additions will be added smoothly. All models will only be dependent on <code>core.layers.py</code>.\nAs time goes on, the model architecture will overall improve (we are and while continue to be still figuring things out).</p>\n<h2>Style</h2>\n<p>Since fastai uses a different style from traditional PEP-8, we will be following <a href=\"https://docs.fast.ai/dev/style.html\" rel=\"nofollow\">Style</a>\nand <a href=\"https://docs.fast.ai/dev/abbr.html\" rel=\"nofollow\">Abbreviations</a>. Also we will use RL specific abbr.</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"center\">Concept</th>\n<th align=\"center\">Abbr.</th>\n<th align=\"center\">Combination Examples</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\"><strong>RL</strong></td>\n<td align=\"center\">State</td>\n<td align=\"center\">st</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td align=\"center\"></td>\n<td align=\"center\">Action</td>\n<td align=\"center\">acn</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td align=\"center\"></td>\n<td align=\"center\">Bounds</td>\n<td align=\"center\">bb</td>\n<td align=\"center\">Same as Bounding Box</td>\n</tr></tbody></table>\n<h2>Examples</h2>\n<h3>Reward Graphs</h3>\n<table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"center\">Model</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\"><img alt=\"01\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b9f260538693ff4d9798f5832e273e5c916d60ab/2e2f7265732f7265776172645f706c6f74732f63617274706f6c655f64716e2e706e67\"></td>\n<td align=\"center\">DQN</td>\n</tr>\n<tr>\n<td align=\"center\"><img alt=\"01\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/88c9a31302a5541a0a6819584418efee0e677cf4/2e2f7265732f7265776172645f706c6f74732f63617274706f6c655f6475656c696e672e706e67\"></td>\n<td align=\"center\">Dueling DQN</td>\n</tr>\n<tr>\n<td align=\"center\"><img alt=\"01\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/78a6a8f29671ed27ded1ca66c68367e6f4154b2b/2e2f7265732f7265776172645f706c6f74732f63617274706f6c655f646f75626c652e706e67\"></td>\n<td align=\"center\">Double DQN</td>\n</tr>\n<tr>\n<td align=\"center\"><img alt=\"01\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/34c73bd2ab20e7879d881818341eae9f3da259e3/2e2f7265732f7265776172645f706c6f74732f63617274706f6c655f646464716e2e706e67\"></td>\n<td align=\"center\">DDDQN</td>\n</tr>\n<tr>\n<td align=\"center\"><img alt=\"01\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2999e987519e21056fde6584663fd964c54e18bb/2e2f7265732f7265776172645f706c6f74732f63617274706f6c655f66697865647461726765742e706e67\"></td>\n<td align=\"center\">Fixed Target DQN</td>\n</tr>\n<tr>\n<td align=\"center\"><img alt=\"01\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2c6227699b3ef4895505f21fa31f62d9b777f6c5/2e2f7265732f7265776172645f706c6f74732f6c756e61726c616e6465725f64716e2e706e67\"></td>\n<td align=\"center\">DQN</td>\n</tr>\n<tr>\n<td align=\"center\"><img alt=\"01\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b76e872918bcfed9cd327685d2526354cf2446bb/2e2f7265732f7265776172645f706c6f74732f6c756e61726c616e6465725f6475656c696e672e706e67\"></td>\n<td align=\"center\">Dueling DQN</td>\n</tr>\n<tr>\n<td align=\"center\"><img alt=\"01\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/11f6903ceced567851d8e18364dd433a99696b7d/2e2f7265732f7265776172645f706c6f74732f6c756e61726c616e6465725f646f75626c652e706e67\"></td>\n<td align=\"center\">Double DQN</td>\n</tr>\n<tr>\n<td align=\"center\"><img alt=\"01\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/eafd7b6a9eaa2d4066a6ddd36a3c0f0e02cd28d1/2e2f7265732f7265776172645f706c6f74732f6c756e61726c616e6465725f646464716e2e706e67\"></td>\n<td align=\"center\">DDDQN</td>\n</tr>\n<tr>\n<td align=\"center\"><img alt=\"01\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5554facdb055001a50ace694fabdd593c96b4ce2/2e2f7265732f7265776172645f706c6f74732f6c756e61726c616e6465725f66697865647461726765742e706e67\"></td>\n<td align=\"center\">Fixed Target DQN</td>\n</tr>\n<tr>\n<td align=\"center\"><img alt=\"01\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8112a6c5508373dd185b78ba1103196f6540c634/2e2f7265732f7265776172645f706c6f74732f616e745f646470672e706e67\"></td>\n<td align=\"center\">DDPG</td>\n</tr>\n<tr>\n<td align=\"center\"><img alt=\"01\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0c41aacc39895906c6538f76b51992ed59018421/2e2f7265732f7265776172645f706c6f74732f70656e64756c756d5f646470672e706e67\"></td>\n<td align=\"center\">DDPG</td>\n</tr>\n<tr>\n<td align=\"center\"><img alt=\"01\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/040b8a84ca1877b8dce1860edf03e9d874a982a2/2e2f7265732f7265776172645f706c6f74732f68616c66636865657461685f646470672e706e67\"></td>\n<td align=\"center\">DDPG</td>\n</tr></tbody></table>\n<h3>Agent Stages</h3>\n<table>\n<thead>\n<tr>\n<th align=\"center\">Model</th>\n<th align=\"center\">Gif(Early)</th>\n<th align=\"center\">Gif(Mid)</th>\n<th align=\"center\">Gif(Late)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">DDPG+PER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/970a2847e0ac3c590750c1af3df13ad91dbb0ec2/2e2f7265732f72756e5f676966732f70656e64756c756d5f5072696f72697479457870657269656e63655265706c61795f444450474d6f64756c655f315f657069736f64655f33352e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/05e9391360ca8f37c82b94963e511a244e72af49/2e2f7265732f72756e5f676966732f70656e64756c756d5f5072696f72697479457870657269656e63655265706c61795f444450474d6f64756c655f315f657069736f64655f3232322e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/58f5fda9c4fa5291a414007c20a7b97751fc98ad/2e2f7265732f72756e5f676966732f70656e64756c756d5f5072696f72697479457870657269656e63655265706c61795f444450474d6f64756c655f315f657069736f64655f3433312e676966\"></td>\n</tr>\n<tr>\n<td align=\"center\">DoubleDueling+ER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/cb434c28cd3c1cfb95bea0283830b4145adb142a/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f457870657269656e63655265706c61795f446f75626c654475656c696e674d6f64756c655f315f657069736f64655f3131342e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9bec39ce3f9f7bb389a93c74ad1f59cb04d83cb6/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f457870657269656e63655265706c61795f446f75626c654475656c696e674d6f64756c655f315f657069736f64655f3334362e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d92f923bd9ff8b9f0bb3339b2356fff22fa138d5/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f457870657269656e63655265706c61795f446f75626c654475656c696e674d6f64756c655f315f657069736f64655f3932352e676966\"></td>\n</tr>\n<tr>\n<td align=\"center\">DoubleDQN+ER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0e5fdf97af008d2025b20bd5c757a5dc2789ce66/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f457870657269656e63655265706c61795f446f75626c6544514e4d6f64756c655f315f657069736f64655f38382e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a0a77bda0ed1b437f70213aea9123f2b1441eeeb/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f457870657269656e63655265706c61795f446f75626c6544514e4d6f64756c655f315f657069736f64655f3631332e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5864f1dbd11fb1ea9ce4352b7c6e50892e99e92f/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f457870657269656e63655265706c61795f446f75626c6544514e4d6f64756c655f315f657069736f64655f3939392e676966\"></td>\n</tr>\n<tr>\n<td align=\"center\">DuelingDQN+ER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c20d1a404e37b33eeb057d8ba712e51e6f91475a/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f457870657269656e63655265706c61795f4475656c696e6744514e4d6f64756c655f315f657069736f64655f3131322e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a24b8e7ab149d22f5661fc3fad23a1b33cb7e352/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f457870657269656e63655265706c61795f4475656c696e6744514e4d6f64756c655f315f657069736f64655f3433312e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bbeb1e1a4b653ef5fe3bc1ce42c92067bd59d340/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f457870657269656e63655265706c61795f4475656c696e6744514e4d6f64756c655f315f657069736f64655f3938302e676966\"></td>\n</tr>\n<tr>\n<td align=\"center\">DoubleDueling+PER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/446bd3b63e7f8284335b4a763e2912c0e013122c/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f5072696f72697479457870657269656e63655265706c61795f446f75626c654475656c696e674d6f64756c655f315f657069736f64655f3135312e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0a060c534af7840d4c19dcf5d3e24dc52eb7f61f/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f5072696f72697479457870657269656e63655265706c61795f446f75626c654475656c696e674d6f64756c655f315f657069736f64655f3334312e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/922ff0b8f144b2184dd052bf9ada6e1982cd20d3/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f5072696f72697479457870657269656e63655265706c61795f446f75626c654475656c696e674d6f64756c655f315f657069736f64655f3939392e676966\"></td>\n</tr>\n<tr>\n<td align=\"center\">DQN+ER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2283ec43c9d59938059dfa1f11e70fb2d574171d/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f457870657269656e63655265706c61795f44514e4d6f64756c655f315f657069736f64655f39332e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/066c6d41b38ac218355e3f2a6949f8c8cb59ad27/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f457870657269656e63655265706c61795f44514e4d6f64756c655f315f657069736f64655f3534312e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/994c56751197cae5a8415434a154b45b9aca38be/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f457870657269656e63655265706c61795f44514e4d6f64756c655f315f657069736f64655f3939392e676966\"></td>\n</tr>\n<tr>\n<td align=\"center\">DuelingDQN+PER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b94cff6d0d4087c26ccbe5684b8cb8c3b66027a9/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f5072696f72697479457870657269656e63655265706c61795f4475656c696e6744514e4d6f64756c655f315f657069736f64655f32312e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bf249405a48c83fc2ca14c3abd57fcaadfc22ad2/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f5072696f72697479457870657269656e63655265706c61795f4475656c696e6744514e4d6f64756c655f315f657069736f64655f3434322e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/411a42c039a0501d0e4b93d83d4e70bcf48b27c7/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f5072696f72697479457870657269656e63655265706c61795f4475656c696e6744514e4d6f64756c655f315f657069736f64655f3939382e676966\"></td>\n</tr>\n<tr>\n<td align=\"center\">DQN+PER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6ab9253196808e0058a9911c3408fc213382450e/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f5072696f72697479457870657269656e63655265706c61795f44514e4d6f64756c655f315f657069736f64655f39392e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f05597fc9b3281f1c59a91cf30e0e5131a670f40/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f5072696f72697479457870657269656e63655265706c61795f44514e4d6f64756c655f315f657069736f64655f3338322e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4a957422bf13420547611d297a087361f2aca96e/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f5072696f72697479457870657269656e63655265706c61795f44514e4d6f64756c655f315f657069736f64655f3934392e676966\"></td>\n</tr>\n<tr>\n<td align=\"center\">DoubleDQN+PER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/580fb0679ce536aea2ac078e7c133a8596cfc0f9/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f5072696f72697479457870657269656e63655265706c61795f446f75626c6544514e4d6f64756c655f315f657069736f64655f372e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/baeea570495aca3030bcfe88f85e616dd66113db/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f5072696f72697479457870657269656e63655265706c61795f446f75626c6544514e4d6f64756c655f315f657069736f64655f3531342e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/80d5acd2fbd8aa156890c041818b871613cd7133/2e2f7265732f72756e5f676966732f6c756e61726c616e6465725f5072696f72697479457870657269656e63655265706c61795f446f75626c6544514e4d6f64756c655f315f657069736f64655f3939392e676966\"></td>\n</tr>\n<tr>\n<td align=\"center\">DDPG+PER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/01d9fdcfae9959077db6f784d1273c6c18a70a5c/2e2f7265732f72756e5f676966732f616e745f5072696f72697479457870657269656e63655265706c61795f444450474d6f64756c655f315f657069736f64655f35322e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/452910f0c207082535dfdecdd9e5e2f9e8c0bdf1/2e2f7265732f72756e5f676966732f616e745f5072696f72697479457870657269656e63655265706c61795f444450474d6f64756c655f315f657069736f64655f3539362e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fb1b9505d0afbfb71974303f0b4a1c543ef770a5/2e2f7265732f72756e5f676966732f616e745f5072696f72697479457870657269656e63655265706c61795f444450474d6f64756c655f315f657069736f64655f3938342e676966\"></td>\n</tr>\n<tr>\n<td align=\"center\">DDPG+ER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/92310d37dc0a6be8dd88bf0411f5e2389bbd15cf/2e2f7265732f72756e5f676966732f616e745f457870657269656e63655265706c61795f444450474d6f64756c655f315f657069736f64655f35342e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/120e9a17628e74e032ad74610f90975729f5a646/2e2f7265732f72756e5f676966732f616e745f457870657269656e63655265706c61795f444450474d6f64756c655f315f657069736f64655f3631342e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2bac99889e10add1b1b6576dc7e5b9fff82adcc4/2e2f7265732f72756e5f676966732f616e745f457870657269656e63655265706c61795f444450474d6f64756c655f315f657069736f64655f3939392e676966\"></td>\n</tr>\n<tr>\n<td align=\"center\">DQN+PER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/be3ed3fb0acc2c8bceb727ff4211964f2dc97be1/2e2f7265732f72756e5f676966732f63617274706f6c655f5072696f72697479457870657269656e63655265706c61795f44514e4d6f64756c655f315f657069736f64655f34342e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/7cd9e7f108e708782070bc3033f0a53519804696/2e2f7265732f72756e5f676966732f63617274706f6c655f5072696f72697479457870657269656e63655265706c61795f44514e4d6f64756c655f315f657069736f64655f3231362e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/33ccb162072ab2b28ccb855567561af72c3002a3/2e2f7265732f72756e5f676966732f63617274706f6c655f5072696f72697479457870657269656e63655265706c61795f44514e4d6f64756c655f315f657069736f64655f3431332e676966\"></td>\n</tr>\n<tr>\n<td align=\"center\">FixedTargetDQN+ER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8eaefc65fc0349b51522af4ae22be9838d4a1511/2e2f7265732f72756e5f676966732f63617274706f6c655f457870657269656e63655265706c61795f466978656454617267657444514e4d6f64756c655f315f657069736f64655f35372e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a13f89eb6e9552a8c7fd4769659414200de46169/2e2f7265732f72756e5f676966732f63617274706f6c655f457870657269656e63655265706c61795f466978656454617267657444514e4d6f64756c655f315f657069736f64655f3330392e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/540b7026ba80c86679d75035b7f923d179ad527e/2e2f7265732f72756e5f676966732f63617274706f6c655f457870657269656e63655265706c61795f466978656454617267657444514e4d6f64756c655f315f657069736f64655f3433382e676966\"></td>\n</tr>\n<tr>\n<td align=\"center\">DQN+ER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/805425a58d3e899c22372f48fa5a73ce2e1da349/2e2f7265732f72756e5f676966732f63617274706f6c655f457870657269656e63655265706c61795f44514e4d6f64756c655f315f657069736f64655f33312e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ecc3ef74f30d4f8d71f76c4f49cd309429f26737/2e2f7265732f72756e5f676966732f63617274706f6c655f457870657269656e63655265706c61795f44514e4d6f64756c655f315f657069736f64655f3230372e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/38291e3d34372295315a5a66bef6fa8daa3aa254/2e2f7265732f72756e5f676966732f63617274706f6c655f457870657269656e63655265706c61795f44514e4d6f64756c655f315f657069736f64655f3434372e676966\"></td>\n</tr>\n<tr>\n<td align=\"center\">FixedTargetDQN+PER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9ba08cf701c175a51fe3c85ed20015358969f955/2e2f7265732f72756e5f676966732f63617274706f6c655f5072696f72697479457870657269656e63655265706c61795f466978656454617267657444514e4d6f64756c655f315f657069736f64655f31332e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8130288b1f878e8d5af56f3a330e4eb3ded754ba/2e2f7265732f72756e5f676966732f63617274706f6c655f5072696f72697479457870657269656e63655265706c61795f466978656454617267657444514e4d6f64756c655f315f657069736f64655f3236352e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fc476125ce2c36f1f7de2b43887bcb2704669611/2e2f7265732f72756e5f676966732f63617274706f6c655f5072696f72697479457870657269656e63655265706c61795f466978656454617267657444514e4d6f64756c655f315f657069736f64655f3434392e676966\"></td>\n</tr>\n<tr>\n<td align=\"center\">DoubleDQN+ER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/69e10ad619c426f0c29de627e64bc1167b5ba68c/2e2f7265732f72756e5f676966732f63617274706f6c655f457870657269656e63655265706c61795f446f75626c6544514e4d6f64756c655f315f657069736f64655f36302e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/52a7690a386fbd510b2362e6276ef9283c1491a5/2e2f7265732f72756e5f676966732f63617274706f6c655f457870657269656e63655265706c61795f446f75626c6544514e4d6f64756c655f315f657069736f64655f3236382e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a2be2432a434aa2337c579c1580805268086528f/2e2f7265732f72756e5f676966732f63617274706f6c655f457870657269656e63655265706c61795f446f75626c6544514e4d6f64756c655f315f657069736f64655f3433382e676966\"></td>\n</tr>\n<tr>\n<td align=\"center\">DoubleDQN+PER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b7c37695ab67ab1db2bc53958d05298a9dee8008/2e2f7265732f72756e5f676966732f63617274706f6c655f5072696f72697479457870657269656e63655265706c61795f446f75626c6544514e4d6f64756c655f315f657069736f64655f33352e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/82653dd47882ca57e06dd1498e40b4d45fd37ec3/2e2f7265732f72756e5f676966732f63617274706f6c655f5072696f72697479457870657269656e63655265706c61795f446f75626c6544514e4d6f64756c655f315f657069736f64655f3236392e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bec04d6fea788d79b75c1359b2151da4a6945fb4/2e2f7265732f72756e5f676966732f63617274706f6c655f5072696f72697479457870657269656e63655265706c61795f446f75626c6544514e4d6f64756c655f315f657069736f64655f3434342e676966\"></td>\n</tr>\n<tr>\n<td align=\"center\">DuelingDQN+ER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e1ef4856c9b76f410040d014b72b57163fad8d1e/2e2f7265732f72756e5f676966732f63617274706f6c655f457870657269656e63655265706c61795f4475656c696e6744514e4d6f64756c655f315f657069736f64655f36322e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/879e20d2272d73c9de0b5399ca57140cb16c0d04/2e2f7265732f72756e5f676966732f63617274706f6c655f457870657269656e63655265706c61795f4475656c696e6744514e4d6f64756c655f315f657069736f64655f3230392e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e3548161f58aeea78367bee272cc877f24833f9d/2e2f7265732f72756e5f676966732f63617274706f6c655f457870657269656e63655265706c61795f4475656c696e6744514e4d6f64756c655f315f657069736f64655f3433322e676966\"></td>\n</tr>\n<tr>\n<td align=\"center\">DoubleDueling+PER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c4ab344e5c3d08849f74912895e786c575a99db1/2e2f7265732f72756e5f676966732f63617274706f6c655f5072696f72697479457870657269656e63655265706c61795f446f75626c654475656c696e674d6f64756c655f315f657069736f64655f322e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/88b61b7ed048eae62247682c5c5abfe0ad0e7bc6/2e2f7265732f72756e5f676966732f63617274706f6c655f5072696f72697479457870657269656e63655265706c61795f446f75626c654475656c696e674d6f64756c655f315f657069736f64655f3236302e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9c51510f4883bc08830e2e70bd6a64d39424c3b4/2e2f7265732f72756e5f676966732f63617274706f6c655f5072696f72697479457870657269656e63655265706c61795f446f75626c654475656c696e674d6f64756c655f315f657069736f64655f3433382e676966\"></td>\n</tr>\n<tr>\n<td align=\"center\">DuelingDQN+PER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/761a5314e0d1e30d73e439c9f2c6cc279004099d/2e2f7265732f72756e5f676966732f63617274706f6c655f5072696f72697479457870657269656e63655265706c61795f4475656c696e6744514e4d6f64756c655f315f657069736f64655f36392e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/64b07f71ffbd164dfef8e8c5dd071a45746e33a8/2e2f7265732f72756e5f676966732f63617274706f6c655f5072696f72697479457870657269656e63655265706c61795f4475656c696e6744514e4d6f64756c655f315f657069736f64655f3237322e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e7ae4c3757ba051ab3eebdad3540a66637a23771/2e2f7265732f72756e5f676966732f63617274706f6c655f5072696f72697479457870657269656e63655265706c61795f4475656c696e6744514e4d6f64756c655f315f657069736f64655f3433382e676966\"></td>\n</tr>\n<tr>\n<td align=\"center\">DoubleDueling+ER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/705c9310c4758d3ad6e634ffb571c52672e33b42/2e2f7265732f72756e5f676966732f63617274706f6c655f457870657269656e63655265706c61795f446f75626c654475656c696e674d6f64756c655f315f657069736f64655f34332e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/09993dd463ceef5d549b6d5edabbc78266fc5e1a/2e2f7265732f72756e5f676966732f63617274706f6c655f457870657269656e63655265706c61795f446f75626c654475656c696e674d6f64756c655f315f657069736f64655f3238372e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/7bae547e91aa926ee8fc18df14cbd5a34d4e484e/2e2f7265732f72756e5f676966732f63617274706f6c655f457870657269656e63655265706c61795f446f75626c654475656c696e674d6f64756c655f315f657069736f64655f3434372e676966\"></td>\n</tr>\n<tr>\n<td align=\"center\">DDPG+ER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2e379348c3d2937f12feae878d7ea2965d3857bf/2e2f7265732f72756e5f676966732f6163726f626f745f457870657269656e63655265706c61795f444450474d6f64756c655f315f657069736f64655f36392e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b11e564b39667188c81300d2f01f84047f9fa380/2e2f7265732f72756e5f676966732f6163726f626f745f457870657269656e63655265706c61795f444450474d6f64756c655f315f657069736f64655f3139372e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bd5f569485603bbf331a1f6a407858ba09c09af2/2e2f7265732f72756e5f676966732f6163726f626f745f457870657269656e63655265706c61795f444450474d6f64756c655f315f657069736f64655f3433382e676966\"></td>\n</tr>\n<tr>\n<td align=\"center\">DDPG+PER</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e52a3f2c8bbdf3a3ea2846b6dc6aa991e1b7b31f/2e2f7265732f72756e5f676966732f6163726f626f745f5072696f72697479457870657269656e63655265706c61795f444450474d6f64756c655f315f657069736f64655f35352e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2d1ce30ddc314626ce5b61bf240f99718e59492a/2e2f7265732f72756e5f676966732f6163726f626f745f5072696f72697479457870657269656e63655265706c61795f444450474d6f64756c655f315f657069736f64655f3236372e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/eba0ffb88e1bd4d16922fc010a8cdd8f1e884e35/2e2f7265732f72756e5f676966732f6163726f626f745f5072696f72697479457870657269656e63655265706c61795f444450474d6f64756c655f315f657069736f64655f3432322e676966\"></td>\n</tr></tbody></table>\n\n          </div>"}, "last_serial": 6560748, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "22413f79074b48b5969ffac6f1910543", "sha256": "ab92a3b77402c4704dc9b8610db16c59f65a65088939c573b36f94b3e6d13d14"}, "downloads": -1, "filename": "fast_rl-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "22413f79074b48b5969ffac6f1910543", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 9767, "upload_time": "2019-08-16T03:10:09", "upload_time_iso_8601": "2019-08-16T03:10:09.590702Z", "url": "https://files.pythonhosted.org/packages/ad/47/13e413ca2d4af206ca146d987a7af6a68f0e0c5a7ab77e8e1ec824d65b11/fast_rl-0.1.0-py3-none-any.whl", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "88854ed3a52d2456b0c736046f58b8b5", "sha256": "ce7d49cda2e2b42eb9823bb7d9030b2b7cd25009ac1f93542d24128a963915c2"}, "downloads": -1, "filename": "fast_rl-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "88854ed3a52d2456b0c736046f58b8b5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 9767, "upload_time": "2019-08-16T03:22:11", "upload_time_iso_8601": "2019-08-16T03:22:11.176705Z", "url": "https://files.pythonhosted.org/packages/82/8e/89c8dc30c5bc5f48f7545df029bb595915db0420b95440b6a640e629ed2c/fast_rl-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "559da6c1a649cc08de6e9988cf9d4f04", "sha256": "9ac037ff184bce0d9a62b0098285eb5b40a3c9e1326ef8cfa4936fa0f958323a"}, "downloads": -1, "filename": "fast_rl-0.1.1.tar.gz", "has_sig": false, "md5_digest": "559da6c1a649cc08de6e9988cf9d4f04", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6420, "upload_time": "2019-08-16T03:22:13", "upload_time_iso_8601": "2019-08-16T03:22:13.019583Z", "url": "https://files.pythonhosted.org/packages/16/18/6b09960201f862006e4767f2a66a797c92aa716978e6fd949a9e37d698bb/fast_rl-0.1.1.tar.gz", "yanked": false}], "0.9.6": [{"comment_text": "", "digests": {"md5": "4e5f561e55f395912707c12f37952c4d", "sha256": "86dba918375190c0b99d8ee5f4f53c0d506de97eef09000d91e910db88ecca6e"}, "downloads": -1, "filename": "fast_rl-0.9.6-py3-none-any.whl", "has_sig": false, "md5_digest": "4e5f561e55f395912707c12f37952c4d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 55744, "upload_time": "2019-12-16T02:08:20", "upload_time_iso_8601": "2019-12-16T02:08:20.259131Z", "url": "https://files.pythonhosted.org/packages/a6/90/3727a50c6a82decdf4152887fa34efcf75b49d6c164f8779d9caf0f5ad77/fast_rl-0.9.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5910f20e6ae0bd9be7e30e99906083af", "sha256": "16ab34d8005c27ecc00676850fdee248ee8939370f0c9ace6fe8323594641771"}, "downloads": -1, "filename": "fast_rl-0.9.6.tar.gz", "has_sig": false, "md5_digest": "5910f20e6ae0bd9be7e30e99906083af", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 45361, "upload_time": "2019-12-16T02:08:21", "upload_time_iso_8601": "2019-12-16T02:08:21.902775Z", "url": "https://files.pythonhosted.org/packages/ee/57/edda11a4a4515a66f598e9cf61391a7ae8bda6754c58b951365911fc6021/fast_rl-0.9.6.tar.gz", "yanked": false}], "0.9.7": [{"comment_text": "", "digests": {"md5": "1e678cd2d70306422a58d57c9da125c9", "sha256": "fc0f81fd99f96c820c4f40739d17586a64fa91adefe006b06360fe61bfd7fb0f"}, "downloads": -1, "filename": "fast_rl-0.9.7-py3-none-any.whl", "has_sig": false, "md5_digest": "1e678cd2d70306422a58d57c9da125c9", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 54812, "upload_time": "2019-12-22T00:48:21", "upload_time_iso_8601": "2019-12-22T00:48:21.162463Z", "url": "https://files.pythonhosted.org/packages/6b/76/0f8187886467969ae98f7bbdb52b7581a81fde8654d2810428a0b1482861/fast_rl-0.9.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "35acb29dc386c8e29995f57c2fd2f23d", "sha256": "15bd244a3715621372371b5b22ac37b717619db57715f956a5ac465baafb0bc1"}, "downloads": -1, "filename": "fast_rl-0.9.7.tar.gz", "has_sig": false, "md5_digest": "35acb29dc386c8e29995f57c2fd2f23d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 42737, "upload_time": "2019-12-22T00:48:23", "upload_time_iso_8601": "2019-12-22T00:48:23.224776Z", "url": "https://files.pythonhosted.org/packages/90/23/81cbb530e68b453c6baab338082c3b2c5c6c99101ec02f96bda3a246af5e/fast_rl-0.9.7.tar.gz", "yanked": false}], "0.9.91": [{"comment_text": "", "digests": {"md5": "a9c076265f1adbd22c242a5d0a4f18d3", "sha256": "0ee457c8df31c8476da51fe10307b17799fdb2d2298efac2346937c18a006c4d"}, "downloads": -1, "filename": "fast_rl-0.9.91-py3-none-any.whl", "has_sig": false, "md5_digest": "a9c076265f1adbd22c242a5d0a4f18d3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 57704, "upload_time": "2020-01-31T23:42:28", "upload_time_iso_8601": "2020-01-31T23:42:28.570270Z", "url": "https://files.pythonhosted.org/packages/c0/aa/c1bd665cdd36369c0c4fc99d24640fe1f717a8ea259a6d4d95aa4fb3ec22/fast_rl-0.9.91-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6359065c6df101fbe573db143d4f9554", "sha256": "50ffd645ffe6d432a42f94546a5b7eccd1b36104aea898bc645f972b66e8ec07"}, "downloads": -1, "filename": "fast_rl-0.9.91.tar.gz", "has_sig": false, "md5_digest": "6359065c6df101fbe573db143d4f9554", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 44695, "upload_time": "2020-01-31T23:42:30", "upload_time_iso_8601": "2020-01-31T23:42:30.479064Z", "url": "https://files.pythonhosted.org/packages/f2/be/81c29059f5f107779819aceee292c892b358cb40a5cc294a6dc47c97fb92/fast_rl-0.9.91.tar.gz", "yanked": false}], "0.9.92": [{"comment_text": "", "digests": {"md5": "c51752d597a836d471c521f07dfc1718", "sha256": "6697e231858e99df4566f544a41a6320ffde4b28c984c87632888924998842db"}, "downloads": -1, "filename": "fast_rl-0.9.92-py3-none-any.whl", "has_sig": false, "md5_digest": "c51752d597a836d471c521f07dfc1718", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 57044, "upload_time": "2020-02-01T23:04:00", "upload_time_iso_8601": "2020-02-01T23:04:00.309610Z", "url": "https://files.pythonhosted.org/packages/8a/90/b2d4f43ffb597510782cf74b8a4abcc01a26f5991305046a531c2e7a1edb/fast_rl-0.9.92-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ae1492902f9ae4f6f44730f61a920e0d", "sha256": "ab2323cf2a317d184939725016f4b831e16a108b0bd761f57ee30f223b07ebfa"}, "downloads": -1, "filename": "fast_rl-0.9.92.tar.gz", "has_sig": false, "md5_digest": "ae1492902f9ae4f6f44730f61a920e0d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 42971, "upload_time": "2020-02-01T23:04:01", "upload_time_iso_8601": "2020-02-01T23:04:01.751159Z", "url": "https://files.pythonhosted.org/packages/95/8b/d6da5ea3413d3101c3010ec51a080d797fd935e5c09e9b94be90487c9836/fast_rl-0.9.92.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "ddfe2ee3632bc5c543136cc9a8085ef4", "sha256": "0375690e70836824c8110ab040764e4c95ec07217099b0154dd7f52e830012ab"}, "downloads": -1, "filename": "fast_rl-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "ddfe2ee3632bc5c543136cc9a8085ef4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 58086, "upload_time": "2020-02-03T03:25:05", "upload_time_iso_8601": "2020-02-03T03:25:05.937112Z", "url": "https://files.pythonhosted.org/packages/c8/e8/ead33d662908c8bc88ee37c96bf4fc37330a33c153e5698831eefa98f0f2/fast_rl-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7a4052bd8d836ffd8bcc8ebce21e76b2", "sha256": "ab5e372ffb08f2324e29a0a9a64739088feacf521dd05867924e3edf3f381e03"}, "downloads": -1, "filename": "fast_rl-1.0.1.tar.gz", "has_sig": false, "md5_digest": "7a4052bd8d836ffd8bcc8ebce21e76b2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 44981, "upload_time": "2020-02-03T03:25:07", "upload_time_iso_8601": "2020-02-03T03:25:07.395730Z", "url": "https://files.pythonhosted.org/packages/39/9a/9b4daa2949474e5780aa7a3176f0c6ead4e1ddf563f0514745537f937364/fast_rl-1.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ddfe2ee3632bc5c543136cc9a8085ef4", "sha256": "0375690e70836824c8110ab040764e4c95ec07217099b0154dd7f52e830012ab"}, "downloads": -1, "filename": "fast_rl-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "ddfe2ee3632bc5c543136cc9a8085ef4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 58086, "upload_time": "2020-02-03T03:25:05", "upload_time_iso_8601": "2020-02-03T03:25:05.937112Z", "url": "https://files.pythonhosted.org/packages/c8/e8/ead33d662908c8bc88ee37c96bf4fc37330a33c153e5698831eefa98f0f2/fast_rl-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7a4052bd8d836ffd8bcc8ebce21e76b2", "sha256": "ab5e372ffb08f2324e29a0a9a64739088feacf521dd05867924e3edf3f381e03"}, "downloads": -1, "filename": "fast_rl-1.0.1.tar.gz", "has_sig": false, "md5_digest": "7a4052bd8d836ffd8bcc8ebce21e76b2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 44981, "upload_time": "2020-02-03T03:25:07", "upload_time_iso_8601": "2020-02-03T03:25:07.395730Z", "url": "https://files.pythonhosted.org/packages/39/9a/9b4daa2949474e5780aa7a3176f0c6ead4e1ddf563f0514745537f937364/fast_rl-1.0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:43:25 2020"}