{"info": {"author": "Sidhartha Parhi", "author_email": "sidhartha.parhi@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "# GAN Lab\n\n<img align=\"center\" src=\"https://github.com/sidward14/gan-lab/raw/master/examples/for_readme/stylegan/stylemixed-grid_sample.png\" height=\"696\" width=\"900\"/>\n\n### _Higher resolutions coming once model finishes training in Google Colab with 16 GB GPU Memory (the above are 128x128 res images from a StyleGAN trained in a 6 GB GPU)_\n\n__Currently supports:__\n+ StyleGAN (https://arxiv.org/pdf/1812.04948.pdf)\n+ ProGAN (https://arxiv.org/pdf/1710.10196.pdf)\n+ ResNet GANs\n\nEach GAN model's default settings emulates its most recent official implementation, but at the same time this package features a simple interface ([config.py](./gan_lab/config.py)) where the user can quickly tune an extensive list of hyperparameter settings to his/her choosing.\n\nComes with additional features such as supervised learning capabilities, an easy-to-use interface for saving/loading pretrained models, flexible learning rate scheduling (and re-scheduling) capabilities, etc.\n\nThis package aims for an intuitive API without sacrificing any complexity anywhere.\n\n--------------------------------------------------------------------------------\n\nIn your virtual environment (e.g. a conda virtual environment), run:\n  ~~~\n  $ pip install gan-lab\n  ~~~\nThis will install all necessary dependencies for you and will enable the option to use the package like an API (see \"Jupyter Notebook (or Custom Script) Usage\" below).\n\nIf you do not wish to use the package like an API (i.e. you just want to install dependencies and then just use the repo by means of running [train.py](./gan_lab/train.py), like shown below in the \"Basic Usage on Command-line\" section), you can run '$ pip install -r requirements.txt' instead.\n\n## Basic Usage on Command-line\n\n__Clone this repo__, then simply run the following to configure your model & dataset and train your chosen model:\n  ~~~\n  $ python config.py [model] [--optional_kwargs]\n  $ python data_config.py [dataset] [dataset_dir] [--optional_kwargs]\n  $ python train.py\n  ~~~\nThe model will be saved into the \"./gan_lab/models\" directory by default.\n\nIf you would like to see a list of what each argument does, run '$ python config.py [model] -h' or '$ python data_config.py [dataset] [dataset_dir] -h' on the command-line.\n\n__NOTE__: Make sure that all images you would like to use in your model are located directly inside the _dataset_dir_ parent directory before running [data_config.py](./gan_lab/data_config.py). Any images within subdirectories of _dataset_dir_ (except for the subdirectories named \"train\" or \"valid\" that get created when you run [data_config.py](./gan_lab/data_config.py)) will not be used when training your model.\n\n### StyleGAN Example:\n\nA StyleGAN Generator that yields 128x128 images _(higher resolutions coming once model is done training in Google Colab with 16 GB GPU Memory)_ can be created by running the following 3 lines. Below is a snapshot of images as the StyleGAN progressively grows. Ofcourse, this is not the only configuration that works:\n  ~~~\n  $ python config.py stylegan --loss=nonsaturating --gradient_penalty=R1 --res_samples=128 --num_main_iters=1071000 --nimg_transition=630000 --batch_size=8 --enable_cudnn_autotuner --num_workers=12\n  $ python data_config.py FFHQ path/to/datasets/ffhq --enable_mirror_augmentation\n  $ python train.py\n  ~~~\n\n  <p align=\"center\">\n  <img align=\"center\" src=\"https://github.com/sidward14/gan-lab/raw/master/examples/for_readme/stylegan/stylegan_image-grid_growth.gif\" width=\"500\" height=\"500\"/>\n  </p>\n\nBy default, image grids like the ones above are saved periodically during training into the \"./gan_lab/samples\" directory every 1,000 iterations (see [config.py](./gan_lab/config.py)).\n\n### ProGAN Example:\n\nA ProGAN Generator that yields 128x128 images _(higher resolutions coming once model is done training in Google Colab with 16 GB GPU Memory)_ like the ones below can be created by running the following 3 lines. Ofcourse, this is not the only configuration that works:\n  ~~~\n  $ python config.py progan --res_samples=128 --num_main_iters=1050000 --batch_size=8\n  $ python data_config.py CelebA-HQ path/to/datasets/celeba_hq --enable_mirror_augmentation\n  $ python train.py\n  ~~~\n\n  <p align=\"center\">\n  <img align=\"center\" src=\"https://github.com/sidward14/gan-lab/raw/master/examples/for_readme/progan/image_grids.gif\" width=\"500\" height=\"500\"/>\n  </p>\n\nBy default, image grids of generator output are saved periodically during training into the \"./gan_lab/samples\" directory every 1,000 iterations (see [config.py](./gan_lab/config.py)).\n\n### ResNet GAN Example:\n\nA ResNet GAN Generator can be created by running the following 3 lines (for example):\n  ~~~\n  $ python config.py resnetgan --lr_base=.00015\n  $ python data_config.py LSUN-Bedrooms path/to/datasets/lsun_bedrooms\n  $ python train.py\n  ~~~\n\n  [SAMPLES FOR RESNET GAN COMING SOON]\n\n\n\n## Jupyter Notebook (or Custom Script) Usage\n\nRunning [train.py](./gan_lab/train.py) is just the very basic usage. This package can be imported and utilized in a modular manner as well (like an API). For example, often it's helpful to experiment inside a Jupyter Notebook, like in the example workflow below.\n\n  First, configure your GAN to your choosing on the command-line (like explained above under the \"Basic Usage on Command-line\" section):\n  ~~~\n  $ python config.py stylegan\n  $ python data_config.py FFHQ path/to/datasets/ffhq\n  ~~~\n\n  Then, write a custom script or Jupyter Notebook cells:\n  ```python\n  from gan_lab import get_current_configuration\n  from gan_lab.utils.data_utils import prepare_dataset, prepare_dataloader\n  from gan_lab.stylegan.learner import StyleGANLearner\n\n  # get most recent configurations:\n  config = get_current_configuration( 'config' )\n  data_config = get_current_configuration( 'data_config' )\n\n  # get DataLoader(s)\n  train_ds, valid_ds = prepare_dataset( data_config )\n  train_dl, valid_dl, z_valid_dl = prepare_dataloader( config, data_config, train_ds, valid_ds )\n\n  # instantiate StyleGANLearner and train:\n  learner = StyleGANLearner( config )\n  learner.train( train_dl, valid_dl, z_valid_dl )   # train for config.num_main_iters iterations\n  learner.config.num_main_iters = 300000            # this is one example of changing your instantiated learner's configurations\n  learner.train( train_dl, valid_dl, z_valid_dl )   # train for another 300000 iterations\n\n  # save your trained model:\n  learner.save_model( 'path/to/models/stylegan_model.tar' )\n\n  # later on, you can load this saved model by instantiating the same learner and then running load_model:\n  # learner = StyleGANLearner( config )\n  # learner.load_model( 'path/to/models/stylegan_model.tar' )\n  ```\n\n__Some Advantages of Jupyter Notebook (there are many more than this)__:\n+ You have the flexibility to think about what to do with your trained model after its trained rather than all at once, such as:\n  + whether you want to save/load your trained model\n  + what learner.config parameters you want to change before training again\n+ You can always stop the kernel during training, do something else, and then resume again and it will work\n\n--------------------------------------------------------------------------------\n\n__NOTE__ that by default, the _--num_workers_ argument in [config.py](./gan_lab/config.py) is set to data-loading from just 1 subprocess; setting this to a larger number (that still falls within the constraints of your CPU(s)) will speed up training significantly. :slightly_smiling_face:\n\n## TODO (will be implemented soon):\n- [ ] Multi-GPU support\n- [ ] TensorBoard capabilities\n- [ ] FID, IS, and MS-SSIM metrics calculation\n- [ ] Incorporate Spectral Normalization\n- [ ] Incorporate Self-attention\n- [ ] TorchScript capabilities", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/sidward14/gan-lab", "keywords": "GAN GAN-Zoo ML generative neural model", "license": "", "maintainer": "", "maintainer_email": "", "name": "gan-lab", "package_url": "https://pypi.org/project/gan-lab/", "platform": "", "project_url": "https://pypi.org/project/gan-lab/", "project_urls": {"Homepage": "https://github.com/sidward14/gan-lab"}, "release_url": "https://pypi.org/project/gan-lab/0.2.4/", "requires_dist": null, "requires_python": ">= 3.6", "summary": "StyleGAN, ProGAN, and ResNet GANs to experiment with", "version": "0.2.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>GAN Lab</h1>\n<img align=\"center\" height=\"696\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/58f9a92708ae0d40a631b4b7613c3db9c0240cbe/68747470733a2f2f6769746875622e636f6d2f7369647761726431342f67616e2d6c61622f7261772f6d61737465722f6578616d706c65732f666f725f726561646d652f7374796c6567616e2f7374796c656d697865642d677269645f73616d706c652e706e67\" width=\"900\">\n<h3><em>Higher resolutions coming once model finishes training in Google Colab with 16 GB GPU Memory (the above are 128x128 res images from a StyleGAN trained in a 6 GB GPU)</em></h3>\n<p><strong>Currently supports:</strong></p>\n<ul>\n<li>StyleGAN (<a href=\"https://arxiv.org/pdf/1812.04948.pdf\" rel=\"nofollow\">https://arxiv.org/pdf/1812.04948.pdf</a>)</li>\n<li>ProGAN (<a href=\"https://arxiv.org/pdf/1710.10196.pdf\" rel=\"nofollow\">https://arxiv.org/pdf/1710.10196.pdf</a>)</li>\n<li>ResNet GANs</li>\n</ul>\n<p>Each GAN model's default settings emulates its most recent official implementation, but at the same time this package features a simple interface (<a href=\"./gan_lab/config.py\" rel=\"nofollow\">config.py</a>) where the user can quickly tune an extensive list of hyperparameter settings to his/her choosing.</p>\n<p>Comes with additional features such as supervised learning capabilities, an easy-to-use interface for saving/loading pretrained models, flexible learning rate scheduling (and re-scheduling) capabilities, etc.</p>\n<p>This package aims for an intuitive API without sacrificing any complexity anywhere.</p>\n<hr>\n<p>In your virtual environment (e.g. a conda virtual environment), run:</p>\n<pre><code>$ pip install gan-lab\n</code></pre>\n<p>This will install all necessary dependencies for you and will enable the option to use the package like an API (see \"Jupyter Notebook (or Custom Script) Usage\" below).</p>\n<p>If you do not wish to use the package like an API (i.e. you just want to install dependencies and then just use the repo by means of running <a href=\"./gan_lab/train.py\" rel=\"nofollow\">train.py</a>, like shown below in the \"Basic Usage on Command-line\" section), you can run '$ pip install -r requirements.txt' instead.</p>\n<h2>Basic Usage on Command-line</h2>\n<p><strong>Clone this repo</strong>, then simply run the following to configure your model &amp; dataset and train your chosen model:</p>\n<pre><code>$ python config.py [model] [--optional_kwargs]\n$ python data_config.py [dataset] [dataset_dir] [--optional_kwargs]\n$ python train.py\n</code></pre>\n<p>The model will be saved into the \"./gan_lab/models\" directory by default.</p>\n<p>If you would like to see a list of what each argument does, run '$ python config.py [model] -h' or '$ python data_config.py [dataset] [dataset_dir] -h' on the command-line.</p>\n<p><strong>NOTE</strong>: Make sure that all images you would like to use in your model are located directly inside the <em>dataset_dir</em> parent directory before running <a href=\"./gan_lab/data_config.py\" rel=\"nofollow\">data_config.py</a>. Any images within subdirectories of <em>dataset_dir</em> (except for the subdirectories named \"train\" or \"valid\" that get created when you run <a href=\"./gan_lab/data_config.py\" rel=\"nofollow\">data_config.py</a>) will not be used when training your model.</p>\n<h3>StyleGAN Example:</h3>\n<p>A StyleGAN Generator that yields 128x128 images <em>(higher resolutions coming once model is done training in Google Colab with 16 GB GPU Memory)</em> can be created by running the following 3 lines. Below is a snapshot of images as the StyleGAN progressively grows. Ofcourse, this is not the only configuration that works:</p>\n<pre><code>$ python config.py stylegan --loss=nonsaturating --gradient_penalty=R1 --res_samples=128 --num_main_iters=1071000 --nimg_transition=630000 --batch_size=8 --enable_cudnn_autotuner --num_workers=12\n$ python data_config.py FFHQ path/to/datasets/ffhq --enable_mirror_augmentation\n$ python train.py\n</code></pre>\n  <p align=\"center\">\n  <img align=\"center\" height=\"500\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c1d5209ca9360863a41fb07d59894290b3dd064a/68747470733a2f2f6769746875622e636f6d2f7369647761726431342f67616e2d6c61622f7261772f6d61737465722f6578616d706c65732f666f725f726561646d652f7374796c6567616e2f7374796c6567616e5f696d6167652d677269645f67726f7774682e676966\" width=\"500\">\n  </p>\n<p>By default, image grids like the ones above are saved periodically during training into the \"./gan_lab/samples\" directory every 1,000 iterations (see <a href=\"./gan_lab/config.py\" rel=\"nofollow\">config.py</a>).</p>\n<h3>ProGAN Example:</h3>\n<p>A ProGAN Generator that yields 128x128 images <em>(higher resolutions coming once model is done training in Google Colab with 16 GB GPU Memory)</em> like the ones below can be created by running the following 3 lines. Ofcourse, this is not the only configuration that works:</p>\n<pre><code>$ python config.py progan --res_samples=128 --num_main_iters=1050000 --batch_size=8\n$ python data_config.py CelebA-HQ path/to/datasets/celeba_hq --enable_mirror_augmentation\n$ python train.py\n</code></pre>\n  <p align=\"center\">\n  <img align=\"center\" height=\"500\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/aeae1ef2de51a592883b94f5587adb653d50d7f3/68747470733a2f2f6769746875622e636f6d2f7369647761726431342f67616e2d6c61622f7261772f6d61737465722f6578616d706c65732f666f725f726561646d652f70726f67616e2f696d6167655f67726964732e676966\" width=\"500\">\n  </p>\n<p>By default, image grids of generator output are saved periodically during training into the \"./gan_lab/samples\" directory every 1,000 iterations (see <a href=\"./gan_lab/config.py\" rel=\"nofollow\">config.py</a>).</p>\n<h3>ResNet GAN Example:</h3>\n<p>A ResNet GAN Generator can be created by running the following 3 lines (for example):</p>\n<pre><code>$ python config.py resnetgan --lr_base=.00015\n$ python data_config.py LSUN-Bedrooms path/to/datasets/lsun_bedrooms\n$ python train.py\n</code></pre>\n<p>[SAMPLES FOR RESNET GAN COMING SOON]</p>\n<h2>Jupyter Notebook (or Custom Script) Usage</h2>\n<p>Running <a href=\"./gan_lab/train.py\" rel=\"nofollow\">train.py</a> is just the very basic usage. This package can be imported and utilized in a modular manner as well (like an API). For example, often it's helpful to experiment inside a Jupyter Notebook, like in the example workflow below.</p>\n<p>First, configure your GAN to your choosing on the command-line (like explained above under the \"Basic Usage on Command-line\" section):</p>\n<pre><code>$ python config.py stylegan\n$ python data_config.py FFHQ path/to/datasets/ffhq\n</code></pre>\n<p>Then, write a custom script or Jupyter Notebook cells:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">gan_lab</span> <span class=\"kn\">import</span> <span class=\"n\">get_current_configuration</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gan_lab.utils.data_utils</span> <span class=\"kn\">import</span> <span class=\"n\">prepare_dataset</span><span class=\"p\">,</span> <span class=\"n\">prepare_dataloader</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gan_lab.stylegan.learner</span> <span class=\"kn\">import</span> <span class=\"n\">StyleGANLearner</span>\n\n<span class=\"c1\"># get most recent configurations:</span>\n<span class=\"n\">config</span> <span class=\"o\">=</span> <span class=\"n\">get_current_configuration</span><span class=\"p\">(</span> <span class=\"s1\">'config'</span> <span class=\"p\">)</span>\n<span class=\"n\">data_config</span> <span class=\"o\">=</span> <span class=\"n\">get_current_configuration</span><span class=\"p\">(</span> <span class=\"s1\">'data_config'</span> <span class=\"p\">)</span>\n\n<span class=\"c1\"># get DataLoader(s)</span>\n<span class=\"n\">train_ds</span><span class=\"p\">,</span> <span class=\"n\">valid_ds</span> <span class=\"o\">=</span> <span class=\"n\">prepare_dataset</span><span class=\"p\">(</span> <span class=\"n\">data_config</span> <span class=\"p\">)</span>\n<span class=\"n\">train_dl</span><span class=\"p\">,</span> <span class=\"n\">valid_dl</span><span class=\"p\">,</span> <span class=\"n\">z_valid_dl</span> <span class=\"o\">=</span> <span class=\"n\">prepare_dataloader</span><span class=\"p\">(</span> <span class=\"n\">config</span><span class=\"p\">,</span> <span class=\"n\">data_config</span><span class=\"p\">,</span> <span class=\"n\">train_ds</span><span class=\"p\">,</span> <span class=\"n\">valid_ds</span> <span class=\"p\">)</span>\n\n<span class=\"c1\"># instantiate StyleGANLearner and train:</span>\n<span class=\"n\">learner</span> <span class=\"o\">=</span> <span class=\"n\">StyleGANLearner</span><span class=\"p\">(</span> <span class=\"n\">config</span> <span class=\"p\">)</span>\n<span class=\"n\">learner</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span> <span class=\"n\">train_dl</span><span class=\"p\">,</span> <span class=\"n\">valid_dl</span><span class=\"p\">,</span> <span class=\"n\">z_valid_dl</span> <span class=\"p\">)</span>   <span class=\"c1\"># train for config.num_main_iters iterations</span>\n<span class=\"n\">learner</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"o\">.</span><span class=\"n\">num_main_iters</span> <span class=\"o\">=</span> <span class=\"mi\">300000</span>            <span class=\"c1\"># this is one example of changing your instantiated learner's configurations</span>\n<span class=\"n\">learner</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span> <span class=\"n\">train_dl</span><span class=\"p\">,</span> <span class=\"n\">valid_dl</span><span class=\"p\">,</span> <span class=\"n\">z_valid_dl</span> <span class=\"p\">)</span>   <span class=\"c1\"># train for another 300000 iterations</span>\n\n<span class=\"c1\"># save your trained model:</span>\n<span class=\"n\">learner</span><span class=\"o\">.</span><span class=\"n\">save_model</span><span class=\"p\">(</span> <span class=\"s1\">'path/to/models/stylegan_model.tar'</span> <span class=\"p\">)</span>\n\n<span class=\"c1\"># later on, you can load this saved model by instantiating the same learner and then running load_model:</span>\n<span class=\"c1\"># learner = StyleGANLearner( config )</span>\n<span class=\"c1\"># learner.load_model( 'path/to/models/stylegan_model.tar' )</span>\n</pre>\n<p><strong>Some Advantages of Jupyter Notebook (there are many more than this)</strong>:</p>\n<ul>\n<li>You have the flexibility to think about what to do with your trained model after its trained rather than all at once, such as:\n<ul>\n<li>whether you want to save/load your trained model</li>\n<li>what learner.config parameters you want to change before training again</li>\n</ul>\n</li>\n<li>You can always stop the kernel during training, do something else, and then resume again and it will work</li>\n</ul>\n<hr>\n<p><strong>NOTE</strong> that by default, the <em>--num_workers</em> argument in <a href=\"./gan_lab/config.py\" rel=\"nofollow\">config.py</a> is set to data-loading from just 1 subprocess; setting this to a larger number (that still falls within the constraints of your CPU(s)) will speed up training significantly. :slightly_smiling_face:</p>\n<h2>TODO (will be implemented soon):</h2>\n<ul>\n<li>[ ] Multi-GPU support</li>\n<li>[ ] TensorBoard capabilities</li>\n<li>[ ] FID, IS, and MS-SSIM metrics calculation</li>\n<li>[ ] Incorporate Spectral Normalization</li>\n<li>[ ] Incorporate Self-attention</li>\n<li>[ ] TorchScript capabilities</li>\n</ul>\n\n          </div>"}, "last_serial": 6883060, "releases": {"0.2.3": [{"comment_text": "", "digests": {"md5": "e6d769993ad5147a8d53b36ceaa89247", "sha256": "1c107ce209fb07c29ace15345690a7a6a27b912a84ca7a5eda5c3e0a758d0dcd"}, "downloads": -1, "filename": "gan-lab-0.2.3.tar.gz", "has_sig": false, "md5_digest": "e6d769993ad5147a8d53b36ceaa89247", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 70441, "upload_time": "2020-03-02T23:01:36", "upload_time_iso_8601": "2020-03-02T23:01:36.828577Z", "url": "https://files.pythonhosted.org/packages/d0/56/cbed0e39a5dcf9ca2302984b8e369990af3919983c949843ee8a645b160a/gan-lab-0.2.3.tar.gz", "yanked": false}], "0.2.4": [{"comment_text": "", "digests": {"md5": "8073e67dfdd7be5bfa3ed7a8b1f67f87", "sha256": "b842a815513507e65ae788f94b0307d12f0889269a84fd95c84ffef6809bab77"}, "downloads": -1, "filename": "gan-lab-0.2.4.tar.gz", "has_sig": false, "md5_digest": "8073e67dfdd7be5bfa3ed7a8b1f67f87", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 70480, "upload_time": "2020-03-25T17:59:57", "upload_time_iso_8601": "2020-03-25T17:59:57.562763Z", "url": "https://files.pythonhosted.org/packages/41/d7/32e3e9e72913a5aededf9e355c90044e833dea6374cb52cb20061286fa06/gan-lab-0.2.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "8073e67dfdd7be5bfa3ed7a8b1f67f87", "sha256": "b842a815513507e65ae788f94b0307d12f0889269a84fd95c84ffef6809bab77"}, "downloads": -1, "filename": "gan-lab-0.2.4.tar.gz", "has_sig": false, "md5_digest": "8073e67dfdd7be5bfa3ed7a8b1f67f87", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 70480, "upload_time": "2020-03-25T17:59:57", "upload_time_iso_8601": "2020-03-25T17:59:57.562763Z", "url": "https://files.pythonhosted.org/packages/41/d7/32e3e9e72913a5aededf9e355c90044e833dea6374cb52cb20061286fa06/gan-lab-0.2.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:59:10 2020"}