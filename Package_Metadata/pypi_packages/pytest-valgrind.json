{"info": {"author": "Sebastian Berg", "author_email": "sebastian@sipsolutions.net", "bugtrack_url": null, "classifiers": ["Framework :: Pytest", "License :: OSI Approved :: MIT License"], "description": "Valgrind testing helper for pytest\n==================================\n\nThis is much of a hack, but it can help you test a C extension module with\nvalgrind. In particular if you are interested in checking for memory leaks.\n\nWhen might I want to use this?:\n  * You have a non-trivial C-extention and should really check it with valgrind.\n  * You have a non-trivial C-extention module that does memory allocations\n    and might leak memory.\n  * You are interested not only in reference count leaks (for which other tools\n    are probably be better). Or hope valgrind can give you some information on the leak.\n  * You are looking for a simple way to get an overview over which tests cause\n    errors detected by valgrind.\n\nWhy not just run the test in valgrind?:\n  * Memory leak checking on valgrind is normally done only at exit. This\n    will run a leak check after every test allowing you to narrow down where\n    a leak occurs without additional effort.\n  * This reports which test fails valgrind and the exact error associated\n    with it. So it may be a bit more convenient\n\nWhy should I not use this?:\n  * It is a a hack with you passing in the valgrind log file to pytest\n    (if you want a helpful error summary).\n  * The error reporting probably has some quirks and hides normal errors.\n  * You want to inspect the full valgrind information and this way you are\n    more likely to miss errors that only show up between tests (e.g. module\n    import/teardown).\n\n**Testing for memory leaks after every test seems to be a bit flaky and\nincreadibly slow. Also I do not know the details well enough to be sure that\nthere are no other issues.**\n\n\nHow to use the plugin\n---------------------\n\nTo use this module, you need to first install it using `pip install .` or\n`pip install . --user`. It currently only supports Python 3 and requires\na C compiler as well as typical valgrind installation (`valgrind/valgrind.h`).\n\nTo then use it, use a normal pytest invocation giving the `--valgrind` option,\nhowever, you also need to run everything in valgrind itself.\n\nThe easiest way to do this is (requires python 3.6 I believe) is the sample\ninvocation below (or similar pytest command). There is an example test in the\n`example` subfolder, which includes a similar invocation as documentation:\n```\nPYTHONMALLOC=malloc valgrind --show-leak-kinds=definite --log-file=/tmp/valgrind-output \\\n    python -m pytest -vv --valgrind --valgrind-log=/tmp/valgrind-output\n```\n\nNote that the `PYTHONMALLOC=malloc` command is crucial (and only works on newer\npython versions). Alternatively, a python debug build with the `--valgrind`\noption can be used. If neither is used, the output will be useless due to\nfalse positives by python (suppression could be added, but are less reliable).\n*It is the responsibility of the caller to pass the correct valgrind arguments.\nyou must pass `--show-leak-kinds=definite` and should use `--log-file` as above!*\n\nYou should provide a log file in this invocation and pass it into pytest. Otherwise\n`pytest-valgrind` will not be able to provide a nice error report. Any normal failures\nwill be skipped. For example in numpy, typically the floating point errors\nfail to report, which causes test failures.\n\nAny valgrind error or memory leak occuring *during* the test will lead to the\ntest being recorded as *FAILURE*. You will have to search the valgrind log\nfile for the specific error.\n\nAs a further example, one may run an individual NumPy test file with the following\ncommend (some of these options are not necessary):\n```\nPYTHONMALLOC=malloc valgrind --show-leak-kinds=definite --log-file=/tmp/valgrind-output python runtests.py -g -t numpy/core/tests/test_dtype.py -- -vv --valgrind --valgrind-log=/tmp/valgrind-output --continue-on-collection-errors\n```\n\n### Options\n\n* `--valgrind` enables the plugin.\n* `--valgrind-log=<log_file>` Should be given. This is the same file passed to\n  valgrind as `--log-file=<log_file>`. If not given, the error reports do not\n  include any valgrind output.\n* `--no-memcheck` will disable checking for memory leaks after every function\n  call (or actually at all). If you are sure there are no leaks, this might\n  speed up execution.\n* `--memcheck-before-func` will run a memory check before each test call. This\n  should not be necessary, so maybe should be removed again.\n\n\nReported failures and marking tests\n-----------------------------------\n\nThis plugin ignores all normal exceptions and replaces them with `KNOWNFAIL`/`xfail`\nright now. It will report failures only for errors/leaks reported by valgrind.\nIt seems that known failures that produce valgrind errors are also reported as known failure.\n\nYou can mark tests with `pytest.mark.valgrind_known_leak(reason=\"?!\")`\nor `pytest.mark.valgrind_known_error(reason=\"Oooops\")` (or both) to make the test result\nan `xfail` specifically for this plugin and specific to either leaks or other errors\nreported by valgrind.\n\nNot all errors are necessarily due to your own code, sometimes false positives can be reported\nfrom known good functions. For example `strcmp` can do this if the valgrind suppressions are not\nup to date. Such failures should be fixed with a valgrind suppression file and not using\npytest markers.\n\n\nNotes, Caveats, and Solutions\n-----------------------------\n\nPlease check the valgrind documentation if you wish to modify your output.\nValgrind starts hiding duplicate errors, so if is highlighted as an error\nbut there is no error in the valgrind output, it might be that the error\nis a repetition of a previous one and thus hidden.\n\nFurter notes:\n\n  * If valgrind has bad interaction causing errors during test gathering\n    this may hang pytest. In that case, you may use\n    `--continue-on-collection-errors` as a quick workaround.\n  * Testing leaks this often slows down testing even more compared to a\n    simple run with valgrind.\n  * It does not seem too elegant, since a valgrind output file is passed\n    to the pytest as an argument.\n  * If you do not have useful function names in your output maybe you did\n    not build a debug build?\n  * Valgrind has lots of options, please check them!\n  * No, I did not check this on different systems/compilers. So if it\n    breaks, you may have to modify the code or setup.py.\n  * By default checks for leaks once before the first test and once after\n    every test. This means:\n       - Leaks occuring before any test is run are not reported!\n       - Leaks should not really occur between tests, but if they do they\n         are reported for the next test.\n  * If your program has caches (e.g. numpy has a small array cache) this might\n    cause leaks to behave non-deterministic, or the object that is being leaked\n    not correspond to the actual leaked object (since the allocation occured\n    originally for another object).\n  * The tool runs the garbage collector before every leak check.\n    This is done only once though (gc runs may need longer to\n    settle, could be fixed to iterate until no change occurs).\n  * I do not know pytest plugins well (and the documentation is not super\n    easy at the time), so a lot of how the pytest things are done can and\n    should probably be much done better.\n\n\nI do not like this or have a better version!\n--------------------------------------------\n\nSure, feel free to create pull requests, if you have something better I will\nbe happy to remove/rename this.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/fridex/pytest-valgrind", "keywords": "", "license": "", "maintainer": "Fridolin Pokorny", "maintainer_email": "fridex.devel@gmail.com", "name": "pytest-valgrind", "package_url": "https://pypi.org/project/pytest-valgrind/", "platform": "", "project_url": "https://pypi.org/project/pytest-valgrind/", "project_urls": {"Homepage": "https://github.com/fridex/pytest-valgrind"}, "release_url": "https://pypi.org/project/pytest-valgrind/0.1.0/", "requires_dist": null, "requires_python": "", "summary": "", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Valgrind testing helper for pytest</h1>\n<p>This is much of a hack, but it can help you test a C extension module with\nvalgrind. In particular if you are interested in checking for memory leaks.</p>\n<p>When might I want to use this?:</p>\n<ul>\n<li>You have a non-trivial C-extention and should really check it with valgrind.</li>\n<li>You have a non-trivial C-extention module that does memory allocations\nand might leak memory.</li>\n<li>You are interested not only in reference count leaks (for which other tools\nare probably be better). Or hope valgrind can give you some information on the leak.</li>\n<li>You are looking for a simple way to get an overview over which tests cause\nerrors detected by valgrind.</li>\n</ul>\n<p>Why not just run the test in valgrind?:</p>\n<ul>\n<li>Memory leak checking on valgrind is normally done only at exit. This\nwill run a leak check after every test allowing you to narrow down where\na leak occurs without additional effort.</li>\n<li>This reports which test fails valgrind and the exact error associated\nwith it. So it may be a bit more convenient</li>\n</ul>\n<p>Why should I not use this?:</p>\n<ul>\n<li>It is a a hack with you passing in the valgrind log file to pytest\n(if you want a helpful error summary).</li>\n<li>The error reporting probably has some quirks and hides normal errors.</li>\n<li>You want to inspect the full valgrind information and this way you are\nmore likely to miss errors that only show up between tests (e.g. module\nimport/teardown).</li>\n</ul>\n<p><strong>Testing for memory leaks after every test seems to be a bit flaky and\nincreadibly slow. Also I do not know the details well enough to be sure that\nthere are no other issues.</strong></p>\n<h2>How to use the plugin</h2>\n<p>To use this module, you need to first install it using <code>pip install .</code> or\n<code>pip install . --user</code>. It currently only supports Python 3 and requires\na C compiler as well as typical valgrind installation (<code>valgrind/valgrind.h</code>).</p>\n<p>To then use it, use a normal pytest invocation giving the <code>--valgrind</code> option,\nhowever, you also need to run everything in valgrind itself.</p>\n<p>The easiest way to do this is (requires python 3.6 I believe) is the sample\ninvocation below (or similar pytest command). There is an example test in the\n<code>example</code> subfolder, which includes a similar invocation as documentation:</p>\n<pre><code>PYTHONMALLOC=malloc valgrind --show-leak-kinds=definite --log-file=/tmp/valgrind-output \\\n    python -m pytest -vv --valgrind --valgrind-log=/tmp/valgrind-output\n</code></pre>\n<p>Note that the <code>PYTHONMALLOC=malloc</code> command is crucial (and only works on newer\npython versions). Alternatively, a python debug build with the <code>--valgrind</code>\noption can be used. If neither is used, the output will be useless due to\nfalse positives by python (suppression could be added, but are less reliable).\n<em>It is the responsibility of the caller to pass the correct valgrind arguments.\nyou must pass <code>--show-leak-kinds=definite</code> and should use <code>--log-file</code> as above!</em></p>\n<p>You should provide a log file in this invocation and pass it into pytest. Otherwise\n<code>pytest-valgrind</code> will not be able to provide a nice error report. Any normal failures\nwill be skipped. For example in numpy, typically the floating point errors\nfail to report, which causes test failures.</p>\n<p>Any valgrind error or memory leak occuring <em>during</em> the test will lead to the\ntest being recorded as <em>FAILURE</em>. You will have to search the valgrind log\nfile for the specific error.</p>\n<p>As a further example, one may run an individual NumPy test file with the following\ncommend (some of these options are not necessary):</p>\n<pre><code>PYTHONMALLOC=malloc valgrind --show-leak-kinds=definite --log-file=/tmp/valgrind-output python runtests.py -g -t numpy/core/tests/test_dtype.py -- -vv --valgrind --valgrind-log=/tmp/valgrind-output --continue-on-collection-errors\n</code></pre>\n<h3>Options</h3>\n<ul>\n<li><code>--valgrind</code> enables the plugin.</li>\n<li><code>--valgrind-log=&lt;log_file&gt;</code> Should be given. This is the same file passed to\nvalgrind as <code>--log-file=&lt;log_file&gt;</code>. If not given, the error reports do not\ninclude any valgrind output.</li>\n<li><code>--no-memcheck</code> will disable checking for memory leaks after every function\ncall (or actually at all). If you are sure there are no leaks, this might\nspeed up execution.</li>\n<li><code>--memcheck-before-func</code> will run a memory check before each test call. This\nshould not be necessary, so maybe should be removed again.</li>\n</ul>\n<h2>Reported failures and marking tests</h2>\n<p>This plugin ignores all normal exceptions and replaces them with <code>KNOWNFAIL</code>/<code>xfail</code>\nright now. It will report failures only for errors/leaks reported by valgrind.\nIt seems that known failures that produce valgrind errors are also reported as known failure.</p>\n<p>You can mark tests with <code>pytest.mark.valgrind_known_leak(reason=\"?!\")</code>\nor <code>pytest.mark.valgrind_known_error(reason=\"Oooops\")</code> (or both) to make the test result\nan <code>xfail</code> specifically for this plugin and specific to either leaks or other errors\nreported by valgrind.</p>\n<p>Not all errors are necessarily due to your own code, sometimes false positives can be reported\nfrom known good functions. For example <code>strcmp</code> can do this if the valgrind suppressions are not\nup to date. Such failures should be fixed with a valgrind suppression file and not using\npytest markers.</p>\n<h2>Notes, Caveats, and Solutions</h2>\n<p>Please check the valgrind documentation if you wish to modify your output.\nValgrind starts hiding duplicate errors, so if is highlighted as an error\nbut there is no error in the valgrind output, it might be that the error\nis a repetition of a previous one and thus hidden.</p>\n<p>Furter notes:</p>\n<ul>\n<li>If valgrind has bad interaction causing errors during test gathering\nthis may hang pytest. In that case, you may use\n<code>--continue-on-collection-errors</code> as a quick workaround.</li>\n<li>Testing leaks this often slows down testing even more compared to a\nsimple run with valgrind.</li>\n<li>It does not seem too elegant, since a valgrind output file is passed\nto the pytest as an argument.</li>\n<li>If you do not have useful function names in your output maybe you did\nnot build a debug build?</li>\n<li>Valgrind has lots of options, please check them!</li>\n<li>No, I did not check this on different systems/compilers. So if it\nbreaks, you may have to modify the code or setup.py.</li>\n<li>By default checks for leaks once before the first test and once after\nevery test. This means:\n<ul>\n<li>Leaks occuring before any test is run are not reported!</li>\n<li>Leaks should not really occur between tests, but if they do they\nare reported for the next test.</li>\n</ul>\n</li>\n<li>If your program has caches (e.g. numpy has a small array cache) this might\ncause leaks to behave non-deterministic, or the object that is being leaked\nnot correspond to the actual leaked object (since the allocation occured\noriginally for another object).</li>\n<li>The tool runs the garbage collector before every leak check.\nThis is done only once though (gc runs may need longer to\nsettle, could be fixed to iterate until no change occurs).</li>\n<li>I do not know pytest plugins well (and the documentation is not super\neasy at the time), so a lot of how the pytest things are done can and\nshould probably be much done better.</li>\n</ul>\n<h2>I do not like this or have a better version!</h2>\n<p>Sure, feel free to create pull requests, if you have something better I will\nbe happy to remove/rename this.</p>\n\n          </div>"}, "last_serial": 6813461, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "a2e46f6e54db71414dd51859acb846cd", "sha256": "eede955affac2ab9f6cd554489c7dc5259ed12519364338b02c3624b1f18ac24"}, "downloads": -1, "filename": "pytest-valgrind-0.1.0.tar.gz", "has_sig": false, "md5_digest": "a2e46f6e54db71414dd51859acb846cd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8135, "upload_time": "2020-03-15T00:33:10", "upload_time_iso_8601": "2020-03-15T00:33:10.635167Z", "url": "https://files.pythonhosted.org/packages/f7/99/19bdba7754166f9b3bfe39e4cfa0d275e92b8cc740043f4f08b569e2ed17/pytest-valgrind-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "a2e46f6e54db71414dd51859acb846cd", "sha256": "eede955affac2ab9f6cd554489c7dc5259ed12519364338b02c3624b1f18ac24"}, "downloads": -1, "filename": "pytest-valgrind-0.1.0.tar.gz", "has_sig": false, "md5_digest": "a2e46f6e54db71414dd51859acb846cd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8135, "upload_time": "2020-03-15T00:33:10", "upload_time_iso_8601": "2020-03-15T00:33:10.635167Z", "url": "https://files.pythonhosted.org/packages/f7/99/19bdba7754166f9b3bfe39e4cfa0d275e92b8cc740043f4f08b569e2ed17/pytest-valgrind-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:54:36 2020"}