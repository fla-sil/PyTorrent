{"info": {"author": "Roboy", "author_email": "", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: BSD License", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "![# Sonosco](docs/source/imgs/sonosco_3.jpg)\n<br>\n<br>\n<br>\n<br>\n\nSonosco (from Lat. sonus - sound and n\u014dsc\u014d - I know, recognize) \nis a library for training and deploying deep speech recognition models.\n\nThe goal of this project is to enable fast, repeatable and structured training of deep \nautomatic speech recognition (ASR) models as well as providing a transcription server (REST API & frontend) to \ntry out the trained models for transcription. <br>\nAdditionally, we provide interfaces to ROS in order to use it with \nthe anthropomimetic robot [Roboy](https://roboy.org/).\n<br>\n<br>\n<br>\n\n___\n### Installation\n\n#### Via pip\nThe easiest way to use Sonosco's functionality is via pip:\n```\npip install sonosco\n```\n**Note**: Sonosco requires Python 3.6 or higher.\n\nFor reliability, we recommend using an environment virtualization tool, like virtualenv or conda.\n\n<br>\n<br>\n\n#### For developers or trying out the transcription server\n\nClone the repository and install dependencies:\n```\n# Clone the repo and cd inside it\ngit clone https://github.com/Roboy/sonosco.git && cd sonosco\n\n# Create a virtual python environment to not pollute the global setup\npython -m venv venv\n\n# Activate the virtual environment\nsource venv/bin/activate\n\n# Install normal requirements\npip install -r requirements.txt\n\n# Link your local sonosco clone into your virtual environment\npip install -e .\n```\nNow you can check out some of the [Getting Started](#getting_started) tutorials, to train a model or use \nthe transcription server.\n<br>\n<br>\n<br>\n____________\n### Quick Start\n<a name=\"start\" class=\"anchor\"></a>\n#### Dockerized inference server\n\nGet the hold of our new fully trained models from the latest release! Try out the LAS model for the best performance.\nThen specify the folder with the model to the runner script as shown underneath.\n\nYou can get the docker image from dockerhub under `yuriyarabskyy/sonosco-inference:1.0`. Just run\n`cd server && ./run.sh yuriyarabskyy/sonosco-inference:1.0` to pull and start the server or\noptionally build your own image by executing the following commands.\n\n```\ncd server\n\n# Build the docker image\n./build.sh\n\n# Run the built image\n./run.sh sonosco_server\n```\n\nYou can also specify the path to your own models by writing\n`./run.sh <image_name> <path/to/models>`.\n\nOpen http://localhost:5000 in Chrome. You should be able to add models for performing\ntranscription by clicking on the plus button. Once the models are added, record your own\nvoice by clicking on the record button. You can replay and transcribe with the\ncorresponding buttons.\n\nYou can get pretrained models from the release tab in this repository.\n____________\n### High Level Design\n\n\n![# High-Level-Design](docs/source/imgs/high-level-design.svg)\n\nThe project is split into 4 parts that correlate with each other:\n\nFor data(-processing) scripts are provided to download and preprocess \nsome publicly available datasets for speech recognition. Additionally, \nwe provide scripts and functions to create manifest files \n(i.e. catalog files) for your own data and merge existing manifest files\ninto one.\n\nThis data or rather the manifest files can then be used to easily train and \nevaluate an ASR model. We provide some ASR model architectures, such as LAS, \nTDS and DeepSpeech2 but also individual pytorch models can be designed to be trained.\n\nThe trained model can then be used in a transcription server, that consists \nof a REST API as well as a simple Vue.js frontend to transcribe voice recorded \nby a microphone and compare the transcription results to other models (that can\nbe downloaded in our [Github](https://github.com/Roboy/sonosco/releases) repository).\n\nFurther we provide example code, how to use different ASR models with ROS\nand especially the Roboy ROS interfaces (i.e. topics & messages).\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Roboy/sonosco/tree/demo", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "sonosco", "package_url": "https://pypi.org/project/sonosco/", "platform": "", "project_url": "https://pypi.org/project/sonosco/", "project_urls": {"Homepage": "https://github.com/Roboy/sonosco/tree/demo"}, "release_url": "https://pypi.org/project/sonosco/1.0.1/", "requires_dist": ["audioread (==2.1.7)", "cycler (==0.10.0)", "decorator (==4.4.0)", "joblib (==0.13.2)", "kiwisolver (==1.1.0)", "librosa (==0.6.3)", "llvmlite (==0.28.0)", "matplotlib (==3.1.0)", "numba (==0.43.1)", "numpy (==1.16.3)", "Pillow (==6.0.0)", "pyparsing (==2.4.0)", "python-dateutil (==2.8.0)", "resampy (==0.2.1)", "scikit-learn (==0.21.2)", "scipy (==1.3.0)", "six (==1.12.0)", "torch (==1.2.0)", "torchvision (==0.3.0)", "tqdm (==4.32.1)", "pyyaml (==5.1)", "wget (==3.2)", "pytest (==4.6.3)", "click (==7.0)", "deprecation (==2.0.6)", "dataclasses (==0.6)", "Flask", "Flask-Cors", "Flask-SocketIO", "azure-cognitiveservices-speech (==1.5.0)", "tb-nightly (==1.15.0a20190802)", "future (==0.17.1)", "python-levenshtein"], "requires_python": ">=3.6", "summary": "Framework for training deep automatic speech recognition models.", "version": "1.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><img alt=\"# Sonosco\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3db2045442c22ca98578bd127e0dd6920c0c06db/646f63732f736f757263652f696d67732f736f6e6f73636f5f332e6a7067\">\n<br>\n<br>\n<br>\n<br></p>\n<p>Sonosco (from Lat. sonus - sound and n\u014dsc\u014d - I know, recognize)\nis a library for training and deploying deep speech recognition models.</p>\n<p>The goal of this project is to enable fast, repeatable and structured training of deep\nautomatic speech recognition (ASR) models as well as providing a transcription server (REST API &amp; frontend) to\ntry out the trained models for transcription. <br>\nAdditionally, we provide interfaces to ROS in order to use it with\nthe anthropomimetic robot <a href=\"https://roboy.org/\" rel=\"nofollow\">Roboy</a>.\n<br>\n<br>\n<br></p>\n<hr>\n<h3>Installation</h3>\n<h4>Via pip</h4>\n<p>The easiest way to use Sonosco's functionality is via pip:</p>\n<pre><code>pip install sonosco\n</code></pre>\n<p><strong>Note</strong>: Sonosco requires Python 3.6 or higher.</p>\n<p>For reliability, we recommend using an environment virtualization tool, like virtualenv or conda.</p>\n<br>\n<br>\n<h4>For developers or trying out the transcription server</h4>\n<p>Clone the repository and install dependencies:</p>\n<pre><code># Clone the repo and cd inside it\ngit clone https://github.com/Roboy/sonosco.git &amp;&amp; cd sonosco\n\n# Create a virtual python environment to not pollute the global setup\npython -m venv venv\n\n# Activate the virtual environment\nsource venv/bin/activate\n\n# Install normal requirements\npip install -r requirements.txt\n\n# Link your local sonosco clone into your virtual environment\npip install -e .\n</code></pre>\n<p>Now you can check out some of the <a href=\"#getting_started\" rel=\"nofollow\">Getting Started</a> tutorials, to train a model or use\nthe transcription server.\n<br>\n<br>\n<br></p>\n<hr>\n<h3>Quick Start</h3>\n<p><a></a></p>\n<h4>Dockerized inference server</h4>\n<p>Get the hold of our new fully trained models from the latest release! Try out the LAS model for the best performance.\nThen specify the folder with the model to the runner script as shown underneath.</p>\n<p>You can get the docker image from dockerhub under <code>yuriyarabskyy/sonosco-inference:1.0</code>. Just run\n<code>cd server &amp;&amp; ./run.sh yuriyarabskyy/sonosco-inference:1.0</code> to pull and start the server or\noptionally build your own image by executing the following commands.</p>\n<pre><code>cd server\n\n# Build the docker image\n./build.sh\n\n# Run the built image\n./run.sh sonosco_server\n</code></pre>\n<p>You can also specify the path to your own models by writing\n<code>./run.sh &lt;image_name&gt; &lt;path/to/models&gt;</code>.</p>\n<p>Open <a href=\"http://localhost:5000\" rel=\"nofollow\">http://localhost:5000</a> in Chrome. You should be able to add models for performing\ntranscription by clicking on the plus button. Once the models are added, record your own\nvoice by clicking on the record button. You can replay and transcribe with the\ncorresponding buttons.</p>\n<p>You can get pretrained models from the release tab in this repository.</p>\n<hr>\n<h3>High Level Design</h3>\n<p><img alt=\"# High-Level-Design\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d5d6a8eb9b8fbe88ecd9fa21216f8b78b1037c74/646f63732f736f757263652f696d67732f686967682d6c6576656c2d64657369676e2e737667\"></p>\n<p>The project is split into 4 parts that correlate with each other:</p>\n<p>For data(-processing) scripts are provided to download and preprocess\nsome publicly available datasets for speech recognition. Additionally,\nwe provide scripts and functions to create manifest files\n(i.e. catalog files) for your own data and merge existing manifest files\ninto one.</p>\n<p>This data or rather the manifest files can then be used to easily train and\nevaluate an ASR model. We provide some ASR model architectures, such as LAS,\nTDS and DeepSpeech2 but also individual pytorch models can be designed to be trained.</p>\n<p>The trained model can then be used in a transcription server, that consists\nof a REST API as well as a simple Vue.js frontend to transcribe voice recorded\nby a microphone and compare the transcription results to other models (that can\nbe downloaded in our <a href=\"https://github.com/Roboy/sonosco/releases\" rel=\"nofollow\">Github</a> repository).</p>\n<p>Further we provide example code, how to use different ASR models with ROS\nand especially the Roboy ROS interfaces (i.e. topics &amp; messages).</p>\n\n          </div>"}, "last_serial": 5903934, "releases": {"0.1.1": [{"comment_text": "", "digests": {"md5": "f801074eaece5fd1df7357c4355e09ac", "sha256": "a48c286beab8365ab40effb5a3221d93b97f4e5de2f3cf7c057a33237824858e"}, "downloads": -1, "filename": "sonosco-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "f801074eaece5fd1df7357c4355e09ac", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 86652, "upload_time": "2019-09-01T14:23:03", "upload_time_iso_8601": "2019-09-01T14:23:03.728001Z", "url": "https://files.pythonhosted.org/packages/cb/fb/bb97bd7463fd91968c54a3da10527efca43e80d3122e4d4b2dced3305940/sonosco-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e18246b8d2a81f1d26b4fa340896b5d4", "sha256": "397689fad9067449f8463a4a1c521fadbd9964324c185def1a3d1c8e83f7f024"}, "downloads": -1, "filename": "sonosco-0.1.1.tar.gz", "has_sig": false, "md5_digest": "e18246b8d2a81f1d26b4fa340896b5d4", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 51754, "upload_time": "2019-09-01T14:23:05", "upload_time_iso_8601": "2019-09-01T14:23:05.149783Z", "url": "https://files.pythonhosted.org/packages/df/5f/e258babd73ee07fe74bbc93babe2c8b11f7fe391fa23bce715a245b1ba5f/sonosco-0.1.1.tar.gz", "yanked": false}], "1.0.0": [{"comment_text": "", "digests": {"md5": "b0dde0b0662b8e728c349e568b82eb02", "sha256": "8e67d4fbc5a409d08435adfec46115daadb17099088eca525031a583ae92ac45"}, "downloads": -1, "filename": "sonosco-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "b0dde0b0662b8e728c349e568b82eb02", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 126294, "upload_time": "2019-09-29T22:04:44", "upload_time_iso_8601": "2019-09-29T22:04:44.965925Z", "url": "https://files.pythonhosted.org/packages/a3/a5/54d95618ee9fb362fbb8a4a1f516c01dfb7663254254c2121be559e3905d/sonosco-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4215e239509310bba3a6586970792b9e", "sha256": "2ea161bc19e94b9e6ff746b754bf0ce3a73beab1822156072c26874400ef0958"}, "downloads": -1, "filename": "sonosco-1.0.0.tar.gz", "has_sig": false, "md5_digest": "4215e239509310bba3a6586970792b9e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 56194, "upload_time": "2019-09-29T22:04:47", "upload_time_iso_8601": "2019-09-29T22:04:47.093707Z", "url": "https://files.pythonhosted.org/packages/6d/83/08f4d60416c2de93102249226ba9eb03ff12de908a052a279bf32415eae8/sonosco-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "0bfcba21f9abefa368251a2617aff7d9", "sha256": "dbcae42073dc2fa2eb48f2e05f8f0a2262a57773536b9cf0356c91d49ec764e7"}, "downloads": -1, "filename": "sonosco-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "0bfcba21f9abefa368251a2617aff7d9", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 130327, "upload_time": "2019-09-29T22:17:42", "upload_time_iso_8601": "2019-09-29T22:17:42.689973Z", "url": "https://files.pythonhosted.org/packages/7a/35/4afbf9b5443d11253cbdc90d70bd0f5982b00705e14553cbf6aa6a9b293d/sonosco-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fe751df5666739a9d025a99f8aa78c7d", "sha256": "7a4e6563e18a77d93bd436e6b3afdaca9c48bebc72d3b5016255b7b78b156451"}, "downloads": -1, "filename": "sonosco-1.0.1.tar.gz", "has_sig": false, "md5_digest": "fe751df5666739a9d025a99f8aa78c7d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 57762, "upload_time": "2019-09-29T22:17:45", "upload_time_iso_8601": "2019-09-29T22:17:45.346134Z", "url": "https://files.pythonhosted.org/packages/a7/f6/2216ec693c880176d5316628095c88dcff21e03364572261cde4c575414c/sonosco-1.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "0bfcba21f9abefa368251a2617aff7d9", "sha256": "dbcae42073dc2fa2eb48f2e05f8f0a2262a57773536b9cf0356c91d49ec764e7"}, "downloads": -1, "filename": "sonosco-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "0bfcba21f9abefa368251a2617aff7d9", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 130327, "upload_time": "2019-09-29T22:17:42", "upload_time_iso_8601": "2019-09-29T22:17:42.689973Z", "url": "https://files.pythonhosted.org/packages/7a/35/4afbf9b5443d11253cbdc90d70bd0f5982b00705e14553cbf6aa6a9b293d/sonosco-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fe751df5666739a9d025a99f8aa78c7d", "sha256": "7a4e6563e18a77d93bd436e6b3afdaca9c48bebc72d3b5016255b7b78b156451"}, "downloads": -1, "filename": "sonosco-1.0.1.tar.gz", "has_sig": false, "md5_digest": "fe751df5666739a9d025a99f8aa78c7d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 57762, "upload_time": "2019-09-29T22:17:45", "upload_time_iso_8601": "2019-09-29T22:17:45.346134Z", "url": "https://files.pythonhosted.org/packages/a7/f6/2216ec693c880176d5316628095c88dcff21e03364572261cde4c575414c/sonosco-1.0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:06:36 2020"}