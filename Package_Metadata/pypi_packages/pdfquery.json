{"info": {"author": "Jack Cushman", "author_email": "jcushman@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.6", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Topic :: Text Processing", "Topic :: Utilities"], "description": "========\nPDFQuery\n========\n------------------------------------------------------------\nConcise, friendly PDF scraping using JQuery or XPath syntax.\n------------------------------------------------------------\n\n.. image:: https://travis-ci.org/jcushman/pdfquery.png\n   :alt: Build Status\n   :target: https://travis-ci.org/jcushman/pdfquery\n   \nPDFQuery is a light wrapper around pdfminer, lxml and pyquery. It's designed to reliably extract data from sets of\nPDFs with as little code as possible.\n\n.. contents:: **Table of Contents**\n\nInstallation\n============\n\n``easy_install pdfquery`` or ``pip install pdfquery``.\n\nQuick Start\n===========\n\nThe basic idea is to transform a PDF document into an element tree so we can find items with JQuery-like selectors\nusing pyquery. Suppose we're trying to extract a name from a set of PDFs, but all we know is that it appears\nunderneath the words \"Your first name and initial\" in each PDF::\n\n    >>> pdf = pdfquery.PDFQuery(\"tests/samples/IRS_1040A.pdf\")\n    >>> pdf.load()\n    >>> label = pdf.pq('LTTextLineHorizontal:contains(\"Your first name and initial\")')\n    >>> left_corner = float(label.attr('x0'))\n    >>> bottom_corner = float(label.attr('y0'))\n    >>> name = pdf.pq('LTTextLineHorizontal:in_bbox(\"%s, %s, %s, %s\")' % (left_corner, bottom_corner-30, left_corner+150, bottom_corner)).text()\n    >>> name\n    'John E.'\n\nNote that we don't have to know where the name is on the page, or what page it's on,\nor how the PDF has it stored internally.\n\n*Performance Note:* The initial call to pdf.load() runs very slowly, because the underlying\npdfminer library has to compare every element on the page to every other element.\nSee the Caching section to avoid this on subsequent runs.\n\nNow let's extract and format a bunch of data all at once::\n\n    >>> pdf = pdfquery.PDFQuery(\"tests/samples/IRS_1040A.pdf\")\n    >>> pdf.extract( [\n         ('with_parent','LTPage[pageid=1]'),\n         ('with_formatter', 'text'),\n\n         ('last_name', 'LTTextLineHorizontal:in_bbox(\"315,680,395,700\")'),\n         ('spouse', 'LTTextLineHorizontal:in_bbox(\"170,650,220,680\")'),\n\n         ('with_parent','LTPage[pageid=2]'),\n\n         ('oath', 'LTTextLineHorizontal:contains(\"perjury\")', lambda match: match.text()[:30]+\"...\"),\n         ('year', 'LTTextLineHorizontal:contains(\"Form 1040A (\")', lambda match: int(match.text()[-5:-1]))\n     ])\n\nResult::\n\n    {'last_name': 'Michaels',\n     'spouse': 'Susan R.',\n     'year': 2007,\n     'oath': 'Under penalties of perjury, I ...',}\n\n------\nUsage\n------\n\nData Models\n===========\n\nPDFQuery works by loading a PDF as a pdfminer layout, converting the layout to an etree with lxml.etree,\nand then applying a pyquery wrapper. All three underlying libraries are exposed, so you can use any of their\ninterfaces to get at the data you want.\n\nFirst pdfminer opens the document and reads its layout.\nYou can access the pdfminer document at ``pdf.doc``::\n\n    >>> pdf = pdfquery.PDFQuery(\"tests/samples/IRS_1040A.pdf\")\n    >>> pdf.doc\n    <pdfminer.pdfparser.PDFDocument object at 0xd95c90>\n    >>> pdf.doc.catalog # fetch attribute of underlying pdfminer document\n    {'JT': <PDFObjRef:14>, 'PageLabels': <PDFObjRef:10>, 'Type': /Catalog, 'Pages': <PDFObjRef:12>, 'Metadata': <PDFObjRef:13>}\n\nNext the layout is turned into an lxml.etree with a pyquery wrapper. After you call ``pdf.load()`` (by far the most\nexpensive operation in the process), you can access the etree at ``pdf.tree``, and the pyquery wrapper at ``pdf.pq``::\n\n    >>> pdf.load()\n    >>> pdf.tree\n    <lxml.etree._ElementTree object at 0x106a285f0>\n    >>> pdf.tree.write(\"test2.xml\", pretty_print=True, encoding=\"utf-8\")\n    >>> pdf.tree.xpath('//*/LTPage')\n    [<Element LTPage at 0x994cb0>, <Element LTPage at 0x994a58>]\n    >>> pdf.pq('LTPage[pageid=1] :contains(\"Your first name\")')\n    [<LTTextLineHorizontal>]\n\nYou'll save some time and memory if you call ``load()`` with only the page numbers you need. For example::\n\n    >>> pdf.load(0, 2, 3, range(4,8))\n\n*Performance Note:* The initial call to pdf.load() runs very slowly, because the underlying\npdfminer library has to compare every element on the page to every other element.\nSee the Caching section to avoid this on subsequent runs.\n\nUnder the hood, pdf.tree is basically an XML representation of the layout tree generated by pdfminer.pdfinterp. By\ndefault the tree is processed to combine individual character nodes, remove extra spaces,\nand sort the tree spatially. You can always get back to the original pdfminer Layout object from an element fetched\nby xpath or pyquery::\n\n    >>> pdf.pq(':contains(\"Your first name and initial\")')[0].layout\n    <LTTextLineHorizontal 143.651,714.694,213.083,721.661 u'Your  first  name  and  initial\\n'>\n\nFinding what you want\n=========================\n\nPDFs are internally messy, so it's usually not helpful to find things based on document structure or element classes\nthe way you would with HTML. Instead the most reliable selectors are the static labels on the page,\nwhich you can find by searching for their text contents, and physical location on the page. PDF coordinates are given\nin points (72 to the inch) starting from the bottom left corner. PDFMiner (and so PDFQuery) describes page locations\nin terms of bounding boxes, or bboxes. A bbox consists of four coordinates: the X and Y of the lower left\ncorner, and the X and Y of the upper right corner.\n\nIf you're scraping text that's always in the same place on the page, the easiest way is to use Acrobat Pro's\nMeasurement Tool, Photoshop, or a similar tool to measure distances (in points) from the lower left corner of the\npage, and use those distances to craft a selector like ``:in_bbox(\"x0,y0,x1,y1\")`` (see below for more on ``in_bbox``).\n\nIf you're scraping text that might be in different parts of the page, the same basic technique applies,\nbut you'll first have to find an element with consistent text that appears a consistent distance from the text you\nwant, and then calculate the bbox relative to that element. See the Quick Start for an example of that approach.\n\nIf both of those fail, your best bet is to dump the xml using ```pdf.tree.write(filename, pretty_print=True)```,\nand see if you can find any other structure, tags or elements that reliably identify the part you're looking for.\nThis is also helpful when you're trying to figure out why your selectors don't match ...\n\nCustom Selectors\n====================\n\nThe version of pyquery returned by pdf.pq supports some PDF-specific selectors to find elements by location on the\npage.\n\n* \\:in_bbox(\"x0,y0,x1,y1\"): Matches only elements that fit entirely within the given bbox.\n\n* \\:overlaps_bbox(\"x0,y0,x1,y1\"): Matches any elements that overlap the given bbox.\n\nIf you need a selector that isn't supported, you can write a filtering function returning a boolean::\n\n    >>> def big_elements():\n        return float(this.get('width',0)) * float(this.get('height',0)) > 40000\n    >>> pdf.pq('LTPage[page_index=\"1\"] *').filter(big_elements)\n    [<LTTextBoxHorizontal>, <LTRect>, <LTRect>]\n\n(If you come up with any particularly useful filters, patch them into pdfquery.py as selectors and submit a pull\nrequest ...)\n\nCaching\n====================\n\nPDFQuery accepts an optional caching argument that will store the results of PDF parsing,\nso subsequent runs on the same file will be much quicker. For example::\n\n    from pdfquery.cache import FileCache\n    pdfquery.PDFQuery(\"tests/samples/IRS_1040A.pdf\", parse_tree_cacher=FileCache(\"/tmp/\"))\n\nBulk Data Scraping\n====================\n\nOften you're going to want to grab a bunch of different data from a PDF, using the same repetitive process:\n(1) find an element of the document using a pyquery selector or Xpath; (2) parse the resulting text; and (3) store it\nin a dict to be used later.\n\nThe ``extract`` method simplifies that process. Given a list of keywords and selectors::\n\n    >>> pdf.extract([\n          ('last_name', ':in_bbox(\"315,680,395,700\")'),\n          ('year', ':contains(\"Form 1040A (\")', lambda match: int(match.text()[-5:-1]))\n     ])\n\nthe ```extract``` method returns a dictionary (by default) with a pyquery result set for each keyword,\noptionally processed through the supplied formatting function. In this example the result is::\n\n    {'last_name': [<LTTextLineHorizontal>], 'year': 2007}\n\n(It's often helpful to start with ``('with_formatter', 'text')`` so you get results like \"Michaels\" instead of\n``[<LTTextLineHorizontal>]``. See Special Keywords below for more.)\n\nSearch Target\n~~~~~~~~~~~~~\n\nBy default, ``extract`` searches the entire tree (or the part of the document loaded earlier by ``load()``,\nif it was limited to particular pages). If you want to limit the search to a part of the tree that you fetched with\n``pdf.pq()`` earlier, pass that in as the second parameter after the list of searches.\n\nFormatting Functions\n~~~~~~~~~~~~~~~~~~~~\n\nNotice that the 'year' example above contains an optional third paramater -- a formatting function. The formatting\nfunction will be passed a pyquery match result, so ``lambda match: match.text()`` will return the text contents of the\nmatched elements.\n\nFiltering Functions\n~~~~~~~~~~~~~~~~~~~\n\nInstead of a string, the selector can be a filtering function returning a boolean::\n\n    >>> pdf.extract([('big', big_elements)])\n    {'big': [<LTPage>, <LTTextBoxHorizontal>, <LTRect>, <LTRect>, <LTPage>, <LTTextBoxHorizontal>, <LTRect>]}\n\n(See Custom Selectors above for how to define functions like ``big_elements``.)\n\nSpecial Keywords\n~~~~~~~~~~~~~~~~\n\n``extract`` also looks for two special keywords in the list of searches that set defaults for the searches listed\nafterward. Note that you can include the same special keyword more than once to change the setting, as demonstrated\nin the Quick Start section. The keywords are\\:\n\nwith_parent\n+++++++++++\n\n The ``with_parent`` keyword limits the following searches to children of the parent search. For example::\n\n    >>> pdf.extract([\n         ('with_parent','LTPage[page_index=\"1\"]'),\n         ('last_name', ':in_bbox(\"315,680,395,700\")') # only matches elements on page 1\n     ])\n\nwith_formatter\n++++++++++++++\n\nThe ``with_formatter`` keyword sets a default formatting function that will be called unless a specific one is supplied.\nFor example::\n\n    ('with_formatter', lambda match: int(match.text()))\n\nwill attempt to convert all of the following search results to integers. If you supply a string instead of a function,\nit will be interpreted as a method name to call on the pyquery search results. For example, the following two lines\nare equivalent::\n\n    ('with_formatter', lambda match: match.text())\n    ('with_formatter', 'text')\n\nIf you want to stop filtering results, you can use::\n\n    ('with_formatter', None)\n\n----------------\nObject Reference\n----------------\n\nPublic Methods\n================\n\n::\n\n    PDFQuery(   file,\n                merge_tags=('LTChar', 'LTAnon'),\n                round_floats=True,\n                round_digits=3,\n                input_text_formatter=None,\n                normalize_spaces=True,\n                resort=True,\n                parse_tree_cacher=None,\n                laparams={'all_texts':True, 'detect_vertical':True})\n\nInitialization function. Usually you'll only need to pass in the file (file object or path). The rest of the arguments\ncontrol preprocessing of the element tree:\n\n*   merge_tags: consecutive runs of these elements will be merged together, with the text of following elements\n    appended to the first element. This is useful for keeping the size of the tree down,\n    but it might help to turn it off if you want to select individual characters regardless of their containers.\n\n*   round_floats and round_digits: if round_floats is True, numbers will be rounded to round_digits places. This is\n    almost always good.\n\n*   input_text_formatter: a function that takes a string and returns a modified string,\n    to be applied to the text content of elements.\n\n*   normalize_spaces: if True (and input_text_formatter isn't otherwise set), sets input_text_formatter to replace \\s+\n    with a single space.\n\n*   resort: if True, elements will be sorted such that any element fully within the bounding box of another element\n    becomes a child of that element.\n\n*   parse_tree_cacher: an object that knows how to save and load results of parsing a given page range from a given PDF.\n    Pass in FileCache('/tmp/') to save caches to the filesystem.\n\n*   laparams: parameters for the ``pdfminer.layout.LAParams`` object used to initialize\n    ``pdfminer.converter.PDFPageAggregator``. Can be `dict`, `LAParams()`, or `None`.\n\n::\n\n    extract(    searches,\n                tree=None,\n                as_dict=True)\n\nSee \"Bulk Data Scraping.\"\n\n* searches: list of searches to run, each consisting of a keyword, selector, and optional formatting function.\n* tree: pyquery tree to run searches against. By default, targets entire tree loaded by pdf.load()\n* as_dict: if changed to False, will return a list instead of a dict to preserve the order of the results.\n\n::\n\n    load(*page_numbers)\n\nInitialize the pdf.tree and pdf.pq objects. This will be called implicitly by pdf.extract(),\nbut it's more efficient to call it explicitly with just the page numbers you need. Page numbers can be any\ncombination of integers and lists, e.g. ``pdf.load(0,2,3,[4,5,6],range(10,15))``.\n\nYou can call ``pdf.load(None)`` if for some reason you want to initialize without loading *any* pages\n(like you are only interested in the document info).\n\nPublic But Less Useful Methods\n================================\n\nThese are mostly used internally, but might be helpful sometimes ...\n\n::\n\n    get_layout(page)\n\nGiven a page number (zero-indexed) or pdfminer PDFPage object, return the LTPage layout object for that page.\n\n::\n\n    get_layouts()\n\nReturn list of all layouts (equivalent to calling get_layout() for each page).\n\n::\n\n    get_page(page_number)\n\nGiven a page number, return the appropriate pdfminer PDFPage object.\n\n::\n\n    get_pyquery(tree=None, page_numbers=[])\n\nWrap a given lxml element tree in pyquery.\nIf no tree is supplied, will generate one from given page numbers, or all page numbers.\n\n::\n\n    get_tree(*page_numbers)\n\nGenerate an etree for the given page numbers. ``*page_numbers`` can be the same form as in ``load()``.\n\n\n----------------------------------------\nDocumentation for Underlying Libraries\n----------------------------------------\n\n* PDFMiner (pdf.doc): pdfminer_homepage_, pdfminer_documentation_.\n\n.. _pdfminer_homepage: http://www.unixuser.org/~euske/python/pdfminer/\n.. _pdfminer_documentation: http://www.unixuser.org/~euske/python/pdfminer/programming.html\n\n* LXML.etree (pdf.tree): lxml_homepage_, tutorial_.\n\n.. _lxml_homepage: http://lxml.de/index.html\n.. _tutorial: http://lxml.de/tutorial.html\n\n* PyQuery (pdf.pq): pyquery_documentation_.\n\n.. _pyquery_documentation: http://packages.python.org/pyquery/", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/jcushman/pdfquery", "keywords": "", "license": "MIT", "maintainer": null, "maintainer_email": null, "name": "pdfquery", "package_url": "https://pypi.org/project/pdfquery/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/pdfquery/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/jcushman/pdfquery"}, "release_url": "https://pypi.org/project/pdfquery/0.4.3/", "requires_dist": null, "requires_python": null, "summary": "Concise and friendly PDF scraper using JQuery or XPath selectors.", "version": "0.4.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"concise-friendly-pdf-scraping-using-jquery-or-xpath-syntax\">\n<h2><a href=\"#id1\" rel=\"nofollow\">Concise, friendly PDF scraping using JQuery or XPath syntax.</a></h2>\n<a href=\"https://travis-ci.org/jcushman/pdfquery\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fdefe84e5913bf28671f2277d34ec5cd6e551a27/68747470733a2f2f7472617669732d63692e6f72672f6a637573686d616e2f70646671756572792e706e67\"></a>\n<p>PDFQuery is a light wrapper around pdfminer, lxml and pyquery. It\u2019s designed to reliably extract data from sets of\nPDFs with as little code as possible.</p>\n<div id=\"table-of-contents\">\n<p><strong>Table of Contents</strong></p>\n<ul>\n<li><a href=\"#concise-friendly-pdf-scraping-using-jquery-or-xpath-syntax\" id=\"id1\" rel=\"nofollow\">Concise, friendly PDF scraping using JQuery or XPath syntax.</a><ul>\n<li><a href=\"#installation\" id=\"id2\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#quick-start\" id=\"id3\" rel=\"nofollow\">Quick Start</a></li>\n</ul>\n</li>\n<li><a href=\"#usage\" id=\"id4\" rel=\"nofollow\">Usage</a><ul>\n<li><a href=\"#data-models\" id=\"id5\" rel=\"nofollow\">Data Models</a></li>\n<li><a href=\"#finding-what-you-want\" id=\"id6\" rel=\"nofollow\">Finding what you want</a></li>\n<li><a href=\"#custom-selectors\" id=\"id7\" rel=\"nofollow\">Custom Selectors</a></li>\n<li><a href=\"#caching\" id=\"id8\" rel=\"nofollow\">Caching</a></li>\n<li><a href=\"#bulk-data-scraping\" id=\"id9\" rel=\"nofollow\">Bulk Data Scraping</a><ul>\n<li><a href=\"#search-target\" id=\"id10\" rel=\"nofollow\">Search Target</a></li>\n<li><a href=\"#formatting-functions\" id=\"id11\" rel=\"nofollow\">Formatting Functions</a></li>\n<li><a href=\"#filtering-functions\" id=\"id12\" rel=\"nofollow\">Filtering Functions</a></li>\n<li><a href=\"#special-keywords\" id=\"id13\" rel=\"nofollow\">Special Keywords</a><ul>\n<li><a href=\"#with-parent\" id=\"id14\" rel=\"nofollow\">with_parent</a></li>\n<li><a href=\"#with-formatter\" id=\"id15\" rel=\"nofollow\">with_formatter</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"#object-reference\" id=\"id16\" rel=\"nofollow\">Object Reference</a><ul>\n<li><a href=\"#public-methods\" id=\"id17\" rel=\"nofollow\">Public Methods</a></li>\n<li><a href=\"#public-but-less-useful-methods\" id=\"id18\" rel=\"nofollow\">Public But Less Useful Methods</a></li>\n</ul>\n</li>\n<li><a href=\"#documentation-for-underlying-libraries\" id=\"id19\" rel=\"nofollow\">Documentation for Underlying Libraries</a></li>\n</ul>\n</div>\n<div id=\"installation\">\n<h3><a href=\"#id2\" rel=\"nofollow\">Installation</a></h3>\n<p><tt>easy_install pdfquery</tt> or <tt>pip install pdfquery</tt>.</p>\n</div>\n<div id=\"quick-start\">\n<h3><a href=\"#id3\" rel=\"nofollow\">Quick Start</a></h3>\n<p>The basic idea is to transform a PDF document into an element tree so we can find items with JQuery-like selectors\nusing pyquery. Suppose we\u2019re trying to extract a name from a set of PDFs, but all we know is that it appears\nunderneath the words \u201cYour first name and initial\u201d in each PDF:</p>\n<pre>&gt;&gt;&gt; pdf = pdfquery.PDFQuery(\"tests/samples/IRS_1040A.pdf\")\n&gt;&gt;&gt; pdf.load()\n&gt;&gt;&gt; label = pdf.pq('LTTextLineHorizontal:contains(\"Your first name and initial\")')\n&gt;&gt;&gt; left_corner = float(label.attr('x0'))\n&gt;&gt;&gt; bottom_corner = float(label.attr('y0'))\n&gt;&gt;&gt; name = pdf.pq('LTTextLineHorizontal:in_bbox(\"%s, %s, %s, %s\")' % (left_corner, bottom_corner-30, left_corner+150, bottom_corner)).text()\n&gt;&gt;&gt; name\n'John E.'\n</pre>\n<p>Note that we don\u2019t have to know where the name is on the page, or what page it\u2019s on,\nor how the PDF has it stored internally.</p>\n<p><em>Performance Note:</em> The initial call to pdf.load() runs very slowly, because the underlying\npdfminer library has to compare every element on the page to every other element.\nSee the Caching section to avoid this on subsequent runs.</p>\n<p>Now let\u2019s extract and format a bunch of data all at once:</p>\n<pre>&gt;&gt;&gt; pdf = pdfquery.PDFQuery(\"tests/samples/IRS_1040A.pdf\")\n&gt;&gt;&gt; pdf.extract( [\n     ('with_parent','LTPage[pageid=1]'),\n     ('with_formatter', 'text'),\n\n     ('last_name', 'LTTextLineHorizontal:in_bbox(\"315,680,395,700\")'),\n     ('spouse', 'LTTextLineHorizontal:in_bbox(\"170,650,220,680\")'),\n\n     ('with_parent','LTPage[pageid=2]'),\n\n     ('oath', 'LTTextLineHorizontal:contains(\"perjury\")', lambda match: match.text()[:30]+\"...\"),\n     ('year', 'LTTextLineHorizontal:contains(\"Form 1040A (\")', lambda match: int(match.text()[-5:-1]))\n ])\n</pre>\n<p>Result:</p>\n<pre>{'last_name': 'Michaels',\n 'spouse': 'Susan R.',\n 'year': 2007,\n 'oath': 'Under penalties of perjury, I ...',}\n</pre>\n</div>\n</div>\n<div id=\"usage\">\n<h2><a href=\"#id4\" rel=\"nofollow\">Usage</a></h2>\n<div id=\"data-models\">\n<h3><a href=\"#id5\" rel=\"nofollow\">Data Models</a></h3>\n<p>PDFQuery works by loading a PDF as a pdfminer layout, converting the layout to an etree with lxml.etree,\nand then applying a pyquery wrapper. All three underlying libraries are exposed, so you can use any of their\ninterfaces to get at the data you want.</p>\n<p>First pdfminer opens the document and reads its layout.\nYou can access the pdfminer document at <tt>pdf.doc</tt>:</p>\n<pre>&gt;&gt;&gt; pdf = pdfquery.PDFQuery(\"tests/samples/IRS_1040A.pdf\")\n&gt;&gt;&gt; pdf.doc\n&lt;pdfminer.pdfparser.PDFDocument object at 0xd95c90&gt;\n&gt;&gt;&gt; pdf.doc.catalog # fetch attribute of underlying pdfminer document\n{'JT': &lt;PDFObjRef:14&gt;, 'PageLabels': &lt;PDFObjRef:10&gt;, 'Type': /Catalog, 'Pages': &lt;PDFObjRef:12&gt;, 'Metadata': &lt;PDFObjRef:13&gt;}\n</pre>\n<p>Next the layout is turned into an lxml.etree with a pyquery wrapper. After you call <tt>pdf.load()</tt> (by far the most\nexpensive operation in the process), you can access the etree at <tt>pdf.tree</tt>, and the pyquery wrapper at <tt>pdf.pq</tt>:</p>\n<pre>&gt;&gt;&gt; pdf.load()\n&gt;&gt;&gt; pdf.tree\n&lt;lxml.etree._ElementTree object at 0x106a285f0&gt;\n&gt;&gt;&gt; pdf.tree.write(\"test2.xml\", pretty_print=True, encoding=\"utf-8\")\n&gt;&gt;&gt; pdf.tree.xpath('//*/LTPage')\n[&lt;Element LTPage at 0x994cb0&gt;, &lt;Element LTPage at 0x994a58&gt;]\n&gt;&gt;&gt; pdf.pq('LTPage[pageid=1] :contains(\"Your first name\")')\n[&lt;LTTextLineHorizontal&gt;]\n</pre>\n<p>You\u2019ll save some time and memory if you call <tt>load()</tt> with only the page numbers you need. For example:</p>\n<pre>&gt;&gt;&gt; pdf.load(0, 2, 3, range(4,8))\n</pre>\n<p><em>Performance Note:</em> The initial call to pdf.load() runs very slowly, because the underlying\npdfminer library has to compare every element on the page to every other element.\nSee the Caching section to avoid this on subsequent runs.</p>\n<p>Under the hood, pdf.tree is basically an XML representation of the layout tree generated by pdfminer.pdfinterp. By\ndefault the tree is processed to combine individual character nodes, remove extra spaces,\nand sort the tree spatially. You can always get back to the original pdfminer Layout object from an element fetched\nby xpath or pyquery:</p>\n<pre>&gt;&gt;&gt; pdf.pq(':contains(\"Your first name and initial\")')[0].layout\n&lt;LTTextLineHorizontal 143.651,714.694,213.083,721.661 u'Your  first  name  and  initial\\n'&gt;\n</pre>\n</div>\n<div id=\"finding-what-you-want\">\n<h3><a href=\"#id6\" rel=\"nofollow\">Finding what you want</a></h3>\n<p>PDFs are internally messy, so it\u2019s usually not helpful to find things based on document structure or element classes\nthe way you would with HTML. Instead the most reliable selectors are the static labels on the page,\nwhich you can find by searching for their text contents, and physical location on the page. PDF coordinates are given\nin points (72 to the inch) starting from the bottom left corner. PDFMiner (and so PDFQuery) describes page locations\nin terms of bounding boxes, or bboxes. A bbox consists of four coordinates: the X and Y of the lower left\ncorner, and the X and Y of the upper right corner.</p>\n<p>If you\u2019re scraping text that\u2019s always in the same place on the page, the easiest way is to use Acrobat Pro\u2019s\nMeasurement Tool, Photoshop, or a similar tool to measure distances (in points) from the lower left corner of the\npage, and use those distances to craft a selector like <tt><span class=\"pre\">:in_bbox(\"x0,y0,x1,y1\")</span></tt> (see below for more on <tt>in_bbox</tt>).</p>\n<p>If you\u2019re scraping text that might be in different parts of the page, the same basic technique applies,\nbut you\u2019ll first have to find an element with consistent text that appears a consistent distance from the text you\nwant, and then calculate the bbox relative to that element. See the Quick Start for an example of that approach.</p>\n<p>If both of those fail, your best bet is to dump the xml using <tt>`pdf.tree.write(filename, pretty_print=True)`</tt>,\nand see if you can find any other structure, tags or elements that reliably identify the part you\u2019re looking for.\nThis is also helpful when you\u2019re trying to figure out why your selectors don\u2019t match \u2026</p>\n</div>\n<div id=\"custom-selectors\">\n<h3><a href=\"#id7\" rel=\"nofollow\">Custom Selectors</a></h3>\n<p>The version of pyquery returned by pdf.pq supports some PDF-specific selectors to find elements by location on the\npage.</p>\n<ul>\n<li>:in_bbox(\u201cx0,y0,x1,y1\u201d): Matches only elements that fit entirely within the given bbox.</li>\n<li>:overlaps_bbox(\u201cx0,y0,x1,y1\u201d): Matches any elements that overlap the given bbox.</li>\n</ul>\n<p>If you need a selector that isn\u2019t supported, you can write a filtering function returning a boolean:</p>\n<pre>&gt;&gt;&gt; def big_elements():\n    return float(this.get('width',0)) * float(this.get('height',0)) &gt; 40000\n&gt;&gt;&gt; pdf.pq('LTPage[page_index=\"1\"] *').filter(big_elements)\n[&lt;LTTextBoxHorizontal&gt;, &lt;LTRect&gt;, &lt;LTRect&gt;]\n</pre>\n<p>(If you come up with any particularly useful filters, patch them into pdfquery.py as selectors and submit a pull\nrequest \u2026)</p>\n</div>\n<div id=\"caching\">\n<h3><a href=\"#id8\" rel=\"nofollow\">Caching</a></h3>\n<p>PDFQuery accepts an optional caching argument that will store the results of PDF parsing,\nso subsequent runs on the same file will be much quicker. For example:</p>\n<pre>from pdfquery.cache import FileCache\npdfquery.PDFQuery(\"tests/samples/IRS_1040A.pdf\", parse_tree_cacher=FileCache(\"/tmp/\"))\n</pre>\n</div>\n<div id=\"bulk-data-scraping\">\n<h3><a href=\"#id9\" rel=\"nofollow\">Bulk Data Scraping</a></h3>\n<p>Often you\u2019re going to want to grab a bunch of different data from a PDF, using the same repetitive process:\n(1) find an element of the document using a pyquery selector or Xpath; (2) parse the resulting text; and (3) store it\nin a dict to be used later.</p>\n<p>The <tt>extract</tt> method simplifies that process. Given a list of keywords and selectors:</p>\n<pre>&gt;&gt;&gt; pdf.extract([\n      ('last_name', ':in_bbox(\"315,680,395,700\")'),\n      ('year', ':contains(\"Form 1040A (\")', lambda match: int(match.text()[-5:-1]))\n ])\n</pre>\n<p>the <tt>`extract`</tt> method returns a dictionary (by default) with a pyquery result set for each keyword,\noptionally processed through the supplied formatting function. In this example the result is:</p>\n<pre>{'last_name': [&lt;LTTextLineHorizontal&gt;], 'year': 2007}\n</pre>\n<p>(It\u2019s often helpful to start with <tt>('with_formatter', 'text')</tt> so you get results like \u201cMichaels\u201d instead of\n<tt>[&lt;LTTextLineHorizontal&gt;]</tt>. See Special Keywords below for more.)</p>\n<div id=\"search-target\">\n<h4><a href=\"#id10\" rel=\"nofollow\">Search Target</a></h4>\n<p>By default, <tt>extract</tt> searches the entire tree (or the part of the document loaded earlier by <tt>load()</tt>,\nif it was limited to particular pages). If you want to limit the search to a part of the tree that you fetched with\n<tt>pdf.pq()</tt> earlier, pass that in as the second parameter after the list of searches.</p>\n</div>\n<div id=\"formatting-functions\">\n<h4><a href=\"#id11\" rel=\"nofollow\">Formatting Functions</a></h4>\n<p>Notice that the \u2018year\u2019 example above contains an optional third paramater \u2013 a formatting function. The formatting\nfunction will be passed a pyquery match result, so <tt>lambda match: match.text()</tt> will return the text contents of the\nmatched elements.</p>\n</div>\n<div id=\"filtering-functions\">\n<h4><a href=\"#id12\" rel=\"nofollow\">Filtering Functions</a></h4>\n<p>Instead of a string, the selector can be a filtering function returning a boolean:</p>\n<pre>&gt;&gt;&gt; pdf.extract([('big', big_elements)])\n{'big': [&lt;LTPage&gt;, &lt;LTTextBoxHorizontal&gt;, &lt;LTRect&gt;, &lt;LTRect&gt;, &lt;LTPage&gt;, &lt;LTTextBoxHorizontal&gt;, &lt;LTRect&gt;]}\n</pre>\n<p>(See Custom Selectors above for how to define functions like <tt>big_elements</tt>.)</p>\n</div>\n<div id=\"special-keywords\">\n<h4><a href=\"#id13\" rel=\"nofollow\">Special Keywords</a></h4>\n<p><tt>extract</tt> also looks for two special keywords in the list of searches that set defaults for the searches listed\nafterward. Note that you can include the same special keyword more than once to change the setting, as demonstrated\nin the Quick Start section. The keywords are:</p>\n<div id=\"with-parent\">\n<h5><a href=\"#id14\" rel=\"nofollow\">with_parent</a></h5>\n<blockquote>\n<p>The <tt>with_parent</tt> keyword limits the following searches to children of the parent search. For example:</p>\n<pre>&gt;&gt;&gt; pdf.extract([\n     ('with_parent','LTPage[page_index=\"1\"]'),\n     ('last_name', ':in_bbox(\"315,680,395,700\")') # only matches elements on page 1\n ])\n</pre>\n</blockquote>\n</div>\n<div id=\"with-formatter\">\n<h5><a href=\"#id15\" rel=\"nofollow\">with_formatter</a></h5>\n<p>The <tt>with_formatter</tt> keyword sets a default formatting function that will be called unless a specific one is supplied.\nFor example:</p>\n<pre>('with_formatter', lambda match: int(match.text()))\n</pre>\n<p>will attempt to convert all of the following search results to integers. If you supply a string instead of a function,\nit will be interpreted as a method name to call on the pyquery search results. For example, the following two lines\nare equivalent:</p>\n<pre>('with_formatter', lambda match: match.text())\n('with_formatter', 'text')\n</pre>\n<p>If you want to stop filtering results, you can use:</p>\n<pre>('with_formatter', None)\n</pre>\n</div>\n</div>\n</div>\n</div>\n<div id=\"object-reference\">\n<h2><a href=\"#id16\" rel=\"nofollow\">Object Reference</a></h2>\n<div id=\"public-methods\">\n<h3><a href=\"#id17\" rel=\"nofollow\">Public Methods</a></h3>\n<pre>PDFQuery(   file,\n            merge_tags=('LTChar', 'LTAnon'),\n            round_floats=True,\n            round_digits=3,\n            input_text_formatter=None,\n            normalize_spaces=True,\n            resort=True,\n            parse_tree_cacher=None,\n            laparams={'all_texts':True, 'detect_vertical':True})\n</pre>\n<p>Initialization function. Usually you\u2019ll only need to pass in the file (file object or path). The rest of the arguments\ncontrol preprocessing of the element tree:</p>\n<ul>\n<li>merge_tags: consecutive runs of these elements will be merged together, with the text of following elements\nappended to the first element. This is useful for keeping the size of the tree down,\nbut it might help to turn it off if you want to select individual characters regardless of their containers.</li>\n<li>round_floats and round_digits: if round_floats is True, numbers will be rounded to round_digits places. This is\nalmost always good.</li>\n<li>input_text_formatter: a function that takes a string and returns a modified string,\nto be applied to the text content of elements.</li>\n<li>normalize_spaces: if True (and input_text_formatter isn\u2019t otherwise set), sets input_text_formatter to replace s+\nwith a single space.</li>\n<li>resort: if True, elements will be sorted such that any element fully within the bounding box of another element\nbecomes a child of that element.</li>\n<li>parse_tree_cacher: an object that knows how to save and load results of parsing a given page range from a given PDF.\nPass in FileCache(\u2018/tmp/\u2019) to save caches to the filesystem.</li>\n<li>laparams: parameters for the <tt>pdfminer.layout.LAParams</tt> object used to initialize\n<tt>pdfminer.converter.PDFPageAggregator</tt>. Can be <cite>dict</cite>, <cite>LAParams()</cite>, or <cite>None</cite>.</li>\n</ul>\n<pre>extract(    searches,\n            tree=None,\n            as_dict=True)\n</pre>\n<p>See \u201cBulk Data Scraping.\u201d</p>\n<ul>\n<li>searches: list of searches to run, each consisting of a keyword, selector, and optional formatting function.</li>\n<li>tree: pyquery tree to run searches against. By default, targets entire tree loaded by pdf.load()</li>\n<li>as_dict: if changed to False, will return a list instead of a dict to preserve the order of the results.</li>\n</ul>\n<pre>load(*page_numbers)\n</pre>\n<p>Initialize the pdf.tree and pdf.pq objects. This will be called implicitly by pdf.extract(),\nbut it\u2019s more efficient to call it explicitly with just the page numbers you need. Page numbers can be any\ncombination of integers and lists, e.g. <tt><span class=\"pre\">pdf.load(0,2,3,[4,5,6],range(10,15))</span></tt>.</p>\n<p>You can call <tt>pdf.load(None)</tt> if for some reason you want to initialize without loading <em>any</em> pages\n(like you are only interested in the document info).</p>\n</div>\n<div id=\"public-but-less-useful-methods\">\n<h3><a href=\"#id18\" rel=\"nofollow\">Public But Less Useful Methods</a></h3>\n<p>These are mostly used internally, but might be helpful sometimes \u2026</p>\n<pre>get_layout(page)\n</pre>\n<p>Given a page number (zero-indexed) or pdfminer PDFPage object, return the LTPage layout object for that page.</p>\n<pre>get_layouts()\n</pre>\n<p>Return list of all layouts (equivalent to calling get_layout() for each page).</p>\n<pre>get_page(page_number)\n</pre>\n<p>Given a page number, return the appropriate pdfminer PDFPage object.</p>\n<pre>get_pyquery(tree=None, page_numbers=[])\n</pre>\n<p>Wrap a given lxml element tree in pyquery.\nIf no tree is supplied, will generate one from given page numbers, or all page numbers.</p>\n<pre>get_tree(*page_numbers)\n</pre>\n<p>Generate an etree for the given page numbers. <tt>*page_numbers</tt> can be the same form as in <tt>load()</tt>.</p>\n</div>\n</div>\n<div id=\"documentation-for-underlying-libraries\">\n<h2><a href=\"#id19\" rel=\"nofollow\">Documentation for Underlying Libraries</a></h2>\n<ul>\n<li>PDFMiner (pdf.doc): <a href=\"http://www.unixuser.org/~euske/python/pdfminer/\" rel=\"nofollow\">pdfminer_homepage</a>, <a href=\"http://www.unixuser.org/~euske/python/pdfminer/programming.html\" rel=\"nofollow\">pdfminer_documentation</a>.</li>\n</ul>\n<ul>\n<li>LXML.etree (pdf.tree): <a href=\"http://lxml.de/index.html\" rel=\"nofollow\">lxml_homepage</a>, <a href=\"http://lxml.de/tutorial.html\" rel=\"nofollow\">tutorial</a>.</li>\n</ul>\n<ul>\n<li>PyQuery (pdf.pq): <a href=\"http://packages.python.org/pyquery/\" rel=\"nofollow\">pyquery_documentation</a>.</li>\n</ul>\n</div>\n\n          </div>"}, "last_serial": 2030215, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "a96644ab6fe214d0850a0a5c9cb70db6", "sha256": "470b3a41d625f26fc1d17c67b3a9829ec7bfc7192037fdb31dded897aedd7aeb"}, "downloads": -1, "filename": "pdfquery-0.1.0.tar.gz", "has_sig": false, "md5_digest": "a96644ab6fe214d0850a0a5c9cb70db6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11809, "upload_time": "2012-04-16T21:27:22", "upload_time_iso_8601": "2012-04-16T21:27:22.864879Z", "url": "https://files.pythonhosted.org/packages/13/ff/8207d3f867ab93587b80cc555d987a2c32209ef9338d94852b98b88df9da/pdfquery-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "8114c1529fe295b6cd8ed9762e89278e", "sha256": "205ce1dd30deb25e4b12878f6e15a59eed54972451172c6f391fdabdc8b05930"}, "downloads": -1, "filename": "pdfquery-0.1.1.tar.gz", "has_sig": false, "md5_digest": "8114c1529fe295b6cd8ed9762e89278e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 54179, "upload_time": "2012-04-16T21:45:07", "upload_time_iso_8601": "2012-04-16T21:45:07.673855Z", "url": "https://files.pythonhosted.org/packages/0d/05/c1bdc61d679f4c096721adea61df8cdbe5cde14db50ab100ff669405ab97/pdfquery-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "644ac96669faf143c7dca17e88636d76", "sha256": "58ee9450248f227946031d4e3c8dab33817957e9246902365a6a4db79b88fa94"}, "downloads": -1, "filename": "pdfquery-0.1.2.tar.gz", "has_sig": false, "md5_digest": "644ac96669faf143c7dca17e88636d76", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 55116, "upload_time": "2012-04-16T21:46:18", "upload_time_iso_8601": "2012-04-16T21:46:18.614146Z", "url": "https://files.pythonhosted.org/packages/0a/8a/38937e4e3fa2cee16244a4f68df55eb6f440f87821dc86122014175a9896/pdfquery-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "ada3c35480bbf3bc69cfc818a3d0e911", "sha256": "3db80be49db04a278758220ffdaabd0901caea6b0c6ef7f13ba6e7d2b47b1a02"}, "downloads": -1, "filename": "pdfquery-0.1.3.tar.gz", "has_sig": false, "md5_digest": "ada3c35480bbf3bc69cfc818a3d0e911", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 55482, "upload_time": "2012-04-16T22:38:58", "upload_time_iso_8601": "2012-04-16T22:38:58.377493Z", "url": "https://files.pythonhosted.org/packages/99/02/ca5651569a45a3d19bb206c2f29299db9c9d37a732c4c784cf2887989926/pdfquery-0.1.3.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "d69f6ac86cd0d7e0b2168a083ecef6f2", "sha256": "432743047aab309c16ec6434cf40b823115d56652eac9336be71060c8281fe1f"}, "downloads": -1, "filename": "pdfquery-0.2.tar.gz", "has_sig": false, "md5_digest": "d69f6ac86cd0d7e0b2168a083ecef6f2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 57421, "upload_time": "2013-11-03T23:43:23", "upload_time_iso_8601": "2013-11-03T23:43:23.242369Z", "url": "https://files.pythonhosted.org/packages/d4/37/8f70ad8803f5903b02e4f12879743081ef09f402a03d49f34c9344889e8c/pdfquery-0.2.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "f34425b4e188d891f91da8d9ebb6b61d", "sha256": "922ebfac71fdab79c16c4d142fed93e2a163814f9be474e447362b468ef72cbd"}, "downloads": -1, "filename": "pdfquery-0.2.1.tar.gz", "has_sig": false, "md5_digest": "f34425b4e188d891f91da8d9ebb6b61d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 57739, "upload_time": "2013-11-30T22:14:41", "upload_time_iso_8601": "2013-11-30T22:14:41.356964Z", "url": "https://files.pythonhosted.org/packages/11/f9/38f7a5125d509ecf90eeec0a43a11f5a55ada5b3054d1f936ab4d3946a4b/pdfquery-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "45034706211585c1ee8eeb8c57220422", "sha256": "5a7b67f9d43e50c8242c39324294f16480ba755f7a2d6a46084ddae2cbefed5e"}, "downloads": -1, "filename": "pdfquery-0.2.2.tar.gz", "has_sig": false, "md5_digest": "45034706211585c1ee8eeb8c57220422", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 57791, "upload_time": "2013-12-05T02:52:32", "upload_time_iso_8601": "2013-12-05T02:52:32.092805Z", "url": "https://files.pythonhosted.org/packages/be/95/515c7ffb5008642f329a7bfdacd41e10c472239ae9b6334e4ffb44ed170c/pdfquery-0.2.2.tar.gz", "yanked": false}], "0.2.3": [{"comment_text": "", "digests": {"md5": "c6c001fe4ce7a11d3f4b8ee34f157940", "sha256": "e2ae362c9e694d70ae51b8e11a473ac587fb31b84e197d2f926a3fb6630e014d"}, "downloads": -1, "filename": "pdfquery-0.2.3.tar.gz", "has_sig": false, "md5_digest": "c6c001fe4ce7a11d3f4b8ee34f157940", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 57867, "upload_time": "2014-05-15T23:22:12", "upload_time_iso_8601": "2014-05-15T23:22:12.923983Z", "url": "https://files.pythonhosted.org/packages/52/36/5941db98b07b41ac0e5bad9aaeadf7fde3601093f6420e93eff5d9fa57e7/pdfquery-0.2.3.tar.gz", "yanked": false}], "0.2.4": [{"comment_text": "", "digests": {"md5": "25ea26773153dac8a0b95b9869d79c36", "sha256": "55c79ef35ca42f253d3b7489df1c7c7655b7b83815fa7ecd42626f970874e40d"}, "downloads": -1, "filename": "pdfquery-0.2.4.tar.gz", "has_sig": false, "md5_digest": "25ea26773153dac8a0b95b9869d79c36", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 58755, "upload_time": "2014-05-29T22:28:03", "upload_time_iso_8601": "2014-05-29T22:28:03.264536Z", "url": "https://files.pythonhosted.org/packages/db/c3/f9da3b3b3aa81aaac17fe5563ee6362fc85b899cc136a3ad41104d8e7753/pdfquery-0.2.4.tar.gz", "yanked": false}], "0.2.5": [{"comment_text": "", "digests": {"md5": "14cdab2be74b1c4737b5d05f4f7d5976", "sha256": "ac24a12f36691eb02f353dfe4575dd79c7f6e1e10f75f11d8ec621041edefb3c"}, "downloads": -1, "filename": "pdfquery-0.2.5.tar.gz", "has_sig": false, "md5_digest": "14cdab2be74b1c4737b5d05f4f7d5976", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 59069, "upload_time": "2014-06-30T01:39:47", "upload_time_iso_8601": "2014-06-30T01:39:47.811483Z", "url": "https://files.pythonhosted.org/packages/48/36/dcfcd8255fd2f7e81327e43c345b0427dc4db6bffd22bfbe018f3e1aaeab/pdfquery-0.2.5.tar.gz", "yanked": false}], "0.2.6": [{"comment_text": "", "digests": {"md5": "b610bc951b5b1258483ca304e6354394", "sha256": "c3d52540406c5350dac6fa5fbee635a0dec07dd3035dd04e8afc480989c840d3"}, "downloads": -1, "filename": "pdfquery-0.2.6.tar.gz", "has_sig": false, "md5_digest": "b610bc951b5b1258483ca304e6354394", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17228, "upload_time": "2014-07-05T18:06:24", "upload_time_iso_8601": "2014-07-05T18:06:24.416911Z", "url": "https://files.pythonhosted.org/packages/11/eb/155ec1767411e10dc6bceddd0fcb26ee925413247967278752fdc3627b58/pdfquery-0.2.6.tar.gz", "yanked": false}], "0.2.7": [{"comment_text": "", "digests": {"md5": "3fa5652e51d4064c905e411d0fa51bd5", "sha256": "4d94089cd80ca22c31c5767263f167d1d12a8c7a28cb55d15f10903380d64d86"}, "downloads": -1, "filename": "pdfquery-0.2.7.tar.gz", "has_sig": false, "md5_digest": "3fa5652e51d4064c905e411d0fa51bd5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15895, "upload_time": "2014-09-22T14:49:28", "upload_time_iso_8601": "2014-09-22T14:49:28.334774Z", "url": "https://files.pythonhosted.org/packages/1d/c4/c5238a1ac4dae28d67b8d8e91c4295b798a79b147a06643014958f1b3efb/pdfquery-0.2.7.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "562ad68ce03ebe12633965c6dd1dc199", "sha256": "331582e9c2700764902b5772e9289d43d707c5cc20ffa33ce3fce0a41b9232ea"}, "downloads": -1, "filename": "pdfquery-0.3.0.tar.gz", "has_sig": false, "md5_digest": "562ad68ce03ebe12633965c6dd1dc199", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16489, "upload_time": "2015-06-26T19:14:16", "upload_time_iso_8601": "2015-06-26T19:14:16.416522Z", "url": "https://files.pythonhosted.org/packages/e2/86/28ee41e8f4e4d09f43f4fd2a863f448508ac2ed2d33282535a83815ca614/pdfquery-0.3.0.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "1f32b48164227782bcb6e07cf7c4e19e", "sha256": "71a5aa2a699ab6649f31715350b93fca59d24256ceac2754597884cd0e807fd5"}, "downloads": -1, "filename": "pdfquery-0.3.1.tar.gz", "has_sig": false, "md5_digest": "1f32b48164227782bcb6e07cf7c4e19e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16519, "upload_time": "2015-07-22T18:08:09", "upload_time_iso_8601": "2015-07-22T18:08:09.289285Z", "url": "https://files.pythonhosted.org/packages/b2/c6/b6b2559c830fefb0c5cd28bbd5286fe0eb0c843f2dd142148a236e90270c/pdfquery-0.3.1.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "4d1e04dd8562b8f19b32d5d480578931", "sha256": "e9af7fcb55f96b72cf0ff44dd7bd15a6689ac43f6e7f1a1e58d6f890ca74f17f"}, "downloads": -1, "filename": "pdfquery-0.4.0.tar.gz", "has_sig": false, "md5_digest": "4d1e04dd8562b8f19b32d5d480578931", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17293, "upload_time": "2015-12-22T01:18:33", "upload_time_iso_8601": "2015-12-22T01:18:33.826917Z", "url": "https://files.pythonhosted.org/packages/bf/01/e17bcdca72c2fac9c8b331c6ae6d5dd23885d6973f6c0a9c6b6ef382a610/pdfquery-0.4.0.tar.gz", "yanked": false}], "0.4.1": [{"comment_text": "", "digests": {"md5": "5ae8a9d18375752b283fb7df0de9cb7c", "sha256": "75697eaaca2d18b270c4db08765108a2a817dd50e32d672e909edd84da357389"}, "downloads": -1, "filename": "pdfquery-0.4.1.tar.gz", "has_sig": false, "md5_digest": "5ae8a9d18375752b283fb7df0de9cb7c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17317, "upload_time": "2015-12-22T01:42:13", "upload_time_iso_8601": "2015-12-22T01:42:13.032993Z", "url": "https://files.pythonhosted.org/packages/48/e8/611bb75adf29b088e13f550630f63dae7a7166ad67f9ee57b3ff2c542d0a/pdfquery-0.4.1.tar.gz", "yanked": false}], "0.4.2": [{"comment_text": "", "digests": {"md5": "27ab547815cb9bd30952a810126ac1db", "sha256": "522277d6307c88856a40faa60fab20ef8747c1e74740cd63e030ec2be004a287"}, "downloads": -1, "filename": "pdfquery-0.4.2.tar.gz", "has_sig": false, "md5_digest": "27ab547815cb9bd30952a810126ac1db", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17336, "upload_time": "2016-02-07T22:39:22", "upload_time_iso_8601": "2016-02-07T22:39:22.752683Z", "url": "https://files.pythonhosted.org/packages/8f/44/1c225901a8a81948b54b5f0f70c2c8e5dab4d4c6cbd65236573a0d7bab8b/pdfquery-0.4.2.tar.gz", "yanked": false}], "0.4.3": [{"comment_text": "", "digests": {"md5": "e037ceb3f4f2c2465205bc3d79766e15", "sha256": "a2a2974cb312fda4f569adc8d63377d25d5c6367240b4a7bfb165392c73e1dce"}, "downloads": -1, "filename": "pdfquery-0.4.3.tar.gz", "has_sig": false, "md5_digest": "e037ceb3f4f2c2465205bc3d79766e15", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17489, "upload_time": "2016-03-27T20:04:23", "upload_time_iso_8601": "2016-03-27T20:04:23.277169Z", "url": "https://files.pythonhosted.org/packages/e5/ed/caf087d2d65ceef10fb117af79bbab50ea3a24ed8b1dc8abb0dc8039d2d3/pdfquery-0.4.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "e037ceb3f4f2c2465205bc3d79766e15", "sha256": "a2a2974cb312fda4f569adc8d63377d25d5c6367240b4a7bfb165392c73e1dce"}, "downloads": -1, "filename": "pdfquery-0.4.3.tar.gz", "has_sig": false, "md5_digest": "e037ceb3f4f2c2465205bc3d79766e15", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17489, "upload_time": "2016-03-27T20:04:23", "upload_time_iso_8601": "2016-03-27T20:04:23.277169Z", "url": "https://files.pythonhosted.org/packages/e5/ed/caf087d2d65ceef10fb117af79bbab50ea3a24ed8b1dc8abb0dc8039d2d3/pdfquery-0.4.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:57:10 2020"}