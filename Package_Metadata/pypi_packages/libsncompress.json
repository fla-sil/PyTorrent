{"info": {"author": "Cong Ma", "author_email": "cong.ma@obspm.fr", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Console", "Intended Audience :: Science/Research", "License :: OSI Approved :: BSD License", "Operating System :: OS Independent", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: Implementation :: CPython", "Topic :: Scientific/Engineering :: Astronomy", "Topic :: Scientific/Engineering :: Information Analysis", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "libsncompress\n=============\n\n|pipeline| |coverage| |pypi| |license| |pyversions| |DOI|\n\nSummary\n-------\n\n``libsncompress`` \u2013 efficient and reproducible Python utility for\ncompressing supernova cosmological data.\n\nIntroduction\n------------\n\nThe Python package ``libsncompress`` implements the linear compression\nmethod described in the paper \u201cApplication of Bayesian graphs to SN Ia\ndata analysis and compression\u201d (C.\u00a0Ma, P.-S.\u00a0Corasaniti, &\nB.\u00a0A.\u00a0Bassett, 2016, `MNRAS, submitted`_, \u201cM16\u201d; accepted version: 2016\nMNRAS, 463, 1651, DOI: `\u261e`_\\ ``10.1093/mnras/stw2069``, BibCode:\n`\u261e <http://adsabs.harvard.edu/abs/2016MNRAS.463.1651M>`__\\ ``2016MNRAS.463.1651M``).\nIt is designed for use with the `JLA`_ dataset, but can be easily\nextended for other similar datasets.\n\nIt also includes a Python executable script,\n`\u261e <https://gitlab.com/congma/libsncompress/blob/master/scripts/jlacompress>`__\\ ``jlacompress``,\nthat serves as a command-line user interface.\n\nThe intended usage includes the following tasks:\n\n-  To obtain a compressed sample of the JLA dataset, obtaining the\n   location (mean) vector and scatter (covariance) matrix of the\n   luminosity distance modulus, possibly for subsequent cosmological\n   analysis.\n-  To perform cross-validation on portions of the dataset.\n-  To study the posterior distribution of SN standardization parameters\n   ``alpha``, ``beta``, and ``delta_M``.\n-  To replicate the results in the above-cited research paper that is\n   built on the preceding tasks.\n-  To help developing new methods of data analysis and compression with\n   current and future data based on the current work.\n\nThe programs work with both Python 2.7 and 3.6/3.7.\n\nInstallation\n------------\n\nThe most convenient to install the package depends on your intended\nusage.\n\nTo simply use the package and compression script, just install the\nlatest version fro the PyPI with ``pip``:\n\n::\n\n   pip install -U libsncompress\n\nAdditional Python packages are required at runtime (please refer to the\nsection \u201c`Dependencies`_\u201d for the list of dependencies of the current\nversion). The recommended installation method is to use the above\ncommand, which will make sure that the supporting packages are installed\nautomatically.\n\nTo contribute to the package development, run the tests with real data,\nor verify the reproducibility of the research, it is necessary to clone\nthe repository using ``git``:\n\n::\n\n   git clone https://gitlab.com/congma/libsncompress.git\n\nThe full repository includes also the necessary files for testing and\nverification. Please refer to the section \u201c`Testing and Development`_\u201d\nfor further details.\n\nIt is also possible to use the library package ``libsncompress`` without\ninstallation, for example, by including them directly in your own\nproject.\n\nUsing the JLA Compression Script\n--------------------------------\n\nThis utility comes with an executable script ``jlacompress`` that is\ntailored to the compression of the `JLA`_ dataset, as done in our `M16`_\npaper.\n\nSynopsis\n~~~~~~~~\n\n::\n\n   jlacompress [-h] [-d DIR] [-t FILE] [-p PREFIX] [-c z1 z2 [...]] [-n] [-v]\n\nThe script requires JLA data files to run. See the section \u201c`Data\nFiles`_\u201d for details.\n\nCommand-Line Options\n~~~~~~~~~~~~~~~~~~~~\n\n-  ``-h``, ``--help``: show help message and exit\n-  ``-d DIR``, ``--covdir DIR``: path to directory of FITS covariance\n   files (default: ``./covmat``)\n-  ``-t FILE``, ``--table FILE``: path to JLA data table file (default:\n   ``./jla_lcparams.txt``)\n-  ``-p PREFIX``, ``--output-prefix PREFIX``: prefix to output file\n   names\n-  ``-c z1 z2 [...]``, ``--controls z1 z2 [...]``: locations of control\n   points (as redshift). At least two control points are required. If\n   unspecified, use the default control points in the `JLA paper`_.\n-  ``-n``, ``--no-logdet``: don\u2019t use the correct conditional\n   probability (default: off; *warning:* use at your own risk)\n-  ``-v``, ``--verbose``: turn on verbose output (default: off)\n\nOutput\n~~~~~~\n\nThe script writes three output files when it solves the optimization\nproblem successfully:\n\n-  Mean (approximate, actually posterior-maximizing) compression\n   parameters in the order of (``alpha``, ``beta``, ``delta_M``,\n   ``mu1``, ``mu2``, \u2026), where ``muN`` is the value of distance modulus\n   at the ``N``-th control point. It is therefore a list of ``N + 3``\n   numbers\n-  Covariance matrix (symmetric, and with all elements filled) of the\n   parameters. It is of shape ``N + 3`` \u00d7 ``N + 3``, and the first 3\n   rows and columns correspond to the three standardization parameters\n   ``alpha``, ``beta``, and ``delta_M``.\n-  Redshifts of the ``N`` control points.\n\nThe default output file names are ``mean.txt``, ``cov.txt`` and\n``redshift.txt`` respectively, but they can be prefixed by arbitrary\nstrings specified by the user with the ``-p``/``--prefix`` option.\n\nThe slash (``/``) character in the prefix will be understood as\ndirectory separators. If the directory part of a resulting path does not\nexist, it will be created if possible, and nested directories may be\ncreated by this process.\n\nThe output files will have suffix ``-no-logdet`` appended to the path\nbut before the ``.txt`` extension, if ``-n`` or ``--no-logdet`` is\nspecified.\n\nWhen verbose output is enabled by ``-v`` or ``--verbose``, additional\ntext will be written to the standard error.\n\nExit Status\n~~~~~~~~~~~\n\nThe script exits with ``0`` for success. Any other value indicates\nerror.\n\nExample Usage\n~~~~~~~~~~~~~\n\nAssuming the data files are in their default locations, the following\ncommand reproduces the default compression results in the `JLA paper`_.\n\n::\n\n   jlacompress -n\n\nData Files\n----------\n\nThe JLA data files are *required* for using the package. However, we\ncannot distribute them with the source package. Please read the `JLA\nreadme`_ page for details about the data files.\n\nThe following *two* files must be downloaded:\n\n1. The file\n   `\u261e <http://supernovae.in2p3.fr/sdss_snls_jla/jla_likelihood_v6.tgz>`__\\ ``jla_likelihood_v6.tgz``,\n   compressed archive containing the file ``data/jla_lcparams.txt``.\n   This file contains the supernova sample catalogue. The other files in\n   this archive are not necessary.\n2. The FITS files containing the components of data covariance, in the\n   compressed archive\n   `\u261e <http://supernovae.in2p3.fr/sdss_snls_jla/covmat_v6.tgz>`__\\ ``covmat_v6.tgz``.\n   The non-FITS files in this archive are not necessary.\n\nIf the JLA data archives are already downloaded, you simply need to\nextract the required files and specify their locations when using the\n``jlacompress`` script, as described `above`_.\n\nThe Git repository includes a shell script to download and extract these\nfiles:\n`\u261e <https://gitlab.com/congma/libsncompress/blob/master/download_jla.sh>`__\\ ``download_jla.sh``.\nThis script is meant to be run manually, and it is not distributed with\nthe wheel distribution on PyPI. However, it is included in the source\ndistribution, even if it\u2019s skipped during installation of the sdist.\n\nTo use the download script, simply invoking the script in the repository\n(or extracted sdist tarball) directory\n\n::\n\n   ./download_jla.sh\n\nwill suffice \u2013 this will populate the ``testdata`` directory with the\nnecessary files and check the file integrity. Doing so also ensures that\nthe tests can run.\n\nTesting and Development\n-----------------------\n\nUsing ``libsncompress`` in Your Project\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nTo use the package directly in your own Python project, simply\n\n.. code:: python\n\n   import libsncompress\n\nThis will import three classes from its sub-modules into the\n``libsncompress`` namespace:\n\n-  ``BinnedSN``: data-file loader and pre-processor\n-  ``BinCollection``: redshift binning and sanitizer; not very useful on\n   its own\n-  ``CovEvaluator``: the actual compressor\n\nThe first thing you need to do is to specify a list (or ``numpy`` array)\nof control points, by their *base-10 logarithm* values. Currently, due\nto development legacy, the \u201cbinning\u201d class and methods are not\nparticularly efficient. This is usually not a problem because it will be\nused only once.\n\nThis list or array of control points must be encapsulate in *another*\ncontainer (list, array, or tuple, etc.) before passing to the\ninitializer of ``libsncompress.BinnedSN`` class. The instance can be\ninitialized by\n\n.. code:: python\n\n   binned_sn = libsncompress.BinnedSN(basedirpath,\n                                      tablepath,\n                                      logbins=control_points)\n\nHere ``basedirpath`` is the path to the directory containing the FITS\ncovariance data files, ``tablepath`` the path to the text file\ncontaining the JLA dataset table, and ``logbins`` is the nested list of\ncontrol points just obtained.\n\nAfter this, we can initialize the evaluator\n``libsncompress.CovEvaluator`` class, which implements the evaluation of\nprobability log-density functions and their first 2 derivatives, like\nthis:\n\n.. code:: python\n\n   ev = libsncompress.CovEvaluator(binned_sn, withlogdet=True)\n\nThe optional argument ``withlogdet`` controls whether the full effect of\nparameter-dependent covariance matrix is taken into account. It is so\nnamed due to the ubiquitous presence of \u201cln det Cov\u201d term. It defaults\nto ``True`` but can be set to ``False``, which will evaluate the\nfunctions as if the customary chi-squared method were used.\n\nThe ``CovEvaluator`` instance, ``ev``, provides a method ``minimize``,\nwhich is a wrapper of ``scipy.optimize.minimize``. Additional positional\nand keyword arguments are passed over to that function. The recommended\noptimization algorithm is ``trust-ncg`` which fully utilizes the Hessian\nmatrix. This is the default minimization algorithm if left unspecified,\nand other algorithms supported by\n`\u261e <https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html>`__\\ ``scipy.optimize.minimize``\ncan be passed as the optional keyword parameter ``method``.\n\nThe return value of ``CovEvaluator.minimize`` method is simply that of\nthe underlying ``scipy`` function, but with results suitably scaled.\n\nThe Hessian of log-PDF function can be obtained, then, at the minimizing\npoint in the parameter space. This can be used for constructing the\napproximate covariance of compression parameters.\n\nPlease notice that this implementation here is not a general, abstract\nimplementation of the linear compression method detailed in `our\npaper`_. It specifically implements the sawtooth-basis compression,\nwhich is compatible with the original `JLA one`_. The implementation\ndetails, as well as the exposed API, are likely to see significant\nrevisions in the future.\n\nSetting Up the Testing Environment\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nTo run the tests (including the reproducibility tests), it is necessary\nto set up the environment with supporting packages and data.\n\nAs described in the `preceding section`_, \u201cData Files\u201d, the recommended\nway is to clone the Git repository and populate the ``testdata``\ndirectory in the repository with the necessary files, which can be done\nusing the ``download_jla.sh`` script.\n\nAfter obtaining the data files, it is recommended to use the recent\nversion of `\u261e <https://tox.readthedocs.io/>`__\\ ``tox`` to manage the\ntesting environments.\n\n::\n\n   pip install 'tox >= 2.8.0'\n\nAlthough not strictly necessary for running the tests themselves *per\nse*, it is recommended to install the\n`\u261e <http://pandoc.org/>`__\\ ``pandoc`` program (please consult your\noperating system documentation) and the\n`\u261e <https://github.com/bebraw/pypandoc>`__\\ ``pypandoc`` Python package.\n\nRunning the Tests\n~~~~~~~~~~~~~~~~~\n\nIf you have both Python 2.7 and 3.6/3.7 installed, simply invoking\n\n::\n\n   tox\n\nwill create the source distribution and run the tests under both Python\nvariants. The default configuration will pull the latest supporting\npackages from PyPI specified in the file ``devel-requirements.txt``.\n\nIf you have only one working variant of Python, for example Python 2.7,\nyou can run\n\n::\n\n   tox -e py2,coverage-report\n\nand skip the unavailable test environment setting.\n\nReproducibility Tests\n~~~~~~~~~~~~~~~~~~~~~\n\nOne important goal of the test suits in this repository is to ensure\nthat the results of JLA SNIa compression are always reproducible.\n\nFirst, as we have shown in `M16`_, the `JLA`_ compression results (their\nTables F.1 and F.2), especially the covariance matrix, are \u201cvery close\u201d\nto the ones obtained using this program on the `JLA data release`_, but\nwith the (highly discouraged) ``withlogdet=False`` option enabled for\n``libsncompress.CovEvaluator``.\n\nSecond, the compression results produced by this program on the released\nJLA data must match those presented in `M16`_, Tables A1 and A2.\n\nThe reproducibility tests check that these constraints are satisfied by\nall revisions to the codebase. These tests are included in the\n``tests/test_reprod.py`` script and are run by ``tox`` by default.\n\nDependencies\n------------\n\n-  `\u261e <https://pythonhosted.org/six/>`__\\ ``six`` (unknown version), for\n   Python 2 and 3 compatibility;\n-  `\u261e <http://www.numpy.org/>`__\\ ``numpy`` (``>= 1.6.0``), for array\n   data structure and basic operations;\n-  `\u261e <https://www.scipy.org/>`__\\ ``scipy`` (``>= 0.11.0``), for linear\n   algebra and numerical optimization;\n-  `\u261e <https://www.astropy.org/>`__\\ ``astropy`` (unknown version), for\n   loading FITS files with the ``astropy.io.fits`` module, which\n   replaces the dependence on\n   `\u261e <https://pythonhosted.org/pyfits/>`__\\ ``pyfits`` in earlier\n   versions;\n-  `\u261e <https://pythonhosted.org/cachetools/>`__\\ ``cachetools`` (unknown\n   version), for caching partial evaluation results, which is essential\n   for compression speed.\n\nPerformance Notes\n-----------------\n\nPerformance is mostly determined by the following two conditions:\n\n1. Underlying BLAS/LAPACK libraries used by ``numpy``/``scipy``,\n   especially the \u201clinear solver by Cholesky decomposition\u201d,\n   ``(D)POTRS`` function of LAPACK. For `NetLib LAPACK`_, this in turn\n   is largely determined by the speed of the level-3 BLAS triangular\n   solver, ``(D)TRSM``. The NetLib reference implementation is rather\n   naive, and an optimized implementation of BLAS is likely to boost the\n   performance.\n2. Choice of initial value and scaling for numerical optimization. If\n   they are suitably chosen, the number of iterations required to\n   achieve convergence is reduced.\n\nThe script\n`\u261e <https://gitlab.com/congma/libsncompress/blob/master/scripts/jlacompress>`__\\ ``jlacompress``\nattempts to automatically create acceptable initial value and scaling\nthat is optimized for the *default* compression used in the `JLA\npaper`_. The automatic initial value and scaling are not optimized for\nany other usage cases.\n\nReporting Bugs\n--------------\n\nPlease report problems via the `issue tracker`_.\n\nBibliography\n------------\n\nIf you use this program in your research, we would like to suggest you\ncite the following paper (\u201cM16\u201d):\n\nMa, C., Corasaniti, P.-S., & Bassett, B.\u00a0A. 2016, MNRAS, 463, 1651,\n`\u261e`_\\ ``doi: 10.1093/mnras/stw2069``\n\nThe following BibTeX entry could be useful in a LaTeX document:\n\n::\n\n   @ARTICLE{2016MNRAS.463.1651M,\n      author = {{Ma}, C. and {Corasaniti}, P.-S. and {Bassett}, B.~A.},\n       title = \"{Application of Bayesian graphs to SN Ia data analysis and compression}\",\n     journal = {MNRAS},\n   archivePrefix = \"arXiv\",\n      eprint = {1603.08519},\n        year = 2016,\n       month = dec,\n      volume = 463,\n       pages = {1651-1665},\n         doi = {10.1093/mnras/stw2069}\n   }\n\n.. _MNRAS, submitted: https://arxiv.org/abs/1603.08519\n.. _\u261e: https://doi.org/10.1093/mnras/stw2069\n.. _JLA: https://arxiv.org/abs/1401.4064\n.. _Dependencies: #dependencies\n.. _Testing and Development: #testing-and-development\n.. _M16: https://arxiv.org/abs/1603.08519\n.. _Data Files: #data-files\n.. _JLA paper: https://arxiv.org/abs/1401.4064\n.. _JLA readme: http://supernovae.in2p3.fr/sdss_snls_jla/ReadMe.html\n.. _above: #command-line-options\n.. _our paper: https://arxiv.org/abs/1603.08519\n.. _JLA one: https://arxiv.org/abs/1401.4064\n.. _preceding section: #data-files\n.. _JLA data release: http://supernovae.in2p3.fr/sdss_snls_jla/ReadMe.html\n.. _NetLib LAPACK: http://www.netlib.org/lapack/\n.. _issue tracker: https://gitlab.com/congma/libsncompress/issues\n\n.. |pipeline| image:: https://gitlab.com/congma/libsncompress/badges/master/pipeline.svg\n   :target: https://gitlab.com/congma/libsncompress/commits/master\n.. |coverage| image:: https://gitlab.com/congma/libsncompress/badges/master/coverage.svg\n   :target: https://gitlab.com/congma/libsncompress/commits/master\n.. |pypi| image:: https://img.shields.io/pypi/v/libsncompress.svg\n   :target: https://pypi.org/project/libsncompress/\n.. |license| image:: https://img.shields.io/pypi/l/libsncompress.svg?longCache=true\n   :target: https://gitlab.com/congma/libsncompress/blob/master/COPYING\n.. |pyversions| image:: https://img.shields.io/pypi/pyversions/libsncompress.svg\n   :target: #introduction\n.. |DOI| image:: https://zenodo.org/badge/DOI/10.5281/zenodo.1208155.svg\n   :target: https://doi.org/10.5281/zenodo.1208155\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://gitlab.com/congma/libsncompress/", "keywords": "", "license": "BSD", "maintainer": "", "maintainer_email": "", "name": "libsncompress", "package_url": "https://pypi.org/project/libsncompress/", "platform": "", "project_url": "https://pypi.org/project/libsncompress/", "project_urls": {"Homepage": "https://gitlab.com/congma/libsncompress/"}, "release_url": "https://pypi.org/project/libsncompress/0.0.8/", "requires_dist": ["six", "numpy (>=1.6.0)", "scipy (>=0.11.0)", "astropy", "cachetools"], "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*, !=3.5.*, <3.8", "summary": "Compress JLA-like supernova data", "version": "0.0.8", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://gitlab.com/congma/libsncompress/commits/master\" rel=\"nofollow\"><img alt=\"pipeline\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9a6df92b9966c52af516149d6fd8ac55907bff41/68747470733a2f2f6769746c61622e636f6d2f636f6e676d612f6c6962736e636f6d70726573732f6261646765732f6d61737465722f706970656c696e652e737667\"></a> <a href=\"https://gitlab.com/congma/libsncompress/commits/master\" rel=\"nofollow\"><img alt=\"coverage\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a296e4e18004922fcf4c837cbeb3872d0a125236/68747470733a2f2f6769746c61622e636f6d2f636f6e676d612f6c6962736e636f6d70726573732f6261646765732f6d61737465722f636f7665726167652e737667\"></a> <a href=\"https://pypi.org/project/libsncompress/\" rel=\"nofollow\"><img alt=\"pypi\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/eb9e6e95730ea57ebb2a4145350ce38a060651ff/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6c6962736e636f6d70726573732e737667\"></a> <a href=\"https://gitlab.com/congma/libsncompress/blob/master/COPYING\" rel=\"nofollow\"><img alt=\"license\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/043787101812444d925b1dc3033bce07d547be39/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f6c6962736e636f6d70726573732e7376673f6c6f6e6743616368653d74727565\"></a> <a href=\"#introduction\" rel=\"nofollow\"><img alt=\"pyversions\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ec77a1e83111ac384cca90e23341b06e6c72401c/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f6c6962736e636f6d70726573732e737667\"></a> <a href=\"https://doi.org/10.5281/zenodo.1208155\" rel=\"nofollow\"><img alt=\"DOI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4beecf7a52a5427f0956ebd2868426836b2abc69/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e313230383135352e737667\"></a></p>\n<div id=\"summary\">\n<h2>Summary</h2>\n<p><tt>libsncompress</tt> \u2013 efficient and reproducible Python utility for\ncompressing supernova cosmological data.</p>\n</div>\n<div id=\"introduction\">\n<h2>Introduction</h2>\n<p>The Python package <tt>libsncompress</tt> implements the linear compression\nmethod described in the paper \u201cApplication of Bayesian graphs to SN Ia\ndata analysis and compression\u201d (C.\u00a0Ma, P.-S.\u00a0Corasaniti, &amp;\nB.\u00a0A.\u00a0Bassett, 2016, <a href=\"https://arxiv.org/abs/1603.08519\" rel=\"nofollow\">MNRAS, submitted</a>, \u201cM16\u201d; accepted version: 2016\nMNRAS, 463, 1651, DOI: <a href=\"https://doi.org/10.1093/mnras/stw2069\" rel=\"nofollow\">\u261e</a><tt>10.1093/mnras/stw2069</tt>, BibCode:\n<a href=\"http://adsabs.harvard.edu/abs/2016MNRAS.463.1651M\" rel=\"nofollow\">\u261e</a><tt>2016MNRAS.463.1651M</tt>).\nIt is designed for use with the <a href=\"https://arxiv.org/abs/1401.4064\" rel=\"nofollow\">JLA</a> dataset, but can be easily\nextended for other similar datasets.</p>\n<p>It also includes a Python executable script,\n<a href=\"https://gitlab.com/congma/libsncompress/blob/master/scripts/jlacompress\" rel=\"nofollow\">\u261e</a><tt>jlacompress</tt>,\nthat serves as a command-line user interface.</p>\n<p>The intended usage includes the following tasks:</p>\n<ul>\n<li>To obtain a compressed sample of the JLA dataset, obtaining the\nlocation (mean) vector and scatter (covariance) matrix of the\nluminosity distance modulus, possibly for subsequent cosmological\nanalysis.</li>\n<li>To perform cross-validation on portions of the dataset.</li>\n<li>To study the posterior distribution of SN standardization parameters\n<tt>alpha</tt>, <tt>beta</tt>, and <tt>delta_M</tt>.</li>\n<li>To replicate the results in the above-cited research paper that is\nbuilt on the preceding tasks.</li>\n<li>To help developing new methods of data analysis and compression with\ncurrent and future data based on the current work.</li>\n</ul>\n<p>The programs work with both Python 2.7 and 3.6/3.7.</p>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>The most convenient to install the package depends on your intended\nusage.</p>\n<p>To simply use the package and compression script, just install the\nlatest version fro the PyPI with <tt>pip</tt>:</p>\n<pre>pip install -U libsncompress\n</pre>\n<p>Additional Python packages are required at runtime (please refer to the\nsection \u201c<a href=\"#dependencies\" rel=\"nofollow\">Dependencies</a>\u201d for the list of dependencies of the current\nversion). The recommended installation method is to use the above\ncommand, which will make sure that the supporting packages are installed\nautomatically.</p>\n<p>To contribute to the package development, run the tests with real data,\nor verify the reproducibility of the research, it is necessary to clone\nthe repository using <tt>git</tt>:</p>\n<pre>git clone https://gitlab.com/congma/libsncompress.git\n</pre>\n<p>The full repository includes also the necessary files for testing and\nverification. Please refer to the section \u201c<a href=\"#testing-and-development\" rel=\"nofollow\">Testing and Development</a>\u201d\nfor further details.</p>\n<p>It is also possible to use the library package <tt>libsncompress</tt> without\ninstallation, for example, by including them directly in your own\nproject.</p>\n</div>\n<div id=\"using-the-jla-compression-script\">\n<h2>Using the JLA Compression Script</h2>\n<p>This utility comes with an executable script <tt>jlacompress</tt> that is\ntailored to the compression of the <a href=\"https://arxiv.org/abs/1401.4064\" rel=\"nofollow\">JLA</a> dataset, as done in our <a href=\"https://arxiv.org/abs/1603.08519\" rel=\"nofollow\">M16</a>\npaper.</p>\n<div id=\"synopsis\">\n<h3>Synopsis</h3>\n<pre>jlacompress [-h] [-d DIR] [-t FILE] [-p PREFIX] [-c z1 z2 [...]] [-n] [-v]\n</pre>\n<p>The script requires JLA data files to run. See the section \u201c<a href=\"#data-files\" rel=\"nofollow\">Data\nFiles</a>\u201d for details.</p>\n</div>\n<div id=\"command-line-options\">\n<h3>Command-Line Options</h3>\n<ul>\n<li><tt><span class=\"pre\">-h</span></tt>, <tt><span class=\"pre\">--help</span></tt>: show help message and exit</li>\n<li><tt><span class=\"pre\">-d</span> DIR</tt>, <tt><span class=\"pre\">--covdir</span> DIR</tt>: path to directory of FITS covariance\nfiles (default: <tt>./covmat</tt>)</li>\n<li><tt><span class=\"pre\">-t</span> FILE</tt>, <tt><span class=\"pre\">--table</span> FILE</tt>: path to JLA data table file (default:\n<tt>./jla_lcparams.txt</tt>)</li>\n<li><tt><span class=\"pre\">-p</span> PREFIX</tt>, <tt><span class=\"pre\">--output-prefix</span> PREFIX</tt>: prefix to output file\nnames</li>\n<li><tt><span class=\"pre\">-c</span> z1 z2 <span class=\"pre\">[...]</span></tt>, <tt><span class=\"pre\">--controls</span> z1 z2 <span class=\"pre\">[...]</span></tt>: locations of control\npoints (as redshift). At least two control points are required. If\nunspecified, use the default control points in the <a href=\"https://arxiv.org/abs/1401.4064\" rel=\"nofollow\">JLA paper</a>.</li>\n<li><tt><span class=\"pre\">-n</span></tt>, <tt><span class=\"pre\">--no-logdet</span></tt>: don\u2019t use the correct conditional\nprobability (default: off; <em>warning:</em> use at your own risk)</li>\n<li><tt><span class=\"pre\">-v</span></tt>, <tt><span class=\"pre\">--verbose</span></tt>: turn on verbose output (default: off)</li>\n</ul>\n</div>\n<div id=\"output\">\n<h3>Output</h3>\n<p>The script writes three output files when it solves the optimization\nproblem successfully:</p>\n<ul>\n<li>Mean (approximate, actually posterior-maximizing) compression\nparameters in the order of (<tt>alpha</tt>, <tt>beta</tt>, <tt>delta_M</tt>,\n<tt>mu1</tt>, <tt>mu2</tt>, \u2026), where <tt>muN</tt> is the value of distance modulus\nat the <tt>N</tt>-th control point. It is therefore a list of <tt>N + 3</tt>\nnumbers</li>\n<li>Covariance matrix (symmetric, and with all elements filled) of the\nparameters. It is of shape <tt>N + 3</tt> \u00d7 <tt>N + 3</tt>, and the first 3\nrows and columns correspond to the three standardization parameters\n<tt>alpha</tt>, <tt>beta</tt>, and <tt>delta_M</tt>.</li>\n<li>Redshifts of the <tt>N</tt> control points.</li>\n</ul>\n<p>The default output file names are <tt>mean.txt</tt>, <tt>cov.txt</tt> and\n<tt>redshift.txt</tt> respectively, but they can be prefixed by arbitrary\nstrings specified by the user with the <tt><span class=\"pre\">-p</span></tt>/<tt><span class=\"pre\">--prefix</span></tt> option.</p>\n<p>The slash (<tt>/</tt>) character in the prefix will be understood as\ndirectory separators. If the directory part of a resulting path does not\nexist, it will be created if possible, and nested directories may be\ncreated by this process.</p>\n<p>The output files will have suffix <tt><span class=\"pre\">-no-logdet</span></tt> appended to the path\nbut before the <tt>.txt</tt> extension, if <tt><span class=\"pre\">-n</span></tt> or <tt><span class=\"pre\">--no-logdet</span></tt> is\nspecified.</p>\n<p>When verbose output is enabled by <tt><span class=\"pre\">-v</span></tt> or <tt><span class=\"pre\">--verbose</span></tt>, additional\ntext will be written to the standard error.</p>\n</div>\n<div id=\"exit-status\">\n<h3>Exit Status</h3>\n<p>The script exits with <tt>0</tt> for success. Any other value indicates\nerror.</p>\n</div>\n<div id=\"example-usage\">\n<h3>Example Usage</h3>\n<p>Assuming the data files are in their default locations, the following\ncommand reproduces the default compression results in the <a href=\"https://arxiv.org/abs/1401.4064\" rel=\"nofollow\">JLA paper</a>.</p>\n<pre>jlacompress -n\n</pre>\n</div>\n</div>\n<div id=\"data-files\">\n<h2>Data Files</h2>\n<p>The JLA data files are <em>required</em> for using the package. However, we\ncannot distribute them with the source package. Please read the <a href=\"http://supernovae.in2p3.fr/sdss_snls_jla/ReadMe.html\" rel=\"nofollow\">JLA\nreadme</a> page for details about the data files.</p>\n<p>The following <em>two</em> files must be downloaded:</p>\n<ol>\n<li>The file\n<a href=\"http://supernovae.in2p3.fr/sdss_snls_jla/jla_likelihood_v6.tgz\" rel=\"nofollow\">\u261e</a><tt>jla_likelihood_v6.tgz</tt>,\ncompressed archive containing the file <tt>data/jla_lcparams.txt</tt>.\nThis file contains the supernova sample catalogue. The other files in\nthis archive are not necessary.</li>\n<li>The FITS files containing the components of data covariance, in the\ncompressed archive\n<a href=\"http://supernovae.in2p3.fr/sdss_snls_jla/covmat_v6.tgz\" rel=\"nofollow\">\u261e</a><tt>covmat_v6.tgz</tt>.\nThe non-FITS files in this archive are not necessary.</li>\n</ol>\n<p>If the JLA data archives are already downloaded, you simply need to\nextract the required files and specify their locations when using the\n<tt>jlacompress</tt> script, as described <a href=\"#command-line-options\" rel=\"nofollow\">above</a>.</p>\n<p>The Git repository includes a shell script to download and extract these\nfiles:\n<a href=\"https://gitlab.com/congma/libsncompress/blob/master/download_jla.sh\" rel=\"nofollow\">\u261e</a><tt>download_jla.sh</tt>.\nThis script is meant to be run manually, and it is not distributed with\nthe wheel distribution on PyPI. However, it is included in the source\ndistribution, even if it\u2019s skipped during installation of the sdist.</p>\n<p>To use the download script, simply invoking the script in the repository\n(or extracted sdist tarball) directory</p>\n<pre>./download_jla.sh\n</pre>\n<p>will suffice \u2013 this will populate the <tt>testdata</tt> directory with the\nnecessary files and check the file integrity. Doing so also ensures that\nthe tests can run.</p>\n</div>\n<div id=\"testing-and-development\">\n<h2>Testing and Development</h2>\n<div id=\"using-libsncompress-in-your-project\">\n<h3>Using <tt>libsncompress</tt> in Your Project</h3>\n<p>To use the package directly in your own Python project, simply</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">libsncompress</span>\n</pre>\n<p>This will import three classes from its sub-modules into the\n<tt>libsncompress</tt> namespace:</p>\n<ul>\n<li><tt>BinnedSN</tt>: data-file loader and pre-processor</li>\n<li><tt>BinCollection</tt>: redshift binning and sanitizer; not very useful on\nits own</li>\n<li><tt>CovEvaluator</tt>: the actual compressor</li>\n</ul>\n<p>The first thing you need to do is to specify a list (or <tt>numpy</tt> array)\nof control points, by their <em>base-10 logarithm</em> values. Currently, due\nto development legacy, the \u201cbinning\u201d class and methods are not\nparticularly efficient. This is usually not a problem because it will be\nused only once.</p>\n<p>This list or array of control points must be encapsulate in <em>another</em>\ncontainer (list, array, or tuple, etc.) before passing to the\ninitializer of <tt>libsncompress.BinnedSN</tt> class. The instance can be\ninitialized by</p>\n<pre><span class=\"n\">binned_sn</span> <span class=\"o\">=</span> <span class=\"n\">libsncompress</span><span class=\"o\">.</span><span class=\"n\">BinnedSN</span><span class=\"p\">(</span><span class=\"n\">basedirpath</span><span class=\"p\">,</span>\n                                   <span class=\"n\">tablepath</span><span class=\"p\">,</span>\n                                   <span class=\"n\">logbins</span><span class=\"o\">=</span><span class=\"n\">control_points</span><span class=\"p\">)</span>\n</pre>\n<p>Here <tt>basedirpath</tt> is the path to the directory containing the FITS\ncovariance data files, <tt>tablepath</tt> the path to the text file\ncontaining the JLA dataset table, and <tt>logbins</tt> is the nested list of\ncontrol points just obtained.</p>\n<p>After this, we can initialize the evaluator\n<tt>libsncompress.CovEvaluator</tt> class, which implements the evaluation of\nprobability log-density functions and their first 2 derivatives, like\nthis:</p>\n<pre><span class=\"n\">ev</span> <span class=\"o\">=</span> <span class=\"n\">libsncompress</span><span class=\"o\">.</span><span class=\"n\">CovEvaluator</span><span class=\"p\">(</span><span class=\"n\">binned_sn</span><span class=\"p\">,</span> <span class=\"n\">withlogdet</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<p>The optional argument <tt>withlogdet</tt> controls whether the full effect of\nparameter-dependent covariance matrix is taken into account. It is so\nnamed due to the ubiquitous presence of \u201cln det Cov\u201d term. It defaults\nto <tt>True</tt> but can be set to <tt>False</tt>, which will evaluate the\nfunctions as if the customary chi-squared method were used.</p>\n<p>The <tt>CovEvaluator</tt> instance, <tt>ev</tt>, provides a method <tt>minimize</tt>,\nwhich is a wrapper of <tt>scipy.optimize.minimize</tt>. Additional positional\nand keyword arguments are passed over to that function. The recommended\noptimization algorithm is <tt><span class=\"pre\">trust-ncg</span></tt> which fully utilizes the Hessian\nmatrix. This is the default minimization algorithm if left unspecified,\nand other algorithms supported by\n<a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html\" rel=\"nofollow\">\u261e</a><tt>scipy.optimize.minimize</tt>\ncan be passed as the optional keyword parameter <tt>method</tt>.</p>\n<p>The return value of <tt>CovEvaluator.minimize</tt> method is simply that of\nthe underlying <tt>scipy</tt> function, but with results suitably scaled.</p>\n<p>The Hessian of log-PDF function can be obtained, then, at the minimizing\npoint in the parameter space. This can be used for constructing the\napproximate covariance of compression parameters.</p>\n<p>Please notice that this implementation here is not a general, abstract\nimplementation of the linear compression method detailed in <a href=\"https://arxiv.org/abs/1603.08519\" rel=\"nofollow\">our\npaper</a>. It specifically implements the sawtooth-basis compression,\nwhich is compatible with the original <a href=\"https://arxiv.org/abs/1401.4064\" rel=\"nofollow\">JLA one</a>. The implementation\ndetails, as well as the exposed API, are likely to see significant\nrevisions in the future.</p>\n</div>\n<div id=\"setting-up-the-testing-environment\">\n<h3>Setting Up the Testing Environment</h3>\n<p>To run the tests (including the reproducibility tests), it is necessary\nto set up the environment with supporting packages and data.</p>\n<p>As described in the <a href=\"#data-files\" rel=\"nofollow\">preceding section</a>, \u201cData Files\u201d, the recommended\nway is to clone the Git repository and populate the <tt>testdata</tt>\ndirectory in the repository with the necessary files, which can be done\nusing the <tt>download_jla.sh</tt> script.</p>\n<p>After obtaining the data files, it is recommended to use the recent\nversion of <a href=\"https://tox.readthedocs.io/\" rel=\"nofollow\">\u261e</a><tt>tox</tt> to manage the\ntesting environments.</p>\n<pre>pip install 'tox &gt;= 2.8.0'\n</pre>\n<p>Although not strictly necessary for running the tests themselves <em>per\nse</em>, it is recommended to install the\n<a href=\"http://pandoc.org/\" rel=\"nofollow\">\u261e</a><tt>pandoc</tt> program (please consult your\noperating system documentation) and the\n<a href=\"https://github.com/bebraw/pypandoc\" rel=\"nofollow\">\u261e</a><tt>pypandoc</tt> Python package.</p>\n</div>\n<div id=\"running-the-tests\">\n<h3>Running the Tests</h3>\n<p>If you have both Python 2.7 and 3.6/3.7 installed, simply invoking</p>\n<pre>tox\n</pre>\n<p>will create the source distribution and run the tests under both Python\nvariants. The default configuration will pull the latest supporting\npackages from PyPI specified in the file <tt><span class=\"pre\">devel-requirements.txt</span></tt>.</p>\n<p>If you have only one working variant of Python, for example Python 2.7,\nyou can run</p>\n<pre>tox -e py2,coverage-report\n</pre>\n<p>and skip the unavailable test environment setting.</p>\n</div>\n<div id=\"reproducibility-tests\">\n<h3>Reproducibility Tests</h3>\n<p>One important goal of the test suits in this repository is to ensure\nthat the results of JLA SNIa compression are always reproducible.</p>\n<p>First, as we have shown in <a href=\"https://arxiv.org/abs/1603.08519\" rel=\"nofollow\">M16</a>, the <a href=\"https://arxiv.org/abs/1401.4064\" rel=\"nofollow\">JLA</a> compression results (their\nTables F.1 and F.2), especially the covariance matrix, are \u201cvery close\u201d\nto the ones obtained using this program on the <a href=\"http://supernovae.in2p3.fr/sdss_snls_jla/ReadMe.html\" rel=\"nofollow\">JLA data release</a>, but\nwith the (highly discouraged) <tt>withlogdet=False</tt> option enabled for\n<tt>libsncompress.CovEvaluator</tt>.</p>\n<p>Second, the compression results produced by this program on the released\nJLA data must match those presented in <a href=\"https://arxiv.org/abs/1603.08519\" rel=\"nofollow\">M16</a>, Tables A1 and A2.</p>\n<p>The reproducibility tests check that these constraints are satisfied by\nall revisions to the codebase. These tests are included in the\n<tt>tests/test_reprod.py</tt> script and are run by <tt>tox</tt> by default.</p>\n</div>\n</div>\n<div id=\"dependencies\">\n<h2>Dependencies</h2>\n<ul>\n<li><a href=\"https://pythonhosted.org/six/\" rel=\"nofollow\">\u261e</a><tt>six</tt> (unknown version), for\nPython 2 and 3 compatibility;</li>\n<li><a href=\"http://www.numpy.org/\" rel=\"nofollow\">\u261e</a><tt>numpy</tt> (<tt>&gt;= 1.6.0</tt>), for array\ndata structure and basic operations;</li>\n<li><a href=\"https://www.scipy.org/\" rel=\"nofollow\">\u261e</a><tt>scipy</tt> (<tt>&gt;= 0.11.0</tt>), for linear\nalgebra and numerical optimization;</li>\n<li><a href=\"https://www.astropy.org/\" rel=\"nofollow\">\u261e</a><tt>astropy</tt> (unknown version), for\nloading FITS files with the <tt>astropy.io.fits</tt> module, which\nreplaces the dependence on\n<a href=\"https://pythonhosted.org/pyfits/\" rel=\"nofollow\">\u261e</a><tt>pyfits</tt> in earlier\nversions;</li>\n<li><a href=\"https://pythonhosted.org/cachetools/\" rel=\"nofollow\">\u261e</a><tt>cachetools</tt> (unknown\nversion), for caching partial evaluation results, which is essential\nfor compression speed.</li>\n</ul>\n</div>\n<div id=\"performance-notes\">\n<h2>Performance Notes</h2>\n<p>Performance is mostly determined by the following two conditions:</p>\n<ol>\n<li>Underlying BLAS/LAPACK libraries used by <tt>numpy</tt>/<tt>scipy</tt>,\nespecially the \u201clinear solver by Cholesky decomposition\u201d,\n<tt>(D)POTRS</tt> function of LAPACK. For <a href=\"http://www.netlib.org/lapack/\" rel=\"nofollow\">NetLib LAPACK</a>, this in turn\nis largely determined by the speed of the level-3 BLAS triangular\nsolver, <tt>(D)TRSM</tt>. The NetLib reference implementation is rather\nnaive, and an optimized implementation of BLAS is likely to boost the\nperformance.</li>\n<li>Choice of initial value and scaling for numerical optimization. If\nthey are suitably chosen, the number of iterations required to\nachieve convergence is reduced.</li>\n</ol>\n<p>The script\n<a href=\"https://gitlab.com/congma/libsncompress/blob/master/scripts/jlacompress\" rel=\"nofollow\">\u261e</a><tt>jlacompress</tt>\nattempts to automatically create acceptable initial value and scaling\nthat is optimized for the <em>default</em> compression used in the <a href=\"https://arxiv.org/abs/1401.4064\" rel=\"nofollow\">JLA\npaper</a>. The automatic initial value and scaling are not optimized for\nany other usage cases.</p>\n</div>\n<div id=\"reporting-bugs\">\n<h2>Reporting Bugs</h2>\n<p>Please report problems via the <a href=\"https://gitlab.com/congma/libsncompress/issues\" rel=\"nofollow\">issue tracker</a>.</p>\n</div>\n<div id=\"bibliography\">\n<h2>Bibliography</h2>\n<p>If you use this program in your research, we would like to suggest you\ncite the following paper (\u201cM16\u201d):</p>\n<p>Ma, C., Corasaniti, P.-S., &amp; Bassett, B.\u00a0A. 2016, MNRAS, 463, 1651,\n<a href=\"https://doi.org/10.1093/mnras/stw2069\" rel=\"nofollow\">\u261e</a><tt>doi: 10.1093/mnras/stw2069</tt></p>\n<p>The following BibTeX entry could be useful in a LaTeX document:</p>\n<pre>@ARTICLE{2016MNRAS.463.1651M,\n   author = {{Ma}, C. and {Corasaniti}, P.-S. and {Bassett}, B.~A.},\n    title = \"{Application of Bayesian graphs to SN Ia data analysis and compression}\",\n  journal = {MNRAS},\narchivePrefix = \"arXiv\",\n   eprint = {1603.08519},\n     year = 2016,\n    month = dec,\n   volume = 463,\n    pages = {1651-1665},\n      doi = {10.1093/mnras/stw2069}\n}\n</pre>\n</div>\n\n          </div>"}, "last_serial": 4905619, "releases": {"0.0.5.post1": [{"comment_text": "", "digests": {"md5": "4afeb47b63ce457370bee82f97287481", "sha256": "a6caa914d27f162bb2f8a94f1ffc44961be3b9523ba932c5f4e36db0e234ff4a"}, "downloads": -1, "filename": "libsncompress-0.0.5.post1-py2.py3-none-any.whl", "has_sig": true, "md5_digest": "4afeb47b63ce457370bee82f97287481", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 41074, "upload_time": "2018-03-21T11:40:17", "upload_time_iso_8601": "2018-03-21T11:40:17.735806Z", "url": "https://files.pythonhosted.org/packages/05/39/f8f0d44740e4c1b88f5dba0c5978890a0a1003d4ef371740f9a4fd71eda5/libsncompress-0.0.5.post1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1c418fbf9d1a4a515cdd1019e0b531d3", "sha256": "ffc53a6feebb7852c05d734070eb3cdde3d063376185240114917bd72bb9a9fb"}, "downloads": -1, "filename": "libsncompress-0.0.5.post1.tar.gz", "has_sig": false, "md5_digest": "1c418fbf9d1a4a515cdd1019e0b531d3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 46962, "upload_time": "2018-03-21T11:22:15", "upload_time_iso_8601": "2018-03-21T11:22:15.847833Z", "url": "https://files.pythonhosted.org/packages/e0/42/d2f02f942eb5299cb63f4028e2b10f7156405e80d4e6c6708b81b78dc52f/libsncompress-0.0.5.post1.tar.gz", "yanked": false}], "0.0.5.post2": [{"comment_text": "", "digests": {"md5": "aac9bf05972066ca37a0955f4328b74a", "sha256": "ddaf8d95dec951e769de65ea5e0a7e9057fff3c8148d5a3bca7b3a64895c15eb"}, "downloads": -1, "filename": "libsncompress-0.0.5.post2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "aac9bf05972066ca37a0955f4328b74a", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 41076, "upload_time": "2018-03-21T12:47:01", "upload_time_iso_8601": "2018-03-21T12:47:01.585028Z", "url": "https://files.pythonhosted.org/packages/35/40/c05d8578c562f82da52ecf5f2e3e5e49155b245a926329ec8223ed8e8cc5/libsncompress-0.0.5.post2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "da2c232708885bb4db45800b4e357450", "sha256": "d38ba2151be402f358f620a1356134c44711e2086063b57ae8df344501464eb5"}, "downloads": -1, "filename": "libsncompress-0.0.5.post2.tar.gz", "has_sig": false, "md5_digest": "da2c232708885bb4db45800b4e357450", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 48382, "upload_time": "2018-03-21T12:47:03", "upload_time_iso_8601": "2018-03-21T12:47:03.121944Z", "url": "https://files.pythonhosted.org/packages/80/7d/c4b6c0898f21ae9ccbd57ab64213b12858d1cece29ecc180e8164d5f2554/libsncompress-0.0.5.post2.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "6e4483b2da168fc861ef84373859a846", "sha256": "b5830ba2dfcb517ae011acf9c270e2294dd8af724092531d965400f491c28083"}, "downloads": -1, "filename": "libsncompress-0.0.6-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "6e4483b2da168fc861ef84373859a846", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 40951, "upload_time": "2018-03-22T05:27:45", "upload_time_iso_8601": "2018-03-22T05:27:45.858682Z", "url": "https://files.pythonhosted.org/packages/5c/26/862c2e9c3fcf3908e190a4f85bde8e58d2e0de89370db156f51096c4bbe1/libsncompress-0.0.6-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ba3701cb0eefbeaf208232a5fa0c422c", "sha256": "96fefe651db6d25ff8ac4df91ce5e43b3585a466b5898cc4e16fefbad7e02e39"}, "downloads": -1, "filename": "libsncompress-0.0.6.tar.gz", "has_sig": false, "md5_digest": "ba3701cb0eefbeaf208232a5fa0c422c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 47037, "upload_time": "2018-03-22T05:27:47", "upload_time_iso_8601": "2018-03-22T05:27:47.463987Z", "url": "https://files.pythonhosted.org/packages/13/cc/44e26fd28bb7df03b95b0f7374545a7e4860da4d36e20e511d86c8a8fc0b/libsncompress-0.0.6.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "335bda78fdaa5069c940871c05df8eb4", "sha256": "91b38ba760ab10e608572bd4aa263a0aab58a121da7def69323629db4cf69554"}, "downloads": -1, "filename": "libsncompress-0.0.7-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "335bda78fdaa5069c940871c05df8eb4", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 41167, "upload_time": "2018-03-27T03:28:14", "upload_time_iso_8601": "2018-03-27T03:28:14.611282Z", "url": "https://files.pythonhosted.org/packages/ad/6b/7d72baa35b117bd3d387294169d302f2f80285e75e7c11d0b2bba50b97bf/libsncompress-0.0.7-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e4c8b354786da6ae9a844bb30ba2f5ef", "sha256": "2f8f732173b8e8c92cff38727aefcc74171ccfb7db61a88b4afc480c51e77aef"}, "downloads": -1, "filename": "libsncompress-0.0.7.tar.gz", "has_sig": false, "md5_digest": "e4c8b354786da6ae9a844bb30ba2f5ef", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 53419, "upload_time": "2018-03-27T03:28:15", "upload_time_iso_8601": "2018-03-27T03:28:15.637222Z", "url": "https://files.pythonhosted.org/packages/fc/35/d522c4a3bd5da873733d3f1ccfdf080d0323bc9298fb63cf4b80d28b14d0/libsncompress-0.0.7.tar.gz", "yanked": false}], "0.0.8": [{"comment_text": "", "digests": {"md5": "3dd9da00950221f6aac70305e6c7b47c", "sha256": "13b9105b928334fd499a2a753127dc93998e136a76183caf8bf81e338f8c0f66"}, "downloads": -1, "filename": "libsncompress-0.0.8-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "3dd9da00950221f6aac70305e6c7b47c", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*, !=3.5.*, <3.8", "size": 41257, "upload_time": "2019-03-06T14:03:36", "upload_time_iso_8601": "2019-03-06T14:03:36.937202Z", "url": "https://files.pythonhosted.org/packages/8a/a7/aa40595069a33c7f53ba93f2083676f7873c5d3fedf16559d7ea6770fd27/libsncompress-0.0.8-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c804e5ba38914b39bcf623b3f06fadb9", "sha256": "791516482ed053812d4f6c2d296acea770a3d080fe1b8fe22988c20a7f60b95a"}, "downloads": -1, "filename": "libsncompress-0.0.8.tar.gz", "has_sig": false, "md5_digest": "c804e5ba38914b39bcf623b3f06fadb9", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*, !=3.5.*, <3.8", "size": 50866, "upload_time": "2019-03-06T14:03:38", "upload_time_iso_8601": "2019-03-06T14:03:38.941999Z", "url": "https://files.pythonhosted.org/packages/23/22/7867d0d49cd065c2b3f84cbcb1b22e174ac500fc6c8b1c5ac8ff2feb1dc3/libsncompress-0.0.8.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "3dd9da00950221f6aac70305e6c7b47c", "sha256": "13b9105b928334fd499a2a753127dc93998e136a76183caf8bf81e338f8c0f66"}, "downloads": -1, "filename": "libsncompress-0.0.8-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "3dd9da00950221f6aac70305e6c7b47c", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*, !=3.5.*, <3.8", "size": 41257, "upload_time": "2019-03-06T14:03:36", "upload_time_iso_8601": "2019-03-06T14:03:36.937202Z", "url": "https://files.pythonhosted.org/packages/8a/a7/aa40595069a33c7f53ba93f2083676f7873c5d3fedf16559d7ea6770fd27/libsncompress-0.0.8-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c804e5ba38914b39bcf623b3f06fadb9", "sha256": "791516482ed053812d4f6c2d296acea770a3d080fe1b8fe22988c20a7f60b95a"}, "downloads": -1, "filename": "libsncompress-0.0.8.tar.gz", "has_sig": false, "md5_digest": "c804e5ba38914b39bcf623b3f06fadb9", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*, !=3.5.*, <3.8", "size": 50866, "upload_time": "2019-03-06T14:03:38", "upload_time_iso_8601": "2019-03-06T14:03:38.941999Z", "url": "https://files.pythonhosted.org/packages/23/22/7867d0d49cd065c2b3f84cbcb1b22e174ac500fc6c8b1c5ac8ff2feb1dc3/libsncompress-0.0.8.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:46:17 2020"}