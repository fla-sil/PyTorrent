{"info": {"author": "Massimo DiPierro", "author_email": "massimo.dipierro@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "## Introduction\n\n`workflow.py` is a minimalist file based workflow engine. It runs as a background process and can automate certain tasks such as deleting old files, emailing you when new files are created or run a script to process new files.\n\n## License\n\n3-clause BSD License\n\nCopyright (c) 2012, Massimo Di Pierro\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n- Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n- Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n- Neither the name of the <organization> nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n## Configuring and Starting the workflow\n\n- create a file `workflow.config` using the syntax below\n- run `workflow.py` in that folder\n\n## Workflow options\n\n- `-f <path>` the folder to monitor and process\n- `-s <seconds>` the time interval between checks for new files\n- `-n <name>` the current filename, defaults to `$0`\n- `-x <path>` the config file to use (workflow.config)\n- `-y <path>` the cache file to use (workflow.cache.db)\n- `-l <path>` the output logfile (else console output)\n- `-d` daemonizes the workflow process\n- `-c <rulename>` does not start the workflow but clears a rule (see below)\n\n## `workflow.config` syntax\n\n`workflow.config` consists of a series of rules with the following syntax\n\n    rulename: pattern [dt]: command\n\nwhere \n- `rulename` is the name of the rule (cannot contain spaces).\n- `pattern` is a glob pattern for files to monitor.\n- `dt` is a time interval (default is 1 second). Only files modified more recently than `dt` seconds will be considered.\n- `command` is the command to execute for each file matching `pattern` created more than `dt` seconds ago and not processed already. If the command ends in `&`, it is executed in background, else it blocks the workflow until completion. The name of the matching file can be referred to into the command with `$0`. Multiline commands can be continued with `\\`.\n\nLines starting with `#` are interpreted as comments and ignored.\n\n## Examples of rules\n\n### Delete all `*.log` files older than one day\n\n    delete_old_logs: *.log [1d]: rm $0\n\n### Move all `*.txt` files older than one hour to other folder\n\n    move_old_txt: *.txt [1h]: mv $0 otherfolder/$0\n\n### Email me when a new `*.doc` file is created\n\n    email_me_on_new_doc: *.doc: mail -s 'new file: $0' me@example.com < /dev/null\n\n### Process new `*.dat` files using a Python script\n\n    process_dat: *.dat: python process.py $0\n\n### Crate a finite state machine for each `*.src` file\n\n    rule1: *.src [1s]: echo > $0.state.1\n    rule2: *.state.1 [1s]: mv $0 `expr \"$0\" : '\\(.*\\).1'`.2\n    rule3: *.state.2 [1s]: mv $0 `expr \"$0\" : '\\(.*\\).2'`.3\n    rule4: *.state.3 [1s]: rm $0\n\n## Details\n\nWhen a file matches a pattern, a new process is created to execute the corresponding command. The pid of the process is saved in `<filename>.<rulename>.pid`. This file is deleted when the process is completed. If the process fails the output log and error is saved in `<filename>.<rulename>.err`. If the process does not fail the output is stored in `<filename>.<rulename>.out`.\n\nIf a file has already been processed according to a ceratin rule, this info is stored in a file `workflow.cache.db` and it is not processed again unless:\n\n- the mtime of the file changes (for example you edit or touch the file)\n- the rule is cleaned up.\n\nYou can cleanup a rule with\n\n    python workflow.py -c rulename\n\nThis has the effect of creating a file `.workflow.rulename.clear` which the running workflow.py picks up and clear all entries in `workflow.cache`, thus the rule will run again.\n\nYou can also delete the `workflow.cache.db` file. In this latter case all rules will run again when you restart `workflow.py`.\n\nIf the main `workflow.py` process is killed or crashes while some commands are being executed, they also are killed. You can find which files and rules where being processed by looking for `<filename>.<rulename>.pid` files. If you restart `workflow.py` those pid files are deleted.\n\nIf a rule results in an error and a `<filename>.<rulename>.err` is created, the file is not processed again according to the rule, unless the error file is deleted.\n\nIf a file is edited or touched and the rule runs again, the `<filename>.<rulename>.out` will be overwritten.\n\nUnless otherwise specified each file is processed 1s after it is last modified. It is possible that a different process is still writing the file but it is pausing more than 1s between writes (for example the file is being downloaded via a slow connection). In this case it is best to download the file with a different name than the name used for the patterm and rename the file to its proper name after the write of the file is completed. This must be handled outside of workflow. Workflow has no way of knowing when a file is completed or not.\n\nIf the `workflow.config` file is edited or changed, it is realoaded without the need to re-start `workflow.py`.", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/mdipierro/workflow", "keywords": "workflow", "license": "BSD", "maintainer": null, "maintainer_email": null, "name": "file-workflow", "package_url": "https://pypi.org/project/file-workflow/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/file-workflow/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/mdipierro/workflow"}, "release_url": "https://pypi.org/project/file-workflow/0.1/", "requires_dist": null, "requires_python": null, "summary": "a minimalist file-based workflow system", "version": "0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            ## Introduction<br><br>`workflow.py` is a minimalist file based workflow engine. It runs as a background process and can automate certain tasks such as deleting old files, emailing you when new files are created or run a script to process new files.<br><br>## License<br><br>3-clause BSD License<br><br>Copyright (c) 2012, Massimo Di Pierro<br>All rights reserved.<br><br>Redistribution and use in source and binary forms, with or without<br>modification, are permitted provided that the following conditions are met:<br><br>- Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.<br>- Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.<br>- Neither the name of the &lt;organization&gt; nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.<br><br>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND<br>ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED<br>WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE<br>DISCLAIMED. IN NO EVENT SHALL &lt;COPYRIGHT HOLDER&gt; BE LIABLE FOR ANY<br>DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES<br>(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;<br>LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND<br>ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT<br>(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS<br>SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.<br><br>## Configuring and Starting the workflow<br><br>- create a file `workflow.config` using the syntax below<br>- run `workflow.py` in that folder<br><br>## Workflow options<br><br>- `-f &lt;path&gt;` the folder to monitor and process<br>- `-s &lt;seconds&gt;` the time interval between checks for new files<br>- `-n &lt;name&gt;` the current filename, defaults to `$0`<br>- `-x &lt;path&gt;` the config file to use (workflow.config)<br>- `-y &lt;path&gt;` the cache file to use (workflow.cache.db)<br>- `-l &lt;path&gt;` the output logfile (else console output)<br>- `-d` daemonizes the workflow process<br>- `-c &lt;rulename&gt;` does not start the workflow but clears a rule (see below)<br><br>## `workflow.config` syntax<br><br>`workflow.config` consists of a series of rules with the following syntax<br><br>    rulename: pattern [dt]: command<br><br>where <br>- `rulename` is the name of the rule (cannot contain spaces).<br>- `pattern` is a glob pattern for files to monitor.<br>- `dt` is a time interval (default is 1 second). Only files modified more recently than `dt` seconds will be considered.<br>- `command` is the command to execute for each file matching `pattern` created more than `dt` seconds ago and not processed already. If the command ends in `&amp;`, it is executed in background, else it blocks the workflow until completion. The name of the matching file can be referred to into the command with `$0`. Multiline commands can be continued with `\\`.<br><br>Lines starting with `#` are interpreted as comments and ignored.<br><br>## Examples of rules<br><br>### Delete all `*.log` files older than one day<br><br>    delete_old_logs: *.log [1d]: rm $0<br><br>### Move all `*.txt` files older than one hour to other folder<br><br>    move_old_txt: *.txt [1h]: mv $0 otherfolder/$0<br><br>### Email me when a new `*.doc` file is created<br><br>    email_me_on_new_doc: *.doc: mail -s 'new file: $0' me@example.com &lt; /dev/null<br><br>### Process new `*.dat` files using a Python script<br><br>    process_dat: *.dat: python process.py $0<br><br>### Crate a finite state machine for each `*.src` file<br><br>    rule1: *.src [1s]: echo &gt; $0.state.1<br>    rule2: *.state.1 [1s]: mv $0 `expr \"$0\" : '\\(.*\\).1'`.2<br>    rule3: *.state.2 [1s]: mv $0 `expr \"$0\" : '\\(.*\\).2'`.3<br>    rule4: *.state.3 [1s]: rm $0<br><br>## Details<br><br>When a file matches a pattern, a new process is created to execute the corresponding command. The pid of the process is saved in `&lt;filename&gt;.&lt;rulename&gt;.pid`. This file is deleted when the process is completed. If the process fails the output log and error is saved in `&lt;filename&gt;.&lt;rulename&gt;.err`. If the process does not fail the output is stored in `&lt;filename&gt;.&lt;rulename&gt;.out`.<br><br>If a file has already been processed according to a ceratin rule, this info is stored in a file `workflow.cache.db` and it is not processed again unless:<br><br>- the mtime of the file changes (for example you edit or touch the file)<br>- the rule is cleaned up.<br><br>You can cleanup a rule with<br><br>    python workflow.py -c rulename<br><br>This has the effect of creating a file `.workflow.rulename.clear` which the running workflow.py picks up and clear all entries in `workflow.cache`, thus the rule will run again.<br><br>You can also delete the `workflow.cache.db` file. In this latter case all rules will run again when you restart `workflow.py`.<br><br>If the main `workflow.py` process is killed or crashes while some commands are being executed, they also are killed. You can find which files and rules where being processed by looking for `&lt;filename&gt;.&lt;rulename&gt;.pid` files. If you restart `workflow.py` those pid files are deleted.<br><br>If a rule results in an error and a `&lt;filename&gt;.&lt;rulename&gt;.err` is created, the file is not processed again according to the rule, unless the error file is deleted.<br><br>If a file is edited or touched and the rule runs again, the `&lt;filename&gt;.&lt;rulename&gt;.out` will be overwritten.<br><br>Unless otherwise specified each file is processed 1s after it is last modified. It is possible that a different process is still writing the file but it is pausing more than 1s between writes (for example the file is being downloaded via a slow connection). In this case it is best to download the file with a different name than the name used for the patterm and rename the file to its proper name after the write of the file is completed. This must be handled outside of workflow. Workflow has no way of knowing when a file is completed or not.<br><br>If the `workflow.config` file is edited or changed, it is realoaded without the need to re-start `workflow.py`.\n          </div>"}, "last_serial": 427853, "releases": {"0.1": []}, "urls": [], "timestamp": "Fri May  8 00:42:30 2020"}