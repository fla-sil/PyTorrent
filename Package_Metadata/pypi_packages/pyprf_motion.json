{"info": {"author": "Marian Schneider, Ingo Marquardt", "author_email": "marian.schneider@maastrichtuniversity.nl", "bugtrack_url": null, "classifiers": [], "description": "pyprf_motion\n============\n\nPopulation receptive field analysis for motion-sensitive early- and\nmid-level visual cortex.\n\nThis is an extension of the `pyprf\npackage <https://github.com/ingo-m/pypRF>`__. Compared to pyprf,\npyprf_motion offers stimuli that were specifically optimized to elicit\nresponses from motion-sensitive areas. On the analysis side,\npyprf_motion offers some additional features made necessary by the\ndifferent stimulation type (model positions defined in polar\ncoordinates, sub-TR temporal resolution for model creation,\ncross-validation for model fitting) at the cost of some speed and\nflexibility. There is currently no support for GPU.\n\nInstallation\n------------\n\nFor installation, follow these steps:\n\n0. (Optional) Create conda environment\n\n.. code:: bash\n\n   conda create -n env_pyprf_motion python=2.7\n   source activate env_pyprf_motion\n   conda install pip\n\n1. Clone repository\n\n.. code:: bash\n\n   git clone https://github.com/MSchnei/pyprf_motion.git\n\n2. Install numpy, e.g.\u00a0by running:\n\n.. code:: bash\n\n   pip install numpy\n\n3. Install pyprf_motion with pip\n\n.. code:: bash\n\n   pip install /path/to/cloned/pyprf_motion\n\nDependencies\n------------\n\n`Python 2.7 <https://www.python.org/download/releases/2.7/>`__\n\n+----------------------------------------------+----------------+\n| Package                                      | Tested version |\n+==============================================+================+\n| `NumPy <http://www.numpy.org/>`__            | 1.14.0         |\n+----------------------------------------------+----------------+\n| `SciPy <http://www.scipy.org/>`__            | 1.0.0          |\n+----------------------------------------------+----------------+\n| `NiBabel <http://nipy.org/nibabel/>`__       | 2.2.1          |\n+----------------------------------------------+----------------+\n| `cython <http://cython.org/>`__              | 0.27.1         |\n+----------------------------------------------+----------------+\n| `tensorflow <https://www.tensorflow.org/>`__ | 1.4.0          |\n+----------------------------------------------+----------------+\n| `scikit-learn <scikit-learn.org/>`__         | 0.19.1         |\n+----------------------------------------------+----------------+\n\nHow to use\n----------\n\n1. Present stimuli and record fMRI data\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe PsychoPy scripts in the stimulus_presentation folder can be used to\nmap motion-sensitive visual areas (especially area hMT+) using the pRF\nframework.\n\n1. Specify your desired parameters in the config file.\n\n2. Run the createTexMasks.py file to generate relevant masks and\n   textures. Masks and textures will be saved as numpy arrays in .npz\n   format in the parent folder called MaskTextures.\n\n3. Run the createCond.py file to generate the condition order. Condition\n   and target presentation orders will be saved as numpy arrays in .npz\n   format in the parent folder called Conditions.\n\n4. Run the stimulus presentation file motLoc.py in PsychoPy. The\n   stimulus setup should look like the following screen-shot:\n\n2. Prepare spatial and temporal information for experiment as arrays\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n1. Run prepro_get_spat_info.py in the prepro folder to obtain an array\n   with the spatial information of the experiment.\n\n2. Run prepro_get_temp_info.py in the prepro folder to obtain an array\n   with the temporal information of the experiment.\n\n3. Prepare the input data\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe input data should be motion-corrected, high-pass filtered and\n(optionally) distortion-corrected. If desired, spatial as well as\ntemporal smoothing can be applied. The PrePro folder contains some\nauxiliary scripts to perform some of these functions.\n\n4. Adjust the csv file\n~~~~~~~~~~~~~~~~~~~~~~\n\nAdjust the information in the config_default.csv file in the Analysis\nfolder, such that the provided information is correct. It is recommended\nto make a specific copy of the csv file for every subject.\n\n5. Run pyprf_motion\n~~~~~~~~~~~~~~~~~~~\n\nOpen a terminal and run\n\n::\n\n   pyprf_motion -config path/to/custom_config.csv\n\nReferences\n----------\n\nThis application is based on the following work:\n\n-  Dumoulin, S. O., & Wandell, B. A. (2008). Population receptive field\n   estimates in human visual cortex. NeuroImage, 39(2), 647\u2013660.\n   https://doi.org/10.1016/j.neuroimage.2007.09.034\n\n-  Amano, K., Wandell, B. A., & Dumoulin, S. O. (2009). Visual field\n   maps, population receptive field sizes, and visual field coverage in\n   the human MT+ complex. Journal of Neurophysiology, 102(5), 2704\u201318.\n   https://doi.org/10.1152/jn.00102.2009\n\n-  van Dijk, J. A., de Haas, B., Moutsiana, C., & Schwarzkopf, D. S.\n   (2016). Intersession reliability of population receptive field\n   estimates. NeuroImage, 143, 293\u2013303.\n   https://doi.org/10.1016/j.neuroimage.2016.09.013\n\nLicense\n-------\n\nThe project is licensed under `GNU General Public License Version\n3 <http://www.gnu.org/licenses/gpl.html>`__.\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/MSchnei/pyprf_motion", "keywords": "pRF", "license": "GNU General Public License Version 3", "maintainer": "", "maintainer_email": "", "name": "pyprf_motion", "package_url": "https://pypi.org/project/pyprf_motion/", "platform": "", "project_url": "https://pypi.org/project/pyprf_motion/", "project_urls": {"Homepage": "https://github.com/MSchnei/pyprf_motion"}, "release_url": "https://pypi.org/project/pyprf_motion/1.0.4/", "requires_dist": null, "requires_python": "", "summary": "Population receptive field analysis for motion-sensitive                     early- and mid-level visual cortex.", "version": "1.0.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>Population receptive field analysis for motion-sensitive early- and\nmid-level visual cortex.</p>\n<p>This is an extension of the <a href=\"https://github.com/ingo-m/pypRF\" rel=\"nofollow\">pyprf\npackage</a>. Compared to pyprf,\npyprf_motion offers stimuli that were specifically optimized to elicit\nresponses from motion-sensitive areas. On the analysis side,\npyprf_motion offers some additional features made necessary by the\ndifferent stimulation type (model positions defined in polar\ncoordinates, sub-TR temporal resolution for model creation,\ncross-validation for model fitting) at the cost of some speed and\nflexibility. There is currently no support for GPU.</p>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>For installation, follow these steps:</p>\n<ol>\n<li>(Optional) Create conda environment</li>\n</ol>\n<pre>conda create -n env_pyprf_motion <span class=\"nv\">python</span><span class=\"o\">=</span><span class=\"m\">2</span>.7\n<span class=\"nb\">source</span> activate env_pyprf_motion\nconda install pip\n</pre>\n<ol>\n<li>Clone repository</li>\n</ol>\n<pre>git clone https://github.com/MSchnei/pyprf_motion.git\n</pre>\n<ol>\n<li>Install numpy, e.g.\u00a0by running:</li>\n</ol>\n<pre>pip install numpy\n</pre>\n<ol>\n<li>Install pyprf_motion with pip</li>\n</ol>\n<pre>pip install /path/to/cloned/pyprf_motion\n</pre>\n</div>\n<div id=\"dependencies\">\n<h2>Dependencies</h2>\n<p><a href=\"https://www.python.org/download/releases/2.7/\" rel=\"nofollow\">Python 2.7</a></p>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Package</th>\n<th>Tested version</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><a href=\"http://www.numpy.org/\" rel=\"nofollow\">NumPy</a></td>\n<td>1.14.0</td>\n</tr>\n<tr><td><a href=\"http://www.scipy.org/\" rel=\"nofollow\">SciPy</a></td>\n<td>1.0.0</td>\n</tr>\n<tr><td><a href=\"http://nipy.org/nibabel/\" rel=\"nofollow\">NiBabel</a></td>\n<td>2.2.1</td>\n</tr>\n<tr><td><a href=\"http://cython.org/\" rel=\"nofollow\">cython</a></td>\n<td>0.27.1</td>\n</tr>\n<tr><td><a href=\"https://www.tensorflow.org/\" rel=\"nofollow\">tensorflow</a></td>\n<td>1.4.0</td>\n</tr>\n<tr><td><a href=\"scikit-learn.org/\" rel=\"nofollow\">scikit-learn</a></td>\n<td>0.19.1</td>\n</tr>\n</tbody>\n</table>\n</div>\n<div id=\"how-to-use\">\n<h2>How to use</h2>\n<div id=\"present-stimuli-and-record-fmri-data\">\n<h3>1. Present stimuli and record fMRI data</h3>\n<p>The PsychoPy scripts in the stimulus_presentation folder can be used to\nmap motion-sensitive visual areas (especially area hMT+) using the pRF\nframework.</p>\n<ol>\n<li>Specify your desired parameters in the config file.</li>\n<li>Run the createTexMasks.py file to generate relevant masks and\ntextures. Masks and textures will be saved as numpy arrays in .npz\nformat in the parent folder called MaskTextures.</li>\n<li>Run the createCond.py file to generate the condition order. Condition\nand target presentation orders will be saved as numpy arrays in .npz\nformat in the parent folder called Conditions.</li>\n<li>Run the stimulus presentation file motLoc.py in PsychoPy. The\nstimulus setup should look like the following screen-shot:</li>\n</ol>\n</div>\n<div id=\"prepare-spatial-and-temporal-information-for-experiment-as-arrays\">\n<h3>2. Prepare spatial and temporal information for experiment as arrays</h3>\n<ol>\n<li>Run prepro_get_spat_info.py in the prepro folder to obtain an array\nwith the spatial information of the experiment.</li>\n<li>Run prepro_get_temp_info.py in the prepro folder to obtain an array\nwith the temporal information of the experiment.</li>\n</ol>\n</div>\n<div id=\"prepare-the-input-data\">\n<h3>3. Prepare the input data</h3>\n<p>The input data should be motion-corrected, high-pass filtered and\n(optionally) distortion-corrected. If desired, spatial as well as\ntemporal smoothing can be applied. The PrePro folder contains some\nauxiliary scripts to perform some of these functions.</p>\n</div>\n<div id=\"adjust-the-csv-file\">\n<h3>4. Adjust the csv file</h3>\n<p>Adjust the information in the config_default.csv file in the Analysis\nfolder, such that the provided information is correct. It is recommended\nto make a specific copy of the csv file for every subject.</p>\n</div>\n<div id=\"run-pyprf-motion\">\n<h3>5. Run pyprf_motion</h3>\n<p>Open a terminal and run</p>\n<pre>pyprf_motion -config path/to/custom_config.csv\n</pre>\n</div>\n</div>\n<div id=\"references\">\n<h2>References</h2>\n<p>This application is based on the following work:</p>\n<ul>\n<li>Dumoulin, S. O., &amp; Wandell, B. A. (2008). Population receptive field\nestimates in human visual cortex. NeuroImage, 39(2), 647\u2013660.\n<a href=\"https://doi.org/10.1016/j.neuroimage.2007.09.034\" rel=\"nofollow\">https://doi.org/10.1016/j.neuroimage.2007.09.034</a></li>\n<li>Amano, K., Wandell, B. A., &amp; Dumoulin, S. O. (2009). Visual field\nmaps, population receptive field sizes, and visual field coverage in\nthe human MT+ complex. Journal of Neurophysiology, 102(5), 2704\u201318.\n<a href=\"https://doi.org/10.1152/jn.00102.2009\" rel=\"nofollow\">https://doi.org/10.1152/jn.00102.2009</a></li>\n<li>van Dijk, J. A., de Haas, B., Moutsiana, C., &amp; Schwarzkopf, D. S.\n(2016). Intersession reliability of population receptive field\nestimates. NeuroImage, 143, 293\u2013303.\n<a href=\"https://doi.org/10.1016/j.neuroimage.2016.09.013\" rel=\"nofollow\">https://doi.org/10.1016/j.neuroimage.2016.09.013</a></li>\n</ul>\n</div>\n<div id=\"license\">\n<h2>License</h2>\n<p>The project is licensed under <a href=\"http://www.gnu.org/licenses/gpl.html\" rel=\"nofollow\">GNU General Public License Version\n3</a>.</p>\n</div>\n\n          </div>"}, "last_serial": 4507146, "releases": {"1.0.2": [{"comment_text": "", "digests": {"md5": "600e74f1e364fa981ae585a7699a9dd8", "sha256": "4ce58ff36b4628c5e3076fc7333bc74bad47301ce6718e5cfc2d82d83eb5fc84"}, "downloads": -1, "filename": "pyprf_motion-1.0.2.tar.gz", "has_sig": false, "md5_digest": "600e74f1e364fa981ae585a7699a9dd8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 154721, "upload_time": "2018-07-10T18:13:39", "upload_time_iso_8601": "2018-07-10T18:13:39.113553Z", "url": "https://files.pythonhosted.org/packages/03/85/16dda26d07e63d05c0a4a380d462b8e6e2f25f4716cd13ef4832faa45e0e/pyprf_motion-1.0.2.tar.gz", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "c39207959853fd946bb0d652ec0f4910", "sha256": "3d3ed9fa9312503ab0450558c6bd9c04d48fb51bc7c6baf96ee79ed12d18b7aa"}, "downloads": -1, "filename": "pyprf_motion-1.0.3.tar.gz", "has_sig": false, "md5_digest": "c39207959853fd946bb0d652ec0f4910", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 155236, "upload_time": "2018-07-10T18:25:32", "upload_time_iso_8601": "2018-07-10T18:25:32.324056Z", "url": "https://files.pythonhosted.org/packages/20/df/e87bcaf46ad54ea4ba6d08c08c9e3bbd5a8d9ffd83554e2dec35aa6cfd45/pyprf_motion-1.0.3.tar.gz", "yanked": false}], "1.0.4": [{"comment_text": "", "digests": {"md5": "cc31a0831623801d1b5d6f623e8dc409", "sha256": "152ac349a30b3559af5c183441d6af808c3a0413cdbc72b48644367911749755"}, "downloads": -1, "filename": "pyprf_motion-1.0.4.tar.gz", "has_sig": false, "md5_digest": "cc31a0831623801d1b5d6f623e8dc409", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 158981, "upload_time": "2018-11-20T12:38:51", "upload_time_iso_8601": "2018-11-20T12:38:51.229242Z", "url": "https://files.pythonhosted.org/packages/d4/37/6b38d9fe9739f8ef8422f7a1cbb58558dedda7c12e9dd366b7225cec5645/pyprf_motion-1.0.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "cc31a0831623801d1b5d6f623e8dc409", "sha256": "152ac349a30b3559af5c183441d6af808c3a0413cdbc72b48644367911749755"}, "downloads": -1, "filename": "pyprf_motion-1.0.4.tar.gz", "has_sig": false, "md5_digest": "cc31a0831623801d1b5d6f623e8dc409", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 158981, "upload_time": "2018-11-20T12:38:51", "upload_time_iso_8601": "2018-11-20T12:38:51.229242Z", "url": "https://files.pythonhosted.org/packages/d4/37/6b38d9fe9739f8ef8422f7a1cbb58558dedda7c12e9dd366b7225cec5645/pyprf_motion-1.0.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:59:09 2020"}