{"info": {"author": "Bradley  Atkins", "author_email": "bradley.atkinz@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.7"], "description": "# API Rate Limiter\n\nA simple Python object that allows you to implement client side API \nrate limiting.\n\n---\n\n## Introduction\n\nThis project was created to address a specific issue \u2013 API rate limiting\n when scanning an AWS platform.\n\nThe problem with AWS applying rate limiting to the services is that it \nis indiscriminate in nature. So if you are running a multi-threaded \nscanner such as ScoutSuite, while for example an Auto Scaling Group is \ntrying to scale something, the auto Scaling can fail because AWS does \nnot distinguish between the third party scanner and its own services.\n\nThis is a cause for frustration amongst the platform support team and \ncan also cause an outage, particularly in the early stages of \ndevelopment of a new service, where resilience and high availability are\nstill but a twinkle in the architect's eye...\n\nThis is becoming more and more of an issue as consumers realise the \nnecessity of scanning their cloud platforms.\n\n## NOTE!\n\nApologies for the lack of images if you are viewing this on PyPi. For \nsome reason PyPi insist on changing the URLs to \nhttps://warehouse-test-camo.cmh1.psfhosted.org/..... I've no idea why.\nYou can read this README correctly on the home project on GitHub.\n\n## History\n\nI started looking into this issue when scanning my own client's platform\n and hit the rate limiting issue when scanning some 15k of snapshots.\n \nInitially I managed to mitigate this using the Network Link Conditioner \non the MAC I was using to run the scanner. \n\nThe NLC allows you to add latency to all outbound packets on a given \nnetwork like so:\n\n![](images/nlc.png)\n\n![](images/nlc-profile.png)\n\nThis blanket approach to delaying all outbound packets did resolve the \nissue of the rate limiting, but at a cost of causing the scanner to now\nrun for two hours in order to complete a scan of all of our development \nenvironments.\n\nNot only was this slow, but it's also not OS agnostic, so hardly a good \nsolution.\n\nIt occurred to me that if a mechanism could be created within boto3 \nitself to queue outbound API calls at a configurable rate, then this \nmight prove to be a more general solution to the issue.\n\nSo I forked botocore [here](https://github.com/museadmin/botorate) into \na project that combined forks of botocore, boto3 and ScoutSuite.\n\nThis project has the queue implemented in it and boto3 has been \nrefactored to pass through the value of the API rate in ms to botocore. \nScoutSuite is included and has simply been hardcoded to apply the queue \nto ec2 clients.\n\nThis has enabled me to conduct comparative runs between this solution \nand using the Network Link Conditioner. With the former completing in 30\n minutes and the latter in around 2 hours.\n \nThe queue was only applied to ec2 clients because I was only \nexperiencing rate limiting on the scanning of the snapshots, around 15k \n\nAt the time of writing botocore seem to be unwilling to accept the PR \nfor this as they feel that it is beyond the scope of their project to \nhandle API rate limiting. \n\nC'est la vie.\n\n## The Solution\n\nRather than cry over a missed opportunity I've now taken the rate \nlimiter and packaged it up as a stand alone utility that anyone can \nconsume in their own projects should they need to avoid server-side rate \nlimiting:   \n\n![](images/api-rate-overview.png)\n\nIn the diagram above, each thread needing to make an API call using \na/the ec2 client calls a method that first enqueues the call in a FIFO \nqueue and then waits for it to reach the head of the queue. Thereby \ntranslating the asynchronous calls from the multiple threads into a \nsynchronous stream of calls at a configurable frequency.\n\nThis approach allows each thread to continue to leverage parallel \nprocessing of tasks while only waiting on the actual API call. So you \nstill see the increase in efficiency of the multi threaded approach.\n\nBy instantiating individual queues for each AWS service, each can be \nindividually configured with an appropriate rate for the consumer's \nplatform, or not rate limited at all.\n\ne.g. in my case I only had to limit the EC2 client because of the \nexcessive number of snapshots being scanned. \n\n## Installation\n\nIn the usual Python fashion, just import the package after it's \ninstalled in the usual fashion:\n\n```sh\nfrom apiqueue import ApiQueue\n```\n\n## Usage example\n\nSee \"The Solution\" above or look at the tests in the GitHub repo:\n\n[Tests on GitHub](https://github.com/museadmin/api-rate-limiter/tree/master/api-rate-limiter/tests)\n\n### Basic Usage\n\nSetup:\n\n* Instantiate the API Queue\n* Start it running in a background thread\n* Call the enqueue() method to join the queue\n* Poll the waiting state until false\n* Make your API call\n\nOn close:\n\n* Soft stop the API Queue \u2013 Waits for background thread to exit or timeout\n\n#### Example - 1 call every 100ms\n```\n    api_queue = ApiQueue(100)\n    api_queue.start()\n    \n    ...\n    \n    def some_method()\n        waiter = api_queue.enqueue()\n        while waiter.waiting is True:\n            pass\n                \n        client.describe_instances()\n    \n    ...\n    \n    api_queue.stop(True) \n    \n    \n```\n\n## Release History\n\n* 0.1.0\n    * CHANGE: Initial code commit\n    * ADD LICENCE\n    * ADD Detailed README\n    * FIX Error handling in integration test\n\n* 0.1.1\n    * FIX Remove requires for multiprocessing as now in Python3 main lib\n## Meta\n\nBradley Atkins \u2013 bradley.atkinz @ gmail.com\n\nDistributed under the MIT license. See ``LICENSE`` for more information.\n\n[This Project on GitHub](https://github.com/museadmin/api-rate-limiter)\n\n## Contributing\n\n1. Fork it (<https://github.com/museadmin/api-rate-limiter>)\n2. Create your feature branch (`git checkout -b feature/fooBar`)\n3. Commit your changes (`git commit -am 'Add some fooBar'`)\n4. Push to the branch (`git push origin feature/fooBar`)\n5. Create a new Pull Request\n6. Email me if I don't notice!", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/museadmin/api-rate-limiter", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "apiqueue", "package_url": "https://pypi.org/project/apiqueue/", "platform": "", "project_url": "https://pypi.org/project/apiqueue/", "project_urls": {"Homepage": "https://github.com/museadmin/api-rate-limiter"}, "release_url": "https://pypi.org/project/apiqueue/0.1.1/", "requires_dist": null, "requires_python": "", "summary": "Implement client side API rate limiting", "version": "0.1.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>API Rate Limiter</h1>\n<p>A simple Python object that allows you to implement client side API\nrate limiting.</p>\n<hr>\n<h2>Introduction</h2>\n<p>This project was created to address a specific issue \u2013 API rate limiting\nwhen scanning an AWS platform.</p>\n<p>The problem with AWS applying rate limiting to the services is that it\nis indiscriminate in nature. So if you are running a multi-threaded\nscanner such as ScoutSuite, while for example an Auto Scaling Group is\ntrying to scale something, the auto Scaling can fail because AWS does\nnot distinguish between the third party scanner and its own services.</p>\n<p>This is a cause for frustration amongst the platform support team and\ncan also cause an outage, particularly in the early stages of\ndevelopment of a new service, where resilience and high availability are\nstill but a twinkle in the architect's eye...</p>\n<p>This is becoming more and more of an issue as consumers realise the\nnecessity of scanning their cloud platforms.</p>\n<h2>NOTE!</h2>\n<p>Apologies for the lack of images if you are viewing this on PyPi. For\nsome reason PyPi insist on changing the URLs to\n<a href=\"https://warehouse-test-camo.cmh1.psfhosted.org/\" rel=\"nofollow\">https://warehouse-test-camo.cmh1.psfhosted.org/</a>..... I've no idea why.\nYou can read this README correctly on the home project on GitHub.</p>\n<h2>History</h2>\n<p>I started looking into this issue when scanning my own client's platform\nand hit the rate limiting issue when scanning some 15k of snapshots.</p>\n<p>Initially I managed to mitigate this using the Network Link Conditioner\non the MAC I was using to run the scanner.</p>\n<p>The NLC allows you to add latency to all outbound packets on a given\nnetwork like so:</p>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1d8b6a37d8d9886d5b249bcbfbff847ecb9a23cf/696d616765732f6e6c632e706e67\"></p>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2a34372b8c3ecc3586a81656abf2b17de9175d64/696d616765732f6e6c632d70726f66696c652e706e67\"></p>\n<p>This blanket approach to delaying all outbound packets did resolve the\nissue of the rate limiting, but at a cost of causing the scanner to now\nrun for two hours in order to complete a scan of all of our development\nenvironments.</p>\n<p>Not only was this slow, but it's also not OS agnostic, so hardly a good\nsolution.</p>\n<p>It occurred to me that if a mechanism could be created within boto3\nitself to queue outbound API calls at a configurable rate, then this\nmight prove to be a more general solution to the issue.</p>\n<p>So I forked botocore <a href=\"https://github.com/museadmin/botorate\" rel=\"nofollow\">here</a> into\na project that combined forks of botocore, boto3 and ScoutSuite.</p>\n<p>This project has the queue implemented in it and boto3 has been\nrefactored to pass through the value of the API rate in ms to botocore.\nScoutSuite is included and has simply been hardcoded to apply the queue\nto ec2 clients.</p>\n<p>This has enabled me to conduct comparative runs between this solution\nand using the Network Link Conditioner. With the former completing in 30\nminutes and the latter in around 2 hours.</p>\n<p>The queue was only applied to ec2 clients because I was only\nexperiencing rate limiting on the scanning of the snapshots, around 15k</p>\n<p>At the time of writing botocore seem to be unwilling to accept the PR\nfor this as they feel that it is beyond the scope of their project to\nhandle API rate limiting.</p>\n<p>C'est la vie.</p>\n<h2>The Solution</h2>\n<p>Rather than cry over a missed opportunity I've now taken the rate\nlimiter and packaged it up as a stand alone utility that anyone can\nconsume in their own projects should they need to avoid server-side rate\nlimiting:</p>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d98046133e930cb844fea20ffc8bf42da7a90b7f/696d616765732f6170692d726174652d6f766572766965772e706e67\"></p>\n<p>In the diagram above, each thread needing to make an API call using\na/the ec2 client calls a method that first enqueues the call in a FIFO\nqueue and then waits for it to reach the head of the queue. Thereby\ntranslating the asynchronous calls from the multiple threads into a\nsynchronous stream of calls at a configurable frequency.</p>\n<p>This approach allows each thread to continue to leverage parallel\nprocessing of tasks while only waiting on the actual API call. So you\nstill see the increase in efficiency of the multi threaded approach.</p>\n<p>By instantiating individual queues for each AWS service, each can be\nindividually configured with an appropriate rate for the consumer's\nplatform, or not rate limited at all.</p>\n<p>e.g. in my case I only had to limit the EC2 client because of the\nexcessive number of snapshots being scanned.</p>\n<h2>Installation</h2>\n<p>In the usual Python fashion, just import the package after it's\ninstalled in the usual fashion:</p>\n<pre>from apiqueue import ApiQueue\n</pre>\n<h2>Usage example</h2>\n<p>See \"The Solution\" above or look at the tests in the GitHub repo:</p>\n<p><a href=\"https://github.com/museadmin/api-rate-limiter/tree/master/api-rate-limiter/tests\" rel=\"nofollow\">Tests on GitHub</a></p>\n<h3>Basic Usage</h3>\n<p>Setup:</p>\n<ul>\n<li>Instantiate the API Queue</li>\n<li>Start it running in a background thread</li>\n<li>Call the enqueue() method to join the queue</li>\n<li>Poll the waiting state until false</li>\n<li>Make your API call</li>\n</ul>\n<p>On close:</p>\n<ul>\n<li>Soft stop the API Queue \u2013 Waits for background thread to exit or timeout</li>\n</ul>\n<h4>Example - 1 call every 100ms</h4>\n<pre><code>    api_queue = ApiQueue(100)\n    api_queue.start()\n    \n    ...\n    \n    def some_method()\n        waiter = api_queue.enqueue()\n        while waiter.waiting is True:\n            pass\n                \n        client.describe_instances()\n    \n    ...\n    \n    api_queue.stop(True) \n    \n    \n</code></pre>\n<h2>Release History</h2>\n<ul>\n<li>\n<p>0.1.0</p>\n<ul>\n<li>CHANGE: Initial code commit</li>\n<li>ADD LICENCE</li>\n<li>ADD Detailed README</li>\n<li>FIX Error handling in integration test</li>\n</ul>\n</li>\n<li>\n<p>0.1.1</p>\n<ul>\n<li>FIX Remove requires for multiprocessing as now in Python3 main lib</li>\n</ul>\n</li>\n</ul>\n<h2>Meta</h2>\n<p>Bradley Atkins \u2013 bradley.atkinz @ gmail.com</p>\n<p>Distributed under the MIT license. See <code>LICENSE</code> for more information.</p>\n<p><a href=\"https://github.com/museadmin/api-rate-limiter\" rel=\"nofollow\">This Project on GitHub</a></p>\n<h2>Contributing</h2>\n<ol>\n<li>Fork it (<a href=\"https://github.com/museadmin/api-rate-limiter\" rel=\"nofollow\">https://github.com/museadmin/api-rate-limiter</a>)</li>\n<li>Create your feature branch (<code>git checkout -b feature/fooBar</code>)</li>\n<li>Commit your changes (<code>git commit -am 'Add some fooBar'</code>)</li>\n<li>Push to the branch (<code>git push origin feature/fooBar</code>)</li>\n<li>Create a new Pull Request</li>\n<li>Email me if I don't notice!</li>\n</ol>\n\n          </div>"}, "last_serial": 5831783, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "7cb1187e9fdb1d419ea2d1991afd8f65", "sha256": "505288ada9e43d4d67c9621c178f50da6834542829b640921170674a371f926f"}, "downloads": -1, "filename": "apiqueue-0.1.0.tar.gz", "has_sig": false, "md5_digest": "7cb1187e9fdb1d419ea2d1991afd8f65", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5949, "upload_time": "2019-09-12T10:43:34", "upload_time_iso_8601": "2019-09-12T10:43:34.735685Z", "url": "https://files.pythonhosted.org/packages/1d/61/71b367615b12efe690014fb21d4491dfe686685d8508265cc6b3227eca00/apiqueue-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "3585c3c0100f6cab50d6fa5605a4d871", "sha256": "617b0e9158d0018e7400631a4976c4128c9a1135a300c5cf5eb3b4456ed1936f"}, "downloads": -1, "filename": "apiqueue-0.1.1.tar.gz", "has_sig": false, "md5_digest": "3585c3c0100f6cab50d6fa5605a4d871", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5981, "upload_time": "2019-09-15T12:30:52", "upload_time_iso_8601": "2019-09-15T12:30:52.654619Z", "url": "https://files.pythonhosted.org/packages/2b/cd/cdd8ff321218ad70907e40e704f972b267c25305286a568f93e177c5c7a8/apiqueue-0.1.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "3585c3c0100f6cab50d6fa5605a4d871", "sha256": "617b0e9158d0018e7400631a4976c4128c9a1135a300c5cf5eb3b4456ed1936f"}, "downloads": -1, "filename": "apiqueue-0.1.1.tar.gz", "has_sig": false, "md5_digest": "3585c3c0100f6cab50d6fa5605a4d871", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5981, "upload_time": "2019-09-15T12:30:52", "upload_time_iso_8601": "2019-09-15T12:30:52.654619Z", "url": "https://files.pythonhosted.org/packages/2b/cd/cdd8ff321218ad70907e40e704f972b267c25305286a568f93e177c5c7a8/apiqueue-0.1.1.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:17:47 2020"}