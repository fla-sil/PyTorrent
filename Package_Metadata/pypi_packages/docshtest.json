{"info": {"author": "Valentin Lab", "author_email": "valentin.lab@kalysto.org", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: BSD License", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Unix Shell", "Topic :: Software Development", "Topic :: Software Development :: Testing"], "description": "=========\ndocshtest\n=========\n\n.. image:: https://img.shields.io/pypi/v/docshtest.svg\n    :target: https://pypi.python.org/pypi/docshtest\n\n.. image:: https://img.shields.io/travis/vaab/docshtest/master.svg?style=flat\n   :target: https://travis-ci.org/vaab/docshtest/\n   :alt: Travis CI build status\n\n.. image:: https://img.shields.io/appveyor/ci/vaab/docshtest.svg\n   :target: https://ci.appveyor.com/project/vaab/docshtest/branch/master\n   :alt: Appveyor CI build status\n\n.. image:: http://img.shields.io/codecov/c/github/vaab/docshtest.svg?style=flat\n   :target: https://codecov.io/gh/vaab/docshtest/\n   :alt: Test coverage\n\n\nDoctest for Shell - Quick, Slim and Dirty\n\n\nFeature\n=======\n\n- Quick way to write doctest in shell\n\n- Works on Windows, Linux, Python 2.7, Python 3+\n\n- Slim because it has no dependencies to other project, one file, in python\n\n- Doctest feeling\n\n- You can mix python tests ans shell tests\n\n- only checks standard output (although, you can tailor your test\n  commands to output what is meaningful to standard output.)\n\n\nCurrent Status\n==============\n\nThis is an early alpha code.\n\nMajor concerns and shortcomings:\n\n- end of blocks and final ``\\n`` are not tested correctly\n- tests execution in current directory with possible consequences.\n- no support of checking error level\n- no support of proper mixed standard error and standard output content\n- limited to ``bash`` testing (needs ``bash -n`` equivalent)\n- rough detection of ``doctests`` command blocks is relying on ``bash\n  -n`` error output. Not sure this is very solid.\n\nMinor concerns, but would be better without:\n\n- fail on first error hard-written.\n- hard-written support of ``<BLANKLINE>``\n\nPossible evolution:\n\n- profiling\n- support of python file (by extracting docs before)\n- integration in nosetests ? is it possible ?\n- colorize output ?\n- move to standalone full fledged program ?\n- coverage integration ?\n\n\nInstallation\n============\n\nYou don't need to download the GIT version of the code as ``docshtest`` is\navailable on the PyPI. So you should be able to run::\n\n    pip install docshtest\n\nIf you have downloaded the GIT sources, then you could add install\nthe current version via traditional::\n\n    python setup.py install\n\nAnd if you don't have the GIT sources but would like to get the latest\nmaster or branch from github, you could also::\n\n    pip install git+https://github.com/vaab/docshtest\n\nOr even select a specific revision (branch/tag/commit)::\n\n    pip install git+https://github.com/vaab/docshtest@master\n\n\nUsage\n=====\n\n\nQuickStart\n----------\n\n``docshtest`` is a ``doctest`` for shell command. This means it allows\nyou to integrate in your documentation some examples of shell code and\ntheir expected output that will be actually verifiable.\n\nFirst please notice that these documentation lines you are reading are\nstored in a ``README.rst`` file that will contain very soon some\nexamples of how to run ``docshtest`` and what outcome to expect.\n\nThe very first example that comes to mind is to run ``docshtest`` on\nthis very documentation::\n\n    docshtest README.rst\n\nBut doing so would generate a infinite loop ! So you can check that\nyourself, and that's done in the CI procedures.\n\nLet's introduce you the basics of writing your own testable documentation...\n\nSo this is how it works::\n\n    $ cat <<'EOF' > mydoc.rst   ## First test file\n\n    This is standard RST, we can include runnable test blocks::\n\n        $ echo 'hello world'\n        hello world\n\n    EOF\n\nNote that indentation is required, as well as the ``\"$ \"`` (dollar sign\nfollowed by a space) before the command to be executed. Please refer\nto the following section to understand how ``docshtest`` figures out\nthe end of your shell code and the start of the output.\n\nThe output starts after the end of your command, indented also, and\nwill be matched with the actual command output. If there is a mismatch\nthe test will fail, and ``docshtest`` will cancel any remaining tests.\nIf it matches, next test block will be executed.\n\nTo run our test::\n\n    $ ./docshtest mydoc.rst\n    #0001 - success (line          4)\n\n\nMultiline Commands\n------------------\n\nMultiline commands are detected with a very simple, but dirty method,\n``docshtest`` will simply provide the exact code, starting with only\nthe first line to the shell interpreter, if the shell interpreter\ncomplains, it'll try again by adding the next line to the output.\n\nThis allows to document/test multi-line shell codes like::\n\n    $ cat <<EOF > mydoc.rst   ## First test file\n\n    Multiline commands::\n\n        $ for a in \\$(seq 1 3); do\n            echo \"foo\\$a\"\n          done\n        foo1\n        foo2\n        foo3\n\n    EOF\n    $ ./docshtest mydoc.rst\n    #0001 - success (lines       4-6)\n\nPlease note that the extra indentation for the body of the ``for`` loop or\nthe ``done`` is unnecessary, but is recommended for reading::\n\n    $ cat <<EOF > mydoc.rst   ## First test file\n\n    Multiline commands::\n\n        $ for a in \\$(seq 1 3); do\n          echo \"foo\\$a\"\n        done\n        foo1\n        foo2\n        foo3\n\n    EOF\n    $ ./docshtest mydoc.rst\n    #0001 - success (lines       4-6)\n\n\nFailing test will display both expected output and current output::\n\n    $ cat <<EOF > mydoc.rst   ## First test file\n\n    Multiline commands::\n\n        $ for a in \\$(seq 1 3); do\n          echo \"foo\\$a\"\n        done\n        foo1\n        foo4\n        foo3\n\n    EOF\n    $ ./docshtest mydoc.rst\n    #0001 - failure (lines       4-6):\n      command:\n      | for a in $(seq 1 3); do\n      |   echo \"foo$a\"\n      | done\n      expected:\n      | foo1\n      | foo4\n      | foo3\n      |\n      output:\n      | foo1\n      | foo2\n      | foo3\n      |\n\nBut note that if these outputs are bigger, a standard unified diff will be\nprinted::\n\n    $ cat <<EOF > mydoc.rst   ## First test file\n\n    Multiline commands::\n\n        $ for a in \\$(seq 1 6); do\n          echo \"foo\\$a\"\n        done\n        foo1\n        foo3\n        foo4\n        foo5\n        foo6\n\n    EOF\n    $ ./docshtest mydoc.rst\n    #0001 - failure (lines       4-6):\n      command:\n      | for a in $(seq 1 6); do\n      |   echo \"foo$a\"\n      | done\n      expected:\n      | foo1\n      | foo3\n      | foo4\n      | foo5\n      | foo6\n      |\n      output:\n      | foo1\n      | foo2\n      | foo3\n      | foo4\n      | foo5\n      | foo6\n      |\n      diff:\n      --- expected\n      +++ output\n      @@ -1,4 +1,5 @@\n       foo1\n      +foo2\n       foo3\n       foo4\n       foo5\n\n\nTinkering all executed code\n---------------------------\n\nYou can transform all executed code before execution thanks to\n``--regex REGEX`` (or ``-r REGEX``) option::\n\n    $ cat <<'EOF' > mydoc.rst   ## First test file\n\n    Our tested command is 'foo'\n\n        $ foo 'hello world'\n        hello world\n\n    EOF\n    $ ./docshtest -r '#\\bfoo\\b#echo#' mydoc.rst\n    #0001 - success (line          4)\n\n\nConditional Tests\n-----------------\n\nYou might want to have conditional tests, that are triggered only\non if specific test succeeds. This feature uses ``meta`` commands\nthat are specified as shell comments in the given block::\n\n    $ cat <<'EOF' > mydoc.rst\n\n    Our tested command is 'foo'\n\n        $ echo $ENVVAR       ## docshtest: if-success-set VAR_WAS_SET\n        0\n        $ echo 'var is set'  ## docshtest: ignore-if VAR_WAS_SET\n        SHOULDFAIL\n        $ echo 'var is not set'  ## docshtest: ignore-if-not VAR_WAS_SET\n        SHOULDFAIL\n\n    EOF\n    $ ENVVAR=0 ./docshtest mydoc.rst\n    #0001 - ignored (line          4): if-success-set VAR_WAS_SET\n    #0002 - ignored (line          6): ignore-if VAR_WAS_SET\n    #0003 - failure (line          8):\n      command: \"echo 'var is not set'  ## docshtest: ignore-if-not VAR_WAS_SET\"\n      expected:\n      | SHOULDFAIL\n      |\n      output:\n      | var is not set\n      |\n\n\nCommand line\n------------\n\n``docshtest`` supports the common GNU standard ``--help`` options::\n\n    $ ./docshtest --help\n\n    docshtest - parse file and run shell doctests\n\n    Usage:\n\n        docshtest (-h|--help)\n        docshtest [[-r|--regex REGEX] ...] DOCSHTEST_FILE\n\n\n    Options:\n\n        -r REGEX, --regex REGEX\n                  Will apply this regex to the lines to be executed. You\n                  can have more than one patterns by re-using this options\n                  as many times as wanted. Regexps will be applied one by one\n                  in the same order than they are provided on the command line.\n\n\n    Examples:\n\n         ## run tests but replace executable on-the-fly for coverage support\n         docshtest README.rst -r '/\\bdocshtest\\b/coverage run docshtest.py/'\n    <BLANKLINE>\n    <BLANKLINE>\n\nFirst argument is necessary::\n\n    $ ./docshtest\n    Error: please provide a rst filename as argument. (use '--help' option to get usage info)\n\n\nContributing\n============\n\nAny suggestion or issue is welcome. Push request are very welcome,\nplease check out the guidelines.\n\n\nPush Request Guidelines\n-----------------------\n\nYou can send any code. I'll look at it and will integrate it myself in\nthe code base and leave you as the author. This process can take time and\nit'll take less time if you follow the following guidelines:\n\n- Try to stick to 80 columns wide.\n- separate your commits per smallest concern.\n- each commit should pass the tests (to allow easy bisect)\n- each functionality/bugfix commit should contain the code, tests,\n  and doc.\n- prior minor commit with typographic or code cosmetic changes are\n  very welcome. These should be tagged in their commit summary with\n  ``!minor``.\n- the commit message should follow gitchangelog rules (check the git\n  log to get examples)\n- if the commit fixes an issue or finished the implementation of a\n  feature, please mention it in the summary.\n\nIf you have some questions about guidelines which is not answered here,\nplease check the current ``git log``, you might find previous commit that\nwould show you how to deal with your issue.\n\n\nLicense\n=======\n\nCopyright (c) 2012-2019 Valentin Lab.\n\nLicensed under the `BSD License`_.\n\n.. _BSD License: http://raw.github.com/0k/sunit/master/LICENSE\n\nChangelog\n=========\n\n\n0.0.1 (2019-02-11)\n------------------\n- First import. [Valentin Lab]\n\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://github.com/0k/docshtest", "keywords": "", "license": "BSD 3-Clause License", "maintainer": "", "maintainer_email": "", "name": "docshtest", "package_url": "https://pypi.org/project/docshtest/", "platform": "", "project_url": "https://pypi.org/project/docshtest/", "project_urls": {"Homepage": "http://github.com/0k/docshtest"}, "release_url": "https://pypi.org/project/docshtest/0.0.2/", "requires_dist": null, "requires_python": "", "summary": "Doctest for shell commands", "version": "0.0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://pypi.python.org/pypi/docshtest\" rel=\"nofollow\"><img alt=\"https://img.shields.io/pypi/v/docshtest.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9b4e7211297a1fbe3485b24b4c52ba646bb4fd8f/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f646f637368746573742e737667\"></a>\n<a href=\"https://travis-ci.org/vaab/docshtest/\" rel=\"nofollow\"><img alt=\"Travis CI build status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/79356bd274fc6eef7b835faeabab25c7b58dd5f9/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f766161622f646f637368746573742f6d61737465722e7376673f7374796c653d666c6174\"></a>\n<a href=\"https://ci.appveyor.com/project/vaab/docshtest/branch/master\" rel=\"nofollow\"><img alt=\"Appveyor CI build status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/29218402ff17d19e0f3bca141e6e6050389c517f/68747470733a2f2f696d672e736869656c64732e696f2f6170707665796f722f63692f766161622f646f637368746573742e737667\"></a>\n<a href=\"https://codecov.io/gh/vaab/docshtest/\" rel=\"nofollow\"><img alt=\"Test coverage\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/465ebb6b1559447a4aa7688bf1c7e80c82b3a775/687474703a2f2f696d672e736869656c64732e696f2f636f6465636f762f632f6769746875622f766161622f646f637368746573742e7376673f7374796c653d666c6174\"></a>\n<p>Doctest for Shell - Quick, Slim and Dirty</p>\n<div id=\"feature\">\n<h2>Feature</h2>\n<ul>\n<li>Quick way to write doctest in shell</li>\n<li>Works on Windows, Linux, Python 2.7, Python 3+</li>\n<li>Slim because it has no dependencies to other project, one file, in python</li>\n<li>Doctest feeling</li>\n<li>You can mix python tests ans shell tests</li>\n<li>only checks standard output (although, you can tailor your test\ncommands to output what is meaningful to standard output.)</li>\n</ul>\n</div>\n<div id=\"current-status\">\n<h2>Current Status</h2>\n<p>This is an early alpha code.</p>\n<p>Major concerns and shortcomings:</p>\n<ul>\n<li>end of blocks and final <tt>\\n</tt> are not tested correctly</li>\n<li>tests execution in current directory with possible consequences.</li>\n<li>no support of checking error level</li>\n<li>no support of proper mixed standard error and standard output content</li>\n<li>limited to <tt>bash</tt> testing (needs <tt>bash <span class=\"pre\">-n</span></tt> equivalent)</li>\n<li>rough detection of <tt>doctests</tt> command blocks is relying on <tt>bash\n<span class=\"pre\">-n</span></tt> error output. Not sure this is very solid.</li>\n</ul>\n<p>Minor concerns, but would be better without:</p>\n<ul>\n<li>fail on first error hard-written.</li>\n<li>hard-written support of <tt>&lt;BLANKLINE&gt;</tt></li>\n</ul>\n<p>Possible evolution:</p>\n<ul>\n<li>profiling</li>\n<li>support of python file (by extracting docs before)</li>\n<li>integration in nosetests ? is it possible ?</li>\n<li>colorize output ?</li>\n<li>move to standalone full fledged program ?</li>\n<li>coverage integration ?</li>\n</ul>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>You don\u2019t need to download the GIT version of the code as <tt>docshtest</tt> is\navailable on the PyPI. So you should be able to run:</p>\n<pre>pip install docshtest\n</pre>\n<p>If you have downloaded the GIT sources, then you could add install\nthe current version via traditional:</p>\n<pre>python setup.py install\n</pre>\n<p>And if you don\u2019t have the GIT sources but would like to get the latest\nmaster or branch from github, you could also:</p>\n<pre>pip install git+https://github.com/vaab/docshtest\n</pre>\n<p>Or even select a specific revision (branch/tag/commit):</p>\n<pre>pip install git+https://github.com/vaab/docshtest@master\n</pre>\n</div>\n<div id=\"usage\">\n<h2>Usage</h2>\n<div id=\"quickstart\">\n<h3>QuickStart</h3>\n<p><tt>docshtest</tt> is a <tt>doctest</tt> for shell command. This means it allows\nyou to integrate in your documentation some examples of shell code and\ntheir expected output that will be actually verifiable.</p>\n<p>First please notice that these documentation lines you are reading are\nstored in a <tt>README.rst</tt> file that will contain very soon some\nexamples of how to run <tt>docshtest</tt> and what outcome to expect.</p>\n<p>The very first example that comes to mind is to run <tt>docshtest</tt> on\nthis very documentation:</p>\n<pre>docshtest README.rst\n</pre>\n<p>But doing so would generate a infinite loop ! So you can check that\nyourself, and that\u2019s done in the CI procedures.</p>\n<p>Let\u2019s introduce you the basics of writing your own testable documentation\u2026</p>\n<p>So this is how it works:</p>\n<pre>$ cat &lt;&lt;'EOF' &gt; mydoc.rst   ## First test file\n\nThis is standard RST, we can include runnable test blocks::\n\n    $ echo 'hello world'\n    hello world\n\nEOF\n</pre>\n<p>Note that indentation is required, as well as the <tt>\"$ \"</tt> (dollar sign\nfollowed by a space) before the command to be executed. Please refer\nto the following section to understand how <tt>docshtest</tt> figures out\nthe end of your shell code and the start of the output.</p>\n<p>The output starts after the end of your command, indented also, and\nwill be matched with the actual command output. If there is a mismatch\nthe test will fail, and <tt>docshtest</tt> will cancel any remaining tests.\nIf it matches, next test block will be executed.</p>\n<p>To run our test:</p>\n<pre>$ ./docshtest mydoc.rst\n#0001 - success (line          4)\n</pre>\n</div>\n<div id=\"multiline-commands\">\n<h3>Multiline Commands</h3>\n<p>Multiline commands are detected with a very simple, but dirty method,\n<tt>docshtest</tt> will simply provide the exact code, starting with only\nthe first line to the shell interpreter, if the shell interpreter\ncomplains, it\u2019ll try again by adding the next line to the output.</p>\n<p>This allows to document/test multi-line shell codes like:</p>\n<pre>$ cat &lt;&lt;EOF &gt; mydoc.rst   ## First test file\n\nMultiline commands::\n\n    $ for a in \\$(seq 1 3); do\n        echo \"foo\\$a\"\n      done\n    foo1\n    foo2\n    foo3\n\nEOF\n$ ./docshtest mydoc.rst\n#0001 - success (lines       4-6)\n</pre>\n<p>Please note that the extra indentation for the body of the <tt>for</tt> loop or\nthe <tt>done</tt> is unnecessary, but is recommended for reading:</p>\n<pre>$ cat &lt;&lt;EOF &gt; mydoc.rst   ## First test file\n\nMultiline commands::\n\n    $ for a in \\$(seq 1 3); do\n      echo \"foo\\$a\"\n    done\n    foo1\n    foo2\n    foo3\n\nEOF\n$ ./docshtest mydoc.rst\n#0001 - success (lines       4-6)\n</pre>\n<p>Failing test will display both expected output and current output:</p>\n<pre>$ cat &lt;&lt;EOF &gt; mydoc.rst   ## First test file\n\nMultiline commands::\n\n    $ for a in \\$(seq 1 3); do\n      echo \"foo\\$a\"\n    done\n    foo1\n    foo4\n    foo3\n\nEOF\n$ ./docshtest mydoc.rst\n#0001 - failure (lines       4-6):\n  command:\n  | for a in $(seq 1 3); do\n  |   echo \"foo$a\"\n  | done\n  expected:\n  | foo1\n  | foo4\n  | foo3\n  |\n  output:\n  | foo1\n  | foo2\n  | foo3\n  |\n</pre>\n<p>But note that if these outputs are bigger, a standard unified diff will be\nprinted:</p>\n<pre>$ cat &lt;&lt;EOF &gt; mydoc.rst   ## First test file\n\nMultiline commands::\n\n    $ for a in \\$(seq 1 6); do\n      echo \"foo\\$a\"\n    done\n    foo1\n    foo3\n    foo4\n    foo5\n    foo6\n\nEOF\n$ ./docshtest mydoc.rst\n#0001 - failure (lines       4-6):\n  command:\n  | for a in $(seq 1 6); do\n  |   echo \"foo$a\"\n  | done\n  expected:\n  | foo1\n  | foo3\n  | foo4\n  | foo5\n  | foo6\n  |\n  output:\n  | foo1\n  | foo2\n  | foo3\n  | foo4\n  | foo5\n  | foo6\n  |\n  diff:\n  --- expected\n  +++ output\n  @@ -1,4 +1,5 @@\n   foo1\n  +foo2\n   foo3\n   foo4\n   foo5\n</pre>\n</div>\n<div id=\"tinkering-all-executed-code\">\n<h3>Tinkering all executed code</h3>\n<p>You can transform all executed code before execution thanks to\n<tt><span class=\"pre\">--regex</span> REGEX</tt> (or <tt><span class=\"pre\">-r</span> REGEX</tt>) option:</p>\n<pre>$ cat &lt;&lt;'EOF' &gt; mydoc.rst   ## First test file\n\nOur tested command is 'foo'\n\n    $ foo 'hello world'\n    hello world\n\nEOF\n$ ./docshtest -r '#\\bfoo\\b#echo#' mydoc.rst\n#0001 - success (line          4)\n</pre>\n</div>\n<div id=\"conditional-tests\">\n<h3>Conditional Tests</h3>\n<p>You might want to have conditional tests, that are triggered only\non if specific test succeeds. This feature uses <tt>meta</tt> commands\nthat are specified as shell comments in the given block:</p>\n<pre>$ cat &lt;&lt;'EOF' &gt; mydoc.rst\n\nOur tested command is 'foo'\n\n    $ echo $ENVVAR       ## docshtest: if-success-set VAR_WAS_SET\n    0\n    $ echo 'var is set'  ## docshtest: ignore-if VAR_WAS_SET\n    SHOULDFAIL\n    $ echo 'var is not set'  ## docshtest: ignore-if-not VAR_WAS_SET\n    SHOULDFAIL\n\nEOF\n$ ENVVAR=0 ./docshtest mydoc.rst\n#0001 - ignored (line          4): if-success-set VAR_WAS_SET\n#0002 - ignored (line          6): ignore-if VAR_WAS_SET\n#0003 - failure (line          8):\n  command: \"echo 'var is not set'  ## docshtest: ignore-if-not VAR_WAS_SET\"\n  expected:\n  | SHOULDFAIL\n  |\n  output:\n  | var is not set\n  |\n</pre>\n</div>\n<div id=\"command-line\">\n<h3>Command line</h3>\n<p><tt>docshtest</tt> supports the common GNU standard <tt><span class=\"pre\">--help</span></tt> options:</p>\n<pre>$ ./docshtest --help\n\ndocshtest - parse file and run shell doctests\n\nUsage:\n\n    docshtest (-h|--help)\n    docshtest [[-r|--regex REGEX] ...] DOCSHTEST_FILE\n\n\nOptions:\n\n    -r REGEX, --regex REGEX\n              Will apply this regex to the lines to be executed. You\n              can have more than one patterns by re-using this options\n              as many times as wanted. Regexps will be applied one by one\n              in the same order than they are provided on the command line.\n\n\nExamples:\n\n     ## run tests but replace executable on-the-fly for coverage support\n     docshtest README.rst -r '/\\bdocshtest\\b/coverage run docshtest.py/'\n&lt;BLANKLINE&gt;\n&lt;BLANKLINE&gt;\n</pre>\n<p>First argument is necessary:</p>\n<pre>$ ./docshtest\nError: please provide a rst filename as argument. (use '--help' option to get usage info)\n</pre>\n</div>\n</div>\n<div id=\"contributing\">\n<h2>Contributing</h2>\n<p>Any suggestion or issue is welcome. Push request are very welcome,\nplease check out the guidelines.</p>\n<div id=\"push-request-guidelines\">\n<h3>Push Request Guidelines</h3>\n<p>You can send any code. I\u2019ll look at it and will integrate it myself in\nthe code base and leave you as the author. This process can take time and\nit\u2019ll take less time if you follow the following guidelines:</p>\n<ul>\n<li>Try to stick to 80 columns wide.</li>\n<li>separate your commits per smallest concern.</li>\n<li>each commit should pass the tests (to allow easy bisect)</li>\n<li>each functionality/bugfix commit should contain the code, tests,\nand doc.</li>\n<li>prior minor commit with typographic or code cosmetic changes are\nvery welcome. These should be tagged in their commit summary with\n<tt>!minor</tt>.</li>\n<li>the commit message should follow gitchangelog rules (check the git\nlog to get examples)</li>\n<li>if the commit fixes an issue or finished the implementation of a\nfeature, please mention it in the summary.</li>\n</ul>\n<p>If you have some questions about guidelines which is not answered here,\nplease check the current <tt>git log</tt>, you might find previous commit that\nwould show you how to deal with your issue.</p>\n</div>\n</div>\n<div id=\"license\">\n<h2>License</h2>\n<p>Copyright (c) 2012-2019 Valentin Lab.</p>\n<p>Licensed under the <a href=\"http://raw.github.com/0k/sunit/master/LICENSE\" rel=\"nofollow\">BSD License</a>.</p>\n</div>\n<div id=\"changelog\">\n<h2>Changelog</h2>\n<h2 id=\"id1\"><span class=\"section-subtitle\">0.0.1 (2019-02-11)</span></h2>\n<ul>\n<li>First import. [Valentin Lab]</li>\n</ul>\n</div>\n\n          </div>"}, "last_serial": 4808038, "releases": {"0.0.2": [{"comment_text": "", "digests": {"md5": "b1d150be29fbfb55aef1c83e08c1e37d", "sha256": "5cf974171c15281e6fc8f1b04d31732f501850e40e08758287fddc8f9b37f302"}, "downloads": -1, "filename": "docshtest-0.0.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "b1d150be29fbfb55aef1c83e08c1e37d", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 14514, "upload_time": "2019-02-11T21:32:06", "upload_time_iso_8601": "2019-02-11T21:32:06.151348Z", "url": "https://files.pythonhosted.org/packages/f1/a7/4008efcd689be12bee6904219e569d17b10047caf4eac849fe9c67a884d5/docshtest-0.0.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f9cf7ab399ff49d966376a1da7650a9f", "sha256": "6ee26db78dd8e7dc2fcc7ee193f184d524823fba9d9a72b491ef00b5f16b0fd0"}, "downloads": -1, "filename": "docshtest-0.0.2.tar.gz", "has_sig": false, "md5_digest": "f9cf7ab399ff49d966376a1da7650a9f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12313, "upload_time": "2019-02-11T21:32:08", "upload_time_iso_8601": "2019-02-11T21:32:08.941599Z", "url": "https://files.pythonhosted.org/packages/21/d5/c591b7cf82000e50ecb644a645e580ffa9d26072af5d2f7365941b308dcd/docshtest-0.0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "b1d150be29fbfb55aef1c83e08c1e37d", "sha256": "5cf974171c15281e6fc8f1b04d31732f501850e40e08758287fddc8f9b37f302"}, "downloads": -1, "filename": "docshtest-0.0.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "b1d150be29fbfb55aef1c83e08c1e37d", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 14514, "upload_time": "2019-02-11T21:32:06", "upload_time_iso_8601": "2019-02-11T21:32:06.151348Z", "url": "https://files.pythonhosted.org/packages/f1/a7/4008efcd689be12bee6904219e569d17b10047caf4eac849fe9c67a884d5/docshtest-0.0.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f9cf7ab399ff49d966376a1da7650a9f", "sha256": "6ee26db78dd8e7dc2fcc7ee193f184d524823fba9d9a72b491ef00b5f16b0fd0"}, "downloads": -1, "filename": "docshtest-0.0.2.tar.gz", "has_sig": false, "md5_digest": "f9cf7ab399ff49d966376a1da7650a9f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12313, "upload_time": "2019-02-11T21:32:08", "upload_time_iso_8601": "2019-02-11T21:32:08.941599Z", "url": "https://files.pythonhosted.org/packages/21/d5/c591b7cf82000e50ecb644a645e580ffa9d26072af5d2f7365941b308dcd/docshtest-0.0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:50:41 2020"}