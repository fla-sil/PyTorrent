{"info": {"author": "helixcs", "author_email": "zhangjian12424@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Programming Language :: Python", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: Implementation :: CPython", "Programming Language :: Python :: Implementation :: PyPy"], "description": "\n# Weibo Scraper\n\n[![PyPI](https://img.shields.io/pypi/v/weibo-scraper.svg)](https://pypi.org/project/weibo-scraper/)\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/weibo-scraper.svg)](https://docs.python.org/3/whatsnew/3.6.html)\n[![Build Status](https://travis-ci.org/Xarrow/weibo-scraper.svg?branch=master)](https://travis-ci.org/Xarrow/weibo-scraper)\n[![codecov](https://codecov.io/gh/Xarrow/weibo-scraper/branch/master/graph/badge.svg)](https://codecov.io/gh/Xarrow/weibo-scraper)\n\n----\n\nSimple weibo tweet scraper . Crawl weibo tweets without authorization.\nThere are many limitations in official API .\nIn general , we can inspect mobile site which has it's own API by Chrome.\n\n----\n\n# Why\n\n1. Crawl weibo data in order to research big data .\n\n2. Back up  data for weibo's shameful blockade . \n\n\n----\n# Installation\n\n\n### pip\n\n```shell\n\n$ pip install weibo-scraper\n\n```\n\nOr Upgrade it.\n\n\n```shell\n\n$ pip install --upgrade weibo-scraper\n\n```\n\n### pipenv\n\n```shell\n\n$ pipenv install weibo-scraper\n\n```\nOr Upgrade it.\n\n```shell\n$ pipenv update --outdated # show packages which are outdated\n\n$ pipenv update weibo-scraper # just update weibo-scraper\n\n```\n\n\n\n\nOnly Python 3.6+ is supported\n\n----\n# Usage\n\n1. Firstly , you can get weibo profile by `name` or `uid` .\n\n```python\n>>> from weibo_scraper import get_weibo_profile\n>>> weibo_profile = get_weibo_profile(name='\u6765\u53bb\u4e4b\u95f4',)\n>>> ....\n```\nYou will get weibo profile response which is type of `weibo_base.UserMeta`, and this response include fields as below\n\nfield|chinese|type|sample|ext\n---|---|---|---|---\nid|\u7528\u6237id|str||\nscreen_name|\u5fae\u535a\u6635\u79f0|Option[str]||\navatar_hd|\u9ad8\u6e05\u5934\u50cf|Option[str]|'https://ww2.sinaimg.cn/orj480/4242e8adjw8elz58g3kyvj20c80c8myg.jpg'|\ncover_image_phone|\u624b\u673a\u7248\u5c01\u9762|Option[str]|'https://tva1.sinaimg.cn/crop.0.0.640.640.640/549d0121tw1egm1kjly3jj20hs0hsq4f.jpg'|\ndescription| \u63cf\u8ff0|Option[str]||\nfollow_count|\u5173\u6ce8\u6570|Option[int]|3568|\nfollower_count|\u88ab\u5173\u6ce8\u6570|Option[int]|794803|\ngender|\u6027\u522b|Option[str]|'m'/'f'|\nraw_user_response|\u539f\u59cb\u8fd4\u56de|Option[dict]||\n\n\n2. Secondly , via `tweet_container_id` to get weibo tweets is a rare way to use but it also works well .\n\n```python\n>>> from weibo_scraper import  get_weibo_tweets\n>>> for tweet in get_weibo_tweets(tweet_container_id='1076033637346297',pages=1):\n>>>     print(tweet)\n>>> ....\n\n```\n\n3. Of Course , you can also get raw weibo tweets by nick name which is exist . And the param of `pages` is optional .\n\n```python\n>>> from weibo_scraper import  get_weibo_tweets_by_name\n>>> for tweet in get_weibo_tweets_by_name(name='\u563b\u7ea2\u8c46', pages=1):\n>>>     print(tweet)\n>>> ....\n```\n\n3. If you want to get all tweets , you can set the param of `pages` as `None`\n\n```python\n>>> from weibo_scraper import  get_weibo_tweets_by_name\n>>> for tweet in get_weibo_tweets_by_name(name='\u563b\u7ea2\u8c46', pages=None):\n>>>     print(tweet)\n>>> ....\n```\n\n4. There is a giant update since 1.0.5 \ud83c\udf70!\n\nYou can also get formatted tweets via api of `weibo_scrapy.get_formatted_weibo_tweets_by_name`,\n\n```python\n>>> from weibo_scraper import  get_formatted_weibo_tweets_by_name\n>>> result_iterator = get_formatted_weibo_tweets_by_name(name='\u563b\u7ea2\u8c46', pages=None)\n>>> for user_meta in result_iterator:\n>>>     for tweetMeta in user_meta.cards_node:\n>>>         print(tweetMeta.mblog.text)\n>>> ....\n```\n\n\n![img](https://raw.githubusercontent.com/Xarrow/weibo-scraper/master/weibo_tweets.png)\n\n----\n\n# Weibo Flasgger\n\n\n[Weibo Flasgger](https://github.com/Xarrow/weibo-scraper/blob/search_name/samples/weibo_flasgger/FLASGGER_README.md) is a web api document for weibo scraper , and powered by flasgger .\n\n![img](https://raw.githubusercontent.com/rochacbruno/flasgger/master/docs/flasgger.png)\n\n# P.S\n1. Inspiration from [Twitter-Scraper](https://github.com/kennethreitz/twitter-scraper) .\n\n2. For 'XIHONGDOU' .\n\n3. Welcome To Fork Me .\n\n----\n# LICENSE\n\nMIT\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Xarrow/weibo-scraper", "keywords": "weibo scraper crawl", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "weibo-scraper", "package_url": "https://pypi.org/project/weibo-scraper/", "platform": "", "project_url": "https://pypi.org/project/weibo-scraper/", "project_urls": {"Homepage": "https://github.com/Xarrow/weibo-scraper"}, "release_url": "https://pypi.org/project/weibo-scraper/1.0.6/", "requires_dist": ["requests"], "requires_python": ">=3.6", "summary": "", "version": "1.0.6", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Weibo Scraper</h1>\n<p><a href=\"https://pypi.org/project/weibo-scraper/\" rel=\"nofollow\"><img alt=\"PyPI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f560faccf4b364ee29c197d04d2fbae08ad72030/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f776569626f2d736372617065722e737667\"></a>\n<a href=\"https://docs.python.org/3/whatsnew/3.6.html\" rel=\"nofollow\"><img alt=\"PyPI - Python Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/287f3b1072bc5e5d1e44cca0d9506293fd3e0d3c/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f776569626f2d736372617065722e737667\"></a>\n<a href=\"https://travis-ci.org/Xarrow/weibo-scraper\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/616304317d58ffa760c84c743fafbfffd49ac925/68747470733a2f2f7472617669732d63692e6f72672f586172726f772f776569626f2d736372617065722e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://codecov.io/gh/Xarrow/weibo-scraper\" rel=\"nofollow\"><img alt=\"codecov\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/685aafe9956a41d2ae43d9724deda57871a71395/68747470733a2f2f636f6465636f762e696f2f67682f586172726f772f776569626f2d736372617065722f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a></p>\n<hr>\n<p>Simple weibo tweet scraper . Crawl weibo tweets without authorization.\nThere are many limitations in official API .\nIn general , we can inspect mobile site which has it's own API by Chrome.</p>\n<hr>\n<h1>Why</h1>\n<ol>\n<li>\n<p>Crawl weibo data in order to research big data .</p>\n</li>\n<li>\n<p>Back up  data for weibo's shameful blockade .</p>\n</li>\n</ol>\n<hr>\n<h1>Installation</h1>\n<h3>pip</h3>\n<pre>$ pip install weibo-scraper\n</pre>\n<p>Or Upgrade it.</p>\n<pre>$ pip install --upgrade weibo-scraper\n</pre>\n<h3>pipenv</h3>\n<pre>$ pipenv install weibo-scraper\n</pre>\n<p>Or Upgrade it.</p>\n<pre>$ pipenv update --outdated <span class=\"c1\"># show packages which are outdated</span>\n\n$ pipenv update weibo-scraper <span class=\"c1\"># just update weibo-scraper</span>\n</pre>\n<p>Only Python 3.6+ is supported</p>\n<hr>\n<h1>Usage</h1>\n<ol>\n<li>Firstly , you can get weibo profile by <code>name</code> or <code>uid</code> .</li>\n</ol>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">weibo_scraper</span> <span class=\"kn\">import</span> <span class=\"n\">get_weibo_profile</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">weibo_profile</span> <span class=\"o\">=</span> <span class=\"n\">get_weibo_profile</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'\u6765\u53bb\u4e4b\u95f4'</span><span class=\"p\">,)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">....</span>\n</pre>\n<p>You will get weibo profile response which is type of <code>weibo_base.UserMeta</code>, and this response include fields as below</p>\n<table>\n<thead>\n<tr>\n<th>field</th>\n<th>chinese</th>\n<th>type</th>\n<th>sample</th>\n<th>ext</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>id</td>\n<td>\u7528\u6237id</td>\n<td>str</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>screen_name</td>\n<td>\u5fae\u535a\u6635\u79f0</td>\n<td>Option[str]</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>avatar_hd</td>\n<td>\u9ad8\u6e05\u5934\u50cf</td>\n<td>Option[str]</td>\n<td>'<a href=\"https://ww2.sinaimg.cn/orj480/4242e8adjw8elz58g3kyvj20c80c8myg.jpg\" rel=\"nofollow\">https://ww2.sinaimg.cn/orj480/4242e8adjw8elz58g3kyvj20c80c8myg.jpg</a>'</td>\n<td></td>\n</tr>\n<tr>\n<td>cover_image_phone</td>\n<td>\u624b\u673a\u7248\u5c01\u9762</td>\n<td>Option[str]</td>\n<td>'<a href=\"https://tva1.sinaimg.cn/crop.0.0.640.640.640/549d0121tw1egm1kjly3jj20hs0hsq4f.jpg\" rel=\"nofollow\">https://tva1.sinaimg.cn/crop.0.0.640.640.640/549d0121tw1egm1kjly3jj20hs0hsq4f.jpg</a>'</td>\n<td></td>\n</tr>\n<tr>\n<td>description</td>\n<td>\u63cf\u8ff0</td>\n<td>Option[str]</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>follow_count</td>\n<td>\u5173\u6ce8\u6570</td>\n<td>Option[int]</td>\n<td>3568</td>\n<td></td>\n</tr>\n<tr>\n<td>follower_count</td>\n<td>\u88ab\u5173\u6ce8\u6570</td>\n<td>Option[int]</td>\n<td>794803</td>\n<td></td>\n</tr>\n<tr>\n<td>gender</td>\n<td>\u6027\u522b</td>\n<td>Option[str]</td>\n<td>'m'/'f'</td>\n<td></td>\n</tr>\n<tr>\n<td>raw_user_response</td>\n<td>\u539f\u59cb\u8fd4\u56de</td>\n<td>Option[dict]</td>\n<td></td>\n<td></td>\n</tr></tbody></table>\n<ol>\n<li>Secondly , via <code>tweet_container_id</code> to get weibo tweets is a rare way to use but it also works well .</li>\n</ol>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">weibo_scraper</span> <span class=\"kn\">import</span>  <span class=\"n\">get_weibo_tweets</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">for</span> <span class=\"n\">tweet</span> <span class=\"ow\">in</span> <span class=\"n\">get_weibo_tweets</span><span class=\"p\">(</span><span class=\"n\">tweet_container_id</span><span class=\"o\">=</span><span class=\"s1\">'1076033637346297'</span><span class=\"p\">,</span><span class=\"n\">pages</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">):</span>\n<span class=\"o\">&gt;&gt;&gt;</span>     <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">tweet</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">....</span>\n</pre>\n<ol>\n<li>Of Course , you can also get raw weibo tweets by nick name which is exist . And the param of <code>pages</code> is optional .</li>\n</ol>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">weibo_scraper</span> <span class=\"kn\">import</span>  <span class=\"n\">get_weibo_tweets_by_name</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">for</span> <span class=\"n\">tweet</span> <span class=\"ow\">in</span> <span class=\"n\">get_weibo_tweets_by_name</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'\u563b\u7ea2\u8c46'</span><span class=\"p\">,</span> <span class=\"n\">pages</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">):</span>\n<span class=\"o\">&gt;&gt;&gt;</span>     <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">tweet</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">....</span>\n</pre>\n<ol>\n<li>If you want to get all tweets , you can set the param of <code>pages</code> as <code>None</code></li>\n</ol>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">weibo_scraper</span> <span class=\"kn\">import</span>  <span class=\"n\">get_weibo_tweets_by_name</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">for</span> <span class=\"n\">tweet</span> <span class=\"ow\">in</span> <span class=\"n\">get_weibo_tweets_by_name</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'\u563b\u7ea2\u8c46'</span><span class=\"p\">,</span> <span class=\"n\">pages</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n<span class=\"o\">&gt;&gt;&gt;</span>     <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">tweet</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">....</span>\n</pre>\n<ol>\n<li>There is a giant update since 1.0.5 \ud83c\udf70!</li>\n</ol>\n<p>You can also get formatted tweets via api of <code>weibo_scrapy.get_formatted_weibo_tweets_by_name</code>,</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">weibo_scraper</span> <span class=\"kn\">import</span>  <span class=\"n\">get_formatted_weibo_tweets_by_name</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result_iterator</span> <span class=\"o\">=</span> <span class=\"n\">get_formatted_weibo_tweets_by_name</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'\u563b\u7ea2\u8c46'</span><span class=\"p\">,</span> <span class=\"n\">pages</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">for</span> <span class=\"n\">user_meta</span> <span class=\"ow\">in</span> <span class=\"n\">result_iterator</span><span class=\"p\">:</span>\n<span class=\"o\">&gt;&gt;&gt;</span>     <span class=\"k\">for</span> <span class=\"n\">tweetMeta</span> <span class=\"ow\">in</span> <span class=\"n\">user_meta</span><span class=\"o\">.</span><span class=\"n\">cards_node</span><span class=\"p\">:</span>\n<span class=\"o\">&gt;&gt;&gt;</span>         <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">tweetMeta</span><span class=\"o\">.</span><span class=\"n\">mblog</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">....</span>\n</pre>\n<p><img alt=\"img\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/55ccb36ab87db4527b0a40f0398f070db97524c2/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f586172726f772f776569626f2d736372617065722f6d61737465722f776569626f5f7477656574732e706e67\"></p>\n<hr>\n<h1>Weibo Flasgger</h1>\n<p><a href=\"https://github.com/Xarrow/weibo-scraper/blob/search_name/samples/weibo_flasgger/FLASGGER_README.md\" rel=\"nofollow\">Weibo Flasgger</a> is a web api document for weibo scraper , and powered by flasgger .</p>\n<p><img alt=\"img\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/09ae02e4faae60bcaedf2b36d01e2525b0b9f6e3/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f726f636861636272756e6f2f666c6173676765722f6d61737465722f646f63732f666c6173676765722e706e67\"></p>\n<h1>P.S</h1>\n<ol>\n<li>\n<p>Inspiration from <a href=\"https://github.com/kennethreitz/twitter-scraper\" rel=\"nofollow\">Twitter-Scraper</a> .</p>\n</li>\n<li>\n<p>For 'XIHONGDOU' .</p>\n</li>\n<li>\n<p>Welcome To Fork Me .</p>\n</li>\n</ol>\n<hr>\n<h1>LICENSE</h1>\n<p>MIT</p>\n\n          </div>"}, "last_serial": 4614995, "releases": {"1.0.2": [{"comment_text": "", "digests": {"md5": "e6496cf6e774bae8fdb78e2b4085a207", "sha256": "6786fedf215b3709c2d4fc023987a4a610c9d228e46d6853705ebb4d20420386"}, "downloads": -1, "filename": "weibo_scraper-1.0.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e6496cf6e774bae8fdb78e2b4085a207", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6", "size": 2791, "upload_time": "2018-05-10T19:55:12", "upload_time_iso_8601": "2018-05-10T19:55:12.456568Z", "url": "https://files.pythonhosted.org/packages/d5/4c/af7faca3101fbca2b21828ad334a3d919c5059f7c4f7e8c80424f5889120/weibo_scraper-1.0.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1280370d3208a4ebf1d5ad1a328de649", "sha256": "e6f448202bfa30173a3da925a6a420e5b345d20c26d9d56dfc99dd7c43200e9b"}, "downloads": -1, "filename": "weibo-scraper-1.0.2.tar.gz", "has_sig": false, "md5_digest": "1280370d3208a4ebf1d5ad1a328de649", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 2993, "upload_time": "2018-05-10T19:55:16", "upload_time_iso_8601": "2018-05-10T19:55:16.337524Z", "url": "https://files.pythonhosted.org/packages/91/cf/ad0a93e3ff6a0e6f07995170280cae067eb2547d98649999f23d60533b73/weibo-scraper-1.0.2.tar.gz", "yanked": false}], "1.0.4": [{"comment_text": "", "digests": {"md5": "34f1732cd24156e516583ce9136b7196", "sha256": "c20a239709b17bf26b61577f47daace9351871c4a378c18f4e834d400376fba5"}, "downloads": -1, "filename": "weibo_scraper-1.0.4-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "34f1732cd24156e516583ce9136b7196", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6", "size": 10172, "upload_time": "2018-05-21T18:20:58", "upload_time_iso_8601": "2018-05-21T18:20:58.823542Z", "url": "https://files.pythonhosted.org/packages/b3/f0/747251a8403d3302fbb3202a58f95f00c1c6df6567798bbfc0a75d781e9f/weibo_scraper-1.0.4-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f638c7a91b2c6c992a3b053e12ed66ff", "sha256": "d0ae4645d15c8c5e2a4367b368845d80bf30a9f354f3ca1e6f0d153f180ef121"}, "downloads": -1, "filename": "weibo-scraper-1.0.4.tar.gz", "has_sig": false, "md5_digest": "f638c7a91b2c6c992a3b053e12ed66ff", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 13930, "upload_time": "2018-05-21T18:21:07", "upload_time_iso_8601": "2018-05-21T18:21:07.092241Z", "url": "https://files.pythonhosted.org/packages/9f/bf/7a807e512d3809c9a54189774be64e9623cd08783b5a1cfddb7b46266da2/weibo-scraper-1.0.4.tar.gz", "yanked": false}], "1.0.6": [{"comment_text": "", "digests": {"md5": "a638d292600fc5c245615fc3aab97492", "sha256": "b2cf9a7b0d88e32df97cb83928c72e50b079ba9a72c387976c3a4f4b337e6653"}, "downloads": -1, "filename": "weibo_scraper-1.0.6-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "a638d292600fc5c245615fc3aab97492", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6", "size": 8498, "upload_time": "2018-06-09T12:16:54", "upload_time_iso_8601": "2018-06-09T12:16:54.336928Z", "url": "https://files.pythonhosted.org/packages/ea/fc/bb8fb49af5ccc52e00cac26bfa270d20920fc4b8575580863e468d0afc3e/weibo_scraper-1.0.6-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "745738a5581fff1d1e1fe762616e265d", "sha256": "02ee046aa163cd9c35eb92f1dd03adaccee3902bc17bd6856de9a828d958a6c7"}, "downloads": -1, "filename": "weibo-scraper-1.0.6.tar.gz", "has_sig": false, "md5_digest": "745738a5581fff1d1e1fe762616e265d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 7847, "upload_time": "2018-06-09T12:16:55", "upload_time_iso_8601": "2018-06-09T12:16:55.582919Z", "url": "https://files.pythonhosted.org/packages/47/c0/77ea5373f5e404f0234d523c6cda1354f7537bf04d7e2131d1a51dcdfda3/weibo-scraper-1.0.6.tar.gz", "yanked": false}], "1.0.7b0": [{"comment_text": "", "digests": {"md5": "df13c267bc09413447ce824626b1167b", "sha256": "e703f23286fb8bd440ac4c75e783fe5e081292e0aa82f8d82d14af5ed9c2168e"}, "downloads": -1, "filename": "weibo_scraper-1.0.7b0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "df13c267bc09413447ce824626b1167b", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6", "size": 22037, "upload_time": "2018-12-19T04:05:51", "upload_time_iso_8601": "2018-12-19T04:05:51.170688Z", "url": "https://files.pythonhosted.org/packages/22/9b/39b263f13fb5cb6defa5aa7c93809aeea7bfcbf2baf081170bad7b414ca9/weibo_scraper-1.0.7b0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e1934798e7855dc2a581cd881f550934", "sha256": "aceedbacd810d6b14b03047cf623a6aae6c9f57989681954f04b0f45107766b6"}, "downloads": -1, "filename": "weibo-scraper-1.0.7b0.tar.gz", "has_sig": false, "md5_digest": "e1934798e7855dc2a581cd881f550934", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 19164, "upload_time": "2018-12-19T04:05:53", "upload_time_iso_8601": "2018-12-19T04:05:53.488077Z", "url": "https://files.pythonhosted.org/packages/5b/fe/206e8a30cbe1e7b9f8f9c0f731679e78a748cf86b590d6ea40898d63ae8e/weibo-scraper-1.0.7b0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "a638d292600fc5c245615fc3aab97492", "sha256": "b2cf9a7b0d88e32df97cb83928c72e50b079ba9a72c387976c3a4f4b337e6653"}, "downloads": -1, "filename": "weibo_scraper-1.0.6-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "a638d292600fc5c245615fc3aab97492", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6", "size": 8498, "upload_time": "2018-06-09T12:16:54", "upload_time_iso_8601": "2018-06-09T12:16:54.336928Z", "url": "https://files.pythonhosted.org/packages/ea/fc/bb8fb49af5ccc52e00cac26bfa270d20920fc4b8575580863e468d0afc3e/weibo_scraper-1.0.6-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "745738a5581fff1d1e1fe762616e265d", "sha256": "02ee046aa163cd9c35eb92f1dd03adaccee3902bc17bd6856de9a828d958a6c7"}, "downloads": -1, "filename": "weibo-scraper-1.0.6.tar.gz", "has_sig": false, "md5_digest": "745738a5581fff1d1e1fe762616e265d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 7847, "upload_time": "2018-06-09T12:16:55", "upload_time_iso_8601": "2018-06-09T12:16:55.582919Z", "url": "https://files.pythonhosted.org/packages/47/c0/77ea5373f5e404f0234d523c6cda1354f7537bf04d7e2131d1a51dcdfda3/weibo-scraper-1.0.6.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:30:23 2020"}