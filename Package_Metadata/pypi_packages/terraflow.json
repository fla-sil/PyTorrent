{"info": {"author": "Micah Martin", "author_email": "micahlmartin@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.6", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Topic :: Software Development :: Build Tools"], "description": "# Terraflow\n\nTerraflow is a python utility that makes it easy to manage multiple environments with Terraform.\n\n## Prerequisites\n\n- **Terraform**: You can download the [latest version here](https://releases.hashicorp.com/terraform/).\n- **S3 Bucket**: You will need an S3 bucket to store your state files.\n- **awscli**: You will need the AWS CLI and credentials configured. `pip install awscli && aws configure`.\n\n## Terms\n\n- **stack**: A collection of cloud resources that are configured to achieve a broad, but unified goal. For example, consider groups of machines that are dedicated to grabbing, storing, transforming, anaylzing, and displaying logs. Not every machine is able to perform every task, but they work with each other to achieve a common goal. Together, they form a logging stack.\n- **environment**: An instantiation of a stack. Environments usually represent different SLA's for a stack. For example, a stack may have infrastructure testing, integration, staging, and production environments. Each environment has different uptime guarantees, but all should have the same types of deployed resoures.\n\n\n## Directory Structure\n\nThis tool relies on a very specific folder structure to work. That structure is as follows:\n\n```\n\u251c\u2500\u2500 stacks\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 stack_name\n\u2502\u00a0\u00a0 |   \u251c\u2500\u2500 envs\n\u2502\u00a0\u00a0 |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 env_name.tfvars\n\u2502\u00a0\u00a0 |   \u251c\u2500\u2500 main.tf\n\u251c\u2500\u2500 .tfconfig\n```\n\n- `stacks`: Stacks that can be instatiated multiple times fall under here.\n  - `stacks/stack_name`: Each stack will have it's own subfolder along with a `main.tf` file. This folder will serve as the root for where the terraform commands will be run.\n  - `stacks/stack_name/envs/env_name.tfvars`: Each environment must have it's own `.tfvars` file to provide environment specific variable overrides when instatiating a stack.\n\n## Configuration\n\nEvery project needs to have a `.tfconfig` file in the root of the project. This will allow the tool to determine where the root of the project is as well as provide project specific configuration.\n\n```\n{\n  \"aws\": {\n    \"profile\": \"mgmt\"\n  },\n  \"backend\": {\n    \"s3\": {\n      \"config\": {\n        \"profile\": \"mgmt\",\n        \"bucket\": \"my_terraform_state\",\n        \"region\": \"us-east-1\"\n      }\n    }\n  }\n}\n```\n\n- `aws`:\n    - `profile`: The AWS profile with your credentials that have access to the s3 bucket to store the state in.\n- `backend`:\n    - `s3`: S3 specific configuration for storing the Terraform remote state\n    - `config`:\n        - `profile`: The aws profile to use for the s3 backend configuration. If not present it defaults to the top-level `aws.profile` setting.\n        - `bucket`: The bucket where the remote state will be stored.\n        - `region`: Which region to create the bucket in\n        - `key`: This generated automatically based on and will be `<stack_name>/<env_name>.tfstate`\n\nIf you're creating multiple environments across different AWS accounts (i.e. mgmt, dev, preprod, prod) it's recommended that you create a bucket in one of those accounts and use that to save your state.\n\n```\n# ~/.aws/credentials\n\n[prod]\naws_access_key_id\naws_secret_access_key\n\n[mgmt]\naws_access_key_id\naws_secret_access_key\n```\n\n## Usage\n\n```\n$ tf -h\nusage: tf [-h] command stack environment ...\n\npositional arguments:\n  command      Terraform command to execute\n  stack        The name of the stack to target.\n  environment  The name of the environment to target.\n  tfargs       Additional arguments to passthrough to Terraform.\n\noptional arguments:\n  -h, --help   show this help message and exit\n```\n\n- To execute a plan for a specific stack and environment:\n  ```\n  tf plan <stack_name> <env>\n  ```", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/micahlmartin/terraflow", "keywords": "terraform iac", "license": "MIT", "maintainer": null, "maintainer_email": null, "name": "terraflow", "package_url": "https://pypi.org/project/terraflow/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/terraflow/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/micahlmartin/terraflow"}, "release_url": "https://pypi.org/project/terraflow/0.0.2/", "requires_dist": null, "requires_python": null, "summary": "A Terraform wrapper script for managing stacks and environments.", "version": "0.0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            # Terraflow<br><br>Terraflow is a python utility that makes it easy to manage multiple environments with Terraform.<br><br>## Prerequisites<br><br>- **Terraform**: You can download the [latest version here](https://releases.hashicorp.com/terraform/).<br>- **S3 Bucket**: You will need an S3 bucket to store your state files.<br>- **awscli**: You will need the AWS CLI and credentials configured. `pip install awscli &amp;&amp; aws configure`.<br><br>## Terms<br><br>- **stack**: A collection of cloud resources that are configured to achieve a broad, but unified goal. For example, consider groups of machines that are dedicated to grabbing, storing, transforming, anaylzing, and displaying logs. Not every machine is able to perform every task, but they work with each other to achieve a common goal. Together, they form a logging stack.<br>- **environment**: An instantiation of a stack. Environments usually represent different SLA's for a stack. For example, a stack may have infrastructure testing, integration, staging, and production environments. Each environment has different uptime guarantees, but all should have the same types of deployed resoures.<br><br><br>## Directory Structure<br><br>This tool relies on a very specific folder structure to work. That structure is as follows:<br><br>```<br>\u251c\u2500\u2500 stacks<br>\u2502\u00a0\u00a0 \u2514\u2500\u2500 stack_name<br>\u2502\u00a0\u00a0 |   \u251c\u2500\u2500 envs<br>\u2502\u00a0\u00a0 |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 env_name.tfvars<br>\u2502\u00a0\u00a0 |   \u251c\u2500\u2500 main.tf<br>\u251c\u2500\u2500 .tfconfig<br>```<br><br>- `stacks`: Stacks that can be instatiated multiple times fall under here.<br>  - `stacks/stack_name`: Each stack will have it's own subfolder along with a `main.tf` file. This folder will serve as the root for where the terraform commands will be run.<br>  - `stacks/stack_name/envs/env_name.tfvars`: Each environment must have it's own `.tfvars` file to provide environment specific variable overrides when instatiating a stack.<br><br>## Configuration<br><br>Every project needs to have a `.tfconfig` file in the root of the project. This will allow the tool to determine where the root of the project is as well as provide project specific configuration.<br><br>```<br>{<br>  \"aws\": {<br>    \"profile\": \"mgmt\"<br>  },<br>  \"backend\": {<br>    \"s3\": {<br>      \"config\": {<br>        \"profile\": \"mgmt\",<br>        \"bucket\": \"my_terraform_state\",<br>        \"region\": \"us-east-1\"<br>      }<br>    }<br>  }<br>}<br>```<br><br>- `aws`:<br>    - `profile`: The AWS profile with your credentials that have access to the s3 bucket to store the state in.<br>- `backend`:<br>    - `s3`: S3 specific configuration for storing the Terraform remote state<br>    - `config`:<br>        - `profile`: The aws profile to use for the s3 backend configuration. If not present it defaults to the top-level `aws.profile` setting.<br>        - `bucket`: The bucket where the remote state will be stored.<br>        - `region`: Which region to create the bucket in<br>        - `key`: This generated automatically based on and will be `&lt;stack_name&gt;/&lt;env_name&gt;.tfstate`<br><br>If you're creating multiple environments across different AWS accounts (i.e. mgmt, dev, preprod, prod) it's recommended that you create a bucket in one of those accounts and use that to save your state.<br><br>```<br># ~/.aws/credentials<br><br>[prod]<br>aws_access_key_id<br>aws_secret_access_key<br><br>[mgmt]<br>aws_access_key_id<br>aws_secret_access_key<br>```<br><br>## Usage<br><br>```<br>$ tf -h<br>usage: tf [-h] command stack environment ...<br><br>positional arguments:<br>  command      Terraform command to execute<br>  stack        The name of the stack to target.<br>  environment  The name of the environment to target.<br>  tfargs       Additional arguments to passthrough to Terraform.<br><br>optional arguments:<br>  -h, --help   show this help message and exit<br>```<br><br>- To execute a plan for a specific stack and environment:<br>  ```<br>  tf plan &lt;stack_name&gt; &lt;env&gt;<br>  ```\n          </div>"}, "last_serial": 2582691, "releases": {"0.0.1": [], "0.0.2": [{"comment_text": "", "digests": {"md5": "e55830fb695219e325b43827ce8b7ba3", "sha256": "f1da07cfbb49284a8569b0093b35cca9166fc340ed0c3cd7e0956bad8f93c423"}, "downloads": -1, "filename": "terraflow-0.0.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e55830fb695219e325b43827ce8b7ba3", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 9978, "upload_time": "2017-01-18T15:54:46", "upload_time_iso_8601": "2017-01-18T15:54:46.011235Z", "url": "https://files.pythonhosted.org/packages/45/88/fc18f1b614b6ab104779a1064b9dddbdd63e6527802f6b54ce4580480d68/terraflow-0.0.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "360e1d197a0c1125e9987d674ae2bb7b", "sha256": "ef45a4c3fb2e3b34b76cc4b9feefc413db91451839857b27fbc53e6f286ce201"}, "downloads": -1, "filename": "terraflow-0.0.2.tar.gz", "has_sig": false, "md5_digest": "360e1d197a0c1125e9987d674ae2bb7b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6397, "upload_time": "2017-01-18T15:54:44", "upload_time_iso_8601": "2017-01-18T15:54:44.245598Z", "url": "https://files.pythonhosted.org/packages/65/c0/bccb80238987acc204a367a7df4720a9047a0f076cab2a0583c0f9dba88b/terraflow-0.0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "e55830fb695219e325b43827ce8b7ba3", "sha256": "f1da07cfbb49284a8569b0093b35cca9166fc340ed0c3cd7e0956bad8f93c423"}, "downloads": -1, "filename": "terraflow-0.0.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e55830fb695219e325b43827ce8b7ba3", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 9978, "upload_time": "2017-01-18T15:54:46", "upload_time_iso_8601": "2017-01-18T15:54:46.011235Z", "url": "https://files.pythonhosted.org/packages/45/88/fc18f1b614b6ab104779a1064b9dddbdd63e6527802f6b54ce4580480d68/terraflow-0.0.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "360e1d197a0c1125e9987d674ae2bb7b", "sha256": "ef45a4c3fb2e3b34b76cc4b9feefc413db91451839857b27fbc53e6f286ce201"}, "downloads": -1, "filename": "terraflow-0.0.2.tar.gz", "has_sig": false, "md5_digest": "360e1d197a0c1125e9987d674ae2bb7b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6397, "upload_time": "2017-01-18T15:54:44", "upload_time_iso_8601": "2017-01-18T15:54:44.245598Z", "url": "https://files.pythonhosted.org/packages/65/c0/bccb80238987acc204a367a7df4720a9047a0f076cab2a0583c0f9dba88b/terraflow-0.0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:55:50 2020"}