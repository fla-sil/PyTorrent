{"info": {"author": "Hugo Hromic", "author_email": "hhromic@gmail.com", "bugtrack_url": null, "classifiers": ["Environment :: Console", "Intended Audience :: Science/Research", "Topic :: System :: Clustering"], "description": "# python-bcubed\n\nSimple extended BCubed implementation in Python for (non-)overlapping clustering evaluation.\n\nMore information on BCubed and details of the algorithm can be found in the following publication:\n\n> Amig\u00f3, Enrique, et al.: A comparison of Extrinsic Clustering Evaluation Metrics based on Formal Constraints. In: Information Retrieval 12.4 (2009): 461-486.\n\n## Installation\n\nYou can simply use `pip` (or any similar package manager) for installation:\n\n    pip install bcubed\n\nor, if you prefer a local user installation:\n\n    pip install --user bcubed\n\n## Usage\n\nTo evaluate any clustering output you will need **ground-truth data** (also called gold-standard data). We call this the `ldict`. The ground-truth is represented in a dictionary where the keys are items in the gold-standard and the values are sets of annotated categories for those items. For example:\n\n```python\nldict = {\n    \"item1\": set([\"gray\", \"black\"]),\n    \"item2\": set([\"gray\", \"black\"]),\n    \"item3\": set([\"gray\"]),\n    \"item4\": set([\"black\"]),\n    \"item5\": set([\"black\"]),\n    \"item6\": set([\"dashed\"]),\n    \"item7\": set([\"dashed\"]),\n}\n```\n\nIn the above example, `item1` is assigned two categories in the ground-truth: `gray` and `black`. For the case of `item6` and `item7`, both are assigned the single annotation `dashed`. This representation supports modelling overlapping and non-overlapping ground-truth data.\n\nThe **clustering output** to be evaluated is called the `cdict` and is also represented as a dictionary in the same way as the `ldict`. In this case, the keys are items in the clustering output and the values are the sets of assigned clusters for those items. For example:\n\n```python\ncdict = {\n    \"item1\": set([\"A\", \"B\"]),\n    \"item2\": set([\"A\", \"B\"]),\n    \"item3\": set([\"A\"]),\n    \"item4\": set([\"B\"]),\n    \"item5\": set([\"B\"]),\n    \"item6\": set([\"C\"]),\n    \"item7\": set([\"C\"]),\n}\n```\n\nPlease note that the clusters names (or IDs) **do not need** to be the same as in the ground-truth data because the algorithm only considers the groupings, it does not try to match the names of clusters to the ground-truth categories.\n\nOnce you have defined the `ldict` (ground-truth data) and the `cdict` (clustering output to evaluate), you can simply do the following to obtain the extended BCubed precision and recall metric values:\n\n```python\nimport bcubed\n\nprecision = bcubed.precision(cdict, ldict)\nrecall = bcubed.recall(cdict, ldict)\nfscore = bcubed.fscore(precision, recall)\n```\n\nThere is also included an [F-score](http://en.wikipedia.org/wiki/F1_score) (also called F-measure) function for your convenience. This function accepts non-standard values for the beta parameter if you need, as follows:\n\n```python\nfscore = bcubed.fscore(precision, recall, beta=2.0)  # weights recall higher\nfscore = bcubed.fscore(precision, recall, beta=0.5)  # weights precision higher\n```\n\nA complete example can be found in the included `example.py` file, where the examples of the source publication are used.\n\n## License\n\nThis software is under the **Apache License 2.0**.\n\n    Licensed under the Apache License, Version 2.0 (the \"License\");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n\n        http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/hhromic/python-bcubed/tarball/1.5", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/hhromic/python-bcubed", "keywords": "bcubed,clustering,evaluation", "license": "Apache-2.0", "maintainer": "Hugo Hromic", "maintainer_email": "hhromic@gmail.com", "name": "bcubed", "package_url": "https://pypi.org/project/bcubed/", "platform": "all", "project_url": "https://pypi.org/project/bcubed/", "project_urls": {"Download": "https://github.com/hhromic/python-bcubed/tarball/1.5", "Homepage": "https://github.com/hhromic/python-bcubed"}, "release_url": "https://pypi.org/project/bcubed/1.5/", "requires_dist": ["numpy"], "requires_python": "", "summary": "Simple extended BCubed implementation in Python for clustering evaluation", "version": "1.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>python-bcubed</h1>\n<p>Simple extended BCubed implementation in Python for (non-)overlapping clustering evaluation.</p>\n<p>More information on BCubed and details of the algorithm can be found in the following publication:</p>\n<blockquote>\n<p>Amig\u00f3, Enrique, et al.: A comparison of Extrinsic Clustering Evaluation Metrics based on Formal Constraints. In: Information Retrieval 12.4 (2009): 461-486.</p>\n</blockquote>\n<h2>Installation</h2>\n<p>You can simply use <code>pip</code> (or any similar package manager) for installation:</p>\n<pre><code>pip install bcubed\n</code></pre>\n<p>or, if you prefer a local user installation:</p>\n<pre><code>pip install --user bcubed\n</code></pre>\n<h2>Usage</h2>\n<p>To evaluate any clustering output you will need <strong>ground-truth data</strong> (also called gold-standard data). We call this the <code>ldict</code>. The ground-truth is represented in a dictionary where the keys are items in the gold-standard and the values are sets of annotated categories for those items. For example:</p>\n<pre><span class=\"n\">ldict</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s2\">\"item1\"</span><span class=\"p\">:</span> <span class=\"nb\">set</span><span class=\"p\">([</span><span class=\"s2\">\"gray\"</span><span class=\"p\">,</span> <span class=\"s2\">\"black\"</span><span class=\"p\">]),</span>\n    <span class=\"s2\">\"item2\"</span><span class=\"p\">:</span> <span class=\"nb\">set</span><span class=\"p\">([</span><span class=\"s2\">\"gray\"</span><span class=\"p\">,</span> <span class=\"s2\">\"black\"</span><span class=\"p\">]),</span>\n    <span class=\"s2\">\"item3\"</span><span class=\"p\">:</span> <span class=\"nb\">set</span><span class=\"p\">([</span><span class=\"s2\">\"gray\"</span><span class=\"p\">]),</span>\n    <span class=\"s2\">\"item4\"</span><span class=\"p\">:</span> <span class=\"nb\">set</span><span class=\"p\">([</span><span class=\"s2\">\"black\"</span><span class=\"p\">]),</span>\n    <span class=\"s2\">\"item5\"</span><span class=\"p\">:</span> <span class=\"nb\">set</span><span class=\"p\">([</span><span class=\"s2\">\"black\"</span><span class=\"p\">]),</span>\n    <span class=\"s2\">\"item6\"</span><span class=\"p\">:</span> <span class=\"nb\">set</span><span class=\"p\">([</span><span class=\"s2\">\"dashed\"</span><span class=\"p\">]),</span>\n    <span class=\"s2\">\"item7\"</span><span class=\"p\">:</span> <span class=\"nb\">set</span><span class=\"p\">([</span><span class=\"s2\">\"dashed\"</span><span class=\"p\">]),</span>\n<span class=\"p\">}</span>\n</pre>\n<p>In the above example, <code>item1</code> is assigned two categories in the ground-truth: <code>gray</code> and <code>black</code>. For the case of <code>item6</code> and <code>item7</code>, both are assigned the single annotation <code>dashed</code>. This representation supports modelling overlapping and non-overlapping ground-truth data.</p>\n<p>The <strong>clustering output</strong> to be evaluated is called the <code>cdict</code> and is also represented as a dictionary in the same way as the <code>ldict</code>. In this case, the keys are items in the clustering output and the values are the sets of assigned clusters for those items. For example:</p>\n<pre><span class=\"n\">cdict</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s2\">\"item1\"</span><span class=\"p\">:</span> <span class=\"nb\">set</span><span class=\"p\">([</span><span class=\"s2\">\"A\"</span><span class=\"p\">,</span> <span class=\"s2\">\"B\"</span><span class=\"p\">]),</span>\n    <span class=\"s2\">\"item2\"</span><span class=\"p\">:</span> <span class=\"nb\">set</span><span class=\"p\">([</span><span class=\"s2\">\"A\"</span><span class=\"p\">,</span> <span class=\"s2\">\"B\"</span><span class=\"p\">]),</span>\n    <span class=\"s2\">\"item3\"</span><span class=\"p\">:</span> <span class=\"nb\">set</span><span class=\"p\">([</span><span class=\"s2\">\"A\"</span><span class=\"p\">]),</span>\n    <span class=\"s2\">\"item4\"</span><span class=\"p\">:</span> <span class=\"nb\">set</span><span class=\"p\">([</span><span class=\"s2\">\"B\"</span><span class=\"p\">]),</span>\n    <span class=\"s2\">\"item5\"</span><span class=\"p\">:</span> <span class=\"nb\">set</span><span class=\"p\">([</span><span class=\"s2\">\"B\"</span><span class=\"p\">]),</span>\n    <span class=\"s2\">\"item6\"</span><span class=\"p\">:</span> <span class=\"nb\">set</span><span class=\"p\">([</span><span class=\"s2\">\"C\"</span><span class=\"p\">]),</span>\n    <span class=\"s2\">\"item7\"</span><span class=\"p\">:</span> <span class=\"nb\">set</span><span class=\"p\">([</span><span class=\"s2\">\"C\"</span><span class=\"p\">]),</span>\n<span class=\"p\">}</span>\n</pre>\n<p>Please note that the clusters names (or IDs) <strong>do not need</strong> to be the same as in the ground-truth data because the algorithm only considers the groupings, it does not try to match the names of clusters to the ground-truth categories.</p>\n<p>Once you have defined the <code>ldict</code> (ground-truth data) and the <code>cdict</code> (clustering output to evaluate), you can simply do the following to obtain the extended BCubed precision and recall metric values:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">bcubed</span>\n\n<span class=\"n\">precision</span> <span class=\"o\">=</span> <span class=\"n\">bcubed</span><span class=\"o\">.</span><span class=\"n\">precision</span><span class=\"p\">(</span><span class=\"n\">cdict</span><span class=\"p\">,</span> <span class=\"n\">ldict</span><span class=\"p\">)</span>\n<span class=\"n\">recall</span> <span class=\"o\">=</span> <span class=\"n\">bcubed</span><span class=\"o\">.</span><span class=\"n\">recall</span><span class=\"p\">(</span><span class=\"n\">cdict</span><span class=\"p\">,</span> <span class=\"n\">ldict</span><span class=\"p\">)</span>\n<span class=\"n\">fscore</span> <span class=\"o\">=</span> <span class=\"n\">bcubed</span><span class=\"o\">.</span><span class=\"n\">fscore</span><span class=\"p\">(</span><span class=\"n\">precision</span><span class=\"p\">,</span> <span class=\"n\">recall</span><span class=\"p\">)</span>\n</pre>\n<p>There is also included an <a href=\"http://en.wikipedia.org/wiki/F1_score\" rel=\"nofollow\">F-score</a> (also called F-measure) function for your convenience. This function accepts non-standard values for the beta parameter if you need, as follows:</p>\n<pre><span class=\"n\">fscore</span> <span class=\"o\">=</span> <span class=\"n\">bcubed</span><span class=\"o\">.</span><span class=\"n\">fscore</span><span class=\"p\">(</span><span class=\"n\">precision</span><span class=\"p\">,</span> <span class=\"n\">recall</span><span class=\"p\">,</span> <span class=\"n\">beta</span><span class=\"o\">=</span><span class=\"mf\">2.0</span><span class=\"p\">)</span>  <span class=\"c1\"># weights recall higher</span>\n<span class=\"n\">fscore</span> <span class=\"o\">=</span> <span class=\"n\">bcubed</span><span class=\"o\">.</span><span class=\"n\">fscore</span><span class=\"p\">(</span><span class=\"n\">precision</span><span class=\"p\">,</span> <span class=\"n\">recall</span><span class=\"p\">,</span> <span class=\"n\">beta</span><span class=\"o\">=</span><span class=\"mf\">0.5</span><span class=\"p\">)</span>  <span class=\"c1\"># weights precision higher</span>\n</pre>\n<p>A complete example can be found in the included <code>example.py</code> file, where the examples of the source publication are used.</p>\n<h2>License</h2>\n<p>This software is under the <strong>Apache License 2.0</strong>.</p>\n<pre><code>Licensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n</code></pre>\n\n          </div>"}, "last_serial": 4707637, "releases": {"1.5": [{"comment_text": "", "digests": {"md5": "a7ff42a5b9ef44f5244ec802b902add4", "sha256": "b465d0e27527f3834d0b053503868ac09b986853a4d8c14a1fa52a4cefd3ac29"}, "downloads": -1, "filename": "bcubed-1.5-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "a7ff42a5b9ef44f5244ec802b902add4", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 8670, "upload_time": "2019-01-17T11:12:03", "upload_time_iso_8601": "2019-01-17T11:12:03.108021Z", "url": "https://files.pythonhosted.org/packages/56/c4/f06199a7de2236e92d3894672b1f8530d4fc1c02d7453d6c30e379fbce41/bcubed-1.5-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9034816a3c699925bcdfc90248fc3376", "sha256": "3dc67a6e4e925d4493ce6bc9747a64a48f84398f31b573f73776c9b836de6ae9"}, "downloads": -1, "filename": "bcubed-1.5.tar.gz", "has_sig": false, "md5_digest": "9034816a3c699925bcdfc90248fc3376", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3625, "upload_time": "2019-01-17T11:12:04", "upload_time_iso_8601": "2019-01-17T11:12:04.615742Z", "url": "https://files.pythonhosted.org/packages/4e/fd/bc5455e5cf3e3aa7cf36f9f7c5cf3c81c0a4fb36c4bff8982599e78f8458/bcubed-1.5.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "a7ff42a5b9ef44f5244ec802b902add4", "sha256": "b465d0e27527f3834d0b053503868ac09b986853a4d8c14a1fa52a4cefd3ac29"}, "downloads": -1, "filename": "bcubed-1.5-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "a7ff42a5b9ef44f5244ec802b902add4", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 8670, "upload_time": "2019-01-17T11:12:03", "upload_time_iso_8601": "2019-01-17T11:12:03.108021Z", "url": "https://files.pythonhosted.org/packages/56/c4/f06199a7de2236e92d3894672b1f8530d4fc1c02d7453d6c30e379fbce41/bcubed-1.5-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9034816a3c699925bcdfc90248fc3376", "sha256": "3dc67a6e4e925d4493ce6bc9747a64a48f84398f31b573f73776c9b836de6ae9"}, "downloads": -1, "filename": "bcubed-1.5.tar.gz", "has_sig": false, "md5_digest": "9034816a3c699925bcdfc90248fc3376", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3625, "upload_time": "2019-01-17T11:12:04", "upload_time_iso_8601": "2019-01-17T11:12:04.615742Z", "url": "https://files.pythonhosted.org/packages/4e/fd/bc5455e5cf3e3aa7cf36f9f7c5cf3c81c0a4fb36c4bff8982599e78f8458/bcubed-1.5.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:14:35 2020"}