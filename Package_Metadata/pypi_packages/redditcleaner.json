{"info": {"author": "Lorenz Leitner", "author_email": "lrnz.ltnr@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3.8"], "description": "# redditcleaner\n\nCleans Reddit Text Data \ud83d\udcdc \ud83e\uddf9 \ud83e\uddfc \ud83e\uddfd\n\n## Installation\n[`pip install redditcleaner`](https://pypi.org/project/redditcleaner/)\n\n## About\n\nReddit uses some characters in the raw text of comments and submission selftexts that may need to be removed if just the plain natural text is required for NLP/Data Science tasks. This Python module cleans this text data.\n\n## Usage\n\n```python\nimport redditcleaner\ntext_raw = <Reddit text>\ntext_cleaned = redditcleaner.clean(text_raw)\n```\n\n### Input\n\nIf [Reddit's](https://www.reddit.com/dev/api/) or [Pushshift's API](https://github.com/pushshift/api) is used to retrieve comments or submissions, the raw comment bodies or submission self texts may look like this:\n```\nNormal text\\n\\n**Bold**\\n\\n*Italic*\\n\\n[Link](https://fsf.org)\\n\\n\n~~Strike-through~~\\n\\n`Code`\\n\\n^(Superscript)\n\\n\\n&gt;!Spoiler!&lt;\\n\\n# Heading\\n\\nBullet list:\\n\\n* Item 1\\n* Item 2\n\\n\\nNumbered list:\\n\\n1. Item 1\\n2. Item 2\\n\\n&gt;Quote\\n\\n \nCode block\\n\\nTable:\\n\\n|Cell 1.1|Cell 1.2|\\n|:-|:-|\\n|Cell 2.1|Cell 2.2|\n\n\\n * Find &amp;#x200B; &gt; \"\\&gt; the \"&gt; hidden\\ntext [fsf](http://fsf.org)...\nThis & that in a normal sentence. \"manual quote\"\n```\n\nThese characters stem from (Reddit-specific) Markdown formatting. See [here](https://i.imgur.com/pWreKRA.png) how the first bit looks like on Reddit.\n\n### Output\n\nThis Python module removes these characters and returns the cleaned text. Using the example above, the output would be:\n```\nNormal text Bold Italic\nStrike-through Code Superscript\nSpoiler Heading Bullet list: Item 1 Item 2 \nNumbered list: 1. Item 1 2. Item 2 Quote\nCode block Table: Cell 1.1 Cell 1.2 Cell 2.1 Cell 2.2\n\nFind the hidden text ... This & that in a normal sentence. \"manual quote\"\n```\n\n:warning: **Common punctuation, numbers, parentheses, quotation marks, emojis, etc. are deliberately not removed**, as this data cleaning task pertains to Reddit-specific characters only. An additional round of data cleaning can be applied manually to clean these common items or apply lowercasing, or whatever else is needed.\n\n### Advanced Usage\nThe `clean` function supports optional arguments and it can be used as a lambda to be applied on e.g. Pandas DataFrames.\n\n#### Optional Arguments\nSpecific removals of characters can be disabled with optional arguments passed to the `clean` function. Everything is on by default, but setting one to `False` disables it.\n\n```python\ndef clean(text, newline=True, quote=True, bullet_point=True, \n          link=True, strikethrough=True, spoiler=True,\n          code=True, superscript=True, table=True, heading=True)\n```\nE.g.\n```python\nredditcleaner.clean(text, heading=False)\n```\n\n#### Pandas Usage\nThis simulates a common format used when retrieving this type of data via the Reddit API:\n```python\n\n# Put \"retrieved\" text into Pandas Dataframe\ntest_body_1 = \"\\n * Find &amp;#x200B; &gt; \\\"\\\\&gt; the \\\"&gt; hidden\\ntext [fsf](http://fsf.org)... This & that in a normal sentence. \\\"manual quote\\\"\"\ntest_body_2 = \"Normal text\\n\\n**Bold**\\n\\n*Italic*\\n\\n[Link](https://fsf.org)\\n\\n~~Strike-through~~\\n\\n`Code`\\n\\n^(Superscript)\\n\\n&gt;!Spoiler!&lt;\\n\\n# Heading\\n\\nBullet list:\\n\\n* Item 1\\n* Item 2\\n\\nNumbered list:\\n\\n1. Item 1\\n2. Item 2\\n\\n&gt;Quote\\n\\n    Code block\\n\\nTable:\\n\\n|Cell 1.1|Cell 1.2|\\n|:-|:-|\\n|Cell 2.1|Cell 2.2|\"\n\nimport pandas as pd\ndf = pd.DataFrame([['asdf', 'test_a', test_body_1],\n                   ['fdsa', 'test_b', test_body_2]],\n                   columns=list(['id', 'author', 'body']))\n\n# Prepare redditcleaner\nimport redditcleaner\n\n# Apply (map) the function on all body column entries\ndf['body'] = df['body'].map(redditcleaner.clean)\ndf\n```\n|    | id   | author   | body                                                                                                                                                                                                                             |\n|---:|:-----|:---------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n|  0 | asdf | testa    | Find    the  hidden text ... This & that in a normal sentence. \"manual quote\"                                                                                                                                                    |\n|  1 | fdsa | testb    | Normal text  Bold  Italic    Strike-through  Code  Superscript  Spoiler   Heading  Bullet list:   Item 1  Item 2  Numbered list:  1. Item 1 2. Item 2  Quote      Code block  Table:   Cell 1.1 Cell 1.2       Cell 2.1 Cell 2.2 |\n\n## Contributing\nIf I missed any characters that should also be removed, please let me know or feel free to create a PR yourself! :heart:\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/lolei/redditcleaner", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "redditcleaner", "package_url": "https://pypi.org/project/redditcleaner/", "platform": "", "project_url": "https://pypi.org/project/redditcleaner/", "project_urls": {"Homepage": "https://github.com/lolei/redditcleaner"}, "release_url": "https://pypi.org/project/redditcleaner/1.1.2/", "requires_dist": null, "requires_python": ">=3", "summary": "Clean Reddit Text Data", "version": "1.1.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>redditcleaner</h1>\n<p>Cleans Reddit Text Data \ud83d\udcdc \ud83e\uddf9 \ud83e\uddfc \ud83e\uddfd</p>\n<h2>Installation</h2>\n<p><a href=\"https://pypi.org/project/redditcleaner/\" rel=\"nofollow\"><code>pip install redditcleaner</code></a></p>\n<h2>About</h2>\n<p>Reddit uses some characters in the raw text of comments and submission selftexts that may need to be removed if just the plain natural text is required for NLP/Data Science tasks. This Python module cleans this text data.</p>\n<h2>Usage</h2>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">redditcleaner</span>\n<span class=\"n\">text_raw</span> <span class=\"o\">=</span> <span class=\"o\">&lt;</span><span class=\"n\">Reddit</span> <span class=\"n\">text</span><span class=\"o\">&gt;</span>\n<span class=\"n\">text_cleaned</span> <span class=\"o\">=</span> <span class=\"n\">redditcleaner</span><span class=\"o\">.</span><span class=\"n\">clean</span><span class=\"p\">(</span><span class=\"n\">text_raw</span><span class=\"p\">)</span>\n</pre>\n<h3>Input</h3>\n<p>If <a href=\"https://www.reddit.com/dev/api/\" rel=\"nofollow\">Reddit's</a> or <a href=\"https://github.com/pushshift/api\" rel=\"nofollow\">Pushshift's API</a> is used to retrieve comments or submissions, the raw comment bodies or submission self texts may look like this:</p>\n<pre><code>Normal text\\n\\n**Bold**\\n\\n*Italic*\\n\\n[Link](https://fsf.org)\\n\\n\n~~Strike-through~~\\n\\n`Code`\\n\\n^(Superscript)\n\\n\\n&amp;gt;!Spoiler!&amp;lt;\\n\\n# Heading\\n\\nBullet list:\\n\\n* Item 1\\n* Item 2\n\\n\\nNumbered list:\\n\\n1. Item 1\\n2. Item 2\\n\\n&amp;gt;Quote\\n\\n \nCode block\\n\\nTable:\\n\\n|Cell 1.1|Cell 1.2|\\n|:-|:-|\\n|Cell 2.1|Cell 2.2|\n\n\\n * Find &amp;amp;#x200B; &amp;gt; \"\\&amp;gt; the \"&amp;gt; hidden\\ntext [fsf](http://fsf.org)...\nThis &amp; that in a normal sentence. \"manual quote\"\n</code></pre>\n<p>These characters stem from (Reddit-specific) Markdown formatting. See <a href=\"https://i.imgur.com/pWreKRA.png\" rel=\"nofollow\">here</a> how the first bit looks like on Reddit.</p>\n<h3>Output</h3>\n<p>This Python module removes these characters and returns the cleaned text. Using the example above, the output would be:</p>\n<pre><code>Normal text Bold Italic\nStrike-through Code Superscript\nSpoiler Heading Bullet list: Item 1 Item 2 \nNumbered list: 1. Item 1 2. Item 2 Quote\nCode block Table: Cell 1.1 Cell 1.2 Cell 2.1 Cell 2.2\n\nFind the hidden text ... This &amp; that in a normal sentence. \"manual quote\"\n</code></pre>\n<p>:warning: <strong>Common punctuation, numbers, parentheses, quotation marks, emojis, etc. are deliberately not removed</strong>, as this data cleaning task pertains to Reddit-specific characters only. An additional round of data cleaning can be applied manually to clean these common items or apply lowercasing, or whatever else is needed.</p>\n<h3>Advanced Usage</h3>\n<p>The <code>clean</code> function supports optional arguments and it can be used as a lambda to be applied on e.g. Pandas DataFrames.</p>\n<h4>Optional Arguments</h4>\n<p>Specific removals of characters can be disabled with optional arguments passed to the <code>clean</code> function. Everything is on by default, but setting one to <code>False</code> disables it.</p>\n<pre><span class=\"k\">def</span> <span class=\"nf\">clean</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">,</span> <span class=\"n\">newline</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">quote</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">bullet_point</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> \n          <span class=\"n\">link</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">strikethrough</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">spoiler</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n          <span class=\"n\">code</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">superscript</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">table</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">heading</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<p>E.g.</p>\n<pre><span class=\"n\">redditcleaner</span><span class=\"o\">.</span><span class=\"n\">clean</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">,</span> <span class=\"n\">heading</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n</pre>\n<h4>Pandas Usage</h4>\n<p>This simulates a common format used when retrieving this type of data via the Reddit API:</p>\n<pre><span class=\"c1\"># Put \"retrieved\" text into Pandas Dataframe</span>\n<span class=\"n\">test_body_1</span> <span class=\"o\">=</span> <span class=\"s2\">\"</span><span class=\"se\">\\n</span><span class=\"s2\"> * Find &amp;amp;#x200B; &amp;gt; </span><span class=\"se\">\\\"\\\\</span><span class=\"s2\">&amp;gt; the </span><span class=\"se\">\\\"</span><span class=\"s2\">&amp;gt; hidden</span><span class=\"se\">\\n</span><span class=\"s2\">text [fsf](http://fsf.org)... This &amp; that in a normal sentence. </span><span class=\"se\">\\\"</span><span class=\"s2\">manual quote</span><span class=\"se\">\\\"</span><span class=\"s2\">\"</span>\n<span class=\"n\">test_body_2</span> <span class=\"o\">=</span> <span class=\"s2\">\"Normal text</span><span class=\"se\">\\n\\n</span><span class=\"s2\">**Bold**</span><span class=\"se\">\\n\\n</span><span class=\"s2\">*Italic*</span><span class=\"se\">\\n\\n</span><span class=\"s2\">[Link](https://fsf.org)</span><span class=\"se\">\\n\\n</span><span class=\"s2\">~~Strike-through~~</span><span class=\"se\">\\n\\n</span><span class=\"s2\">`Code`</span><span class=\"se\">\\n\\n</span><span class=\"s2\">^(Superscript)</span><span class=\"se\">\\n\\n</span><span class=\"s2\">&amp;gt;!Spoiler!&amp;lt;</span><span class=\"se\">\\n\\n</span><span class=\"s2\"># Heading</span><span class=\"se\">\\n\\n</span><span class=\"s2\">Bullet list:</span><span class=\"se\">\\n\\n</span><span class=\"s2\">* Item 1</span><span class=\"se\">\\n</span><span class=\"s2\">* Item 2</span><span class=\"se\">\\n\\n</span><span class=\"s2\">Numbered list:</span><span class=\"se\">\\n\\n</span><span class=\"s2\">1. Item 1</span><span class=\"se\">\\n</span><span class=\"s2\">2. Item 2</span><span class=\"se\">\\n\\n</span><span class=\"s2\">&amp;gt;Quote</span><span class=\"se\">\\n\\n</span><span class=\"s2\">    Code block</span><span class=\"se\">\\n\\n</span><span class=\"s2\">Table:</span><span class=\"se\">\\n\\n</span><span class=\"s2\">|Cell 1.1|Cell 1.2|</span><span class=\"se\">\\n</span><span class=\"s2\">|:-|:-|</span><span class=\"se\">\\n</span><span class=\"s2\">|Cell 2.1|Cell 2.2|\"</span>\n\n<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">([[</span><span class=\"s1\">'asdf'</span><span class=\"p\">,</span> <span class=\"s1\">'test_a'</span><span class=\"p\">,</span> <span class=\"n\">test_body_1</span><span class=\"p\">],</span>\n                   <span class=\"p\">[</span><span class=\"s1\">'fdsa'</span><span class=\"p\">,</span> <span class=\"s1\">'test_b'</span><span class=\"p\">,</span> <span class=\"n\">test_body_2</span><span class=\"p\">]],</span>\n                   <span class=\"n\">columns</span><span class=\"o\">=</span><span class=\"nb\">list</span><span class=\"p\">([</span><span class=\"s1\">'id'</span><span class=\"p\">,</span> <span class=\"s1\">'author'</span><span class=\"p\">,</span> <span class=\"s1\">'body'</span><span class=\"p\">]))</span>\n\n<span class=\"c1\"># Prepare redditcleaner</span>\n<span class=\"kn\">import</span> <span class=\"nn\">redditcleaner</span>\n\n<span class=\"c1\"># Apply (map) the function on all body column entries</span>\n<span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'body'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'body'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">map</span><span class=\"p\">(</span><span class=\"n\">redditcleaner</span><span class=\"o\">.</span><span class=\"n\">clean</span><span class=\"p\">)</span>\n<span class=\"n\">df</span>\n</pre>\n<table>\n<thead>\n<tr>\n<th align=\"right\"></th>\n<th align=\"left\">id</th>\n<th align=\"left\">author</th>\n<th align=\"left\">body</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"right\">0</td>\n<td align=\"left\">asdf</td>\n<td align=\"left\">testa</td>\n<td align=\"left\">Find    the  hidden text ... This &amp; that in a normal sentence. \"manual quote\"</td>\n</tr>\n<tr>\n<td align=\"right\">1</td>\n<td align=\"left\">fdsa</td>\n<td align=\"left\">testb</td>\n<td align=\"left\">Normal text  Bold  Italic    Strike-through  Code  Superscript  Spoiler   Heading  Bullet list:   Item 1  Item 2  Numbered list:  1. Item 1 2. Item 2  Quote      Code block  Table:   Cell 1.1 Cell 1.2       Cell 2.1 Cell 2.2</td>\n</tr></tbody></table>\n<h2>Contributing</h2>\n<p>If I missed any characters that should also be removed, please let me know or feel free to create a PR yourself! :heart:</p>\n\n          </div>"}, "last_serial": 7016092, "releases": {"1.0": [{"comment_text": "", "digests": {"md5": "10ac4e3aef2d3c7e87357152d3b07540", "sha256": "19bd2258baf10724a67280c7d1ecb9fff00a28e8eb84fafb0f166406c710bb0f"}, "downloads": -1, "filename": "redditcleaner-1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "10ac4e3aef2d3c7e87357152d3b07540", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 4491, "upload_time": "2020-04-10T11:11:45", "upload_time_iso_8601": "2020-04-10T11:11:45.768819Z", "url": "https://files.pythonhosted.org/packages/cf/2e/f1b6bbee03cd58c9c664d87484d5674076b392350686b92cccb645328fef/redditcleaner-1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "eaff9c24b59ee53d347dcf94ffe3dd36", "sha256": "1c21c8a1c1891c32a98171bd4f5643594313bff7a68b7299bb5c98f267f25432"}, "downloads": -1, "filename": "redditcleaner-1.0.tar.gz", "has_sig": false, "md5_digest": "eaff9c24b59ee53d347dcf94ffe3dd36", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 3718, "upload_time": "2020-04-10T11:11:47", "upload_time_iso_8601": "2020-04-10T11:11:47.858827Z", "url": "https://files.pythonhosted.org/packages/f8/ff/4397549da820b69e897fd8f9dfa8c1776e4186563853cef7fd6b3d112b2d/redditcleaner-1.0.tar.gz", "yanked": false}], "1.1": [{"comment_text": "", "digests": {"md5": "8c0682bf3ca2ee3c14e61662690fb2bc", "sha256": "95cab5518e512f6cd3bbf686e8fb0603495ec0a35daac79b75d2075f0777bbae"}, "downloads": -1, "filename": "redditcleaner-1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "8c0682bf3ca2ee3c14e61662690fb2bc", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 4609, "upload_time": "2020-04-11T16:15:05", "upload_time_iso_8601": "2020-04-11T16:15:05.655597Z", "url": "https://files.pythonhosted.org/packages/6f/5e/b29b768cbbef065067fdd0083e919418492d9119fc4a907842191079f62b/redditcleaner-1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "55ca236ba9488cb11cf7d7c60dd454b9", "sha256": "3d95d46245f606ff941fe462b08f5d96744ac7f0dc185dcd421ca1885363d891"}, "downloads": -1, "filename": "redditcleaner-1.1.tar.gz", "has_sig": false, "md5_digest": "55ca236ba9488cb11cf7d7c60dd454b9", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 3833, "upload_time": "2020-04-11T16:15:06", "upload_time_iso_8601": "2020-04-11T16:15:06.845447Z", "url": "https://files.pythonhosted.org/packages/56/4f/7bee0539f3a93fddc631dfcc6833a3ba9f2ac346ad452b62b4e40d5f7cca/redditcleaner-1.1.tar.gz", "yanked": false}], "1.1.1": [{"comment_text": "", "digests": {"md5": "54e6044255d13e2cfb29a21964b1046a", "sha256": "7f7e4fce6376156f255778c5467726a13729ca42e6e10745d5d007e77b014e40"}, "downloads": -1, "filename": "redditcleaner-1.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "54e6044255d13e2cfb29a21964b1046a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 4605, "upload_time": "2020-04-11T16:44:06", "upload_time_iso_8601": "2020-04-11T16:44:06.623441Z", "url": "https://files.pythonhosted.org/packages/28/55/d98aac3c51774834eac205585c7ca3314b9f0f8a399bd7b7b298b6f8062a/redditcleaner-1.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cadfd79e2678ea40d2b55820bbbbbd17", "sha256": "1f274bce28eb259193964d358ff0c88088f86a7c67c0a87bb1a7c4bd55fce9ba"}, "downloads": -1, "filename": "redditcleaner-1.1.1.tar.gz", "has_sig": false, "md5_digest": "cadfd79e2678ea40d2b55820bbbbbd17", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 3811, "upload_time": "2020-04-11T16:44:07", "upload_time_iso_8601": "2020-04-11T16:44:07.999495Z", "url": "https://files.pythonhosted.org/packages/ca/1f/4f9b88ed57535d5dffa1fe95f6ca41bb52c2d9cbb137845ca8cc833b084e/redditcleaner-1.1.1.tar.gz", "yanked": false}], "1.1.2": [{"comment_text": "", "digests": {"md5": "ba19f361a6bc1ce34bc2a20a2d2099bc", "sha256": "bd07bd225fdf1a8e64a6588470180e53b82fde614aba1740f586569f41bb9368"}, "downloads": -1, "filename": "redditcleaner-1.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "ba19f361a6bc1ce34bc2a20a2d2099bc", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 4662, "upload_time": "2020-04-14T10:21:53", "upload_time_iso_8601": "2020-04-14T10:21:53.775406Z", "url": "https://files.pythonhosted.org/packages/f9/8a/7491757daaf8f3381f736473018880c9e89defd44b9ebbf48a83c172e5ff/redditcleaner-1.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "12d49a956616d0f2df74e8cd32d478d1", "sha256": "08f0fe87189ebfb861e55b10f0d29ae6436d03e71b0b92959fb0b361b6788089"}, "downloads": -1, "filename": "redditcleaner-1.1.2.tar.gz", "has_sig": false, "md5_digest": "12d49a956616d0f2df74e8cd32d478d1", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 3862, "upload_time": "2020-04-14T10:21:55", "upload_time_iso_8601": "2020-04-14T10:21:55.224570Z", "url": "https://files.pythonhosted.org/packages/25/0c/230a93f35d48e60d6daf8695ac7d0a7ccf62e28f35dcdb2d12718607c043/redditcleaner-1.1.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ba19f361a6bc1ce34bc2a20a2d2099bc", "sha256": "bd07bd225fdf1a8e64a6588470180e53b82fde614aba1740f586569f41bb9368"}, "downloads": -1, "filename": "redditcleaner-1.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "ba19f361a6bc1ce34bc2a20a2d2099bc", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 4662, "upload_time": "2020-04-14T10:21:53", "upload_time_iso_8601": "2020-04-14T10:21:53.775406Z", "url": "https://files.pythonhosted.org/packages/f9/8a/7491757daaf8f3381f736473018880c9e89defd44b9ebbf48a83c172e5ff/redditcleaner-1.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "12d49a956616d0f2df74e8cd32d478d1", "sha256": "08f0fe87189ebfb861e55b10f0d29ae6436d03e71b0b92959fb0b361b6788089"}, "downloads": -1, "filename": "redditcleaner-1.1.2.tar.gz", "has_sig": false, "md5_digest": "12d49a956616d0f2df74e8cd32d478d1", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 3862, "upload_time": "2020-04-14T10:21:55", "upload_time_iso_8601": "2020-04-14T10:21:55.224570Z", "url": "https://files.pythonhosted.org/packages/25/0c/230a93f35d48e60d6daf8695ac7d0a7ccf62e28f35dcdb2d12718607c043/redditcleaner-1.1.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:05:58 2020"}