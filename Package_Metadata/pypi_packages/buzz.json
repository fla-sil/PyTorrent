{"info": {"author": "Daniel McDonald", "author_email": "mcddjx@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "[![Build Status](https://travis-ci.org/interrogator/buzz.svg?branch=master)](https://travis-ci.org/interrogator/buzz)\n[![codecov.io](https://codecov.io/gh/interrogator/buzz/branch/master/graph/badge.svg)](https://codecov.io/gh/interrogator/buzz)\n[![readthedocs](https://readthedocs.org/projects/buzz/badge/?version=latest)](https://buzz.readthedocs.io/en/latest/)\n[![PyPI version](https://badge.fury.io/py/buzz.svg)](https://badge.fury.io/py/buzz)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/python/black)\n\n# buzz: python corpus linguistics\n\n<!--- Don't edit the version line below manually. Let bump2version do it for you. -->\n> Version 3.1.4\n\n> *buzz* is a linguistics tool for parsing and then exploring plain or metadata-rich text. This README provides an overview of functionality. Visit the [full documentation](https://buzz.readthedocs.io/en/latest/) for a more complete user guide.\n\n## Install\n\n*buzz* requires Python 3.6 or higher. A virtual environment is recommended.\n\n```bash\npip install buzz[word]\n# or\ngit clone http://github.com/interrogator/buzz\ncd buzz\npython setup.py install\n```\n\n## Frontend: *buzzword*\n\n*buzz* has an optional frontend, *buzzword*, for exploring parsed corpora. To use it, install:\n\n```bash\npip install buzz[word]\n```\n\nThen, generate a workspace, `cd` into it, and start:\n\n```bash\npython -m buzzword.create workspace\ncd workspace\npython -m buzzword\n```\n\nMore complete documentation is available [here](https://buzzword.readthedocs.io/en/latest/), as well from the main page of the app itself.\n\nA URL will be printed, which can be used to access the app in your browser.\n\n## Creating corpora\n\n*buzz* models plain text, or [CONLL-U formatted](https://universaldependencies.org/format.html) files. The remainder of this guide will assume that you are have plain text data, and want to process and analyse it on the command line using *buzz*.\n\nFirst, you need to make sure that your corpus is in a format and structure that *buzz* can work with. This simply means putting all your text files into a folder, and optionally within subfolders (representing subcorpora).\n\nText files should be plain text, with a `.txt` extension. Importantly though, they can be augmented with metadata, which can be stored in two ways. First, speaker names can be added by using capital letters and a colon, much like in a script. Second, you can use XML style metadata markup. Here is an example file, `sopranos/s1/e01.txt`:\n\n```html\n<meta aired=\"10.01.1999\" />\nMELFI: My understanding from Dr. Cusamano, your family physician, is you collapsed? Possibly a panic attack? <meta exposition=true interrogative-type=\"intonation\" move=\"info-request\">\nTONY: <meta emph=true>They</meta> said it was a panic attack <meta move=\"refute\" /> \nMELFI: You don't agree that you had a panic attack? <meta move=\"info-request\" question=type=\"in\" />\n...\n```\n\nIf you add a `meta` element at the start of the text file, it will be understood as file-level metadata. For sentence-specific metadata, the element should follow the sentence, ideally at the end of a line. Span- and token-level metadata should wrap the tokens you want to annotate. All metadata will be searchable later, so the more you can add, the more you can do with your corpus.\n\nTo load corpora as *buzz* objects:\n\n```python\nfrom buzz import Corpus\n\ncorpus = Corpus(\"sopranos\")\n```\n\nYou can also make virtual corpora from strings, optionally saving the corpus to disk.\n\n```python\ncorpus = Corpus.from_string(\"Some sentences here.\", save_as=\"corpusname\")\n```\n\n## Parsing\n\nbuzz uses [`spaCy`](https://spacy.io/) to parse your text, saving the results as CONLL-U files to your hard drive. Parsing by default is only for dependencies, but constituency parsing can be added with a keyword argument:\n\n```python\n# only dependency parsing\nparsed = corpus.parse()\n# if you also want constituency parsing, using benepar\nparsed = corpus.parse(cons_parser=\"benepar\")\n# if you want constituency parsing using bllip\nparsed = corpus.parse(cons_parser=\"bblip\")\n```\n\nYou can also parse text strings, optionally passing in a name under which to save the corpus:\n\n```python\nfrom buzz import Parser\nparser = Parser(cons_parser=\"benepar\")\nfor text in list_of_texts:\n    dataset = parser.run(text, save_as=False)\n```\n\nThe main advantages of parsing with *buzz* are that:\n\n* Parse results are stored as valid CONLL-U 2.0\n* Metadata is respected, and transferred into the output files\n* You can do constituency and dependency parsing at the same time (with parse trees being stored as CONLL-U metadata)\n\nthe `parse()` method returns another `Corpus` object, representing the newly created files. We can explore this corpus via commands like:\n\n```python\nparsed.subcorpora.s1.files.e01\nparsed.files[0]\nparsed.subcorpora.s1[:5]\nparsed.subcorpora[\"s1\"]\n```\n\n### Parse command\n\nYou can also parse corpora without entering a Python session by using the `parse` command:\n\n```bash\nparse --language en --cons-parser=benepar|bllip|none path/to/conll/files\n# or \npython -m buzz.parse path/to/conll/files\n```\n\nBoth commands will create `path/to/conll/files-parsed`, a folder containing CONLL-U files.\n\n### Loading corpora into memory\n\nYou can use the `load()` method to load a whole or partial corpus into memory, as a Dataset object, which extends the [pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html).\n\n```python\nloaded = parsed.load()\n```\n\nYou don't need to load corpora into memory to work on them, but it's great for small corpora. As a rule of thumb, datasets under a million words should be easily loadable on a personal computer.\n\nThe loaded corpus is a `Dataset` object, which is based on the pandas DataFrame. So, you can use pandas methods on it:\n\n\n```python\nloaded.head()\n```\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>w</th>\n      <th>l</th>\n      <th>x</th>\n      <th>p</th>\n      <th>g</th>\n      <th>f</th>\n      <th>e</th>\n      <th>aired</th>\n      <th>emph</th>\n      <th>ent_id</th>\n      <th>ent_iob</th>\n      <th>ent_type</th>\n      <th>exposition</th>\n      <th>interrogative_type</th>\n      <th>move</th>\n      <th>question</th>\n      <th>sent_id</th>\n      <th>sent_len</th>\n      <th>speaker</th>\n      <th>text</th>\n      <th>_n</th>\n    </tr>\n    <tr>\n      <th>file</th>\n      <th>s</th>\n      <th>i</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">text</th>\n      <th rowspan=\"5\" valign=\"top\">1</th>\n      <th>1</th>\n      <td>My</td>\n      <td>-PRON-</td>\n      <td>DET</td>\n      <td>PRP$</td>\n      <td>2</td>\n      <td>poss</td>\n      <td>_</td>\n      <td>10.01.1999</td>\n      <td>_</td>\n      <td>2</td>\n      <td>O</td>\n      <td>_</td>\n      <td>True</td>\n      <td>intonation</td>\n      <td>info-request</td>\n      <td>_</td>\n      <td>1</td>\n      <td>14</td>\n      <td>MELFI</td>\n      <td>My understanding from Dr. Cusamano, your family physician, is you collapsed?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>understanding</td>\n      <td>understanding</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>13</td>\n      <td>nsubjpass</td>\n      <td>_</td>\n      <td>10.01.1999</td>\n      <td>_</td>\n      <td>2</td>\n      <td>O</td>\n      <td>_</td>\n      <td>True</td>\n      <td>intonation</td>\n      <td>info-request</td>\n      <td>_</td>\n      <td>1</td>\n      <td>14</td>\n      <td>MELFI</td>\n      <td>My understanding from Dr. Cusamano, your family physician, is you collapsed?</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>from</td>\n      <td>from</td>\n      <td>ADP</td>\n      <td>IN</td>\n      <td>2</td>\n      <td>prep</td>\n      <td>_</td>\n      <td>10.01.1999</td>\n      <td>_</td>\n      <td>2</td>\n      <td>O</td>\n      <td>_</td>\n      <td>True</td>\n      <td>intonation</td>\n      <td>info-request</td>\n      <td>_</td>\n      <td>1</td>\n      <td>14</td>\n      <td>MELFI</td>\n      <td>My understanding from Dr. Cusamano, your family physician, is you collapsed?</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dr.</td>\n      <td>Dr.</td>\n      <td>PROPN</td>\n      <td>NNP</td>\n      <td>5</td>\n      <td>compound</td>\n      <td>_</td>\n      <td>10.01.1999</td>\n      <td>_</td>\n      <td>2</td>\n      <td>O</td>\n      <td>_</td>\n      <td>True</td>\n      <td>intonation</td>\n      <td>info-request</td>\n      <td>_</td>\n      <td>1</td>\n      <td>14</td>\n      <td>MELFI</td>\n      <td>My understanding from Dr. Cusamano, your family physician, is you collapsed?</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Cusamano</td>\n      <td>Cusamano</td>\n      <td>PROPN</td>\n      <td>NNP</td>\n      <td>3</td>\n      <td>pobj</td>\n      <td>_</td>\n      <td>10.01.1999</td>\n      <td>_</td>\n      <td>3</td>\n      <td>B</td>\n      <td>PERSON</td>\n      <td>True</td>\n      <td>intonation</td>\n      <td>info-request</td>\n      <td>_</td>\n      <td>1</td>\n      <td>14</td>\n      <td>MELFI</td>\n      <td>My understanding from Dr. Cusamano, your family physician, is you collapsed?</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n\nYou can also interactively explore the corpus with [tabview](https://github.com/TabViewer/tabview) using the `view()` method:\n\n```python\nloaded.view()\n```\n\nThe interactive view has a number of cool features, such as the ability to sort by row or column. Also, pressing `enter` on a given line will generate a concordance based on that line's contents. Neat!\n\n## Exploring parsed and loaded corpora\n\nA corpus is a pandas DataFrame object. The index is a multiindex, comprised of `filename`, `sent_id` and `token`. Each token in the corpus is therefore uniquely identifiable through this index. The columns for the loaded copus are all the CONLL columns, plus anything included as metadata.\n\n```python\n# get the first sentence using buzz.dataset.sent()\nfirst = loaded.sent(0)\n# using pandas syntax to get first 5 words\nfirst.iloc[:5][\"w\"]\n# join the wordclasses and words\nprint(\" \".join(first.x.str.cat(first.w, sep=\"/\")))\n```\n\n```\n\"DET/My NOUN/understanding ADP/from PROPN/Dr. PROPN/Cusamano PUNCT/, DET/your NOUN/family NOUN/physician PUNCT/, VERB/is PRON/you VERB/collapsed PUNCT/?\n```\n\nYou don't need to know pandas, however, in order to use *buzz*, because *buzz* makes possible some more intuitive measures with linguistics in mind. For example, if you want to slice the corpus some way, you can easily do this using the `just` and `skip` properties, combined with the column/metadata feature you want to filter by:\n\n```python\ntony = loaded.just.speaker.TONY\n# you can use brackets (i.e. for regular expressions):\nno_punct = loaded.skip.lemmata(\"^[^a-zA-Z0-9]\")\n# or you can pass in a list/set/tuple:\nend_in_s = loaded.just.pos([\"NNS\", \"NNPS\", \"VBZ\"])\n```\n\nAny object created by *buzz* has a `.view()` method, which launches a `tabview` interactive space where you can explore corpora, frequencies or concordances.\n\n## spaCy\n\n[`spaCy`](https://spacy.io/) is used under the hood for dependency parsing, and a couple of other things. spaCy bring with it a lot of state of the art methods in NLP. You can access the `spaCy` representation of your data with:\n\n```python\ncorpus.to_spacy()\n# or\nloaded.to_spacy()\n```\n\n## Searching dependencies\n\nTo search the dependency graph generated by spaCy during parsing, you can use the *depgrep* method.\n\n\n```python\n# search dependencies for nominal subjects with definite articles\nnsubj = loaded.depgrep('f/nsubj.*/ -> (w\"the\" & x\"DET\")')\n```\n\nThe search language works by modelling nodes and the links between them. Specifying a node, like `f/nsubj/`, is done by specifying the feature you want to match (`f` for `function`), and a query inside slashes (for regular expressions) or inside quotation marks (for literal matches).\n\nThe arrow-like link specifies that the `nsubj` must govern the determiner. The `&` relation specifies that the two nodes are actually the same node. Brackets may be necessary to contain the query.\n\nThis language is based on `Tgrep2`, syntax, customised for dependencies. It is still a work in progress, but documentation should emerge [here](https://buzzword.readthedocs.io/en/latest/depgrep/), with repository [here](https://github.com/interrogator/depgrep).\n\n## Drill-down\n\nWhen you search a `Corpus` or `Dataset`, the result is simply another Dataset, representing a subset of the Corpus. Therefore, rather than trying to construct one query string that gets everything you want, it is often easier to perform multiple small searches:\n\n```python\nquery = 'f/nsubj/ <- f/ROOT/'\ntony_subjects = loaded.skip.wordclass.PUNCT.just.speaker.TONY.depgrep(query)\n```\n\nNote that for any searches that do not require traversal of the grammatical structure, you should use the `skip` and `just` methods. *tgrep* and *depgrep* only need to be used when your search involves the grammar, and not just token features.\n\n## Searching constituency trees\n\nThis is deprecated right now, due to lack of use (combined with requiring a lot of special handling). Make an issue if you really need this functionality and we can consider bringing it back, probably via BLLIP or Benepar. If you're making corpora with constituency parses, please use `parse = (S ...)` as sentence-level metadata to encode the parse.\n\n## Viewing search results\n\nAn important principle in *buzz* is the separation of searching and viewing results. Unlike many other tools, you do not search for a concordance---instead, you search the corpus, and then visualise the output of the data as a concordance.\n\n### Concordancing\n\nConcordancing is a nice way of looking at results. The main thing you have to do is tell *buzz* how you want the match column to look---it can be just the matching words, but also any combination of things. To show words and their parts of speech, you can do:\n\n```python\nnsubj = loaded.just.function.nsubj\nnsubj.conc(show=[\"w\", \"p\"])\n```\n\n### Frequency tables\n\nYou can turn your dataset into frequency tables, both before or after searching or filtering. Tabling takes a `show` argument similar to the `show` argument for concordancing, as well as an additional `subcorpora` argument. `show` represents the how the columns will be formatted, and `subcorpora` is used as the index. Below we create a frequency table of `nsubj` tokens, in lemma form, organised by speaker.\n\n```python\ntab = nsubj.table(show=\"l\", subcorpora=[\"speaker\"])\n```\n\nPossible keyword arguments for the `.table()` method are as follows:\n\n| Argument           | Description                                                                                                                                                                                                                                                                                      | Default  |\n|--------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------|\n| `subcorpora`         | Feature(s) to use as the index of the table. Passing in a list of multiple features will create a multiindex                                                                                                                                                                                     | `['file']` |\n| `show`               | Feature(s) to use as the columns of the table. Passing a list will join the features with slash, so `['w', 'p']` results in columns with names like `'friend/NN'`                                                                                                                                | `['w']`    |\n| `sort`               | How to sort the results. 'total'/'infreq', 'increase/'decrease', 'static/turbulent', 'name'/'inverse'                                                                                                                                                                                            | `'total'`  |\n| `relative`           | Use relative, rather than absolute frequencies with `True`. You can also pass in Series, DataFrame or buzz objects to calculate relative frequencies against the passed in data.                                                                                                                 | `False`    |\n| `remove_above_p`     | Sorting by increase/decrease/static/turbulent calculates the slope of the frequencies across each subcorpus, and p-values where the null hypothesis is no slope. If you pass in a float, entries with p-values above this float are dropped from the results. Passing in `True` will use `0.05`. | `False`    |\n| `keep_stats`         | If True, keep generated statistics related to the trajectory calculation                                                                                                                                                                                                                         | `False`    |\n| `preserve_case`      | Keep the original case for `show` (column) values                                                                                                                                                                                                                                                | `False`    |\n| `multiindex_columns` | When `show` is a list with multiple features, rather than joining `show` with slashes, build a multiindex                                                                                                                                                                                        | `False`    |\n\n\nThis creates a `Table` object, which is also based on DataFrame. You can use its `.view()` method to quickly explore results. Pressing enter on a given frequency will bring up a concordance of instances of this entry.\n\n### Plotting\n\nYou can also use *buzz* to create high-quality visualisations of frequency data. This relies completely on [pandas' plotting method](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html). A `plot` method more tailored to language datasets is still in development.\n\n```python\ntab.plot(...)\n```\n\n## Contributing\n\nIf you find bugs, feel free to create an issue. The project is open-source, so pull requests are also welcome. Code style is [`black`](https://github.com/psf/black), and versioning is handled by [`bump2version`](https://github.com/c4urself/bump2version).", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://github.com/interrogator/buzz", "keywords": "corpus,linguistics,nlp", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "buzz", "package_url": "https://pypi.org/project/buzz/", "platform": "", "project_url": "https://pypi.org/project/buzz/", "project_urls": {"Homepage": "http://github.com/interrogator/buzz"}, "release_url": "https://pypi.org/project/buzz/3.1.4/", "requires_dist": null, "requires_python": "", "summary": "Sophisticated corpus linguistics", "version": "3.1.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://travis-ci.org/interrogator/buzz\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ab8655b34bd09747f6cfc2018d43636e6ac443d8/68747470733a2f2f7472617669732d63692e6f72672f696e746572726f6761746f722f62757a7a2e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://codecov.io/gh/interrogator/buzz\" rel=\"nofollow\"><img alt=\"codecov.io\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/dd8d70f78175902186e5a2fe680faf3c4aff4a76/68747470733a2f2f636f6465636f762e696f2f67682f696e746572726f6761746f722f62757a7a2f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a>\n<a href=\"https://buzz.readthedocs.io/en/latest/\" rel=\"nofollow\"><img alt=\"readthedocs\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f9484d32c19f5c3655b6de1c9fdba02f417928ab/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f62757a7a2f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<a href=\"https://badge.fury.io/py/buzz\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f99765f3723bd648efcde2ac80eb8728fb55e0dd/68747470733a2f2f62616467652e667572792e696f2f70792f62757a7a2e737667\"></a>\n<a href=\"https://github.com/python/black\" rel=\"nofollow\"><img alt=\"Code style: black\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fbfdc7754183ecf079bc71ddeabaf88f6cbc5c00/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667\"></a></p>\n<h1>buzz: python corpus linguistics</h1>\n\n<blockquote>\n<p>Version 3.1.4</p>\n</blockquote>\n<blockquote>\n<p><em>buzz</em> is a linguistics tool for parsing and then exploring plain or metadata-rich text. This README provides an overview of functionality. Visit the <a href=\"https://buzz.readthedocs.io/en/latest/\" rel=\"nofollow\">full documentation</a> for a more complete user guide.</p>\n</blockquote>\n<h2>Install</h2>\n<p><em>buzz</em> requires Python 3.6 or higher. A virtual environment is recommended.</p>\n<pre>pip install buzz<span class=\"o\">[</span>word<span class=\"o\">]</span>\n<span class=\"c1\"># or</span>\ngit clone http://github.com/interrogator/buzz\n<span class=\"nb\">cd</span> buzz\npython setup.py install\n</pre>\n<h2>Frontend: <em>buzzword</em></h2>\n<p><em>buzz</em> has an optional frontend, <em>buzzword</em>, for exploring parsed corpora. To use it, install:</p>\n<pre>pip install buzz<span class=\"o\">[</span>word<span class=\"o\">]</span>\n</pre>\n<p>Then, generate a workspace, <code>cd</code> into it, and start:</p>\n<pre>python -m buzzword.create workspace\n<span class=\"nb\">cd</span> workspace\npython -m buzzword\n</pre>\n<p>More complete documentation is available <a href=\"https://buzzword.readthedocs.io/en/latest/\" rel=\"nofollow\">here</a>, as well from the main page of the app itself.</p>\n<p>A URL will be printed, which can be used to access the app in your browser.</p>\n<h2>Creating corpora</h2>\n<p><em>buzz</em> models plain text, or <a href=\"https://universaldependencies.org/format.html\" rel=\"nofollow\">CONLL-U formatted</a> files. The remainder of this guide will assume that you are have plain text data, and want to process and analyse it on the command line using <em>buzz</em>.</p>\n<p>First, you need to make sure that your corpus is in a format and structure that <em>buzz</em> can work with. This simply means putting all your text files into a folder, and optionally within subfolders (representing subcorpora).</p>\n<p>Text files should be plain text, with a <code>.txt</code> extension. Importantly though, they can be augmented with metadata, which can be stored in two ways. First, speaker names can be added by using capital letters and a colon, much like in a script. Second, you can use XML style metadata markup. Here is an example file, <code>sopranos/s1/e01.txt</code>:</p>\n<pre><span class=\"p\">&lt;</span><span class=\"nt\">meta</span> <span class=\"na\">aired</span><span class=\"o\">=</span><span class=\"s\">\"10.01.1999\"</span> <span class=\"p\">/&gt;</span>\nMELFI: My understanding from Dr. Cusamano, your family physician, is you collapsed? Possibly a panic attack? <span class=\"p\">&lt;</span><span class=\"nt\">meta</span> <span class=\"na\">exposition</span><span class=\"o\">=</span><span class=\"s\">true</span> <span class=\"na\">interrogative-type</span><span class=\"o\">=</span><span class=\"s\">\"intonation\"</span> <span class=\"na\">move</span><span class=\"o\">=</span><span class=\"s\">\"info-request\"</span><span class=\"p\">&gt;</span>\nTONY: <span class=\"p\">&lt;</span><span class=\"nt\">meta</span> <span class=\"na\">emph</span><span class=\"o\">=</span><span class=\"s\">true</span><span class=\"p\">&gt;</span>They<span class=\"p\">&lt;/</span><span class=\"nt\">meta</span><span class=\"p\">&gt;</span> said it was a panic attack <span class=\"p\">&lt;</span><span class=\"nt\">meta</span> <span class=\"na\">move</span><span class=\"o\">=</span><span class=\"s\">\"refute\"</span> <span class=\"p\">/&gt;</span> \nMELFI: You don't agree that you had a panic attack? <span class=\"p\">&lt;</span><span class=\"nt\">meta</span> <span class=\"na\">move</span><span class=\"o\">=</span><span class=\"s\">\"info-request\"</span> <span class=\"na\">question</span><span class=\"o\">=</span><span class=\"s\">type=\"in\"</span> <span class=\"p\">/&gt;</span>\n...\n</pre>\n<p>If you add a <code>meta</code> element at the start of the text file, it will be understood as file-level metadata. For sentence-specific metadata, the element should follow the sentence, ideally at the end of a line. Span- and token-level metadata should wrap the tokens you want to annotate. All metadata will be searchable later, so the more you can add, the more you can do with your corpus.</p>\n<p>To load corpora as <em>buzz</em> objects:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">buzz</span> <span class=\"kn\">import</span> <span class=\"n\">Corpus</span>\n\n<span class=\"n\">corpus</span> <span class=\"o\">=</span> <span class=\"n\">Corpus</span><span class=\"p\">(</span><span class=\"s2\">\"sopranos\"</span><span class=\"p\">)</span>\n</pre>\n<p>You can also make virtual corpora from strings, optionally saving the corpus to disk.</p>\n<pre><span class=\"n\">corpus</span> <span class=\"o\">=</span> <span class=\"n\">Corpus</span><span class=\"o\">.</span><span class=\"n\">from_string</span><span class=\"p\">(</span><span class=\"s2\">\"Some sentences here.\"</span><span class=\"p\">,</span> <span class=\"n\">save_as</span><span class=\"o\">=</span><span class=\"s2\">\"corpusname\"</span><span class=\"p\">)</span>\n</pre>\n<h2>Parsing</h2>\n<p>buzz uses <a href=\"https://spacy.io/\" rel=\"nofollow\"><code>spaCy</code></a> to parse your text, saving the results as CONLL-U files to your hard drive. Parsing by default is only for dependencies, but constituency parsing can be added with a keyword argument:</p>\n<pre><span class=\"c1\"># only dependency parsing</span>\n<span class=\"n\">parsed</span> <span class=\"o\">=</span> <span class=\"n\">corpus</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">()</span>\n<span class=\"c1\"># if you also want constituency parsing, using benepar</span>\n<span class=\"n\">parsed</span> <span class=\"o\">=</span> <span class=\"n\">corpus</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"n\">cons_parser</span><span class=\"o\">=</span><span class=\"s2\">\"benepar\"</span><span class=\"p\">)</span>\n<span class=\"c1\"># if you want constituency parsing using bllip</span>\n<span class=\"n\">parsed</span> <span class=\"o\">=</span> <span class=\"n\">corpus</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"n\">cons_parser</span><span class=\"o\">=</span><span class=\"s2\">\"bblip\"</span><span class=\"p\">)</span>\n</pre>\n<p>You can also parse text strings, optionally passing in a name under which to save the corpus:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">buzz</span> <span class=\"kn\">import</span> <span class=\"n\">Parser</span>\n<span class=\"n\">parser</span> <span class=\"o\">=</span> <span class=\"n\">Parser</span><span class=\"p\">(</span><span class=\"n\">cons_parser</span><span class=\"o\">=</span><span class=\"s2\">\"benepar\"</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">text</span> <span class=\"ow\">in</span> <span class=\"n\">list_of_texts</span><span class=\"p\">:</span>\n    <span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">parser</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">,</span> <span class=\"n\">save_as</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n</pre>\n<p>The main advantages of parsing with <em>buzz</em> are that:</p>\n<ul>\n<li>Parse results are stored as valid CONLL-U 2.0</li>\n<li>Metadata is respected, and transferred into the output files</li>\n<li>You can do constituency and dependency parsing at the same time (with parse trees being stored as CONLL-U metadata)</li>\n</ul>\n<p>the <code>parse()</code> method returns another <code>Corpus</code> object, representing the newly created files. We can explore this corpus via commands like:</p>\n<pre><span class=\"n\">parsed</span><span class=\"o\">.</span><span class=\"n\">subcorpora</span><span class=\"o\">.</span><span class=\"n\">s1</span><span class=\"o\">.</span><span class=\"n\">files</span><span class=\"o\">.</span><span class=\"n\">e01</span>\n<span class=\"n\">parsed</span><span class=\"o\">.</span><span class=\"n\">files</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n<span class=\"n\">parsed</span><span class=\"o\">.</span><span class=\"n\">subcorpora</span><span class=\"o\">.</span><span class=\"n\">s1</span><span class=\"p\">[:</span><span class=\"mi\">5</span><span class=\"p\">]</span>\n<span class=\"n\">parsed</span><span class=\"o\">.</span><span class=\"n\">subcorpora</span><span class=\"p\">[</span><span class=\"s2\">\"s1\"</span><span class=\"p\">]</span>\n</pre>\n<h3>Parse command</h3>\n<p>You can also parse corpora without entering a Python session by using the <code>parse</code> command:</p>\n<pre>parse --language en --cons-parser<span class=\"o\">=</span>benepar<span class=\"p\">|</span>bllip<span class=\"p\">|</span>none path/to/conll/files\n<span class=\"c1\"># or </span>\npython -m buzz.parse path/to/conll/files\n</pre>\n<p>Both commands will create <code>path/to/conll/files-parsed</code>, a folder containing CONLL-U files.</p>\n<h3>Loading corpora into memory</h3>\n<p>You can use the <code>load()</code> method to load a whole or partial corpus into memory, as a Dataset object, which extends the <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html\" rel=\"nofollow\">pandas DataFrame</a>.</p>\n<pre><span class=\"n\">loaded</span> <span class=\"o\">=</span> <span class=\"n\">parsed</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">()</span>\n</pre>\n<p>You don't need to load corpora into memory to work on them, but it's great for small corpora. As a rule of thumb, datasets under a million words should be easily loadable on a personal computer.</p>\n<p>The loaded corpus is a <code>Dataset</code> object, which is based on the pandas DataFrame. So, you can use pandas methods on it:</p>\n<pre><span class=\"n\">loaded</span><span class=\"o\">.</span><span class=\"n\">head</span><span class=\"p\">()</span>\n</pre>\n<table>\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>w</th>\n      <th>l</th>\n      <th>x</th>\n      <th>p</th>\n      <th>g</th>\n      <th>f</th>\n      <th>e</th>\n      <th>aired</th>\n      <th>emph</th>\n      <th>ent_id</th>\n      <th>ent_iob</th>\n      <th>ent_type</th>\n      <th>exposition</th>\n      <th>interrogative_type</th>\n      <th>move</th>\n      <th>question</th>\n      <th>sent_id</th>\n      <th>sent_len</th>\n      <th>speaker</th>\n      <th>text</th>\n      <th>_n</th>\n    </tr>\n    <tr>\n      <th>file</th>\n      <th>s</th>\n      <th>i</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>text</th>\n      <th>1</th>\n      <th>1</th>\n      <td>My</td>\n      <td>-PRON-</td>\n      <td>DET</td>\n      <td>PRP$</td>\n      <td>2</td>\n      <td>poss</td>\n      <td>_</td>\n      <td>10.01.1999</td>\n      <td>_</td>\n      <td>2</td>\n      <td>O</td>\n      <td>_</td>\n      <td>True</td>\n      <td>intonation</td>\n      <td>info-request</td>\n      <td>_</td>\n      <td>1</td>\n      <td>14</td>\n      <td>MELFI</td>\n      <td>My understanding from Dr. Cusamano, your family physician, is you collapsed?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>understanding</td>\n      <td>understanding</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>13</td>\n      <td>nsubjpass</td>\n      <td>_</td>\n      <td>10.01.1999</td>\n      <td>_</td>\n      <td>2</td>\n      <td>O</td>\n      <td>_</td>\n      <td>True</td>\n      <td>intonation</td>\n      <td>info-request</td>\n      <td>_</td>\n      <td>1</td>\n      <td>14</td>\n      <td>MELFI</td>\n      <td>My understanding from Dr. Cusamano, your family physician, is you collapsed?</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>from</td>\n      <td>from</td>\n      <td>ADP</td>\n      <td>IN</td>\n      <td>2</td>\n      <td>prep</td>\n      <td>_</td>\n      <td>10.01.1999</td>\n      <td>_</td>\n      <td>2</td>\n      <td>O</td>\n      <td>_</td>\n      <td>True</td>\n      <td>intonation</td>\n      <td>info-request</td>\n      <td>_</td>\n      <td>1</td>\n      <td>14</td>\n      <td>MELFI</td>\n      <td>My understanding from Dr. Cusamano, your family physician, is you collapsed?</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dr.</td>\n      <td>Dr.</td>\n      <td>PROPN</td>\n      <td>NNP</td>\n      <td>5</td>\n      <td>compound</td>\n      <td>_</td>\n      <td>10.01.1999</td>\n      <td>_</td>\n      <td>2</td>\n      <td>O</td>\n      <td>_</td>\n      <td>True</td>\n      <td>intonation</td>\n      <td>info-request</td>\n      <td>_</td>\n      <td>1</td>\n      <td>14</td>\n      <td>MELFI</td>\n      <td>My understanding from Dr. Cusamano, your family physician, is you collapsed?</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Cusamano</td>\n      <td>Cusamano</td>\n      <td>PROPN</td>\n      <td>NNP</td>\n      <td>3</td>\n      <td>pobj</td>\n      <td>_</td>\n      <td>10.01.1999</td>\n      <td>_</td>\n      <td>3</td>\n      <td>B</td>\n      <td>PERSON</td>\n      <td>True</td>\n      <td>intonation</td>\n      <td>info-request</td>\n      <td>_</td>\n      <td>1</td>\n      <td>14</td>\n      <td>MELFI</td>\n      <td>My understanding from Dr. Cusamano, your family physician, is you collapsed?</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>You can also interactively explore the corpus with <a href=\"https://github.com/TabViewer/tabview\" rel=\"nofollow\">tabview</a> using the <code>view()</code> method:</p>\n<pre><span class=\"n\">loaded</span><span class=\"o\">.</span><span class=\"n\">view</span><span class=\"p\">()</span>\n</pre>\n<p>The interactive view has a number of cool features, such as the ability to sort by row or column. Also, pressing <code>enter</code> on a given line will generate a concordance based on that line's contents. Neat!</p>\n<h2>Exploring parsed and loaded corpora</h2>\n<p>A corpus is a pandas DataFrame object. The index is a multiindex, comprised of <code>filename</code>, <code>sent_id</code> and <code>token</code>. Each token in the corpus is therefore uniquely identifiable through this index. The columns for the loaded copus are all the CONLL columns, plus anything included as metadata.</p>\n<pre><span class=\"c1\"># get the first sentence using buzz.dataset.sent()</span>\n<span class=\"n\">first</span> <span class=\"o\">=</span> <span class=\"n\">loaded</span><span class=\"o\">.</span><span class=\"n\">sent</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"c1\"># using pandas syntax to get first 5 words</span>\n<span class=\"n\">first</span><span class=\"o\">.</span><span class=\"n\">iloc</span><span class=\"p\">[:</span><span class=\"mi\">5</span><span class=\"p\">][</span><span class=\"s2\">\"w\"</span><span class=\"p\">]</span>\n<span class=\"c1\"># join the wordclasses and words</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\" \"</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">first</span><span class=\"o\">.</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">str</span><span class=\"o\">.</span><span class=\"n\">cat</span><span class=\"p\">(</span><span class=\"n\">first</span><span class=\"o\">.</span><span class=\"n\">w</span><span class=\"p\">,</span> <span class=\"n\">sep</span><span class=\"o\">=</span><span class=\"s2\">\"/\"</span><span class=\"p\">)))</span>\n</pre>\n<pre><code>\"DET/My NOUN/understanding ADP/from PROPN/Dr. PROPN/Cusamano PUNCT/, DET/your NOUN/family NOUN/physician PUNCT/, VERB/is PRON/you VERB/collapsed PUNCT/?\n</code></pre>\n<p>You don't need to know pandas, however, in order to use <em>buzz</em>, because <em>buzz</em> makes possible some more intuitive measures with linguistics in mind. For example, if you want to slice the corpus some way, you can easily do this using the <code>just</code> and <code>skip</code> properties, combined with the column/metadata feature you want to filter by:</p>\n<pre><span class=\"n\">tony</span> <span class=\"o\">=</span> <span class=\"n\">loaded</span><span class=\"o\">.</span><span class=\"n\">just</span><span class=\"o\">.</span><span class=\"n\">speaker</span><span class=\"o\">.</span><span class=\"n\">TONY</span>\n<span class=\"c1\"># you can use brackets (i.e. for regular expressions):</span>\n<span class=\"n\">no_punct</span> <span class=\"o\">=</span> <span class=\"n\">loaded</span><span class=\"o\">.</span><span class=\"n\">skip</span><span class=\"o\">.</span><span class=\"n\">lemmata</span><span class=\"p\">(</span><span class=\"s2\">\"^[^a-zA-Z0-9]\"</span><span class=\"p\">)</span>\n<span class=\"c1\"># or you can pass in a list/set/tuple:</span>\n<span class=\"n\">end_in_s</span> <span class=\"o\">=</span> <span class=\"n\">loaded</span><span class=\"o\">.</span><span class=\"n\">just</span><span class=\"o\">.</span><span class=\"n\">pos</span><span class=\"p\">([</span><span class=\"s2\">\"NNS\"</span><span class=\"p\">,</span> <span class=\"s2\">\"NNPS\"</span><span class=\"p\">,</span> <span class=\"s2\">\"VBZ\"</span><span class=\"p\">])</span>\n</pre>\n<p>Any object created by <em>buzz</em> has a <code>.view()</code> method, which launches a <code>tabview</code> interactive space where you can explore corpora, frequencies or concordances.</p>\n<h2>spaCy</h2>\n<p><a href=\"https://spacy.io/\" rel=\"nofollow\"><code>spaCy</code></a> is used under the hood for dependency parsing, and a couple of other things. spaCy bring with it a lot of state of the art methods in NLP. You can access the <code>spaCy</code> representation of your data with:</p>\n<pre><span class=\"n\">corpus</span><span class=\"o\">.</span><span class=\"n\">to_spacy</span><span class=\"p\">()</span>\n<span class=\"c1\"># or</span>\n<span class=\"n\">loaded</span><span class=\"o\">.</span><span class=\"n\">to_spacy</span><span class=\"p\">()</span>\n</pre>\n<h2>Searching dependencies</h2>\n<p>To search the dependency graph generated by spaCy during parsing, you can use the <em>depgrep</em> method.</p>\n<pre><span class=\"c1\"># search dependencies for nominal subjects with definite articles</span>\n<span class=\"n\">nsubj</span> <span class=\"o\">=</span> <span class=\"n\">loaded</span><span class=\"o\">.</span><span class=\"n\">depgrep</span><span class=\"p\">(</span><span class=\"s1\">'f/nsubj.*/ -&gt; (w\"the\" &amp; x\"DET\")'</span><span class=\"p\">)</span>\n</pre>\n<p>The search language works by modelling nodes and the links between them. Specifying a node, like <code>f/nsubj/</code>, is done by specifying the feature you want to match (<code>f</code> for <code>function</code>), and a query inside slashes (for regular expressions) or inside quotation marks (for literal matches).</p>\n<p>The arrow-like link specifies that the <code>nsubj</code> must govern the determiner. The <code>&amp;</code> relation specifies that the two nodes are actually the same node. Brackets may be necessary to contain the query.</p>\n<p>This language is based on <code>Tgrep2</code>, syntax, customised for dependencies. It is still a work in progress, but documentation should emerge <a href=\"https://buzzword.readthedocs.io/en/latest/depgrep/\" rel=\"nofollow\">here</a>, with repository <a href=\"https://github.com/interrogator/depgrep\" rel=\"nofollow\">here</a>.</p>\n<h2>Drill-down</h2>\n<p>When you search a <code>Corpus</code> or <code>Dataset</code>, the result is simply another Dataset, representing a subset of the Corpus. Therefore, rather than trying to construct one query string that gets everything you want, it is often easier to perform multiple small searches:</p>\n<pre><span class=\"n\">query</span> <span class=\"o\">=</span> <span class=\"s1\">'f/nsubj/ &lt;- f/ROOT/'</span>\n<span class=\"n\">tony_subjects</span> <span class=\"o\">=</span> <span class=\"n\">loaded</span><span class=\"o\">.</span><span class=\"n\">skip</span><span class=\"o\">.</span><span class=\"n\">wordclass</span><span class=\"o\">.</span><span class=\"n\">PUNCT</span><span class=\"o\">.</span><span class=\"n\">just</span><span class=\"o\">.</span><span class=\"n\">speaker</span><span class=\"o\">.</span><span class=\"n\">TONY</span><span class=\"o\">.</span><span class=\"n\">depgrep</span><span class=\"p\">(</span><span class=\"n\">query</span><span class=\"p\">)</span>\n</pre>\n<p>Note that for any searches that do not require traversal of the grammatical structure, you should use the <code>skip</code> and <code>just</code> methods. <em>tgrep</em> and <em>depgrep</em> only need to be used when your search involves the grammar, and not just token features.</p>\n<h2>Searching constituency trees</h2>\n<p>This is deprecated right now, due to lack of use (combined with requiring a lot of special handling). Make an issue if you really need this functionality and we can consider bringing it back, probably via BLLIP or Benepar. If you're making corpora with constituency parses, please use <code>parse = (S ...)</code> as sentence-level metadata to encode the parse.</p>\n<h2>Viewing search results</h2>\n<p>An important principle in <em>buzz</em> is the separation of searching and viewing results. Unlike many other tools, you do not search for a concordance---instead, you search the corpus, and then visualise the output of the data as a concordance.</p>\n<h3>Concordancing</h3>\n<p>Concordancing is a nice way of looking at results. The main thing you have to do is tell <em>buzz</em> how you want the match column to look---it can be just the matching words, but also any combination of things. To show words and their parts of speech, you can do:</p>\n<pre><span class=\"n\">nsubj</span> <span class=\"o\">=</span> <span class=\"n\">loaded</span><span class=\"o\">.</span><span class=\"n\">just</span><span class=\"o\">.</span><span class=\"n\">function</span><span class=\"o\">.</span><span class=\"n\">nsubj</span>\n<span class=\"n\">nsubj</span><span class=\"o\">.</span><span class=\"n\">conc</span><span class=\"p\">(</span><span class=\"n\">show</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"w\"</span><span class=\"p\">,</span> <span class=\"s2\">\"p\"</span><span class=\"p\">])</span>\n</pre>\n<h3>Frequency tables</h3>\n<p>You can turn your dataset into frequency tables, both before or after searching or filtering. Tabling takes a <code>show</code> argument similar to the <code>show</code> argument for concordancing, as well as an additional <code>subcorpora</code> argument. <code>show</code> represents the how the columns will be formatted, and <code>subcorpora</code> is used as the index. Below we create a frequency table of <code>nsubj</code> tokens, in lemma form, organised by speaker.</p>\n<pre><span class=\"n\">tab</span> <span class=\"o\">=</span> <span class=\"n\">nsubj</span><span class=\"o\">.</span><span class=\"n\">table</span><span class=\"p\">(</span><span class=\"n\">show</span><span class=\"o\">=</span><span class=\"s2\">\"l\"</span><span class=\"p\">,</span> <span class=\"n\">subcorpora</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"speaker\"</span><span class=\"p\">])</span>\n</pre>\n<p>Possible keyword arguments for the <code>.table()</code> method are as follows:</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Description</th>\n<th>Default</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>subcorpora</code></td>\n<td>Feature(s) to use as the index of the table. Passing in a list of multiple features will create a multiindex</td>\n<td><code>['file']</code></td>\n</tr>\n<tr>\n<td><code>show</code></td>\n<td>Feature(s) to use as the columns of the table. Passing a list will join the features with slash, so <code>['w', 'p']</code> results in columns with names like <code>'friend/NN'</code></td>\n<td><code>['w']</code></td>\n</tr>\n<tr>\n<td><code>sort</code></td>\n<td>How to sort the results. 'total'/'infreq', 'increase/'decrease', 'static/turbulent', 'name'/'inverse'</td>\n<td><code>'total'</code></td>\n</tr>\n<tr>\n<td><code>relative</code></td>\n<td>Use relative, rather than absolute frequencies with <code>True</code>. You can also pass in Series, DataFrame or buzz objects to calculate relative frequencies against the passed in data.</td>\n<td><code>False</code></td>\n</tr>\n<tr>\n<td><code>remove_above_p</code></td>\n<td>Sorting by increase/decrease/static/turbulent calculates the slope of the frequencies across each subcorpus, and p-values where the null hypothesis is no slope. If you pass in a float, entries with p-values above this float are dropped from the results. Passing in <code>True</code> will use <code>0.05</code>.</td>\n<td><code>False</code></td>\n</tr>\n<tr>\n<td><code>keep_stats</code></td>\n<td>If True, keep generated statistics related to the trajectory calculation</td>\n<td><code>False</code></td>\n</tr>\n<tr>\n<td><code>preserve_case</code></td>\n<td>Keep the original case for <code>show</code> (column) values</td>\n<td><code>False</code></td>\n</tr>\n<tr>\n<td><code>multiindex_columns</code></td>\n<td>When <code>show</code> is a list with multiple features, rather than joining <code>show</code> with slashes, build a multiindex</td>\n<td><code>False</code></td>\n</tr></tbody></table>\n<p>This creates a <code>Table</code> object, which is also based on DataFrame. You can use its <code>.view()</code> method to quickly explore results. Pressing enter on a given frequency will bring up a concordance of instances of this entry.</p>\n<h3>Plotting</h3>\n<p>You can also use <em>buzz</em> to create high-quality visualisations of frequency data. This relies completely on <a href=\"https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html\" rel=\"nofollow\">pandas' plotting method</a>. A <code>plot</code> method more tailored to language datasets is still in development.</p>\n<pre><span class=\"n\">tab</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">)</span>\n</pre>\n<h2>Contributing</h2>\n<p>If you find bugs, feel free to create an issue. The project is open-source, so pull requests are also welcome. Code style is <a href=\"https://github.com/psf/black\" rel=\"nofollow\"><code>black</code></a>, and versioning is handled by <a href=\"https://github.com/c4urself/bump2version\" rel=\"nofollow\"><code>bump2version</code></a>.</p>\n\n          </div>"}, "last_serial": 7176206, "releases": {"1.0.2": [{"comment_text": "", "digests": {"md5": "6956a68e5e881b25d72489a6d87981f8", "sha256": "fceda3efcaed0e3a720e2587a760f923a61452e30f055f88bea0d5089fabb453"}, "downloads": -1, "filename": "buzz-1.0.2-py3.6.egg", "has_sig": false, "md5_digest": "6956a68e5e881b25d72489a6d87981f8", "packagetype": "bdist_egg", "python_version": "3.6", "requires_python": null, "size": 770657, "upload_time": "2019-01-06T21:55:34", "upload_time_iso_8601": "2019-01-06T21:55:34.691944Z", "url": "https://files.pythonhosted.org/packages/47/8c/55574de04e7ced451a607cd8a7f1aa356740f075d19b6079aab1b38fcd6d/buzz-1.0.2-py3.6.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "9b84e26037162f38f791b1ad07126044", "sha256": "3011634b23724c77b071f51a144692bcfc475195b153386c5558a2c11beb1ee2"}, "downloads": -1, "filename": "buzz-1.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "9b84e26037162f38f791b1ad07126044", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 676897, "upload_time": "2018-12-30T23:00:26", "upload_time_iso_8601": "2018-12-30T23:00:26.818041Z", "url": "https://files.pythonhosted.org/packages/a4/b7/5122cf65426438a1118a6ed02253cc781b187a4136a7e13bc38c63354274/buzz-1.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "911ca72df0cda92ef10061125ccd0838", "sha256": "4d4e7c17265f321c2d439b4a36c96586710a8c53207a2477ee62a42381f41c60"}, "downloads": -1, "filename": "buzz-1.0.2.tar.gz", "has_sig": false, "md5_digest": "911ca72df0cda92ef10061125ccd0838", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 31984, "upload_time": "2018-12-30T23:00:29", "upload_time_iso_8601": "2018-12-30T23:00:29.134908Z", "url": "https://files.pythonhosted.org/packages/91/2e/1ddae01e591095671b616bd23710c01ecc5df4156f1106fc6fa3685b6038/buzz-1.0.2.tar.gz", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "8ee627edc47e4e951840dfedbd9d020a", "sha256": "04394fb255e73685f5a4aa19aed996b11dea3f44c47c052f18b3133098e0e948"}, "downloads": -1, "filename": "buzz-1.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "8ee627edc47e4e951840dfedbd9d020a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 340452, "upload_time": "2019-01-06T21:55:32", "upload_time_iso_8601": "2019-01-06T21:55:32.717675Z", "url": "https://files.pythonhosted.org/packages/1a/10/5c59acef918ac16cca2370ecee5159e9ab019877c14f7d100e1eb54d9d9a/buzz-1.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e12a6fa6df6335b08a1b13c06dd318f6", "sha256": "e7b564d02b7c9d6ca21930cdd9fdf397569af87e30a86362ba4831c08d21a0a8"}, "downloads": -1, "filename": "buzz-1.0.3.tar.gz", "has_sig": false, "md5_digest": "e12a6fa6df6335b08a1b13c06dd318f6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 32437, "upload_time": "2019-01-06T21:56:14", "upload_time_iso_8601": "2019-01-06T21:56:14.711175Z", "url": "https://files.pythonhosted.org/packages/40/92/6b210e7fe03067f3e23e837c83be594c3ad862d3a24fbd06881c243e3d96/buzz-1.0.3.tar.gz", "yanked": false}], "2.0.2": [{"comment_text": "", "digests": {"md5": "4c129addb00470621665b162d8cee269", "sha256": "a1a2e218bb11472a1b68fabc2447ab932d3b1ee4e56372efd889da52ad1c8176"}, "downloads": -1, "filename": "buzz-2.0.2-py3.7.egg", "has_sig": false, "md5_digest": "4c129addb00470621665b162d8cee269", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 71509, "upload_time": "2019-07-03T13:18:08", "upload_time_iso_8601": "2019-07-03T13:18:08.121032Z", "url": "https://files.pythonhosted.org/packages/a2/3c/c65ee5e836c3754959bfa862dbad68a2b65a3346a9151a937023f3119b38/buzz-2.0.2-py3.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "576bcf82aeea300464b6e2a44a8611a4", "sha256": "56dd20b25d3555ff58f0d85e0d944d4357b3332fcf774782a61ffbff1ab96e9a"}, "downloads": -1, "filename": "buzz-2.0.2.tar.gz", "has_sig": false, "md5_digest": "576bcf82aeea300464b6e2a44a8611a4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 32700, "upload_time": "2019-07-03T13:18:10", "upload_time_iso_8601": "2019-07-03T13:18:10.090938Z", "url": "https://files.pythonhosted.org/packages/56/bc/b9218f805b050206618911c9da05c3d0ce57ed66f4c5573718419edb36a3/buzz-2.0.2.tar.gz", "yanked": false}], "2.0.3": [{"comment_text": "", "digests": {"md5": "e07f5400eb04afa7420361bf8cfe82c6", "sha256": "61b2abe823e58acace29d89bddbb9c90f8cd3eaa5ad8031e711b0fdbfad80b68"}, "downloads": -1, "filename": "buzz-2.0.3-py3.7.egg", "has_sig": false, "md5_digest": "e07f5400eb04afa7420361bf8cfe82c6", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 72260, "upload_time": "2019-07-03T15:49:11", "upload_time_iso_8601": "2019-07-03T15:49:11.524897Z", "url": "https://files.pythonhosted.org/packages/3d/8f/0ce9ba32878d6cd6b9afa0667090105850b9ebbf1e408247c3e09bf02133/buzz-2.0.3-py3.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "4e6dc357b0d491a649ac231b42aa59f2", "sha256": "af27862ca1df0b7b6581a42b53ba554e45ed790e4644d977d9ceaa1881f49f24"}, "downloads": -1, "filename": "buzz-2.0.3.tar.gz", "has_sig": false, "md5_digest": "4e6dc357b0d491a649ac231b42aa59f2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 33092, "upload_time": "2019-07-03T15:49:13", "upload_time_iso_8601": "2019-07-03T15:49:13.530319Z", "url": "https://files.pythonhosted.org/packages/13/65/759ae4a87973f6ac9222557c39c1cbb879c9340721524eecc384ce396932/buzz-2.0.3.tar.gz", "yanked": false}], "2.0.5": [{"comment_text": "", "digests": {"md5": "836413de71e0a807af8164ac6d9b08dc", "sha256": "93ff2e7c9beca0780de5bc355c88e640578757933add2c1de7628cbcfa42cd26"}, "downloads": -1, "filename": "buzz-2.0.5-py3.7.egg", "has_sig": false, "md5_digest": "836413de71e0a807af8164ac6d9b08dc", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 72208, "upload_time": "2019-07-03T15:59:42", "upload_time_iso_8601": "2019-07-03T15:59:42.802973Z", "url": "https://files.pythonhosted.org/packages/3b/b6/ed4e2adf714a5c16aa96c3ca90ba292e348e11fc4d91cff5f25d1b0c515d/buzz-2.0.5-py3.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "15d659c66c640933bd23adeb0a039b2b", "sha256": "8b672561334c64009111d9577094a16b79cb1525f391f025387279e2a1bd989a"}, "downloads": -1, "filename": "buzz-2.0.5.tar.gz", "has_sig": false, "md5_digest": "15d659c66c640933bd23adeb0a039b2b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 33091, "upload_time": "2019-07-03T15:59:44", "upload_time_iso_8601": "2019-07-03T15:59:44.723185Z", "url": "https://files.pythonhosted.org/packages/a7/fe/4df3b4ec363d571038d6ad853cc423bd777078d1ba9157d5851e2dc12a02/buzz-2.0.5.tar.gz", "yanked": false}], "3.0.0": [{"comment_text": "", "digests": {"md5": "27873379c0a0618c33d02cec9f122274", "sha256": "d58a42387bf60b955eb166218959e792da1e0ad9ba12378b46eb7753877da44f"}, "downloads": -1, "filename": "buzz-3.0.0-py3.7.egg", "has_sig": false, "md5_digest": "27873379c0a0618c33d02cec9f122274", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 86257, "upload_time": "2019-08-17T14:46:45", "upload_time_iso_8601": "2019-08-17T14:46:45.367751Z", "url": "https://files.pythonhosted.org/packages/3d/ef/1bca66cf626c0c3840a4515d1b08c97a958802056729682cb8390f91351e/buzz-3.0.0-py3.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "8c5d02f5fe13aeffc95c2b9fe5be0353", "sha256": "b381c5f42eacfd54b67cf952c79c9cde9c730e976e8e9dd120611c6b22922051"}, "downloads": -1, "filename": "buzz-3.0.0.tar.gz", "has_sig": false, "md5_digest": "8c5d02f5fe13aeffc95c2b9fe5be0353", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 40064, "upload_time": "2019-08-17T14:46:47", "upload_time_iso_8601": "2019-08-17T14:46:47.649862Z", "url": "https://files.pythonhosted.org/packages/89/fb/8509700ef8ea7a36b8e8c4186510e53b4573fed6b1bfa9e8780728a16c09/buzz-3.0.0.tar.gz", "yanked": false}], "3.0.1": [{"comment_text": "", "digests": {"md5": "29154dec4b59718d1aac864f9eca3940", "sha256": "279626fd96d8e5d513a173f146539f4a9614f2ae84c977bea4f92315b91b1656"}, "downloads": -1, "filename": "buzz-3.0.1-py3.7.egg", "has_sig": false, "md5_digest": "29154dec4b59718d1aac864f9eca3940", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 86262, "upload_time": "2019-08-17T16:09:22", "upload_time_iso_8601": "2019-08-17T16:09:22.718084Z", "url": "https://files.pythonhosted.org/packages/97/ca/da86cd0e4fb39fffc02837b6b9b4462688dca8cc4f0cc4d0429af531cc01/buzz-3.0.1-py3.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "b5b2589691aa741f5841d83aa0a31673", "sha256": "b42ec1cc5d7e7a0be42330f2b39b522ed3015e0ebbd2ee612e41c25e4fe2dfeb"}, "downloads": -1, "filename": "buzz-3.0.1.tar.gz", "has_sig": false, "md5_digest": "b5b2589691aa741f5841d83aa0a31673", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 40079, "upload_time": "2019-08-17T16:09:24", "upload_time_iso_8601": "2019-08-17T16:09:24.569482Z", "url": "https://files.pythonhosted.org/packages/2d/f3/986b36b89538fee7e89aed15a3ce372ee4ea4621984c22a69bae69cffe5c/buzz-3.0.1.tar.gz", "yanked": false}], "3.0.10": [{"comment_text": "", "digests": {"md5": "61611dcf749a55365f0b23a77e51289f", "sha256": "7d773b9dd254d131e2d92c3e0d68dd9f4d0e45e55403c73b530bfc10c8da36a1"}, "downloads": -1, "filename": "buzz-3.0.10-py3.7.egg", "has_sig": false, "md5_digest": "61611dcf749a55365f0b23a77e51289f", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 128719, "upload_time": "2019-08-25T20:22:24", "upload_time_iso_8601": "2019-08-25T20:22:24.224656Z", "url": "https://files.pythonhosted.org/packages/eb/9c/1b1bfe688a8a0568941ba7c39c8b50e8161ddf26bba6588b57d42ffdf2fa/buzz-3.0.10-py3.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "44cbd12c95e2486a558990e880362a5f", "sha256": "bb15153e3dd8cfd1e6b95be53a93a0064b92c9bb534385fab392290766d34667"}, "downloads": -1, "filename": "buzz-3.0.10.tar.gz", "has_sig": false, "md5_digest": "44cbd12c95e2486a558990e880362a5f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 56450, "upload_time": "2019-08-25T20:22:26", "upload_time_iso_8601": "2019-08-25T20:22:26.890309Z", "url": "https://files.pythonhosted.org/packages/24/6b/e4cd6f0bfc44de75177a56043dc2b1c9b3300c9ba2324c904c7117e0b778/buzz-3.0.10.tar.gz", "yanked": false}], "3.0.2": [{"comment_text": "", "digests": {"md5": "e1307198b950cd107c1a7db4957a9ece", "sha256": "fae9014dd88b6a0855279c451b6a438be8045136a5fc2b9210735dd390904cf9"}, "downloads": -1, "filename": "buzz-3.0.2-py3.7.egg", "has_sig": false, "md5_digest": "e1307198b950cd107c1a7db4957a9ece", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 121114, "upload_time": "2019-08-17T17:16:20", "upload_time_iso_8601": "2019-08-17T17:16:20.335807Z", "url": "https://files.pythonhosted.org/packages/90/6a/f02fc6fdb99010c36324ef71abbc5c0ff096ecd8e152d1d1bcc81991cbf3/buzz-3.0.2-py3.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "d271e79f4b498ca04dd54bea8b315fd1", "sha256": "800cd100b9297c8814326d51c9b2e9f40a482aa5bfeb18c617bc3ddd7b6044c8"}, "downloads": -1, "filename": "buzz-3.0.2.tar.gz", "has_sig": false, "md5_digest": "d271e79f4b498ca04dd54bea8b315fd1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 53775, "upload_time": "2019-08-17T17:16:23", "upload_time_iso_8601": "2019-08-17T17:16:23.302340Z", "url": "https://files.pythonhosted.org/packages/df/76/fede2814aceaca774dd2a948ac34d4f8f4d3ddecd382ecb5d20713c9c6f0/buzz-3.0.2.tar.gz", "yanked": false}], "3.0.3": [{"comment_text": "", "digests": {"md5": "091a977516f10e5af1629e1dffad2097", "sha256": "c94b243cae961f8252e3bba17841573354201e40ad5a1758823e94d86e013aaf"}, "downloads": -1, "filename": "buzz-3.0.3-py3.7.egg", "has_sig": false, "md5_digest": "091a977516f10e5af1629e1dffad2097", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 121143, "upload_time": "2019-08-17T22:12:37", "upload_time_iso_8601": "2019-08-17T22:12:37.053134Z", "url": "https://files.pythonhosted.org/packages/cc/9e/1018de2efc9183f38dffa5822e7d1d41e0c2cc5780974c608c5e4a09ae80/buzz-3.0.3-py3.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "7baa0e3d8596dc81b466d44af2cdf387", "sha256": "40db197fb03a9942787cb24831f70166fe444efbe28dc6ecf356e3745c6bbe9b"}, "downloads": -1, "filename": "buzz-3.0.3.tar.gz", "has_sig": false, "md5_digest": "7baa0e3d8596dc81b466d44af2cdf387", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 53802, "upload_time": "2019-08-17T22:12:39", "upload_time_iso_8601": "2019-08-17T22:12:39.440819Z", "url": "https://files.pythonhosted.org/packages/c9/1c/b7ec4c27ba0d6c9111531142956db0d1a38049d4c8d7ac48afb470783ea0/buzz-3.0.3.tar.gz", "yanked": false}], "3.0.4": [{"comment_text": "", "digests": {"md5": "6984d7440aae3837b1d206d36e66fcb8", "sha256": "cd075415512d3bb84c67d3545342eeb51f867c87195bc88a7cdf1d4cab6d929b"}, "downloads": -1, "filename": "buzz-3.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "6984d7440aae3837b1d206d36e66fcb8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 54382, "upload_time": "2019-08-19T16:44:38", "upload_time_iso_8601": "2019-08-19T16:44:38.002348Z", "url": "https://files.pythonhosted.org/packages/2a/d1/a553c058289bcfc20a03219e738ceb093c39ceb2d05ced2279b9cf9a0205/buzz-3.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4f707ced3dd7ca99c2ba6f7fd412d961", "sha256": "e7d932cfdbc27effafe175666d99b5f638e7e110a9573304a87c4411da1a751e"}, "downloads": -1, "filename": "buzz-3.0.4.tar.gz", "has_sig": false, "md5_digest": "4f707ced3dd7ca99c2ba6f7fd412d961", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 54305, "upload_time": "2019-08-19T16:44:40", "upload_time_iso_8601": "2019-08-19T16:44:40.014175Z", "url": "https://files.pythonhosted.org/packages/9e/44/39a12a413c2607bdba2a42ef1b79aaba7f4c1bd318e7cea65777cf70ea01/buzz-3.0.4.tar.gz", "yanked": false}], "3.0.5": [{"comment_text": "", "digests": {"md5": "c2770d733bf5b00cecda3ed4234671df", "sha256": "1307586dc467ac4075d1ac171e8a8dbef4c4f3dcabfeefcb1e7b4dba280582a0"}, "downloads": -1, "filename": "buzz-3.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "c2770d733bf5b00cecda3ed4234671df", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 54815, "upload_time": "2019-08-20T09:05:25", "upload_time_iso_8601": "2019-08-20T09:05:25.603747Z", "url": "https://files.pythonhosted.org/packages/f6/89/8d659386063e221e4bcc386d872176172d6302d2809dea601c7cc7fa8f50/buzz-3.0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "80513b789aa7548b510191a819fba6d4", "sha256": "1cd0da268f9aeac04bfc4aa6e7cfcb72b80179f606497ba97402025438bfdbaa"}, "downloads": -1, "filename": "buzz-3.0.5.tar.gz", "has_sig": false, "md5_digest": "80513b789aa7548b510191a819fba6d4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 54733, "upload_time": "2019-08-20T09:05:27", "upload_time_iso_8601": "2019-08-20T09:05:27.341258Z", "url": "https://files.pythonhosted.org/packages/91/96/98876dab74342b426af2b7fa4bac268eeb3f56749d61453b58a256a6bd99/buzz-3.0.5.tar.gz", "yanked": false}], "3.0.6": [{"comment_text": "", "digests": {"md5": "d2e7f915e1205ea776d57e6687a1030e", "sha256": "fca00dcc9e6f6a55416018af2cbfc4c405a8481107426f24f88d58cc28cede7c"}, "downloads": -1, "filename": "buzz-3.0.6-py3-none-any.whl", "has_sig": false, "md5_digest": "d2e7f915e1205ea776d57e6687a1030e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 54977, "upload_time": "2019-08-21T13:45:24", "upload_time_iso_8601": "2019-08-21T13:45:24.896180Z", "url": "https://files.pythonhosted.org/packages/80/0f/77f2c3ea6132e189a41010e0559de7854ac9044ec2eeb298c4597b8e6be1/buzz-3.0.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "06087b4c67090a561c4232a6e5c804ce", "sha256": "7d0ea13654472fd9da1d1c00be51846f45a38ed8cfd474c4abb99c1bd7ff3928"}, "downloads": -1, "filename": "buzz-3.0.6.tar.gz", "has_sig": false, "md5_digest": "06087b4c67090a561c4232a6e5c804ce", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 54868, "upload_time": "2019-08-21T13:45:27", "upload_time_iso_8601": "2019-08-21T13:45:27.074783Z", "url": "https://files.pythonhosted.org/packages/47/86/e9d0741254e40b64abd1616525b3fda0eb313c7203909a156e0a94612a4d/buzz-3.0.6.tar.gz", "yanked": false}], "3.0.8": [{"comment_text": "", "digests": {"md5": "7c338a187459451bd7c3abf0794da315", "sha256": "26b1ea9802afef25e6ce09c0c4475d1f60ca03d0e5d8d829907abf19fe64c5a6"}, "downloads": -1, "filename": "buzz-3.0.8-py3.7.egg", "has_sig": false, "md5_digest": "7c338a187459451bd7c3abf0794da315", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 126118, "upload_time": "2019-08-24T21:34:14", "upload_time_iso_8601": "2019-08-24T21:34:14.705534Z", "url": "https://files.pythonhosted.org/packages/be/44/87b22069d2eb59b061aa68b024ef85919070149ed38dc2f7b4ddd0305c97/buzz-3.0.8-py3.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "94f82b9e0064a1625d011ec23dba24f0", "sha256": "c6c150dc719159836e1151501cc11a70f3f926ebcd128a4fdf44717b1f2dbba5"}, "downloads": -1, "filename": "buzz-3.0.8.tar.gz", "has_sig": false, "md5_digest": "94f82b9e0064a1625d011ec23dba24f0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 55388, "upload_time": "2019-08-24T21:34:16", "upload_time_iso_8601": "2019-08-24T21:34:16.974623Z", "url": "https://files.pythonhosted.org/packages/e0/fc/26c69009a99edcca73a63078e0d894c66985f025eb6d21fb21b0b07bc2c6/buzz-3.0.8.tar.gz", "yanked": false}], "3.0.9": [{"comment_text": "", "digests": {"md5": "9c289e8b2f16c1eea9f843f4719c1768", "sha256": "de7eea34206e979ba9bbe9f58a5664dca5541d69f24e806c0b284affca2e1a9a"}, "downloads": -1, "filename": "buzz-3.0.9-py3.7.egg", "has_sig": false, "md5_digest": "9c289e8b2f16c1eea9f843f4719c1768", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 128714, "upload_time": "2019-08-25T20:20:30", "upload_time_iso_8601": "2019-08-25T20:20:30.155886Z", "url": "https://files.pythonhosted.org/packages/0b/3c/ccd012aa2505e1a1d4bd497f8d3ea11e91227de17c64456895fb783139e7/buzz-3.0.9-py3.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "a450b41c19aebec5102ba9d51d53d857", "sha256": "0b3f5e650e9cfbeb4a03708dfaa8b26416e02e882c141418867784a5cf428e65"}, "downloads": -1, "filename": "buzz-3.0.9.tar.gz", "has_sig": false, "md5_digest": "a450b41c19aebec5102ba9d51d53d857", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 56450, "upload_time": "2019-08-25T20:20:32", "upload_time_iso_8601": "2019-08-25T20:20:32.731695Z", "url": "https://files.pythonhosted.org/packages/fb/f1/a818b45e9a384278935f1aadbcd16b3bbab5d066ab83866ff490838b0d45/buzz-3.0.9.tar.gz", "yanked": false}], "3.1.0": [{"comment_text": "", "digests": {"md5": "256e7ec7486678df169bdc9882503b15", "sha256": "453768aade79b53e968b4cd4abac2329903c8db94d6ff37cd87a63c09ef27e96"}, "downloads": -1, "filename": "buzz-3.1.0-py3.7.egg", "has_sig": false, "md5_digest": "256e7ec7486678df169bdc9882503b15", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 129978, "upload_time": "2019-09-06T12:49:11", "upload_time_iso_8601": "2019-09-06T12:49:11.490577Z", "url": "https://files.pythonhosted.org/packages/a4/50/fd45e0f11fa29685df1570993414a5d6b3eb520f8fb015e1e0700ad29652/buzz-3.1.0-py3.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "80192fbc7ba1e97da2fed7ad39d36de0", "sha256": "605c7b82f531c3690df08a35597cb527a412c2a3539fd505cf3be28e46eb4c92"}, "downloads": -1, "filename": "buzz-3.1.0.tar.gz", "has_sig": false, "md5_digest": "80192fbc7ba1e97da2fed7ad39d36de0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 57074, "upload_time": "2019-09-06T12:49:14", "upload_time_iso_8601": "2019-09-06T12:49:14.234094Z", "url": "https://files.pythonhosted.org/packages/6a/04/f0f0acc8cdc3e2b1982fd24d24ec7711cee302b87e4d83895af6b5b4bf4c/buzz-3.1.0.tar.gz", "yanked": false}], "3.1.1": [{"comment_text": "", "digests": {"md5": "75073f0d9d0942ecc379a777696d6259", "sha256": "7a7882bf965925844eb004c6f7f4571375148afa4aaacf316d9f4ae8ef69e851"}, "downloads": -1, "filename": "buzz-3.1.1-py3.7.egg", "has_sig": false, "md5_digest": "75073f0d9d0942ecc379a777696d6259", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 144215, "upload_time": "2020-05-03T18:23:32", "upload_time_iso_8601": "2020-05-03T18:23:32.863279Z", "url": "https://files.pythonhosted.org/packages/24/5f/4d32632458df40c243cafc232ebdd6e89e414c3570859ab88d2e91823e10/buzz-3.1.1-py3.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "345f21fd316424eaa5d4d55cf9aebdf9", "sha256": "a473a5dfe6bc2db683d788e41ca810c8b7c3dd6416727b4959acfe1cd9378582"}, "downloads": -1, "filename": "buzz-3.1.1.tar.gz", "has_sig": false, "md5_digest": "345f21fd316424eaa5d4d55cf9aebdf9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 62930, "upload_time": "2020-05-03T18:23:34", "upload_time_iso_8601": "2020-05-03T18:23:34.716068Z", "url": "https://files.pythonhosted.org/packages/16/c0/3b3c8afb0d1ad40c6a43c8f3cc002bb8566dc24d3d91dfced4364af353e2/buzz-3.1.1.tar.gz", "yanked": false}], "3.1.2": [{"comment_text": "", "digests": {"md5": "2989e246fff963e068975e4d4135e972", "sha256": "0071f00e75defc01f2d0a89db027e39e7aa28d58fa24dba3e413d63289897e0f"}, "downloads": -1, "filename": "buzz-3.1.2-py3.7.egg", "has_sig": false, "md5_digest": "2989e246fff963e068975e4d4135e972", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 145106, "upload_time": "2020-05-05T16:53:49", "upload_time_iso_8601": "2020-05-05T16:53:49.592634Z", "url": "https://files.pythonhosted.org/packages/3f/fc/b3aefe376e236da58ad74c9d72ced067a902ae25ecccecd1c2f70a35a41c/buzz-3.1.2-py3.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "9fd29cb056456f36df86884fea78b1c7", "sha256": "e5d23d426e37ef2d13f52ba8764db256b4bd45583d4ccc0cb3e22879910cc7b9"}, "downloads": -1, "filename": "buzz-3.1.2.tar.gz", "has_sig": false, "md5_digest": "9fd29cb056456f36df86884fea78b1c7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 63322, "upload_time": "2020-05-05T16:53:51", "upload_time_iso_8601": "2020-05-05T16:53:51.509600Z", "url": "https://files.pythonhosted.org/packages/4c/2d/b8fb7742fcd2d2f8a7663568242238c6e7885aa39d10cab1a0f06b141d71/buzz-3.1.2.tar.gz", "yanked": false}], "3.1.3": [{"comment_text": "", "digests": {"md5": "d92b36c8b2d403a0c3414c376d1ce711", "sha256": "4f5d98850f0c4a6b8cf4965d11eaba08feef135e5f4641124eeabf44a58668bc"}, "downloads": -1, "filename": "buzz-3.1.3-py3.7.egg", "has_sig": false, "md5_digest": "d92b36c8b2d403a0c3414c376d1ce711", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 145024, "upload_time": "2020-05-05T21:11:13", "upload_time_iso_8601": "2020-05-05T21:11:13.033474Z", "url": "https://files.pythonhosted.org/packages/98/d1/416081ec52c68105c0aa89539e7b95ff619643f422d4310f78fa1bd25471/buzz-3.1.3-py3.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "76ce9c5b52592353fba2ec18e469ffb2", "sha256": "9e180686d8c70e71cc80d63c0d2e82afb307b1b7e9b362d80e3b3766cd3b1c02"}, "downloads": -1, "filename": "buzz-3.1.3.tar.gz", "has_sig": false, "md5_digest": "76ce9c5b52592353fba2ec18e469ffb2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 63231, "upload_time": "2020-05-05T21:11:15", "upload_time_iso_8601": "2020-05-05T21:11:15.046147Z", "url": "https://files.pythonhosted.org/packages/b9/fd/def400d3140e37ec2611b75439a13101fcf5c8b20329b9272f70036ec3f8/buzz-3.1.3.tar.gz", "yanked": false}], "3.1.4": [{"comment_text": "", "digests": {"md5": "6ea7ff5d5d7952f34f28549402540183", "sha256": "286f19409c12c84834b9558b41a69cd206fd6a4cdaa30028faae16b6e68475bf"}, "downloads": -1, "filename": "buzz-3.1.4-py3.7.egg", "has_sig": false, "md5_digest": "6ea7ff5d5d7952f34f28549402540183", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 144948, "upload_time": "2020-05-05T22:08:21", "upload_time_iso_8601": "2020-05-05T22:08:21.516712Z", "url": "https://files.pythonhosted.org/packages/6b/4e/0eecad290f544167f40ca016c1a6c04928e71dfd15a0074927f0eecdb17c/buzz-3.1.4-py3.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "e8eed74adebef43a1fed55d7237582e3", "sha256": "0f499168f60e83131f10fed921ecb3c3ad19ca4fb2c60efe17c6771ae41b892d"}, "downloads": -1, "filename": "buzz-3.1.4.tar.gz", "has_sig": false, "md5_digest": "e8eed74adebef43a1fed55d7237582e3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 63229, "upload_time": "2020-05-05T22:08:23", "upload_time_iso_8601": "2020-05-05T22:08:23.151192Z", "url": "https://files.pythonhosted.org/packages/39/9e/18b88c7e936090dd4e48cadebfa6be4c963b44454932c3605c15d416cff4/buzz-3.1.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "6ea7ff5d5d7952f34f28549402540183", "sha256": "286f19409c12c84834b9558b41a69cd206fd6a4cdaa30028faae16b6e68475bf"}, "downloads": -1, "filename": "buzz-3.1.4-py3.7.egg", "has_sig": false, "md5_digest": "6ea7ff5d5d7952f34f28549402540183", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 144948, "upload_time": "2020-05-05T22:08:21", "upload_time_iso_8601": "2020-05-05T22:08:21.516712Z", "url": "https://files.pythonhosted.org/packages/6b/4e/0eecad290f544167f40ca016c1a6c04928e71dfd15a0074927f0eecdb17c/buzz-3.1.4-py3.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "e8eed74adebef43a1fed55d7237582e3", "sha256": "0f499168f60e83131f10fed921ecb3c3ad19ca4fb2c60efe17c6771ae41b892d"}, "downloads": -1, "filename": "buzz-3.1.4.tar.gz", "has_sig": false, "md5_digest": "e8eed74adebef43a1fed55d7237582e3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 63229, "upload_time": "2020-05-05T22:08:23", "upload_time_iso_8601": "2020-05-05T22:08:23.151192Z", "url": "https://files.pythonhosted.org/packages/39/9e/18b88c7e936090dd4e48cadebfa6be4c963b44454932c3605c15d416cff4/buzz-3.1.4.tar.gz", "yanked": false}], "timestamp": "Thu May  7 22:35:54 2020"}