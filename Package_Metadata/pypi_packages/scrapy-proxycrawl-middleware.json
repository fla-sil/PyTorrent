{"info": {"author": "ProxyCrawl", "author_email": "info@proxycrawl.com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Intended Audience :: Developers", "License :: OSI Approved :: Apache Software License", "Operating System :: OS Independent", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Topic :: Utilities"], "description": "# ProxyCrawl API middleware for Scrapy\n\nProcesses [Scrapy](http://scrapy.org/) requests using [ProxyCrawl](https://proxycrawl.com) services either with Normal or Javascript tokens\n\n\n## Installing\n\nChoose a way of installing:\n\n- Clone the repository inside your Scrapy project and run the following:\n```bash\npython setup.py install\n```\n- Or use [PyPi](https://pypi.org/project/scrapy-proxycrawl-middleware/) Python package manager. `pip install scrapy-proxycrawl-middleware`\n\nThen in your Scrapy `settings.py` add the following lines:\n\n```python\n# Activate the middleware\nPROXYCRAWL_ENABLED = True\n\n# The ProxyCrawl API token you wish to use, either normal of javascript token\nPROXYCRAWL_TOKEN = 'your token'\n\n# Enable the middleware\nDOWNLOADER_MIDDLEWARES = {\n    'scrapy_proxycrawl.ProxyCrawlMiddleware': 610\n}\n```\n## Usage\n\nUse the scrapy_proxycrawl.ProxyCrawlRequest instead of the scrapy built-in Request.\nThe scrapy_proxycrawl.ProxyCrawlRequest accepts additional arguments, used in Proxy Crawl API:\n\n```python\nfrom scrapy_proxycrawl import ProxyCrawlRequest\n\nyield ProxyCrawlRequest(\n    \"http://target-url\",\n    callback=self.parse_result\n    device='desktop',\n    country='US',\n    page_wait=1000,\n    ajax_wait=True,\n    dont_filter=True\n)\n```\n\nThe target url will be replaced with proxy crawl url and parameters will be encoded into the url by the middleware automatically.\n\n\nIf you have questions or need help using the library, please open an issue or [contact us](https://proxycrawl.com/contact).\n\n---\n\nCopyright 2020 ProxyCrawl\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/proxycrawl/scrapy-proxycrawl-middleware", "keywords": "scrapy middleware scraping scraper crawler crawling proxycrawl api", "license": "Apache-2.0", "maintainer": "", "maintainer_email": "", "name": "scrapy-proxycrawl-middleware", "package_url": "https://pypi.org/project/scrapy-proxycrawl-middleware/", "platform": "", "project_url": "https://pypi.org/project/scrapy-proxycrawl-middleware/", "project_urls": {"Homepage": "https://github.com/proxycrawl/scrapy-proxycrawl-middleware"}, "release_url": "https://pypi.org/project/scrapy-proxycrawl-middleware/1.1.0/", "requires_dist": null, "requires_python": "", "summary": "Scrapy ProxyCrawl Proxy Middleware: ProxyCrawl interfacing middleware for Scrapy", "version": "1.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>ProxyCrawl API middleware for Scrapy</h1>\n<p>Processes <a href=\"http://scrapy.org/\" rel=\"nofollow\">Scrapy</a> requests using <a href=\"https://proxycrawl.com\" rel=\"nofollow\">ProxyCrawl</a> services either with Normal or Javascript tokens</p>\n<h2>Installing</h2>\n<p>Choose a way of installing:</p>\n<ul>\n<li>Clone the repository inside your Scrapy project and run the following:</li>\n</ul>\n<pre>python setup.py install\n</pre>\n<ul>\n<li>Or use <a href=\"https://pypi.org/project/scrapy-proxycrawl-middleware/\" rel=\"nofollow\">PyPi</a> Python package manager. <code>pip install scrapy-proxycrawl-middleware</code></li>\n</ul>\n<p>Then in your Scrapy <code>settings.py</code> add the following lines:</p>\n<pre><span class=\"c1\"># Activate the middleware</span>\n<span class=\"n\">PROXYCRAWL_ENABLED</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n\n<span class=\"c1\"># The ProxyCrawl API token you wish to use, either normal of javascript token</span>\n<span class=\"n\">PROXYCRAWL_TOKEN</span> <span class=\"o\">=</span> <span class=\"s1\">'your token'</span>\n\n<span class=\"c1\"># Enable the middleware</span>\n<span class=\"n\">DOWNLOADER_MIDDLEWARES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy_proxycrawl.ProxyCrawlMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">610</span>\n<span class=\"p\">}</span>\n</pre>\n<h2>Usage</h2>\n<p>Use the scrapy_proxycrawl.ProxyCrawlRequest instead of the scrapy built-in Request.\nThe scrapy_proxycrawl.ProxyCrawlRequest accepts additional arguments, used in Proxy Crawl API:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">scrapy_proxycrawl</span> <span class=\"kn\">import</span> <span class=\"n\">ProxyCrawlRequest</span>\n\n<span class=\"k\">yield</span> <span class=\"n\">ProxyCrawlRequest</span><span class=\"p\">(</span>\n    <span class=\"s2\">\"http://target-url\"</span><span class=\"p\">,</span>\n    <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_result</span>\n    <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">'desktop'</span><span class=\"p\">,</span>\n    <span class=\"n\">country</span><span class=\"o\">=</span><span class=\"s1\">'US'</span><span class=\"p\">,</span>\n    <span class=\"n\">page_wait</span><span class=\"o\">=</span><span class=\"mi\">1000</span><span class=\"p\">,</span>\n    <span class=\"n\">ajax_wait</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n    <span class=\"n\">dont_filter</span><span class=\"o\">=</span><span class=\"kc\">True</span>\n<span class=\"p\">)</span>\n</pre>\n<p>The target url will be replaced with proxy crawl url and parameters will be encoded into the url by the middleware automatically.</p>\n<p>If you have questions or need help using the library, please open an issue or <a href=\"https://proxycrawl.com/contact\" rel=\"nofollow\">contact us</a>.</p>\n<hr>\n<p>Copyright 2020 ProxyCrawl</p>\n\n          </div>"}, "last_serial": 6530006, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "16ebb20b9b0b4a1ffd8403fdfcd44ecc", "sha256": "1b077adde12e8b4bd08ef59dd7780e5cb338a42e528907abc09e52130a8e86b6"}, "downloads": -1, "filename": "scrapy_proxycrawl_middleware-1.0.0-py2-none-any.whl", "has_sig": false, "md5_digest": "16ebb20b9b0b4a1ffd8403fdfcd44ecc", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 6989, "upload_time": "2019-02-04T16:35:35", "upload_time_iso_8601": "2019-02-04T16:35:35.368915Z", "url": "https://files.pythonhosted.org/packages/da/b1/6af1bad81fbf79740030e1c9aeca09bc77dbb78d6df2ea7fc5e6c5924298/scrapy_proxycrawl_middleware-1.0.0-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2111e5c3d14f954ae7df78b0477a56b3", "sha256": "7be25df425af806a43be7d0f6578234ab0b98ca6318854255053245257ccc046"}, "downloads": -1, "filename": "scrapy_proxycrawl_middleware-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "2111e5c3d14f954ae7df78b0477a56b3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6990, "upload_time": "2019-02-04T16:35:37", "upload_time_iso_8601": "2019-02-04T16:35:37.561909Z", "url": "https://files.pythonhosted.org/packages/e1/16/8b0a4ea8f6e750a6c94c4acd03000e43a39551596f6c79ba61ef3820ac23/scrapy_proxycrawl_middleware-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ce7b5946f83d28a67632ebac8cc2b55c", "sha256": "c3ce179cf0ca92d9db92029a2eeed645eb178f9e151af6f2e7142e67de2f18e2"}, "downloads": -1, "filename": "scrapy-proxycrawl-middleware-1.0.0.tar.gz", "has_sig": false, "md5_digest": "ce7b5946f83d28a67632ebac8cc2b55c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2192, "upload_time": "2019-02-04T16:35:39", "upload_time_iso_8601": "2019-02-04T16:35:39.026788Z", "url": "https://files.pythonhosted.org/packages/6f/64/241080f10be67bfc98285517f07d7e6b268e7709fb4938237fa3faeb80f0/scrapy-proxycrawl-middleware-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "f9b8d13869d201bcec105e4df641ffcf", "sha256": "a20dafdb92454641d7f59d4c49659a4084e4d5d754750cf4d997229adcbd553a"}, "downloads": -1, "filename": "scrapy_proxycrawl_middleware-1.0.1-py2-none-any.whl", "has_sig": false, "md5_digest": "f9b8d13869d201bcec105e4df641ffcf", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 7052, "upload_time": "2019-02-04T16:45:00", "upload_time_iso_8601": "2019-02-04T16:45:00.046851Z", "url": "https://files.pythonhosted.org/packages/e6/2d/cdf3319cca36519d2aa59eeee89bf34810bef2b56c9353a518046daadd44/scrapy_proxycrawl_middleware-1.0.1-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "906934e665da0cf831d406552aa9cbeb", "sha256": "8f4c81aeed66d78d0442a250af6cb028abf65c53b9b87916d9f4d925b73a5a25"}, "downloads": -1, "filename": "scrapy_proxycrawl_middleware-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "906934e665da0cf831d406552aa9cbeb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7055, "upload_time": "2019-02-04T16:45:01", "upload_time_iso_8601": "2019-02-04T16:45:01.274461Z", "url": "https://files.pythonhosted.org/packages/e8/a1/2d3b42d4724166f3064ab7e50f93954f01eba6c6596f3d3094534e3fb033/scrapy_proxycrawl_middleware-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0a5540c6afe562d14e9bcef5e0357fb5", "sha256": "27678659abd6c36dd143e2a7f0dfcb34067a29cae906fb310d5bf2ad39717819"}, "downloads": -1, "filename": "scrapy-proxycrawl-middleware-1.0.1.tar.gz", "has_sig": false, "md5_digest": "0a5540c6afe562d14e9bcef5e0357fb5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2264, "upload_time": "2019-02-04T16:45:03", "upload_time_iso_8601": "2019-02-04T16:45:03.426821Z", "url": "https://files.pythonhosted.org/packages/d2/84/7036219916d770c48341c919c3a86d2299c6dff6787333cdd0a9bf7df5f5/scrapy-proxycrawl-middleware-1.0.1.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "40b1abf4a98baa8e6a5be2628b5c63c9", "sha256": "b4295e648236ea06f770334d2446e026f5b3d41b796c3130d03f5ad1e82eeccb"}, "downloads": -1, "filename": "scrapy_proxycrawl_middleware-1.0.2-py2-none-any.whl", "has_sig": false, "md5_digest": "40b1abf4a98baa8e6a5be2628b5c63c9", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 7051, "upload_time": "2019-02-21T18:17:18", "upload_time_iso_8601": "2019-02-21T18:17:18.332805Z", "url": "https://files.pythonhosted.org/packages/ce/80/103ee6fa995f9827b1bc3cda98189c5956dceb3eb0719479bbb779b0f5cf/scrapy_proxycrawl_middleware-1.0.2-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f4351be29df8c38b331eec4eb8fbc50b", "sha256": "a7c9a9a8c57d48af2e413296415ed650856d57b6381ff81f6e6702c02df41723"}, "downloads": -1, "filename": "scrapy_proxycrawl_middleware-1.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "f4351be29df8c38b331eec4eb8fbc50b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7049, "upload_time": "2019-02-21T18:17:19", "upload_time_iso_8601": "2019-02-21T18:17:19.838784Z", "url": "https://files.pythonhosted.org/packages/39/44/1e0ca40d6b39e4157d32a3d160109e76d2e49b6bfd289179b0d32ceda4be/scrapy_proxycrawl_middleware-1.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f3ca4363320725b2af65a6f995805f47", "sha256": "164f01dc7af7a55fb033d1249e47474e96cef161e3675adb7e6af625e1c45860"}, "downloads": -1, "filename": "scrapy-proxycrawl-middleware-1.0.2.tar.gz", "has_sig": false, "md5_digest": "f3ca4363320725b2af65a6f995805f47", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2251, "upload_time": "2019-02-21T18:17:23", "upload_time_iso_8601": "2019-02-21T18:17:23.028987Z", "url": "https://files.pythonhosted.org/packages/94/d8/5fd6ba6a72909c74e4757bc241ab1fd81f092748aa3f7b4ad1274f51a4ad/scrapy-proxycrawl-middleware-1.0.2.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "ed37a55c15bd0d974e0c0e00ad73ef9b", "sha256": "1d1461044197456cab54b0e7d5cd0dbd38419710d6e657439510bc7810d9fb40"}, "downloads": -1, "filename": "scrapy_proxycrawl_middleware-1.1.0-py2-none-any.whl", "has_sig": false, "md5_digest": "ed37a55c15bd0d974e0c0e00ad73ef9b", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 10038, "upload_time": "2020-01-28T02:58:55", "upload_time_iso_8601": "2020-01-28T02:58:55.679323Z", "url": "https://files.pythonhosted.org/packages/1e/be/e0738f10157b8a391d0787bbc8ec37de404b92518d521a6582b503aab9c0/scrapy_proxycrawl_middleware-1.1.0-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f12902f7ca25b70f56bf806b7206dce5", "sha256": "22b3c6a7eaf5293c7464b1d8ced6cc0cfe968fa6c89984d926d4f884cafab481"}, "downloads": -1, "filename": "scrapy_proxycrawl_middleware-1.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "f12902f7ca25b70f56bf806b7206dce5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10039, "upload_time": "2020-01-28T02:58:57", "upload_time_iso_8601": "2020-01-28T02:58:57.038081Z", "url": "https://files.pythonhosted.org/packages/6e/1f/e8a0a931d4a1e8d2fc96ac78c88de3dcacc1a69f265feadc9d3cc934243f/scrapy_proxycrawl_middleware-1.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "05753f6af5ad138a262c58d8e6513486", "sha256": "156a8c61e4d881df3f382c28117567e4668c81378b73d92d76ef5efb7fd0e06f"}, "downloads": -1, "filename": "scrapy-proxycrawl-middleware-1.1.0.tar.gz", "has_sig": false, "md5_digest": "05753f6af5ad138a262c58d8e6513486", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4935, "upload_time": "2020-01-28T02:59:01", "upload_time_iso_8601": "2020-01-28T02:59:01.675934Z", "url": "https://files.pythonhosted.org/packages/8c/74/0b70ab4209a263a966035b5fab571d2f732bf85d32d5bf9c064370797917/scrapy-proxycrawl-middleware-1.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ed37a55c15bd0d974e0c0e00ad73ef9b", "sha256": "1d1461044197456cab54b0e7d5cd0dbd38419710d6e657439510bc7810d9fb40"}, "downloads": -1, "filename": "scrapy_proxycrawl_middleware-1.1.0-py2-none-any.whl", "has_sig": false, "md5_digest": "ed37a55c15bd0d974e0c0e00ad73ef9b", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 10038, "upload_time": "2020-01-28T02:58:55", "upload_time_iso_8601": "2020-01-28T02:58:55.679323Z", "url": "https://files.pythonhosted.org/packages/1e/be/e0738f10157b8a391d0787bbc8ec37de404b92518d521a6582b503aab9c0/scrapy_proxycrawl_middleware-1.1.0-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f12902f7ca25b70f56bf806b7206dce5", "sha256": "22b3c6a7eaf5293c7464b1d8ced6cc0cfe968fa6c89984d926d4f884cafab481"}, "downloads": -1, "filename": "scrapy_proxycrawl_middleware-1.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "f12902f7ca25b70f56bf806b7206dce5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10039, "upload_time": "2020-01-28T02:58:57", "upload_time_iso_8601": "2020-01-28T02:58:57.038081Z", "url": "https://files.pythonhosted.org/packages/6e/1f/e8a0a931d4a1e8d2fc96ac78c88de3dcacc1a69f265feadc9d3cc934243f/scrapy_proxycrawl_middleware-1.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "05753f6af5ad138a262c58d8e6513486", "sha256": "156a8c61e4d881df3f382c28117567e4668c81378b73d92d76ef5efb7fd0e06f"}, "downloads": -1, "filename": "scrapy-proxycrawl-middleware-1.1.0.tar.gz", "has_sig": false, "md5_digest": "05753f6af5ad138a262c58d8e6513486", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4935, "upload_time": "2020-01-28T02:59:01", "upload_time_iso_8601": "2020-01-28T02:59:01.675934Z", "url": "https://files.pythonhosted.org/packages/8c/74/0b70ab4209a263a966035b5fab571d2f732bf85d32d5bf9c064370797917/scrapy-proxycrawl-middleware-1.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:56:44 2020"}