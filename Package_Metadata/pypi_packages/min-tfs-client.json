{"info": {"author": "", "author_email": "", "bugtrack_url": null, "classifiers": [], "description": "# Minimal Tensor Serving Python Client\nA lightweight python client to communicate with Tensor Serving.\n\n## Description\nCommunicating with Tensorflow models via Tensor Serving requires [gRPC](https://grpc.io/) and Tensorflow-specific protobufs. The `tensorflow-serving-apis` package on PyPI provides these interfaces, but requires `tensorflow` as a dependency. The Tensorflow python package currently stands at 700 Mb, with much of this space dedicated to libraries and executables required for training, saving, and visualising Tensorflow Models; these libraries are not required at inference time when communicating with Tensorflow Serving.\n\nThis package exposes a minimal Tensor Serving client that does not include Tensorflow as a dependency. This reduces the overall package size to < 1 Mb. This is particularly useful when deploying web services via AWS Lambda that need to communicate with Tensorflow Serving, as Lambda carries a size limit on deployments.\n\n## Install from PyPi\nThis is the quickest way to get started! Just run:\n\n```Bash\npip install min-tfs-client\n```\n\n## Installing from source\nInstallation from source will require the protobuf compiler `protoc` to be installed and available to the command line (e.g. via the `PATH` environment variable). The protobuf compiler can be downloaded from the [protocolbuffers/protobuf](https://github.com/protocolbuffers/protobuf/releases) Github repo. Once `protoc` is installed and available, you can run:\n\n```Bash\ngit clone https://github.com/zendesk/min-tfs-client.git\ncd min-tfs-client\npython setup.py compile_pb copy_grpc\npip install .\n```\n\n## Development Installation\nFor dev installation, run `pip install -e .` instead of `pip install .`. Also, you will require `tensorflow-model-server` and `tensorflow` to be installed to run and modify the integration tests. Specifically:\n\n1. `tensorflow` is required to run the model generation script (`tests/integration/fixtures`) that creates a test model for integration testing. It is **not** required to just run the tests.\n2. `tensorflow-model-server` is required to serve the model to perform the integration test. The commands that are used to run these tests in Travis are contained in `.travis.yml`.\n\n## Usage\nBasic Usage\n``` Python\nfrom min_tfs_client.requests import TensorServingClient\nfrom min_tfs_client.tensors import tensor_proto_to_ndarray\n\nclient = TensorServingClient(host=\"127.0.0.1\", port=4080, credentials=None)\nresponse = client.predict_request(\n    model_name=\"default\",\n    model_version=1,\n    input_dict={\n        # These input keys are model-specific\n        \"string_input\": np.array([\"hello world\"]),\n        \"float_input\": np.array([0.1], dtype=np.float32),\n        \"int_input\": np.array([2], dtype=np.int64),\n    },\n)\nfloat_output = tensor_proto_to_ndarray(\n    # This output key is model-specific\n    response.outputs[\"float_output\"]\n)\n```\n\n## Running tests\n\nRun all tests with\n\n```Bash\npytest -v tests/\n```\n\nRun a single test file with\n\n```Bash\npytest <path_to_test_file>\n```\n\nRun unit / integration tests with\n\n```Bash\npytest tests/<unit or integration>\n```\n\n## Contribution Guidelines\nImprovements are always welcome. Please follow these steps to contribute:\n1. Submit a Pull Request with a detailed explanation of changes\n2. Receive approval from maintainers\n3. Maintainers will merge your changes\n\n## Licence Information\nUse of this software is subject to important terms and conditions as set forth in the [LICENSE](LICENCE) file.\n\nThe code contained within [protobuf_srcs/tensorflow](protobuf_srcs/tensorflow) is forked from [Tensorflow](https://github.com/tensorflow/tensorflow), and the code contained within [protobuf_srcs/tensorflow_serving](protobuf_srcs/tensorflow_serving) is forked from [Tensorflow Serving](https://github.com/tensorflow/serving). Please refer to the individual source files within `protobuf_srcs` for individual file licence information.\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "min-tfs-client", "package_url": "https://pypi.org/project/min-tfs-client/", "platform": "", "project_url": "https://pypi.org/project/min-tfs-client/", "project_urls": null, "release_url": "https://pypi.org/project/min-tfs-client/1.0.2/", "requires_dist": ["grpcio (>=1.21)", "protobuf (>=3.8)", "numpy (>=1.16.4)", "black (==19.10b0) ; extra == 'dev'", "flake8 ; extra == 'dev'", "mypy ; extra == 'dev'"], "requires_python": "", "summary": "A minified Tensor Serving Client for Python", "version": "1.0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Minimal Tensor Serving Python Client</h1>\n<p>A lightweight python client to communicate with Tensor Serving.</p>\n<h2>Description</h2>\n<p>Communicating with Tensorflow models via Tensor Serving requires <a href=\"https://grpc.io/\" rel=\"nofollow\">gRPC</a> and Tensorflow-specific protobufs. The <code>tensorflow-serving-apis</code> package on PyPI provides these interfaces, but requires <code>tensorflow</code> as a dependency. The Tensorflow python package currently stands at 700 Mb, with much of this space dedicated to libraries and executables required for training, saving, and visualising Tensorflow Models; these libraries are not required at inference time when communicating with Tensorflow Serving.</p>\n<p>This package exposes a minimal Tensor Serving client that does not include Tensorflow as a dependency. This reduces the overall package size to &lt; 1 Mb. This is particularly useful when deploying web services via AWS Lambda that need to communicate with Tensorflow Serving, as Lambda carries a size limit on deployments.</p>\n<h2>Install from PyPi</h2>\n<p>This is the quickest way to get started! Just run:</p>\n<pre>pip install min-tfs-client\n</pre>\n<h2>Installing from source</h2>\n<p>Installation from source will require the protobuf compiler <code>protoc</code> to be installed and available to the command line (e.g. via the <code>PATH</code> environment variable). The protobuf compiler can be downloaded from the <a href=\"https://github.com/protocolbuffers/protobuf/releases\" rel=\"nofollow\">protocolbuffers/protobuf</a> Github repo. Once <code>protoc</code> is installed and available, you can run:</p>\n<pre>git clone https://github.com/zendesk/min-tfs-client.git\n<span class=\"nb\">cd</span> min-tfs-client\npython setup.py compile_pb copy_grpc\npip install .\n</pre>\n<h2>Development Installation</h2>\n<p>For dev installation, run <code>pip install -e .</code> instead of <code>pip install .</code>. Also, you will require <code>tensorflow-model-server</code> and <code>tensorflow</code> to be installed to run and modify the integration tests. Specifically:</p>\n<ol>\n<li><code>tensorflow</code> is required to run the model generation script (<code>tests/integration/fixtures</code>) that creates a test model for integration testing. It is <strong>not</strong> required to just run the tests.</li>\n<li><code>tensorflow-model-server</code> is required to serve the model to perform the integration test. The commands that are used to run these tests in Travis are contained in <code>.travis.yml</code>.</li>\n</ol>\n<h2>Usage</h2>\n<p>Basic Usage</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">min_tfs_client.requests</span> <span class=\"kn\">import</span> <span class=\"n\">TensorServingClient</span>\n<span class=\"kn\">from</span> <span class=\"nn\">min_tfs_client.tensors</span> <span class=\"kn\">import</span> <span class=\"n\">tensor_proto_to_ndarray</span>\n\n<span class=\"n\">client</span> <span class=\"o\">=</span> <span class=\"n\">TensorServingClient</span><span class=\"p\">(</span><span class=\"n\">host</span><span class=\"o\">=</span><span class=\"s2\">\"127.0.0.1\"</span><span class=\"p\">,</span> <span class=\"n\">port</span><span class=\"o\">=</span><span class=\"mi\">4080</span><span class=\"p\">,</span> <span class=\"n\">credentials</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">predict_request</span><span class=\"p\">(</span>\n    <span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s2\">\"default\"</span><span class=\"p\">,</span>\n    <span class=\"n\">model_version</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"n\">input_dict</span><span class=\"o\">=</span><span class=\"p\">{</span>\n        <span class=\"c1\"># These input keys are model-specific</span>\n        <span class=\"s2\">\"string_input\"</span><span class=\"p\">:</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"s2\">\"hello world\"</span><span class=\"p\">]),</span>\n        <span class=\"s2\">\"float_input\"</span><span class=\"p\">:</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"mf\">0.1</span><span class=\"p\">],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">),</span>\n        <span class=\"s2\">\"int_input\"</span><span class=\"p\">:</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"mi\">2</span><span class=\"p\">],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">int64</span><span class=\"p\">),</span>\n    <span class=\"p\">},</span>\n<span class=\"p\">)</span>\n<span class=\"n\">float_output</span> <span class=\"o\">=</span> <span class=\"n\">tensor_proto_to_ndarray</span><span class=\"p\">(</span>\n    <span class=\"c1\"># This output key is model-specific</span>\n    <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">outputs</span><span class=\"p\">[</span><span class=\"s2\">\"float_output\"</span><span class=\"p\">]</span>\n<span class=\"p\">)</span>\n</pre>\n<h2>Running tests</h2>\n<p>Run all tests with</p>\n<pre>pytest -v tests/\n</pre>\n<p>Run a single test file with</p>\n<pre>pytest &lt;path_to_test_file&gt;\n</pre>\n<p>Run unit / integration tests with</p>\n<pre>pytest tests/&lt;unit or integration&gt;\n</pre>\n<h2>Contribution Guidelines</h2>\n<p>Improvements are always welcome. Please follow these steps to contribute:</p>\n<ol>\n<li>Submit a Pull Request with a detailed explanation of changes</li>\n<li>Receive approval from maintainers</li>\n<li>Maintainers will merge your changes</li>\n</ol>\n<h2>Licence Information</h2>\n<p>Use of this software is subject to important terms and conditions as set forth in the <a href=\"LICENCE\" rel=\"nofollow\">LICENSE</a> file.</p>\n<p>The code contained within <a href=\"protobuf_srcs/tensorflow\" rel=\"nofollow\">protobuf_srcs/tensorflow</a> is forked from <a href=\"https://github.com/tensorflow/tensorflow\" rel=\"nofollow\">Tensorflow</a>, and the code contained within <a href=\"protobuf_srcs/tensorflow_serving\" rel=\"nofollow\">protobuf_srcs/tensorflow_serving</a> is forked from <a href=\"https://github.com/tensorflow/serving\" rel=\"nofollow\">Tensorflow Serving</a>. Please refer to the individual source files within <code>protobuf_srcs</code> for individual file licence information.</p>\n\n          </div>"}, "last_serial": 6982686, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "4f7c12f0da59b53f1bd6c6d85a9cff77", "sha256": "eccf994f2d91132076274fb69e11a59d8e58a1bb0bdd6bf3a6ceaa8823dffa34"}, "downloads": -1, "filename": "min_tfs_client-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "4f7c12f0da59b53f1bd6c6d85a9cff77", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 376810, "upload_time": "2020-02-27T04:06:09", "upload_time_iso_8601": "2020-02-27T04:06:09.277552Z", "url": "https://files.pythonhosted.org/packages/a6/41/8656eb7410b688f2a8486a618de66b1e2ee85d29e56b197d84f3f3f4a403/min_tfs_client-1.0.0-py3-none-any.whl", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "2baaf42fe526ed3ccfd866f74ff99196", "sha256": "d280927af0247bb11e705bfb3d61b552c717536f36fb05a996cac3beaa50ff46"}, "downloads": -1, "filename": "min_tfs_client-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "2baaf42fe526ed3ccfd866f74ff99196", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 378433, "upload_time": "2020-02-27T04:23:06", "upload_time_iso_8601": "2020-02-27T04:23:06.033894Z", "url": "https://files.pythonhosted.org/packages/3c/c5/612372393aa886f6c568e6586e411f73bbedd60f008c2a4e2648c73b089a/min_tfs_client-1.0.1-py3-none-any.whl", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "1406cc4d99c8d82e1e69a6c9b5e49c63", "sha256": "2e0bd3ea0d7fd96c22d043135171726f2fc6bb72c555f617ef9ebf4ab53c5a75"}, "downloads": -1, "filename": "min_tfs_client-1.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "1406cc4d99c8d82e1e69a6c9b5e49c63", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 378454, "upload_time": "2020-03-16T00:41:48", "upload_time_iso_8601": "2020-03-16T00:41:48.704274Z", "url": "https://files.pythonhosted.org/packages/b5/b1/0d07285714d16e0606440484f5fa0a749562cbf48d963b5f75315beb847a/min_tfs_client-1.0.2-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "1406cc4d99c8d82e1e69a6c9b5e49c63", "sha256": "2e0bd3ea0d7fd96c22d043135171726f2fc6bb72c555f617ef9ebf4ab53c5a75"}, "downloads": -1, "filename": "min_tfs_client-1.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "1406cc4d99c8d82e1e69a6c9b5e49c63", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 378454, "upload_time": "2020-03-16T00:41:48", "upload_time_iso_8601": "2020-03-16T00:41:48.704274Z", "url": "https://files.pythonhosted.org/packages/b5/b1/0d07285714d16e0606440484f5fa0a749562cbf48d963b5f75315beb847a/min_tfs_client-1.0.2-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 00:54:13 2020"}