{"info": {"author": "vindarel", "author_email": "ehvince@mailz.org", "bugtrack_url": null, "classifiers": ["Environment :: Console", "Environment :: Plugins", "Environment :: Web Environment", "Intended Audience :: Developers", "Intended Audience :: End Users/Desktop", "License :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)", "Programming Language :: Python :: 2.7", "Topic :: Internet", "Topic :: Software Development :: Libraries", "Topic :: Utilities"], "description": "Web scraping to get book information\n====================================\n\nThis library is to get book information. We can search with\n**keywords**, with the **isbn**, with an **advanced search**, and do\n**pagination**.\n\nWe get the data from existing websites. We scrape:\n\n-  for French books, http://www.librairie-de-paris.fr (also Decitre, but\n   it's less complete)\n-  for Spain: http://www.casadellibro.com\n-  for Germany: http://www.buchlentner.de\n\nwe get: the title and authors, the price, the publisher(s), the cover,\netc\n\nImport data from an ods or csv file\n-----------------------------------\n\nAnother goal of this lib is to easily fetch a large amount of books you\nhave listed in an ods or csv file.\n\nIf your file has an 'isbn' and a 'quantity' column, it's easy, we will\nfind all the book information.\n\nIf it only has the title and the publisher, it's doable but error prone.\nWe can still do it, but you shall do an inventory of your stock\nafterwards.\n\nSee the ``odsimport`` module. It gives back a json. It's your\nresponsibility to add what you want in your database (this is done in\nAbelujo https://gitlab.com/vindarel/abelujo).\n\nUsable, but work in progress.\n\nAccepted format and columns\n~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nWe can read ods and csv files.\n\n-  a file with an \"isbn\" and \"quantity\" column,\n-  a file with columns \"title\", \"publisher\", \"isbn\" (optionnal in this\n   case), \"shelf\", \"distributor\", \"quantity\". There is **no** \"price\"\n   column. \"authors\" is optionnal (it can help to fetch the correct\n   book).\n\nIf the file has no headers, use the \"odsettings.py\" configuration file\n(in particular, to set the csv delimiter, either \",\" or \";\").\n\nWhy not Amazon ?\n----------------\n\nAmazon kills the book industry and its employees. But moreover, we can\nadd value to our results. We can link to a good and independent bookshop\nfrom within our application, we could command books from it, we could\nsay if it has exemplaries in stock or not, etc. And\u2026 we learn a lot in\ndoing this !\n\nTechnically speaking, the Amazon API web service can be too limitating\nand not appropriate. One must register to Amazon Product Advertising and\nto AWS, and the requests rate is limited to 1 request per second.\n\nWhy not Google books ?\n----------------------\n\nIt has very few data.\n\nWhy not the BNF (Biblioth\u00e8que Nationale de France) ?\n----------------------------------------------------\n\nBecause, for bookshops, we need recent books (they enter the BNF\ndatabase after a few months), up to date information. There isn't a lot\nof tools either.\n\nInstall\n=======\n\nInstall from pypi:\n\n::\n\n    pip install bookshops\n\nUse\n===\n\nCommand line\n------------\n\nYou can try this lib on the command line with the following commands: -\n``livres``: french books - ``libros``: spanish books - ``bucher``:\ngerman books - come and ask for more :)\n\nFor example:\n\n::\n\n    livres antigone\n\nor\n\n::\n\n    livres 9782918059363\n\nand you get the above screenshot.\n\n**Options**: (this may vary according to the scrapers, check them with\n``-h``) - ``-i`` or ``--isbn`` to ensure to get all the isbn. The\ncommand line tool won't get them by default if they need to be fetched\nwith another http request for each book. That depends on the websites.\n\nAs a library\n------------\n\nBut most of all, from within your program:\n\n::\n\n    from bookshops.frFR.librairiedeparis.librairiedeparisScraper import Scraper as frenchScraper\n\n    scraper = frenchScraper(\"search keywords\")\n    cards = scraper.search()\n    # we get a list of dictionnaries with the title, the authors, etc.\n\nAdvanced search\n---------------\n\nWork in progress.\n\nYou can search ``ed:agone`` to search for a specific publisher.\n\nPagination\n----------\n\nWe do pagination:\n\n::\n\n    scraper = frenchScraper(\"search keywords\", PAGE=2)\n\nDevelop and test\n================\n\nSee http://dev.abelujo.cc/webscraping.html\n\nDevelopment mode:\n\n::\n\n    pip install -e .\n\nNow you can edit the project and run the development version like the\nlib is meant to be run, i.e. with the ``entry_points``: ``livres``,\n``libros``, etc.\n\ndoc:\nhttps://python-packaging-user-guide.readthedocs.org/en/latest/distributing/#working-in-development-mode\n\nBugs and shortcomings\n=====================\n\nThis is webscraping, so it doesn't go without pitfalls:\n\n-  the site can go down. It happened already.\n-  the site can change, it which case we would have to change our sraper\n   too. This can be catched early with automated and frequent tests\n   (work ongoing).\n\nChangelog\n=========\n\n0.2.1\n-----\n\n-  german scraper: search by isbn\n\n0.2.0\n-----\n\n-  German scraper\n-  multiprocessing for the german scraper (from 15 to 9s) (see `issue\n   #1 <https://gitlab.com/vindarel/bookshops/issues/1>`__)\n-  ``--isbn`` option for it\n\n0.1.x\n-----\n\n-  french, spanish scrapers\n-  command line tool\n\nLicence\n=======\n\nLGPLv3", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://gitlab.com/vindarel/bookshops", "keywords": "bookshop bookstore library book isbn ean webscraping", "license": "GNU LGPLv3", "maintainer": "", "maintainer_email": "", "name": "bookshops", "package_url": "https://pypi.org/project/bookshops/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/bookshops/", "project_urls": {"Homepage": "https://gitlab.com/vindarel/bookshops"}, "release_url": "https://pypi.org/project/bookshops/0.2.1/", "requires_dist": null, "requires_python": "", "summary": "Get book information (isbn or search) from real bookstores.", "version": "0.2.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"web-scraping-to-get-book-information\">\n<h2>Web scraping to get book information</h2>\n<p>This library is to get book information. We can search with\n<strong>keywords</strong>, with the <strong>isbn</strong>, with an <strong>advanced search</strong>, and do\n<strong>pagination</strong>.</p>\n<p>We get the data from existing websites. We scrape:</p>\n<ul>\n<li>for French books, <a href=\"http://www.librairie-de-paris.fr\" rel=\"nofollow\">http://www.librairie-de-paris.fr</a> (also Decitre, but\nit\u2019s less complete)</li>\n<li>for Spain: <a href=\"http://www.casadellibro.com\" rel=\"nofollow\">http://www.casadellibro.com</a></li>\n<li>for Germany: <a href=\"http://www.buchlentner.de\" rel=\"nofollow\">http://www.buchlentner.de</a></li>\n</ul>\n<p>we get: the title and authors, the price, the publisher(s), the cover,\netc</p>\n<div id=\"import-data-from-an-ods-or-csv-file\">\n<h3>Import data from an ods or csv file</h3>\n<p>Another goal of this lib is to easily fetch a large amount of books you\nhave listed in an ods or csv file.</p>\n<p>If your file has an \u2018isbn\u2019 and a \u2018quantity\u2019 column, it\u2019s easy, we will\nfind all the book information.</p>\n<p>If it only has the title and the publisher, it\u2019s doable but error prone.\nWe can still do it, but you shall do an inventory of your stock\nafterwards.</p>\n<p>See the <tt>odsimport</tt> module. It gives back a json. It\u2019s your\nresponsibility to add what you want in your database (this is done in\nAbelujo <a href=\"https://gitlab.com/vindarel/abelujo\" rel=\"nofollow\">https://gitlab.com/vindarel/abelujo</a>).</p>\n<p>Usable, but work in progress.</p>\n<div id=\"accepted-format-and-columns\">\n<h4>Accepted format and columns</h4>\n<p>We can read ods and csv files.</p>\n<ul>\n<li>a file with an \u201cisbn\u201d and \u201cquantity\u201d column,</li>\n<li>a file with columns \u201ctitle\u201d, \u201cpublisher\u201d, \u201cisbn\u201d (optionnal in this\ncase), \u201cshelf\u201d, \u201cdistributor\u201d, \u201cquantity\u201d. There is <strong>no</strong> \u201cprice\u201d\ncolumn. \u201cauthors\u201d is optionnal (it can help to fetch the correct\nbook).</li>\n</ul>\n<p>If the file has no headers, use the \u201codsettings.py\u201d configuration file\n(in particular, to set the csv delimiter, either \u201c,\u201d or \u201c;\u201d).</p>\n</div>\n</div>\n<div id=\"why-not-amazon\">\n<h3>Why not Amazon ?</h3>\n<p>Amazon kills the book industry and its employees. But moreover, we can\nadd value to our results. We can link to a good and independent bookshop\nfrom within our application, we could command books from it, we could\nsay if it has exemplaries in stock or not, etc. And\u2026 we learn a lot in\ndoing this !</p>\n<p>Technically speaking, the Amazon API web service can be too limitating\nand not appropriate. One must register to Amazon Product Advertising and\nto AWS, and the requests rate is limited to 1 request per second.</p>\n</div>\n<div id=\"why-not-google-books\">\n<h3>Why not Google books ?</h3>\n<p>It has very few data.</p>\n</div>\n<div id=\"why-not-the-bnf-bibliotheque-nationale-de-france\">\n<h3>Why not the BNF (Biblioth\u00e8que Nationale de France) ?</h3>\n<p>Because, for bookshops, we need recent books (they enter the BNF\ndatabase after a few months), up to date information. There isn\u2019t a lot\nof tools either.</p>\n</div>\n</div>\n<div id=\"install\">\n<h2>Install</h2>\n<p>Install from pypi:</p>\n<pre>pip install bookshops\n</pre>\n</div>\n<div id=\"use\">\n<h2>Use</h2>\n<div id=\"command-line\">\n<h3>Command line</h3>\n<p>You can try this lib on the command line with the following commands: -\n<tt>livres</tt>: french books - <tt>libros</tt>: spanish books - <tt>bucher</tt>:\ngerman books - come and ask for more :)</p>\n<p>For example:</p>\n<pre>livres antigone\n</pre>\n<p>or</p>\n<pre>livres 9782918059363\n</pre>\n<p>and you get the above screenshot.</p>\n<p><strong>Options</strong>: (this may vary according to the scrapers, check them with\n<tt><span class=\"pre\">-h</span></tt>) - <tt><span class=\"pre\">-i</span></tt> or <tt><span class=\"pre\">--isbn</span></tt> to ensure to get all the isbn. The\ncommand line tool won\u2019t get them by default if they need to be fetched\nwith another http request for each book. That depends on the websites.</p>\n</div>\n<div id=\"as-a-library\">\n<h3>As a library</h3>\n<p>But most of all, from within your program:</p>\n<pre>from bookshops.frFR.librairiedeparis.librairiedeparisScraper import Scraper as frenchScraper\n\nscraper = frenchScraper(\"search keywords\")\ncards = scraper.search()\n# we get a list of dictionnaries with the title, the authors, etc.\n</pre>\n</div>\n<div id=\"advanced-search\">\n<h3>Advanced search</h3>\n<p>Work in progress.</p>\n<p>You can search <tt>ed:agone</tt> to search for a specific publisher.</p>\n</div>\n<div id=\"pagination\">\n<h3>Pagination</h3>\n<p>We do pagination:</p>\n<pre>scraper = frenchScraper(\"search keywords\", PAGE=2)\n</pre>\n</div>\n</div>\n<div id=\"develop-and-test\">\n<h2>Develop and test</h2>\n<p>See <a href=\"http://dev.abelujo.cc/webscraping.html\" rel=\"nofollow\">http://dev.abelujo.cc/webscraping.html</a></p>\n<p>Development mode:</p>\n<pre>pip install -e .\n</pre>\n<p>Now you can edit the project and run the development version like the\nlib is meant to be run, i.e. with the <tt>entry_points</tt>: <tt>livres</tt>,\n<tt>libros</tt>, etc.</p>\n<p>doc:\n<a href=\"https://python-packaging-user-guide.readthedocs.org/en/latest/distributing/#working-in-development-mode\" rel=\"nofollow\">https://python-packaging-user-guide.readthedocs.org/en/latest/distributing/#working-in-development-mode</a></p>\n</div>\n<div id=\"bugs-and-shortcomings\">\n<h2>Bugs and shortcomings</h2>\n<p>This is webscraping, so it doesn\u2019t go without pitfalls:</p>\n<ul>\n<li>the site can go down. It happened already.</li>\n<li>the site can change, it which case we would have to change our sraper\ntoo. This can be catched early with automated and frequent tests\n(work ongoing).</li>\n</ul>\n</div>\n<div id=\"changelog\">\n<h2>Changelog</h2>\n<div id=\"id1\">\n<h3>0.2.1</h3>\n<ul>\n<li>german scraper: search by isbn</li>\n</ul>\n</div>\n<div id=\"id2\">\n<h3>0.2.0</h3>\n<ul>\n<li>German scraper</li>\n<li>multiprocessing for the german scraper (from 15 to 9s) (see <a href=\"https://gitlab.com/vindarel/bookshops/issues/1\" rel=\"nofollow\">issue\n#1</a>)</li>\n<li><tt><span class=\"pre\">--isbn</span></tt> option for it</li>\n</ul>\n</div>\n<div id=\"x\">\n<h3>0.1.x</h3>\n<ul>\n<li>french, spanish scrapers</li>\n<li>command line tool</li>\n</ul>\n</div>\n</div>\n<div id=\"licence\">\n<h2>Licence</h2>\n<p>LGPLv3</p>\n</div>\n\n          </div>"}, "last_serial": 2114542, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "592c7fad2933a12a54bb21684beedddb", "sha256": "62c7c56ea81466d73333ad7422c51b4682418d4f868e5ed48282c730efeb4908"}, "downloads": -1, "filename": "bookshops-0.1.tar.gz", "has_sig": false, "md5_digest": "592c7fad2933a12a54bb21684beedddb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 39456, "upload_time": "2016-04-18T16:01:47", "upload_time_iso_8601": "2016-04-18T16:01:47.779364Z", "url": "https://files.pythonhosted.org/packages/45/8c/89a9b7c3e08055c982cafe7a342fca7a8855df94656ac64dc5245d279043/bookshops-0.1.tar.gz", "yanked": false}], "0.1.1": [], "0.1.1dev": [{"comment_text": "", "digests": {"md5": "23704688af7e5b86aad9461eec58dcd6", "sha256": "78669ba37ab5f301c639dbf1438af593e75cb81c9fec902516be0f4acbf2bec9"}, "downloads": -1, "filename": "bookshops-0.1.1dev-py2.7.egg", "has_sig": false, "md5_digest": "23704688af7e5b86aad9461eec58dcd6", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": null, "size": 253820, "upload_time": "2016-04-20T14:23:45", "upload_time_iso_8601": "2016-04-20T14:23:45.558692Z", "url": "https://files.pythonhosted.org/packages/ff/7d/67896e3d51e71663e0ae30e51de25cf06984d90ef3a8adee503d9208fc49/bookshops-0.1.1dev-py2.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "3d4b8ea2110b34b8a7f9bca61bdfdf42", "sha256": "3b054804ab9e5c3c1f1a964ccded484acae3d094c740d75a9c9a04481ab53ebc"}, "downloads": -1, "filename": "bookshops-0.1.1dev.tar.gz", "has_sig": false, "md5_digest": "3d4b8ea2110b34b8a7f9bca61bdfdf42", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 39013, "upload_time": "2016-04-20T14:24:05", "upload_time_iso_8601": "2016-04-20T14:24:05.453645Z", "url": "https://files.pythonhosted.org/packages/52/05/1fea5c65da416949fd453dea8c976351cf126fe49045854b1b8e98112c32/bookshops-0.1.1dev.tar.gz", "yanked": false}], "0.1.1dev2": [{"comment_text": "", "digests": {"md5": "b644fa5a7814042079da9b774fcca8bb", "sha256": "593474212881527b62714ca8912420fc5bd03f30ed91b9311ce0752d848da82a"}, "downloads": -1, "filename": "bookshops-0.1.1dev2-py2.7.egg", "has_sig": false, "md5_digest": "b644fa5a7814042079da9b774fcca8bb", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": null, "size": 253821, "upload_time": "2016-04-20T14:30:30", "upload_time_iso_8601": "2016-04-20T14:30:30.446934Z", "url": "https://files.pythonhosted.org/packages/ae/a7/da66a6ba311c9dab304f9e565093d9f92ec637f57041fae12bc7ac5bdfb2/bookshops-0.1.1dev2-py2.7.egg", "yanked": false}], "0.1.1dev3": [{"comment_text": "", "digests": {"md5": "bdb100226dac49230b70ebcd2853d140", "sha256": "bd675e8f37d28cdf1d5439d203d617dc14d6e517cafe00173ce3e1cbf7da7785"}, "downloads": -1, "filename": "bookshops-0.1.1dev3.tar.gz", "has_sig": false, "md5_digest": "bdb100226dac49230b70ebcd2853d140", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 39013, "upload_time": "2016-04-20T14:37:50", "upload_time_iso_8601": "2016-04-20T14:37:50.451304Z", "url": "https://files.pythonhosted.org/packages/7f/16/d65b314fb26d74052eb345f49cbbaca824751e969108ccd3fa8bfd2794ff/bookshops-0.1.1dev3.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "0fe84ee04083d36995cddc8e2097f1da", "sha256": "ed67df60ded65f26f977eb08648c62f73e1f921234a651c8b1324ab37cb6fcc5"}, "downloads": -1, "filename": "bookshops-0.1.2.tar.gz", "has_sig": false, "md5_digest": "0fe84ee04083d36995cddc8e2097f1da", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 39042, "upload_time": "2016-04-20T14:58:53", "upload_time_iso_8601": "2016-04-20T14:58:53.715515Z", "url": "https://files.pythonhosted.org/packages/27/5a/314889bc31b152221043df3e39874c1db29701e6a78c2d50703904c52a52/bookshops-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "fc845e19dbfc14dcbf54439f0b150fb5", "sha256": "54c761699e03cf01dbb39276b1d2f35ef8eb3f8826046f375c1f9c4f2623007a"}, "downloads": -1, "filename": "bookshops-0.1.3.tar.gz", "has_sig": false, "md5_digest": "fc845e19dbfc14dcbf54439f0b150fb5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 39439, "upload_time": "2016-04-25T14:44:21", "upload_time_iso_8601": "2016-04-25T14:44:21.912761Z", "url": "https://files.pythonhosted.org/packages/36/9d/49df4c1c513d964eb384f95ce76650f0efffe8c18ed68e5f388760fb13ca/bookshops-0.1.3.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "3dc4187b500998d7883edd428e8c71be", "sha256": "3caf9aef15aad85fc19b33d7571d5f336e30428be2439c844df52a25d33909f7"}, "downloads": -1, "filename": "bookshops-0.2.0.tar.gz", "has_sig": false, "md5_digest": "3dc4187b500998d7883edd428e8c71be", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 39076, "upload_time": "2016-05-13T12:34:56", "upload_time_iso_8601": "2016-05-13T12:34:56.905491Z", "url": "https://files.pythonhosted.org/packages/5a/cb/df2231cb31b91325f426569073029ed85f6790deb9c68db6b2abeb02ec51/bookshops-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "96592aead7102c02e74e2cd4ed7ce105", "sha256": "fceea12cb8f518d70e1dedd9dbe239b85cd04817fc0f7305514029ef03b22fe3"}, "downloads": -1, "filename": "bookshops-0.2.1.tar.gz", "has_sig": false, "md5_digest": "96592aead7102c02e74e2cd4ed7ce105", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 37864, "upload_time": "2016-05-13T18:51:43", "upload_time_iso_8601": "2016-05-13T18:51:43.483477Z", "url": "https://files.pythonhosted.org/packages/05/19/c0834038edd74b247caf01d7885499a22cf470e2d0e9df8206db28825a53/bookshops-0.2.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "96592aead7102c02e74e2cd4ed7ce105", "sha256": "fceea12cb8f518d70e1dedd9dbe239b85cd04817fc0f7305514029ef03b22fe3"}, "downloads": -1, "filename": "bookshops-0.2.1.tar.gz", "has_sig": false, "md5_digest": "96592aead7102c02e74e2cd4ed7ce105", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 37864, "upload_time": "2016-05-13T18:51:43", "upload_time_iso_8601": "2016-05-13T18:51:43.483477Z", "url": "https://files.pythonhosted.org/packages/05/19/c0834038edd74b247caf01d7885499a22cf470e2d0e9df8206db28825a53/bookshops-0.2.1.tar.gz", "yanked": false}], "timestamp": "Thu May  7 22:36:43 2020"}