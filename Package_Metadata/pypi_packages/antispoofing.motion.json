{"info": {"author": "Andre Anjos", "author_email": "andre.anjos@idiap.ch", "bugtrack_url": null, "classifiers": [], "description": "====================================================\n Motion-Based Counter-Measures for Spoofing Attacks\n====================================================\n\nThis package implements a motion-based counter-measure to spoofing attacks to\nface recognition systems as described at the paper `Counter-Measures to Photo\nAttacks in Face Recognition: a public database and a baseline`, by Anjos and\nMarcel, International Joint Conference on Biometrics, 2011.\n\nIf you use this package and/or its results, please cite the following\npublications:\n\n1. The original paper with the counter-measure explained in details::\n\n    @inproceedings{Anjos_IJCB_2011,\n      author = {Anjos, Andr{\\'{e}} and Marcel, S{\\'{e}}bastien},\n      keywords = {Attack, Counter-Measures, Counter-Spoofing, Disguise, Dishonest Acts, Face Recognition, Face Verification, Forgery, Liveness Detection, Replay, Spoofing, Trick},\n      month = oct,\n      title = {Counter-Measures to Photo Attacks in Face Recognition: a public database and a baseline},\n      booktitle = {International Joint Conference on Biometrics 2011},\n      year = {2011},\n      url = {http://publications.idiap.ch/downloads/papers/2011/Anjos_IJCB_2011.pdf}\n    }\n\n2. Bob as the core framework used to run the experiments::\n\n    @inproceedings{Anjos_ACMMM_2012,\n      author = {A. Anjos and L. El Shafey and R. Wallace and M. G\\\"unther and C. McCool and S. Marcel},\n      title = {Bob: a free signal processing and machine learning toolbox for researchers},\n      year = {2012},\n      month = oct,\n      booktitle = {20th ACM Conference on Multimedia Systems (ACMMM), Nara, Japan},\n      publisher = {ACM Press},\n      url = {http://publications.idiap.ch/downloads/papers/2012/Anjos_Bob_ACMMM12.pdf},\n    }\n\n3. If you decide to use the REPLAY-ATTACK database, you should also mention the\n   following paper, where it is introduced::\n\n    @inproceedings{Chingovska_BIOSIG_2012,\n      author = {Chingovska, Ivana and Anjos, Andr{\\'{e}} and Marcel, S{\\'{e}}bastien},\n      keywords = {Attack, Counter-Measures, Counter-Spoofing, Face Recognition, Liveness Detection, Replay, Spoofing},\n      month = sep,\n      title = {On the Effectiveness of Local Binary Patterns in Face Anti-spoofing},\n      booktitle = {IEEE Biometrics Special Interest Group},\n      year = {2012},\n      url = {http://publications.idiap.ch/downloads/papers/2012/Chingovska_IEEEBIOSIG2012_2012.pdf},\n    }\n\nIf you wish to report problems or improvements concerning this code, please\ncontact the authors of the above mentioned papers.\n\nRaw data\n--------\n\nThis method was originally conceived to work with the `the PRINT-ATTACK\ndatabase <https://www.idiap.ch/dataset/printattack>`_, but has since evolved to\nwork with the whole of the `the REPLAY-ATTACK database\n<https://www.idiap.ch/dataset/replayattack>`_, which is a super-set of the\nPRINT-ATTACK database. You are allowed to select protocols in each of the\napplications described in this manual. To generate the results for the paper,\njust select `print` as protocol option where necessary. Detailed comments about\nspecific results or tables are given where required.\n\nThe data used in the paper is publicly available and should be downloaded and\ninstalled **prior** to try using the programs described in this package. The\nroot directory of the database installation is used by the first program in the\nAntispoofing-Motion toolchain.\n\nInstallation\n------------\n\n.. note:: \n\n  If you are reading this page through our GitHub portal and not through PyPI,\n  note **the development tip of the package may not be stable** or become\n  unstable in a matter of moments.\n\n  Go to `http://pypi.python.org/pypi/antispoofing.motion\n  <http://pypi.python.org/pypi/antispoofing.motion>`_ to download the latest\n  stable version of this package. Then, extract the .zip file to a folder of your choice.\n\nThe ``antispoofing.motion`` package is a satellite package of the free signal processing and machine learning library Bob_. This dependency has to be downloaded manually. This version of the package depends on Bob_ version 2 or greater. To install `packages of Bob <https://github.com/idiap/bob/wiki/Packages>`_, please read the `Installation Instructions <https://github.com/idiap/bob/wiki/Installation>`_. For Bob_ to be able to work properly, some dependent Bob packages are required to be installed. Please make sure that you have read the Dependencies for your operating system.\n\nThe most simple solution is to download and extract ``antispoofing.motion`` package, then to go to the console and write::\n\n  $ cd antispoofing.motion\n  $ python bootstrap-buildout.py\n  $ bin/buildout\n\nThis will download all required dependent Bob_ and other packages and install them locally. \n\nUser Guide\n----------\n\nIt is assumed you have followed the installation instructions for the package\nand got this package installed and the REPLAY-ATTACK (or PRINT-ATTACK) database\ndownloaded and uncompressed in a directory to which you have read access.\nThrough this manual, we will call this directory ``/root/of/database``. That\nwould be the directory that *contains* the sub-directories ``train``, ``test``,\n``devel`` and ``face-locations``.\n\nNote for Grid Users\n===================\n\nAt Idiap, we use the powerful Sun Grid Engine (SGE) to parallelize our job\nsubmissions as much as we can. At the Biometrics group, we have developed a\n`little toolbox <http://pypi.python.org/pypi/gridtk>` that can submit and\nmanage jobs at the Idiap computing grid through SGE.  If you are at Idiap, you\ncan download and install this toolset by adding ``gridtk`` at the ``eggs``\nsection of your ``buildout.cfg`` file, if it is not already there. If you are\nnot, you still may look inside for tips on automated parallelization of\nscripts.\n\nThe following sections will explain how to reproduce the paper results in\nsingle (non-gridified) jobs. A note will be given where relevant explaining how\nto parallalize the job submission using ``gridtk``.\n\nCalculate Frame Differences\n===========================\n\nThe first stage of the process is to calculate the normalized frame differences\nusing video sequences. The program that will do that should be sitting in\n``bin/motion_framediff.py``. It can calculate normalize frame differences in distinct\nparts of the scene (given you provide face locations for each of the frames in\nall video sequences to be analyzed).\n\nTo execute the frame difference process to all videos in the REPLAY-ATTACK\ndatabase, just execute::\n\n  $ ./bin/motion_framediff.py /root/of/database results/framediff replay\n\nThere are more options for the ``motion_framediff.py`` script you can use (such\nas the sub-protocol selection for the Replay Attack database). Note that, by\ndefault, all applications are tunned to work with the **whole** of the\ndatabase.  Just type ``--help`` **after** the keyword ``replay`` at the command\nline for instructions.\n\n.. note::\n\n  To parallelize this job, do the following::\n\n    $ ./bin/jman submit --array=1200 ./bin/motion_framediff.py /root/of/database results/framediff replay\n\n  The `magic` number of `1200` entries can be found by executing::\n\n    $ ./bin/motion_framediff.py --grid-count replay\n\n  Which just prints the number of jobs it requires for the grid execution.\n\nCalculate the 5 Quantities\n==========================\n\nThe second step in calculating the frame differences is to compute the set of 5\nquantities that are required for the detection process. To reproduce the\nresults in the paper, we accumulate the results in windows of 20 frames,\nwithout overlap::\n\n  $ ./bin/motion_diffcluster.py results/framediff results/quantities replay\n\nThere are more options for the `motion_diffcluster.py` script you can use (such\nas the sub-protocol selection). Just type `--help` at the command line for\ninstructions.\n\n.. note::\n\n  This job is very fast and normally does not require parallelization. You can\n  still do it with::\n\n    $ ./bin/jman submit --array=1200 ./bin/motion_diffcluster.py results/framediff results/quantities replay\n\nTraining with Linear Discriminant Analysis (LDA)\n================================================\n\nTraining a linear machine to perform LDA should go like this::\n\n  $ ./bin/motion_ldatrain.py --verbose results/quantities results/lda replay\n\nThis will create a new linear machine train it using the training data.\nEvaluation based on the EER on the development set will be performed by the end\nof the training::\n\n  Performance evaluation:\n   -> EER @ devel set threshold: 8.11125e-02\n   -> Devel set results:\n       * FAR : 16.204% (175/1080)\n       * FRR : 16.174% (558/3450)\n       * HTER: 16.189%\n   -> Test set results:\n       * FAR: 16.389% (236/1440)\n       * FRR: 18.641% (856/4592)\n       * HTER: 17.515%\n\nThe resulting linear machine will be saved in the output directory called\n``results/lda``.\n\nTraining an MLP\n===============\n\nTraining MLPs to perform discrimination should go like this::\n\n  $ ./bin/motion_rproptrain.py --verbose --epoch=10000 --batch-size=500 --no-improvements=1000000 --maximum-iterations=10000000 results/quantities results/mlp replay\n\nThis will create a new MLP and train it using the data produced by the\n\"clustering\" step. The training can take anywhere from 20 to 30 minutes (or\neven more), depending on your machine speed. You should see some debugging\noutput with the partial results as the training go along::\n\n  ...\n  iteration: RMSE:real/RMSE:attack (EER:%) ( train | devel )\n  0: 9.1601e-01/1.0962e+00 (60.34%) | 9.1466e-01/1.0972e+00 (58.71%)\n  0: Saving best network so far with average devel. RMSE = 1.0059e+00\n  0: New valley stop threshold set to 1.2574e+00\n  10000: 5.6706e-01/4.2730e-01 (8.29%) | 7.6343e-01/4.3836e-01 (11.90%)\n  10000: Saving best network so far with average devel. RMSE = 6.0089e-01\n  10000: New valley stop threshold set to 7.5112e-01\n  20000: 5.6752e-01/4.2222e-01 (8.21%) | 7.6444e-01/4.3515e-01 (12.07%)\n  20000: Saving best network so far with average devel. RMSE = 5.9979e-01\n  20000: New valley stop threshold set to 7.4974e-01\n\nThe resulting MLP will be saved in the output directory called\n``results/mlp``. The resulting directory will also contain performance\nanalysis plots. The results derived after this step are equivalent to the\nresults shown at Table 2 and Figure 3 at the paper.\n\nTo get results for specific supports as shown at the first two lines of Table\n2, just select the support using the ``--support=hand`` or ``--support=fixed``\nas a flag to ``motion_rproptrain.py``. Place this flags **after** the keyword\n``replay`` at the command line. At this point, it is adviseable to use\ndifferent output directories using the ``--output-dir`` flag as well. If you\nneed to modify or regenerate Figure 3 at the paper, just look at\n``antispoofing/motion/ml/perf.py``, which contains all plotting and analysis\nroutines.\n\n.. note::\n\n  If you think that the training is taking too long, you can interrupt it by\n  pressing ``CTRL-C``. This will cause the script to quit gracefully and still\n  evaluate the best MLP network performance to that point. \n\n.. note::\n\n  To execute this script in the grid environment, just set the output directory\n  to depend on the SGE_TASK_ID environment variable::\n\n    $ ./bin/jman submit --array=10 ./bin/motion_rproptrain.py --verbose --epoch=10000 --batch-size=500 --no-improvements=1000000 --maximum-iterations=10000000 results/quantities 'results/mlp.%(SGE_TASK_ID)s' replay\n\nDumping Machine (MLP or LDA) Scores\n===================================\n\nYou should now dump the scores for every input file in the\n``results/quantities`` directory using the ``motion_make_scores.py`` script,\nfor example, to dump scores produced with by an MLP::\n\n  $ ./bin/motion_make_scores.py --verbose results/quantities results/mlp/mlp.hdf5 results/mlp-scores replay\n\nThis should give you the detailed output of the machine for every input file in\nthe training, development and test sets. You can use these score files in your\nown score analysis routines, for example.\n\n.. note::\n\n  The score file format is an HDF5 file with a single array, which contains the\n  scores for every frame in the input video. Values which are marked as NaN\n  should be ignored by your procedure. The reason varies: it may mean no valid\n  face was detected on such a frame or that the motion-detection procedure\n  decided to skip (on user configuration) the analysis of that frame.\n\nRunning the Time Analysis\n=========================\n\nThe time analysis is the end of the processing chain, it fuses the scores of\ninstantaneous outputs to give out a better estimation of attacks and\nreal-accesses **for a set of frames**. You can used with the scores output by\nMLPs or linear machines (LDA training). To use it, write something like::\n\n  $ ./bin/motion_time_analysis.py --verbose results/mlp-scores results/mlp-time replay\n\nThe 3 curves on Figure 4 at the paper relate to the different support types.\nJust repeat the procedure for every system trained with data for a particular\nsupport (equivalent for then entries in Table 2). To set the support use\n``--help`` after the keyword ``replay`` on the command-line above to find out\nhow to specify the support to this program. The output for this script is\ndumped in PDF (plot) and text (``.rst`` file) on the specified directory.\n\nMerging Scores\n==============\n\nIf you wish to create a single `5-column format file\n<http://www.idiap.ch/software/bob/docs/releases/last/sphinx/html/measure/index.html?highlight=five#bob.measure.load.five_column>`_\nby combining this counter-measure scores for every video into a single file\nthat can be fed to external analysis utilities such as our\n`antispoofing.evaluation <http://pypi.python.org/pypi/antispoofing.evaluation>`\npackage, you should use the script ``motion_merge_scores.py``. You will have to\nspecify how many of the scores in every video you will want to average and the\ninput directory containing the scores files that will be merged.\n\nThe output of the program consists of three 5-column formatted files with the\nclient identities and scores for **every video** in the input directory. A line\nin the output file corresponds to a video from the database.\n\nYou run this program on the output of ``motion_make_scores.py``. So, it should\nlook like this if you followed the previous example::\n\n  $ ./bin/motion_merge_scores.py results/mlp-scores results/mlp-merged replay\n\nThe above commandline examples will generate 3 files containing the training,\ndevelopment and test scores, accumulated over each video in the respective\nsubsets, for input scores in the given input directory.\n\nProblems\n--------\n\nIn case of problems, please contact any of the authors of the paper.\n\n.. _Bob: http://www.idiap.ch/software/bob", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://pypi.python.org/pypi/antispoofing.motion", "keywords": null, "license": "GPLv3", "maintainer": null, "maintainer_email": null, "name": "antispoofing.motion", "package_url": "https://pypi.org/project/antispoofing.motion/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/antispoofing.motion/", "project_urls": {"Download": "UNKNOWN", "Homepage": "http://pypi.python.org/pypi/antispoofing.motion"}, "release_url": "https://pypi.org/project/antispoofing.motion/2.0.3/", "requires_dist": null, "requires_python": null, "summary": "Motion counter-measures for the REPLAY-ATTACK database", "version": "2.0.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>This package implements a motion-based counter-measure to spoofing attacks to\nface recognition systems as described at the paper <cite>Counter-Measures to Photo\nAttacks in Face Recognition: a public database and a baseline</cite>, by Anjos and\nMarcel, International Joint Conference on Biometrics, 2011.</p>\n<p>If you use this package and/or its results, please cite the following\npublications:</p>\n<ol>\n<li><p>The original paper with the counter-measure explained in details:</p>\n<pre>@inproceedings{Anjos_IJCB_2011,\n  author = {Anjos, Andr{\\'{e}} and Marcel, S{\\'{e}}bastien},\n  keywords = {Attack, Counter-Measures, Counter-Spoofing, Disguise, Dishonest Acts, Face Recognition, Face Verification, Forgery, Liveness Detection, Replay, Spoofing, Trick},\n  month = oct,\n  title = {Counter-Measures to Photo Attacks in Face Recognition: a public database and a baseline},\n  booktitle = {International Joint Conference on Biometrics 2011},\n  year = {2011},\n  url = {http://publications.idiap.ch/downloads/papers/2011/Anjos_IJCB_2011.pdf}\n}\n</pre>\n</li>\n<li><p>Bob as the core framework used to run the experiments:</p>\n<pre>@inproceedings{Anjos_ACMMM_2012,\n  author = {A. Anjos and L. El Shafey and R. Wallace and M. G\\\"unther and C. McCool and S. Marcel},\n  title = {Bob: a free signal processing and machine learning toolbox for researchers},\n  year = {2012},\n  month = oct,\n  booktitle = {20th ACM Conference on Multimedia Systems (ACMMM), Nara, Japan},\n  publisher = {ACM Press},\n  url = {http://publications.idiap.ch/downloads/papers/2012/Anjos_Bob_ACMMM12.pdf},\n}\n</pre>\n</li>\n<li><p>If you decide to use the REPLAY-ATTACK database, you should also mention the\nfollowing paper, where it is introduced:</p>\n<pre>@inproceedings{Chingovska_BIOSIG_2012,\n  author = {Chingovska, Ivana and Anjos, Andr{\\'{e}} and Marcel, S{\\'{e}}bastien},\n  keywords = {Attack, Counter-Measures, Counter-Spoofing, Face Recognition, Liveness Detection, Replay, Spoofing},\n  month = sep,\n  title = {On the Effectiveness of Local Binary Patterns in Face Anti-spoofing},\n  booktitle = {IEEE Biometrics Special Interest Group},\n  year = {2012},\n  url = {http://publications.idiap.ch/downloads/papers/2012/Chingovska_IEEEBIOSIG2012_2012.pdf},\n}\n</pre>\n</li>\n</ol>\n<p>If you wish to report problems or improvements concerning this code, please\ncontact the authors of the above mentioned papers.</p>\n<div id=\"raw-data\">\n<h2>Raw data</h2>\n<p>This method was originally conceived to work with the <a href=\"https://www.idiap.ch/dataset/printattack\" rel=\"nofollow\">the PRINT-ATTACK\ndatabase</a>, but has since evolved to\nwork with the whole of the <a href=\"https://www.idiap.ch/dataset/replayattack\" rel=\"nofollow\">the REPLAY-ATTACK database</a>, which is a super-set of the\nPRINT-ATTACK database. You are allowed to select protocols in each of the\napplications described in this manual. To generate the results for the paper,\njust select <cite>print</cite> as protocol option where necessary. Detailed comments about\nspecific results or tables are given where required.</p>\n<p>The data used in the paper is publicly available and should be downloaded and\ninstalled <strong>prior</strong> to try using the programs described in this package. The\nroot directory of the database installation is used by the first program in the\nAntispoofing-Motion toolchain.</p>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<div>\n<p>Note</p>\n<p>If you are reading this page through our GitHub portal and not through PyPI,\nnote <strong>the development tip of the package may not be stable</strong> or become\nunstable in a matter of moments.</p>\n<p>Go to <a href=\"http://pypi.python.org/pypi/antispoofing.motion\" rel=\"nofollow\">http://pypi.python.org/pypi/antispoofing.motion</a> to download the latest\nstable version of this package. Then, extract the .zip file to a folder of your choice.</p>\n</div>\n<p>The <tt>antispoofing.motion</tt> package is a satellite package of the free signal processing and machine learning library <a href=\"http://www.idiap.ch/software/bob\" rel=\"nofollow\">Bob</a>. This dependency has to be downloaded manually. This version of the package depends on <a href=\"http://www.idiap.ch/software/bob\" rel=\"nofollow\">Bob</a> version 2 or greater. To install <a href=\"https://github.com/idiap/bob/wiki/Packages\" rel=\"nofollow\">packages of Bob</a>, please read the <a href=\"https://github.com/idiap/bob/wiki/Installation\" rel=\"nofollow\">Installation Instructions</a>. For <a href=\"http://www.idiap.ch/software/bob\" rel=\"nofollow\">Bob</a> to be able to work properly, some dependent Bob packages are required to be installed. Please make sure that you have read the Dependencies for your operating system.</p>\n<p>The most simple solution is to download and extract <tt>antispoofing.motion</tt> package, then to go to the console and write:</p>\n<pre>$ cd antispoofing.motion\n$ python bootstrap-buildout.py\n$ bin/buildout\n</pre>\n<p>This will download all required dependent <a href=\"http://www.idiap.ch/software/bob\" rel=\"nofollow\">Bob</a> and other packages and install them locally.</p>\n</div>\n<div id=\"user-guide\">\n<h2>User Guide</h2>\n<p>It is assumed you have followed the installation instructions for the package\nand got this package installed and the REPLAY-ATTACK (or PRINT-ATTACK) database\ndownloaded and uncompressed in a directory to which you have read access.\nThrough this manual, we will call this directory <tt>/root/of/database</tt>. That\nwould be the directory that <em>contains</em> the sub-directories <tt>train</tt>, <tt>test</tt>,\n<tt>devel</tt> and <tt><span class=\"pre\">face-locations</span></tt>.</p>\n<div id=\"note-for-grid-users\">\n<h3>Note for Grid Users</h3>\n<p>At Idiap, we use the powerful Sun Grid Engine (SGE) to parallelize our job\nsubmissions as much as we can. At the Biometrics group, we have developed a\n<cite>little toolbox &lt;http://pypi.python.org/pypi/gridtk&gt;</cite> that can submit and\nmanage jobs at the Idiap computing grid through SGE.  If you are at Idiap, you\ncan download and install this toolset by adding <tt>gridtk</tt> at the <tt>eggs</tt>\nsection of your <tt>buildout.cfg</tt> file, if it is not already there. If you are\nnot, you still may look inside for tips on automated parallelization of\nscripts.</p>\n<p>The following sections will explain how to reproduce the paper results in\nsingle (non-gridified) jobs. A note will be given where relevant explaining how\nto parallalize the job submission using <tt>gridtk</tt>.</p>\n</div>\n<div id=\"calculate-frame-differences\">\n<h3>Calculate Frame Differences</h3>\n<p>The first stage of the process is to calculate the normalized frame differences\nusing video sequences. The program that will do that should be sitting in\n<tt>bin/motion_framediff.py</tt>. It can calculate normalize frame differences in distinct\nparts of the scene (given you provide face locations for each of the frames in\nall video sequences to be analyzed).</p>\n<p>To execute the frame difference process to all videos in the REPLAY-ATTACK\ndatabase, just execute:</p>\n<pre>$ ./bin/motion_framediff.py /root/of/database results/framediff replay\n</pre>\n<p>There are more options for the <tt>motion_framediff.py</tt> script you can use (such\nas the sub-protocol selection for the Replay Attack database). Note that, by\ndefault, all applications are tunned to work with the <strong>whole</strong> of the\ndatabase.  Just type <tt><span class=\"pre\">--help</span></tt> <strong>after</strong> the keyword <tt>replay</tt> at the command\nline for instructions.</p>\n<div>\n<p>Note</p>\n<p>To parallelize this job, do the following:</p>\n<pre>$ ./bin/jman submit --array=1200 ./bin/motion_framediff.py /root/of/database results/framediff replay\n</pre>\n<p>The <cite>magic</cite> number of <cite>1200</cite> entries can be found by executing:</p>\n<pre>$ ./bin/motion_framediff.py --grid-count replay\n</pre>\n<p>Which just prints the number of jobs it requires for the grid execution.</p>\n</div>\n</div>\n<div id=\"calculate-the-5-quantities\">\n<h3>Calculate the 5 Quantities</h3>\n<p>The second step in calculating the frame differences is to compute the set of 5\nquantities that are required for the detection process. To reproduce the\nresults in the paper, we accumulate the results in windows of 20 frames,\nwithout overlap:</p>\n<pre>$ ./bin/motion_diffcluster.py results/framediff results/quantities replay\n</pre>\n<p>There are more options for the <cite>motion_diffcluster.py</cite> script you can use (such\nas the sub-protocol selection). Just type <cite>\u2013help</cite> at the command line for\ninstructions.</p>\n<div>\n<p>Note</p>\n<p>This job is very fast and normally does not require parallelization. You can\nstill do it with:</p>\n<pre>$ ./bin/jman submit --array=1200 ./bin/motion_diffcluster.py results/framediff results/quantities replay\n</pre>\n</div>\n</div>\n<div id=\"training-with-linear-discriminant-analysis-lda\">\n<h3>Training with Linear Discriminant Analysis (LDA)</h3>\n<p>Training a linear machine to perform LDA should go like this:</p>\n<pre>$ ./bin/motion_ldatrain.py --verbose results/quantities results/lda replay\n</pre>\n<p>This will create a new linear machine train it using the training data.\nEvaluation based on the EER on the development set will be performed by the end\nof the training:</p>\n<pre>Performance evaluation:\n -&gt; EER @ devel set threshold: 8.11125e-02\n -&gt; Devel set results:\n     * FAR : 16.204% (175/1080)\n     * FRR : 16.174% (558/3450)\n     * HTER: 16.189%\n -&gt; Test set results:\n     * FAR: 16.389% (236/1440)\n     * FRR: 18.641% (856/4592)\n     * HTER: 17.515%\n</pre>\n<p>The resulting linear machine will be saved in the output directory called\n<tt>results/lda</tt>.</p>\n</div>\n<div id=\"training-an-mlp\">\n<h3>Training an MLP</h3>\n<p>Training MLPs to perform discrimination should go like this:</p>\n<pre>$ ./bin/motion_rproptrain.py --verbose --epoch=10000 --batch-size=500 --no-improvements=1000000 --maximum-iterations=10000000 results/quantities results/mlp replay\n</pre>\n<p>This will create a new MLP and train it using the data produced by the\n\u201cclustering\u201d step. The training can take anywhere from 20 to 30 minutes (or\neven more), depending on your machine speed. You should see some debugging\noutput with the partial results as the training go along:</p>\n<pre>...\niteration: RMSE:real/RMSE:attack (EER:%) ( train | devel )\n0: 9.1601e-01/1.0962e+00 (60.34%) | 9.1466e-01/1.0972e+00 (58.71%)\n0: Saving best network so far with average devel. RMSE = 1.0059e+00\n0: New valley stop threshold set to 1.2574e+00\n10000: 5.6706e-01/4.2730e-01 (8.29%) | 7.6343e-01/4.3836e-01 (11.90%)\n10000: Saving best network so far with average devel. RMSE = 6.0089e-01\n10000: New valley stop threshold set to 7.5112e-01\n20000: 5.6752e-01/4.2222e-01 (8.21%) | 7.6444e-01/4.3515e-01 (12.07%)\n20000: Saving best network so far with average devel. RMSE = 5.9979e-01\n20000: New valley stop threshold set to 7.4974e-01\n</pre>\n<p>The resulting MLP will be saved in the output directory called\n<tt>results/mlp</tt>. The resulting directory will also contain performance\nanalysis plots. The results derived after this step are equivalent to the\nresults shown at Table 2 and Figure 3 at the paper.</p>\n<p>To get results for specific supports as shown at the first two lines of Table\n2, just select the support using the <tt><span class=\"pre\">--support=hand</span></tt> or <tt><span class=\"pre\">--support=fixed</span></tt>\nas a flag to <tt>motion_rproptrain.py</tt>. Place this flags <strong>after</strong> the keyword\n<tt>replay</tt> at the command line. At this point, it is adviseable to use\ndifferent output directories using the <tt><span class=\"pre\">--output-dir</span></tt> flag as well. If you\nneed to modify or regenerate Figure 3 at the paper, just look at\n<tt>antispoofing/motion/ml/perf.py</tt>, which contains all plotting and analysis\nroutines.</p>\n<div>\n<p>Note</p>\n<p>If you think that the training is taking too long, you can interrupt it by\npressing <tt><span class=\"pre\">CTRL-C</span></tt>. This will cause the script to quit gracefully and still\nevaluate the best MLP network performance to that point.</p>\n</div>\n<div>\n<p>Note</p>\n<p>To execute this script in the grid environment, just set the output directory\nto depend on the SGE_TASK_ID environment variable:</p>\n<pre>$ ./bin/jman submit --array=10 ./bin/motion_rproptrain.py --verbose --epoch=10000 --batch-size=500 --no-improvements=1000000 --maximum-iterations=10000000 results/quantities 'results/mlp.%(SGE_TASK_ID)s' replay\n</pre>\n</div>\n</div>\n<div id=\"dumping-machine-mlp-or-lda-scores\">\n<h3>Dumping Machine (MLP or LDA) Scores</h3>\n<p>You should now dump the scores for every input file in the\n<tt>results/quantities</tt> directory using the <tt>motion_make_scores.py</tt> script,\nfor example, to dump scores produced with by an MLP:</p>\n<pre>$ ./bin/motion_make_scores.py --verbose results/quantities results/mlp/mlp.hdf5 results/mlp-scores replay\n</pre>\n<p>This should give you the detailed output of the machine for every input file in\nthe training, development and test sets. You can use these score files in your\nown score analysis routines, for example.</p>\n<div>\n<p>Note</p>\n<p>The score file format is an HDF5 file with a single array, which contains the\nscores for every frame in the input video. Values which are marked as NaN\nshould be ignored by your procedure. The reason varies: it may mean no valid\nface was detected on such a frame or that the motion-detection procedure\ndecided to skip (on user configuration) the analysis of that frame.</p>\n</div>\n</div>\n<div id=\"running-the-time-analysis\">\n<h3>Running the Time Analysis</h3>\n<p>The time analysis is the end of the processing chain, it fuses the scores of\ninstantaneous outputs to give out a better estimation of attacks and\nreal-accesses <strong>for a set of frames</strong>. You can used with the scores output by\nMLPs or linear machines (LDA training). To use it, write something like:</p>\n<pre>$ ./bin/motion_time_analysis.py --verbose results/mlp-scores results/mlp-time replay\n</pre>\n<p>The 3 curves on Figure 4 at the paper relate to the different support types.\nJust repeat the procedure for every system trained with data for a particular\nsupport (equivalent for then entries in Table 2). To set the support use\n<tt><span class=\"pre\">--help</span></tt> after the keyword <tt>replay</tt> on the command-line above to find out\nhow to specify the support to this program. The output for this script is\ndumped in PDF (plot) and text (<tt>.rst</tt> file) on the specified directory.</p>\n</div>\n<div id=\"merging-scores\">\n<h3>Merging Scores</h3>\n<p>If you wish to create a single <a href=\"http://www.idiap.ch/software/bob/docs/releases/last/sphinx/html/measure/index.html?highlight=five#bob.measure.load.five_column\" rel=\"nofollow\">5-column format file</a>\nby combining this counter-measure scores for every video into a single file\nthat can be fed to external analysis utilities such as our\n<cite>antispoofing.evaluation &lt;http://pypi.python.org/pypi/antispoofing.evaluation&gt;</cite>\npackage, you should use the script <tt>motion_merge_scores.py</tt>. You will have to\nspecify how many of the scores in every video you will want to average and the\ninput directory containing the scores files that will be merged.</p>\n<p>The output of the program consists of three 5-column formatted files with the\nclient identities and scores for <strong>every video</strong> in the input directory. A line\nin the output file corresponds to a video from the database.</p>\n<p>You run this program on the output of <tt>motion_make_scores.py</tt>. So, it should\nlook like this if you followed the previous example:</p>\n<pre>$ ./bin/motion_merge_scores.py results/mlp-scores results/mlp-merged replay\n</pre>\n<p>The above commandline examples will generate 3 files containing the training,\ndevelopment and test scores, accumulated over each video in the respective\nsubsets, for input scores in the given input directory.</p>\n</div>\n</div>\n<div id=\"problems\">\n<h2>Problems</h2>\n<p>In case of problems, please contact any of the authors of the paper.</p>\n</div>\n\n          </div>"}, "last_serial": 1895313, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "ba6007828dd47537fef4bbd4a0e45ee2", "sha256": "a1c5ee64906cc971d70a78edd5a2b2f6d0256eab05beb9d0423c2c72308baa6e"}, "downloads": -1, "filename": "antispoofing.motion-1.0.0.zip", "has_sig": false, "md5_digest": "ba6007828dd47537fef4bbd4a0e45ee2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 48166, "upload_time": "2012-08-30T14:05:15", "upload_time_iso_8601": "2012-08-30T14:05:15.911798Z", "url": "https://files.pythonhosted.org/packages/90/80/46e99ce5a294397e0c60220271ae02ec5a44e03e39832cbba50f25f03b0a/antispoofing.motion-1.0.0.zip", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "8d51bb953d8c2dc19eea522e7311d7af", "sha256": "3757a85cdfb8a87afbe656b3a13c69ba807fd69af654b49b4cf0b9acaefe4059"}, "downloads": -1, "filename": "antispoofing.motion-1.0.1.zip", "has_sig": false, "md5_digest": "8d51bb953d8c2dc19eea522e7311d7af", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 46914, "upload_time": "2012-08-30T14:14:59", "upload_time_iso_8601": "2012-08-30T14:14:59.213990Z", "url": "https://files.pythonhosted.org/packages/3a/7d/1373a75d47a66f7fee0a7d44e119f1c0d7ca82d537ff337a20e5b0e2f293/antispoofing.motion-1.0.1.zip", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "1b42c7733c9ac6ae7dea26fc29b9e191", "sha256": "95aabfcffc2cbf7fe284100e64ba9ebe5c3cbfcea5ba619039761a7fa560e69f"}, "downloads": -1, "filename": "antispoofing.motion-1.0.2.zip", "has_sig": false, "md5_digest": "1b42c7733c9ac6ae7dea26fc29b9e191", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 47537, "upload_time": "2012-08-30T14:40:04", "upload_time_iso_8601": "2012-08-30T14:40:04.759589Z", "url": "https://files.pythonhosted.org/packages/e0/15/6a46f85f4be99ea4d9e8aa10d2e7aae3a512951bfd9a4384a24775c2f2f4/antispoofing.motion-1.0.2.zip", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "094c8787b4c4e1a7c9fa20e9c9221359", "sha256": "81177efde26cf5b9d7cb50a9b1200944d47b0ae8ae288d24e60d3929e4ade290"}, "downloads": -1, "filename": "antispoofing.motion-1.0.3.zip", "has_sig": false, "md5_digest": "094c8787b4c4e1a7c9fa20e9c9221359", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 47667, "upload_time": "2013-02-13T15:56:41", "upload_time_iso_8601": "2013-02-13T15:56:41.576109Z", "url": "https://files.pythonhosted.org/packages/b2/6a/eb7e5a2b8fa60b221132daa5be72642dc6f0a8aebcfe9190d05b4c38a842/antispoofing.motion-1.0.3.zip", "yanked": false}], "1.0.4": [{"comment_text": "", "digests": {"md5": "8f0a34283fb0fe77c685908219e0f76e", "sha256": "17cf1f6c6193067bdcbbc09c4e0d801c01ae2aa863522958e1a469d7b3a69454"}, "downloads": -1, "filename": "antispoofing.motion-1.0.4.zip", "has_sig": false, "md5_digest": "8f0a34283fb0fe77c685908219e0f76e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 47675, "upload_time": "2013-02-19T14:35:45", "upload_time_iso_8601": "2013-02-19T14:35:45.362378Z", "url": "https://files.pythonhosted.org/packages/b0/36/410c95af88acb1d4e92f6868e1eeedb53e3756f8ee0278e14e05ae3a6d71/antispoofing.motion-1.0.4.zip", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "ce0ed56ed04a85b5f40c2147fb1fbb56", "sha256": "d76cb9f17f5cc3df1044b751ec0f3b4c861a95d9469c9b238f71a1659c3c6c63"}, "downloads": -1, "filename": "antispoofing.motion-1.1.0.zip", "has_sig": false, "md5_digest": "ce0ed56ed04a85b5f40c2147fb1fbb56", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 54069, "upload_time": "2013-04-04T11:36:04", "upload_time_iso_8601": "2013-04-04T11:36:04.719037Z", "url": "https://files.pythonhosted.org/packages/5f/9d/b318e09da032d67081b886a582dce1a9ec46fab82991126b9ce12294d202/antispoofing.motion-1.1.0.zip", "yanked": false}], "1.1.1": [{"comment_text": "", "digests": {"md5": "983dfdfabb5e887b6e15658f827373c9", "sha256": "ca06ae37d05f3c5fe3242a97a4bdd3bfdfda10ec2e2fb5068f9c4b19d1295cdb"}, "downloads": -1, "filename": "antispoofing.motion-1.1.1.zip", "has_sig": false, "md5_digest": "983dfdfabb5e887b6e15658f827373c9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 54190, "upload_time": "2013-07-19T12:15:26", "upload_time_iso_8601": "2013-07-19T12:15:26.039403Z", "url": "https://files.pythonhosted.org/packages/81/53/f019d79332b837451b266092e50f189e7233cc03a626f4423ededb06ab98/antispoofing.motion-1.1.1.zip", "yanked": false}], "2.0.1": [{"comment_text": "", "digests": {"md5": "38497b1aaed8ba01b7c034984b0c66ca", "sha256": "ffc26535f5bf5621d319fda1c8601a5541cf3af627e2fd9a8889169a17829094"}, "downloads": -1, "filename": "antispoofing.motion-2.0.1.zip", "has_sig": false, "md5_digest": "38497b1aaed8ba01b7c034984b0c66ca", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 53222, "upload_time": "2015-02-27T17:34:54", "upload_time_iso_8601": "2015-02-27T17:34:54.180934Z", "url": "https://files.pythonhosted.org/packages/db/b8/ec05192c480b308f40d6a48a3f43b26360701dc0e5dab1bc1b4edfea7c96/antispoofing.motion-2.0.1.zip", "yanked": false}], "2.0.3": [{"comment_text": "", "digests": {"md5": "a5999637ea3e5a58567e24f76810b136", "sha256": "5856a4322c2aea3f421ef3cc8e859a25df7217a3eaee01a879ef17a252502526"}, "downloads": -1, "filename": "antispoofing.motion-2.0.3.zip", "has_sig": false, "md5_digest": "a5999637ea3e5a58567e24f76810b136", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 53358, "upload_time": "2016-01-08T17:16:26", "upload_time_iso_8601": "2016-01-08T17:16:26.399085Z", "url": "https://files.pythonhosted.org/packages/38/8c/fba78339c3c9e38d9256e00bc12f27718b19a5363e94dc44e829ce48354f/antispoofing.motion-2.0.3.zip", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "a5999637ea3e5a58567e24f76810b136", "sha256": "5856a4322c2aea3f421ef3cc8e859a25df7217a3eaee01a879ef17a252502526"}, "downloads": -1, "filename": "antispoofing.motion-2.0.3.zip", "has_sig": false, "md5_digest": "a5999637ea3e5a58567e24f76810b136", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 53358, "upload_time": "2016-01-08T17:16:26", "upload_time_iso_8601": "2016-01-08T17:16:26.399085Z", "url": "https://files.pythonhosted.org/packages/38/8c/fba78339c3c9e38d9256e00bc12f27718b19a5363e94dc44e829ce48354f/antispoofing.motion-2.0.3.zip", "yanked": false}], "timestamp": "Thu May  7 18:17:59 2020"}