{"info": {"author": "Tim Luca Turan", "author_email": "timturan@web.de", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# SASA Database\nI don't think this is usable by anyone lese but it's a dependency to `sasa_stacker` and I wanted to package it separately. An explanation to the whole project can be found [here](https://github.com/TimLucaTuran/bachlor-arbeit/blob/master/bachlor-arbeit.pdf).\n\n## Usage\n`exl_to_sql.py -h`:\n<pre><code>\nexl_to_sql.py [-h] [-n SHEET_NUMBER] [-v] [-s] exl db\n\npositional arguments:\n  exl                   path to excel-file\n  db                    path to sqlite3-db\n\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -n SHEET_NUMBER, --sheet-number SHEET_NUMBER\n                        which excel-sheet to convert\n  -v, --verbose         verbose output\n  -s, --skip-existing   skipping rows already contained in the db\n</code></pre>\n\nWrites the excel file `exl` into the sqlite database `db`. Every row in the Excel sheet represents one simulation run of metasurfaces. The problem is with our current setup they are saved as one big `.mat` file but the `sasa_stacker` needs to access them and their parameters individually. This script assigns each single metasurface an address and saves its parameters in the db separately. Examples for the formating of the excel sheet can be found in `data/NN_smats.xlsx`.\n\n## Crawler\nThe Crawler class allows access to the db and loads the simulation data. The main functions are:\n\n\n### find_smat\n\n```python\nCrawler.find_smat(name, adress=None)\n```\nLoads the simulation data to `name`. If an adress is provided it only loads this single S-matrix.\n\n__Arguments__\n\n- __name__: string, name of the simulation in the database\n- __adress__: list, for example `[1,4,5,3]` the adress can also be found in the database\n\n----\n\n### find_smat_by_id\n\n```python\nCrawler.find_smat_by_id(id)\n```\nSame as above but takes the simulation id\n\n\n__Arguments__\n\n- __id__: int, simulation id found in the database\n\n----\n\n### extract_params\n\n```python\nCrawler.extract_params(id)\n```\nQueries meta_materials.db for all the parameters to the given ID.\n\n__Arguments__\n\n- __id__: int, simulation id found in the database\n\n\n__Returns__\n- __param_dict__: dict, contains the combined data from the simulations and geometry tables with coresponding names\n\n----", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/TimLucaTuran/sasa_db", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "sasa-db", "package_url": "https://pypi.org/project/sasa-db/", "platform": "", "project_url": "https://pypi.org/project/sasa-db/", "project_urls": {"Homepage": "https://github.com/TimLucaTuran/sasa_db"}, "release_url": "https://pypi.org/project/sasa-db/0.2/", "requires_dist": null, "requires_python": "", "summary": "Utility to convert Excel tables to a sqlite database and access the data", "version": "0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>SASA Database</h1>\n<p>I don't think this is usable by anyone lese but it's a dependency to <code>sasa_stacker</code> and I wanted to package it separately. An explanation to the whole project can be found <a href=\"https://github.com/TimLucaTuran/bachlor-arbeit/blob/master/bachlor-arbeit.pdf\" rel=\"nofollow\">here</a>.</p>\n<h2>Usage</h2>\n<p><code>exl_to_sql.py -h</code>:</p>\n<pre><code>\nexl_to_sql.py [-h] [-n SHEET_NUMBER] [-v] [-s] exl db\n\npositional arguments:\n  exl                   path to excel-file\n  db                    path to sqlite3-db\n\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -n SHEET_NUMBER, --sheet-number SHEET_NUMBER\n                        which excel-sheet to convert\n  -v, --verbose         verbose output\n  -s, --skip-existing   skipping rows already contained in the db\n</code></pre>\n<p>Writes the excel file <code>exl</code> into the sqlite database <code>db</code>. Every row in the Excel sheet represents one simulation run of metasurfaces. The problem is with our current setup they are saved as one big <code>.mat</code> file but the <code>sasa_stacker</code> needs to access them and their parameters individually. This script assigns each single metasurface an address and saves its parameters in the db separately. Examples for the formating of the excel sheet can be found in <code>data/NN_smats.xlsx</code>.</p>\n<h2>Crawler</h2>\n<p>The Crawler class allows access to the db and loads the simulation data. The main functions are:</p>\n<h3>find_smat</h3>\n<pre><span class=\"n\">Crawler</span><span class=\"o\">.</span><span class=\"n\">find_smat</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">adress</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">)</span>\n</pre>\n<p>Loads the simulation data to <code>name</code>. If an adress is provided it only loads this single S-matrix.</p>\n<p><strong>Arguments</strong></p>\n<ul>\n<li><strong>name</strong>: string, name of the simulation in the database</li>\n<li><strong>adress</strong>: list, for example <code>[1,4,5,3]</code> the adress can also be found in the database</li>\n</ul>\n<hr>\n<h3>find_smat_by_id</h3>\n<pre><span class=\"n\">Crawler</span><span class=\"o\">.</span><span class=\"n\">find_smat_by_id</span><span class=\"p\">(</span><span class=\"nb\">id</span><span class=\"p\">)</span>\n</pre>\n<p>Same as above but takes the simulation id</p>\n<p><strong>Arguments</strong></p>\n<ul>\n<li><strong>id</strong>: int, simulation id found in the database</li>\n</ul>\n<hr>\n<h3>extract_params</h3>\n<pre><span class=\"n\">Crawler</span><span class=\"o\">.</span><span class=\"n\">extract_params</span><span class=\"p\">(</span><span class=\"nb\">id</span><span class=\"p\">)</span>\n</pre>\n<p>Queries meta_materials.db for all the parameters to the given ID.</p>\n<p><strong>Arguments</strong></p>\n<ul>\n<li><strong>id</strong>: int, simulation id found in the database</li>\n</ul>\n<p><strong>Returns</strong></p>\n<ul>\n<li><strong>param_dict</strong>: dict, contains the combined data from the simulations and geometry tables with coresponding names</li>\n</ul>\n<hr>\n\n          </div>"}, "last_serial": 7023043, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "92b02a023e16d219839b7796c0a3e72d", "sha256": "f5b95490b70ca86620f2f97bd48e42ee76f2b40e55327fa52d47c84482638da5"}, "downloads": -1, "filename": "sasa_db-0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "92b02a023e16d219839b7796c0a3e72d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 11226, "upload_time": "2020-03-11T11:06:12", "upload_time_iso_8601": "2020-03-11T11:06:12.135019Z", "url": "https://files.pythonhosted.org/packages/37/aa/bd954bd2459da5b60101dc4f201ab2be0befe3d696f9d8572747380de4ed/sasa_db-0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9d8342f2fcba6e90f81676b71a1c29f7", "sha256": "fb049ff9e493ea292a9d90ba66baa81dbb6d4364e3a214fb5c90b771ad80e1f4"}, "downloads": -1, "filename": "sasa_db-0.1.tar.gz", "has_sig": false, "md5_digest": "9d8342f2fcba6e90f81676b71a1c29f7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 112476, "upload_time": "2020-03-11T11:06:15", "upload_time_iso_8601": "2020-03-11T11:06:15.270782Z", "url": "https://files.pythonhosted.org/packages/7d/0f/20a0a4c444b55384cf25f5a3f505f8615e0a0139efb1b42623f3c67a294e/sasa_db-0.1.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "b5db7e2c91026ff3f4021ded097db3c1", "sha256": "50a999b5edb45e6daa33a70f849c511f5c9213e0ba854010ceefec20aa7901c8"}, "downloads": -1, "filename": "sasa_db-0.2.tar.gz", "has_sig": false, "md5_digest": "b5db7e2c91026ff3f4021ded097db3c1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10627, "upload_time": "2020-04-15T08:28:37", "upload_time_iso_8601": "2020-04-15T08:28:37.641457Z", "url": "https://files.pythonhosted.org/packages/77/ac/774b63eb51eaf5bd8e3d37ea5dfe253281cd88291f894f7d5e11000891d1/sasa_db-0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "b5db7e2c91026ff3f4021ded097db3c1", "sha256": "50a999b5edb45e6daa33a70f849c511f5c9213e0ba854010ceefec20aa7901c8"}, "downloads": -1, "filename": "sasa_db-0.2.tar.gz", "has_sig": false, "md5_digest": "b5db7e2c91026ff3f4021ded097db3c1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10627, "upload_time": "2020-04-15T08:28:37", "upload_time_iso_8601": "2020-04-15T08:28:37.641457Z", "url": "https://files.pythonhosted.org/packages/77/ac/774b63eb51eaf5bd8e3d37ea5dfe253281cd88291f894f7d5e11000891d1/sasa_db-0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:58:34 2020"}