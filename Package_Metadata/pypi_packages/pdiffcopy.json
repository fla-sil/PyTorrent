{"info": {"author": "Peter Odding", "author_email": "peter@peterodding.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Environment :: Console", "Intended Audience :: Developers", "Intended Audience :: Information Technology", "Intended Audience :: System Administrators", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Operating System :: POSIX", "Operating System :: POSIX :: Linux", "Operating System :: Unix", "Programming Language :: Python", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: Implementation :: CPython", "Programming Language :: Python :: Implementation :: PyPy", "Topic :: Communications", "Topic :: Software Development", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules", "Topic :: System :: Shells", "Topic :: System :: Systems Administration", "Topic :: System :: System Shells", "Topic :: Terminals", "Topic :: Utilities"], "description": "Fast large file synchronization inspired by rsync\n=================================================\n\n.. image:: https://travis-ci.org/xolox/python-pdiffcopy.svg?branch=master\n   :target: https://travis-ci.org/xolox/python-pdiffcopy\n\n.. image:: https://coveralls.io/repos/xolox/python-pdiffcopy/badge.svg?branch=master\n   :target: https://coveralls.io/r/xolox/python-pdiffcopy?branch=master\n\nThe pdiffcopy program synchronizes large binary data files between Linux\nservers at blazing speeds by performing delta transfers and spreading its work\nover many CPU cores. It's currently tested on Python_ 2.7, 3.5+ and PyPy (2.7)\non Ubuntu Linux but is expected to work on most Linux systems.\n\n.. contents::\n   :local:\n\nStatus\n------\n\nAlthough the first prototype of pdiffcopy was developed back in June 2019 it\nwasn't until March 2020 that the first release was published as an open source\nproject.\n\n.. note:: This is an `alpha release`_, meaning it's not considered mature and\n          you may encounter bugs. As such, if you're going to use pdiffcopy,\n          I would suggest you to keep backups, be cautious and sanity check\n          your results.\n\nThere are lots of features and improvements I'd love to add but more\nimportantly the project needs to actually be used for a while before\nI'll consider changing the alpha label to beta or mature.\n\nInstallation\n------------\n\nThe pdiffcopy package is available on PyPI_ which means installation should be\nas simple as:\n\n.. code-block:: console\n\n   $ pip install 'pdiffcopy[client,server]'\n\nThere's actually a multitude of ways to install Python_ packages (e.g. the\n`per user site-packages directory`_, `virtual environments`_ or just installing\nsystem wide) and I have no intention of getting into that discussion here, so\nif this intimidates you then read up on your options before returning to these\ninstructions \ud83d\ude09.\n\nThe names between the square brackets (``client`` and ``server``) are called\n\"extras\" and they enable you to choose whether to install the client\ndependencies, server dependencies or both.\n\nCommand line\n------------\n\n.. A DRY solution to avoid duplication of the `pdiffcopy --help' text:\n..\n.. [[[cog\n.. from humanfriendly.usage import inject_usage\n.. inject_usage('pdiffcopy.cli')\n.. ]]]\n\n**Usage:** `pdiffcopy [OPTIONS] [SOURCE, TARGET]`\n\nSynchronize large binary data files between Linux servers at blazing speeds\nby performing delta transfers and spreading the work over many CPU cores.\n\nOne of the SOURCE and TARGET arguments is expected to be the pathname of a\nlocal file and the other argument is expected to be a URL that provides the\nlocation of a remote pdiffcopy server and a remote filename. File data will be\nread from SOURCE and written to TARGET.\n\nIf no positional arguments are given the server is started.\n\n**Supported options:**\n\n.. csv-table::\n   :header: Option, Description\n   :widths: 30, 70\n\n\n   \"``-b``, ``--block-size=BYTES``\",\"Customize the block size of the delta transfer. Can be a plain\n   integer number (bytes) or an expression like 5K, 1MiB, etc.\"\n   \"``-m``, ``--hash-method=NAME``\",\"Customize the hash method of the delta transfer (defaults to 'sha1'\n   but supports all hash methods provided by the Python hashlib module).\"\n   \"``-W``, ``--whole-file``\",\"Disable the delta transfer algorithm (skips computing\n   of hashing and downloads all blocks unconditionally).\"\n   \"``-c``, ``--concurrency=COUNT``\",Change the number of parallel block hash / copy operations.\n   \"``-n``, ``--dry-run``\",\"Scan for differences between the source and target file and report the\n   similarity index, but don't write any changed blocks to the target.\"\n   \"``-B``, ``--benchmark=COUNT``\",\"Evaluate the effectiveness of delta transfer by mutating the TARGET\n   file (which must be a local file) and resynchronizing its contents.\n   This process is repeated ``COUNT`` times, with varying similarity.\n   At the end an overview is printed.\"\n   \"``-l``, ``--listen=ADDRESS``\",Listen on the specified IP:PORT or PORT.\n   \"``-v``, ``--verbose``\",Increase logging verbosity (can be repeated).\n   \"``-q``, ``--quiet``\",Decrease logging verbosity (can be repeated).\n   \"``-h``, ``--help``\",Show this message and exit.\n\n.. [[[end]]]\n\nBenchmarks\n----------\n\nThe command line interface provides a simple way to evaluate the effectiveness\nof the delta transfer implementation and compare it against rsync_. The tables\nin the following sections are based on that benchmark.\n\n.. contents::\n   :local:\n\nLow concurrency\n~~~~~~~~~~~~~~~\n\n:Concurrency: 6 processes on 4 CPU cores\n:Disks: `Magnetic storage`_ (slow)\n:Filesize: 1.79 GiB\n\nThe following table shows the results of the benchmark on a 1.79 GiB\ndatafile that's synchronized between two bare metal servers that each\nhave four CPU cores and spinning disks, where pdiffcopy was run with\na concurrency of six [#]_:\n\n=====  =========  =============  =========================\nDelta  Data size  pdiffcopy      rsync\n=====  =========  =============  =========================\n  10%    183 MiB   3.20 seconds              38.55 seconds\n  20%    366 MiB   4.15 seconds              44.33 seconds\n  30%    549 MiB   5.17 seconds              49.63 seconds\n  40%    732 MiB   6.09 seconds              53.74 seconds\n  50%    916 MiB   6.99 seconds              57.49 seconds\n  60%   1.07 GiB   8.06 seconds  1 minute and 0.97 seconds\n  70%   1.25 GiB   9.06 seconds  1 minute and 2.38 seconds\n  80%   1.43 GiB  10.12 seconds  1 minute and 4.20 seconds\n  90%   1.61 GiB  10.89 seconds  1 minute and 3.80 seconds\n 100%   1.79 GiB  12.05 seconds  1 minute and 4.14 seconds\n=====  =========  =============  =========================\n\n.. [#] Allocating more processes than there are CPU cores available can make\n       sense when the majority of the time spent by those processes is waiting\n       for I/O (this definitely applies to pdiffcopy).\n\nHigh concurrency\n~~~~~~~~~~~~~~~~\n\n:Concurrency: 10 processes on 48 CPU cores\n:Disks: NVMe_ (fast)\n:Filesize: 5.5 GiB\n\nHere's a benchmark based on a 5.5 GB datafile that's synchronized between two\nbare metal servers that each have 48 CPU cores and high-end NVMe_ disks, where\npdiffcopy was run with a concurrency of ten:\n\n=====  =========  =============  ==========================\nDelta  Data size  pdiffcopy      rsync\n=====  =========  =============  ==========================\n  10%    562 MiB   4.23 seconds               49.96 seconds\n  20%   1.10 GiB   6.76 seconds  1 minute and  2.38 seconds\n  30%   1.65 GiB   9.43 seconds  1 minute and 13.73 seconds\n  40%   2.20 GiB  12.41 seconds  1 minute and 19.67 seconds\n  50%   2.75 GiB  14.54 seconds  1 minute and 25.86 seconds\n  60%   3.29 GiB  17.21 seconds  1 minute and 26.97 seconds\n  70%   3.84 GiB  19.79 seconds  1 minute and 27.46 seconds\n  80%   4.39 GiB  23.10 seconds  1 minute and 26.15 seconds\n  90%   4.94 GiB  25.19 seconds  1 minute and 21.96 seconds\n 100%   5.43 GiB  27.82 seconds  1 minute and 19.17 seconds\n=====  =========  =============  ==========================\n\nThis benchmark shows how well pdiffcopy can scale up its performance by running\non a large number of CPU cores. Notice how the smaller the delta is, the bigger\nthe edge is that pdiffcopy has over rsync_? This is because pdiffcopy computes\nthe differences between the local and remote file using many CPU cores at the\nsame time. This operation requires only reading, and that parallelizes\nsurprisingly well on modern NVMe_ disks.\n\nSilly concurrency\n~~~~~~~~~~~~~~~~~\n\n:Concurrency: 20 processes on 48 CPU cores\n:Disks: NVMe_ (fast)\n:Filesize: 5.5 GiB\n\nIn case you looked at the high concurrency benchmark above, noticed the large\nnumber of CPU cores available and wondered whether increasing the concurrency\nfurther would make a difference, this section is for you \ud83d\ude09. Having taken the\neffort of developing pdiffcopy and enabling it to run on many CPU cores I was\ncurious myself so I reran the high concurrency benchmark using 20 processes\ninstead of 10. Here are the results:\n\n=====  =========  =============  ==========================\nDelta  Data size  pdiffcopy      rsync\n=====  =========  =============  ==========================\n  10%    562 MiB   3.80 seconds               49.71 seconds\n  20%   1.10 GiB   6.25 seconds  1 minute and  3.37 seconds\n  30%   1.65 GiB   8.90 seconds  1 minute and 12.40 seconds\n  40%   2.20 GiB  11.44 seconds  1 minute and 19.57 seconds\n  50%   2.75 GiB  14.21 seconds  1 minute and 25.43 seconds\n  60%   3.29 GiB  16.45 seconds  1 minute and 28.12 seconds\n  70%   3.84 GiB  19.05 seconds  1 minute and 28.34 seconds\n  80%   4.39 GiB  21.95 seconds  1 minute and 25.49 seconds\n  90%   4.94 GiB  24.60 seconds  1 minute and 22.27 seconds\n 100%   5.43 GiB  26.42 seconds  1 minute and 18.73 seconds\n=====  =========  =============  ==========================\n\nAs you can see increasing the concurrency from 10 to 20 does make the benchmark\na bit faster, however the margin is so small that it's hardly worth bothering.\nI interpret this to mean that the NVMe_ disks on these servers can be more or\nless saturated using 8--12 writer processes.\n\n.. note:: In the end the question is how many CPU cores it takes to saturate\n          your storage infrastructure. This can be determined through\n          experimentation, which the benchmark can assist with. There are no\n          fundamental reasons why 30 or even 50 processes couldn't work well,\n          as long as your storage infrastructure can keep up...\n\nLimitations\n-----------\n\nWhile inspired by rsync_ the goal definitely isn't feature parity with rsync_.\nRight now only single files can be transferred and only the file data is\ncopied, not the metadata. It's a proof of concept that works but is limited.\nWhile I'm tempted to add support for synchronization of directory trees and\nfile metadata just because its convenient, it's definitely not my intention to\ncompete with rsync_ in the domain of synchronizing large directory trees,\nbecause I would most likely fail.\n\nError handling is currently very limited and interrupting the program using\nControl-C may get you stuck with an angry pool of multiprocessing_ workers that\nrefuse to shut down \ud83d\ude1d. In all seriousness, hitting Control-C a couple of times\nshould break out of it, otherwise try Control-\\\\ (that's a backslash, it should\nsend a QUIT signal).\n\nHistory\n-------\n\nIn June 2019 I found myself in a situation where I wanted to quickly\nsynchronize large binary datafiles (a small set of very large MySQL_\n``*.ibd`` files totaling several hundred gigabytes) using the abundant\ncomputing resources available to me (48 CPU cores, NVMe_ disks,\nbonded network interfaces, you name it \ud83d\ude09).\n\nI spent quite a bit of time experimenting with running many rsync_ processes in\nparallel, but the small number of very large files was \"clogging up the pipe\"\nso to speak, no matter what I did. This was how I realized that rsync_ was a\nreally poor fit, which was a disappointment for me because rsync_ has long been\none my go-to programs for ad hoc problem solving on Linux servers \ud83d\ude42.\n\nIn any case I decided to prove to myself that the hardware available to me\ncould do much more than what rsync_ was getting me and after a weekend of\nhacking on a prototype I had something that could outperform rsync_ even though\nit was written in Python_ and used HTTP_ as a transport \ud83d\ude01. During this weekend\nI decided that my prototype was worthy of being published as an open source\nproject, however it wasn't until months later that I actually found the time to\ndo so.\n\nAbout the name\n--------------\n\nThe name pdiffcopy is intended as a (possibly somewhat obscure) abbreviation of\n\"Parallel Differential Copy\":\n\n- Parallel because it's intended run on many CPU cores.\n- Differential because of the delta transfer mechanism.\n\nBut mostly I just needed a short, unique name like rsync_ so that searching for\nthis project will actually turn up this project instead of a dozen others \ud83d\ude07.\n\nContact\n-------\n\nThe latest version of pdiffcopy is available on PyPI_ and GitHub_. The\ndocumentation is hosted on `Read the Docs`_ and includes a changelog_. For bug\nreports please create an issue on GitHub_. If you have questions, suggestions,\netc. feel free to send me an e-mail at `peter@peterodding.com`_.\n\nLicense\n-------\n\nThis software is licensed under the `MIT license`_.\n\n\u00a9 2020 Peter Odding.\n\n.. External references:\n.. _alpha release: https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha\n.. _changelog: https://pdiffcopy.readthedocs.io/en/latest/changelog.html\n.. _GitHub: https://github.com/xolox/python-pdiffcopy\n.. _HTTP: https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol\n.. _Magnetic storage: https://en.wikipedia.org/wiki/Hard_disk_drive\n.. _MIT license: http://en.wikipedia.org/wiki/MIT_License\n.. _multiprocessing: https://docs.python.org/library/multiprocessing.html\n.. _MySQL: https://en.wikipedia.org/wiki/MySQL\n.. _NVMe: https://en.wikipedia.org/wiki/NVM_Express\n.. _per user site-packages directory: https://www.python.org/dev/peps/pep-0370/\n.. _peter@peterodding.com: peter@peterodding.com\n.. _PyPI: https://pypi.org/project/pdiffcopy\n.. _Python: https://en.wikipedia.org/wiki/Python_(programming_language)\n.. _Read the Docs: https://pdiffcopy.readthedocs.io/\n.. _rsync: https://en.wikipedia.org/wiki/Rsync\n.. _virtual environments: http://docs.python-guide.org/en/latest/dev/virtualenvs/\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://pdiffcopy.readthedocs.io", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "pdiffcopy", "package_url": "https://pypi.org/project/pdiffcopy/", "platform": "", "project_url": "https://pypi.org/project/pdiffcopy/", "project_urls": {"Homepage": "https://pdiffcopy.readthedocs.io"}, "release_url": "https://pypi.org/project/pdiffcopy/1.0.1/", "requires_dist": ["coloredlogs (>=10.0)", "humanfriendly (>=8.1)", "property-manager (>=3.0)", "six (>=1.12.0)", "requests (>=2.22.0) ; extra == 'client'", "flask (>=1.0.3) ; extra == 'server'", "gunicorn (>=19.9.0) ; extra == 'server'"], "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*", "summary": "Fast large file synchronization inspired by rsync", "version": "1.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://travis-ci.org/xolox/python-pdiffcopy\" rel=\"nofollow\"><img alt=\"https://travis-ci.org/xolox/python-pdiffcopy.svg?branch=master\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9dc23b9761f9ac0efa0845748008b09c2ad5606e/68747470733a2f2f7472617669732d63692e6f72672f786f6c6f782f707974686f6e2d7064696666636f70792e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://coveralls.io/r/xolox/python-pdiffcopy?branch=master\" rel=\"nofollow\"><img alt=\"https://coveralls.io/repos/xolox/python-pdiffcopy/badge.svg?branch=master\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b85416cf30629458124dda3896ab37ec73190b56/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f786f6c6f782f707974686f6e2d7064696666636f70792f62616467652e7376673f6272616e63683d6d6173746572\"></a>\n<p>The pdiffcopy program synchronizes large binary data files between Linux\nservers at blazing speeds by performing delta transfers and spreading its work\nover many CPU cores. It\u2019s currently tested on <a href=\"https://en.wikipedia.org/wiki/Python_(programming_language)\" rel=\"nofollow\">Python</a> 2.7, 3.5+ and PyPy (2.7)\non Ubuntu Linux but is expected to work on most Linux systems.</p>\n<div id=\"contents\">\n<ul>\n<li><a href=\"#status\" id=\"id4\" rel=\"nofollow\">Status</a></li>\n<li><a href=\"#installation\" id=\"id5\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#command-line\" id=\"id6\" rel=\"nofollow\">Command line</a></li>\n<li><a href=\"#benchmarks\" id=\"id7\" rel=\"nofollow\">Benchmarks</a><ul>\n<li><a href=\"#low-concurrency\" id=\"id8\" rel=\"nofollow\">Low concurrency</a></li>\n<li><a href=\"#high-concurrency\" id=\"id9\" rel=\"nofollow\">High concurrency</a></li>\n<li><a href=\"#silly-concurrency\" id=\"id10\" rel=\"nofollow\">Silly concurrency</a></li>\n</ul>\n</li>\n<li><a href=\"#limitations\" id=\"id11\" rel=\"nofollow\">Limitations</a></li>\n<li><a href=\"#history\" id=\"id12\" rel=\"nofollow\">History</a></li>\n<li><a href=\"#about-the-name\" id=\"id13\" rel=\"nofollow\">About the name</a></li>\n<li><a href=\"#contact\" id=\"id14\" rel=\"nofollow\">Contact</a></li>\n<li><a href=\"#license\" id=\"id15\" rel=\"nofollow\">License</a></li>\n</ul>\n</div>\n<div id=\"status\">\n<h2><a href=\"#id4\" rel=\"nofollow\">Status</a></h2>\n<p>Although the first prototype of pdiffcopy was developed back in June 2019 it\nwasn\u2019t until March 2020 that the first release was published as an open source\nproject.</p>\n<div>\n<p>Note</p>\n<p>This is an <a href=\"https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha\" rel=\"nofollow\">alpha release</a>, meaning it\u2019s not considered mature and\nyou may encounter bugs. As such, if you\u2019re going to use pdiffcopy,\nI would suggest you to keep backups, be cautious and sanity check\nyour results.</p>\n</div>\n<p>There are lots of features and improvements I\u2019d love to add but more\nimportantly the project needs to actually be used for a while before\nI\u2019ll consider changing the alpha label to beta or mature.</p>\n</div>\n<div id=\"installation\">\n<h2><a href=\"#id5\" rel=\"nofollow\">Installation</a></h2>\n<p>The pdiffcopy package is available on <a href=\"https://pypi.org/project/pdiffcopy\" rel=\"nofollow\">PyPI</a> which means installation should be\nas simple as:</p>\n<pre><span class=\"gp\">$</span> pip install <span class=\"s1\">'pdiffcopy[client,server]'</span>\n</pre>\n<p>There\u2019s actually a multitude of ways to install <a href=\"https://en.wikipedia.org/wiki/Python_(programming_language)\" rel=\"nofollow\">Python</a> packages (e.g. the\n<a href=\"https://www.python.org/dev/peps/pep-0370/\" rel=\"nofollow\">per user site-packages directory</a>, <a href=\"http://docs.python-guide.org/en/latest/dev/virtualenvs/\" rel=\"nofollow\">virtual environments</a> or just installing\nsystem wide) and I have no intention of getting into that discussion here, so\nif this intimidates you then read up on your options before returning to these\ninstructions \ud83d\ude09.</p>\n<p>The names between the square brackets (<tt>client</tt> and <tt>server</tt>) are called\n\u201cextras\u201d and they enable you to choose whether to install the client\ndependencies, server dependencies or both.</p>\n</div>\n<div id=\"command-line\">\n<h2><a href=\"#id6\" rel=\"nofollow\">Command line</a></h2>\n<p><strong>Usage:</strong> <cite>pdiffcopy [OPTIONS] [SOURCE, TARGET]</cite></p>\n<p>Synchronize large binary data files between Linux servers at blazing speeds\nby performing delta transfers and spreading the work over many CPU cores.</p>\n<p>One of the SOURCE and TARGET arguments is expected to be the pathname of a\nlocal file and the other argument is expected to be a URL that provides the\nlocation of a remote pdiffcopy server and a remote filename. File data will be\nread from SOURCE and written to TARGET.</p>\n<p>If no positional arguments are given the server is started.</p>\n<p><strong>Supported options:</strong></p>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Option</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><tt><span class=\"pre\">-b</span></tt>, <tt><span class=\"pre\">--block-size=BYTES</span></tt></td>\n<td>Customize the block size of the delta transfer. Can be a plain\ninteger number (bytes) or an expression like 5K, 1MiB, etc.</td>\n</tr>\n<tr><td><tt><span class=\"pre\">-m</span></tt>, <tt><span class=\"pre\">--hash-method=NAME</span></tt></td>\n<td>Customize the hash method of the delta transfer (defaults to \u2018sha1\u2019\nbut supports all hash methods provided by the Python hashlib module).</td>\n</tr>\n<tr><td><tt><span class=\"pre\">-W</span></tt>, <tt><span class=\"pre\">--whole-file</span></tt></td>\n<td>Disable the delta transfer algorithm (skips computing\nof hashing and downloads all blocks unconditionally).</td>\n</tr>\n<tr><td><tt><span class=\"pre\">-c</span></tt>, <tt><span class=\"pre\">--concurrency=COUNT</span></tt></td>\n<td>Change the number of parallel block hash / copy operations.</td>\n</tr>\n<tr><td><tt><span class=\"pre\">-n</span></tt>, <tt><span class=\"pre\">--dry-run</span></tt></td>\n<td>Scan for differences between the source and target file and report the\nsimilarity index, but don\u2019t write any changed blocks to the target.</td>\n</tr>\n<tr><td><tt><span class=\"pre\">-B</span></tt>, <tt><span class=\"pre\">--benchmark=COUNT</span></tt></td>\n<td>Evaluate the effectiveness of delta transfer by mutating the TARGET\nfile (which must be a local file) and resynchronizing its contents.\nThis process is repeated <tt>COUNT</tt> times, with varying similarity.\nAt the end an overview is printed.</td>\n</tr>\n<tr><td><tt><span class=\"pre\">-l</span></tt>, <tt><span class=\"pre\">--listen=ADDRESS</span></tt></td>\n<td>Listen on the specified IP:PORT or PORT.</td>\n</tr>\n<tr><td><tt><span class=\"pre\">-v</span></tt>, <tt><span class=\"pre\">--verbose</span></tt></td>\n<td>Increase logging verbosity (can be repeated).</td>\n</tr>\n<tr><td><tt><span class=\"pre\">-q</span></tt>, <tt><span class=\"pre\">--quiet</span></tt></td>\n<td>Decrease logging verbosity (can be repeated).</td>\n</tr>\n<tr><td><tt><span class=\"pre\">-h</span></tt>, <tt><span class=\"pre\">--help</span></tt></td>\n<td>Show this message and exit.</td>\n</tr>\n</tbody>\n</table>\n</div>\n<div id=\"benchmarks\">\n<h2><a href=\"#id7\" rel=\"nofollow\">Benchmarks</a></h2>\n<p>The command line interface provides a simple way to evaluate the effectiveness\nof the delta transfer implementation and compare it against <a href=\"https://en.wikipedia.org/wiki/Rsync\" rel=\"nofollow\">rsync</a>. The tables\nin the following sections are based on that benchmark.</p>\n<div id=\"id1\">\n<ul>\n<li><a href=\"#low-concurrency\" id=\"id16\" rel=\"nofollow\">Low concurrency</a></li>\n<li><a href=\"#high-concurrency\" id=\"id17\" rel=\"nofollow\">High concurrency</a></li>\n<li><a href=\"#silly-concurrency\" id=\"id18\" rel=\"nofollow\">Silly concurrency</a></li>\n</ul>\n</div>\n<div id=\"low-concurrency\">\n<h3><a href=\"#id16\" rel=\"nofollow\">Low concurrency</a></h3>\n<table>\n<col>\n<col>\n<tbody>\n<tr><th>Concurrency:</th><td>6 processes on 4 CPU cores</td>\n</tr>\n<tr><th>Disks:</th><td><a href=\"https://en.wikipedia.org/wiki/Hard_disk_drive\" rel=\"nofollow\">Magnetic storage</a> (slow)</td>\n</tr>\n<tr><th>Filesize:</th><td>1.79 GiB</td>\n</tr>\n</tbody>\n</table>\n<p>The following table shows the results of the benchmark on a 1.79 GiB\ndatafile that\u2019s synchronized between two bare metal servers that each\nhave four CPU cores and spinning disks, where pdiffcopy was run with\na concurrency of six <a href=\"#id3\" id=\"id2\" rel=\"nofollow\">[1]</a>:</p>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Delta</th>\n<th>Data size</th>\n<th>pdiffcopy</th>\n<th>rsync</th>\n</tr>\n</thead>\n<tbody>\n<tr><td>10%</td>\n<td>183 MiB</td>\n<td>3.20 seconds</td>\n<td>38.55 seconds</td>\n</tr>\n<tr><td>20%</td>\n<td>366 MiB</td>\n<td>4.15 seconds</td>\n<td>44.33 seconds</td>\n</tr>\n<tr><td>30%</td>\n<td>549 MiB</td>\n<td>5.17 seconds</td>\n<td>49.63 seconds</td>\n</tr>\n<tr><td>40%</td>\n<td>732 MiB</td>\n<td>6.09 seconds</td>\n<td>53.74 seconds</td>\n</tr>\n<tr><td>50%</td>\n<td>916 MiB</td>\n<td>6.99 seconds</td>\n<td>57.49 seconds</td>\n</tr>\n<tr><td>60%</td>\n<td>1.07 GiB</td>\n<td>8.06 seconds</td>\n<td>1 minute and 0.97 seconds</td>\n</tr>\n<tr><td>70%</td>\n<td>1.25 GiB</td>\n<td>9.06 seconds</td>\n<td>1 minute and 2.38 seconds</td>\n</tr>\n<tr><td>80%</td>\n<td>1.43 GiB</td>\n<td>10.12 seconds</td>\n<td>1 minute and 4.20 seconds</td>\n</tr>\n<tr><td>90%</td>\n<td>1.61 GiB</td>\n<td>10.89 seconds</td>\n<td>1 minute and 3.80 seconds</td>\n</tr>\n<tr><td>100%</td>\n<td>1.79 GiB</td>\n<td>12.05 seconds</td>\n<td>1 minute and 4.14 seconds</td>\n</tr>\n</tbody>\n</table>\n<table id=\"id3\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id2\" rel=\"nofollow\">[1]</a></td><td>Allocating more processes than there are CPU cores available can make\nsense when the majority of the time spent by those processes is waiting\nfor I/O (this definitely applies to pdiffcopy).</td></tr>\n</tbody>\n</table>\n</div>\n<div id=\"high-concurrency\">\n<h3><a href=\"#id17\" rel=\"nofollow\">High concurrency</a></h3>\n<table>\n<col>\n<col>\n<tbody>\n<tr><th>Concurrency:</th><td>10 processes on 48 CPU cores</td>\n</tr>\n<tr><th>Disks:</th><td><a href=\"https://en.wikipedia.org/wiki/NVM_Express\" rel=\"nofollow\">NVMe</a> (fast)</td>\n</tr>\n<tr><th>Filesize:</th><td>5.5 GiB</td>\n</tr>\n</tbody>\n</table>\n<p>Here\u2019s a benchmark based on a 5.5 GB datafile that\u2019s synchronized between two\nbare metal servers that each have 48 CPU cores and high-end <a href=\"https://en.wikipedia.org/wiki/NVM_Express\" rel=\"nofollow\">NVMe</a> disks, where\npdiffcopy was run with a concurrency of ten:</p>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Delta</th>\n<th>Data size</th>\n<th>pdiffcopy</th>\n<th>rsync</th>\n</tr>\n</thead>\n<tbody>\n<tr><td>10%</td>\n<td>562 MiB</td>\n<td>4.23 seconds</td>\n<td>49.96 seconds</td>\n</tr>\n<tr><td>20%</td>\n<td>1.10 GiB</td>\n<td>6.76 seconds</td>\n<td>1 minute and  2.38 seconds</td>\n</tr>\n<tr><td>30%</td>\n<td>1.65 GiB</td>\n<td>9.43 seconds</td>\n<td>1 minute and 13.73 seconds</td>\n</tr>\n<tr><td>40%</td>\n<td>2.20 GiB</td>\n<td>12.41 seconds</td>\n<td>1 minute and 19.67 seconds</td>\n</tr>\n<tr><td>50%</td>\n<td>2.75 GiB</td>\n<td>14.54 seconds</td>\n<td>1 minute and 25.86 seconds</td>\n</tr>\n<tr><td>60%</td>\n<td>3.29 GiB</td>\n<td>17.21 seconds</td>\n<td>1 minute and 26.97 seconds</td>\n</tr>\n<tr><td>70%</td>\n<td>3.84 GiB</td>\n<td>19.79 seconds</td>\n<td>1 minute and 27.46 seconds</td>\n</tr>\n<tr><td>80%</td>\n<td>4.39 GiB</td>\n<td>23.10 seconds</td>\n<td>1 minute and 26.15 seconds</td>\n</tr>\n<tr><td>90%</td>\n<td>4.94 GiB</td>\n<td>25.19 seconds</td>\n<td>1 minute and 21.96 seconds</td>\n</tr>\n<tr><td>100%</td>\n<td>5.43 GiB</td>\n<td>27.82 seconds</td>\n<td>1 minute and 19.17 seconds</td>\n</tr>\n</tbody>\n</table>\n<p>This benchmark shows how well pdiffcopy can scale up its performance by running\non a large number of CPU cores. Notice how the smaller the delta is, the bigger\nthe edge is that pdiffcopy has over <a href=\"https://en.wikipedia.org/wiki/Rsync\" rel=\"nofollow\">rsync</a>? This is because pdiffcopy computes\nthe differences between the local and remote file using many CPU cores at the\nsame time. This operation requires only reading, and that parallelizes\nsurprisingly well on modern <a href=\"https://en.wikipedia.org/wiki/NVM_Express\" rel=\"nofollow\">NVMe</a> disks.</p>\n</div>\n<div id=\"silly-concurrency\">\n<h3><a href=\"#id18\" rel=\"nofollow\">Silly concurrency</a></h3>\n<table>\n<col>\n<col>\n<tbody>\n<tr><th>Concurrency:</th><td>20 processes on 48 CPU cores</td>\n</tr>\n<tr><th>Disks:</th><td><a href=\"https://en.wikipedia.org/wiki/NVM_Express\" rel=\"nofollow\">NVMe</a> (fast)</td>\n</tr>\n<tr><th>Filesize:</th><td>5.5 GiB</td>\n</tr>\n</tbody>\n</table>\n<p>In case you looked at the high concurrency benchmark above, noticed the large\nnumber of CPU cores available and wondered whether increasing the concurrency\nfurther would make a difference, this section is for you \ud83d\ude09. Having taken the\neffort of developing pdiffcopy and enabling it to run on many CPU cores I was\ncurious myself so I reran the high concurrency benchmark using 20 processes\ninstead of 10. Here are the results:</p>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Delta</th>\n<th>Data size</th>\n<th>pdiffcopy</th>\n<th>rsync</th>\n</tr>\n</thead>\n<tbody>\n<tr><td>10%</td>\n<td>562 MiB</td>\n<td>3.80 seconds</td>\n<td>49.71 seconds</td>\n</tr>\n<tr><td>20%</td>\n<td>1.10 GiB</td>\n<td>6.25 seconds</td>\n<td>1 minute and  3.37 seconds</td>\n</tr>\n<tr><td>30%</td>\n<td>1.65 GiB</td>\n<td>8.90 seconds</td>\n<td>1 minute and 12.40 seconds</td>\n</tr>\n<tr><td>40%</td>\n<td>2.20 GiB</td>\n<td>11.44 seconds</td>\n<td>1 minute and 19.57 seconds</td>\n</tr>\n<tr><td>50%</td>\n<td>2.75 GiB</td>\n<td>14.21 seconds</td>\n<td>1 minute and 25.43 seconds</td>\n</tr>\n<tr><td>60%</td>\n<td>3.29 GiB</td>\n<td>16.45 seconds</td>\n<td>1 minute and 28.12 seconds</td>\n</tr>\n<tr><td>70%</td>\n<td>3.84 GiB</td>\n<td>19.05 seconds</td>\n<td>1 minute and 28.34 seconds</td>\n</tr>\n<tr><td>80%</td>\n<td>4.39 GiB</td>\n<td>21.95 seconds</td>\n<td>1 minute and 25.49 seconds</td>\n</tr>\n<tr><td>90%</td>\n<td>4.94 GiB</td>\n<td>24.60 seconds</td>\n<td>1 minute and 22.27 seconds</td>\n</tr>\n<tr><td>100%</td>\n<td>5.43 GiB</td>\n<td>26.42 seconds</td>\n<td>1 minute and 18.73 seconds</td>\n</tr>\n</tbody>\n</table>\n<p>As you can see increasing the concurrency from 10 to 20 does make the benchmark\na bit faster, however the margin is so small that it\u2019s hardly worth bothering.\nI interpret this to mean that the <a href=\"https://en.wikipedia.org/wiki/NVM_Express\" rel=\"nofollow\">NVMe</a> disks on these servers can be more or\nless saturated using 8\u201312 writer processes.</p>\n<div>\n<p>Note</p>\n<p>In the end the question is how many CPU cores it takes to saturate\nyour storage infrastructure. This can be determined through\nexperimentation, which the benchmark can assist with. There are no\nfundamental reasons why 30 or even 50 processes couldn\u2019t work well,\nas long as your storage infrastructure can keep up\u2026</p>\n</div>\n</div>\n</div>\n<div id=\"limitations\">\n<h2><a href=\"#id11\" rel=\"nofollow\">Limitations</a></h2>\n<p>While inspired by <a href=\"https://en.wikipedia.org/wiki/Rsync\" rel=\"nofollow\">rsync</a> the goal definitely isn\u2019t feature parity with <a href=\"https://en.wikipedia.org/wiki/Rsync\" rel=\"nofollow\">rsync</a>.\nRight now only single files can be transferred and only the file data is\ncopied, not the metadata. It\u2019s a proof of concept that works but is limited.\nWhile I\u2019m tempted to add support for synchronization of directory trees and\nfile metadata just because its convenient, it\u2019s definitely not my intention to\ncompete with <a href=\"https://en.wikipedia.org/wiki/Rsync\" rel=\"nofollow\">rsync</a> in the domain of synchronizing large directory trees,\nbecause I would most likely fail.</p>\n<p>Error handling is currently very limited and interrupting the program using\nControl-C may get you stuck with an angry pool of <a href=\"https://docs.python.org/library/multiprocessing.html\" rel=\"nofollow\">multiprocessing</a> workers that\nrefuse to shut down \ud83d\ude1d. In all seriousness, hitting Control-C a couple of times\nshould break out of it, otherwise try Control-\\ (that\u2019s a backslash, it should\nsend a QUIT signal).</p>\n</div>\n<div id=\"history\">\n<h2><a href=\"#id12\" rel=\"nofollow\">History</a></h2>\n<p>In June 2019 I found myself in a situation where I wanted to quickly\nsynchronize large binary datafiles (a small set of very large <a href=\"https://en.wikipedia.org/wiki/MySQL\" rel=\"nofollow\">MySQL</a>\n<tt>*.ibd</tt> files totaling several hundred gigabytes) using the abundant\ncomputing resources available to me (48 CPU cores, <a href=\"https://en.wikipedia.org/wiki/NVM_Express\" rel=\"nofollow\">NVMe</a> disks,\nbonded network interfaces, you name it \ud83d\ude09).</p>\n<p>I spent quite a bit of time experimenting with running many <a href=\"https://en.wikipedia.org/wiki/Rsync\" rel=\"nofollow\">rsync</a> processes in\nparallel, but the small number of very large files was \u201cclogging up the pipe\u201d\nso to speak, no matter what I did. This was how I realized that <a href=\"https://en.wikipedia.org/wiki/Rsync\" rel=\"nofollow\">rsync</a> was a\nreally poor fit, which was a disappointment for me because <a href=\"https://en.wikipedia.org/wiki/Rsync\" rel=\"nofollow\">rsync</a> has long been\none my go-to programs for ad hoc problem solving on Linux servers \ud83d\ude42.</p>\n<p>In any case I decided to prove to myself that the hardware available to me\ncould do much more than what <a href=\"https://en.wikipedia.org/wiki/Rsync\" rel=\"nofollow\">rsync</a> was getting me and after a weekend of\nhacking on a prototype I had something that could outperform <a href=\"https://en.wikipedia.org/wiki/Rsync\" rel=\"nofollow\">rsync</a> even though\nit was written in <a href=\"https://en.wikipedia.org/wiki/Python_(programming_language)\" rel=\"nofollow\">Python</a> and used <a href=\"https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol\" rel=\"nofollow\">HTTP</a> as a transport \ud83d\ude01. During this weekend\nI decided that my prototype was worthy of being published as an open source\nproject, however it wasn\u2019t until months later that I actually found the time to\ndo so.</p>\n</div>\n<div id=\"about-the-name\">\n<h2><a href=\"#id13\" rel=\"nofollow\">About the name</a></h2>\n<p>The name pdiffcopy is intended as a (possibly somewhat obscure) abbreviation of\n\u201cParallel Differential Copy\u201d:</p>\n<ul>\n<li>Parallel because it\u2019s intended run on many CPU cores.</li>\n<li>Differential because of the delta transfer mechanism.</li>\n</ul>\n<p>But mostly I just needed a short, unique name like <a href=\"https://en.wikipedia.org/wiki/Rsync\" rel=\"nofollow\">rsync</a> so that searching for\nthis project will actually turn up this project instead of a dozen others \ud83d\ude07.</p>\n</div>\n<div id=\"contact\">\n<h2><a href=\"#id14\" rel=\"nofollow\">Contact</a></h2>\n<p>The latest version of pdiffcopy is available on <a href=\"https://pypi.org/project/pdiffcopy\" rel=\"nofollow\">PyPI</a> and <a href=\"https://github.com/xolox/python-pdiffcopy\" rel=\"nofollow\">GitHub</a>. The\ndocumentation is hosted on <a href=\"https://pdiffcopy.readthedocs.io/\" rel=\"nofollow\">Read the Docs</a> and includes a <a href=\"https://pdiffcopy.readthedocs.io/en/latest/changelog.html\" rel=\"nofollow\">changelog</a>. For bug\nreports please create an issue on <a href=\"https://github.com/xolox/python-pdiffcopy\" rel=\"nofollow\">GitHub</a>. If you have questions, suggestions,\netc. feel free to send me an e-mail at <a href=\"mailto:peter%40peterodding.com\">peter<span>@</span>peterodding<span>.</span>com</a>.</p>\n</div>\n<div id=\"license\">\n<h2><a href=\"#id15\" rel=\"nofollow\">License</a></h2>\n<p>This software is licensed under the <a href=\"http://en.wikipedia.org/wiki/MIT_License\" rel=\"nofollow\">MIT license</a>.</p>\n<p>\u00a9 2020 Peter Odding.</p>\n</div>\n\n          </div>"}, "last_serial": 6765762, "releases": {"1.0": [{"comment_text": "", "digests": {"md5": "4e0ad7c7fd0f12101d194a058eb5a714", "sha256": "367a9e9debaea151cfc50adddf403a670e29cb0f377b000353e50bfe96f74fda"}, "downloads": -1, "filename": "pdiffcopy-1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "4e0ad7c7fd0f12101d194a058eb5a714", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*", "size": 26689, "upload_time": "2020-03-06T23:19:19", "upload_time_iso_8601": "2020-03-06T23:19:19.228929Z", "url": "https://files.pythonhosted.org/packages/db/24/cfee97fd8a0365f0b79e830354f08900e1c5f24ce7c5ad1208450a582841/pdiffcopy-1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9adc148edf908b96e0768646d5214afd", "sha256": "197c6c93b726347da1a302f873367db6f8faf944a2789603052d6c23b2f6fc77"}, "downloads": -1, "filename": "pdiffcopy-1.0.tar.gz", "has_sig": false, "md5_digest": "9adc148edf908b96e0768646d5214afd", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*", "size": 29550, "upload_time": "2020-03-06T23:19:22", "upload_time_iso_8601": "2020-03-06T23:19:22.247040Z", "url": "https://files.pythonhosted.org/packages/e3/67/8d81b3c894a4a0d6519d68c863fdcb7fda182f35ec37116107fa167f218b/pdiffcopy-1.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "ab10d53b2a78d619676b1374d3e4c04c", "sha256": "11bdd41d67d2db66d8f1a9c64c459eb914df4d6a7c9070b8cd96fceadc3213ff"}, "downloads": -1, "filename": "pdiffcopy-1.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "ab10d53b2a78d619676b1374d3e4c04c", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*", "size": 26807, "upload_time": "2020-03-06T23:30:24", "upload_time_iso_8601": "2020-03-06T23:30:24.413563Z", "url": "https://files.pythonhosted.org/packages/12/47/61ef28cb850bb6a5b89387ec0fa29dece3347a19f90398bc1444038e7ac1/pdiffcopy-1.0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c5f0d3d2e640d6d62081aacf26e382c3", "sha256": "4ad4d081e2f9c8d546052608845d9f9698e62b9b4ae3909abfb43085f5b2af90"}, "downloads": -1, "filename": "pdiffcopy-1.0.1.tar.gz", "has_sig": false, "md5_digest": "c5f0d3d2e640d6d62081aacf26e382c3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*", "size": 30395, "upload_time": "2020-03-06T23:30:26", "upload_time_iso_8601": "2020-03-06T23:30:26.028281Z", "url": "https://files.pythonhosted.org/packages/e0/6d/d7b88cb213c89d5e7e3f354f25fde03d250577e85300c9557f7638150e2b/pdiffcopy-1.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ab10d53b2a78d619676b1374d3e4c04c", "sha256": "11bdd41d67d2db66d8f1a9c64c459eb914df4d6a7c9070b8cd96fceadc3213ff"}, "downloads": -1, "filename": "pdiffcopy-1.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "ab10d53b2a78d619676b1374d3e4c04c", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*", "size": 26807, "upload_time": "2020-03-06T23:30:24", "upload_time_iso_8601": "2020-03-06T23:30:24.413563Z", "url": "https://files.pythonhosted.org/packages/12/47/61ef28cb850bb6a5b89387ec0fa29dece3347a19f90398bc1444038e7ac1/pdiffcopy-1.0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c5f0d3d2e640d6d62081aacf26e382c3", "sha256": "4ad4d081e2f9c8d546052608845d9f9698e62b9b4ae3909abfb43085f5b2af90"}, "downloads": -1, "filename": "pdiffcopy-1.0.1.tar.gz", "has_sig": false, "md5_digest": "c5f0d3d2e640d6d62081aacf26e382c3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*", "size": 30395, "upload_time": "2020-03-06T23:30:26", "upload_time_iso_8601": "2020-03-06T23:30:26.028281Z", "url": "https://files.pythonhosted.org/packages/e0/6d/d7b88cb213c89d5e7e3f354f25fde03d250577e85300c9557f7638150e2b/pdiffcopy-1.0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:57:07 2020"}