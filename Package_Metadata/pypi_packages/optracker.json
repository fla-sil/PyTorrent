{"info": {"author": "suxSx", "author_email": "marcuscrazy@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Console", "Intended Audience :: Developers", "Intended Audience :: Education", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 3.6", "Topic :: Education :: Testing"], "description": "<!-- PROJECT LOGO -->\n![Imgur](https://i.imgur.com/YpzZFfg.png)\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/optracker)\n![PyPI](https://img.shields.io/pypi/v/optracker)\n![PyPI - Status](https://img.shields.io/pypi/status/optracker)\n![PyPI - License](https://img.shields.io/pypi/l/optracker)\n![PyPI - Downloads](https://img.shields.io/pypi/dm/optracker)\n![Discord](https://img.shields.io/discord/633751704868749322)\n\n\n# openSource Tracker\nEasy to use program for scraping openSources, saves data and enable you to analyze it in your favorite graphic display. I created the projected based on <a href=\"https://github.com/realsirjoe/instagram-scraper\">instagram scraper</a>, witch allows you to get data from Instagram without API. The goal of this project is to make it easy for everyone to gather openSource content and analyze it.\n\n\n<!-- CONTENT -->\n## How to install\n***Simply run:***\n```cmd\npip install optracker\n```\n\n***Or download the project via git clone and run the following:***\n```cmd\npip install -r requirements.txt\npython .\\run_tracker.py\n```\n\n## Getting Started\nThe projects found here are for my own study for confirming and testing out theory according to social network analyzing. They can be used and altered as you see fit. To use it you need to install some required library for python see install.\n\n### 1. Running the program\nTo run simply type: **optracker** in console if you installed it from PIP. If you downloaded it from github: **python .\\run_tracker.py** from the optracker directory.<br />\n<br />\n***NB! You will need to run the script as administrator if you are using windows***\n\n### 2. Userlist\nThe program need functional accounts to work. They can either be added manually when you run it for the first time. Or create a local file with usernames and password. They will then be added to the database automatically on startup. In experience you need more then one user account to scan large list of users so your user don't get blocked because of to many requests.\n\n>**The following user list can be created:**\n>- inst_user.txt\n>- face_user.txt\n>- user_list.txt\n\nYou don't need to have a separate list for facebook or instagram but some people prefer it. You can add all the userdata in the same file by using user_list.txt. They all need to be setup the same way anyway.\n\n```python\n#Setup for user_list file\n{USERNAME}, {PASSWORD}, {EMAIL}, {FULLNAME}, {ACCOUNT}\n```\nAccount type can be: **facebook** or **instagram**. It is so the program know witch account to use where.\n\n```python\n#Example of insta_user.txt\nmy_username, my_password, my_email, my_fullname, instagram\nmy_username2, my_password2, my_email3, my_fullname2, facebook\nmy_username3, my_password3, my_email3, my_fullname3, instagram\n```\n\n**User list** will update each time you start the program, so new users can be added directly into the .txt document or you can add them manually into the program at start up.\n\n**Place for userlist** are in root directory. Usually is it ***c:\\optracker*** or ***\\optracker*** for Linux\n```cmd\noptracker/\n    userlist.txt\n    db/\n        openSource-tracker.db\n    export/\n        node.csv\n        egdes.csv\n```\n\n\n### 3. How to use\nWhen you run the program it will first try to connect to Instagram, if youdon'tt have a user file you will be asked to enter a username and password. After that you will get the option to choose from a menu. Start by running a single scan of one account. After that you can run more single scan to grow your node database or use follow by scan options. You also have a help menu that will give you all the information you need.<br />\n\n> ### Root Folder\n> Root folder for the program are the lowest dir. Usally is it ***c:\\optracker*** or ***\\optracker*** for linux\n\n### 4. First time scraping\nThe first time you scrape all the users will be saved as nodes. This will take some time, since we also want to save all the info we can get for each node. During this a lot of request will be send to the target server for the scrape, and as a result some of your user account may be blocked because of to many request in a short time. Laster when you scrape instagram as an example it will check if the node all ready exist in your database, if so it only add the connections it finds and your request to the server fall. Conclusion is that the bigger node base you have the faster you can scrape, and less request will be made.\n\n###\t5. Scan all follower\nYou will be presented with a list of users that you have finnished adding to your database. The program will then scan all the connections it has that are not private, add the nodes to DB and connections in edges.\n\n### 6. Max Follows and Max Followed by\nDuring **Scan all follower**, where you scan the profile for one user that have completet the singel search you can set a limit to how many followers a user can have or how many it are following. This is to prevent to scan uninterested profils like public organizations and so on as they can have up to 10K. Default is 2000 and is considerated a normal amount of followes/followed by.\n\n### 7. Deepscan and Surfacescan\nBy turning on surfacescan you only extract username and instagram id when scraping. This is to save you for request to the server so you can use one user for a longer periode of time, and make the scan go quicker if you are scraping a big nettwork. You can later add specific users found in the graphic to a text file and scan only the ones that are interesting and get all the data.\n\n### 8. Deepscan from list\nGives you the possibility to run a deep scan on a selected list of users. It will scrape all the data from instagram for the selected ones, and update DB Node. You need to create a file in **ROOT FOLDER** called **user_scan_insta.txt**\n```cmd\noptracker/\n    userlist.txt\n    user_scan_insta.txt\n    db/\n        openSource-tracker.db\n    export/\n        node.csv\n        egdes.csv\n```\nContent of the list need to be one username per line:\n```python\n{USER 1}\n{USER 2}\n{USER 3}\n{USER 4}\n```\n### 9. Detail Print\nOn Default is it turned **OFF** you will only get the minimum of info to see if it is working properly. If you turn it **ON** will you be presented with all the output the scraper have.\n\n### 10. Download Profile Image\nThe program will download every Instagram profile image it scans for face recognition. It saves it to **profile_pic**. You can turn it of from default value menu.\n\n```cmd\noptracker/\n    userlist.txt\n    user_scan_insta.txt\n    db/\n        openSource-tracker.db\n    export/\n        node.csv\n        egdes.csv\n    instadata/\n        profilepic/\n            **INSTA ID**.jpg\n        post/\n```\n\n### 11. Update Profile Image\nRunning this will check the DB agenst profile image folder, and download all the images that are missing. \n\n### 12. Change default value\nFrom the menu can you change default values like surfacescan, max follow and mysql or sqlite with more. To change select yes, fill in new value, if you dont want to change one value leave it blank.\n\n\n## Database Information\nBy default the scraper use **SQLite**, all the data are stored in **optracker/db/openSource-tracker.db**. \n\n> **MySQL** are also available to use. Current version tested and found OK is **MySQL 8.0.18**. You can change the database settings in the menu. But you need to download and install the latest version of Mysql and create a database called **openSource-tracker**, if you dont have an online version you want to use instead of local. Also remember to use **utf8mb4**. The following are default:\n> * DB_MYSQL = \"localhost\"\n> * DB_MYSQL_USER = \"optracker\"\n> * DB_MYSQL_PASSWORD = \"localpassword\"\n> * DB_MYSQL_DATABASE = \"openSource_tracker\"\n> * DB_MYSQL_PORT = \"3306\"\n> * DB_MYSQL_ON = 0\n> * DB_MYSQL_COLLATION = \"utf8mb4_general_ci\"\n> * DB_MYSQL_CHARSET = \"utf8mb4\"  \n>   \n>***Scraping big amount of data can be really slow if you use SQLite, therefore are MySQL an option if you plan on collectingg huge amounts.*** \n\n**The database consist of the following tabels:**\n- accounts\n- edges_insta\n- nodes\n- options\n- new_insta\n\n> **Note!** All SQL data are saved in **optracker.config** located in root folder. The format are in JSON and you can change it as you would like to match your current DB. But I recomend to keep the standar settings. \n\n\n### 1. Accounts\nStores all your usernames and password for the different openSource sites.\n\n### 2. Edges_insta\nHave list of all the connections. Rows are target, source, weight and type. This is all made to be used with gephi for visualizing the data in graph form. The numbers are connected to ID in nodes. Show how is following or connected to who.\n\n### 3. nodes\nList of all the nodes created. They all have their own ID. It also contain all information scraped on a single user like username, email, bio and so on found in the different scraping sites.\n\n### 4. Options\nTemporary table to store information like follow list, last search and so on for the program to use.\n\n### 5. New_insta\nThis table have a list of all instagram accounts that have been found during scraping. The program will used this to see witch account have not yet been fully scraped. When it is finnish are the account set to DONE. If you dont want the account to be scraped set the WAIT value to True. 0 = False, 1 = True. ***This can also be used in the case of a user have to many follower, or non at all so you dont want to scan it. When the user pop up, the scanner jumps over it.***\n\n### 6. Export\nTo export the data you can connect to the DB file under the db/folder. Or you can export it from the program. From main menu choose export. It will the generate two files **nodes.csv** and **egdes.csv**. You can then import this into your favorite graphic display\n\n## Common Error\n### 1. F String\n```python\nTraceback (most recent call last):\n  File \"/usr/local/bin/optracker\", line 6, in <module>\n    from optracker.optracker import run\n  File \"/usr/local/lib/python3.5/dist-packages/optracker/optracker.py\", line 14, in <module>\n    from igramscraper.instagram import Instagram\n  File \"/usr/local/lib/python3.5/dist-packages/igramscraper/instagram.py\", line 153\n    cookies += f\"{key}={session[key]}; \"\n                                       ^\nSyntaxError: invalid syntax\n```\nTo fix update python to latest, you are using an old version that dosent support **f\"\"** you need to use **python3.6**\n\n### 2. Instagram useragent\n```\nERROR: {\"message\": \"useragent mismatch\", \"status\": \"fail\"}\n```\nIgramscraper are using a useragent that are not up to date. You need to update **self.user_agent** in **igramscraper/instagram.py**. Locate this file and look for somethong that looks like this:\n```python\nself.user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) ' \\\n                          'AppleWebKit/537.36 (KHTML, like Gecko) ' \\\n                          'Chrome/66.0.3359.139 Safari/537.36'\n```\nAfter this change it to a new useragent that are allowed by instagram, this is one example that worked in october 2019.\n```python\nself.user_agent =   'Mozilla/5.0 (iPhone; CPU iPhone OS 12_3_1 like Mac OS X)' \\\n                            'AppleWebKit/605.1.15 (KHTML, like Gecko)' \\\n                            'Mobile/15E148 Instagram 105.0.0.11.118 (iPhone11,8; iOS 12_3_1; en_US; en-US; scale=2.00; 828x1792; 165586599)'\n```\n\n### 3. Private Instagram\n```python\n  File \"\\optracker\\functions\\instagram_func.py\", line 20, in get_insta_following\n    following = self.instagram.get_following(insta_id, totalFollow, self.page_size_check(totalFollow), delayed=True)\n  File \"\\optracker\\igramscraper\\instagram.py\", line 963, in get_following\n    Instagram.HTTP_FORBIDDEN)\noptracker.igramscraper.exception.instagram_exception.InstagramException: Failed to get follows of account id ******. The account is private., Code:403\n```\nWhen searhing profiles sometimes the user have set it to private after first scraping. When extracting data after this the program will stop and give an error that the profile is private. Just run it once more, the program have updated the profile automatic to private so it wont happen on the next scan. \n\n## Common Information\n\n- Look at TODO if you want to help: [TODO](https://github.com/suxSx/opensource-tracker/blob/master/TODO.md) <br />\n- Read the CODE of Conduct before you edit: [Code of Conduct](https://github.com/suxSx/opensource-tracker/blob/master/CODE_OF_CONDUCT.md)<br />\n- We use MIT License: [MIT](https://github.com/suxSx/opensource-tracker/blob/master/LICENSE.md)\n\n### Worth mentioning\n- instagram-php-scraper [here](https://github.com/postaddictme/instagram-php-scraper/)<br />\n- instagram-scraper [here](https://github.com/realsirjoe/instagram-scraper)<br />\n- logo-design [here](http://freepik.com)  \n- face-recognition [here](https://github.com/ageitgey/face_recognition)\n\n\n<br /><a href=\"https://www.buymeacoffee.com/knoph\" target=\"_blank\"><img src=\"https://cdn.buymeacoffee.com/buttons/default-black.png\" alt=\"Buy Me A Coffee\" style=\"height: 51px !important;width: 217px !important;\" ></a>\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/suxSx/openSource-tracker", "keywords": "scraper media social network mapper tracker instagram scrape like follow analyze", "license": "MIT", "maintainer": "suxSx", "maintainer_email": "", "name": "optracker", "package_url": "https://pypi.org/project/optracker/", "platform": "", "project_url": "https://pypi.org/project/optracker/", "project_urls": {"Homepage": "https://github.com/suxSx/openSource-tracker"}, "release_url": "https://pypi.org/project/optracker/1.3.6/", "requires_dist": ["python-slugify (==3.0.2)", "unicodecsv (==0.14.1)", "mysql-connector-python (==8.0.18)", "cmake", "Pillow", "dlib (>=19.7)"], "requires_python": "", "summary": "Scrapes medias, likes, followers from social media. Organize them in a database for more deeper analyze.", "version": "1.3.6", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><img alt=\"Imgur\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/96841eaccb6f568e1a0dbddc65808daaaff674d3/68747470733a2f2f692e696d6775722e636f6d2f59707a5a4666672e706e67\">\n<img alt=\"PyPI - Python Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/919dc07ee3615e40afa8c4dab5ca2ba1e84d491f/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f6f70747261636b6572\">\n<img alt=\"PyPI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3431d03ae5da6ad7d691c3107d5bc538e1ff76f0/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6f70747261636b6572\">\n<img alt=\"PyPI - Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bc1c4490c68ae137c5dd17379fdb2ac3547693a0/68747470733a2f2f696d672e736869656c64732e696f2f707970692f7374617475732f6f70747261636b6572\">\n<img alt=\"PyPI - License\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/75242410ecb9e650f73985f114cc3e5b93510e06/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f6f70747261636b6572\">\n<img alt=\"PyPI - Downloads\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/93c9cb468898aa866ad410ec5fa01ba5a37ef458/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f6f70747261636b6572\">\n<img alt=\"Discord\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2238189e571956bfabf1881ae426771702fa380e/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f363333373531373034383638373439333232\"></p>\n<h1>openSource Tracker</h1>\n<p>Easy to use program for scraping openSources, saves data and enable you to analyze it in your favorite graphic display. I created the projected based on <a href=\"https://github.com/realsirjoe/instagram-scraper\" rel=\"nofollow\">instagram scraper</a>, witch allows you to get data from Instagram without API. The goal of this project is to make it easy for everyone to gather openSource content and analyze it.</p>\n\n<h2>How to install</h2>\n<p><em><strong>Simply run:</strong></em></p>\n<pre>pip install optracker\n</pre>\n<p><em><strong>Or download the project via git clone and run the following:</strong></em></p>\n<pre>pip install -r requirements.txt\npython .\\run_tracker.py\n</pre>\n<h2>Getting Started</h2>\n<p>The projects found here are for my own study for confirming and testing out theory according to social network analyzing. They can be used and altered as you see fit. To use it you need to install some required library for python see install.</p>\n<h3>1. Running the program</h3>\n<p>To run simply type: <strong>optracker</strong> in console if you installed it from PIP. If you downloaded it from github: <strong>python .\\run_tracker.py</strong> from the optracker directory.<br>\n<br>\n<em><strong>NB! You will need to run the script as administrator if you are using windows</strong></em></p>\n<h3>2. Userlist</h3>\n<p>The program need functional accounts to work. They can either be added manually when you run it for the first time. Or create a local file with usernames and password. They will then be added to the database automatically on startup. In experience you need more then one user account to scan large list of users so your user don't get blocked because of to many requests.</p>\n<blockquote>\n<p><strong>The following user list can be created:</strong></p>\n<ul>\n<li>inst_user.txt</li>\n<li>face_user.txt</li>\n<li>user_list.txt</li>\n</ul>\n</blockquote>\n<p>You don't need to have a separate list for facebook or instagram but some people prefer it. You can add all the userdata in the same file by using user_list.txt. They all need to be setup the same way anyway.</p>\n<pre><span class=\"c1\">#Setup for user_list file</span>\n<span class=\"p\">{</span><span class=\"n\">USERNAME</span><span class=\"p\">},</span> <span class=\"p\">{</span><span class=\"n\">PASSWORD</span><span class=\"p\">},</span> <span class=\"p\">{</span><span class=\"n\">EMAIL</span><span class=\"p\">},</span> <span class=\"p\">{</span><span class=\"n\">FULLNAME</span><span class=\"p\">},</span> <span class=\"p\">{</span><span class=\"n\">ACCOUNT</span><span class=\"p\">}</span>\n</pre>\n<p>Account type can be: <strong>facebook</strong> or <strong>instagram</strong>. It is so the program know witch account to use where.</p>\n<pre><span class=\"c1\">#Example of insta_user.txt</span>\n<span class=\"n\">my_username</span><span class=\"p\">,</span> <span class=\"n\">my_password</span><span class=\"p\">,</span> <span class=\"n\">my_email</span><span class=\"p\">,</span> <span class=\"n\">my_fullname</span><span class=\"p\">,</span> <span class=\"n\">instagram</span>\n<span class=\"n\">my_username2</span><span class=\"p\">,</span> <span class=\"n\">my_password2</span><span class=\"p\">,</span> <span class=\"n\">my_email3</span><span class=\"p\">,</span> <span class=\"n\">my_fullname2</span><span class=\"p\">,</span> <span class=\"n\">facebook</span>\n<span class=\"n\">my_username3</span><span class=\"p\">,</span> <span class=\"n\">my_password3</span><span class=\"p\">,</span> <span class=\"n\">my_email3</span><span class=\"p\">,</span> <span class=\"n\">my_fullname3</span><span class=\"p\">,</span> <span class=\"n\">instagram</span>\n</pre>\n<p><strong>User list</strong> will update each time you start the program, so new users can be added directly into the .txt document or you can add them manually into the program at start up.</p>\n<p><strong>Place for userlist</strong> are in root directory. Usually is it <em><strong>c:\\optracker</strong></em> or <em><strong>\\optracker</strong></em> for Linux</p>\n<pre>optracker/\n    userlist.txt\n    db/\n        openSource-tracker.db\n    export/\n        node.csv\n        egdes.csv\n</pre>\n<h3>3. How to use</h3>\n<p>When you run the program it will first try to connect to Instagram, if youdon'tt have a user file you will be asked to enter a username and password. After that you will get the option to choose from a menu. Start by running a single scan of one account. After that you can run more single scan to grow your node database or use follow by scan options. You also have a help menu that will give you all the information you need.<br></p>\n<blockquote>\n<h3>Root Folder</h3>\n<p>Root folder for the program are the lowest dir. Usally is it <em><strong>c:\\optracker</strong></em> or <em><strong>\\optracker</strong></em> for linux</p>\n</blockquote>\n<h3>4. First time scraping</h3>\n<p>The first time you scrape all the users will be saved as nodes. This will take some time, since we also want to save all the info we can get for each node. During this a lot of request will be send to the target server for the scrape, and as a result some of your user account may be blocked because of to many request in a short time. Laster when you scrape instagram as an example it will check if the node all ready exist in your database, if so it only add the connections it finds and your request to the server fall. Conclusion is that the bigger node base you have the faster you can scrape, and less request will be made.</p>\n<h3>5. Scan all follower</h3>\n<p>You will be presented with a list of users that you have finnished adding to your database. The program will then scan all the connections it has that are not private, add the nodes to DB and connections in edges.</p>\n<h3>6. Max Follows and Max Followed by</h3>\n<p>During <strong>Scan all follower</strong>, where you scan the profile for one user that have completet the singel search you can set a limit to how many followers a user can have or how many it are following. This is to prevent to scan uninterested profils like public organizations and so on as they can have up to 10K. Default is 2000 and is considerated a normal amount of followes/followed by.</p>\n<h3>7. Deepscan and Surfacescan</h3>\n<p>By turning on surfacescan you only extract username and instagram id when scraping. This is to save you for request to the server so you can use one user for a longer periode of time, and make the scan go quicker if you are scraping a big nettwork. You can later add specific users found in the graphic to a text file and scan only the ones that are interesting and get all the data.</p>\n<h3>8. Deepscan from list</h3>\n<p>Gives you the possibility to run a deep scan on a selected list of users. It will scrape all the data from instagram for the selected ones, and update DB Node. You need to create a file in <strong>ROOT FOLDER</strong> called <strong>user_scan_insta.txt</strong></p>\n<pre>optracker/\n    userlist.txt\n    user_scan_insta.txt\n    db/\n        openSource-tracker.db\n    export/\n        node.csv\n        egdes.csv\n</pre>\n<p>Content of the list need to be one username per line:</p>\n<pre><span class=\"p\">{</span><span class=\"n\">USER</span> <span class=\"mi\">1</span><span class=\"p\">}</span>\n<span class=\"p\">{</span><span class=\"n\">USER</span> <span class=\"mi\">2</span><span class=\"p\">}</span>\n<span class=\"p\">{</span><span class=\"n\">USER</span> <span class=\"mi\">3</span><span class=\"p\">}</span>\n<span class=\"p\">{</span><span class=\"n\">USER</span> <span class=\"mi\">4</span><span class=\"p\">}</span>\n</pre>\n<h3>9. Detail Print</h3>\n<p>On Default is it turned <strong>OFF</strong> you will only get the minimum of info to see if it is working properly. If you turn it <strong>ON</strong> will you be presented with all the output the scraper have.</p>\n<h3>10. Download Profile Image</h3>\n<p>The program will download every Instagram profile image it scans for face recognition. It saves it to <strong>profile_pic</strong>. You can turn it of from default value menu.</p>\n<pre>optracker/\n    userlist.txt\n    user_scan_insta.txt\n    db/\n        openSource-tracker.db\n    export/\n        node.csv\n        egdes.csv\n    instadata/\n        profilepic/\n            **INSTA ID**.jpg\n        post/\n</pre>\n<h3>11. Update Profile Image</h3>\n<p>Running this will check the DB agenst profile image folder, and download all the images that are missing.</p>\n<h3>12. Change default value</h3>\n<p>From the menu can you change default values like surfacescan, max follow and mysql or sqlite with more. To change select yes, fill in new value, if you dont want to change one value leave it blank.</p>\n<h2>Database Information</h2>\n<p>By default the scraper use <strong>SQLite</strong>, all the data are stored in <strong>optracker/db/openSource-tracker.db</strong>.</p>\n<blockquote>\n<p><strong>MySQL</strong> are also available to use. Current version tested and found OK is <strong>MySQL 8.0.18</strong>. You can change the database settings in the menu. But you need to download and install the latest version of Mysql and create a database called <strong>openSource-tracker</strong>, if you dont have an online version you want to use instead of local. Also remember to use <strong>utf8mb4</strong>. The following are default:</p>\n<ul>\n<li>DB_MYSQL = \"localhost\"</li>\n<li>DB_MYSQL_USER = \"optracker\"</li>\n<li>DB_MYSQL_PASSWORD = \"localpassword\"</li>\n<li>DB_MYSQL_DATABASE = \"openSource_tracker\"</li>\n<li>DB_MYSQL_PORT = \"3306\"</li>\n<li>DB_MYSQL_ON = 0</li>\n<li>DB_MYSQL_COLLATION = \"utf8mb4_general_ci\"</li>\n<li>DB_MYSQL_CHARSET = \"utf8mb4\"</li>\n</ul>\n<p><em><strong>Scraping big amount of data can be really slow if you use SQLite, therefore are MySQL an option if you plan on collectingg huge amounts.</strong></em></p>\n</blockquote>\n<p><strong>The database consist of the following tabels:</strong></p>\n<ul>\n<li>accounts</li>\n<li>edges_insta</li>\n<li>nodes</li>\n<li>options</li>\n<li>new_insta</li>\n</ul>\n<blockquote>\n<p><strong>Note!</strong> All SQL data are saved in <strong>optracker.config</strong> located in root folder. The format are in JSON and you can change it as you would like to match your current DB. But I recomend to keep the standar settings.</p>\n</blockquote>\n<h3>1. Accounts</h3>\n<p>Stores all your usernames and password for the different openSource sites.</p>\n<h3>2. Edges_insta</h3>\n<p>Have list of all the connections. Rows are target, source, weight and type. This is all made to be used with gephi for visualizing the data in graph form. The numbers are connected to ID in nodes. Show how is following or connected to who.</p>\n<h3>3. nodes</h3>\n<p>List of all the nodes created. They all have their own ID. It also contain all information scraped on a single user like username, email, bio and so on found in the different scraping sites.</p>\n<h3>4. Options</h3>\n<p>Temporary table to store information like follow list, last search and so on for the program to use.</p>\n<h3>5. New_insta</h3>\n<p>This table have a list of all instagram accounts that have been found during scraping. The program will used this to see witch account have not yet been fully scraped. When it is finnish are the account set to DONE. If you dont want the account to be scraped set the WAIT value to True. 0 = False, 1 = True. <em><strong>This can also be used in the case of a user have to many follower, or non at all so you dont want to scan it. When the user pop up, the scanner jumps over it.</strong></em></p>\n<h3>6. Export</h3>\n<p>To export the data you can connect to the DB file under the db/folder. Or you can export it from the program. From main menu choose export. It will the generate two files <strong>nodes.csv</strong> and <strong>egdes.csv</strong>. You can then import this into your favorite graphic display</p>\n<h2>Common Error</h2>\n<h3>1. F String</h3>\n<pre><span class=\"n\">Traceback</span> <span class=\"p\">(</span><span class=\"n\">most</span> <span class=\"n\">recent</span> <span class=\"n\">call</span> <span class=\"n\">last</span><span class=\"p\">):</span>\n  <span class=\"n\">File</span> <span class=\"s2\">\"/usr/local/bin/optracker\"</span><span class=\"p\">,</span> <span class=\"n\">line</span> <span class=\"mi\">6</span><span class=\"p\">,</span> <span class=\"ow\">in</span> <span class=\"o\">&lt;</span><span class=\"n\">module</span><span class=\"o\">&gt;</span>\n    <span class=\"kn\">from</span> <span class=\"nn\">optracker.optracker</span> <span class=\"kn\">import</span> <span class=\"n\">run</span>\n  <span class=\"n\">File</span> <span class=\"s2\">\"/usr/local/lib/python3.5/dist-packages/optracker/optracker.py\"</span><span class=\"p\">,</span> <span class=\"n\">line</span> <span class=\"mi\">14</span><span class=\"p\">,</span> <span class=\"ow\">in</span> <span class=\"o\">&lt;</span><span class=\"n\">module</span><span class=\"o\">&gt;</span>\n    <span class=\"kn\">from</span> <span class=\"nn\">igramscraper.instagram</span> <span class=\"kn\">import</span> <span class=\"n\">Instagram</span>\n  <span class=\"n\">File</span> <span class=\"s2\">\"/usr/local/lib/python3.5/dist-packages/igramscraper/instagram.py\"</span><span class=\"p\">,</span> <span class=\"n\">line</span> <span class=\"mi\">153</span>\n    <span class=\"n\">cookies</span> <span class=\"o\">+=</span> <span class=\"sa\">f</span><span class=\"s2\">\"</span><span class=\"si\">{</span><span class=\"n\">key</span><span class=\"si\">}</span><span class=\"s2\">=</span><span class=\"si\">{</span><span class=\"n\">session</span><span class=\"p\">[</span><span class=\"n\">key</span><span class=\"p\">]</span><span class=\"si\">}</span><span class=\"s2\">; \"</span>\n                                       <span class=\"o\">^</span>\n<span class=\"ne\">SyntaxError</span><span class=\"p\">:</span> <span class=\"n\">invalid</span> <span class=\"n\">syntax</span>\n</pre>\n<p>To fix update python to latest, you are using an old version that dosent support <strong>f\"\"</strong> you need to use <strong>python3.6</strong></p>\n<h3>2. Instagram useragent</h3>\n<pre><code>ERROR: {\"message\": \"useragent mismatch\", \"status\": \"fail\"}\n</code></pre>\n<p>Igramscraper are using a useragent that are not up to date. You need to update <strong>self.user_agent</strong> in <strong>igramscraper/instagram.py</strong>. Locate this file and look for somethong that looks like this:</p>\n<pre><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">user_agent</span> <span class=\"o\">=</span> <span class=\"s1\">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) '</span> \\\n                          <span class=\"s1\">'AppleWebKit/537.36 (KHTML, like Gecko) '</span> \\\n                          <span class=\"s1\">'Chrome/66.0.3359.139 Safari/537.36'</span>\n</pre>\n<p>After this change it to a new useragent that are allowed by instagram, this is one example that worked in october 2019.</p>\n<pre><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">user_agent</span> <span class=\"o\">=</span>   <span class=\"s1\">'Mozilla/5.0 (iPhone; CPU iPhone OS 12_3_1 like Mac OS X)'</span> \\\n                            <span class=\"s1\">'AppleWebKit/605.1.15 (KHTML, like Gecko)'</span> \\\n                            <span class=\"s1\">'Mobile/15E148 Instagram 105.0.0.11.118 (iPhone11,8; iOS 12_3_1; en_US; en-US; scale=2.00; 828x1792; 165586599)'</span>\n</pre>\n<h3>3. Private Instagram</h3>\n<pre>  <span class=\"n\">File</span> <span class=\"s2\">\"\\optracker</span><span class=\"se\">\\f</span><span class=\"s2\">unctions\\instagram_func.py\"</span><span class=\"p\">,</span> <span class=\"n\">line</span> <span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"ow\">in</span> <span class=\"n\">get_insta_following</span>\n    <span class=\"n\">following</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">instagram</span><span class=\"o\">.</span><span class=\"n\">get_following</span><span class=\"p\">(</span><span class=\"n\">insta_id</span><span class=\"p\">,</span> <span class=\"n\">totalFollow</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">page_size_check</span><span class=\"p\">(</span><span class=\"n\">totalFollow</span><span class=\"p\">),</span> <span class=\"n\">delayed</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n  <span class=\"n\">File</span> <span class=\"s2\">\"\\optracker\\igramscraper\\instagram.py\"</span><span class=\"p\">,</span> <span class=\"n\">line</span> <span class=\"mi\">963</span><span class=\"p\">,</span> <span class=\"ow\">in</span> <span class=\"n\">get_following</span>\n    <span class=\"n\">Instagram</span><span class=\"o\">.</span><span class=\"n\">HTTP_FORBIDDEN</span><span class=\"p\">)</span>\n<span class=\"n\">optracker</span><span class=\"o\">.</span><span class=\"n\">igramscraper</span><span class=\"o\">.</span><span class=\"n\">exception</span><span class=\"o\">.</span><span class=\"n\">instagram_exception</span><span class=\"o\">.</span><span class=\"n\">InstagramException</span><span class=\"p\">:</span> <span class=\"n\">Failed</span> <span class=\"n\">to</span> <span class=\"n\">get</span> <span class=\"n\">follows</span> <span class=\"n\">of</span> <span class=\"n\">account</span> <span class=\"nb\">id</span> <span class=\"o\">******.</span> <span class=\"n\">The</span> <span class=\"n\">account</span> <span class=\"ow\">is</span> <span class=\"n\">private</span><span class=\"o\">.</span><span class=\"p\">,</span> <span class=\"n\">Code</span><span class=\"p\">:</span><span class=\"mi\">403</span>\n</pre>\n<p>When searhing profiles sometimes the user have set it to private after first scraping. When extracting data after this the program will stop and give an error that the profile is private. Just run it once more, the program have updated the profile automatic to private so it wont happen on the next scan.</p>\n<h2>Common Information</h2>\n<ul>\n<li>Look at TODO if you want to help: <a href=\"https://github.com/suxSx/opensource-tracker/blob/master/TODO.md\" rel=\"nofollow\">TODO</a> <br></li>\n<li>Read the CODE of Conduct before you edit: <a href=\"https://github.com/suxSx/opensource-tracker/blob/master/CODE_OF_CONDUCT.md\" rel=\"nofollow\">Code of Conduct</a><br></li>\n<li>We use MIT License: <a href=\"https://github.com/suxSx/opensource-tracker/blob/master/LICENSE.md\" rel=\"nofollow\">MIT</a></li>\n</ul>\n<h3>Worth mentioning</h3>\n<ul>\n<li>instagram-php-scraper <a href=\"https://github.com/postaddictme/instagram-php-scraper/\" rel=\"nofollow\">here</a><br></li>\n<li>instagram-scraper <a href=\"https://github.com/realsirjoe/instagram-scraper\" rel=\"nofollow\">here</a><br></li>\n<li>logo-design <a href=\"http://freepik.com\" rel=\"nofollow\">here</a></li>\n<li>face-recognition <a href=\"https://github.com/ageitgey/face_recognition\" rel=\"nofollow\">here</a></li>\n</ul>\n<p><br><a href=\"https://www.buymeacoffee.com/knoph\" rel=\"nofollow\"><img alt=\"Buy Me A Coffee\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1c5648514ba6421829ddbfe6129206c9b1ec0744/68747470733a2f2f63646e2e6275796d6561636f666665652e636f6d2f627574746f6e732f64656661756c742d626c61636b2e706e67\"></a></p>\n\n          </div>"}, "last_serial": 6082032, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "a3a847193ac4eb6325309e0a61f277c1", "sha256": "65bba13c077e829eeac1b464c9fbd0168c843bb78ae7a89762d3a097e8fb83d6"}, "downloads": -1, "filename": "optracker-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "a3a847193ac4eb6325309e0a61f277c1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 41634, "upload_time": "2019-10-16T10:53:46", "upload_time_iso_8601": "2019-10-16T10:53:46.970785Z", "url": "https://files.pythonhosted.org/packages/17/27/423b213d805082b7ae41cb1d19da8093c467d82adcc777457cf3689ac3ef/optracker-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d56c0fb205f857609ad23c6ad7d0f06e", "sha256": "68fa10d910a02b9f15c782760600c81495d40aaf2b4f5ccf07bfac1c2b867e5b"}, "downloads": -1, "filename": "optracker-1.0.0.tar.gz", "has_sig": false, "md5_digest": "d56c0fb205f857609ad23c6ad7d0f06e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 35072, "upload_time": "2019-10-16T10:53:49", "upload_time_iso_8601": "2019-10-16T10:53:49.580139Z", "url": "https://files.pythonhosted.org/packages/6f/a2/084fb71aa68668905af9645f41090a03a504e55878ae2635a4723493d6db/optracker-1.0.0.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "ea5b157c8ab986c3c45940bfd3620c02", "sha256": "6f3e18916f930e09a7e80e8f31860ee7d04d0b5fb30311cd2b1b0eee1eda0f7e"}, "downloads": -1, "filename": "optracker-1.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "ea5b157c8ab986c3c45940bfd3620c02", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 43418, "upload_time": "2019-10-18T13:34:23", "upload_time_iso_8601": "2019-10-18T13:34:23.703917Z", "url": "https://files.pythonhosted.org/packages/70/85/f9f2d1a90dfea91204a7c3fafbbb4e993d7cd9b6abd2693322b6e076ab04/optracker-1.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fa84c3a1333e5e28738efc70726b1be3", "sha256": "4018224740c85ab1ec445590c4bb4899ded6bc16556122775a85fce0f8b96c5b"}, "downloads": -1, "filename": "optracker-1.1.0.tar.gz", "has_sig": false, "md5_digest": "fa84c3a1333e5e28738efc70726b1be3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 36840, "upload_time": "2019-10-18T13:34:25", "upload_time_iso_8601": "2019-10-18T13:34:25.706974Z", "url": "https://files.pythonhosted.org/packages/b0/3e/b0a3243bef2b1d8494e04422760e7836c4cee23c42e0f2db46fa021c5d8e/optracker-1.1.0.tar.gz", "yanked": false}], "1.1.1": [{"comment_text": "", "digests": {"md5": "3e121f8c3dea455b30c7a75e2bbad05e", "sha256": "e10a60490495ef2d5c789f9f0c6e7b392bbbf4fc690135b5d7f758bed7f3887b"}, "downloads": -1, "filename": "optracker-1.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "3e121f8c3dea455b30c7a75e2bbad05e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 43419, "upload_time": "2019-10-19T10:27:08", "upload_time_iso_8601": "2019-10-19T10:27:08.249068Z", "url": "https://files.pythonhosted.org/packages/4c/6f/fb28816d4151791513a14f46668ecf2031086b6f5d5a02941d1b73b07c72/optracker-1.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7f7dab9d735bb237b69cf6e8920a85ca", "sha256": "082201cd472e63168a98c6fb50790adc006170ffce21526a700ea854964c565e"}, "downloads": -1, "filename": "optracker-1.1.1.tar.gz", "has_sig": false, "md5_digest": "7f7dab9d735bb237b69cf6e8920a85ca", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 36850, "upload_time": "2019-10-19T10:27:10", "upload_time_iso_8601": "2019-10-19T10:27:10.244012Z", "url": "https://files.pythonhosted.org/packages/e2/a5/f7c713c85a01ea936da0b2b6449af5f824dd9e67fc3f7c18508a55f02ebe/optracker-1.1.1.tar.gz", "yanked": false}], "1.2.1": [{"comment_text": "", "digests": {"md5": "16a2de6c74463e10402cb1342c66ce70", "sha256": "2087769630f928f44736b86a68f2246e9a1618015eca6d6237f340170593e4ff"}, "downloads": -1, "filename": "optracker-1.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "16a2de6c74463e10402cb1342c66ce70", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 47162, "upload_time": "2019-10-25T18:39:57", "upload_time_iso_8601": "2019-10-25T18:39:57.796156Z", "url": "https://files.pythonhosted.org/packages/27/52/777791a47a0e36b274a8713e2f2b79477a3072dc870360f6287c5d959f66/optracker-1.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a380f4f26d8308acb5ff90e5171458f7", "sha256": "74e2f1d01fc8a884ccbf08235740a598711080e3f8438c03ba6861873bde478b"}, "downloads": -1, "filename": "optracker-1.2.1.tar.gz", "has_sig": false, "md5_digest": "a380f4f26d8308acb5ff90e5171458f7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 41817, "upload_time": "2019-10-25T18:40:04", "upload_time_iso_8601": "2019-10-25T18:40:04.895190Z", "url": "https://files.pythonhosted.org/packages/81/12/d1f228f59f6f20ce0d534a014e8848c4ca6e262f5a8184cba4e30b02a00c/optracker-1.2.1.tar.gz", "yanked": false}], "1.2.2": [{"comment_text": "", "digests": {"md5": "ece882d40893b39046935a8cc1b42951", "sha256": "229b3e24371fe4f82e2d7abd08d28359a819a7e4789ba7cc4746a0cd1ac2ab97"}, "downloads": -1, "filename": "optracker-1.2.2-py3-none-any.whl", "has_sig": false, "md5_digest": "ece882d40893b39046935a8cc1b42951", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 47169, "upload_time": "2019-10-26T21:57:33", "upload_time_iso_8601": "2019-10-26T21:57:33.484876Z", "url": "https://files.pythonhosted.org/packages/ea/19/8292d8ec1d919e792e8606ef4a1694b3de5c76b17d25bf860709e02fd462/optracker-1.2.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0adea6e19d5348a42c03878c7124ab08", "sha256": "fd2ea44b249ebb182e7cc0663340703ace610d222915f01c95e5141b4497c708"}, "downloads": -1, "filename": "optracker-1.2.2.tar.gz", "has_sig": false, "md5_digest": "0adea6e19d5348a42c03878c7124ab08", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 41831, "upload_time": "2019-10-26T21:57:36", "upload_time_iso_8601": "2019-10-26T21:57:36.063147Z", "url": "https://files.pythonhosted.org/packages/fa/b3/38aa0ae2cbe96ada98b1408c0b19b7146a65608fa3849802fddaa5519824/optracker-1.2.2.tar.gz", "yanked": false}], "1.2.3": [{"comment_text": "", "digests": {"md5": "f94e9edef87c1dca3eeb829437a6ab8c", "sha256": "1683ae9089bf714cf8d3db23059ce8f00f4104674b31bac62b01a6865fcb347a"}, "downloads": -1, "filename": "optracker-1.2.3-py3-none-any.whl", "has_sig": false, "md5_digest": "f94e9edef87c1dca3eeb829437a6ab8c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 47170, "upload_time": "2019-10-26T22:00:30", "upload_time_iso_8601": "2019-10-26T22:00:30.509583Z", "url": "https://files.pythonhosted.org/packages/43/af/02ff9d9cead43fa7e6ebcc75989caf0131ec05794e66be473e7fefe77800/optracker-1.2.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "290305575108e2f6a863965e6ef65574", "sha256": "0387071d21321dba61d434729a43886292964d75425449d1ae1bfba62e222c81"}, "downloads": -1, "filename": "optracker-1.2.3.tar.gz", "has_sig": false, "md5_digest": "290305575108e2f6a863965e6ef65574", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 41826, "upload_time": "2019-10-26T22:00:33", "upload_time_iso_8601": "2019-10-26T22:00:33.814565Z", "url": "https://files.pythonhosted.org/packages/6f/07/940ac69107c546d8b309909ae5d4ab8ee503849aa8ad1b9a1663614ef0db/optracker-1.2.3.tar.gz", "yanked": false}], "1.2.4": [{"comment_text": "", "digests": {"md5": "29577260ce6ca5d0301b4577193f3af7", "sha256": "8a55042727dde39aeac9c132230c387871b846510206cca2829fed0a9638c702"}, "downloads": -1, "filename": "optracker-1.2.4-py3-none-any.whl", "has_sig": false, "md5_digest": "29577260ce6ca5d0301b4577193f3af7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 47396, "upload_time": "2019-10-27T13:30:39", "upload_time_iso_8601": "2019-10-27T13:30:39.347849Z", "url": "https://files.pythonhosted.org/packages/b3/24/0254c116658eb6e0b2e7b21ff40020e3589a778999a1aafa0a4c6a05e4bc/optracker-1.2.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "938b51f6e2ce55b81355eea611db0046", "sha256": "15b9a54eeb4ee8124d22408d4fb32c5cce370d1672a2b957dd4ba1bca5cc67ea"}, "downloads": -1, "filename": "optracker-1.2.4.tar.gz", "has_sig": false, "md5_digest": "938b51f6e2ce55b81355eea611db0046", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 42033, "upload_time": "2019-10-27T13:30:44", "upload_time_iso_8601": "2019-10-27T13:30:44.644044Z", "url": "https://files.pythonhosted.org/packages/41/9d/1eac0a571f053dd393c994a8dca560803a8c861d64dbaf9f9df8698874d6/optracker-1.2.4.tar.gz", "yanked": false}], "1.2.5": [{"comment_text": "", "digests": {"md5": "b77ed89904d0c052e8957b6fc2aa2502", "sha256": "2a3499bb2fae1561a0cff7594e135752fea98128ce2cd8324926fc290b09eece"}, "downloads": -1, "filename": "optracker-1.2.5-py3-none-any.whl", "has_sig": false, "md5_digest": "b77ed89904d0c052e8957b6fc2aa2502", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 47581, "upload_time": "2019-10-27T16:58:51", "upload_time_iso_8601": "2019-10-27T16:58:51.320931Z", "url": "https://files.pythonhosted.org/packages/4e/a1/46e0eb6ab6778dacb7c7aabc6277a84773c8a2a8561cde4937c68d8b4895/optracker-1.2.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0684e690c0892ed00329f3246906dcc1", "sha256": "c3ddb15e633dca42871c166b44df997a08fa739080780729e462102f31e6b63a"}, "downloads": -1, "filename": "optracker-1.2.5.tar.gz", "has_sig": false, "md5_digest": "0684e690c0892ed00329f3246906dcc1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 42246, "upload_time": "2019-10-27T16:58:58", "upload_time_iso_8601": "2019-10-27T16:58:58.511917Z", "url": "https://files.pythonhosted.org/packages/74/3e/0f7869b7e7b08ba94d472e95b188d44453bfe5fbb612170507f67afa1522/optracker-1.2.5.tar.gz", "yanked": false}], "1.2.6": [{"comment_text": "", "digests": {"md5": "301443c66eefb72b1a03136ae6fac9ea", "sha256": "eeb2f36b4555c25fd0ad8d8bc064ad3c23f206dd4f72ea68d7f7d077d4afdca9"}, "downloads": -1, "filename": "optracker-1.2.6-py3-none-any.whl", "has_sig": false, "md5_digest": "301443c66eefb72b1a03136ae6fac9ea", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 47583, "upload_time": "2019-10-27T17:01:13", "upload_time_iso_8601": "2019-10-27T17:01:13.064790Z", "url": "https://files.pythonhosted.org/packages/23/ac/3931be0269423dabf6aeb7e145842c7c47619787c3acfba4bdff8637c45b/optracker-1.2.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7444770bc065114b3f9d841b9a86f37c", "sha256": "12b7935323dcae4e528bb75e3a3648c753fb37c3a0032e8072d00febb90cf4c9"}, "downloads": -1, "filename": "optracker-1.2.6.tar.gz", "has_sig": false, "md5_digest": "7444770bc065114b3f9d841b9a86f37c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 42242, "upload_time": "2019-10-27T17:01:20", "upload_time_iso_8601": "2019-10-27T17:01:20.132728Z", "url": "https://files.pythonhosted.org/packages/f1/bd/36d1da347b1d3064b5fd645316733386194a312150d46a214d779de30132/optracker-1.2.6.tar.gz", "yanked": false}], "1.3.6": [{"comment_text": "", "digests": {"md5": "2270b8e6e87c8491d086eb527d7e6188", "sha256": "0e5770ffa364da79692378fd60b65bc99af893bfa4990eca2832650d6c56b397"}, "downloads": -1, "filename": "optracker-1.3.6-py3-none-any.whl", "has_sig": false, "md5_digest": "2270b8e6e87c8491d086eb527d7e6188", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 28288592, "upload_time": "2019-11-05T17:41:36", "upload_time_iso_8601": "2019-11-05T17:41:36.413331Z", "url": "https://files.pythonhosted.org/packages/bb/fa/bef41bdf812d62d16bf4c2d6bada5902884941a12c46892cf88007b25afb/optracker-1.3.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fc41b7b35f23624e0738dc0f9a66af23", "sha256": "a39b8de36d269c9df3153a483c1308308472c4a1cb9f196bd40f1f18d979558f"}, "downloads": -1, "filename": "optracker-1.3.6.tar.gz", "has_sig": false, "md5_digest": "fc41b7b35f23624e0738dc0f9a66af23", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28246301, "upload_time": "2019-11-05T17:42:04", "upload_time_iso_8601": "2019-11-05T17:42:04.894608Z", "url": "https://files.pythonhosted.org/packages/14/57/c35f6fc8cfc206b580099cc1c3266e67aed6b2f13f1bef5cd464456d099d/optracker-1.3.6.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "2270b8e6e87c8491d086eb527d7e6188", "sha256": "0e5770ffa364da79692378fd60b65bc99af893bfa4990eca2832650d6c56b397"}, "downloads": -1, "filename": "optracker-1.3.6-py3-none-any.whl", "has_sig": false, "md5_digest": "2270b8e6e87c8491d086eb527d7e6188", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 28288592, "upload_time": "2019-11-05T17:41:36", "upload_time_iso_8601": "2019-11-05T17:41:36.413331Z", "url": "https://files.pythonhosted.org/packages/bb/fa/bef41bdf812d62d16bf4c2d6bada5902884941a12c46892cf88007b25afb/optracker-1.3.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fc41b7b35f23624e0738dc0f9a66af23", "sha256": "a39b8de36d269c9df3153a483c1308308472c4a1cb9f196bd40f1f18d979558f"}, "downloads": -1, "filename": "optracker-1.3.6.tar.gz", "has_sig": false, "md5_digest": "fc41b7b35f23624e0738dc0f9a66af23", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28246301, "upload_time": "2019-11-05T17:42:04", "upload_time_iso_8601": "2019-11-05T17:42:04.894608Z", "url": "https://files.pythonhosted.org/packages/14/57/c35f6fc8cfc206b580099cc1c3266e67aed6b2f13f1bef5cd464456d099d/optracker-1.3.6.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:01:57 2020"}