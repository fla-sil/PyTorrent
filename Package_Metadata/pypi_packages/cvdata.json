{"info": {"author": "James Adams", "author_email": "monocongo@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "![build](https://github.com/monocongo/cvdata/workflows/build/badge.svg)\n[![codecov](https://codecov.io/gh/monocongo/cvdata/branch/master/graph/badge.svg)](https://codecov.io/gh/monocongo/cvdata)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/cvdata)\n<!-- [![CircleCI](https://circleci.com/gh/monocongo/cvdata.svg?style=svg)](https://circleci.com/gh/monocongo/cvdata) -->\n\n# cvdata\nTools for creating and manipulating computer vision datasets\n\n## Installation\n\nThis package can be installed into the active Python environment, making the `cvdata` \nmodule available for import within other Python codes and available for utilization \nat the command line as illustrated in the usage examples below. This package \nis currently supported for Python versions 3.6 and 3.7, and the installation methods below \nassume that the package will be installed into a Python 3.6 or 3.7 virtual environment.\n\n##### From PyPI\nThis package can be installed into the active Python environment from PyPI via \n`pip`. In addition to installing this package from PyPI, users will also need to \ninstall the TensorFlow Object Detection API from that project's GitHub repository.\n```bash\n$ pip install cvdata\n$ pip install -e git+https://github.com/tensorflow/models.git#egg=object_detection\\&subdirectory=research\n```\n\n##### From source\nThis package can be installed into the active Python environment as source from \nits git repository. We'll first clone/download from GitHub and then install the \npackage into the active Python environment:\n```bash\n$ git clone git@github.com:monocongo/cvdata.git\n$ cd cvdata\n$ pip install -e .\n```\n\n## Resize images\nIn order to resize images and update the associated annotations use the script \n`cvdata/resize.py` or the corresponding script entry point `cvdata_resize`. This \nscript currently supports annotations in KITTI (*.txt) and PASCAL VOC (*.xml) formats. \nFor example to resize images to 1024x768 and update the associated annotations in \nKITTI format:\n```bash\n$ cvdata_resize --input_images /ssd_training/kitti/image_2 \\\n    --input_annotations /ssd_training/kitti/label_2 \\\n    --output_images /ssd_training/kitti/image_2 \\\n    --output_annotations /ssd_training/kitti/label_2 \\\n    --width 1024 --height 768 --format kitti\n```\n\nWe can also resize all images in a directory by using the same command as above \nbut without an annotation directory or format specified:\n```bash\n$ cvdata_resize --input_images /ssd_training/kitti/image_2 \\\n    --output_images /ssd_training/kitti/image_2 \\\n    --width 1024 --height 768\n```\n\n## Rename files\nIn order to perform bulk renaming of image files we provide the script \n`cvdata/rename` or the corresponding script entry point `cvdata_rename`. This \nallows us to specify a directory containing image files, all of which will be renamed \naccording to the `--prefix` (the prefix used for the resulting file names), `--start` \n(the initial number in the enumeration part of the new file names), and `--digits` \n(the width of the enumeration part of the new file names) arguments. For example: \n```bash\n$ cvdata_rename --images_dir ~/datasets/handgun/images --prefix handgun --start 100 --digits 6\n```\nIn a future release we'll support renaming of image and corresponding annotation \nfiles. For example:\n```bash\n$ cvdata_rename --annotations_dir ~/datasets/handgun/kitti \\\n>  --images_dir ~/datasets/handgun/images \\\n> --prefix handgun --start 100 --digits 6 \\\n> --format kitti --kitti_ids_file file_ids.txt\n```\n\n## Annotation format conversion\nIn order to convert from one annotation format to another use the script \n`cvdata/convert.py` or the corresponding script entry point `cvdata_convert`. This \nscript currently supports converting annotations from PASCAL to KITTI, from PASCAL \nto TFRecord, from PASCAL to OpenImages, from KITTI to Darknet, and from KITTI to \nTFRecord. For example: \n```bash\n$ cvdata_convert --in_format pascal --out_format kitti \\\n    --annotations_dir /data/handgun/pascal \\\n    --images_dir /data/handgun/images \\\n    --out_dir /data/handgun/kitti \\\n    --kitti_ids_file handgun.txt\n\n$ cvdata_convert --in_format kitti --out_format tfrecord \\\n    --annotations_dir /data/kitti \\ \n    --images_dir /data/images \\\n    --out_dir /data/tfrecord/dataset.tfrecord \\\n    --tf_label_map /data/tfrecord/label_map.pbtxt \\\n    --tf_shards 2\n``` \n\n## Image format conversion\nIn order to convert all images in a directory from PNG to JPG we can use the script \n`cvdata/convert.py` or the corresponding script entry point `cvdata_convert`. For \nexample:\n```bash\n$ cvdata_convert --in_format png --out_format jpg --images_dir /datasets/vehicle\n```\n\n## Rename annotation labels\nIn order to rename the image class labels of annotations use the script \n`cvdata/rename.py` or the corresponding script entry point `cvdata_rename`. This \nscript currently supports annotations in KITTI (*.txt) and PASCAL VOC (*.xml) \nformats. It is used to replace the label name for all annotation files of the \nspecified format in the specified directory. For example:\n```bash\n$ cvdata_rename.py --labels_dir /data/cvdata/pascal --old handgun --new firearm --format pascal\n```\n\n## Exclusion of unwanted images/annotations\nUnwanted images and (optionally) their corresponding annotations can be excluded \n(removed) from a dataset using the script `cvdata/exclude.py` or the corresponding \nscript entry point `cvdata_exclude`. For example: \n```bash\n$ cvdata_exclude --format pascal \\\n>  --exclusions /data/handgun/exclusions.txt\n>  --images /data/handgun/images \\\n>  --annotations /data/handgun/pascal \\\n```\nThe script can also be used to filter out only corresponding image files by omitting \nthe `--annotations` argument and corresponding `--format` argument. For example: \n```bash\n$ cvdata_exclude --exclusions /data/handgun/exclusions.txt --images /data/handgun/images\n```\n\n## Sanitize dataset\nIn order to clean a dataset's annotations we can utilize the script `cvdata/clean.py` \nor the corresponding script entry point `cvdata_clean` which will convert the images \nto JPG (if any are in PNG format), (optionally) replace labels, (optionally) remove \nbounding boxes that contain specified labels, and update the annotation files so that \nall bounding boxes are within reasonable ranges. If specified then offending/problematic \nfiles can be moved into a \"problems\" directory, otherwise they will be removed. \nFor example:\n```bash\n$ cvdata_clean --format pascal \\\n>    --annotations_dir /data/datasets/delivery_truck/pascal \\\n>    --images_dir /data/datasets/delivery_truck/images \\\n>    --problems_dir /data/datasets/delivery_truck/problem \\\n>    --replace_labels deivery:delivery truck:ups \\\n>    --remove_labels bus train\n```\n\n## Split dataset into training, validation, and test subsets\nIn order to split a dataset into training, validation, and test subsets we can \nutilize the script `cvdata/split.py` or the corresponding script entry point `cvdata_split`. \nThis script's CLI contains options for specifying the source dataset's images and \nannotations directories and the destination images and annotations directories for \nthe respective train/valid/test subset splits. The default split ratio is 70% training, \n20% validation, and 10% testing but can be modified with the `--split` argument \n(these are colon-separated float values and should sum to 1). For example: \n```bash\n$ cvdata_split --annotations_dir /data/rifle/kitti/label_2 \\\n> --images_dir /data/rifle/kitti/image_2 \\\n> --train_annotations_dir /data/rifle/split/kitti/trainval/label_2 \\\n> --train_images_dir /data/rifle/split/kitti/trainval/image_2 \\\n> --val_annotations_dir /data/rifle/split/kitti/trainval/label_2 \\\n> --val_images_dir /data/rifle/split/kitti/trainval/image_2 \\\n> --test_annotations_dir /data/rifle/split/kitti/test/label_2 \\\n> --test_images_dir /data/rifle/split/kitti/test/image_2 \\\n> --format kitti --split 0.65:0.25:0.1 --move\n```\nIn the case where only images are required to be split, we can omit the \nannotations related arguments from the command:\n```bash\n$ cvdata_split --images_dir /data/rifle/kitti/image_2 \\\n> --train_images_dir /data/rifle/split/kitti/train/image_2 \\\n> --val_images_dir /data/rifle/split/kitti/valid/image_2 \\\n> --test_images_dir /data/rifle/split/kitti/test/image_2 \\\n> --move\n```\n\n## Filtering\nThe module/script `cvdata/filter.py` or the corresponding script entry point `cvdata_filter` \ncan be used to filter the number of image/annotation files of a dataset. It currently \nsupports limiting the number of bounding boxes per class type. The filtered dataset \nwill contain annotation files with bounding boxes only for the class labels specified \nand limited to the number of boxes specified for each class label. For example: \n```bash\n$ cvdata_filter --format darknet \\\n    --src_annotations /data/darknet \\ \n    --dest_annotations /data/filtered_darknet \\\n    --src_images /data/images \\\n    --dest_images /data/filtered_images \\\n    --darknet_labels /data/darknet/labels.txt \\\n    --boxes_per_class car:6000 truck:6000\n```\n\n## Relabel annotations\nThe module/script `cvdata/relabel.py` or the corresponding script entry point `cvdata_relabel` \ncan be used to filter the number of image/annotation files of a dataset. For example, \nto relabel all PASCAL annotation files in a directory from \"dog\" to \"beagle\":\n```bash\n$ cvdata_relabel --labels_dir /data/cvdata/pascal \\\n  --old dog --new beagle --format pascal\n```\nSince Darknet (YOLO) annotation files use index values that correspond to entries \nin a class labels file we would use integer values for the `--old` and `--new` \narguments:\n```bash\n$ cvdata_relabel --labels_dir /data/cvdata/darknet \\\n  --old 1 --new 4 --format darknet\n```\nThis function currently supports `darknet`, `kitti`, and `pascal` formats.\n\n## Remove duplicates\nThe module/script `cvdata/duplicates.py`  or the corresponding script entry point \n`cvdata_duplicates` can be used to remove duplicate images from a directory. This \nworks on images that are similar, i.e. images don't need to be exactly the same. \nOptionally the module can remove corresponding annotation files, assuming that the \nannotation file names correspond to the image file names (for example `abc.jpg` and \n`abc.xml`). Also we can move the duplicate files into a separate directory rather \nthan removing the files if a directory for duplicates is specified. For example:\n```bash\n$ cvdata_duplicates --images_dir /data/trucks/ups/images \\\n>   --annotations_dir /data/trucks/ups/pascal \\\n>   --dups_dir /data/trucks/ups/dups\n```\n\n## Masks\nCreate masks from region polygons described in an annotation JSON file created by \nthe [VGG Image Annotator](http://www.robots.ox.ac.uk/~vgg/software/via/via.html) tool:\n```bash\n$ cvdata_mask --images /data/images \\\n>   --annotations /data/via_annotations.json \\\n>   --masks /data/masks \\\n>   --format vgg \\\n>   --classes /data/class_labels.txt\n```\nMasks will be written with the mask value corresponding to the class ID. For example, \nif we have a class labels file with a single label, then the only class ID is 1 \nand so the masks will have a pixel value of (1, 1, 1) where pixels are masked.\n\nBy default each mask described in the annotations file will result in a separate \nmask file. So, for example, if the annotation for image file \"abc.jpg\" includes \ntwo mask regions then the resulting mask files will be named \"abc_0_segmentation.png\" \nand \"abc_0_segmentation.png\". However, if the `--combine` option is used then all \nmasks for an images will be included in a single mask file, so the single mask file \ncorresponding to image file named \"abc.jpg\" will be \"abc_segmentation.png\".\n\nWe can also use the `cvdata_mask` script entry point to create TFRecord files \nfrom an input dataset of JPG images and corresponding PNG masks. For this scenario \nwe expect the mask files to have the same base file name as the images files, and \nfor the image and mask files to be present in their own separate directories. For \nexample:\n```bash\n$ cvdata_mask --images /data/images --masks /data/masks \\\n>       --in_format png --out_format tfrecord \\\n>       --tfrecords /data/tfrecords \\\n>       --shards 4 -- train_pct 0.8\n```\n## Visualize annotations\nIn order to visualize images and corresponding annotations use the script \n`cvdata/visualize.py` or the corresponding script entry point `cvdata_visualize`. \nThis script currently supports annotations in COCO (*.json), Darknet (*.txt), KITTI \n(*.txt), TFRecords, and PASCAL VOC (*.xml) formats. It will display bounding boxes \nand labels for all images/annotations in the specified images and annotations \ndirectories. For example:\n```bash\n$ cvdata_visualize --format pascal --images_dir /data/weapons/images --annotations_dir /data/weapons/pascal\n```\n\n### For developers\n##### Testing\nTests are based on `pytest` and are launched in stand-alone virtual environments \nvia [tox](https://tox.readthedocs.io/en/latest/): \n```bash\n$ tox\n```\n\n## Citation\n```\n@misc {cvdata,\n    author = \"James Adams\",\n    title  = \"cvdata, an open source Python library for manipulating computer vision datasets\",\n    url    = \"https://github.com/monocongo/cvdata\",\n    month  = \"october\",\n    year   = \"2019--\"\n}\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/monocongo/cvdata", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "cvdata", "package_url": "https://pypi.org/project/cvdata/", "platform": "", "project_url": "https://pypi.org/project/cvdata/", "project_urls": {"Homepage": "https://github.com/monocongo/cvdata"}, "release_url": "https://pypi.org/project/cvdata/0.0.7/", "requires_dist": ["contextlib2", "lxml", "ImageHash", "opencv-python", "pandas", "pillow", "tensorflow-cpu (>=2.1)", "tqdm"], "requires_python": ">=3.6,<3.8", "summary": "Tools for creating and manipulating computer vision datasets", "version": "0.0.7", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><img alt=\"build\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c982c5a3f3016f32e0cf4b9f0dc56762d2553074/68747470733a2f2f6769746875622e636f6d2f6d6f6e6f636f6e676f2f6376646174612f776f726b666c6f77732f6275696c642f62616467652e737667\">\n<a href=\"https://codecov.io/gh/monocongo/cvdata\" rel=\"nofollow\"><img alt=\"codecov\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d5bd3c7fbb907713ce941200b1ad615f2175679f/68747470733a2f2f636f6465636f762e696f2f67682f6d6f6e6f636f6e676f2f6376646174612f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a>\n<a href=\"https://opensource.org/licenses/MIT\" rel=\"nofollow\"><img alt=\"License: MIT\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8645b002dd7ec1b54275a80574942e7a318e03c6/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d79656c6c6f772e737667\"></a>\n<img alt=\"PyPI - Python Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5147ab55659033113ef9fe3e9312496c9a3b8381/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f637664617461\"></p>\n\n<h1>cvdata</h1>\n<p>Tools for creating and manipulating computer vision datasets</p>\n<h2>Installation</h2>\n<p>This package can be installed into the active Python environment, making the <code>cvdata</code>\nmodule available for import within other Python codes and available for utilization\nat the command line as illustrated in the usage examples below. This package\nis currently supported for Python versions 3.6 and 3.7, and the installation methods below\nassume that the package will be installed into a Python 3.6 or 3.7 virtual environment.</p>\n<h5>From PyPI</h5>\n<p>This package can be installed into the active Python environment from PyPI via\n<code>pip</code>. In addition to installing this package from PyPI, users will also need to\ninstall the TensorFlow Object Detection API from that project's GitHub repository.</p>\n<pre>$ pip install cvdata\n$ pip install -e git+https://github.com/tensorflow/models.git#egg<span class=\"o\">=</span>object_detection<span class=\"se\">\\&amp;</span><span class=\"nv\">subdirectory</span><span class=\"o\">=</span>research\n</pre>\n<h5>From source</h5>\n<p>This package can be installed into the active Python environment as source from\nits git repository. We'll first clone/download from GitHub and then install the\npackage into the active Python environment:</p>\n<pre>$ git clone git@github.com:monocongo/cvdata.git\n$ <span class=\"nb\">cd</span> cvdata\n$ pip install -e .\n</pre>\n<h2>Resize images</h2>\n<p>In order to resize images and update the associated annotations use the script\n<code>cvdata/resize.py</code> or the corresponding script entry point <code>cvdata_resize</code>. This\nscript currently supports annotations in KITTI (<em>.txt) and PASCAL VOC (</em>.xml) formats.\nFor example to resize images to 1024x768 and update the associated annotations in\nKITTI format:</p>\n<pre>$ cvdata_resize --input_images /ssd_training/kitti/image_2 <span class=\"se\">\\</span>\n    --input_annotations /ssd_training/kitti/label_2 <span class=\"se\">\\</span>\n    --output_images /ssd_training/kitti/image_2 <span class=\"se\">\\</span>\n    --output_annotations /ssd_training/kitti/label_2 <span class=\"se\">\\</span>\n    --width <span class=\"m\">1024</span> --height <span class=\"m\">768</span> --format kitti\n</pre>\n<p>We can also resize all images in a directory by using the same command as above\nbut without an annotation directory or format specified:</p>\n<pre>$ cvdata_resize --input_images /ssd_training/kitti/image_2 <span class=\"se\">\\</span>\n    --output_images /ssd_training/kitti/image_2 <span class=\"se\">\\</span>\n    --width <span class=\"m\">1024</span> --height <span class=\"m\">768</span>\n</pre>\n<h2>Rename files</h2>\n<p>In order to perform bulk renaming of image files we provide the script\n<code>cvdata/rename</code> or the corresponding script entry point <code>cvdata_rename</code>. This\nallows us to specify a directory containing image files, all of which will be renamed\naccording to the <code>--prefix</code> (the prefix used for the resulting file names), <code>--start</code>\n(the initial number in the enumeration part of the new file names), and <code>--digits</code>\n(the width of the enumeration part of the new file names) arguments. For example:</p>\n<pre>$ cvdata_rename --images_dir ~/datasets/handgun/images --prefix handgun --start <span class=\"m\">100</span> --digits <span class=\"m\">6</span>\n</pre>\n<p>In a future release we'll support renaming of image and corresponding annotation\nfiles. For example:</p>\n<pre>$ cvdata_rename --annotations_dir ~/datasets/handgun/kitti <span class=\"se\">\\</span>\n&gt;  --images_dir ~/datasets/handgun/images <span class=\"se\">\\</span>\n&gt; --prefix handgun --start <span class=\"m\">100</span> --digits <span class=\"m\">6</span> <span class=\"se\">\\</span>\n&gt; --format kitti --kitti_ids_file file_ids.txt\n</pre>\n<h2>Annotation format conversion</h2>\n<p>In order to convert from one annotation format to another use the script\n<code>cvdata/convert.py</code> or the corresponding script entry point <code>cvdata_convert</code>. This\nscript currently supports converting annotations from PASCAL to KITTI, from PASCAL\nto TFRecord, from PASCAL to OpenImages, from KITTI to Darknet, and from KITTI to\nTFRecord. For example:</p>\n<pre>$ cvdata_convert --in_format pascal --out_format kitti <span class=\"se\">\\</span>\n    --annotations_dir /data/handgun/pascal <span class=\"se\">\\</span>\n    --images_dir /data/handgun/images <span class=\"se\">\\</span>\n    --out_dir /data/handgun/kitti <span class=\"se\">\\</span>\n    --kitti_ids_file handgun.txt\n\n$ cvdata_convert --in_format kitti --out_format tfrecord <span class=\"se\">\\</span>\n    --annotations_dir /data/kitti <span class=\"se\">\\ </span>\n    --images_dir /data/images <span class=\"se\">\\</span>\n    --out_dir /data/tfrecord/dataset.tfrecord <span class=\"se\">\\</span>\n    --tf_label_map /data/tfrecord/label_map.pbtxt <span class=\"se\">\\</span>\n    --tf_shards <span class=\"m\">2</span>\n</pre>\n<h2>Image format conversion</h2>\n<p>In order to convert all images in a directory from PNG to JPG we can use the script\n<code>cvdata/convert.py</code> or the corresponding script entry point <code>cvdata_convert</code>. For\nexample:</p>\n<pre>$ cvdata_convert --in_format png --out_format jpg --images_dir /datasets/vehicle\n</pre>\n<h2>Rename annotation labels</h2>\n<p>In order to rename the image class labels of annotations use the script\n<code>cvdata/rename.py</code> or the corresponding script entry point <code>cvdata_rename</code>. This\nscript currently supports annotations in KITTI (<em>.txt) and PASCAL VOC (</em>.xml)\nformats. It is used to replace the label name for all annotation files of the\nspecified format in the specified directory. For example:</p>\n<pre>$ cvdata_rename.py --labels_dir /data/cvdata/pascal --old handgun --new firearm --format pascal\n</pre>\n<h2>Exclusion of unwanted images/annotations</h2>\n<p>Unwanted images and (optionally) their corresponding annotations can be excluded\n(removed) from a dataset using the script <code>cvdata/exclude.py</code> or the corresponding\nscript entry point <code>cvdata_exclude</code>. For example:</p>\n<pre>$ cvdata_exclude --format pascal <span class=\"se\">\\</span>\n&gt;  --exclusions /data/handgun/exclusions.txt\n&gt;  --images /data/handgun/images <span class=\"se\">\\</span>\n&gt;  --annotations /data/handgun/pascal <span class=\"se\">\\</span>\n</pre>\n<p>The script can also be used to filter out only corresponding image files by omitting\nthe <code>--annotations</code> argument and corresponding <code>--format</code> argument. For example:</p>\n<pre>$ cvdata_exclude --exclusions /data/handgun/exclusions.txt --images /data/handgun/images\n</pre>\n<h2>Sanitize dataset</h2>\n<p>In order to clean a dataset's annotations we can utilize the script <code>cvdata/clean.py</code>\nor the corresponding script entry point <code>cvdata_clean</code> which will convert the images\nto JPG (if any are in PNG format), (optionally) replace labels, (optionally) remove\nbounding boxes that contain specified labels, and update the annotation files so that\nall bounding boxes are within reasonable ranges. If specified then offending/problematic\nfiles can be moved into a \"problems\" directory, otherwise they will be removed.\nFor example:</p>\n<pre>$ cvdata_clean --format pascal <span class=\"se\">\\</span>\n&gt;    --annotations_dir /data/datasets/delivery_truck/pascal <span class=\"se\">\\</span>\n&gt;    --images_dir /data/datasets/delivery_truck/images <span class=\"se\">\\</span>\n&gt;    --problems_dir /data/datasets/delivery_truck/problem <span class=\"se\">\\</span>\n&gt;    --replace_labels deivery:delivery truck:ups <span class=\"se\">\\</span>\n&gt;    --remove_labels bus train\n</pre>\n<h2>Split dataset into training, validation, and test subsets</h2>\n<p>In order to split a dataset into training, validation, and test subsets we can\nutilize the script <code>cvdata/split.py</code> or the corresponding script entry point <code>cvdata_split</code>.\nThis script's CLI contains options for specifying the source dataset's images and\nannotations directories and the destination images and annotations directories for\nthe respective train/valid/test subset splits. The default split ratio is 70% training,\n20% validation, and 10% testing but can be modified with the <code>--split</code> argument\n(these are colon-separated float values and should sum to 1). For example:</p>\n<pre>$ cvdata_split --annotations_dir /data/rifle/kitti/label_2 <span class=\"se\">\\</span>\n&gt; --images_dir /data/rifle/kitti/image_2 <span class=\"se\">\\</span>\n&gt; --train_annotations_dir /data/rifle/split/kitti/trainval/label_2 <span class=\"se\">\\</span>\n&gt; --train_images_dir /data/rifle/split/kitti/trainval/image_2 <span class=\"se\">\\</span>\n&gt; --val_annotations_dir /data/rifle/split/kitti/trainval/label_2 <span class=\"se\">\\</span>\n&gt; --val_images_dir /data/rifle/split/kitti/trainval/image_2 <span class=\"se\">\\</span>\n&gt; --test_annotations_dir /data/rifle/split/kitti/test/label_2 <span class=\"se\">\\</span>\n&gt; --test_images_dir /data/rifle/split/kitti/test/image_2 <span class=\"se\">\\</span>\n&gt; --format kitti --split <span class=\"m\">0</span>.65:0.25:0.1 --move\n</pre>\n<p>In the case where only images are required to be split, we can omit the\nannotations related arguments from the command:</p>\n<pre>$ cvdata_split --images_dir /data/rifle/kitti/image_2 <span class=\"se\">\\</span>\n&gt; --train_images_dir /data/rifle/split/kitti/train/image_2 <span class=\"se\">\\</span>\n&gt; --val_images_dir /data/rifle/split/kitti/valid/image_2 <span class=\"se\">\\</span>\n&gt; --test_images_dir /data/rifle/split/kitti/test/image_2 <span class=\"se\">\\</span>\n&gt; --move\n</pre>\n<h2>Filtering</h2>\n<p>The module/script <code>cvdata/filter.py</code> or the corresponding script entry point <code>cvdata_filter</code>\ncan be used to filter the number of image/annotation files of a dataset. It currently\nsupports limiting the number of bounding boxes per class type. The filtered dataset\nwill contain annotation files with bounding boxes only for the class labels specified\nand limited to the number of boxes specified for each class label. For example:</p>\n<pre>$ cvdata_filter --format darknet <span class=\"se\">\\</span>\n    --src_annotations /data/darknet <span class=\"se\">\\ </span>\n    --dest_annotations /data/filtered_darknet <span class=\"se\">\\</span>\n    --src_images /data/images <span class=\"se\">\\</span>\n    --dest_images /data/filtered_images <span class=\"se\">\\</span>\n    --darknet_labels /data/darknet/labels.txt <span class=\"se\">\\</span>\n    --boxes_per_class car:6000 truck:6000\n</pre>\n<h2>Relabel annotations</h2>\n<p>The module/script <code>cvdata/relabel.py</code> or the corresponding script entry point <code>cvdata_relabel</code>\ncan be used to filter the number of image/annotation files of a dataset. For example,\nto relabel all PASCAL annotation files in a directory from \"dog\" to \"beagle\":</p>\n<pre>$ cvdata_relabel --labels_dir /data/cvdata/pascal <span class=\"se\">\\</span>\n  --old dog --new beagle --format pascal\n</pre>\n<p>Since Darknet (YOLO) annotation files use index values that correspond to entries\nin a class labels file we would use integer values for the <code>--old</code> and <code>--new</code>\narguments:</p>\n<pre>$ cvdata_relabel --labels_dir /data/cvdata/darknet <span class=\"se\">\\</span>\n  --old <span class=\"m\">1</span> --new <span class=\"m\">4</span> --format darknet\n</pre>\n<p>This function currently supports <code>darknet</code>, <code>kitti</code>, and <code>pascal</code> formats.</p>\n<h2>Remove duplicates</h2>\n<p>The module/script <code>cvdata/duplicates.py</code>  or the corresponding script entry point\n<code>cvdata_duplicates</code> can be used to remove duplicate images from a directory. This\nworks on images that are similar, i.e. images don't need to be exactly the same.\nOptionally the module can remove corresponding annotation files, assuming that the\nannotation file names correspond to the image file names (for example <code>abc.jpg</code> and\n<code>abc.xml</code>). Also we can move the duplicate files into a separate directory rather\nthan removing the files if a directory for duplicates is specified. For example:</p>\n<pre>$ cvdata_duplicates --images_dir /data/trucks/ups/images <span class=\"se\">\\</span>\n&gt;   --annotations_dir /data/trucks/ups/pascal <span class=\"se\">\\</span>\n&gt;   --dups_dir /data/trucks/ups/dups\n</pre>\n<h2>Masks</h2>\n<p>Create masks from region polygons described in an annotation JSON file created by\nthe <a href=\"http://www.robots.ox.ac.uk/%7Evgg/software/via/via.html\" rel=\"nofollow\">VGG Image Annotator</a> tool:</p>\n<pre>$ cvdata_mask --images /data/images <span class=\"se\">\\</span>\n&gt;   --annotations /data/via_annotations.json <span class=\"se\">\\</span>\n&gt;   --masks /data/masks <span class=\"se\">\\</span>\n&gt;   --format vgg <span class=\"se\">\\</span>\n&gt;   --classes /data/class_labels.txt\n</pre>\n<p>Masks will be written with the mask value corresponding to the class ID. For example,\nif we have a class labels file with a single label, then the only class ID is 1\nand so the masks will have a pixel value of (1, 1, 1) where pixels are masked.</p>\n<p>By default each mask described in the annotations file will result in a separate\nmask file. So, for example, if the annotation for image file \"abc.jpg\" includes\ntwo mask regions then the resulting mask files will be named \"abc_0_segmentation.png\"\nand \"abc_0_segmentation.png\". However, if the <code>--combine</code> option is used then all\nmasks for an images will be included in a single mask file, so the single mask file\ncorresponding to image file named \"abc.jpg\" will be \"abc_segmentation.png\".</p>\n<p>We can also use the <code>cvdata_mask</code> script entry point to create TFRecord files\nfrom an input dataset of JPG images and corresponding PNG masks. For this scenario\nwe expect the mask files to have the same base file name as the images files, and\nfor the image and mask files to be present in their own separate directories. For\nexample:</p>\n<pre>$ cvdata_mask --images /data/images --masks /data/masks <span class=\"se\">\\</span>\n&gt;       --in_format png --out_format tfrecord <span class=\"se\">\\</span>\n&gt;       --tfrecords /data/tfrecords <span class=\"se\">\\</span>\n&gt;       --shards <span class=\"m\">4</span> -- train_pct <span class=\"m\">0</span>.8\n</pre>\n<h2>Visualize annotations</h2>\n<p>In order to visualize images and corresponding annotations use the script\n<code>cvdata/visualize.py</code> or the corresponding script entry point <code>cvdata_visualize</code>.\nThis script currently supports annotations in COCO (<em>.json), Darknet (</em>.txt), KITTI\n(<em>.txt), TFRecords, and PASCAL VOC (</em>.xml) formats. It will display bounding boxes\nand labels for all images/annotations in the specified images and annotations\ndirectories. For example:</p>\n<pre>$ cvdata_visualize --format pascal --images_dir /data/weapons/images --annotations_dir /data/weapons/pascal\n</pre>\n<h3>For developers</h3>\n<h5>Testing</h5>\n<p>Tests are based on <code>pytest</code> and are launched in stand-alone virtual environments\nvia <a href=\"https://tox.readthedocs.io/en/latest/\" rel=\"nofollow\">tox</a>:</p>\n<pre>$ tox\n</pre>\n<h2>Citation</h2>\n<pre><code>@misc {cvdata,\n    author = \"James Adams\",\n    title  = \"cvdata, an open source Python library for manipulating computer vision datasets\",\n    url    = \"https://github.com/monocongo/cvdata\",\n    month  = \"october\",\n    year   = \"2019--\"\n}\n\n\n</code></pre>\n\n          </div>"}, "last_serial": 6585523, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "dc3d42cccb28ca77dd862e9a8a5e2f3c", "sha256": "6d65b3ea5c5a6cc83cf31127749945b4d25f0d3263bdd63120e39ca3a2d82eca"}, "downloads": -1, "filename": "cvdata-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "dc3d42cccb28ca77dd862e9a8a5e2f3c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.0, <3.8", "size": 32121, "upload_time": "2019-11-27T18:51:58", "upload_time_iso_8601": "2019-11-27T18:51:58.813584Z", "url": "https://files.pythonhosted.org/packages/1d/9a/d69284ff46f1f2b1e6d4def8bfd75dbb85457a7aa1deb39219b89e1d1118/cvdata-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b5b745657d588ead2b22245db22754d1", "sha256": "0b436239defe5bd0aa067d10dd4f69fd175c0e3479a764525f1f7796bfcb9826"}, "downloads": -1, "filename": "cvdata-0.0.1.tar.gz", "has_sig": false, "md5_digest": "b5b745657d588ead2b22245db22754d1", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.0, <3.8", "size": 24248, "upload_time": "2019-11-27T18:52:01", "upload_time_iso_8601": "2019-11-27T18:52:01.361168Z", "url": "https://files.pythonhosted.org/packages/03/0c/57536d7ba0397d98022d4cedcccdd4d75ea68ff2b7e5e79f7da6472e9a64/cvdata-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "e17b68b1145ee69a7b90ecaa8445b9f6", "sha256": "039221a98663933eb00e16e92f88120044052dc0ce84c8791b33ae0f1345b5b9"}, "downloads": -1, "filename": "cvdata-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "e17b68b1145ee69a7b90ecaa8445b9f6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.0", "size": 32359, "upload_time": "2019-11-27T19:13:14", "upload_time_iso_8601": "2019-11-27T19:13:14.655550Z", "url": "https://files.pythonhosted.org/packages/84/fa/f51268129a7cf0b5ac2e0e12ce660986c265de11b6b42f0ab8c1b443d30e/cvdata-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b1a80a20684bae799d04ec8ef24b74ee", "sha256": "19f0cbd8d8166dd5cbfe382c3f375bd4d8d7e945fd288f8c266ce984dd38fb3f"}, "downloads": -1, "filename": "cvdata-0.0.2.tar.gz", "has_sig": false, "md5_digest": "b1a80a20684bae799d04ec8ef24b74ee", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.0", "size": 24769, "upload_time": "2019-11-27T19:13:16", "upload_time_iso_8601": "2019-11-27T19:13:16.229178Z", "url": "https://files.pythonhosted.org/packages/c1/76/b7ce694a04108a874269287791b1eaf50e8aaaa3202233a5b7ac4feb4bd4/cvdata-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "4c21e5d98f115dd7b392a2e4d0701804", "sha256": "ecfe673a8bb7a2d835ef2ba076b3a42598a88188271abb25774d24cd50d75c04"}, "downloads": -1, "filename": "cvdata-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "4c21e5d98f115dd7b392a2e4d0701804", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.0", "size": 37334, "upload_time": "2019-12-18T16:53:46", "upload_time_iso_8601": "2019-12-18T16:53:46.725289Z", "url": "https://files.pythonhosted.org/packages/7c/33/ad3499f2cfbd21205417942ccd5565427b35cabbbf63670a7346e7013e7e/cvdata-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0ee70491332ef47a90711a97224b3ebd", "sha256": "387a225a11ff59535556b49c5dd0819bb668dcf3ee504a4f73d00e799dda9f1e"}, "downloads": -1, "filename": "cvdata-0.0.3.tar.gz", "has_sig": false, "md5_digest": "0ee70491332ef47a90711a97224b3ebd", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.0", "size": 30020, "upload_time": "2019-12-18T16:53:48", "upload_time_iso_8601": "2019-12-18T16:53:48.257306Z", "url": "https://files.pythonhosted.org/packages/0f/bd/3c093aac63058dc374accd6dcb2c877461e24ac0255defb49e7a89061bb8/cvdata-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "9a1d3ca98359217645fa82b45b2d72de", "sha256": "9045924fd63fbb2b73195e5bb5199ba21586cc14f78291c039775fe98e5c8a65"}, "downloads": -1, "filename": "cvdata-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "9a1d3ca98359217645fa82b45b2d72de", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": "==3.7.*", "size": 48844, "upload_time": "2020-01-08T17:54:20", "upload_time_iso_8601": "2020-01-08T17:54:20.678982Z", "url": "https://files.pythonhosted.org/packages/0f/ea/018155e50f19126ca7661524ed18a0880c4541ebf7addadf7f19db5bbf00/cvdata-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "65c6e6da547283b11cb81916baa0df7d", "sha256": "40c2824f0df5848fb3511509d9d4e9c97fcaee11645eb4c83d32ccc673ad15b9"}, "downloads": -1, "filename": "cvdata-0.0.4.tar.gz", "has_sig": false, "md5_digest": "65c6e6da547283b11cb81916baa0df7d", "packagetype": "sdist", "python_version": "source", "requires_python": "==3.7.*", "size": 41525, "upload_time": "2020-01-08T17:54:22", "upload_time_iso_8601": "2020-01-08T17:54:22.475048Z", "url": "https://files.pythonhosted.org/packages/22/fd/a76f9f8cc7c2a59603782c868ebfb3378d4ce2cf7ad61e6e82ab733922db/cvdata-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "bc3c6d186e2d9bad9f6a56e56251468b", "sha256": "7fc07765640b65a57215cf4cc8732ff08cbbc963755c5f7d1fd4a094c7d3d7dd"}, "downloads": -1, "filename": "cvdata-0.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "bc3c6d186e2d9bad9f6a56e56251468b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": "==3.7.*", "size": 51348, "upload_time": "2020-01-13T04:11:38", "upload_time_iso_8601": "2020-01-13T04:11:38.090838Z", "url": "https://files.pythonhosted.org/packages/a3/54/ebe9545e13e43f9b90b44356f2dfbb81a42e78e779edb177d70be3177350/cvdata-0.0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6b6cc34c7f4278192d9d8a7b0bf3bdfa", "sha256": "95b1e5a7200bbabb0f3a756f69258975f38999799ca2b53f9d6d9d5a5edac46f"}, "downloads": -1, "filename": "cvdata-0.0.5.tar.gz", "has_sig": false, "md5_digest": "6b6cc34c7f4278192d9d8a7b0bf3bdfa", "packagetype": "sdist", "python_version": "source", "requires_python": "==3.7.*", "size": 43531, "upload_time": "2020-01-13T04:11:39", "upload_time_iso_8601": "2020-01-13T04:11:39.440903Z", "url": "https://files.pythonhosted.org/packages/41/a7/b469005ff5cf8613241c91b176248f468326dc0cbc9f2359eb398cdcc8f7/cvdata-0.0.5.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "b5c4c9b10eb1b4a42608a93d98e8531a", "sha256": "c7e29400071bacb4b82e27454a820b4cbae0e795bcfa0bc88d46756d1711238b"}, "downloads": -1, "filename": "cvdata-0.0.6-py3-none-any.whl", "has_sig": false, "md5_digest": "b5c4c9b10eb1b4a42608a93d98e8531a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": "==3.7.*", "size": 54902, "upload_time": "2020-01-25T00:26:11", "upload_time_iso_8601": "2020-01-25T00:26:11.489293Z", "url": "https://files.pythonhosted.org/packages/22/ec/e037969a3fd5a5fb70474fecfa955f149a8ca96a116efba133cee89f18d3/cvdata-0.0.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "256a3abc87471c4b2f5c5b63c016acf7", "sha256": "998ac45f66baed9551c5e5fbea68a1c98897089881a59c50ae4287bc4a60c857"}, "downloads": -1, "filename": "cvdata-0.0.6.tar.gz", "has_sig": false, "md5_digest": "256a3abc87471c4b2f5c5b63c016acf7", "packagetype": "sdist", "python_version": "source", "requires_python": "==3.7.*", "size": 47512, "upload_time": "2020-01-25T00:26:13", "upload_time_iso_8601": "2020-01-25T00:26:13.239382Z", "url": "https://files.pythonhosted.org/packages/18/80/6fc403d2d85efb89c66c6e5f043896db1fad2244881279d88d886dca54b7/cvdata-0.0.6.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "6f0cdb62e14592e75e12bde9c7d5409e", "sha256": "6c047965058bbfbd2902c1841207b343575d7db4ed34e5462ab8f1c42bc75941"}, "downloads": -1, "filename": "cvdata-0.0.7-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "6f0cdb62e14592e75e12bde9c7d5409e", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6,<3.8", "size": 49189, "upload_time": "2020-02-07T00:19:31", "upload_time_iso_8601": "2020-02-07T00:19:31.991870Z", "url": "https://files.pythonhosted.org/packages/47/e5/5361375b284ac1da759cf78329f8484cb33c039c4c91e38862ca4cba2ae6/cvdata-0.0.7-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3e7a2de1bed1ec3a586f24f1e63a2b8d", "sha256": "aecb35b5174c91a46f99b221d22ea7d445a4c60bdbcffd81100f450cc88c78ec"}, "downloads": -1, "filename": "cvdata-0.0.7.tar.gz", "has_sig": false, "md5_digest": "3e7a2de1bed1ec3a586f24f1e63a2b8d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6,<3.8", "size": 75731, "upload_time": "2020-02-07T00:19:33", "upload_time_iso_8601": "2020-02-07T00:19:33.474783Z", "url": "https://files.pythonhosted.org/packages/bb/45/258b4f36cf7acaf918627dca0adefa2f69e025e5f61de8da6df6dfd4e42b/cvdata-0.0.7.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "6f0cdb62e14592e75e12bde9c7d5409e", "sha256": "6c047965058bbfbd2902c1841207b343575d7db4ed34e5462ab8f1c42bc75941"}, "downloads": -1, "filename": "cvdata-0.0.7-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "6f0cdb62e14592e75e12bde9c7d5409e", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6,<3.8", "size": 49189, "upload_time": "2020-02-07T00:19:31", "upload_time_iso_8601": "2020-02-07T00:19:31.991870Z", "url": "https://files.pythonhosted.org/packages/47/e5/5361375b284ac1da759cf78329f8484cb33c039c4c91e38862ca4cba2ae6/cvdata-0.0.7-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3e7a2de1bed1ec3a586f24f1e63a2b8d", "sha256": "aecb35b5174c91a46f99b221d22ea7d445a4c60bdbcffd81100f450cc88c78ec"}, "downloads": -1, "filename": "cvdata-0.0.7.tar.gz", "has_sig": false, "md5_digest": "3e7a2de1bed1ec3a586f24f1e63a2b8d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6,<3.8", "size": 75731, "upload_time": "2020-02-07T00:19:33", "upload_time_iso_8601": "2020-02-07T00:19:33.474783Z", "url": "https://files.pythonhosted.org/packages/bb/45/258b4f36cf7acaf918627dca0adefa2f69e025e5f61de8da6df6dfd4e42b/cvdata-0.0.7.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:41:14 2020"}