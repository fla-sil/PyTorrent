{"info": {"author": "Angela Lambert", "author_email": "alambe13@terpmail.umd.edu", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# Alphabet Soup\n\n> You have been contracted from a newspaper tasked with the job of providing an answer key to their word search for the \n>Sunday print. The newspaper's word search is a traditional game consisting of a grid of characters in which a selection \n>of words have been hidden. You are provided with the list of words that have been hidden and must find the words within \n>the grid of characters. \n\n## Requirements\nLoad a character grid with scrambled words embedded within it and a words list of the words to find.  The following \nconditions apply:\n\n- Within the grid of characters, the words may appear vertical, horizontal or diagonal.\n- Within the grid of characters, the words may appear forwards or backwards. \n- Words that have spaces in them will not include spaces when hidden in the grid of characters.\n\n# Execution\nWhen approaching this problem, I first made a list of what I needed- a way to read and store the words and the grid from\nthe given file. I also needed to write functions that could search through the grid as well as a way to pass the \nretrieved locations around. I decided a dictionary would be best for this so that when printing the output to the \nconsole, a for-loop could just run through it. I also created a list to store the words and a 2D list to store the \ngrid. \n\nAnalyze is where the file is read and parsed. Word_find is the function that is used to create the dictionary and to \ncall each of the search functions. When running through the searches, I wanted to create a separate function for each \ndirection so that the code would be cleaner and easier to test. Vertical and horizontal are the two most straightforward\nfunctions- based on row and column. The diagonal searches were mostly trial and error using print statements to see\nwhich parts of the grid were being accessed. Using join on the list seemed the easiest way to search for a word. The\nlocations list of tuples in each diagonal method made it easier to track the locations of the elements based on where \nthey were located in the current string.\n\nWhen testing, I created analyze as a separate function so that tests could be run without requesting the\ninput file. I did do some research and attempted to make it work with a mock input file. That is something that I am\ngoing to continue to work with so that I can learn it. As a workaround, I created an output text file that analyze can\nwrite to for comparison with the answer files while running the tests. There is a test for each direction that tests \nwords going forward and backward within the grid. There is also a test that has words going in every direction to \nensure that all the functions work together.\n\n## Sample Data\nThe following was used as one of the sample input and output datasets.\n\n### Input\n\n```\n10x10\nH A S S T A S T U I\nS E Y B S P L E A T\nB K R N A E J A U E\nI V G D F K T S B N\nG O O D E Y I S K L\nW N O E L D N I I T\nM M S L T R K X Q L\nQ U E E N J W K S A\nS A D T I V I T C A\nP I R X T O V I P Q\nTINT\nHERDED\nGOOD\nLIST\nLEAP\nSPA\nQUEEN\nTEAS\nGOOSE\nKNIT\nSEEK\nTEAS\n```\n\n### Output\n\n```\nTINT 9:4 6:4\nTEAS 0:7 3:7\nSEEK 6:2 3:5\nQUEEN 7:0 7:4\nLIST 6:9 3:6\nHERDED 0:0 5:5\nGOOSE 3:2 7:2\nLEAP 6:3 9:0\nGOOD 4:0 4:3\nSPA 0:6 2:4\nKNIT 6:6 3:6\n```\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/alambe13/alphabet-soup", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "alphabet-soup-lambert", "package_url": "https://pypi.org/project/alphabet-soup-lambert/", "platform": "", "project_url": "https://pypi.org/project/alphabet-soup-lambert/", "project_urls": {"Homepage": "https://github.com/alambe13/alphabet-soup"}, "release_url": "https://pypi.org/project/alphabet-soup-lambert/0.1/", "requires_dist": null, "requires_python": ">=2.7", "summary": "A word search project", "version": "0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Alphabet Soup</h1>\n<blockquote>\n<p>You have been contracted from a newspaper tasked with the job of providing an answer key to their word search for the\nSunday print. The newspaper's word search is a traditional game consisting of a grid of characters in which a selection\nof words have been hidden. You are provided with the list of words that have been hidden and must find the words within\nthe grid of characters.</p>\n</blockquote>\n<h2>Requirements</h2>\n<p>Load a character grid with scrambled words embedded within it and a words list of the words to find.  The following\nconditions apply:</p>\n<ul>\n<li>Within the grid of characters, the words may appear vertical, horizontal or diagonal.</li>\n<li>Within the grid of characters, the words may appear forwards or backwards.</li>\n<li>Words that have spaces in them will not include spaces when hidden in the grid of characters.</li>\n</ul>\n<h1>Execution</h1>\n<p>When approaching this problem, I first made a list of what I needed- a way to read and store the words and the grid from\nthe given file. I also needed to write functions that could search through the grid as well as a way to pass the\nretrieved locations around. I decided a dictionary would be best for this so that when printing the output to the\nconsole, a for-loop could just run through it. I also created a list to store the words and a 2D list to store the\ngrid.</p>\n<p>Analyze is where the file is read and parsed. Word_find is the function that is used to create the dictionary and to\ncall each of the search functions. When running through the searches, I wanted to create a separate function for each\ndirection so that the code would be cleaner and easier to test. Vertical and horizontal are the two most straightforward\nfunctions- based on row and column. The diagonal searches were mostly trial and error using print statements to see\nwhich parts of the grid were being accessed. Using join on the list seemed the easiest way to search for a word. The\nlocations list of tuples in each diagonal method made it easier to track the locations of the elements based on where\nthey were located in the current string.</p>\n<p>When testing, I created analyze as a separate function so that tests could be run without requesting the\ninput file. I did do some research and attempted to make it work with a mock input file. That is something that I am\ngoing to continue to work with so that I can learn it. As a workaround, I created an output text file that analyze can\nwrite to for comparison with the answer files while running the tests. There is a test for each direction that tests\nwords going forward and backward within the grid. There is also a test that has words going in every direction to\nensure that all the functions work together.</p>\n<h2>Sample Data</h2>\n<p>The following was used as one of the sample input and output datasets.</p>\n<h3>Input</h3>\n<pre><code>10x10\nH A S S T A S T U I\nS E Y B S P L E A T\nB K R N A E J A U E\nI V G D F K T S B N\nG O O D E Y I S K L\nW N O E L D N I I T\nM M S L T R K X Q L\nQ U E E N J W K S A\nS A D T I V I T C A\nP I R X T O V I P Q\nTINT\nHERDED\nGOOD\nLIST\nLEAP\nSPA\nQUEEN\nTEAS\nGOOSE\nKNIT\nSEEK\nTEAS\n</code></pre>\n<h3>Output</h3>\n<pre><code>TINT 9:4 6:4\nTEAS 0:7 3:7\nSEEK 6:2 3:5\nQUEEN 7:0 7:4\nLIST 6:9 3:6\nHERDED 0:0 5:5\nGOOSE 3:2 7:2\nLEAP 6:3 9:0\nGOOD 4:0 4:3\nSPA 0:6 2:4\nKNIT 6:6 3:6\n</code></pre>\n\n          </div>"}, "last_serial": 7026179, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "b49a405e2bdc1c088a68af8ed7786013", "sha256": "d64e2a561c7c6ea74be7a04d11410ce50755d67b8c3d34ab2dd834f08350edd5"}, "downloads": -1, "filename": "alphabet_soup_lambert-0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "b49a405e2bdc1c088a68af8ed7786013", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=2.7", "size": 5614, "upload_time": "2020-04-15T17:39:43", "upload_time_iso_8601": "2020-04-15T17:39:43.445143Z", "url": "https://files.pythonhosted.org/packages/78/25/4feb6c03d17d577378db33afe18084f1cde415e20e655d13802d2e078e35/alphabet_soup_lambert-0.1-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "b49a405e2bdc1c088a68af8ed7786013", "sha256": "d64e2a561c7c6ea74be7a04d11410ce50755d67b8c3d34ab2dd834f08350edd5"}, "downloads": -1, "filename": "alphabet_soup_lambert-0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "b49a405e2bdc1c088a68af8ed7786013", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=2.7", "size": 5614, "upload_time": "2020-04-15T17:39:43", "upload_time_iso_8601": "2020-04-15T17:39:43.445143Z", "url": "https://files.pythonhosted.org/packages/78/25/4feb6c03d17d577378db33afe18084f1cde415e20e655d13802d2e078e35/alphabet_soup_lambert-0.1-py3-none-any.whl", "yanked": false}], "timestamp": "Thu May  7 16:19:18 2020"}