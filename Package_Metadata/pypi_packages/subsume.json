{"info": {"author": "Stephen Macke", "author_email": "stephen.macke@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "subsync\n=======\n\n[![](https://github.com/smacke/subsync/workflows/Subsync_CI/badge.svg)](https://github.com/smacke/subsync/actions)\n[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)\n\nLanguage-agnostic automatic synchronization of subtitles with video, so that\nsubtitles are aligned to the correct starting point within the video.\n\nTurn this:                       |  Into this:\n:-------------------------------:|:-------------------------:\n![](https://raw.githubusercontent.com/smacke/subsync/master/tearing-me-apart-wrong.gif)  |  ![](https://raw.githubusercontent.com/smacke/subsync/master/tearing-me-apart-correct.gif)\n\nInstall\n-------\nFirst, make sure ffmpeg is installed. On MacOS, this looks like:\n~~~\nbrew install ffmpeg\n~~~\nNext, grab the script. It should work with both Python 2 and Python 3:\n~~~\npip install git+https://github.com/smacke/subsync@STABLE\n~~~\n\nUsage\n-----\n~~~\nsubsync video.mp4 -i unsynchronized.srt > synchronized.srt\n~~~\n\nor\n\n~~~\nsubsync video.mp4 -i unsynchronized.srt -o synchronized.srt\n~~~\n\nThere may be occasions where you have a correctly synchronized srt file in a\nlanguage you are unfamiliar with, as well as an unsynchronized srt file in your\nnative language. In this case, you can use the correctly synchronized srt file\ndirectly as a reference for synchronization, instead of using the video as the\nreference:\n\n~~~\nsubsync reference.srt -i unsynchronized.srt -o synchronized.srt\n~~~\n\n`subsync` uses the file extension to decide whether to perform voice activity\ndetection on the audio or to directly extract speech from an srt file.\n\nSpeed\n-----\n`subsync` usually finishes in 20 to 30 seconds, depending on the length of the\nvideo. The most expensive step is actually extraction of raw audio. If you\nalready have a correctly synchronized \"reference\" srt file (in which case audio\nextraction can be skipped), `subsync` typically runs in less than a second.\n\nHow It Works\n------------\nThe synchronization algorithm operates in 3 steps:\n1. Discretize video and subtitles by time into 10ms windows.\n2. For each 10ms window, determine whether that window contains speech.  This\n   is trivial to do for subtitles (we just determine whether any subtitle is\n   \"on\" during each time window); for video, use an off-the-shelf voice\n   activity detector (VAD) like\n   the one built into [webrtc](https://webrtc.org/).\n3. Now we have two binary strings: one for the subtitles, and one for the\n   video.  Try to align these strings by matching 0's with 0's and 1's with\n   1's. We score these alignments as (# video 1's matched w/ subtitle 1's) - (#\n   video 1's matched with subtitle 0's).\n\nThe best-scoring alignment from step 3 determines how to offset the subtitles\nin time so that they are properly synced with the video. Because the binary\nstrings are fairly long (millions of digits for video longer than an hour), the\nnaive O(n^2) strategy for scoring all alignments is unacceptable. Instead, we\nuse the fact that \"scoring all alignments\" is a convolution operation and can\nbe implemented with the Fast Fourier Transform (FFT), bringing the complexity\ndown to O(n log n).\n\nLimitations\n-----------\nIn most cases, inconsistencies between video and subtitles occur when starting\nor ending segments present in video are not present in subtitles, or vice versa.\nThis can occur, for example, when a TV episode recap in the subtitles was pruned\nfrom video. Subsync typically works well in these cases, and in my experience\nthis covers >95% of use cases. Handling breaks and splits outside of the beginning\nand ending segments is left to future work (see below).\n\nVLC Integration\n---------------\nTo demonstrate how one might use `subsync` seamlessly with real video software,\nwe developed a prototype integration into the popular\n[VLC](https://www.videolan.org/vlc/index.html) media player, which was demoed\nduring the HackIllinois 2019 project expo. The resulting patch can be found in\nthe file\n[subsync-vlc.patch](https://github.com/smacke/subsync/raw/master/subsync-vlc.patch).\nHere are instructions for how to use it.\n\n1. First clone the 3.0 maintenance branch of VLC and checkout 3.0.6:\n~~~\ngit clone git://git.videolan.org/vlc/vlc-3.0.git\ncd vlc-3.0\ngit checkout 3.0.6\n~~~\n2. Next, apply the patch:\n~~~\nwget https://github.com/smacke/subsync/raw/master/subsync-vlc.patch\ngit apply subsync-vlc.patch\n~~~\n3. Follow the normal instructions on the\n[VideoLAN wiki](https://wiki.videolan.org/VLC_Developers_Corner/)\nfor building VLC from source. *Warning: this is not easy.*\n\nYou should now be able to autosynchronize subtitles using the hotkey `Ctrl+Shift+S`\n(only enabled while subtitles are present).\n\nFuture Work\n-----------\n1. I am currently working to extend the synchronization algorithm to handle\n   splits / breaks in the middle of video not present in subtitles (or vice\n   versa). It will take some time before I have a robust solution (assuming one\n   is possible). See [#10](https://github.com/smacke/subsync/issues/10) for\n   more details.\n\n2. The prototype VLC patch is very experimental -- it was developed under\n   pressure and just barely works. I would love to see this project more\n   robustly integrated with VLC, either directly in the VLC core, or as a\n   plugin.  If you or anyone you know has ideas for how to accomplish this,\n   please let me know!\n\nHistory\n-------\nThe implementation for this project was started during HackIllinois 2019, for\nwhich it received an **_Honorable Mention_** (ranked in the top 5 projects,\nexcluding projects that won company-specific prizes).\n\nCredits\n-------\nThis project would not be possible without the following libraries:\n- [ffmpeg](https://www.ffmpeg.org/) and the [ffmpeg-python](https://github.com/kkroening/ffmpeg-python) wrapper, for extracting raw audio from video\n- VAD from [webrtc](https://webrtc.org/) and the [py-webrtcvad](https://github.com/wiseman/py-webrtcvad) wrapper, for speech detection\n- [srt](https://pypi.org/project/srt/) for operating on [SRT files](https://en.wikipedia.org/wiki/SubRip#SubRip_text_file_format)\n- [numpy](http://www.numpy.org/) and, indirectly, [FFTPACK](https://www.netlib.org/fftpack/), which powers the FFT-based algorithm for fast scoring of alignments between subtitles (or subtitles and video)\n- [sklearn](https://scikit-learn.org/) for its data pipeline API\n- Other excellent Python libraries like [argparse](https://docs.python.org/3/library/argparse.html) and [tqdm](https://tqdm.github.io/), not related to the core functionality, but which enable much better experiences for developers and users.\n\n# License\nCode in this project is [MIT licensed](https://opensource.org/licenses/MIT).\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/smacke/subsync", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "subsume", "package_url": "https://pypi.org/project/subsume/", "platform": "", "project_url": "https://pypi.org/project/subsume/", "project_urls": {"Homepage": "https://github.com/smacke/subsync"}, "release_url": "https://pypi.org/project/subsume/0.2.16/", "requires_dist": ["argparse", "ffmpeg-python", "future", "numpy (>=1.12.0)", "scikit-learn (>=0.20.4)", "six", "srt (>=3.0.0)", "tqdm", "webrtcvad"], "requires_python": "", "summary": "Language-agnostic synchronization of subtitles with video via speech detection.", "version": "0.2.16", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>subsync</h1>\n<p><a href=\"https://github.com/smacke/subsync/actions\" rel=\"nofollow\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a75a8e3343ae25c1c3926fba87f327b2baa999a5/68747470733a2f2f6769746875622e636f6d2f736d61636b652f73756273796e632f776f726b666c6f77732f53756273796e635f43492f62616467652e737667\"></a>\n<a href=\"https://opensource.org/licenses/MIT\" rel=\"nofollow\"><img alt=\"License: MIT\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4150014b4dfdd7b565fa18de88e9bb1b8ccd7c08/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d626c75652e737667\"></a></p>\n<p>Language-agnostic automatic synchronization of subtitles with video, so that\nsubtitles are aligned to the correct starting point within the video.</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">Turn this:</th>\n<th align=\"center\">Into this:</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6f0a36fe95a294d6807f08ea92e9827788c2c7e3/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f736d61636b652f73756273796e632f6d61737465722f74656172696e672d6d652d61706172742d77726f6e672e676966\"></td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/924189a9155b278244ffcd39e9bdd4d442a2cffd/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f736d61636b652f73756273796e632f6d61737465722f74656172696e672d6d652d61706172742d636f72726563742e676966\"></td>\n</tr></tbody></table>\n<h2>Install</h2>\n<p>First, make sure ffmpeg is installed. On MacOS, this looks like:</p>\n<pre><code>brew install ffmpeg\n</code></pre>\n<p>Next, grab the script. It should work with both Python 2 and Python 3:</p>\n<pre><code>pip install git+https://github.com/smacke/subsync@STABLE\n</code></pre>\n<h2>Usage</h2>\n<pre><code>subsync video.mp4 -i unsynchronized.srt &gt; synchronized.srt\n</code></pre>\n<p>or</p>\n<pre><code>subsync video.mp4 -i unsynchronized.srt -o synchronized.srt\n</code></pre>\n<p>There may be occasions where you have a correctly synchronized srt file in a\nlanguage you are unfamiliar with, as well as an unsynchronized srt file in your\nnative language. In this case, you can use the correctly synchronized srt file\ndirectly as a reference for synchronization, instead of using the video as the\nreference:</p>\n<pre><code>subsync reference.srt -i unsynchronized.srt -o synchronized.srt\n</code></pre>\n<p><code>subsync</code> uses the file extension to decide whether to perform voice activity\ndetection on the audio or to directly extract speech from an srt file.</p>\n<h2>Speed</h2>\n<p><code>subsync</code> usually finishes in 20 to 30 seconds, depending on the length of the\nvideo. The most expensive step is actually extraction of raw audio. If you\nalready have a correctly synchronized \"reference\" srt file (in which case audio\nextraction can be skipped), <code>subsync</code> typically runs in less than a second.</p>\n<h2>How It Works</h2>\n<p>The synchronization algorithm operates in 3 steps:</p>\n<ol>\n<li>Discretize video and subtitles by time into 10ms windows.</li>\n<li>For each 10ms window, determine whether that window contains speech.  This\nis trivial to do for subtitles (we just determine whether any subtitle is\n\"on\" during each time window); for video, use an off-the-shelf voice\nactivity detector (VAD) like\nthe one built into <a href=\"https://webrtc.org/\" rel=\"nofollow\">webrtc</a>.</li>\n<li>Now we have two binary strings: one for the subtitles, and one for the\nvideo.  Try to align these strings by matching 0's with 0's and 1's with\n1's. We score these alignments as (# video 1's matched w/ subtitle 1's) - (#\nvideo 1's matched with subtitle 0's).</li>\n</ol>\n<p>The best-scoring alignment from step 3 determines how to offset the subtitles\nin time so that they are properly synced with the video. Because the binary\nstrings are fairly long (millions of digits for video longer than an hour), the\nnaive O(n^2) strategy for scoring all alignments is unacceptable. Instead, we\nuse the fact that \"scoring all alignments\" is a convolution operation and can\nbe implemented with the Fast Fourier Transform (FFT), bringing the complexity\ndown to O(n log n).</p>\n<h2>Limitations</h2>\n<p>In most cases, inconsistencies between video and subtitles occur when starting\nor ending segments present in video are not present in subtitles, or vice versa.\nThis can occur, for example, when a TV episode recap in the subtitles was pruned\nfrom video. Subsync typically works well in these cases, and in my experience\nthis covers &gt;95% of use cases. Handling breaks and splits outside of the beginning\nand ending segments is left to future work (see below).</p>\n<h2>VLC Integration</h2>\n<p>To demonstrate how one might use <code>subsync</code> seamlessly with real video software,\nwe developed a prototype integration into the popular\n<a href=\"https://www.videolan.org/vlc/index.html\" rel=\"nofollow\">VLC</a> media player, which was demoed\nduring the HackIllinois 2019 project expo. The resulting patch can be found in\nthe file\n<a href=\"https://github.com/smacke/subsync/raw/master/subsync-vlc.patch\" rel=\"nofollow\">subsync-vlc.patch</a>.\nHere are instructions for how to use it.</p>\n<ol>\n<li>First clone the 3.0 maintenance branch of VLC and checkout 3.0.6:</li>\n</ol>\n<pre><code>git clone git://git.videolan.org/vlc/vlc-3.0.git\ncd vlc-3.0\ngit checkout 3.0.6\n</code></pre>\n<ol>\n<li>Next, apply the patch:</li>\n</ol>\n<pre><code>wget https://github.com/smacke/subsync/raw/master/subsync-vlc.patch\ngit apply subsync-vlc.patch\n</code></pre>\n<ol>\n<li>Follow the normal instructions on the\n<a href=\"https://wiki.videolan.org/VLC_Developers_Corner/\" rel=\"nofollow\">VideoLAN wiki</a>\nfor building VLC from source. <em>Warning: this is not easy.</em></li>\n</ol>\n<p>You should now be able to autosynchronize subtitles using the hotkey <code>Ctrl+Shift+S</code>\n(only enabled while subtitles are present).</p>\n<h2>Future Work</h2>\n<ol>\n<li>\n<p>I am currently working to extend the synchronization algorithm to handle\nsplits / breaks in the middle of video not present in subtitles (or vice\nversa). It will take some time before I have a robust solution (assuming one\nis possible). See <a href=\"https://github.com/smacke/subsync/issues/10\" rel=\"nofollow\">#10</a> for\nmore details.</p>\n</li>\n<li>\n<p>The prototype VLC patch is very experimental -- it was developed under\npressure and just barely works. I would love to see this project more\nrobustly integrated with VLC, either directly in the VLC core, or as a\nplugin.  If you or anyone you know has ideas for how to accomplish this,\nplease let me know!</p>\n</li>\n</ol>\n<h2>History</h2>\n<p>The implementation for this project was started during HackIllinois 2019, for\nwhich it received an <strong><em>Honorable Mention</em></strong> (ranked in the top 5 projects,\nexcluding projects that won company-specific prizes).</p>\n<h2>Credits</h2>\n<p>This project would not be possible without the following libraries:</p>\n<ul>\n<li><a href=\"https://www.ffmpeg.org/\" rel=\"nofollow\">ffmpeg</a> and the <a href=\"https://github.com/kkroening/ffmpeg-python\" rel=\"nofollow\">ffmpeg-python</a> wrapper, for extracting raw audio from video</li>\n<li>VAD from <a href=\"https://webrtc.org/\" rel=\"nofollow\">webrtc</a> and the <a href=\"https://github.com/wiseman/py-webrtcvad\" rel=\"nofollow\">py-webrtcvad</a> wrapper, for speech detection</li>\n<li><a href=\"https://pypi.org/project/srt/\" rel=\"nofollow\">srt</a> for operating on <a href=\"https://en.wikipedia.org/wiki/SubRip#SubRip_text_file_format\" rel=\"nofollow\">SRT files</a></li>\n<li><a href=\"http://www.numpy.org/\" rel=\"nofollow\">numpy</a> and, indirectly, <a href=\"https://www.netlib.org/fftpack/\" rel=\"nofollow\">FFTPACK</a>, which powers the FFT-based algorithm for fast scoring of alignments between subtitles (or subtitles and video)</li>\n<li><a href=\"https://scikit-learn.org/\" rel=\"nofollow\">sklearn</a> for its data pipeline API</li>\n<li>Other excellent Python libraries like <a href=\"https://docs.python.org/3/library/argparse.html\" rel=\"nofollow\">argparse</a> and <a href=\"https://tqdm.github.io/\" rel=\"nofollow\">tqdm</a>, not related to the core functionality, but which enable much better experiences for developers and users.</li>\n</ul>\n<h1>License</h1>\n<p>Code in this project is <a href=\"https://opensource.org/licenses/MIT\" rel=\"nofollow\">MIT licensed</a>.</p>\n\n          </div>"}, "last_serial": 6244639, "releases": {"0.2.16": [{"comment_text": "", "digests": {"md5": "ba302319c38797c1a9f6be98ba9e5ac9", "sha256": "1d3ce71c3de4b89479805cf5cbba3fdd02b517e9314957669cdcaa575e458b27"}, "downloads": -1, "filename": "subsume-0.2.16-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "ba302319c38797c1a9f6be98ba9e5ac9", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 26644, "upload_time": "2019-12-05T01:02:35", "upload_time_iso_8601": "2019-12-05T01:02:35.527669Z", "url": "https://files.pythonhosted.org/packages/48/6e/847660fe98c1e274b911b0eab087c72161999d9317c18fa21f75c351dcae/subsume-0.2.16-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b92f91eb62afb561dd8ffe7dedce660d", "sha256": "0b83d8e45e4a9f819f371c7a95681a985863f30e57fddec9897e6725877ba735"}, "downloads": -1, "filename": "subsume-0.2.16.tar.gz", "has_sig": false, "md5_digest": "b92f91eb62afb561dd8ffe7dedce660d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12622, "upload_time": "2019-12-05T01:02:37", "upload_time_iso_8601": "2019-12-05T01:02:37.767148Z", "url": "https://files.pythonhosted.org/packages/c9/7d/90602d5a7e52453c55d033c931ed5398bb5d4ab50dd98417eaad874a9f52/subsume-0.2.16.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ba302319c38797c1a9f6be98ba9e5ac9", "sha256": "1d3ce71c3de4b89479805cf5cbba3fdd02b517e9314957669cdcaa575e458b27"}, "downloads": -1, "filename": "subsume-0.2.16-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "ba302319c38797c1a9f6be98ba9e5ac9", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 26644, "upload_time": "2019-12-05T01:02:35", "upload_time_iso_8601": "2019-12-05T01:02:35.527669Z", "url": "https://files.pythonhosted.org/packages/48/6e/847660fe98c1e274b911b0eab087c72161999d9317c18fa21f75c351dcae/subsume-0.2.16-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b92f91eb62afb561dd8ffe7dedce660d", "sha256": "0b83d8e45e4a9f819f371c7a95681a985863f30e57fddec9897e6725877ba735"}, "downloads": -1, "filename": "subsume-0.2.16.tar.gz", "has_sig": false, "md5_digest": "b92f91eb62afb561dd8ffe7dedce660d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12622, "upload_time": "2019-12-05T01:02:37", "upload_time_iso_8601": "2019-12-05T01:02:37.767148Z", "url": "https://files.pythonhosted.org/packages/c9/7d/90602d5a7e52453c55d033c931ed5398bb5d4ab50dd98417eaad874a9f52/subsume-0.2.16.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:00:37 2020"}