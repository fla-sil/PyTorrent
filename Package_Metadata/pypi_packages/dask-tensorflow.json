{"info": {"author": "Matthew Rocklin", "author_email": "mrocklin@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "Dask-Tensorflow\n===============\n\n.. |Build Status| image:: https://travis-ci.org/mrocklin/dask-tensorflow.svg?branch=master\n   :target: https://travis-ci.org/mrocklin/dask-tensorflow\n\nStart TensorFlow clusters from Dask\n\nExample\n-------\n\nGiven a Dask cluster\n\n.. code-block:: python\n\n   from dask.distributed import Client\n   client = Client('scheduler-address:8786')\n\nGet a TensorFlow cluster, specifying groups by name\n\n.. code-block:: python\n\n   from dask_tensorflow import start_tensorflow\n   tf_spec, dask_spec = start_tensorflow(client, ps=2, worker=4)\n\n   >>> tf_spec\n   {'worker': ['192.168.1.100:2222', '192.168.1.101:2222',\n               '192.168.1.102:2222', '192.168.1.103:2222'],\n    'ps': ['192.168.1.104:2222', '192.168.1.105:2222']}\n\nThis creates a ``tensorflow.train.Server`` on each Dask worker and sets up a\nQueue for data transfer on each worker.  These are accessible directly as\n``tensorflow_server`` and ``tensorflow_queue`` attributes on the workers.\n\nMore Complex Workflow\n---------------------\n\nTypically then we set up long running Dask tasks that get these servers and\nparticipate in general TensorFlow compuations.\n\n.. code-block:: python\n\n   from dask.distributed import worker_client\n\n   def ps_function(self):\n       with worker_client() as c:\n           tf_server = c.worker.tensorflow_server\n           tf_server.join()\n\n   ps_tasks = [client.submit(ps_function, workers=worker, pure=False)\n               for worker in dask_spec['ps']]\n\n   def worker_function(self):\n       with worker_client() as c:\n           tf_server = c.worker.tensorflow_server\n\n           # ... use tensorflow as desired ...\n\n   worker_tasks = [client.submit(worker_function, workers=worker, pure=False)\n                   for worker in dask_spec['worker']]\n\nOne simple and flexible approach is to have these functions block on queues and\nfeed them data from dask arrays, dataframes, etc.\n\n\n.. code-block:: python\n\n   def worker_function(self):\n       with worker_client() as c:\n           tf_server = c.worker.tensorflow_server\n           queue = c.worker.tensorflow_queue\n\n           while not stopping_condition():\n               batch = queue.get()\n               # train with batch\n\nAnd then dump blocks of numpy and pandas dataframes to these queues\n\n.. code-block:: python\n\n   from distributed.worker_client import get_worker\n   def dump_batch(batch):\n       worker = get_worker()\n       worker.tensorflow_queue.put(batch)\n\n\n   import dask.dataframe as dd\n   df = dd.read_csv('hdfs:///path/to/*.csv')\n   # clean up dataframe as necessary\n   partitions = df.to_delayed()  # delayed pandas dataframes\n   client.map(dump_batch, partitions)\n\n\n", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "BSD", "maintainer": "", "maintainer_email": "", "name": "dask-tensorflow", "package_url": "https://pypi.org/project/dask-tensorflow/", "platform": "", "project_url": "https://pypi.org/project/dask-tensorflow/", "project_urls": null, "release_url": "https://pypi.org/project/dask-tensorflow/0.0.2/", "requires_dist": ["dask", "distributed", "tensorflow"], "requires_python": "", "summary": "Interactions between Dask and Tensorflow", "version": "0.0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>Start TensorFlow clusters from Dask</p>\n<div id=\"example\">\n<h2>Example</h2>\n<p>Given a Dask cluster</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">dask.distributed</span> <span class=\"kn\">import</span> <span class=\"n\">Client</span>\n<span class=\"n\">client</span> <span class=\"o\">=</span> <span class=\"n\">Client</span><span class=\"p\">(</span><span class=\"s1\">'scheduler-address:8786'</span><span class=\"p\">)</span>\n</pre>\n<p>Get a TensorFlow cluster, specifying groups by name</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">dask_tensorflow</span> <span class=\"kn\">import</span> <span class=\"n\">start_tensorflow</span>\n<span class=\"n\">tf_spec</span><span class=\"p\">,</span> <span class=\"n\">dask_spec</span> <span class=\"o\">=</span> <span class=\"n\">start_tensorflow</span><span class=\"p\">(</span><span class=\"n\">client</span><span class=\"p\">,</span> <span class=\"n\">ps</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">worker</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">)</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">tf_spec</span>\n<span class=\"p\">{</span><span class=\"s1\">'worker'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'192.168.1.100:2222'</span><span class=\"p\">,</span> <span class=\"s1\">'192.168.1.101:2222'</span><span class=\"p\">,</span>\n            <span class=\"s1\">'192.168.1.102:2222'</span><span class=\"p\">,</span> <span class=\"s1\">'192.168.1.103:2222'</span><span class=\"p\">],</span>\n <span class=\"s1\">'ps'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'192.168.1.104:2222'</span><span class=\"p\">,</span> <span class=\"s1\">'192.168.1.105:2222'</span><span class=\"p\">]}</span>\n</pre>\n<p>This creates a <tt>tensorflow.train.Server</tt> on each Dask worker and sets up a\nQueue for data transfer on each worker.  These are accessible directly as\n<tt>tensorflow_server</tt> and <tt>tensorflow_queue</tt> attributes on the workers.</p>\n</div>\n<div id=\"more-complex-workflow\">\n<h2>More Complex Workflow</h2>\n<p>Typically then we set up long running Dask tasks that get these servers and\nparticipate in general TensorFlow compuations.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">dask.distributed</span> <span class=\"kn\">import</span> <span class=\"n\">worker_client</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">ps_function</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n    <span class=\"k\">with</span> <span class=\"n\">worker_client</span><span class=\"p\">()</span> <span class=\"k\">as</span> <span class=\"n\">c</span><span class=\"p\">:</span>\n        <span class=\"n\">tf_server</span> <span class=\"o\">=</span> <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">worker</span><span class=\"o\">.</span><span class=\"n\">tensorflow_server</span>\n        <span class=\"n\">tf_server</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">()</span>\n\n<span class=\"n\">ps_tasks</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">submit</span><span class=\"p\">(</span><span class=\"n\">ps_function</span><span class=\"p\">,</span> <span class=\"n\">workers</span><span class=\"o\">=</span><span class=\"n\">worker</span><span class=\"p\">,</span> <span class=\"n\">pure</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n            <span class=\"k\">for</span> <span class=\"n\">worker</span> <span class=\"ow\">in</span> <span class=\"n\">dask_spec</span><span class=\"p\">[</span><span class=\"s1\">'ps'</span><span class=\"p\">]]</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">worker_function</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n    <span class=\"k\">with</span> <span class=\"n\">worker_client</span><span class=\"p\">()</span> <span class=\"k\">as</span> <span class=\"n\">c</span><span class=\"p\">:</span>\n        <span class=\"n\">tf_server</span> <span class=\"o\">=</span> <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">worker</span><span class=\"o\">.</span><span class=\"n\">tensorflow_server</span>\n\n        <span class=\"c1\"># ... use tensorflow as desired ...</span>\n\n<span class=\"n\">worker_tasks</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">submit</span><span class=\"p\">(</span><span class=\"n\">worker_function</span><span class=\"p\">,</span> <span class=\"n\">workers</span><span class=\"o\">=</span><span class=\"n\">worker</span><span class=\"p\">,</span> <span class=\"n\">pure</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n                <span class=\"k\">for</span> <span class=\"n\">worker</span> <span class=\"ow\">in</span> <span class=\"n\">dask_spec</span><span class=\"p\">[</span><span class=\"s1\">'worker'</span><span class=\"p\">]]</span>\n</pre>\n<p>One simple and flexible approach is to have these functions block on queues and\nfeed them data from dask arrays, dataframes, etc.</p>\n<pre><span class=\"k\">def</span> <span class=\"nf\">worker_function</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n    <span class=\"k\">with</span> <span class=\"n\">worker_client</span><span class=\"p\">()</span> <span class=\"k\">as</span> <span class=\"n\">c</span><span class=\"p\">:</span>\n        <span class=\"n\">tf_server</span> <span class=\"o\">=</span> <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">worker</span><span class=\"o\">.</span><span class=\"n\">tensorflow_server</span>\n        <span class=\"n\">queue</span> <span class=\"o\">=</span> <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">worker</span><span class=\"o\">.</span><span class=\"n\">tensorflow_queue</span>\n\n        <span class=\"k\">while</span> <span class=\"ow\">not</span> <span class=\"n\">stopping_condition</span><span class=\"p\">():</span>\n            <span class=\"n\">batch</span> <span class=\"o\">=</span> <span class=\"n\">queue</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n            <span class=\"c1\"># train with batch</span>\n</pre>\n<p>And then dump blocks of numpy and pandas dataframes to these queues</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">distributed.worker_client</span> <span class=\"kn\">import</span> <span class=\"n\">get_worker</span>\n<span class=\"k\">def</span> <span class=\"nf\">dump_batch</span><span class=\"p\">(</span><span class=\"n\">batch</span><span class=\"p\">):</span>\n    <span class=\"n\">worker</span> <span class=\"o\">=</span> <span class=\"n\">get_worker</span><span class=\"p\">()</span>\n    <span class=\"n\">worker</span><span class=\"o\">.</span><span class=\"n\">tensorflow_queue</span><span class=\"o\">.</span><span class=\"n\">put</span><span class=\"p\">(</span><span class=\"n\">batch</span><span class=\"p\">)</span>\n\n\n<span class=\"kn\">import</span> <span class=\"nn\">dask.dataframe</span> <span class=\"k\">as</span> <span class=\"nn\">dd</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">dd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s1\">'hdfs:///path/to/*.csv'</span><span class=\"p\">)</span>\n<span class=\"c1\"># clean up dataframe as necessary</span>\n<span class=\"n\">partitions</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">to_delayed</span><span class=\"p\">()</span>  <span class=\"c1\"># delayed pandas dataframes</span>\n<span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">map</span><span class=\"p\">(</span><span class=\"n\">dump_batch</span><span class=\"p\">,</span> <span class=\"n\">partitions</span><span class=\"p\">)</span>\n</pre>\n</div>\n\n          </div>"}, "last_serial": 3477998, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "d80264571f2c4aa18d1548cbd8317376", "sha256": "2fda52e365b86afc67b544bc85421e841ddb273eae701bad0dec98013f0b8f06"}, "downloads": -1, "filename": "dask-tensorflow-0.0.1.tar.gz", "has_sig": false, "md5_digest": "d80264571f2c4aa18d1548cbd8317376", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3352, "upload_time": "2017-10-23T20:33:14", "upload_time_iso_8601": "2017-10-23T20:33:14.067102Z", "url": "https://files.pythonhosted.org/packages/36/a1/a7a233185381a117cf1716278524d73d07fb5c1d7ed5ea90ed96dc467e86/dask-tensorflow-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "944c7b4c6cde97705bc54036fff531ff", "sha256": "b88b6f330f846bb1a9d58cfdd612ca5a3d3ef4874e3e81405395e6104d8ad2d9"}, "downloads": -1, "filename": "dask_tensorflow-0.0.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "944c7b4c6cde97705bc54036fff531ff", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 5307, "upload_time": "2018-01-10T16:03:24", "upload_time_iso_8601": "2018-01-10T16:03:24.881404Z", "url": "https://files.pythonhosted.org/packages/00/a5/6cd58713aacf16fc8ef801e3020894a1faba7710c19c047c3e9582081b20/dask_tensorflow-0.0.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0a27b2144c4f550cafd6ddb98a29d018", "sha256": "9687ca632ca9769ccc2c8f99300ebfc675b19ef6369a57e33c00e7178f412d2e"}, "downloads": -1, "filename": "dask-tensorflow-0.0.2.tar.gz", "has_sig": false, "md5_digest": "0a27b2144c4f550cafd6ddb98a29d018", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4762, "upload_time": "2018-01-10T16:03:26", "upload_time_iso_8601": "2018-01-10T16:03:26.152146Z", "url": "https://files.pythonhosted.org/packages/9c/6e/b09e3fa80760aef4bb77ed5cee6df94ef21dec347da6be0fea9505f9d792/dask-tensorflow-0.0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "944c7b4c6cde97705bc54036fff531ff", "sha256": "b88b6f330f846bb1a9d58cfdd612ca5a3d3ef4874e3e81405395e6104d8ad2d9"}, "downloads": -1, "filename": "dask_tensorflow-0.0.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "944c7b4c6cde97705bc54036fff531ff", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 5307, "upload_time": "2018-01-10T16:03:24", "upload_time_iso_8601": "2018-01-10T16:03:24.881404Z", "url": "https://files.pythonhosted.org/packages/00/a5/6cd58713aacf16fc8ef801e3020894a1faba7710c19c047c3e9582081b20/dask_tensorflow-0.0.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0a27b2144c4f550cafd6ddb98a29d018", "sha256": "9687ca632ca9769ccc2c8f99300ebfc675b19ef6369a57e33c00e7178f412d2e"}, "downloads": -1, "filename": "dask-tensorflow-0.0.2.tar.gz", "has_sig": false, "md5_digest": "0a27b2144c4f550cafd6ddb98a29d018", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4762, "upload_time": "2018-01-10T16:03:26", "upload_time_iso_8601": "2018-01-10T16:03:26.152146Z", "url": "https://files.pythonhosted.org/packages/9c/6e/b09e3fa80760aef4bb77ed5cee6df94ef21dec347da6be0fea9505f9d792/dask-tensorflow-0.0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:40:32 2020"}