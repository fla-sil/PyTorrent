{"info": {"author": "Guojian Li", "author_email": "guojianlee@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: BSD License", "Programming Language :: Python :: 3"], "description": "=======\nDatabot\n=======\n\n* Data-driven programming framework\n* Paralleled in coroutines\n* Type- and content-based route function\n\n\nInstalling\n----------\n\nInstall and update using ``pip``:\n\n`pip install -U databot`\n\nDocumentation\n------------\n\nhttp://databot.readthedocs.io\n\nDiscuss:\n-------\nhttps://groups.google.com/forum/#!forum/databotpy\n\n\nWhat's data-driven programming?\n===============================\n\nAll functions are connected by pipes (queues) and communicate by data.  \n\nWhen data come in, the function will be called and return the result.\n\nThink about the pipeline operation in unix: ``ls|grep|sed``.\n\nBenefits:\n\n#. Decouple data and functionality\n#. Easy to reuse \n\nDatabot provides pipe and route. It makes data-driven programming and powerful data flow processes easier.\n\n\nDatabot is...\n=============\n\n- **Simple**\n\nDatabot is easy to use and maintain, *does not need configuration files*, and knows about ``asyncio`` and how to parallelize computation.\n\nHere's one of the simple applications you can make:\n\n_Load the price of Bitoin every 2 seconds. Advantage price aggregator sample can be found `here <https://github.com/kkyon/databot/tree/master/examples>`_.\n\n\n.. code-block:: python\n\n    from databot import Pipe,Timer,BotFrame,HttpLoader\n\n     def main():\n        Pipe(\n\n\n            Timer(delay=2),#send timer data to pipe every 2 sen\n            \"http://api.coindesk.com/v1/bpi/currentprice.json\", #send url to pipe when timer trigger\n            HttpLoader(),#read url and load http response\n            lambda r:r.json['bpi']['USD']['rate_float'], #read http response and parse as json\n            print, #print out\n\n        )\n\n        BotFrame.render('simple_bitcoin_price')\n        BotFrame.run()\n\n    main()\n\n\n- **flow graph**\nbelow is the flow graph generated by databot.\n\n.. image:: https://github.com/kkyon/databot/raw/master/examples/simple_bitcoin_price.png\n   :align: center\n   :width: 400\n   :alt: simple_bitcoin_price\n\n- **Fast**\nNodes will be run in parallel, and they will perform well when processing stream data.\n\n\n- **Visualization**\n\nWith render function:\n`BotFrame.render('bitcoin_arbitrage')` \ndatabot will render the data flow network into a graphviz image. \nhttps://github.com/kkyon/databot/blob/master/docs/bitcoin_arbitrage.png\n\n- **Replay-able**\n\nWith replay mode enabled:\n``config.replay_mode=True``\nwhen an exception is raised at step N, you don't need to run from setup 1 to N.\nDatabot will replay the data from nearest completed node, usually step N-1.\nIt will save a lot of time in the development phase.\n\n\nMore about Databot and data-driven programming\n===============\n\nData-driven programming is a programming paradigm which describes the data to be matched and the processing required rather than defining a sequence of steps to be taken.\nStandard examples of data-driven languages are the text-processing languages sed and AWK, where the data is a sequence of lines in an input stream.\nData-driven programming is typically applied to streams of structured data for filtering, transforming, aggregating (such as computing statistics), or calling other programs.\n\nDatabot has a few basic concepts to implement DDP.\n\n- **Pipe**\n   It is the main stream process of the program. All units will work inside.\n- **Node**\n        It is the process logic node. It is driven by data. Custom functions work as Nodes.\n        There are some built-in nodes:\n   * **Loop**: Works as a **for** loop\n   * **Timer**: It will send a message in the pipe by timer param. **delay**, **max_time**\n   * **HttpLoader**: Get a url and return the HTTP response\n   * **MySQL query or insert**: For mysql querying and insert\n   * **File read/write**: for file I/O.\n- **Route**\n        It will be used to create a complex data flow network, not just one main process. Databot can nest Routes inside Routes.\n        It is a powerful concept.\n        There are some pre built-in Route:\n    * **Branch** : Duplicate data from parent pipe to a branch.\n    * **Return** : Duplicate data from parent pipe, and return final result to parent pipe.\n    * **Filter** : Drop data from pipe if it does not match some condition\n    * **Fork** : Duplicate data to many branches.\n    * **Join** : Duplicate data to many branches, and return result to pipe.\n\nAll units (Pipe, Node, Route) communicate via queues and perform parallel computation in coroutines.\nThis is abstracted so that Databot can be used with only limited knowledge of ``asyncio``.\n\nBelow some graphs will get you some basic concept for the Route:\n      branch:https://github.com/kkyon/databot/blob/master/docs/databot_branch.jpg\n      fork:https://github.com/kkyon/databot/blob/master/docs/databot_fork.jpg\n      join:https://github.com/kkyon/databot/blob/master/docs/databot_join.jpg\n      return:https://github.com/kkyon/databot/blob/master/docs/databot_return.jpg\n\n\nContributing\n------------\n\n\nDonate\n------\n\n\nLinks\n-----\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/kkyx/databot", "keywords": "", "license": "BSD", "maintainer": "", "maintainer_email": "", "name": "databot", "package_url": "https://pypi.org/project/databot/", "platform": "", "project_url": "https://pypi.org/project/databot/", "project_urls": {"Homepage": "https://github.com/kkyx/databot"}, "release_url": "https://pypi.org/project/databot/0.1.8/", "requires_dist": ["aiohttp (>=3.3.0)", "aiomysql (>=0.0.19)", "graphviz"], "requires_python": ">=3.6.5", "summary": "data flow programming framework with asyncio", "version": "0.1.8", "yanked": false, "html_description": "<div class=\"project-description\">\n            =======<br>Databot<br>=======<br><br>* Data-driven programming framework<br>* Paralleled in coroutines<br>* Type- and content-based route function<br><br><br>Installing<br>----------<br><br>Install and update using ``pip``:<br><br>`pip install -U databot`<br><br>Documentation<br>------------<br><br>http://databot.readthedocs.io<br><br>Discuss:<br>-------<br>https://groups.google.com/forum/#!forum/databotpy<br><br><br>What's data-driven programming?<br>===============================<br><br>All functions are connected by pipes (queues) and communicate by data.  <br><br>When data come in, the function will be called and return the result.<br><br>Think about the pipeline operation in unix: ``ls|grep|sed``.<br><br>Benefits:<br><br>#. Decouple data and functionality<br>#. Easy to reuse <br><br>Databot provides pipe and route. It makes data-driven programming and powerful data flow processes easier.<br><br><br>Databot is...<br>=============<br><br>- **Simple**<br><br>Databot is easy to use and maintain, *does not need configuration files*, and knows about ``asyncio`` and how to parallelize computation.<br><br>Here's one of the simple applications you can make:<br><br>_Load the price of Bitoin every 2 seconds. Advantage price aggregator sample can be found `here &lt;https://github.com/kkyon/databot/tree/master/examples&gt;`_.<br><br><br>.. code-block:: python<br><br>    from databot import Pipe,Timer,BotFrame,HttpLoader<br><br>     def main():<br>        Pipe(<br><br><br>            Timer(delay=2),#send timer data to pipe every 2 sen<br>            \"http://api.coindesk.com/v1/bpi/currentprice.json\", #send url to pipe when timer trigger<br>            HttpLoader(),#read url and load http response<br>            lambda r:r.json['bpi']['USD']['rate_float'], #read http response and parse as json<br>            print, #print out<br><br>        )<br><br>        BotFrame.render('simple_bitcoin_price')<br>        BotFrame.run()<br><br>    main()<br><br><br>- **flow graph**<br>below is the flow graph generated by databot.<br><br>.. image:: https://github.com/kkyon/databot/raw/master/examples/simple_bitcoin_price.png<br>   :align: center<br>   :width: 400<br>   :alt: simple_bitcoin_price<br><br>- **Fast**<br>Nodes will be run in parallel, and they will perform well when processing stream data.<br><br><br>- **Visualization**<br><br>With render function:<br>`BotFrame.render('bitcoin_arbitrage')` <br>databot will render the data flow network into a graphviz image. <br>https://github.com/kkyon/databot/blob/master/docs/bitcoin_arbitrage.png<br><br>- **Replay-able**<br><br>With replay mode enabled:<br>``config.replay_mode=True``<br>when an exception is raised at step N, you don't need to run from setup 1 to N.<br>Databot will replay the data from nearest completed node, usually step N-1.<br>It will save a lot of time in the development phase.<br><br><br>More about Databot and data-driven programming<br>===============<br><br>Data-driven programming is a programming paradigm which describes the data to be matched and the processing required rather than defining a sequence of steps to be taken.<br>Standard examples of data-driven languages are the text-processing languages sed and AWK, where the data is a sequence of lines in an input stream.<br>Data-driven programming is typically applied to streams of structured data for filtering, transforming, aggregating (such as computing statistics), or calling other programs.<br><br>Databot has a few basic concepts to implement DDP.<br><br>- **Pipe**<br>   It is the main stream process of the program. All units will work inside.<br>- **Node**<br>        It is the process logic node. It is driven by data. Custom functions work as Nodes.<br>        There are some built-in nodes:<br>   * **Loop**: Works as a **for** loop<br>   * **Timer**: It will send a message in the pipe by timer param. **delay**, **max_time**<br>   * **HttpLoader**: Get a url and return the HTTP response<br>   * **MySQL query or insert**: For mysql querying and insert<br>   * **File read/write**: for file I/O.<br>- **Route**<br>        It will be used to create a complex data flow network, not just one main process. Databot can nest Routes inside Routes.<br>        It is a powerful concept.<br>        There are some pre built-in Route:<br>    * **Branch** : Duplicate data from parent pipe to a branch.<br>    * **Return** : Duplicate data from parent pipe, and return final result to parent pipe.<br>    * **Filter** : Drop data from pipe if it does not match some condition<br>    * **Fork** : Duplicate data to many branches.<br>    * **Join** : Duplicate data to many branches, and return result to pipe.<br><br>All units (Pipe, Node, Route) communicate via queues and perform parallel computation in coroutines.<br>This is abstracted so that Databot can be used with only limited knowledge of ``asyncio``.<br><br>Below some graphs will get you some basic concept for the Route:<br>      branch:https://github.com/kkyon/databot/blob/master/docs/databot_branch.jpg<br>      fork:https://github.com/kkyon/databot/blob/master/docs/databot_fork.jpg<br>      join:https://github.com/kkyon/databot/blob/master/docs/databot_join.jpg<br>      return:https://github.com/kkyon/databot/blob/master/docs/databot_return.jpg<br><br><br>Contributing<br>------------<br><br><br>Donate<br>------<br><br><br>Links<br>-----<br><br><br>\n          </div>"}, "last_serial": 4226635, "releases": {"0.1.5": [{"comment_text": "", "digests": {"md5": "37fb0c2e9b74637db87d1e5f63fb973c", "sha256": "b605e3ff96c91e25bec720cb410651b632ad4b6ca4ef98a38cba2e3816e880b9"}, "downloads": -1, "filename": "databot-0.1.5-py3-none-any.whl", "has_sig": false, "md5_digest": "37fb0c2e9b74637db87d1e5f63fb973c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.5", "size": 13136, "upload_time": "2018-08-25T13:06:57", "upload_time_iso_8601": "2018-08-25T13:06:57.575345Z", "url": "https://files.pythonhosted.org/packages/3e/f1/cb6e0b613524f47070f1fa8fa8ea4d38249be7d5c2739ebece1328d9da6c/databot-0.1.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "178fb3d989081f2072140548c27e3a66", "sha256": "2eddfc769df1bdfb357a5abd368de802ac7cec1342d8584db8fd5986cc2df674"}, "downloads": -1, "filename": "databot-0.1.5.tar.gz", "has_sig": false, "md5_digest": "178fb3d989081f2072140548c27e3a66", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.5", "size": 12383, "upload_time": "2018-08-25T13:06:59", "upload_time_iso_8601": "2018-08-25T13:06:59.255263Z", "url": "https://files.pythonhosted.org/packages/78/64/14b656870d1a00faffe7b90cbdeefcf990be43ae4cefb47c5c9a06fd8e65/databot-0.1.5.tar.gz", "yanked": false}], "0.1.6": [{"comment_text": "", "digests": {"md5": "9f5f81194f51f02b3cef9f72aed049d5", "sha256": "4c5a8fde79690212788b2011a38956a87cdcbc19093ee21c80a0c4768f9e3771"}, "downloads": -1, "filename": "databot-0.1.6-py3-none-any.whl", "has_sig": false, "md5_digest": "9f5f81194f51f02b3cef9f72aed049d5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.5", "size": 13755, "upload_time": "2018-08-27T01:37:14", "upload_time_iso_8601": "2018-08-27T01:37:14.350749Z", "url": "https://files.pythonhosted.org/packages/ae/02/354211e2ba68f56e2514880734c9a562a513d98fba872b3aa0627c61bba6/databot-0.1.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ff37cbc2c968cda4a590e142073d636c", "sha256": "13fc159ae8f2dc589f851f3b3d8d71b28164ead72d3ec9f911e39412086801ea"}, "downloads": -1, "filename": "databot-0.1.6.tar.gz", "has_sig": false, "md5_digest": "ff37cbc2c968cda4a590e142073d636c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.5", "size": 13727, "upload_time": "2018-08-27T01:37:16", "upload_time_iso_8601": "2018-08-27T01:37:16.569447Z", "url": "https://files.pythonhosted.org/packages/0f/25/c6b6a3fd9c96f8652b967628c6eb642ec149acb2d027f2a0d89a078bdafa/databot-0.1.6.tar.gz", "yanked": false}], "0.1.7": [{"comment_text": "", "digests": {"md5": "191c4dddb26012039ca6ed59825b6e38", "sha256": "ee634fa6aa63fcac7129f24e4627fd99c5cca191063de560e38725e370a50fdd"}, "downloads": -1, "filename": "databot-0.1.7-py3-none-any.whl", "has_sig": false, "md5_digest": "191c4dddb26012039ca6ed59825b6e38", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.5", "size": 14669, "upload_time": "2018-08-27T07:32:09", "upload_time_iso_8601": "2018-08-27T07:32:09.650281Z", "url": "https://files.pythonhosted.org/packages/72/94/51b2b7294b94b88a68a3f2016720e8c70557238ecac4ef943d2304e3ef7d/databot-0.1.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "56615bd09a34554b48ee4c4e2f66af01", "sha256": "d9320474f300e8ab3b64bac6ad81eaabeaec9c562c1a637892660c04113e36bb"}, "downloads": -1, "filename": "databot-0.1.7.tar.gz", "has_sig": false, "md5_digest": "56615bd09a34554b48ee4c4e2f66af01", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.5", "size": 14480, "upload_time": "2018-08-27T07:32:11", "upload_time_iso_8601": "2018-08-27T07:32:11.450887Z", "url": "https://files.pythonhosted.org/packages/fa/73/8ef2e56726fbb778bad13a06d685757067ba476745e50156590bff8aded5/databot-0.1.7.tar.gz", "yanked": false}], "0.1.8": [{"comment_text": "", "digests": {"md5": "183000f5edd47d3fe90b3a6827e5b9ee", "sha256": "94e69277c24d3827646c1d0ad99adb82715c57fd0824d550c912eea85c8a389b"}, "downloads": -1, "filename": "databot-0.1.8-py3-none-any.whl", "has_sig": false, "md5_digest": "183000f5edd47d3fe90b3a6827e5b9ee", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.5", "size": 15774, "upload_time": "2018-08-31T14:50:36", "upload_time_iso_8601": "2018-08-31T14:50:36.164038Z", "url": "https://files.pythonhosted.org/packages/8f/c6/0f48395296496e8b01414ed3dc8d03815970eab63f42a1e55396009a6e85/databot-0.1.8-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "98f3edd81d5ccbb876af6d29569b2967", "sha256": "9a320a5ab76de1be6038d4f91306bec2958cd95527a000d2558d25456f455a5d"}, "downloads": -1, "filename": "databot-0.1.8.tar.gz", "has_sig": false, "md5_digest": "98f3edd81d5ccbb876af6d29569b2967", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.5", "size": 14998, "upload_time": "2018-08-31T14:50:37", "upload_time_iso_8601": "2018-08-31T14:50:37.905108Z", "url": "https://files.pythonhosted.org/packages/24/8c/40e8d13081ba820393adf0804b791bf234c475d9dd11a48c8b999df63193/databot-0.1.8.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "183000f5edd47d3fe90b3a6827e5b9ee", "sha256": "94e69277c24d3827646c1d0ad99adb82715c57fd0824d550c912eea85c8a389b"}, "downloads": -1, "filename": "databot-0.1.8-py3-none-any.whl", "has_sig": false, "md5_digest": "183000f5edd47d3fe90b3a6827e5b9ee", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.5", "size": 15774, "upload_time": "2018-08-31T14:50:36", "upload_time_iso_8601": "2018-08-31T14:50:36.164038Z", "url": "https://files.pythonhosted.org/packages/8f/c6/0f48395296496e8b01414ed3dc8d03815970eab63f42a1e55396009a6e85/databot-0.1.8-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "98f3edd81d5ccbb876af6d29569b2967", "sha256": "9a320a5ab76de1be6038d4f91306bec2958cd95527a000d2558d25456f455a5d"}, "downloads": -1, "filename": "databot-0.1.8.tar.gz", "has_sig": false, "md5_digest": "98f3edd81d5ccbb876af6d29569b2967", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.5", "size": 14998, "upload_time": "2018-08-31T14:50:37", "upload_time_iso_8601": "2018-08-31T14:50:37.905108Z", "url": "https://files.pythonhosted.org/packages/24/8c/40e8d13081ba820393adf0804b791bf234c475d9dd11a48c8b999df63193/databot-0.1.8.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:40:30 2020"}