{"info": {"author": "Kevin Ballard", "author_email": "kevin@tellapart.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Natural Language :: English", "Operating System :: POSIX"], "description": "<div id=\"container\" align=\"center\">\n  <img\n    src=\"http://tellapart.com/wp-content/uploads/2012/06/taba-kanji.gif\"\n    alt=\"Taba\" />\n</div>\n\nIntroduction\n====================\n\nTaba is a service for aggregating instrumentation events from large distributed\nsystems in near real-time. It was built to handle high throughput and scale\neasily.\n\nCheck out an overview of Taba's architecture on the TellApart Eng Blog:\n[http://www.tellapart.com/taba-low-latency-event-aggregation\n](http://www.tellapart.com/taba-low-latency-event-aggregation)\n\nExample\n====================\n\nTaba helps you instrument your services and provide a near real-time view into\nwhat's happening across a large cluster. For example, you could use it to track\nthe winning bid price for a certain type of bid:\n\n    from taba import client\n\n    ...\n\n    client.Counter('bids_won', 1)\n    client.Counter('winning_bid_price', wincpm)\n\nWhen those Events reach the Taba Server and are aggregated, they produce an\noutput like the following:\n\n    $ taba-cli agg winning_bid_price\n    winning_bid_price: {\n        \"1m\": {\"count\": 436, \"total\": 571.64},\n        \"10m\": {\"count\": 5285, \"total\": 6884.57},\n        \"1h\": {\"count\": 34265, \"total\": 44175.47},\n        \"1d\": {\"count\": 569787, \"total\": 744423.87},\n        \"pct\": [0.09, 0.47, 2.19, 3.55, 4.37, 14.09, 17.59]}\n\nThere are many other input data types and aggregation methods available. See the\nTypes and Handlers documentation.\n\nOverview\n====================\n\nA Taba deployment consists of 6 layers, each horizontally scalable. These\nlayers are:\n\n- Taba Client code integrated into applications\n- Taba Agent process running locally to the application servers\n- Taba Server processes in the frontend ('fe') role\n- Taba Server processes in the backend ('be') role\n- Redis sentinel processes\n- Redis database processes\n\nThe Taba Client is integrated into the application it is instrumenting, and\nexposes an API for recording events to different counter types. The Python\ndistribution includes a default Client implementation based on threads, and\na Gevent engine. There is also a Java Client available\n([https://github.com/tellapart/taba-java-client]\n(https://github.com/tellapart/taba-java-client))\n\nThe Client typically sends events to a Taba Agent process running on the same\nserver. While the Client will only forward events on a best-effort basis, the\nAgent provides more robust buffering and failure recovery. It is also\nsignificantly smarter about load balancing.\n\nThe will forward events to one of the Taba Server end-points it has been\nconfigured to connect to. Any Server in the cluster can receive any set of\nevents.\n\nThe Taba Server processes are split into two groups: frontend ('fe') and backend\n('be'). These roles are configured when the process starts. Assigning a process\na 'fe' role has no effect on its operation -- it is simply a marker that the\nprocess will use to advertise its role. (The intention it to allow a\nload-balancer to use that indicator to route traffic to just the 'fe'\nprocesses). Assigning the 'be' role will configure the process to launch a\nbackground worker that processes queued events. There must be at least one 'be'\nServer process in the cluster.\n\nA Server process can be assigned both 'fe' and 'be' roles. For small clusters,\nthis will work well. However, once a cluster becomes large enough to require\nmultiple Server processes, separating 'fe' and 'be' processes will perform\nbetter.\n\nThere is a third role 'ctrl', which essentially marks a Server process as\nneither 'fe' nor 'be'. This is useful for maintaining a separate set of\nprocesses for querying.\n\nThe Taba Server uses a group of Redis databases and Sentinels. Having at least\none Sentinel is a requirement, as it is used for service discovery of the\nindividual database processes. Sharding across the databases is accomplished by\nsplitting the key-space into a large number of virtual buckets, and assigning\nranges of buckets to each process.\n\nInstalling Taba\n====================\n\nTaba was designed to run on Python 2.6/2.7. It has the following Python package\ndependencies, which should be installed automatically:\n\n- gevent (>= 0.13.1)\n- python-cjson (>= 1.0.5)\n- cython (>= 0.13)\n- redis (>= 2.9)\n- requests (>= 1.2.0)\n\nAdditionally, building the Python dependencies requires the following. These\ndependencies are _not_ installed automatically:\n\n- gcc\n- make\n- python-dev\n- libevent-dev\n\nThe latest stable release can be installed from PyPi:\n\n    pip install taba\n\nOr Taba can be installed directly from the repository:\n\n    git clone https://github.com/tellapart/taba.git\n    cd taba\n    python setup.py install\n\nInstalling Redis\n====================\n\nThe Taba Server uses a group of Redis instances with Sentinels as its\ndatabase. It requires at least Redis 2.8. For details about installing Redis,\nplease visit the [Redis Downloads page](http://redis.io/download)\n\nDeploying Taba\n====================\n\nThere are many ways to deploy Taba, depending on the use case. See\n`examples/EXAMPLES` for pointers on how to get started.\n\nAbout\n====================\n\nTaba is a project at TellApart led by\n[Kevin Ballard](https://github.com/kevinballard) to create a reliable, high\nperformance platform for real-time monitoring. It is used to monitor over\n30,000 Tabs, consuming nearly 10,000,000 Events per second, and an average\nlatency of under 15s.\n\nAny questions or comments can be forwarded to \n[taba@tellapart.com](mailto:taba@tellapart.com)", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://github.com/tellapart/taba", "keywords": null, "license": "Apache License, Version 2.0", "maintainer": null, "maintainer_email": null, "name": "taba", "package_url": "https://pypi.org/project/taba/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/taba/", "project_urls": {"Download": "UNKNOWN", "Homepage": "http://github.com/tellapart/taba"}, "release_url": "https://pypi.org/project/taba/0.3.5/", "requires_dist": null, "requires_python": null, "summary": "UNKNOWN", "version": "0.3.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            &lt;div id=\"container\" align=\"center\"&gt;<br>  &lt;img<br>    src=\"http://tellapart.com/wp-content/uploads/2012/06/taba-kanji.gif\"<br>    alt=\"Taba\" /&gt;<br>&lt;/div&gt;<br><br>Introduction<br>====================<br><br>Taba is a service for aggregating instrumentation events from large distributed<br>systems in near real-time. It was built to handle high throughput and scale<br>easily.<br><br>Check out an overview of Taba's architecture on the TellApart Eng Blog:<br>[http://www.tellapart.com/taba-low-latency-event-aggregation<br>](http://www.tellapart.com/taba-low-latency-event-aggregation)<br><br>Example<br>====================<br><br>Taba helps you instrument your services and provide a near real-time view into<br>what's happening across a large cluster. For example, you could use it to track<br>the winning bid price for a certain type of bid:<br><br>    from taba import client<br><br>    ...<br><br>    client.Counter('bids_won', 1)<br>    client.Counter('winning_bid_price', wincpm)<br><br>When those Events reach the Taba Server and are aggregated, they produce an<br>output like the following:<br><br>    $ taba-cli agg winning_bid_price<br>    winning_bid_price: {<br>        \"1m\": {\"count\": 436, \"total\": 571.64},<br>        \"10m\": {\"count\": 5285, \"total\": 6884.57},<br>        \"1h\": {\"count\": 34265, \"total\": 44175.47},<br>        \"1d\": {\"count\": 569787, \"total\": 744423.87},<br>        \"pct\": [0.09, 0.47, 2.19, 3.55, 4.37, 14.09, 17.59]}<br><br>There are many other input data types and aggregation methods available. See the<br>Types and Handlers documentation.<br><br>Overview<br>====================<br><br>A Taba deployment consists of 6 layers, each horizontally scalable. These<br>layers are:<br><br>- Taba Client code integrated into applications<br>- Taba Agent process running locally to the application servers<br>- Taba Server processes in the frontend ('fe') role<br>- Taba Server processes in the backend ('be') role<br>- Redis sentinel processes<br>- Redis database processes<br><br>The Taba Client is integrated into the application it is instrumenting, and<br>exposes an API for recording events to different counter types. The Python<br>distribution includes a default Client implementation based on threads, and<br>a Gevent engine. There is also a Java Client available<br>([https://github.com/tellapart/taba-java-client]<br>(https://github.com/tellapart/taba-java-client))<br><br>The Client typically sends events to a Taba Agent process running on the same<br>server. While the Client will only forward events on a best-effort basis, the<br>Agent provides more robust buffering and failure recovery. It is also<br>significantly smarter about load balancing.<br><br>The will forward events to one of the Taba Server end-points it has been<br>configured to connect to. Any Server in the cluster can receive any set of<br>events.<br><br>The Taba Server processes are split into two groups: frontend ('fe') and backend<br>('be'). These roles are configured when the process starts. Assigning a process<br>a 'fe' role has no effect on its operation -- it is simply a marker that the<br>process will use to advertise its role. (The intention it to allow a<br>load-balancer to use that indicator to route traffic to just the 'fe'<br>processes). Assigning the 'be' role will configure the process to launch a<br>background worker that processes queued events. There must be at least one 'be'<br>Server process in the cluster.<br><br>A Server process can be assigned both 'fe' and 'be' roles. For small clusters,<br>this will work well. However, once a cluster becomes large enough to require<br>multiple Server processes, separating 'fe' and 'be' processes will perform<br>better.<br><br>There is a third role 'ctrl', which essentially marks a Server process as<br>neither 'fe' nor 'be'. This is useful for maintaining a separate set of<br>processes for querying.<br><br>The Taba Server uses a group of Redis databases and Sentinels. Having at least<br>one Sentinel is a requirement, as it is used for service discovery of the<br>individual database processes. Sharding across the databases is accomplished by<br>splitting the key-space into a large number of virtual buckets, and assigning<br>ranges of buckets to each process.<br><br>Installing Taba<br>====================<br><br>Taba was designed to run on Python 2.6/2.7. It has the following Python package<br>dependencies, which should be installed automatically:<br><br>- gevent (&gt;= 0.13.1)<br>- python-cjson (&gt;= 1.0.5)<br>- cython (&gt;= 0.13)<br>- redis (&gt;= 2.9)<br>- requests (&gt;= 1.2.0)<br><br>Additionally, building the Python dependencies requires the following. These<br>dependencies are _not_ installed automatically:<br><br>- gcc<br>- make<br>- python-dev<br>- libevent-dev<br><br>The latest stable release can be installed from PyPi:<br><br>    pip install taba<br><br>Or Taba can be installed directly from the repository:<br><br>    git clone https://github.com/tellapart/taba.git<br>    cd taba<br>    python setup.py install<br><br>Installing Redis<br>====================<br><br>The Taba Server uses a group of Redis instances with Sentinels as its<br>database. It requires at least Redis 2.8. For details about installing Redis,<br>please visit the [Redis Downloads page](http://redis.io/download)<br><br>Deploying Taba<br>====================<br><br>There are many ways to deploy Taba, depending on the use case. See<br>`examples/EXAMPLES` for pointers on how to get started.<br><br>About<br>====================<br><br>Taba is a project at TellApart led by<br>[Kevin Ballard](https://github.com/kevinballard) to create a reliable, high<br>performance platform for real-time monitoring. It is used to monitor over<br>30,000 Tabs, consuming nearly 10,000,000 Events per second, and an average<br>latency of under 15s.<br><br>Any questions or comments can be forwarded to <br>[taba@tellapart.com](mailto:taba@tellapart.com)\n          </div>"}, "last_serial": 1218639, "releases": {"0.3.2": [{"comment_text": "", "digests": {"md5": "021520b3a179f30a1a100d9a9f7eb1b2", "sha256": "2340d48e0a6e5902820700f0e258bbfd6ff0608ff24e2f4aacd4ae6791d15d45"}, "downloads": -1, "filename": "taba-0.3.2.tar.gz", "has_sig": false, "md5_digest": "021520b3a179f30a1a100d9a9f7eb1b2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 126027, "upload_time": "2014-04-12T00:05:52", "upload_time_iso_8601": "2014-04-12T00:05:52.095939Z", "url": "https://files.pythonhosted.org/packages/63/b9/fb48c4fcd55255387d5925808dc862111ca04ac5e041cd0f89cd5bec22de/taba-0.3.2.tar.gz", "yanked": false}], "0.3.3": [{"comment_text": "", "digests": {"md5": "16ff258069f2d287fb40d32aaf6aa379", "sha256": "452fc9bcde31df02be4e6491cfa6d4f78bc41b912915c674b085ba533b8b5864"}, "downloads": -1, "filename": "taba-0.3.3.tar.gz", "has_sig": false, "md5_digest": "16ff258069f2d287fb40d32aaf6aa379", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 128408, "upload_time": "2014-04-12T00:07:28", "upload_time_iso_8601": "2014-04-12T00:07:28.114009Z", "url": "https://files.pythonhosted.org/packages/59/76/b30f45032836d62987dd6b8849970fc070bdde23edbd454ce448ed2347e4/taba-0.3.3.tar.gz", "yanked": false}], "0.3.4": [{"comment_text": "", "digests": {"md5": "dbfb7f3d2f3a2702468f6aa8901a958c", "sha256": "dee4b8dfde8f27ba95b9e28d7c123a1d27aa09ecda65d1c8a8eb925f865bc2cc"}, "downloads": -1, "filename": "taba-0.3.4.tar.gz", "has_sig": false, "md5_digest": "dbfb7f3d2f3a2702468f6aa8901a958c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 128422, "upload_time": "2014-04-12T21:40:53", "upload_time_iso_8601": "2014-04-12T21:40:53.686992Z", "url": "https://files.pythonhosted.org/packages/4b/9a/1f301a1a0a003d50d8e506e7fc9332c4b38c58f17db668a0a1f09ae23fed/taba-0.3.4.tar.gz", "yanked": false}], "0.3.5": [{"comment_text": "", "digests": {"md5": "cfd0a85b51cf1c993215b2a97128093f", "sha256": "b1dc0e099d2bde86dd05b7894a69b5ce052154958d7be3b1ed89f3858f95be71"}, "downloads": -1, "filename": "taba-0.3.5.tar.gz", "has_sig": false, "md5_digest": "cfd0a85b51cf1c993215b2a97128093f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 131259, "upload_time": "2014-09-09T19:16:07", "upload_time_iso_8601": "2014-09-09T19:16:07.877948Z", "url": "https://files.pythonhosted.org/packages/f6/ef/a96fb4a9d990cfe24b2c321f470ae7a9510979705f865b5790aa7d7f1182/taba-0.3.5.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "cfd0a85b51cf1c993215b2a97128093f", "sha256": "b1dc0e099d2bde86dd05b7894a69b5ce052154958d7be3b1ed89f3858f95be71"}, "downloads": -1, "filename": "taba-0.3.5.tar.gz", "has_sig": false, "md5_digest": "cfd0a85b51cf1c993215b2a97128093f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 131259, "upload_time": "2014-09-09T19:16:07", "upload_time_iso_8601": "2014-09-09T19:16:07.877948Z", "url": "https://files.pythonhosted.org/packages/f6/ef/a96fb4a9d990cfe24b2c321f470ae7a9510979705f865b5790aa7d7f1182/taba-0.3.5.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:58:45 2020"}