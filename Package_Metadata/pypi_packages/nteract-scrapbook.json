{"info": {"author": "nteract contributors", "author_email": "nteract@googlegroups.com", "bugtrack_url": null, "classifiers": ["Intended Audience :: Developers", "Intended Audience :: Science/Research", "Intended Audience :: System Administrators", "License :: OSI Approved :: BSD License", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8"], "description": "<img width=\"616\" alt=\"scrapbook logo\" src=\"https://user-images.githubusercontent.com/836375/52512549-31260f00-2bba-11e9-9556-515ba5ff0b4b.png\">\n\n# scrapbook\n\n<!---(binder links generated at https://mybinder.readthedocs.io/en/latest/howto/badges.html and compressed at https://tinyurl.com) -->\n\n[![Travis Build Status](https://travis-ci.org/nteract/scrapbook.svg?branch=master)](https://travis-ci.org/nteract/scrapbook)\n[![Azure Build Status](https://dev.azure.com/nteract/nteract/_apis/build/status/nteract.scrapbook?branchName=master)](https://dev.azure.com/nteract/nteract/_build/latest?definitionId=6&branchName=master)\n[![image](https://codecov.io/github/nteract/scrapbook/coverage.svg?branch=master)](https://codecov.io/github/nteract/scrapbook=master)\n[![Documentation Status](https://readthedocs.org/projects/nteract-scrapbook/badge/?version=latest)](https://nteract-scrapbook.readthedocs.io/en/latest/?badge=latest)\n[![badge](https://tinyurl.com/y3moqkmc)](https://mybinder.org/v2/gh/nteract/scrapbook/master?filepath=binder%2Freglue_highlight_dates.ipynb)\n[![badge](https://tinyurl.com/ybk8qa3j)](https://mybinder.org/v2/gh/nteract/scrapbook/master?filepath=binder%2FResultsDemo.ipynb)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/ambv/black)\n\nTHE **scrapbook** library records a notebook\u2019s data values and generated visual\ncontent as \"scraps\". Recorded scraps can be read at a future time.\n\n[See the scrapbook documentation](https://nteract-scrapbook.readthedocs.io/) for\nmore information on how to use scrapbook.\n\n## Use Cases\n\nNotebook users may wish to record data produced during a notebook's execution.\nThis recorded data, **scraps**, can be used at a later time or passed in a\nworkflow to another notebook as input.\n\nNamely, scrapbook lets you:\n\n- **persist** data and visual content displays in a notebook as scraps\n- **recall** any persisted scrap of data\n- **summarize collections** of notebooks\n\n## Python Version Support\n\nThis library's long term support target is Python 3.5+. It currently also\nsupports Python 2.7 until Python 2 reaches end-of-life in 2020. After this\ndate, Python 2 support will halt, and only 3.x versions will be maintained.\n\n## Installation\n\nInstall using `pip`:\n\n```{.sourceCode .bash}\npip install nteract-scrapbook\n```\n\nFor installing optional IO dependencies, you can specify individual store bundles,\nlike `s3` or `azure`:\n\n```{.sourceCode .bash}\npip install nteract-scrapbook[s3]\n```\n\nor use `all`:\n\n```{.sourceCode .bash}\npip install nteract-scrapbook[all]\n```\n\n---\n\n## Models and Terminology\n\nScrapbook defines the following items:\n\n- **scraps**: serializable data values and visualizations such as strings, lists of\n  objects, pandas dataframes, charts, images, or data references.\n- **notebook**: a wrapped nbformat notebook object with extra methods for interacting\n  with scraps.\n- **scrapbook**: a collection of notebooks with an interface for asking questions of\n  the collection.\n- **encoders**: a registered translator of data to/from notebook\n  storage formats.\n\n### `scrap` model\n\nThe `scrap` model houses a few key attributes in a tuple, including:\n\n- **name**: The name of the scrap\n- **data**: Any data captured by the scrapbook api call\n- **encoder**: The name of the encoder used to encode/decode data to/from the notebook\n- **display**: Any display data used by IPython to display visual content\n\n---\n\n## API\n\nScrapbook adds a few basic api commands which enable saving and retrieving data\nincluding:\n\n- `glue` to persist scraps with or without _display output_\n- `read_notebook` reads one notebook\n- `scraps` provides a searchable dictionary of all scraps by name\n- `reglue` which copies a scrap from another notebook to the current notebook\n- `read_notebooks` reads many notebooks from a given path\n- `scraps_report` displays a report about collected scraps\n- `papermill_dataframe` and `papermill_metrics` for backward compatibility\n  for two deprecated papermill features\n\nThe following sections provide more detail on these api commands.\n\n### `glue` to persist scraps\n\nRecords a `scrap` (data or display value) in the given notebook cell.\n\nThe `scrap` (recorded value) can be retrieved during later inspection of the\noutput notebook.\n\n```python\n\"\"\"glue example for recording data values\"\"\"\nimport scrapbook as sb\n\nsb.glue(\"hello\", \"world\")\nsb.glue(\"number\", 123)\nsb.glue(\"some_list\", [1, 3, 5])\nsb.glue(\"some_dict\", {\"a\": 1, \"b\": 2})\nsb.glue(\"non_json\", df, 'arrow')\n```\n\nThe scrapbook library can be used later to recover `scraps` from the output\nnotebook:\n\n```python\n# read a notebook and get previously recorded scraps\nnb = sb.read_notebook('notebook.ipynb')\nnb.scraps\n```\n\n**scrapbook** will imply the storage format by the value type of any registered\ndata encoders. Alternatively, the implied encoding format can be overwritten by\nsetting the `encoder` argument to the registered name (e.g. `\"json\"`) of a\nparticular encoder.\n\nThis data is persisted by generating a display output with a special media type\nidentifying the content encoding format and data. These outputs are not always\nvisible in notebook rendering but still exist in the document. Scrapbook can\nthen rehydrate the data associated with the notebook in the future by reading\nthese cell outputs.\n\n#### With _display output_\n\nTo display a named scrap with visible display outputs, you need to indicate that\nthe scrap is directly renderable.\n\nThis can be done by toggling the `display` argument.\n\n```python\n# record a UI message along with the input string\nsb.glue(\"hello\", \"Hello World\", display=True)\n```\n\nThe call will save the data and the display attributes of the Scrap object,\nmaking it visible as well as encoding the original data. This leans on the\n`IPython.core.formatters.format_display_data` function to translate the data\nobject into a display and metadata dict for the notebook kernel to parse.\n\nAnother pattern that can be used is to specify that **only the display data**\nshould be saved, and not the original object. This is achieved by setting\nthe encoder to be `display`.\n\n```python\n# record an image without the original input object\nsb.glue(\"sharable_png\",\n  IPython.display.Image(filename=\"sharable.png\"),\n  encoder='display'\n)\n```\n\nFinally the media types that are generated can be controlled by passing\na list, tuple, or dict object as the display argument.\n\n```python\nsb.glue(\"media_as_text_only\",\n  media_obj,\n  encoder='display',\n  display=('text/plain',) # This passes [text/plain] to format_display_data's include argument\n)\n\nsb.glue(\"media_without_text\",\n  media_obj,\n  encoder='display',\n  display={'exclude': 'text/plain'} # forward to format_display_data's kwargs\n)\n```\n\nLike data scraps, these can be retrieved at a later time be accessing the scrap's\n`display` attribute. Though usually one will just use Notebook's `reglue` method\n(described below).\n\n### `read_notebook` reads one notebook\n\nReads a Notebook object loaded from the location specified at `path`.\nYou've already seen how this function is used in the above api call examples,\nbut essentially this provides a thin wrapper over an `nbformat`'s NotebookNode\nwith the ability to extract scrapbook scraps.\n\n```python\nnb = sb.read_notebook('notebook.ipynb')\n```\n\nThis Notebook object adheres to the [nbformat's json schema](https://github.com/jupyter/nbformat/blob/master/nbformat/v4/nbformat.v4.schema.json),\nallowing for access to its required fields.\n\n```python\nnb.cells # The cells from the notebook\nnb.metadata\nnb.nbformat\nnb.nbformat_minor\n```\n\nThere's a few additional methods provided, most of which are outlined in more detail\nbelow:\n\n```python\nnb.scraps\nnb.reglue\n```\n\nThe abstraction also makes saved content available as a dataframe referencing each\nkey and source. More of these methods will be made available in later versions.\n\n```python\n# Produces a data frame with [\"name\", \"data\", \"encoder\", \"display\", \"filename\"] as columns\nnb.scrap_dataframe # Warning: This might be a large object if data or display is large\n```\n\nThe Notebook object also has a few legacy functions for backwards compatibility\nwith papermill's Notebook object model. As a result, it can be used to read\npapermill execution statistics as well as scrapbook abstractions:\n\n```python\nnb.cell_timing # List of cell execution timings in cell order\nnb.execution_counts # List of cell execution counts in cell order\nnb.papermill_metrics # Dataframe of cell execution counts and times\nnb.papermill_record_dataframe # Dataframe of notebook records (scraps with only data)\nnb.parameter_dataframe # Dataframe of notebook parameters\nnb.papermill_dataframe # Dataframe of notebook parameters and cell scraps\n```\n\nThe notebook reader relies on [papermill's registered iorw](https://papermill.readthedocs.io/en/latest/reference/papermill-io.html)\nto enable access to a variety of sources such as -- but not limited to -- S3,\nAzure, and Google Cloud.\n\n### `scraps` provides a name -> scrap lookup\n\nThe `scraps` method allows for access to all of the scraps in a particular notebook.\n\n```python\nnb = sb.read_notebook('notebook.ipynb')\nnb.scraps # Prints a dict of all scraps by name\n```\n\nThis object has a few additional methods as well for convenient conversion and\nexecution.\n\n```python\nnb.scraps.data_scraps # Filters to only scraps with `data` associated\nnb.scraps.data_dict # Maps `data_scraps` to a `name` -> `data` dict\nnb.scraps.display_scraps # Filters to only scraps with `display` associated\nnb.scraps.display_dict # Maps `display_scraps` to a `name` -> `display` dict\nnb.scraps.dataframe # Generates a dataframe with [\"name\", \"data\", \"encoder\", \"display\"] as columns\n```\n\nThese methods allow for simple use-cases to not require digging through model\nabstractions.\n\n### `reglue` copys a scrap into the current notebook\n\nUsing `reglue` one can take any scrap glue'd into one notebook and glue into the\ncurrent one.\n\n```python\nnb = sb.read_notebook('notebook.ipynb')\nnb.reglue(\"table_scrap\") # This copies both data and displays\n```\n\nAny data or display information will be copied verbatim into the currently\nexecuting notebook as though the user called `glue` again on the original source.\n\nIt's also possible to rename the scrap in the process.\n\n```python\nnb.reglue(\"table_scrap\", \"old_table_scrap\")\n```\n\nAnd finally if one wishes to try to reglue without checking for existence the\n`raise_on_missing` can be set to just display a message on failure.\n\n```python\nnb.reglue(\"maybe_missing\", raise_on_missing=False)\n# => \"No scrap found with name 'maybe_missing' in this notebook\"\n```\n\n### `read_notebooks` reads many notebooks\n\nReads all notebooks located in a given `path` into a Scrapbook object.\n\n```python\n# create a scrapbook named `book`\nbook = sb.read_notebooks('path/to/notebook/collection/')\n# get the underlying notebooks as a list\nbook.notebooks # Or `book.values`\n```\n\nThe path reuses [papermill's registered `iorw`](https://papermill.readthedocs.io/en/latest/reference/papermill-io.html)\nto list and read files form various sources, such that non-local urls can load data.\n\n```python\n# create a scrapbook named `book`\nbook = sb.read_notebooks('s3://bucket/key/prefix/to/notebook/collection/')\n```\n\nThe Scrapbook (`book` in this example) can be used to recall all scraps across\nthe collection of notebooks:\n\n```python\nbook.notebook_scraps # Dict of shape `notebook` -> (`name` -> `scrap`)\nbook.scraps # merged dict of shape `name` -> `scrap`\n```\n\n### `scraps_report` displays a report about collected scraps\n\nThe Scrapbook collection can be used to generate a `scraps_report` on all the\nscraps from the collection as a markdown structured output.\n\n```python\nbook.scraps_report()\n```\n\nThis display can filter on scrap and notebook names, as well as enable or disable\nan overall header for the display.\n\n```python\nbook.scraps_report(\n  scrap_names=[\"scrap1\", \"scrap2\"],\n  notebook_names=[\"result1\"], # matches `/notebook/collections/result1.ipynb` pathed notebooks\n  header=False\n)\n```\n\nBy default the report will only populate with visual elements. To also\nreport on data elements set include_data.\n\n```python\nbook.scraps_report(include_data=True)\n```\n\n### papermill support\n\nFinally the scrapbook provides two backwards compatible features for deprecated\n`papermill` capabilities:\n\n```python\nbook.papermill_dataframe\nbook.papermill_metrics\n```\n\n## Encoders\n\nEncoders are accessible by key names to Encoder objects registered\nagainst the `encoders.registry` object. To register new data encoders\nsimply call:\n\n```python\nfrom encoder import registry as encoder_registry\n# add encoder to the registry\nencoder_registry.register(\"custom_encoder_name\", MyCustomEncoder())\n```\n\nThe encode class must implement two methods, `encode` and `decode`:\n\n```python\nclass MyCustomEncoder(object):\n    def encode(self, scrap):\n        # scrap.data is any type, usually specific to the encoder name\n        pass  # Return a `Scrap` with `data` type one of [None, list, dict, *six.integer_types, *six.string_types]\n\n    def decode(self, scrap):\n        # scrap.data is one of [None, list, dict, *six.integer_types, *six.string_types]\n        pass  # Return a `Scrap` with `data` type as any type, usually specific to the encoder name\n```\n\nThis can read transform scraps into a json object representing their contents or\nlocation and load those strings back into the original data objects.\n\n### `text`\n\nA basic string storage format that saves data as python strings.\n\n```python\nsb.glue(\"hello\", \"world\", \"text\")\n```\n\n### `json`\n\n```python\nsb.glue(\"foo_json\", {\"foo\": \"bar\", \"baz\": 1}, \"json\")\n```\n\n### `arrow`\n\nImplementation Pending!\n\n## papermill's deprecated `record` feature\n\n**scrapbook** provides a robust and flexible recording schema. This library replaces [papermill](https://papermill.readthedocs.io)'s existing\n`record` functionality.\n\n[Documentation for papermill `record`](https://papermill.readthedocs.io/en/latest/usage-recording.html?#recording-values-to-the-notebook) exists on ReadTheDocs.\nIn brief, the deprecated `record` function:\n\n`pm.record(name, value)`: enables values to be saved\nwith the notebook [[API documentation]](https://papermill.readthedocs.io/en/latest/reference/papermill.html#papermill.api.record)\n\n```python\npm.record(\"hello\", \"world\")\npm.record(\"number\", 123)\npm.record(\"some_list\", [1, 3, 5])\npm.record(\"some_dict\", {\"a\": 1, \"b\": 2})\n```\n\n`pm.read_notebook(notebook)`: pandas could be used later to recover recorded\nvalues by reading the output notebook into a dataframe. For example:\n\n```python\nnb = pm.read_notebook('notebook.ipynb')\nnb.dataframe\n```\n\n### Rationale for Papermill `record` deprecation\n\nPapermill's `record` function was deprecated due to these limitations and challenges:\n\n- The `record` function didn't follow papermill's pattern of linear execution\n  of a notebook. It was awkward to describe `record` as an additional\n  feature of papermill, and really felt like describing a second less\n  developed library.\n- Recording / Reading required data translation to JSON for everything. This is\n  a tedious, painful process for dataframes.\n- Reading recorded values into a dataframe would result in unintuitive dataframe\n  shapes.\n- Less modularity and flexiblity than other papermill components where custom\n  operators can be registered.\n\nTo overcome these limitations in Papermill, a decision was made to create\n**Scrapbook**.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/nteract/scrapbook", "keywords": "jupyter,mapreduce,nteract,pipeline,notebook", "license": "BSD", "maintainer": "", "maintainer_email": "", "name": "nteract-scrapbook", "package_url": "https://pypi.org/project/nteract-scrapbook/", "platform": "", "project_url": "https://pypi.org/project/nteract-scrapbook/", "project_urls": {"Documentation": "https://nteract-scrapbook.readthedocs.io", "Funding": "https://nteract.io", "Homepage": "https://github.com/nteract/scrapbook", "Source": "https://github.com/nteract/scrapbook/", "Tracker": "https://github.com/nteract/scrapbook/issues"}, "release_url": "https://pypi.org/project/nteract-scrapbook/0.4.1/", "requires_dist": ["pandas", "papermill", "jsonschema", "ipython", "pyarrow", "papermill[all] ; extra == 'all'", "papermill[azure] ; extra == 'azure'", "bumpversion ; extra == 'dev'", "wheel (>=0.31.0) ; extra == 'dev'", "setuptools (>=38.6.0) ; extra == 'dev'", "twine (>=1.11.0) ; extra == 'dev'", "flake8 ; extra == 'dev'", "tox ; extra == 'dev'", "mock ; extra == 'dev'", "ipython ; extra == 'dev'", "papermill[dev] ; extra == 'dev'", "pytest (>=4.1) ; extra == 'dev'", "pytest-cov (>=2.6.1) ; extra == 'dev'", "pytest-mock (>=1.10) ; extra == 'dev'", "pytest-env (>=0.6.2) ; extra == 'dev'", "codecov ; extra == 'dev'", "coverage ; extra == 'dev'", "papermill[gcs] ; extra == 'gcs'", "papermill[s3] ; extra == 's3'", "bumpversion ; extra == 'test'", "wheel (>=0.31.0) ; extra == 'test'", "setuptools (>=38.6.0) ; extra == 'test'", "twine (>=1.11.0) ; extra == 'test'", "flake8 ; extra == 'test'", "tox ; extra == 'test'", "mock ; extra == 'test'", "ipython ; extra == 'test'", "papermill[dev] ; extra == 'test'", "pytest (>=4.1) ; extra == 'test'", "pytest-cov (>=2.6.1) ; extra == 'test'", "pytest-mock (>=1.10) ; extra == 'test'", "pytest-env (>=0.6.2) ; extra == 'test'", "codecov ; extra == 'test'", "coverage ; extra == 'test'"], "requires_python": ">=3.5", "summary": "A library for recording and reading data in Jupyter and nteract Notebooks", "version": "0.4.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <img alt=\"scrapbook logo\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a76db7e105a5b6efb270cbb3f1ef418de6cf2b6f/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f3833363337352f35323531323534392d33313236306630302d326262612d313165392d393535362d3531356261356666306234622e706e67\" width=\"616\">\n<h1>scrapbook</h1>\n\n<p><a href=\"https://travis-ci.org/nteract/scrapbook\" rel=\"nofollow\"><img alt=\"Travis Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0664d5292374b791a222739abbe945e0e76759bc/68747470733a2f2f7472617669732d63692e6f72672f6e7465726163742f7363726170626f6f6b2e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://dev.azure.com/nteract/nteract/_build/latest?definitionId=6&amp;branchName=master\" rel=\"nofollow\"><img alt=\"Azure Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/50d31c2b6563c28841a6ee13b15a16a20fa16353/68747470733a2f2f6465762e617a7572652e636f6d2f6e7465726163742f6e7465726163742f5f617069732f6275696c642f7374617475732f6e7465726163742e7363726170626f6f6b3f6272616e63684e616d653d6d6173746572\"></a>\n<a href=\"https://codecov.io/github/nteract/scrapbook=master\" rel=\"nofollow\"><img alt=\"image\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bba09909a08764a0e6ddba010232f6bd66c27421/68747470733a2f2f636f6465636f762e696f2f6769746875622f6e7465726163742f7363726170626f6f6b2f636f7665726167652e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://nteract-scrapbook.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0f921e11458a21e1e80b7f3bf2cc4dea17042ce4/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6e7465726163742d7363726170626f6f6b2f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<a href=\"https://mybinder.org/v2/gh/nteract/scrapbook/master?filepath=binder%2Freglue_highlight_dates.ipynb\" rel=\"nofollow\"><img alt=\"badge\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/dd338040798843950b171fed192ac4a87720909e/68747470733a2f2f74696e7975726c2e636f6d2f79336d6f716b6d63\"></a>\n<a href=\"https://mybinder.org/v2/gh/nteract/scrapbook/master?filepath=binder%2FResultsDemo.ipynb\" rel=\"nofollow\"><img alt=\"badge\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1668b2006c71490c10c1968dfe61aa19aeef4015/68747470733a2f2f74696e7975726c2e636f6d2f79626b387161336a\"></a>\n<a href=\"https://github.com/ambv/black\" rel=\"nofollow\"><img alt=\"Code style: black\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fbfdc7754183ecf079bc71ddeabaf88f6cbc5c00/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667\"></a></p>\n<p>THE <strong>scrapbook</strong> library records a notebook\u2019s data values and generated visual\ncontent as \"scraps\". Recorded scraps can be read at a future time.</p>\n<p><a href=\"https://nteract-scrapbook.readthedocs.io/\" rel=\"nofollow\">See the scrapbook documentation</a> for\nmore information on how to use scrapbook.</p>\n<h2>Use Cases</h2>\n<p>Notebook users may wish to record data produced during a notebook's execution.\nThis recorded data, <strong>scraps</strong>, can be used at a later time or passed in a\nworkflow to another notebook as input.</p>\n<p>Namely, scrapbook lets you:</p>\n<ul>\n<li><strong>persist</strong> data and visual content displays in a notebook as scraps</li>\n<li><strong>recall</strong> any persisted scrap of data</li>\n<li><strong>summarize collections</strong> of notebooks</li>\n</ul>\n<h2>Python Version Support</h2>\n<p>This library's long term support target is Python 3.5+. It currently also\nsupports Python 2.7 until Python 2 reaches end-of-life in 2020. After this\ndate, Python 2 support will halt, and only 3.x versions will be maintained.</p>\n<h2>Installation</h2>\n<p>Install using <code>pip</code>:</p>\n<pre>pip install nteract-scrapbook\n</pre>\n<p>For installing optional IO dependencies, you can specify individual store bundles,\nlike <code>s3</code> or <code>azure</code>:</p>\n<pre>pip install nteract-scrapbook[s3]\n</pre>\n<p>or use <code>all</code>:</p>\n<pre>pip install nteract-scrapbook[all]\n</pre>\n<hr>\n<h2>Models and Terminology</h2>\n<p>Scrapbook defines the following items:</p>\n<ul>\n<li><strong>scraps</strong>: serializable data values and visualizations such as strings, lists of\nobjects, pandas dataframes, charts, images, or data references.</li>\n<li><strong>notebook</strong>: a wrapped nbformat notebook object with extra methods for interacting\nwith scraps.</li>\n<li><strong>scrapbook</strong>: a collection of notebooks with an interface for asking questions of\nthe collection.</li>\n<li><strong>encoders</strong>: a registered translator of data to/from notebook\nstorage formats.</li>\n</ul>\n<h3><code>scrap</code> model</h3>\n<p>The <code>scrap</code> model houses a few key attributes in a tuple, including:</p>\n<ul>\n<li><strong>name</strong>: The name of the scrap</li>\n<li><strong>data</strong>: Any data captured by the scrapbook api call</li>\n<li><strong>encoder</strong>: The name of the encoder used to encode/decode data to/from the notebook</li>\n<li><strong>display</strong>: Any display data used by IPython to display visual content</li>\n</ul>\n<hr>\n<h2>API</h2>\n<p>Scrapbook adds a few basic api commands which enable saving and retrieving data\nincluding:</p>\n<ul>\n<li><code>glue</code> to persist scraps with or without <em>display output</em></li>\n<li><code>read_notebook</code> reads one notebook</li>\n<li><code>scraps</code> provides a searchable dictionary of all scraps by name</li>\n<li><code>reglue</code> which copies a scrap from another notebook to the current notebook</li>\n<li><code>read_notebooks</code> reads many notebooks from a given path</li>\n<li><code>scraps_report</code> displays a report about collected scraps</li>\n<li><code>papermill_dataframe</code> and <code>papermill_metrics</code> for backward compatibility\nfor two deprecated papermill features</li>\n</ul>\n<p>The following sections provide more detail on these api commands.</p>\n<h3><code>glue</code> to persist scraps</h3>\n<p>Records a <code>scrap</code> (data or display value) in the given notebook cell.</p>\n<p>The <code>scrap</code> (recorded value) can be retrieved during later inspection of the\noutput notebook.</p>\n<pre><span class=\"sd\">\"\"\"glue example for recording data values\"\"\"</span>\n<span class=\"kn\">import</span> <span class=\"nn\">scrapbook</span> <span class=\"k\">as</span> <span class=\"nn\">sb</span>\n\n<span class=\"n\">sb</span><span class=\"o\">.</span><span class=\"n\">glue</span><span class=\"p\">(</span><span class=\"s2\">\"hello\"</span><span class=\"p\">,</span> <span class=\"s2\">\"world\"</span><span class=\"p\">)</span>\n<span class=\"n\">sb</span><span class=\"o\">.</span><span class=\"n\">glue</span><span class=\"p\">(</span><span class=\"s2\">\"number\"</span><span class=\"p\">,</span> <span class=\"mi\">123</span><span class=\"p\">)</span>\n<span class=\"n\">sb</span><span class=\"o\">.</span><span class=\"n\">glue</span><span class=\"p\">(</span><span class=\"s2\">\"some_list\"</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">])</span>\n<span class=\"n\">sb</span><span class=\"o\">.</span><span class=\"n\">glue</span><span class=\"p\">(</span><span class=\"s2\">\"some_dict\"</span><span class=\"p\">,</span> <span class=\"p\">{</span><span class=\"s2\">\"a\"</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"s2\">\"b\"</span><span class=\"p\">:</span> <span class=\"mi\">2</span><span class=\"p\">})</span>\n<span class=\"n\">sb</span><span class=\"o\">.</span><span class=\"n\">glue</span><span class=\"p\">(</span><span class=\"s2\">\"non_json\"</span><span class=\"p\">,</span> <span class=\"n\">df</span><span class=\"p\">,</span> <span class=\"s1\">'arrow'</span><span class=\"p\">)</span>\n</pre>\n<p>The scrapbook library can be used later to recover <code>scraps</code> from the output\nnotebook:</p>\n<pre><span class=\"c1\"># read a notebook and get previously recorded scraps</span>\n<span class=\"n\">nb</span> <span class=\"o\">=</span> <span class=\"n\">sb</span><span class=\"o\">.</span><span class=\"n\">read_notebook</span><span class=\"p\">(</span><span class=\"s1\">'notebook.ipynb'</span><span class=\"p\">)</span>\n<span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">scraps</span>\n</pre>\n<p><strong>scrapbook</strong> will imply the storage format by the value type of any registered\ndata encoders. Alternatively, the implied encoding format can be overwritten by\nsetting the <code>encoder</code> argument to the registered name (e.g. <code>\"json\"</code>) of a\nparticular encoder.</p>\n<p>This data is persisted by generating a display output with a special media type\nidentifying the content encoding format and data. These outputs are not always\nvisible in notebook rendering but still exist in the document. Scrapbook can\nthen rehydrate the data associated with the notebook in the future by reading\nthese cell outputs.</p>\n<h4>With <em>display output</em></h4>\n<p>To display a named scrap with visible display outputs, you need to indicate that\nthe scrap is directly renderable.</p>\n<p>This can be done by toggling the <code>display</code> argument.</p>\n<pre><span class=\"c1\"># record a UI message along with the input string</span>\n<span class=\"n\">sb</span><span class=\"o\">.</span><span class=\"n\">glue</span><span class=\"p\">(</span><span class=\"s2\">\"hello\"</span><span class=\"p\">,</span> <span class=\"s2\">\"Hello World\"</span><span class=\"p\">,</span> <span class=\"n\">display</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<p>The call will save the data and the display attributes of the Scrap object,\nmaking it visible as well as encoding the original data. This leans on the\n<code>IPython.core.formatters.format_display_data</code> function to translate the data\nobject into a display and metadata dict for the notebook kernel to parse.</p>\n<p>Another pattern that can be used is to specify that <strong>only the display data</strong>\nshould be saved, and not the original object. This is achieved by setting\nthe encoder to be <code>display</code>.</p>\n<pre><span class=\"c1\"># record an image without the original input object</span>\n<span class=\"n\">sb</span><span class=\"o\">.</span><span class=\"n\">glue</span><span class=\"p\">(</span><span class=\"s2\">\"sharable_png\"</span><span class=\"p\">,</span>\n  <span class=\"n\">IPython</span><span class=\"o\">.</span><span class=\"n\">display</span><span class=\"o\">.</span><span class=\"n\">Image</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"o\">=</span><span class=\"s2\">\"sharable.png\"</span><span class=\"p\">),</span>\n  <span class=\"n\">encoder</span><span class=\"o\">=</span><span class=\"s1\">'display'</span>\n<span class=\"p\">)</span>\n</pre>\n<p>Finally the media types that are generated can be controlled by passing\na list, tuple, or dict object as the display argument.</p>\n<pre><span class=\"n\">sb</span><span class=\"o\">.</span><span class=\"n\">glue</span><span class=\"p\">(</span><span class=\"s2\">\"media_as_text_only\"</span><span class=\"p\">,</span>\n  <span class=\"n\">media_obj</span><span class=\"p\">,</span>\n  <span class=\"n\">encoder</span><span class=\"o\">=</span><span class=\"s1\">'display'</span><span class=\"p\">,</span>\n  <span class=\"n\">display</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"s1\">'text/plain'</span><span class=\"p\">,)</span> <span class=\"c1\"># This passes [text/plain] to format_display_data's include argument</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">sb</span><span class=\"o\">.</span><span class=\"n\">glue</span><span class=\"p\">(</span><span class=\"s2\">\"media_without_text\"</span><span class=\"p\">,</span>\n  <span class=\"n\">media_obj</span><span class=\"p\">,</span>\n  <span class=\"n\">encoder</span><span class=\"o\">=</span><span class=\"s1\">'display'</span><span class=\"p\">,</span>\n  <span class=\"n\">display</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'exclude'</span><span class=\"p\">:</span> <span class=\"s1\">'text/plain'</span><span class=\"p\">}</span> <span class=\"c1\"># forward to format_display_data's kwargs</span>\n<span class=\"p\">)</span>\n</pre>\n<p>Like data scraps, these can be retrieved at a later time be accessing the scrap's\n<code>display</code> attribute. Though usually one will just use Notebook's <code>reglue</code> method\n(described below).</p>\n<h3><code>read_notebook</code> reads one notebook</h3>\n<p>Reads a Notebook object loaded from the location specified at <code>path</code>.\nYou've already seen how this function is used in the above api call examples,\nbut essentially this provides a thin wrapper over an <code>nbformat</code>'s NotebookNode\nwith the ability to extract scrapbook scraps.</p>\n<pre><span class=\"n\">nb</span> <span class=\"o\">=</span> <span class=\"n\">sb</span><span class=\"o\">.</span><span class=\"n\">read_notebook</span><span class=\"p\">(</span><span class=\"s1\">'notebook.ipynb'</span><span class=\"p\">)</span>\n</pre>\n<p>This Notebook object adheres to the <a href=\"https://github.com/jupyter/nbformat/blob/master/nbformat/v4/nbformat.v4.schema.json\" rel=\"nofollow\">nbformat's json schema</a>,\nallowing for access to its required fields.</p>\n<pre><span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">cells</span> <span class=\"c1\"># The cells from the notebook</span>\n<span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">metadata</span>\n<span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">nbformat</span>\n<span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">nbformat_minor</span>\n</pre>\n<p>There's a few additional methods provided, most of which are outlined in more detail\nbelow:</p>\n<pre><span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">scraps</span>\n<span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">reglue</span>\n</pre>\n<p>The abstraction also makes saved content available as a dataframe referencing each\nkey and source. More of these methods will be made available in later versions.</p>\n<pre><span class=\"c1\"># Produces a data frame with [\"name\", \"data\", \"encoder\", \"display\", \"filename\"] as columns</span>\n<span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">scrap_dataframe</span> <span class=\"c1\"># Warning: This might be a large object if data or display is large</span>\n</pre>\n<p>The Notebook object also has a few legacy functions for backwards compatibility\nwith papermill's Notebook object model. As a result, it can be used to read\npapermill execution statistics as well as scrapbook abstractions:</p>\n<pre><span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">cell_timing</span> <span class=\"c1\"># List of cell execution timings in cell order</span>\n<span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">execution_counts</span> <span class=\"c1\"># List of cell execution counts in cell order</span>\n<span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">papermill_metrics</span> <span class=\"c1\"># Dataframe of cell execution counts and times</span>\n<span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">papermill_record_dataframe</span> <span class=\"c1\"># Dataframe of notebook records (scraps with only data)</span>\n<span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">parameter_dataframe</span> <span class=\"c1\"># Dataframe of notebook parameters</span>\n<span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">papermill_dataframe</span> <span class=\"c1\"># Dataframe of notebook parameters and cell scraps</span>\n</pre>\n<p>The notebook reader relies on <a href=\"https://papermill.readthedocs.io/en/latest/reference/papermill-io.html\" rel=\"nofollow\">papermill's registered iorw</a>\nto enable access to a variety of sources such as -- but not limited to -- S3,\nAzure, and Google Cloud.</p>\n<h3><code>scraps</code> provides a name -&gt; scrap lookup</h3>\n<p>The <code>scraps</code> method allows for access to all of the scraps in a particular notebook.</p>\n<pre><span class=\"n\">nb</span> <span class=\"o\">=</span> <span class=\"n\">sb</span><span class=\"o\">.</span><span class=\"n\">read_notebook</span><span class=\"p\">(</span><span class=\"s1\">'notebook.ipynb'</span><span class=\"p\">)</span>\n<span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">scraps</span> <span class=\"c1\"># Prints a dict of all scraps by name</span>\n</pre>\n<p>This object has a few additional methods as well for convenient conversion and\nexecution.</p>\n<pre><span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">scraps</span><span class=\"o\">.</span><span class=\"n\">data_scraps</span> <span class=\"c1\"># Filters to only scraps with `data` associated</span>\n<span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">scraps</span><span class=\"o\">.</span><span class=\"n\">data_dict</span> <span class=\"c1\"># Maps `data_scraps` to a `name` -&gt; `data` dict</span>\n<span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">scraps</span><span class=\"o\">.</span><span class=\"n\">display_scraps</span> <span class=\"c1\"># Filters to only scraps with `display` associated</span>\n<span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">scraps</span><span class=\"o\">.</span><span class=\"n\">display_dict</span> <span class=\"c1\"># Maps `display_scraps` to a `name` -&gt; `display` dict</span>\n<span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">scraps</span><span class=\"o\">.</span><span class=\"n\">dataframe</span> <span class=\"c1\"># Generates a dataframe with [\"name\", \"data\", \"encoder\", \"display\"] as columns</span>\n</pre>\n<p>These methods allow for simple use-cases to not require digging through model\nabstractions.</p>\n<h3><code>reglue</code> copys a scrap into the current notebook</h3>\n<p>Using <code>reglue</code> one can take any scrap glue'd into one notebook and glue into the\ncurrent one.</p>\n<pre><span class=\"n\">nb</span> <span class=\"o\">=</span> <span class=\"n\">sb</span><span class=\"o\">.</span><span class=\"n\">read_notebook</span><span class=\"p\">(</span><span class=\"s1\">'notebook.ipynb'</span><span class=\"p\">)</span>\n<span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">reglue</span><span class=\"p\">(</span><span class=\"s2\">\"table_scrap\"</span><span class=\"p\">)</span> <span class=\"c1\"># This copies both data and displays</span>\n</pre>\n<p>Any data or display information will be copied verbatim into the currently\nexecuting notebook as though the user called <code>glue</code> again on the original source.</p>\n<p>It's also possible to rename the scrap in the process.</p>\n<pre><span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">reglue</span><span class=\"p\">(</span><span class=\"s2\">\"table_scrap\"</span><span class=\"p\">,</span> <span class=\"s2\">\"old_table_scrap\"</span><span class=\"p\">)</span>\n</pre>\n<p>And finally if one wishes to try to reglue without checking for existence the\n<code>raise_on_missing</code> can be set to just display a message on failure.</p>\n<pre><span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">reglue</span><span class=\"p\">(</span><span class=\"s2\">\"maybe_missing\"</span><span class=\"p\">,</span> <span class=\"n\">raise_on_missing</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n<span class=\"c1\"># =&gt; \"No scrap found with name 'maybe_missing' in this notebook\"</span>\n</pre>\n<h3><code>read_notebooks</code> reads many notebooks</h3>\n<p>Reads all notebooks located in a given <code>path</code> into a Scrapbook object.</p>\n<pre><span class=\"c1\"># create a scrapbook named `book`</span>\n<span class=\"n\">book</span> <span class=\"o\">=</span> <span class=\"n\">sb</span><span class=\"o\">.</span><span class=\"n\">read_notebooks</span><span class=\"p\">(</span><span class=\"s1\">'path/to/notebook/collection/'</span><span class=\"p\">)</span>\n<span class=\"c1\"># get the underlying notebooks as a list</span>\n<span class=\"n\">book</span><span class=\"o\">.</span><span class=\"n\">notebooks</span> <span class=\"c1\"># Or `book.values`</span>\n</pre>\n<p>The path reuses <a href=\"https://papermill.readthedocs.io/en/latest/reference/papermill-io.html\" rel=\"nofollow\">papermill's registered <code>iorw</code></a>\nto list and read files form various sources, such that non-local urls can load data.</p>\n<pre><span class=\"c1\"># create a scrapbook named `book`</span>\n<span class=\"n\">book</span> <span class=\"o\">=</span> <span class=\"n\">sb</span><span class=\"o\">.</span><span class=\"n\">read_notebooks</span><span class=\"p\">(</span><span class=\"s1\">'s3://bucket/key/prefix/to/notebook/collection/'</span><span class=\"p\">)</span>\n</pre>\n<p>The Scrapbook (<code>book</code> in this example) can be used to recall all scraps across\nthe collection of notebooks:</p>\n<pre><span class=\"n\">book</span><span class=\"o\">.</span><span class=\"n\">notebook_scraps</span> <span class=\"c1\"># Dict of shape `notebook` -&gt; (`name` -&gt; `scrap`)</span>\n<span class=\"n\">book</span><span class=\"o\">.</span><span class=\"n\">scraps</span> <span class=\"c1\"># merged dict of shape `name` -&gt; `scrap`</span>\n</pre>\n<h3><code>scraps_report</code> displays a report about collected scraps</h3>\n<p>The Scrapbook collection can be used to generate a <code>scraps_report</code> on all the\nscraps from the collection as a markdown structured output.</p>\n<pre><span class=\"n\">book</span><span class=\"o\">.</span><span class=\"n\">scraps_report</span><span class=\"p\">()</span>\n</pre>\n<p>This display can filter on scrap and notebook names, as well as enable or disable\nan overall header for the display.</p>\n<pre><span class=\"n\">book</span><span class=\"o\">.</span><span class=\"n\">scraps_report</span><span class=\"p\">(</span>\n  <span class=\"n\">scrap_names</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"scrap1\"</span><span class=\"p\">,</span> <span class=\"s2\">\"scrap2\"</span><span class=\"p\">],</span>\n  <span class=\"n\">notebook_names</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"result1\"</span><span class=\"p\">],</span> <span class=\"c1\"># matches `/notebook/collections/result1.ipynb` pathed notebooks</span>\n  <span class=\"n\">header</span><span class=\"o\">=</span><span class=\"kc\">False</span>\n<span class=\"p\">)</span>\n</pre>\n<p>By default the report will only populate with visual elements. To also\nreport on data elements set include_data.</p>\n<pre><span class=\"n\">book</span><span class=\"o\">.</span><span class=\"n\">scraps_report</span><span class=\"p\">(</span><span class=\"n\">include_data</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<h3>papermill support</h3>\n<p>Finally the scrapbook provides two backwards compatible features for deprecated\n<code>papermill</code> capabilities:</p>\n<pre><span class=\"n\">book</span><span class=\"o\">.</span><span class=\"n\">papermill_dataframe</span>\n<span class=\"n\">book</span><span class=\"o\">.</span><span class=\"n\">papermill_metrics</span>\n</pre>\n<h2>Encoders</h2>\n<p>Encoders are accessible by key names to Encoder objects registered\nagainst the <code>encoders.registry</code> object. To register new data encoders\nsimply call:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">encoder</span> <span class=\"kn\">import</span> <span class=\"n\">registry</span> <span class=\"k\">as</span> <span class=\"n\">encoder_registry</span>\n<span class=\"c1\"># add encoder to the registry</span>\n<span class=\"n\">encoder_registry</span><span class=\"o\">.</span><span class=\"n\">register</span><span class=\"p\">(</span><span class=\"s2\">\"custom_encoder_name\"</span><span class=\"p\">,</span> <span class=\"n\">MyCustomEncoder</span><span class=\"p\">())</span>\n</pre>\n<p>The encode class must implement two methods, <code>encode</code> and <code>decode</code>:</p>\n<pre><span class=\"k\">class</span> <span class=\"nc\">MyCustomEncoder</span><span class=\"p\">(</span><span class=\"nb\">object</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">encode</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">scrap</span><span class=\"p\">):</span>\n        <span class=\"c1\"># scrap.data is any type, usually specific to the encoder name</span>\n        <span class=\"k\">pass</span>  <span class=\"c1\"># Return a `Scrap` with `data` type one of [None, list, dict, *six.integer_types, *six.string_types]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">decode</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">scrap</span><span class=\"p\">):</span>\n        <span class=\"c1\"># scrap.data is one of [None, list, dict, *six.integer_types, *six.string_types]</span>\n        <span class=\"k\">pass</span>  <span class=\"c1\"># Return a `Scrap` with `data` type as any type, usually specific to the encoder name</span>\n</pre>\n<p>This can read transform scraps into a json object representing their contents or\nlocation and load those strings back into the original data objects.</p>\n<h3><code>text</code></h3>\n<p>A basic string storage format that saves data as python strings.</p>\n<pre><span class=\"n\">sb</span><span class=\"o\">.</span><span class=\"n\">glue</span><span class=\"p\">(</span><span class=\"s2\">\"hello\"</span><span class=\"p\">,</span> <span class=\"s2\">\"world\"</span><span class=\"p\">,</span> <span class=\"s2\">\"text\"</span><span class=\"p\">)</span>\n</pre>\n<h3><code>json</code></h3>\n<pre><span class=\"n\">sb</span><span class=\"o\">.</span><span class=\"n\">glue</span><span class=\"p\">(</span><span class=\"s2\">\"foo_json\"</span><span class=\"p\">,</span> <span class=\"p\">{</span><span class=\"s2\">\"foo\"</span><span class=\"p\">:</span> <span class=\"s2\">\"bar\"</span><span class=\"p\">,</span> <span class=\"s2\">\"baz\"</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">},</span> <span class=\"s2\">\"json\"</span><span class=\"p\">)</span>\n</pre>\n<h3><code>arrow</code></h3>\n<p>Implementation Pending!</p>\n<h2>papermill's deprecated <code>record</code> feature</h2>\n<p><strong>scrapbook</strong> provides a robust and flexible recording schema. This library replaces <a href=\"https://papermill.readthedocs.io\" rel=\"nofollow\">papermill</a>'s existing\n<code>record</code> functionality.</p>\n<p><a href=\"https://papermill.readthedocs.io/en/latest/usage-recording.html?#recording-values-to-the-notebook\" rel=\"nofollow\">Documentation for papermill <code>record</code></a> exists on ReadTheDocs.\nIn brief, the deprecated <code>record</code> function:</p>\n<p><code>pm.record(name, value)</code>: enables values to be saved\nwith the notebook <a href=\"https://papermill.readthedocs.io/en/latest/reference/papermill.html#papermill.api.record\" rel=\"nofollow\">[API documentation]</a></p>\n<pre><span class=\"n\">pm</span><span class=\"o\">.</span><span class=\"n\">record</span><span class=\"p\">(</span><span class=\"s2\">\"hello\"</span><span class=\"p\">,</span> <span class=\"s2\">\"world\"</span><span class=\"p\">)</span>\n<span class=\"n\">pm</span><span class=\"o\">.</span><span class=\"n\">record</span><span class=\"p\">(</span><span class=\"s2\">\"number\"</span><span class=\"p\">,</span> <span class=\"mi\">123</span><span class=\"p\">)</span>\n<span class=\"n\">pm</span><span class=\"o\">.</span><span class=\"n\">record</span><span class=\"p\">(</span><span class=\"s2\">\"some_list\"</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">])</span>\n<span class=\"n\">pm</span><span class=\"o\">.</span><span class=\"n\">record</span><span class=\"p\">(</span><span class=\"s2\">\"some_dict\"</span><span class=\"p\">,</span> <span class=\"p\">{</span><span class=\"s2\">\"a\"</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"s2\">\"b\"</span><span class=\"p\">:</span> <span class=\"mi\">2</span><span class=\"p\">})</span>\n</pre>\n<p><code>pm.read_notebook(notebook)</code>: pandas could be used later to recover recorded\nvalues by reading the output notebook into a dataframe. For example:</p>\n<pre><span class=\"n\">nb</span> <span class=\"o\">=</span> <span class=\"n\">pm</span><span class=\"o\">.</span><span class=\"n\">read_notebook</span><span class=\"p\">(</span><span class=\"s1\">'notebook.ipynb'</span><span class=\"p\">)</span>\n<span class=\"n\">nb</span><span class=\"o\">.</span><span class=\"n\">dataframe</span>\n</pre>\n<h3>Rationale for Papermill <code>record</code> deprecation</h3>\n<p>Papermill's <code>record</code> function was deprecated due to these limitations and challenges:</p>\n<ul>\n<li>The <code>record</code> function didn't follow papermill's pattern of linear execution\nof a notebook. It was awkward to describe <code>record</code> as an additional\nfeature of papermill, and really felt like describing a second less\ndeveloped library.</li>\n<li>Recording / Reading required data translation to JSON for everything. This is\na tedious, painful process for dataframes.</li>\n<li>Reading recorded values into a dataframe would result in unintuitive dataframe\nshapes.</li>\n<li>Less modularity and flexiblity than other papermill components where custom\noperators can be registered.</li>\n</ul>\n<p>To overcome these limitations in Papermill, a decision was made to create\n<strong>Scrapbook</strong>.</p>\n\n          </div>"}, "last_serial": 7005682, "releases": {"0.2.0": [{"comment_text": "", "digests": {"md5": "cdb41a147a540e3f4e60c916ef5d2518", "sha256": "94f3f61fe7b295112234619c4c6c0f909dc8e5add67ea38c8876741866c83bae"}, "downloads": -1, "filename": "nteract_scrapbook-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "cdb41a147a540e3f4e60c916ef5d2518", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 31214, "upload_time": "2019-02-26T19:29:23", "upload_time_iso_8601": "2019-02-26T19:29:23.215294Z", "url": "https://files.pythonhosted.org/packages/66/9f/0ce03da20d8c687d59299c15e9a32ce85684e4d7ca4719b8329e9a622bc6/nteract_scrapbook-0.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b0eea68792a39d888a8dd75a92c64940", "sha256": "e85f300163d5fa7eb87e6bb00b6896494a33ccc44b37f3b92179aae56cd1ed19"}, "downloads": -1, "filename": "nteract-scrapbook-0.2.0.tar.gz", "has_sig": false, "md5_digest": "b0eea68792a39d888a8dd75a92c64940", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 124707, "upload_time": "2019-02-26T19:29:25", "upload_time_iso_8601": "2019-02-26T19:29:25.593818Z", "url": "https://files.pythonhosted.org/packages/66/85/3f26d39362f0a0b24f1a2983785f4563a6a499ea18f840dda93069311f84/nteract-scrapbook-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "e30d5d14def0f72dd9d29743666b052a", "sha256": "32b6b13817ae442eec50922d1b94c7637d0f58777dbf2447d61b8292d840c858"}, "downloads": -1, "filename": "nteract_scrapbook-0.2.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e30d5d14def0f72dd9d29743666b052a", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 35205, "upload_time": "2019-05-01T02:20:14", "upload_time_iso_8601": "2019-05-01T02:20:14.539142Z", "url": "https://files.pythonhosted.org/packages/d0/f2/ed95d0909cdd6b8318eb3b0f77ab446b0e99b47b638228001b78820a9271/nteract_scrapbook-0.2.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "58e41c5bad3223228c2fef64da2d871e", "sha256": "4f14ac2460bbb0f6787faa88726ad65031879be595a0e757d68e8b77e93dc93f"}, "downloads": -1, "filename": "nteract-scrapbook-0.2.1.tar.gz", "has_sig": false, "md5_digest": "58e41c5bad3223228c2fef64da2d871e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 127660, "upload_time": "2019-05-01T02:20:17", "upload_time_iso_8601": "2019-05-01T02:20:17.578966Z", "url": "https://files.pythonhosted.org/packages/01/36/0d69368d9a41d72e6af2a25462ac00529fedfee083eeaac8ece6bfe87307/nteract-scrapbook-0.2.1.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "ac651a041c708fbdd53a8bd744563757", "sha256": "9b9573b6c456dde64d5713d1776012181cf4942c96d77b0f8fc175dd5517e98f"}, "downloads": -1, "filename": "nteract_scrapbook-0.3.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "ac651a041c708fbdd53a8bd744563757", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 37484, "upload_time": "2019-08-19T21:33:38", "upload_time_iso_8601": "2019-08-19T21:33:38.212351Z", "url": "https://files.pythonhosted.org/packages/53/b8/9beda12875f4bcc44be2a602a9add699428d543bd04bdab3f13578e27935/nteract_scrapbook-0.3.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e3332ef079e9e96f9e1afc65a6df70c4", "sha256": "e8b053dfee8db3871a79408a68a04c696b39cd606bd5382c9f464b4ed840ee5e"}, "downloads": -1, "filename": "nteract-scrapbook-0.3.0.tar.gz", "has_sig": false, "md5_digest": "e3332ef079e9e96f9e1afc65a6df70c4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 132871, "upload_time": "2019-08-19T21:33:40", "upload_time_iso_8601": "2019-08-19T21:33:40.281174Z", "url": "https://files.pythonhosted.org/packages/67/dd/d7cc6468ff4b1875a397f66f280bdfb2ae942f699f7466069658d240ccaa/nteract-scrapbook-0.3.0.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "8a8f292b4424117f280be066aad17af5", "sha256": "0eb83afe0c45d7444681ae3ea5366493d61a95a61fea584b7814114f44891b69"}, "downloads": -1, "filename": "nteract_scrapbook-0.3.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "8a8f292b4424117f280be066aad17af5", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 37482, "upload_time": "2019-08-22T21:03:43", "upload_time_iso_8601": "2019-08-22T21:03:43.636652Z", "url": "https://files.pythonhosted.org/packages/1a/85/05460941cf6f07bce751b566f93c7f90d169681826109915c513c07289f5/nteract_scrapbook-0.3.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b489c42a55c3da3c35578b600da4a25e", "sha256": "6607dd3ec4a078d640167752b0bf5b49bbfe6d4f4e60fe17e8339bc8a7878ec8"}, "downloads": -1, "filename": "nteract-scrapbook-0.3.1.tar.gz", "has_sig": false, "md5_digest": "b489c42a55c3da3c35578b600da4a25e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 132901, "upload_time": "2019-08-22T21:03:45", "upload_time_iso_8601": "2019-08-22T21:03:45.735382Z", "url": "https://files.pythonhosted.org/packages/c8/16/8e203190cb24a2d81256f66a6fbaeba33decd9f2174453b5d29772bd05fa/nteract-scrapbook-0.3.1.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "fe4cdf11244cfb1025457ad6e787fdbf", "sha256": "8b60d20b3a0f8358a36332cb49d513ba81b8d0cc32be83b139e4dc6f88524817"}, "downloads": -1, "filename": "nteract_scrapbook-0.4.0-py3-none-any.whl", "has_sig": false, "md5_digest": "fe4cdf11244cfb1025457ad6e787fdbf", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 265480, "upload_time": "2020-04-12T18:15:14", "upload_time_iso_8601": "2020-04-12T18:15:14.699297Z", "url": "https://files.pythonhosted.org/packages/f3/ed/e29aee664cb3715f8e31cfb0fd0190bbbde643a086ff7b3d9d6e23a20031/nteract_scrapbook-0.4.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a3416a19d8c5bded19d0b8cbdc6b7ddf", "sha256": "0f78452033c9542c084ede75c9844423ff272cec37511bbf22228c1b29084032"}, "downloads": -1, "filename": "nteract-scrapbook-0.4.0.tar.gz", "has_sig": false, "md5_digest": "a3416a19d8c5bded19d0b8cbdc6b7ddf", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 363822, "upload_time": "2020-04-12T18:15:16", "upload_time_iso_8601": "2020-04-12T18:15:16.709254Z", "url": "https://files.pythonhosted.org/packages/0a/f0/3ba55ac4a4e7991db974a6a390dbaa62a409a5c9a942d5c46a4ffee8df8a/nteract-scrapbook-0.4.0.tar.gz", "yanked": false}], "0.4.1": [{"comment_text": "", "digests": {"md5": "3999d806e42b24b49071425ca7e92126", "sha256": "4b283d0c09c87ca60391f679203acadb25999c006beb2997dd74902d4f363776"}, "downloads": -1, "filename": "nteract_scrapbook-0.4.1-py3-none-any.whl", "has_sig": false, "md5_digest": "3999d806e42b24b49071425ca7e92126", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 265493, "upload_time": "2020-04-12T18:22:50", "upload_time_iso_8601": "2020-04-12T18:22:50.986540Z", "url": "https://files.pythonhosted.org/packages/2d/06/c026c536ee7f671540836ba44e686edfbb1d50981db774fd16d336515664/nteract_scrapbook-0.4.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "48764d7eaadcd4321ab1b9854f782fa9", "sha256": "27dfad870797e6b49152b49cacc55869349e259097568732f273d8703bae91fe"}, "downloads": -1, "filename": "nteract-scrapbook-0.4.1.tar.gz", "has_sig": false, "md5_digest": "48764d7eaadcd4321ab1b9854f782fa9", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 363873, "upload_time": "2020-04-12T18:22:53", "upload_time_iso_8601": "2020-04-12T18:22:53.249214Z", "url": "https://files.pythonhosted.org/packages/10/d9/c24fb571519ac753977bf20493a2f7ab03cea863574cd7a9a8e52c178154/nteract-scrapbook-0.4.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "3999d806e42b24b49071425ca7e92126", "sha256": "4b283d0c09c87ca60391f679203acadb25999c006beb2997dd74902d4f363776"}, "downloads": -1, "filename": "nteract_scrapbook-0.4.1-py3-none-any.whl", "has_sig": false, "md5_digest": "3999d806e42b24b49071425ca7e92126", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 265493, "upload_time": "2020-04-12T18:22:50", "upload_time_iso_8601": "2020-04-12T18:22:50.986540Z", "url": "https://files.pythonhosted.org/packages/2d/06/c026c536ee7f671540836ba44e686edfbb1d50981db774fd16d336515664/nteract_scrapbook-0.4.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "48764d7eaadcd4321ab1b9854f782fa9", "sha256": "27dfad870797e6b49152b49cacc55869349e259097568732f273d8703bae91fe"}, "downloads": -1, "filename": "nteract-scrapbook-0.4.1.tar.gz", "has_sig": false, "md5_digest": "48764d7eaadcd4321ab1b9854f782fa9", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 363873, "upload_time": "2020-04-12T18:22:53", "upload_time_iso_8601": "2020-04-12T18:22:53.249214Z", "url": "https://files.pythonhosted.org/packages/10/d9/c24fb571519ac753977bf20493a2f7ab03cea863574cd7a9a8e52c178154/nteract-scrapbook-0.4.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:44:22 2020"}