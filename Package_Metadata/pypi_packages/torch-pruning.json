{"info": {"author": "Gongfan Fang", "author_email": "fgf@zju.edu.cn", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# Torch-Pruning\n\nA pytorch toolkit for neural network pruning and layer dependency maintaining.\n\nTorch-Pruning is dedicated to automatically detecting and maintaining the layer dependencies for structured pruning and providing reusable implementations. You can pay more attention to the design of pruning algorithms with the help of the dependency management.\n\nThis toolkit has the following features:\n\n* Basic pruning functions for Convolutional Neural Networks\n* Layer dependency management\n* Dependency customization for complex modules\n\n## Installation\n\n```bash\npip install torch_pruning\n```\n\n## Layer Dependency\n\n### A Simple Dependency\n\n<img src=\"examples/images/dep1.png\" width=\"80%\">\n\n### More Complicated Cases\n\nthe layer dependency becomes much more complicated when the model contains skip connections or concatenations. \n\n#### Residual Block: \n<img src=\"examples/images/dep2.png\" width=\"80%\">\n\n#### Concatenation: \n<img src=\"examples/images/dep3.png\" width=\"80%\">\n\nSee paper [Pruning Filters for Efficient ConvNets](https://arxiv.org/abs/1608.08710) for more details.\n\n## How does it works\n\nTorch-Pruning provide a `DependencyGraph` to detect and manage the dependencies between layers. \nIt requires a fake input to run the model and collect layer infomation from the dynamic computational graph.\n`DependencyGraph.get_pruning_plan` will detect the broken dependencies according to your pruning operation, and prepare a executable `PruningPlan` which contains all the required pruning operations. \n\n## Quickstart\n\n### Pruning with DependencyGraph \n\n```python\nimport torch\nfrom torchvision.models import resnet18\nimport torch_pruning as pruning\nmodel = resnet18(pretrained=True)\n# build layer dependency for resnet18\nDG = pruning.DependencyGraph( model, fake_input=torch.randn(1,3,224,224) )\n# get a pruning plan according to the dependency graph. idxs is the indices of pruned filters.\npruning_plan = DG.get_pruning_plan( model.conv1, pruning.prune_conv, idxs=[2, 6, 9] )\nprint(pruning_plan)\n# execute this plan (prune the model)\npruning_plan.exec()\n```\n\nPruning the resnet.conv1 will affect several modules. The pruning plan:\n\n```\n[ prune_conv on conv1 (Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)), Indexs=[2, 6, 9], NumPruned=441]\n[ prune_batchnorm on bn1 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), Indexs=[2, 6, 9], NumPruned=6]\n[ _prune_elementwise_op on elementwise (_ElementWiseOp()), Indexs=[2, 6, 9], NumPruned=0]\n[ _prune_elementwise_op on elementwise (_ElementWiseOp()), Indexs=[2, 6, 9], NumPruned=0]\n[ prune_related_conv on layer2.0.conv1 (Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)), Indexs=[2, 6, 9], NumPruned=3456]\n[ prune_batchnorm on layer1.1.bn2 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), Indexs=[2, 6, 9], NumPruned=6]\n[ prune_conv on layer1.1.conv2 (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), Indexs=[2, 6, 9], NumPruned=1728]\n[ prune_related_conv on layer2.0.downsample.0 (Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)), Indexs=[2, 6, 9], NumPruned=384]\n[ prune_related_conv on layer1.1.conv1 (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), Indexs=[2, 6, 9], NumPruned=1728]\n[ prune_batchnorm on layer1.0.bn2 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), Indexs=[2, 6, 9], NumPruned=6]\n[ prune_conv on layer1.0.conv2 (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), Indexs=[2, 6, 9], NumPruned=1728]\n[ prune_related_conv on layer1.0.conv1 (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), Indexs=[2, 6, 9], NumPruned=1728]\n11211 parameters will be pruned\n-------------\n```\n\n### Pruning with low-level functions\n\nWithout DependencyGraph, you need to manually handle the broken dependencies between layers. \nSee [examples/example_pruning_fn.py](https://github.com/VainF/Torch-Pruning/blob/master/examples/example_pruning_fn.py) for more details about pruning functions.\n\n```python\npruning.prune_conv( model.conv1, idxs=[2,6,9] )\n\n# fix the broken dependencies\npruning.prune_batchnorm( model.bn1, idxs=[2,6,9] )\npruning.prune_related_conv( model.layer2[0].conv1, idxs=[2,6,9] )\n...\n```\n\n## Example: ResNet18 on Cifar10\n\n### 1. Train the model\n```bash\ncd examples\npython prune_resnet18.py --mode train # 11.1M, Acc=0.9248\n```\n\n### 2. Pruning and fintuning\n```bash\npython prune_resnet18.py --mode prune --round 1 --total_epochs 30 --step_size 20 # 4.5M, Acc=0.9229\npython prune_resnet18.py --mode prune --round 2 --total_epochs 30 --step_size 20 # 1.9M, Acc=0.9207\npython prune_resnet18.py --mode prune --round 3 --total_epochs 30 --step_size 20 # 0.8M, Acc=0.9176\npython prune_resnet18.py --mode prune --round 4 --total_epochs 30 --step_size 20 # 0.4M, Acc=0.9102\npython prune_resnet18.py --mode prune --round 5 --total_epochs 30 --step_size 20 # 0.2M, Acc=0.9011\n...\n```\n\n# TODO\n\n* Documents\n* Predefined pruning algorithms\n* Test the toolkit with Densenet / MobileNet / ...\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/VainF/Torch-Pruning", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "torch-pruning", "package_url": "https://pypi.org/project/torch-pruning/", "platform": "", "project_url": "https://pypi.org/project/torch-pruning/", "project_urls": {"Homepage": "https://github.com/VainF/Torch-Pruning"}, "release_url": "https://pypi.org/project/torch-pruning/0.1.5/", "requires_dist": ["torch"], "requires_python": ">=3.6", "summary": "A pytorch toolkit for structured neural network pruning and layer dependency maintaining.", "version": "0.1.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Torch-Pruning</h1>\n<p>A pytorch toolkit for neural network pruning and layer dependency maintaining.</p>\n<p>Torch-Pruning is dedicated to automatically detecting and maintaining the layer dependencies for structured pruning and providing reusable implementations. You can pay more attention to the design of pruning algorithms with the help of the dependency management.</p>\n<p>This toolkit has the following features:</p>\n<ul>\n<li>Basic pruning functions for Convolutional Neural Networks</li>\n<li>Layer dependency management</li>\n<li>Dependency customization for complex modules</li>\n</ul>\n<h2>Installation</h2>\n<pre>pip install torch_pruning\n</pre>\n<h2>Layer Dependency</h2>\n<h3>A Simple Dependency</h3>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e6db9ce3287685da051eb3ef53b67e77f3a83bbc/6578616d706c65732f696d616765732f646570312e706e67\" width=\"80%\">\n<h3>More Complicated Cases</h3>\n<p>the layer dependency becomes much more complicated when the model contains skip connections or concatenations.</p>\n<h4>Residual Block:</h4>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/50b746e5c088da3e59d774cc3987c5ac02e0d963/6578616d706c65732f696d616765732f646570322e706e67\" width=\"80%\">\n<h4>Concatenation:</h4>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0490da24198f71bd49fd10f3cc7ca58c6c219d81/6578616d706c65732f696d616765732f646570332e706e67\" width=\"80%\">\n<p>See paper <a href=\"https://arxiv.org/abs/1608.08710\" rel=\"nofollow\">Pruning Filters for Efficient ConvNets</a> for more details.</p>\n<h2>How does it works</h2>\n<p>Torch-Pruning provide a <code>DependencyGraph</code> to detect and manage the dependencies between layers.\nIt requires a fake input to run the model and collect layer infomation from the dynamic computational graph.\n<code>DependencyGraph.get_pruning_plan</code> will detect the broken dependencies according to your pruning operation, and prepare a executable <code>PruningPlan</code> which contains all the required pruning operations.</p>\n<h2>Quickstart</h2>\n<h3>Pruning with DependencyGraph</h3>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchvision.models</span> <span class=\"kn\">import</span> <span class=\"n\">resnet18</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch_pruning</span> <span class=\"k\">as</span> <span class=\"nn\">pruning</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">resnet18</span><span class=\"p\">(</span><span class=\"n\">pretrained</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"c1\"># build layer dependency for resnet18</span>\n<span class=\"n\">DG</span> <span class=\"o\">=</span> <span class=\"n\">pruning</span><span class=\"o\">.</span><span class=\"n\">DependencyGraph</span><span class=\"p\">(</span> <span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">fake_input</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">224</span><span class=\"p\">,</span><span class=\"mi\">224</span><span class=\"p\">)</span> <span class=\"p\">)</span>\n<span class=\"c1\"># get a pruning plan according to the dependency graph. idxs is the indices of pruned filters.</span>\n<span class=\"n\">pruning_plan</span> <span class=\"o\">=</span> <span class=\"n\">DG</span><span class=\"o\">.</span><span class=\"n\">get_pruning_plan</span><span class=\"p\">(</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">conv1</span><span class=\"p\">,</span> <span class=\"n\">pruning</span><span class=\"o\">.</span><span class=\"n\">prune_conv</span><span class=\"p\">,</span> <span class=\"n\">idxs</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">6</span><span class=\"p\">,</span> <span class=\"mi\">9</span><span class=\"p\">]</span> <span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">pruning_plan</span><span class=\"p\">)</span>\n<span class=\"c1\"># execute this plan (prune the model)</span>\n<span class=\"n\">pruning_plan</span><span class=\"o\">.</span><span class=\"n\">exec</span><span class=\"p\">()</span>\n</pre>\n<p>Pruning the resnet.conv1 will affect several modules. The pruning plan:</p>\n<pre><code>[ prune_conv on conv1 (Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)), Indexs=[2, 6, 9], NumPruned=441]\n[ prune_batchnorm on bn1 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), Indexs=[2, 6, 9], NumPruned=6]\n[ _prune_elementwise_op on elementwise (_ElementWiseOp()), Indexs=[2, 6, 9], NumPruned=0]\n[ _prune_elementwise_op on elementwise (_ElementWiseOp()), Indexs=[2, 6, 9], NumPruned=0]\n[ prune_related_conv on layer2.0.conv1 (Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)), Indexs=[2, 6, 9], NumPruned=3456]\n[ prune_batchnorm on layer1.1.bn2 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), Indexs=[2, 6, 9], NumPruned=6]\n[ prune_conv on layer1.1.conv2 (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), Indexs=[2, 6, 9], NumPruned=1728]\n[ prune_related_conv on layer2.0.downsample.0 (Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)), Indexs=[2, 6, 9], NumPruned=384]\n[ prune_related_conv on layer1.1.conv1 (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), Indexs=[2, 6, 9], NumPruned=1728]\n[ prune_batchnorm on layer1.0.bn2 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), Indexs=[2, 6, 9], NumPruned=6]\n[ prune_conv on layer1.0.conv2 (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), Indexs=[2, 6, 9], NumPruned=1728]\n[ prune_related_conv on layer1.0.conv1 (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), Indexs=[2, 6, 9], NumPruned=1728]\n11211 parameters will be pruned\n-------------\n</code></pre>\n<h3>Pruning with low-level functions</h3>\n<p>Without DependencyGraph, you need to manually handle the broken dependencies between layers.\nSee <a href=\"https://github.com/VainF/Torch-Pruning/blob/master/examples/example_pruning_fn.py\" rel=\"nofollow\">examples/example_pruning_fn.py</a> for more details about pruning functions.</p>\n<pre><span class=\"n\">pruning</span><span class=\"o\">.</span><span class=\"n\">prune_conv</span><span class=\"p\">(</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">conv1</span><span class=\"p\">,</span> <span class=\"n\">idxs</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">9</span><span class=\"p\">]</span> <span class=\"p\">)</span>\n\n<span class=\"c1\"># fix the broken dependencies</span>\n<span class=\"n\">pruning</span><span class=\"o\">.</span><span class=\"n\">prune_batchnorm</span><span class=\"p\">(</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">bn1</span><span class=\"p\">,</span> <span class=\"n\">idxs</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">9</span><span class=\"p\">]</span> <span class=\"p\">)</span>\n<span class=\"n\">pruning</span><span class=\"o\">.</span><span class=\"n\">prune_related_conv</span><span class=\"p\">(</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">layer2</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">conv1</span><span class=\"p\">,</span> <span class=\"n\">idxs</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">9</span><span class=\"p\">]</span> <span class=\"p\">)</span>\n<span class=\"o\">...</span>\n</pre>\n<h2>Example: ResNet18 on Cifar10</h2>\n<h3>1. Train the model</h3>\n<pre><span class=\"nb\">cd</span> examples\npython prune_resnet18.py --mode train <span class=\"c1\"># 11.1M, Acc=0.9248</span>\n</pre>\n<h3>2. Pruning and fintuning</h3>\n<pre>python prune_resnet18.py --mode prune --round <span class=\"m\">1</span> --total_epochs <span class=\"m\">30</span> --step_size <span class=\"m\">20</span> <span class=\"c1\"># 4.5M, Acc=0.9229</span>\npython prune_resnet18.py --mode prune --round <span class=\"m\">2</span> --total_epochs <span class=\"m\">30</span> --step_size <span class=\"m\">20</span> <span class=\"c1\"># 1.9M, Acc=0.9207</span>\npython prune_resnet18.py --mode prune --round <span class=\"m\">3</span> --total_epochs <span class=\"m\">30</span> --step_size <span class=\"m\">20</span> <span class=\"c1\"># 0.8M, Acc=0.9176</span>\npython prune_resnet18.py --mode prune --round <span class=\"m\">4</span> --total_epochs <span class=\"m\">30</span> --step_size <span class=\"m\">20</span> <span class=\"c1\"># 0.4M, Acc=0.9102</span>\npython prune_resnet18.py --mode prune --round <span class=\"m\">5</span> --total_epochs <span class=\"m\">30</span> --step_size <span class=\"m\">20</span> <span class=\"c1\"># 0.2M, Acc=0.9011</span>\n...\n</pre>\n<h1>TODO</h1>\n<ul>\n<li>Documents</li>\n<li>Predefined pruning algorithms</li>\n<li>Test the toolkit with Densenet / MobileNet / ...</li>\n</ul>\n\n          </div>"}, "last_serial": 6783709, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "37e723c96c5fcc2a29b20b33536f8d71", "sha256": "abd5929597dd7de6130509e39f8d2c61f4b962a2e9f480436dd94ed7cfddf72c"}, "downloads": -1, "filename": "torch_pruning-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "37e723c96c5fcc2a29b20b33536f8d71", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 9442, "upload_time": "2019-12-16T01:59:09", "upload_time_iso_8601": "2019-12-16T01:59:09.180258Z", "url": "https://files.pythonhosted.org/packages/b8/92/e61c81160b0bc54f489ec2f9b5bedc106160c7c9b9c16a4e5c39bcab6235/torch_pruning-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "70b0f8d012e3814ebd65302edf65e9c9", "sha256": "a51d9452cbaaa92b9af3b33af89e9099ff02cb121ae069a503118f3590cf2e4d"}, "downloads": -1, "filename": "torch_pruning-0.1.0.tar.gz", "has_sig": false, "md5_digest": "70b0f8d012e3814ebd65302edf65e9c9", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 9881, "upload_time": "2019-12-16T01:59:12", "upload_time_iso_8601": "2019-12-16T01:59:12.129698Z", "url": "https://files.pythonhosted.org/packages/4e/29/3239710a0915cc1f393f9d0c684404b713a4dff9bf08bbd83ae1778abc4f/torch_pruning-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "1f2b37045532950e50eb5c6159ce499e", "sha256": "60e4aa1b8a85398a11f2ce598dc0a9967907705e558cb6b00a3ffadd0a72db77"}, "downloads": -1, "filename": "torch_pruning-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "1f2b37045532950e50eb5c6159ce499e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 10312, "upload_time": "2019-12-17T08:35:12", "upload_time_iso_8601": "2019-12-17T08:35:12.341340Z", "url": "https://files.pythonhosted.org/packages/94/9e/3d95c4e8fe0eb4b87dc8b2755eba03453b4605e3e64ee07ecf7352e118f8/torch_pruning-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f30038301af7552a31fccbfb07506e65", "sha256": "89057a93a5d2711d4814047b4c9cd1e3f94023f416de28870691afb5972cdd8d"}, "downloads": -1, "filename": "torch_pruning-0.1.1.tar.gz", "has_sig": false, "md5_digest": "f30038301af7552a31fccbfb07506e65", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 9990, "upload_time": "2019-12-17T08:35:14", "upload_time_iso_8601": "2019-12-17T08:35:14.975378Z", "url": "https://files.pythonhosted.org/packages/c7/1a/fdc90be2040bae84a02ab29fae9dc9a12130fc744f10bb722d2d0f904db7/torch_pruning-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "bcb8ebe067f123ec77467c182a1d459f", "sha256": "8a3b92ced2af1990157d3c6a9f574e11d78a167798435cbc87c6fc6082c96c8c"}, "downloads": -1, "filename": "torch_pruning-0.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "bcb8ebe067f123ec77467c182a1d459f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 10229, "upload_time": "2019-12-18T05:46:08", "upload_time_iso_8601": "2019-12-18T05:46:08.059100Z", "url": "https://files.pythonhosted.org/packages/13/57/bdbf242e2140dab6c77e0d891065eaea2b610b1cdc11a996918d6009d835/torch_pruning-0.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "726df0cfb537a852ec1473cade296011", "sha256": "9b92b9583062565ab9fad91a68fa8b98806256f5bbe230214325bf32a86fcf99"}, "downloads": -1, "filename": "torch-pruning-0.1.2.tar.gz", "has_sig": false, "md5_digest": "726df0cfb537a852ec1473cade296011", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 9906, "upload_time": "2019-12-18T05:46:15", "upload_time_iso_8601": "2019-12-18T05:46:15.909140Z", "url": "https://files.pythonhosted.org/packages/d5/67/6c12d8b50c77b88b06215a0741a903d7d0316c0d09acc6039d418abf7f3a/torch-pruning-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "72718e0efe5f5a87cb6f9ad3df510e2f", "sha256": "c76372b52de828ea60fa7fe4d28ce031b56dcc687b67a176f876cb180a6ae150"}, "downloads": -1, "filename": "torch_pruning-0.1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "72718e0efe5f5a87cb6f9ad3df510e2f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 10228, "upload_time": "2019-12-18T05:49:15", "upload_time_iso_8601": "2019-12-18T05:49:15.204739Z", "url": "https://files.pythonhosted.org/packages/2c/a6/8ee16c61980b3199f9e39f6c10d9276fcdc18e3feaf9fb8c657e71d865c6/torch_pruning-0.1.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "81f0e885b5e67e7f5bb98784c06f93df", "sha256": "ca74e439d33ef8d3185bdb906b11f2ab7f8a4889d5c55e19d71c342d56c87f7d"}, "downloads": -1, "filename": "torch-pruning-0.1.3.tar.gz", "has_sig": false, "md5_digest": "81f0e885b5e67e7f5bb98784c06f93df", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 9908, "upload_time": "2019-12-18T05:49:16", "upload_time_iso_8601": "2019-12-18T05:49:16.790780Z", "url": "https://files.pythonhosted.org/packages/e2/95/9e46ceaded4cf1db5dfe2b2d63876b3358f8e8c6f4fe89157878c5c38e5e/torch-pruning-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "28f6827a688f287259c496712aae0786", "sha256": "398fb43405309760175a3c254a0ea8c648c0d90cd2f7dce23b3fcd9bf9fdd49f"}, "downloads": -1, "filename": "torch_pruning-0.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "28f6827a688f287259c496712aae0786", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 10196, "upload_time": "2020-01-09T01:49:59", "upload_time_iso_8601": "2020-01-09T01:49:59.733113Z", "url": "https://files.pythonhosted.org/packages/dc/ca/781cf89094b2eccbde32652bca0d2b0674ee995ff8c3037ac46c7cdecceb/torch_pruning-0.1.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "343fe716a7f34e57990141ec1977d67e", "sha256": "617ebee24b975e90ffd32adeca3a0d85dcc13ac2314ac4292015c1a8bada1a03"}, "downloads": -1, "filename": "torch-pruning-0.1.4.tar.gz", "has_sig": false, "md5_digest": "343fe716a7f34e57990141ec1977d67e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 9841, "upload_time": "2020-01-09T01:50:01", "upload_time_iso_8601": "2020-01-09T01:50:01.978379Z", "url": "https://files.pythonhosted.org/packages/40/6a/b56b95eb6e14389dccae81e6421d4e986c474f59f6e55b3f4354eb9c7737/torch-pruning-0.1.4.tar.gz", "yanked": false}], "0.1.5": [{"comment_text": "", "digests": {"md5": "9732e2f252c77b57c1bfaf4fa67915f6", "sha256": "acf15ddce3fde923e747ad79c0dbcf9fa000df78b9cdd1adbe0c91c1fcda9039"}, "downloads": -1, "filename": "torch_pruning-0.1.5-py3-none-any.whl", "has_sig": false, "md5_digest": "9732e2f252c77b57c1bfaf4fa67915f6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 10210, "upload_time": "2020-03-10T08:52:19", "upload_time_iso_8601": "2020-03-10T08:52:19.176227Z", "url": "https://files.pythonhosted.org/packages/4f/0e/b436a03f48434235d6aebd1eed8848741ef69a89fac449bbf3fcf8af155f/torch_pruning-0.1.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1d676f55066429a314efe961adc16e04", "sha256": "636be65aeb5c3efaaf5dc59d87892357642972c5ac11202b4a625b8ed5c63dfb"}, "downloads": -1, "filename": "torch-pruning-0.1.5.tar.gz", "has_sig": false, "md5_digest": "1d676f55066429a314efe961adc16e04", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 9873, "upload_time": "2020-03-10T08:52:21", "upload_time_iso_8601": "2020-03-10T08:52:21.279042Z", "url": "https://files.pythonhosted.org/packages/fc/f2/fdd01060df80e5b79291b58ea5f07f3e5eabc960696ae2ed7dd1d5cd8a2f/torch-pruning-0.1.5.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "9732e2f252c77b57c1bfaf4fa67915f6", "sha256": "acf15ddce3fde923e747ad79c0dbcf9fa000df78b9cdd1adbe0c91c1fcda9039"}, "downloads": -1, "filename": "torch_pruning-0.1.5-py3-none-any.whl", "has_sig": false, "md5_digest": "9732e2f252c77b57c1bfaf4fa67915f6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 10210, "upload_time": "2020-03-10T08:52:19", "upload_time_iso_8601": "2020-03-10T08:52:19.176227Z", "url": "https://files.pythonhosted.org/packages/4f/0e/b436a03f48434235d6aebd1eed8848741ef69a89fac449bbf3fcf8af155f/torch_pruning-0.1.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1d676f55066429a314efe961adc16e04", "sha256": "636be65aeb5c3efaaf5dc59d87892357642972c5ac11202b4a625b8ed5c63dfb"}, "downloads": -1, "filename": "torch-pruning-0.1.5.tar.gz", "has_sig": false, "md5_digest": "1d676f55066429a314efe961adc16e04", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 9873, "upload_time": "2020-03-10T08:52:21", "upload_time_iso_8601": "2020-03-10T08:52:21.279042Z", "url": "https://files.pythonhosted.org/packages/fc/f2/fdd01060df80e5b79291b58ea5f07f3e5eabc960696ae2ed7dd1d5cd8a2f/torch-pruning-0.1.5.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:50:13 2020"}