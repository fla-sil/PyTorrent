{"info": {"author": "Olivier Jolly", "author_email": "olivier@pcedev.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Environment :: Console", "Intended Audience :: Developers", "Intended Audience :: End Users/Desktop", "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)", "Operating System :: OS Independent", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.2", "Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Topic :: Multimedia :: Sound/Audio", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "audio-display\n=============\n\n**audio-display** is a set of utility aimed at rendering images based on audio input.\nIt aims at generating images to produce visual \"companion\" to audio files. Typically to create\na video clip supporting a musical composition.\n\n\nfft2png\n-------\n\n**fft2png** is a command line utility to create a set of image files representing audio spectrum from a wav file.\nIt is an offline version of a spectrum analyser output and is not totally dissimilar to `Sonic Candle`_.\n\nGenerated files can be imported and postprocessed in any video edition tool accepting a set of images as input.\nJust make sure that the framerate used during the call to **fft2png** matches the framerate at which you consume\nimages in your video edition software. Libre software able to consume and use those images includes, but aren't\nlimited to, Natron_.\n\nYou can also use FFmpeg_ for either previewing quickly or for simple needs (just the spectrum over a fixed image\nor a video. Some samples of `ffmpeg usage`_ can be found later.\n\n\nUsage\n.....\n\n    usage: fft2png [-h] [-d] [-n] [-r TARGET_FPS] [-R {0,1,2,3}] [-v]\n                   [-w BAR_WIDTH] [-s BAR_SPACING] [-c BAR_COUNT] [-C COLOR]\n                   [-b BLENDING] [-W FFT_WINDOW] [--image-height IMAGE_HEIGHT]\n                   [--audio-min-freq AUDIO_MIN_FREQ]\n                   [--audio-max-freq AUDIO_MAX_FREQ]\n                   [--silence-ceiling SILENCE_CEILING] [-i INPUT_FILENAME] -o\n                   OUTPUT_FILENAME_MASK\n\n    GPL v3+ 2015 Olivier Jolly\n\n    optional arguments:\n      -h, --help            show this help message and exit\n      -d, --debug           debug operations [default: False]\n      -n                    don't perform actions [default: False]\n      -r TARGET_FPS, --framerate TARGET_FPS\n                            output framerate [default: 30]\n\n      -R {0,1,2,3}, --renderer {0,1,2,3}\n                            which renderer to use to display bars (0=filled, 1=hollow, 2=symetrical filled, 3=symetrical hollow)\n\n      -v, --version         show program's version number and exit\n      -w BAR_WIDTH, --bar-width BAR_WIDTH\n                            bar width in output images\n      -s BAR_SPACING, --bar-spacing BAR_SPACING\n                            bar spacing in output images\n      -c BAR_COUNT, --bar-count BAR_COUNT\n                            number of bars in output images\n      -C COLOR, --color COLOR\n                            hexa color of bars [RRGGBB or RRGGBBAA, default: FFFFFFFF]\n      -b BLENDING, --blending BLENDING\n                            blending of previous spectrum into current one (0 =\n                            display only fresh data, 1 = use as many previous than\n                            fresh data)\n      -W FFT_WINDOW, --window FFT_WINDOW\n                            window size for FFT [default: 4096]\n      --image-height IMAGE_HEIGHT\n                            output images height\n      --audio-min-freq AUDIO_MIN_FREQ\n                            min frequency in input audio\n      --audio-max-freq AUDIO_MAX_FREQ\n                            max frequency in input audio\n      --silence-ceiling SILENCE_CEILING\n                            opposite of threshold considered silence [in dB,\n                            default: 70]\n      -i INPUT_FILENAME     input file in wav format\n      -o OUTPUT_FILENAME_MASK\n                            output filename mask (should contain {:06} or similar\n                            to generate sequence)\n\n    Convert audio file to stack of images\n\n**-r**\n  Framerate of the generated images. Should match the framerate at which they will be consumed.\n  Higher framerate gives a smoother result.\n\n**-R**\n  Aspect of the bar representing power for one frequency. 0 uses filled boxes, 1 uses hollow boxes,\n  2 uses filled boxes vertically centered and 3 uses hollow boxes vertically centered.\n\n**-w**\n  Width (in pixel) per bar.\n\n**-s**\n  Spacing (in pixel) between bars.\n\n**-c**\n  Number of bars per images.\n\n**-C**\n  Color of the bars in hexa. Can be RGB or RGBA. For instance, FF0000 will render pure opaque red bars,\n  00FF0080 will render 50% transparent pure green bars, ...\n\n**-b**\n  Blending ratio from previous frame into current one. When set to 0, only fresh data will be used to\n  render bars. When set to 1, bars will be rendered from an average of the fresh and previous frame data.\n  Intermediate values will inject a fraction of the previous frame data into the current one for rendering.\n  Lower values tends to render more reactive spectrum while higher ones will smooth data over time and react slower.\n\n**-W**\n  Spectrum generation window is the amount of data in the audio file used to determine the spectrum raw data.\n  Lower value will make spectrum blockier but will be slightly faster to generate.\n\nExample\n.......\n\nTo use default values when generating spectrum, just invoke::\n\n    fft2png -i input.wav -o output-{:06}.png\n\n`result of default fft2png settings`_\n\nFor a slightly different result, you can invoke it like this::\n\n    fft2png -R2 -w4 -s4 -c30 -C FF8080A0 --audio-min-freq 100 -i input.wav -o output-{:06}.png\n\nYou'll end up with 30 symetrical transparent redish solid bars 4 pixels wide, spaced by 4 pixels\n\n`result of red solid symetrical bars ff2png settings`_\n\n****\n\nFFMpeg usage\n............\n\n.. _ffmpeg usage:\n\nIf you already have a video as background and want to add spectrogram center on it while adding some musique, you can\ninvoke ffmpeg like this::\n\n    ffmpeg -i <background_video.mp4> -framerate <generated frames framerate> -i <audio-00%4d.png> -filter_complex \"overlay=(main_w-overlay_w)/2:(main_h-overlay_h)/2:shortest=1\" -i <music.wav> -map 2:0 -vframes <number of generated frames> -strict -2 <output.mp4> -y\n\nwhere :\n  * <background_video.mp4> is the filename of your background video\n  * <generated frames framerate> is the framerate used when generating spectrogram frames\n  * <audio-00%4d.png> is the mask of the generated frames to overlay\n  * <music.wav> is the filename of the your music\n  * <number of generated frames> is, well, the number of generated spectrogram frames\n  * <output.mp4> is the generated muxed video\n\nA few notes :\n  * you can change the overlay position by setting the position in absolute coordinates or using some maths with main_w, main_h, overlay_w, overlay_h as show here\n  * **-y** is for overwriting the result file\n  * **-strict -2** alleviates some error with aac encoding on my version/system combo\n  * the background video will not loop. As for now (ffmpeg 3.0.1), looping is not for video. If your video is too short, prepare one which is long enough by concatenating it several times. The **shortest=1** in the filter expression will  stop whenever an input stream (background video, spectrogram images or music) reaches its end.\n  * use the ffmpeg manual, Luke\n\nIf you want to use a static image as background, the invocation becomes something like::\n\n    ffmpeg -loop 1 -i <background_image.jpg> -framerate <generated frames framerate> -i <audio-00%4d.png> -filter_complex \"overlay=(main_w-overlay_w)/2:(main_h-overlay_h)/2:shortest=1\" -i <music.wav> -map 2:0 -vframes <number of generated frames> -strict -2 <output.mp4> -y\n\nThe main difference being the **-loop 1** to loop the background image over and over until one of the other\nstream ends.\n\nInstallation\n------------\n\n**audio-display** is installable from PyPI with a single pip command::\n\n    pip install audio-display\n\nAlternatively, **audio-display** can be run directly from sources after a git pull (recommended if you want to tweak\nor read the source)::\n\n    git clone https://gitlab.com/zeograd/audio-display.git\n    cd audio-display && python setup.py install\n\nor directly from its git repository::\n\n    pip install git+https://gitlab.com/zeograd/audio-display.git\n\n.. _Sonic Candle: http://soniccandle.sourceforge.net/\n.. _Natron: http://natron.fr\n.. _FFmpeg: http://ffmpeg.org\n.. _result of default fft2png settings: https://i.imgur.com/hrc0YRv\n.. _result of red solid symetrical bars ff2png settings: https://imgur.com/e0hy5qG", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://gitlab.com/zeograd/audio-display", "keywords": "audio display spectrum", "license": "GPLv3+", "maintainer": null, "maintainer_email": null, "name": "audio_display", "package_url": "https://pypi.org/project/audio_display/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/audio_display/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://gitlab.com/zeograd/audio-display"}, "release_url": "https://pypi.org/project/audio_display/0.1.0/", "requires_dist": null, "requires_python": null, "summary": "Generate image stack representing audio", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><strong>audio-display</strong> is a set of utility aimed at rendering images based on audio input.\nIt aims at generating images to produce visual \u201ccompanion\u201d to audio files. Typically to create\na video clip supporting a musical composition.</p>\n<div id=\"fft2png\">\n<h2>fft2png</h2>\n<p><strong>fft2png</strong> is a command line utility to create a set of image files representing audio spectrum from a wav file.\nIt is an offline version of a spectrum analyser output and is not totally dissimilar to <a href=\"http://soniccandle.sourceforge.net/\" rel=\"nofollow\">Sonic Candle</a>.</p>\n<p>Generated files can be imported and postprocessed in any video edition tool accepting a set of images as input.\nJust make sure that the framerate used during the call to <strong>fft2png</strong> matches the framerate at which you consume\nimages in your video edition software. Libre software able to consume and use those images includes, but aren\u2019t\nlimited to, <a href=\"http://natron.fr\" rel=\"nofollow\">Natron</a>.</p>\n<p>You can also use <a href=\"http://ffmpeg.org\" rel=\"nofollow\">FFmpeg</a> for either previewing quickly or for simple needs (just the spectrum over a fixed image\nor a video. Some samples of <a href=\"#id1\" rel=\"nofollow\">ffmpeg usage</a> can be found later.</p>\n<div id=\"usage\">\n<h3>Usage</h3>\n<blockquote>\n<dl>\n<dt>usage: fft2png [-h] [-d] [-n] [-r TARGET_FPS] [-R {0,1,2,3}] [-v]</dt>\n<dd>[-w BAR_WIDTH] [-s BAR_SPACING] [-c BAR_COUNT] [-C COLOR]\n[-b BLENDING] [-W FFT_WINDOW] [\u2013image-height IMAGE_HEIGHT]\n[\u2013audio-min-freq AUDIO_MIN_FREQ]\n[\u2013audio-max-freq AUDIO_MAX_FREQ]\n[\u2013silence-ceiling SILENCE_CEILING] [-i INPUT_FILENAME] -o\nOUTPUT_FILENAME_MASK</dd>\n</dl>\n<p>GPL v3+ 2015 Olivier Jolly</p>\n<dl>\n<dt>optional arguments:</dt>\n<dd><table>\n<col>\n<col>\n<tbody>\n<tr><td>\n<kbd><span class=\"option\">-h</span>, <span class=\"option\">--help</span></kbd></td>\n<td>show this help message and exit</td></tr>\n<tr><td>\n<kbd><span class=\"option\">-d</span>, <span class=\"option\">--debug</span></kbd></td>\n<td>debug operations [default: False]</td></tr>\n<tr><td>\n<kbd><span class=\"option\">-n</span></kbd></td>\n<td>don\u2019t perform actions [default: False]</td></tr>\n<tr><td>\n<kbd><span class=\"option\">-r <var>TARGET_FPS</var></span>, <span class=\"option\">--framerate <var>TARGET_FPS</var></span></kbd></td>\n</tr>\n<tr><td>\u00a0</td><td>output framerate [default: 30]</td></tr>\n</tbody>\n</table>\n<dl>\n<dt>-R {0,1,2,3}, \u2013renderer {0,1,2,3}</dt>\n<dd>which renderer to use to display bars (0=filled, 1=hollow, 2=symetrical filled, 3=symetrical hollow)</dd>\n</dl>\n<table>\n<col>\n<col>\n<tbody>\n<tr><td>\n<kbd><span class=\"option\">-v</span>, <span class=\"option\">--version</span></kbd></td>\n<td>show program\u2019s version number and exit</td></tr>\n<tr><td>\n<kbd><span class=\"option\">-w <var>BAR_WIDTH</var></span>, <span class=\"option\">--bar-width <var>BAR_WIDTH</var></span></kbd></td>\n</tr>\n<tr><td>\u00a0</td><td>bar width in output images</td></tr>\n<tr><td>\n<kbd><span class=\"option\">-s <var>BAR_SPACING</var></span>, <span class=\"option\">--bar-spacing <var>BAR_SPACING</var></span></kbd></td>\n</tr>\n<tr><td>\u00a0</td><td>bar spacing in output images</td></tr>\n<tr><td>\n<kbd><span class=\"option\">-c <var>BAR_COUNT</var></span>, <span class=\"option\">--bar-count <var>BAR_COUNT</var></span></kbd></td>\n</tr>\n<tr><td>\u00a0</td><td>number of bars in output images</td></tr>\n<tr><td>\n<kbd><span class=\"option\">-C <var>COLOR</var></span>, <span class=\"option\">--color <var>COLOR</var></span></kbd></td>\n</tr>\n<tr><td>\u00a0</td><td>hexa color of bars [RRGGBB or RRGGBBAA, default: FFFFFFFF]</td></tr>\n<tr><td>\n<kbd><span class=\"option\">-b <var>BLENDING</var></span>, <span class=\"option\">--blending <var>BLENDING</var></span></kbd></td>\n</tr>\n<tr><td>\u00a0</td><td>blending of previous spectrum into current one (0 =\ndisplay only fresh data, 1 = use as many previous than\nfresh data)</td></tr>\n<tr><td>\n<kbd><span class=\"option\">-W <var>FFT_WINDOW</var></span>, <span class=\"option\">--window <var>FFT_WINDOW</var></span></kbd></td>\n</tr>\n<tr><td>\u00a0</td><td>window size for FFT [default: 4096]</td></tr>\n<tr><td>\n<kbd><span class=\"option\">--image-height <var>IMAGE_HEIGHT</var></span></kbd></td>\n</tr>\n<tr><td>\u00a0</td><td>output images height</td></tr>\n<tr><td>\n<kbd><span class=\"option\">--audio-min-freq <var>AUDIO_MIN_FREQ</var></span></kbd></td>\n</tr>\n<tr><td>\u00a0</td><td>min frequency in input audio</td></tr>\n<tr><td>\n<kbd><span class=\"option\">--audio-max-freq <var>AUDIO_MAX_FREQ</var></span></kbd></td>\n</tr>\n<tr><td>\u00a0</td><td>max frequency in input audio</td></tr>\n<tr><td>\n<kbd><span class=\"option\">--silence-ceiling <var>SILENCE_CEILING</var></span></kbd></td>\n</tr>\n<tr><td>\u00a0</td><td>opposite of threshold considered silence [in dB,\ndefault: 70]</td></tr>\n<tr><td>\n<kbd><span class=\"option\">-i <var>INPUT_FILENAME</var></span></kbd></td>\n</tr>\n<tr><td>\u00a0</td><td>input file in wav format</td></tr>\n<tr><td>\n<kbd><span class=\"option\">-o <var>OUTPUT_FILENAME_MASK</var></span></kbd></td>\n</tr>\n<tr><td>\u00a0</td><td>output filename mask (should contain {:06} or similar\nto generate sequence)</td></tr>\n</tbody>\n</table>\n</dd>\n</dl>\n<p>Convert audio file to stack of images</p>\n</blockquote>\n<dl>\n<dt><strong>-r</strong></dt>\n<dd>Framerate of the generated images. Should match the framerate at which they will be consumed.\nHigher framerate gives a smoother result.</dd>\n<dt><strong>-R</strong></dt>\n<dd>Aspect of the bar representing power for one frequency. 0 uses filled boxes, 1 uses hollow boxes,\n2 uses filled boxes vertically centered and 3 uses hollow boxes vertically centered.</dd>\n<dt><strong>-w</strong></dt>\n<dd>Width (in pixel) per bar.</dd>\n<dt><strong>-s</strong></dt>\n<dd>Spacing (in pixel) between bars.</dd>\n<dt><strong>-c</strong></dt>\n<dd>Number of bars per images.</dd>\n<dt><strong>-C</strong></dt>\n<dd>Color of the bars in hexa. Can be RGB or RGBA. For instance, FF0000 will render pure opaque red bars,\n00FF0080 will render 50% transparent pure green bars, \u2026</dd>\n<dt><strong>-b</strong></dt>\n<dd>Blending ratio from previous frame into current one. When set to 0, only fresh data will be used to\nrender bars. When set to 1, bars will be rendered from an average of the fresh and previous frame data.\nIntermediate values will inject a fraction of the previous frame data into the current one for rendering.\nLower values tends to render more reactive spectrum while higher ones will smooth data over time and react slower.</dd>\n<dt><strong>-W</strong></dt>\n<dd>Spectrum generation window is the amount of data in the audio file used to determine the spectrum raw data.\nLower value will make spectrum blockier but will be slightly faster to generate.</dd>\n</dl>\n</div>\n<div id=\"example\">\n<h3>Example</h3>\n<p>To use default values when generating spectrum, just invoke:</p>\n<pre>fft2png -i input.wav -o output-{:06}.png\n</pre>\n<p><a href=\"https://i.imgur.com/hrc0YRv\" rel=\"nofollow\">result of default fft2png settings</a></p>\n<p>For a slightly different result, you can invoke it like this:</p>\n<pre>fft2png -R2 -w4 -s4 -c30 -C FF8080A0 --audio-min-freq 100 -i input.wav -o output-{:06}.png\n</pre>\n<p>You\u2019ll end up with 30 symetrical transparent redish solid bars 4 pixels wide, spaced by 4 pixels</p>\n<p><a href=\"https://imgur.com/e0hy5qG\" rel=\"nofollow\">result of red solid symetrical bars ff2png settings</a></p>\n</div>\n<hr class=\"docutils\">\n<div id=\"ffmpeg-usage\">\n<h3>FFMpeg usage</h3>\n<p id=\"id1\">If you already have a video as background and want to add spectrogram center on it while adding some musique, you can\ninvoke ffmpeg like this:</p>\n<pre>ffmpeg -i &lt;background_video.mp4&gt; -framerate &lt;generated frames framerate&gt; -i &lt;audio-00%4d.png&gt; -filter_complex \"overlay=(main_w-overlay_w)/2:(main_h-overlay_h)/2:shortest=1\" -i &lt;music.wav&gt; -map 2:0 -vframes &lt;number of generated frames&gt; -strict -2 &lt;output.mp4&gt; -y\n</pre>\n<dl>\n<dt>where :</dt>\n<dd><ul>\n<li>&lt;background_video.mp4&gt; is the filename of your background video</li>\n<li>&lt;generated frames framerate&gt; is the framerate used when generating spectrogram frames</li>\n<li>&lt;audio-00%4d.png&gt; is the mask of the generated frames to overlay</li>\n<li>&lt;music.wav&gt; is the filename of the your music</li>\n<li>&lt;number of generated frames&gt; is, well, the number of generated spectrogram frames</li>\n<li>&lt;output.mp4&gt; is the generated muxed video</li>\n</ul>\n</dd>\n<dt>A few notes :</dt>\n<dd><ul>\n<li>you can change the overlay position by setting the position in absolute coordinates or using some maths with main_w, main_h, overlay_w, overlay_h as show here</li>\n<li><strong>-y</strong> is for overwriting the result file</li>\n<li><strong>-strict -2</strong> alleviates some error with aac encoding on my version/system combo</li>\n<li>the background video will not loop. As for now (ffmpeg 3.0.1), looping is not for video. If your video is too short, prepare one which is long enough by concatenating it several times. The <strong>shortest=1</strong> in the filter expression will  stop whenever an input stream (background video, spectrogram images or music) reaches its end.</li>\n<li>use the ffmpeg manual, Luke</li>\n</ul>\n</dd>\n</dl>\n<p>If you want to use a static image as background, the invocation becomes something like:</p>\n<pre>ffmpeg -loop 1 -i &lt;background_image.jpg&gt; -framerate &lt;generated frames framerate&gt; -i &lt;audio-00%4d.png&gt; -filter_complex \"overlay=(main_w-overlay_w)/2:(main_h-overlay_h)/2:shortest=1\" -i &lt;music.wav&gt; -map 2:0 -vframes &lt;number of generated frames&gt; -strict -2 &lt;output.mp4&gt; -y\n</pre>\n<p>The main difference being the <strong>-loop 1</strong> to loop the background image over and over until one of the other\nstream ends.</p>\n</div>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p><strong>audio-display</strong> is installable from PyPI with a single pip command:</p>\n<pre>pip install audio-display\n</pre>\n<p>Alternatively, <strong>audio-display</strong> can be run directly from sources after a git pull (recommended if you want to tweak\nor read the source):</p>\n<pre>git clone https://gitlab.com/zeograd/audio-display.git\ncd audio-display &amp;&amp; python setup.py install\n</pre>\n<p>or directly from its git repository:</p>\n<pre>pip install git+https://gitlab.com/zeograd/audio-display.git\n</pre>\n</div>\n\n          </div>"}, "last_serial": 2127137, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "c8c18a37152fa7cf9a2590bf0088f3ef", "sha256": "d772077728578f439844835185f5f1b7988222b6d50b8ac85cf1612812c83d47"}, "downloads": -1, "filename": "audio_display-0.1.0.tar.gz", "has_sig": true, "md5_digest": "c8c18a37152fa7cf9a2590bf0088f3ef", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12007, "upload_time": "2016-05-21T23:08:38", "upload_time_iso_8601": "2016-05-21T23:08:38.386598Z", "url": "https://files.pythonhosted.org/packages/46/d7/18ad259405f030ccc4ea4fb9b0983e53dc76077204301b90a02dd525ec1b/audio_display-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "c8c18a37152fa7cf9a2590bf0088f3ef", "sha256": "d772077728578f439844835185f5f1b7988222b6d50b8ac85cf1612812c83d47"}, "downloads": -1, "filename": "audio_display-0.1.0.tar.gz", "has_sig": true, "md5_digest": "c8c18a37152fa7cf9a2590bf0088f3ef", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12007, "upload_time": "2016-05-21T23:08:38", "upload_time_iso_8601": "2016-05-21T23:08:38.386598Z", "url": "https://files.pythonhosted.org/packages/46/d7/18ad259405f030ccc4ea4fb9b0983e53dc76077204301b90a02dd525ec1b/audio_display-0.1.0.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:16:28 2020"}