{"info": {"author": "Ozan \u00d6zg\u00fcr", "author_email": "ozan.zgur@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "License :: OSI Approved :: GNU General Public License v3 (GPLv3)", "Operating System :: OS Independent", "Programming Language :: Python :: 3", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "# mlpl\n\nA machine learning pipeline to speed up data science lifecycle.\n\nUsing this library, you can:\n- Test new experiments easily and keep track of their results.\n- Keep details of each preprocessing/FE step easily accessible in collapsibles.\n- Do hyperparameter search. (Bayesian search, quick linear search)\n- Create a pipeline that consists of useful steps and save/load it.\n- Automatically try different processing steps and use useful ones. (imputations, binning, one-hot encoding, ...)\n- Make your predictions more reliable by averaging results obtained from different CV splits and random seeds.\n\n#### Install:\n```\npip install mlpl\n```\n\n### Start a new pipeline\n***\nA pipeline consists of  a class and its config and log files.\nA pipeline will save your baseline model and the data after the baseline.\nFor trying new steps, it will load the data from its last state.\nIt will also automatically compare results of new steps to that of the baseline.\nAfter each useful step, final form of the dataset and hparams will be saved.\n\n**Hyperparameter search**\nPipeline will conduct bayesian/random search for the baseline.\nFor new steps after that, a simple hyperparameter search will take place.\n\n(The reason for that is you cannot conduct a bayesian search for each experiment.\nHowever, adding a new step will usually change the ideal hyperparameters, so\ndoing some hyperparameter search is required. Approach in this project is to conduct a bayesian search for the baseline, which will take a lot of time. For testing new steps, a custom simple hyperparameter search method will be used.)\n\n**create new pipeline:\n[(example: Titanic competition from Kaggle)](https://www.kaggle.com/c/titanic/overview \"(example: Titanic competition from Kaggle)\")**\n```python\nlabel_name = 'Survived'\ntrn_path = 'data/train.csv'\ntest_path = 'data/test.csv'\n\n# Pipeline class will keep track of your processed files, model metrics and experiments. \nlr_pipeline = pipe.Pipeline(label_name = label_name,\n                               overwrite = True,\n                               project_path = 'lr_pipeline',\n                               train_data_path = trn_path,\n                               test_data_path = test_path,\n                               minimize_metric = False,\n                               useful_limit = 0.001,\n                               line_search_iter = 1,\n                               n_random_seeds = 1,\n                               bayesian_search_iter= 50,\n                               bayesian_search_count = 1,\n                               final_bayesian_search_iter = 0,\n                               line_search_patience = 2,\n                               line_search_params = {'C': (1e-7, 1e3)})\n```\n\n\n### Hyperparameter search using hyperopt\n***\n- Specify hyperameter search space for each model.\n\nSearch is conducted on parameters in search space.\nFixed parameters are parameters that define the model.\n\nThis is an example for logistic regression.\n**fixed parameters:**\n```python\nfixed_params_lr = dict(score=accuracy_score,\n                       model=sklearn.linear_model.LogisticRegression,                       \n                       max_iter=5000,\n                       verbose = 0,\n                       n_jobs = 3,\n                       model_type = 'linear',\n                       folds=[KFold(n_splits= 5, shuffle = True, random_state = 42),\n                                  KFold(n_splits= 5, shuffle = True, random_state = 13),\n                                  KFold(n_splits= 5, shuffle = True, random_state = 100)])\n```\n**search space:**\n```python\nlr_search_space = dict(C = hp.loguniform('C', -7, 3),\n                       class_weight =  hp.choice('class_weight', ['balanced', None]),\n                       solver =  hp.choice('solver ', ['lbfgs', 'sag']))\n```\n**Averaging results over different splits**\n***\nBy  specifying multiple sklearn folds objects, average predictions over different splits.\n(Also available for random_state parameters for models.)\n\n```python\n    folds=[KFold(n_splits= 5, shuffle = True, random_state = 42),\n                 KFold(n_splits= 5, shuffle = True, random_state = 13),\n                 KFold(n_splits= 5, shuffle = True, random_state = 100)]\n```\n\n**Creating a baseline model**\n***\nA baseline step is a step with minimal processing. Preprocessing steps and feature engineering steps in the project will be tested against the metrics of baseline model.\n\n**create the baseline step:**\n```python\nlr_pipeline.set_baseline_step(model = pmodels.train_sklearn_pipeline,\n                                proc = pdefaults.default_sklearn_preprocess,\n                                search_model_params= lr_search_space,\n                                fixed_model_params = fixed_params_lr\n                               )\n```\n\n### Run baseline step\n***\n```python\nres = lr_pipeline.run_baseline(return_result = True)\n```\n- Output contains a javascript that hides details about the step in collapsible boxes.\n**output:**\n![baseline1](https://user-images.githubusercontent.com/40238324/69920598-f53a9e00-149a-11ea-9fed-45c60fb11b84.PNG)\n\n***\n\n![baseline2](https://user-images.githubusercontent.com/40238324/69920654-7c881180-149b-11ea-8168-3a07f9d28a04.PNG)\n\n***\n\n![baseline3](https://user-images.githubusercontent.com/40238324/69920657-89a50080-149b-11ea-9712-703a5c536042.PNG)\n\n### Create submission and save pipeline\n***\n**create submission:**\n```python\n# Convert test_preds to int from probabilities\n\n# Since this competition requires values to be 0 or 1,\n# We have to adjust a decision threshold. While selecting this threshold,\n# criteria is to make mean(label) equal to mean(predictions)\n# This step is not necessary in most projects\ntest_preds = (res['test_preds'] > 0.55).astype('int')\n\n# Prepare submission file\nto_sub = sub.copy()\nto_sub[label_name] = test_preds\nto_sub.to_csv('titanic_sub.csv', index = False)\ntest_preds.mean()\n\n# Baseline LB score: 0.76555\n```\n**save pipeline:**\n```python\nlr_pipeline.save_project()\n```\n\n### Experiments:\n***\nNew steps should be tried in a separate notebook. First, load the previously saved pipeline.\n```python\nlr_pipeline = pipe.Pipeline(project_path = 'lr_pipeline')\n```\nThen, create a function to create a kaggle submission for this competition.\nThis is not a part of the library.\n```python\n# Convert to (1,0) from probabilities\ndef make_submission(res, thresh):\n    test_preds = (res['test_preds'] > thresh).astype('int')\n\n    # Print mean to adjust threshold\n    print(test_preds.mean())\n\n    # Save submission\n    sub = pd.read_csv(r'data/gender_submission.csv')\n    to_sub = sub.copy()\n    to_sub[lr_pipeline.label_name] = test_preds\n    to_sub.to_csv('titanic_sub.csv', index = False)\n```\nThen we will try default steps for preprocessing and imputation.\n#### Default steps that will be tried:\nFor nominals, features with missing values are imputed in 3 different ways. These are:\n(Baseline model imputes with the most frequent value.)\n- Separate category (-9999)\n- Impute by dependent\n    (If missing values depend on another feature, this method will be useful.)\n\nOther default steps for nominals is to:\n- One-hot encode if specified\n- Group values with value_count < limit (default for limit is 10.)\n\nFor numeric steps, features with missing values are imputed in 3 different ways. These are:\n- Mean impute\n- Impute by dependent\n- Impute with fixed value (-9999)\n\nOther steps:\nBinning (if specified), One-hot encoding for binned features (if specified.)\nOne-hot encoding (if specified.)\n\n#### Standardization\nWhen we were creating a baseline step, we used argument\n```python\nmodel = pmodels.train_sklearn_pipeline\n```\npmodels.train_sklearn_pipeline standardizes all features if model_type = 'linear'.\n\n#### Sparse data\nCategoricals that were OHEd and numerics  that were binned and OHEd are kept in sparse form.\n\n#### Access current form of data\nYou can get the dataset from pipeline using,\n```python\ntrain, test = mypipeline.load_files()\n```\ntrain and test are DataTable instances, which are stored in pickles.\nDataTable is a class created to keep dataframes and sparse matrices together.\nWhen a column from a DataTable is OHEd, it is converted to a sparse matrix and added to the DataTable. Then, features can be accessed in the same way as in pandas. \n\n**try nominal steps:**\n```python\nsteps.try_default_nominal_steps(lr_pipeline,\n                                ohe = True,\n                                group_outliers = True,\n                                ohe_max_unique = 5000)\n```\n**try numeric steps:**\n```python\nsteps.try_default_numeric_steps(lr_pipeline,\n                                ohe = True,\n                                binning = True)\n```\n\n**Example output for nominals:**\n![steps1](https://user-images.githubusercontent.com/40238324/70061444-54142a80-15f5-11ea-9d64-7fdd80c8e5a6.PNG)\n***\n![steps2](https://user-images.githubusercontent.com/40238324/70061477-61c9b000-15f5-11ea-9fb9-9e7cbf256391.PNG)\n***\n![steps3](https://user-images.githubusercontent.com/40238324/70061511-71e18f80-15f5-11ea-825f-67c58b70a27c.PNG)\n\nSteps of each step can be also viewed.\n\n### Test after default steps\n***\n```python\n# When model is not specified, it is the baseline model\nlr_pipeline.add_model('lr')\nres = lr_pipeline.run_model('lr',\n                            hyperparam_search = False,\n                            return_pred = True,\n                            use_final_params = True)\n```\n```python\nmake_submission(res, 0.675)\n```\n### Try custom steps\n***\nIn order to try new steps, write your own function with the following arguments and outputs:\n```python\ndef my_step(feature_properties, train, test, label_name, MYARG1, MYARG2, ...):\n\t# first 4 features are obligatory, but you can add other arguments.\n\t# Arguments other than the first 4 must be provided to add_step function in\n\t# parameter proc_params as a dictionary\n\n\t# Preprocessing, FE, ... (Mutate train, test)\n\n\treturn cols_not_to_model, train, test\n```\n**another example:**\n```python\ndef my_step(feature_properties, train, test, label_name):\n\n\t# Add a new column to train, test\n\ttrain['mycol'] = train['a'] + train['b']\n\ttest['mycol'] = test['a'] + test['b']\n\n\t # Add absolute value of a\n\tfor df in [train, test]:\n\t\tdf['abs_a'] = df['a'].abs()\n\n\t# We don't want 'a' to be used in training. If it will be used in future, don't drop 'a'.\n\t# Instead, add it to cols_not_to_model. \n\t# If all columns will be used, place [ ] in cols_not_to_model.\n\tcols_not_to_model = ['a']\n\n\treturn cols_not_to_model, train, test\n```\n\n**example from titanic:**\n```python\n# Extract title from Name\n\ndef add_title(feature_properties, train, test, label_name):\n    # From: https://www.kaggle.com/kpacocha/top-5-titanic-machine-learning-from-disaster\n    def fe_title(df, col):\n        title_col = df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n        title_col = np.where((title_col=='Capt') | (title_col=='Countess')\n                           | (title_col=='Don') | (title_col=='Dona')\n                           | (title_col=='Jonkheer') | (title_col=='Lady')\n                           | (title_col=='Sir') | (title_col=='Major')\n                           | (title_col=='Rev') | (title_col=='Col'),\n                           'Other',title_col)\n\n        title_col = pd.Series(title_col)\n        title_col = title_col.replace('Ms','Miss')\n        title_col = title_col.replace('Mlle','Miss')\n        title_col = title_col.replace('Mme','Mrs')\n        return title_col\n\n    # utils.utilize is a python decorator that transforms a function from:\n    # - takes dataframe, column name as input, returns pd.Series\n    # to:\n    # - takes multiple dataframes, can return a pd.Series, can add new column to\n    #   dataframes with a new name or replaces the original.\n    #   This behavior is controlled by 'mode' argument.\n    #  mode:\n    #  - 'add': add resulting column to the dataframe with a generated name\n    #  - 'replace': replace original column. \n    #  - 'return' : return pd.Series for each df.\n    #  \n    # utilize also has join_dfs argument (default=True)\n    # if join_dfs = True, operation is carried out after concatenating the column\n    # from dataframes.\n\n    # Process name, append result to train and test.\n    utils.utilize(mode = 'add')(fe_title)([train, test], 'Name')\n\n    # This is the name of the added column.\n    # Names are generated by utilize using this template:\n    #     '{function_name}_{col}'\n    #\n    # (This is if col is a single string. It can be a list)\n\n    new_name = 'fe_title_Name'\n\n    # Label encode new column and replace it.\n    utils.utilize(mode = 'replace')(prep.label_encode)([train, test], new_name)\n\n    # One hot encode new column\n    train, test = prep.one_hot_encode([train, test], col = new_name, sparse = True)\n    return [], train, test\n```\n#### Try a new step:\n```python\nres = lr_pipeline.add_step_apply_if_useful(proc = add_title)\n```\n**output: (details can be viewed by clicking on add_title)**\n![steps4](https://user-images.githubusercontent.com/40238324/70067928-1ff23700-1600-11ea-90e7-decad7b72cb9.PNG)\n\n**create a kaggle submission:**\n```python\nmake_submission(res, 0.7335)\n```\n\n#### Try mutually exclusive steps:\nSome steps are mutually excusive, which means that you will only apply one of them,\neven if more than one is useful. For example, different methods of imputations are mutually exclusive.\n\n<details>\n<summary>Code</summary>\n\n```python\ndef add_prefix(feature_properties, train, test, label_name, col_name):\n    def prefix(df, col):\n        def get_prefix(x):\n            x = str(x)\n            if len(x) == 1:\n                return x\n            else:\n                return x.split(' ')[0][0]\n        return df[col].apply(lambda x: get_prefix(x))\n\n    utils.utilize(mode = 'add')(prefix)([train, test], col_name)\n    new_name = f'prefix_{col_name}'\n    utils.utilize(mode = 'replace')(prep.label_encode)([train, test], new_name)\n    train, test = prep.one_hot_encode([train, test],\n                                      col = new_name,\n                                      mode = 'replace')\n    return [], train, test\n\ndef add_prefix_group_outliers(\n        feature_properties, train, test,\n        label_name, col_name, limit = 10):\n    @utils.utilize(mode = 'add')\n    def prefix(df, col):\n        def get_prefix(x):\n            x = str(x)\n            if len(x) == 1:\n                return x\n            else:\n                return x.split(' ')[0][0]\n        return df[col].apply(lambda x: get_prefix(x))\n\n    prefix([train, test], col_name)\n    new_name = f'prefix_{col_name}'\n    utils.utilize(mode = 'replace')(prep.label_encode)([train, test], new_name)\n    prep.group_outliers_replace([train, test], new_name, limit = limit)\n    train, test = prep.one_hot_encode([train, test],\n                                      col = new_name,\n                                      mode = 'add')\n\n    # Don't drop the original column, but don't use it in training\n    return [col_name], train, test\n\nlr_pipeline.add_step(proc = add_prefix,\n                     group = 'prefix_ticket',\n                     proc_params= {'col_name': 'Ticket'})\n\nlr_pipeline.add_step(proc = add_prefix_group_outliers,\n                     group = 'prefix_ticket',\n                     proc_params= {'col_name': 'Ticket'})\n\nres = lr_pipeline.group_apply_useful('prefix_ticket')\n```\n</details>\n\n**output:**\n![steps5](https://user-images.githubusercontent.com/40238324/70068419-043b6080-1601-11ea-969b-d6340d949ed5.PNG)\n\nNo need to generate a submission for this one, as nothing was changed in the data.\n\n### Train other models (or train from scratch using bayesian search)\n***\nTrain baseline model. (using hparams determined in line search)\n(Training baseline is necessary only if you will stack/blend)\n\n**train baseline:**\n```python\n# When model is not specified, it is the baseline model\nlr_pipeline.add_model('lr')\nres = lr_pipeline.run_model('lr',\n                            hyperparam_search = False,\n                            return_pred = True,\n                            use_final_params = True)\n```\n**output:**\n![models1](https://user-images.githubusercontent.com/40238324/70069132-55981f80-1602-11ea-8545-6e36bae1c840.PNG)\n***\n**train svm:**\nfixed_hparams and search_hparams can be used in other projects as they are.\n(I will add them to the library soon.)\n```python\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\n\nfixed_hparams = dict(model = SVC,\n                     probability = True,\n                     random_state = 42,\n                     score = accuracy_score,\n                     max_iter = 2000,\n                     folds=[KFold(n_splits= 5, shuffle = True, random_state = 42),\n                              KFold(n_splits= 5, shuffle = True, random_state = 13),\n                              KFold(n_splits= 5, shuffle = True, random_state = 100)\n                              ])\n\n\nsearch_hparams = dict(C = hp.loguniform('C', -3, 7),\n                      gamma = hp.loguniform('gamma', -3, 3),\n                      class_weight =  hp.choice('class_weight', ['balanced', None]),\n                      kernel = hp.choice('kernel', ['linear', 'rbf', 'poly'])\n                      )\n\nlr_pipeline.add_model('svc',\n                      model = pmodels.train_sklearn_pipeline,\n                      fixed_hparams = fixed_hparams,\n                      search_hparams = search_hparams)\n\nres = lr_pipeline.run_model('svc', return_pred = True, hyperparam_search = True)\n```\n**create submission:**\nYou should test each model before stacking/blending.\n```python\nmake_submission(res, 0.675)\n```\n***\n**train kneighbors:**\n```python\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfixed_hparams = dict(model = KNeighborsClassifier,\n                     folds = lr_pipeline.baseline_step['model_params']['folds'],\n                     score = accuracy_score)\n\n\nsearch_hparams = dict(n_neighbors  = hp.choice('n_neighbors', np.arange(4,25)),\n                      leaf_size = hp.choice('leaf_size', np.arange(15,50)))\n\nlr_pipeline.add_model('kn',\n                      model = pmodels.train_sklearn_pipeline,\n                      fixed_hparams = fixed_hparams,\n                      search_hparams = search_hparams)\n\nres = lr_pipeline.run_model('kn', hyperparam_search = True)\n```\n**output:**\n![steps6](https://user-images.githubusercontent.com/40238324/70069483-e53dce00-1602-11ea-82c1-634115cab3df.PNG)\n\n**create submission:**\n```python\nmake_submission(res, 0.675)\n```\n\n***\n### Blending\n(Stacking will be also available.)\n\n**blend predictions in a directory:**\n```python\nres = {}\nres['test_preds'] = putils.blend_from_csv(directory = lr_pipeline.test_preds_path)\n```\n**create submission:**\n```python\nmake_submission(res, 0.7)\n```\n\n**save project:**\n```python\nlr_pipeline.save_project()\n```\n\n### Note:\nIdeally, you should place each new experiment/step in a new notebook and save project after each useful step. In Titanic example, baseline is in its own notebook, but following steps are in a second one, to keep the example simpler.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/ozanzgur/mlpl", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "mlpl", "package_url": "https://pypi.org/project/mlpl/", "platform": "", "project_url": "https://pypi.org/project/mlpl/", "project_urls": {"Homepage": "https://github.com/ozanzgur/mlpl"}, "release_url": "https://pypi.org/project/mlpl/0.1.1/", "requires_dist": ["dill (>=0.3.1.1)", "hyperopt (>=0.2.2)", "ipython (>=7.7.0)", "jupyter (>=1.0.0)", "pandas (>=0.25.1)", "scikit-learn (>=0.21.2)", "scipy (>=1.3.0)", "tqdm (>=4.36.1)", "lightgbm (>=2.2.3)", "json5 (>=0.8.5)"], "requires_python": "", "summary": "A data science pipeline tool to speed up data science life cycle.", "version": "0.1.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>mlpl</h1>\n<p>A machine learning pipeline to speed up data science lifecycle.</p>\n<p>Using this library, you can:</p>\n<ul>\n<li>Test new experiments easily and keep track of their results.</li>\n<li>Keep details of each preprocessing/FE step easily accessible in collapsibles.</li>\n<li>Do hyperparameter search. (Bayesian search, quick linear search)</li>\n<li>Create a pipeline that consists of useful steps and save/load it.</li>\n<li>Automatically try different processing steps and use useful ones. (imputations, binning, one-hot encoding, ...)</li>\n<li>Make your predictions more reliable by averaging results obtained from different CV splits and random seeds.</li>\n</ul>\n<h4>Install:</h4>\n<pre><code>pip install mlpl\n</code></pre>\n<h3>Start a new pipeline</h3>\n<hr>\n<p>A pipeline consists of  a class and its config and log files.\nA pipeline will save your baseline model and the data after the baseline.\nFor trying new steps, it will load the data from its last state.\nIt will also automatically compare results of new steps to that of the baseline.\nAfter each useful step, final form of the dataset and hparams will be saved.</p>\n<p><strong>Hyperparameter search</strong>\nPipeline will conduct bayesian/random search for the baseline.\nFor new steps after that, a simple hyperparameter search will take place.</p>\n<p>(The reason for that is you cannot conduct a bayesian search for each experiment.\nHowever, adding a new step will usually change the ideal hyperparameters, so\ndoing some hyperparameter search is required. Approach in this project is to conduct a bayesian search for the baseline, which will take a lot of time. For testing new steps, a custom simple hyperparameter search method will be used.)</p>\n<p><strong>create new pipeline:\n<a href=\"https://www.kaggle.com/c/titanic/overview\" rel=\"nofollow\" title=\"(example: Titanic competition from Kaggle)\">(example: Titanic competition from Kaggle)</a></strong></p>\n<pre><span class=\"n\">label_name</span> <span class=\"o\">=</span> <span class=\"s1\">'Survived'</span>\n<span class=\"n\">trn_path</span> <span class=\"o\">=</span> <span class=\"s1\">'data/train.csv'</span>\n<span class=\"n\">test_path</span> <span class=\"o\">=</span> <span class=\"s1\">'data/test.csv'</span>\n\n<span class=\"c1\"># Pipeline class will keep track of your processed files, model metrics and experiments. </span>\n<span class=\"n\">lr_pipeline</span> <span class=\"o\">=</span> <span class=\"n\">pipe</span><span class=\"o\">.</span><span class=\"n\">Pipeline</span><span class=\"p\">(</span><span class=\"n\">label_name</span> <span class=\"o\">=</span> <span class=\"n\">label_name</span><span class=\"p\">,</span>\n                               <span class=\"n\">overwrite</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">,</span>\n                               <span class=\"n\">project_path</span> <span class=\"o\">=</span> <span class=\"s1\">'lr_pipeline'</span><span class=\"p\">,</span>\n                               <span class=\"n\">train_data_path</span> <span class=\"o\">=</span> <span class=\"n\">trn_path</span><span class=\"p\">,</span>\n                               <span class=\"n\">test_data_path</span> <span class=\"o\">=</span> <span class=\"n\">test_path</span><span class=\"p\">,</span>\n                               <span class=\"n\">minimize_metric</span> <span class=\"o\">=</span> <span class=\"kc\">False</span><span class=\"p\">,</span>\n                               <span class=\"n\">useful_limit</span> <span class=\"o\">=</span> <span class=\"mf\">0.001</span><span class=\"p\">,</span>\n                               <span class=\"n\">line_search_iter</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n                               <span class=\"n\">n_random_seeds</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n                               <span class=\"n\">bayesian_search_iter</span><span class=\"o\">=</span> <span class=\"mi\">50</span><span class=\"p\">,</span>\n                               <span class=\"n\">bayesian_search_count</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n                               <span class=\"n\">final_bayesian_search_iter</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n                               <span class=\"n\">line_search_patience</span> <span class=\"o\">=</span> <span class=\"mi\">2</span><span class=\"p\">,</span>\n                               <span class=\"n\">line_search_params</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'C'</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"mf\">1e-7</span><span class=\"p\">,</span> <span class=\"mf\">1e3</span><span class=\"p\">)})</span>\n</pre>\n<h3>Hyperparameter search using hyperopt</h3>\n<hr>\n<ul>\n<li>Specify hyperameter search space for each model.</li>\n</ul>\n<p>Search is conducted on parameters in search space.\nFixed parameters are parameters that define the model.</p>\n<p>This is an example for logistic regression.\n<strong>fixed parameters:</strong></p>\n<pre><span class=\"n\">fixed_params_lr</span> <span class=\"o\">=</span> <span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">score</span><span class=\"o\">=</span><span class=\"n\">accuracy_score</span><span class=\"p\">,</span>\n                       <span class=\"n\">model</span><span class=\"o\">=</span><span class=\"n\">sklearn</span><span class=\"o\">.</span><span class=\"n\">linear_model</span><span class=\"o\">.</span><span class=\"n\">LogisticRegression</span><span class=\"p\">,</span>                       \n                       <span class=\"n\">max_iter</span><span class=\"o\">=</span><span class=\"mi\">5000</span><span class=\"p\">,</span>\n                       <span class=\"n\">verbose</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n                       <span class=\"n\">n_jobs</span> <span class=\"o\">=</span> <span class=\"mi\">3</span><span class=\"p\">,</span>\n                       <span class=\"n\">model_type</span> <span class=\"o\">=</span> <span class=\"s1\">'linear'</span><span class=\"p\">,</span>\n                       <span class=\"n\">folds</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">KFold</span><span class=\"p\">(</span><span class=\"n\">n_splits</span><span class=\"o\">=</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">shuffle</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">random_state</span> <span class=\"o\">=</span> <span class=\"mi\">42</span><span class=\"p\">),</span>\n                                  <span class=\"n\">KFold</span><span class=\"p\">(</span><span class=\"n\">n_splits</span><span class=\"o\">=</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">shuffle</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">random_state</span> <span class=\"o\">=</span> <span class=\"mi\">13</span><span class=\"p\">),</span>\n                                  <span class=\"n\">KFold</span><span class=\"p\">(</span><span class=\"n\">n_splits</span><span class=\"o\">=</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">shuffle</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">random_state</span> <span class=\"o\">=</span> <span class=\"mi\">100</span><span class=\"p\">)])</span>\n</pre>\n<p><strong>search space:</strong></p>\n<pre><span class=\"n\">lr_search_space</span> <span class=\"o\">=</span> <span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">C</span> <span class=\"o\">=</span> <span class=\"n\">hp</span><span class=\"o\">.</span><span class=\"n\">loguniform</span><span class=\"p\">(</span><span class=\"s1\">'C'</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mi\">7</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">),</span>\n                       <span class=\"n\">class_weight</span> <span class=\"o\">=</span>  <span class=\"n\">hp</span><span class=\"o\">.</span><span class=\"n\">choice</span><span class=\"p\">(</span><span class=\"s1\">'class_weight'</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s1\">'balanced'</span><span class=\"p\">,</span> <span class=\"kc\">None</span><span class=\"p\">]),</span>\n                       <span class=\"n\">solver</span> <span class=\"o\">=</span>  <span class=\"n\">hp</span><span class=\"o\">.</span><span class=\"n\">choice</span><span class=\"p\">(</span><span class=\"s1\">'solver '</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s1\">'lbfgs'</span><span class=\"p\">,</span> <span class=\"s1\">'sag'</span><span class=\"p\">]))</span>\n</pre>\n<p><strong>Averaging results over different splits</strong></p>\n<hr>\n<p>By  specifying multiple sklearn folds objects, average predictions over different splits.\n(Also available for random_state parameters for models.)</p>\n<pre>    <span class=\"n\">folds</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">KFold</span><span class=\"p\">(</span><span class=\"n\">n_splits</span><span class=\"o\">=</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">shuffle</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">random_state</span> <span class=\"o\">=</span> <span class=\"mi\">42</span><span class=\"p\">),</span>\n                 <span class=\"n\">KFold</span><span class=\"p\">(</span><span class=\"n\">n_splits</span><span class=\"o\">=</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">shuffle</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">random_state</span> <span class=\"o\">=</span> <span class=\"mi\">13</span><span class=\"p\">),</span>\n                 <span class=\"n\">KFold</span><span class=\"p\">(</span><span class=\"n\">n_splits</span><span class=\"o\">=</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">shuffle</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">random_state</span> <span class=\"o\">=</span> <span class=\"mi\">100</span><span class=\"p\">)]</span>\n</pre>\n<p><strong>Creating a baseline model</strong></p>\n<hr>\n<p>A baseline step is a step with minimal processing. Preprocessing steps and feature engineering steps in the project will be tested against the metrics of baseline model.</p>\n<p><strong>create the baseline step:</strong></p>\n<pre><span class=\"n\">lr_pipeline</span><span class=\"o\">.</span><span class=\"n\">set_baseline_step</span><span class=\"p\">(</span><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">pmodels</span><span class=\"o\">.</span><span class=\"n\">train_sklearn_pipeline</span><span class=\"p\">,</span>\n                                <span class=\"n\">proc</span> <span class=\"o\">=</span> <span class=\"n\">pdefaults</span><span class=\"o\">.</span><span class=\"n\">default_sklearn_preprocess</span><span class=\"p\">,</span>\n                                <span class=\"n\">search_model_params</span><span class=\"o\">=</span> <span class=\"n\">lr_search_space</span><span class=\"p\">,</span>\n                                <span class=\"n\">fixed_model_params</span> <span class=\"o\">=</span> <span class=\"n\">fixed_params_lr</span>\n                               <span class=\"p\">)</span>\n</pre>\n<h3>Run baseline step</h3>\n<hr>\n<pre><span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"n\">lr_pipeline</span><span class=\"o\">.</span><span class=\"n\">run_baseline</span><span class=\"p\">(</span><span class=\"n\">return_result</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<ul>\n<li>Output contains a javascript that hides details about the step in collapsible boxes.\n<strong>output:</strong>\n<img alt=\"baseline1\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ba12ec6d7711a2da5d8736c930d8397478c869f4/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f34303233383332342f36393932303539382d66353361396530302d313439612d313165612d396665642d3435633630666231316238342e504e47\"></li>\n</ul>\n<hr>\n<p><img alt=\"baseline2\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/671cb2d539e622eed82c84741a1db1adadb69f80/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f34303233383332342f36393932303635342d37633838313138302d313439622d313165612d383136382d3361303766396432386130342e504e47\"></p>\n<hr>\n<p><img alt=\"baseline3\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d217536c6af5ddab24b33e6421b0b415f81d8e35/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f34303233383332342f36393932303635372d38396135303038302d313439622d313165612d393731322d3730336135633533363034322e504e47\"></p>\n<h3>Create submission and save pipeline</h3>\n<hr>\n<p><strong>create submission:</strong></p>\n<pre><span class=\"c1\"># Convert test_preds to int from probabilities</span>\n\n<span class=\"c1\"># Since this competition requires values to be 0 or 1,</span>\n<span class=\"c1\"># We have to adjust a decision threshold. While selecting this threshold,</span>\n<span class=\"c1\"># criteria is to make mean(label) equal to mean(predictions)</span>\n<span class=\"c1\"># This step is not necessary in most projects</span>\n<span class=\"n\">test_preds</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">[</span><span class=\"s1\">'test_preds'</span><span class=\"p\">]</span> <span class=\"o\">&gt;</span> <span class=\"mf\">0.55</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s1\">'int'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Prepare submission file</span>\n<span class=\"n\">to_sub</span> <span class=\"o\">=</span> <span class=\"n\">sub</span><span class=\"o\">.</span><span class=\"n\">copy</span><span class=\"p\">()</span>\n<span class=\"n\">to_sub</span><span class=\"p\">[</span><span class=\"n\">label_name</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">test_preds</span>\n<span class=\"n\">to_sub</span><span class=\"o\">.</span><span class=\"n\">to_csv</span><span class=\"p\">(</span><span class=\"s1\">'titanic_sub.csv'</span><span class=\"p\">,</span> <span class=\"n\">index</span> <span class=\"o\">=</span> <span class=\"kc\">False</span><span class=\"p\">)</span>\n<span class=\"n\">test_preds</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># Baseline LB score: 0.76555</span>\n</pre>\n<p><strong>save pipeline:</strong></p>\n<pre><span class=\"n\">lr_pipeline</span><span class=\"o\">.</span><span class=\"n\">save_project</span><span class=\"p\">()</span>\n</pre>\n<h3>Experiments:</h3>\n<hr>\n<p>New steps should be tried in a separate notebook. First, load the previously saved pipeline.</p>\n<pre><span class=\"n\">lr_pipeline</span> <span class=\"o\">=</span> <span class=\"n\">pipe</span><span class=\"o\">.</span><span class=\"n\">Pipeline</span><span class=\"p\">(</span><span class=\"n\">project_path</span> <span class=\"o\">=</span> <span class=\"s1\">'lr_pipeline'</span><span class=\"p\">)</span>\n</pre>\n<p>Then, create a function to create a kaggle submission for this competition.\nThis is not a part of the library.</p>\n<pre><span class=\"c1\"># Convert to (1,0) from probabilities</span>\n<span class=\"k\">def</span> <span class=\"nf\">make_submission</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"n\">thresh</span><span class=\"p\">):</span>\n    <span class=\"n\">test_preds</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">[</span><span class=\"s1\">'test_preds'</span><span class=\"p\">]</span> <span class=\"o\">&gt;</span> <span class=\"n\">thresh</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s1\">'int'</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># Print mean to adjust threshold</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">test_preds</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">())</span>\n\n    <span class=\"c1\"># Save submission</span>\n    <span class=\"n\">sub</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'data/gender_submission.csv'</span><span class=\"p\">)</span>\n    <span class=\"n\">to_sub</span> <span class=\"o\">=</span> <span class=\"n\">sub</span><span class=\"o\">.</span><span class=\"n\">copy</span><span class=\"p\">()</span>\n    <span class=\"n\">to_sub</span><span class=\"p\">[</span><span class=\"n\">lr_pipeline</span><span class=\"o\">.</span><span class=\"n\">label_name</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">test_preds</span>\n    <span class=\"n\">to_sub</span><span class=\"o\">.</span><span class=\"n\">to_csv</span><span class=\"p\">(</span><span class=\"s1\">'titanic_sub.csv'</span><span class=\"p\">,</span> <span class=\"n\">index</span> <span class=\"o\">=</span> <span class=\"kc\">False</span><span class=\"p\">)</span>\n</pre>\n<p>Then we will try default steps for preprocessing and imputation.</p>\n<h4>Default steps that will be tried:</h4>\n<p>For nominals, features with missing values are imputed in 3 different ways. These are:\n(Baseline model imputes with the most frequent value.)</p>\n<ul>\n<li>Separate category (-9999)</li>\n<li>Impute by dependent\n(If missing values depend on another feature, this method will be useful.)</li>\n</ul>\n<p>Other default steps for nominals is to:</p>\n<ul>\n<li>One-hot encode if specified</li>\n<li>Group values with value_count &lt; limit (default for limit is 10.)</li>\n</ul>\n<p>For numeric steps, features with missing values are imputed in 3 different ways. These are:</p>\n<ul>\n<li>Mean impute</li>\n<li>Impute by dependent</li>\n<li>Impute with fixed value (-9999)</li>\n</ul>\n<p>Other steps:\nBinning (if specified), One-hot encoding for binned features (if specified.)\nOne-hot encoding (if specified.)</p>\n<h4>Standardization</h4>\n<p>When we were creating a baseline step, we used argument</p>\n<pre><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">pmodels</span><span class=\"o\">.</span><span class=\"n\">train_sklearn_pipeline</span>\n</pre>\n<p>pmodels.train_sklearn_pipeline standardizes all features if model_type = 'linear'.</p>\n<h4>Sparse data</h4>\n<p>Categoricals that were OHEd and numerics  that were binned and OHEd are kept in sparse form.</p>\n<h4>Access current form of data</h4>\n<p>You can get the dataset from pipeline using,</p>\n<pre><span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span> <span class=\"o\">=</span> <span class=\"n\">mypipeline</span><span class=\"o\">.</span><span class=\"n\">load_files</span><span class=\"p\">()</span>\n</pre>\n<p>train and test are DataTable instances, which are stored in pickles.\nDataTable is a class created to keep dataframes and sparse matrices together.\nWhen a column from a DataTable is OHEd, it is converted to a sparse matrix and added to the DataTable. Then, features can be accessed in the same way as in pandas.</p>\n<p><strong>try nominal steps:</strong></p>\n<pre><span class=\"n\">steps</span><span class=\"o\">.</span><span class=\"n\">try_default_nominal_steps</span><span class=\"p\">(</span><span class=\"n\">lr_pipeline</span><span class=\"p\">,</span>\n                                <span class=\"n\">ohe</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">,</span>\n                                <span class=\"n\">group_outliers</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">,</span>\n                                <span class=\"n\">ohe_max_unique</span> <span class=\"o\">=</span> <span class=\"mi\">5000</span><span class=\"p\">)</span>\n</pre>\n<p><strong>try numeric steps:</strong></p>\n<pre><span class=\"n\">steps</span><span class=\"o\">.</span><span class=\"n\">try_default_numeric_steps</span><span class=\"p\">(</span><span class=\"n\">lr_pipeline</span><span class=\"p\">,</span>\n                                <span class=\"n\">ohe</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">,</span>\n                                <span class=\"n\">binning</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<p><strong>Example output for nominals:</strong>\n<img alt=\"steps1\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/eb79213e465e95779ee30bfe3d3021bdb2c795ce/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f34303233383332342f37303036313434342d35343134326138302d313566352d313165612d396436342d3766646438306338653561362e504e47\"></p>\n<hr>\n<p><img alt=\"steps2\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/29dca054f6305a22d0c2f6a7da554973d9fd5e87/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f34303233383332342f37303036313437372d36316339623030302d313566352d313165612d396662392d3965376362663235363339312e504e47\"></p>\n<hr>\n<p><img alt=\"steps3\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ec0723a570834c72671c570421f1d7b2d6dbf29d/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f34303233383332342f37303036313531312d37316531386638302d313566352d313165612d383235662d3637633538623730613237632e504e47\"></p>\n<p>Steps of each step can be also viewed.</p>\n<h3>Test after default steps</h3>\n<hr>\n<pre><span class=\"c1\"># When model is not specified, it is the baseline model</span>\n<span class=\"n\">lr_pipeline</span><span class=\"o\">.</span><span class=\"n\">add_model</span><span class=\"p\">(</span><span class=\"s1\">'lr'</span><span class=\"p\">)</span>\n<span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"n\">lr_pipeline</span><span class=\"o\">.</span><span class=\"n\">run_model</span><span class=\"p\">(</span><span class=\"s1\">'lr'</span><span class=\"p\">,</span>\n                            <span class=\"n\">hyperparam_search</span> <span class=\"o\">=</span> <span class=\"kc\">False</span><span class=\"p\">,</span>\n                            <span class=\"n\">return_pred</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">,</span>\n                            <span class=\"n\">use_final_params</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<pre><span class=\"n\">make_submission</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"mf\">0.675</span><span class=\"p\">)</span>\n</pre>\n<h3>Try custom steps</h3>\n<hr>\n<p>In order to try new steps, write your own function with the following arguments and outputs:</p>\n<pre><span class=\"k\">def</span> <span class=\"nf\">my_step</span><span class=\"p\">(</span><span class=\"n\">feature_properties</span><span class=\"p\">,</span> <span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span><span class=\"p\">,</span> <span class=\"n\">label_name</span><span class=\"p\">,</span> <span class=\"n\">MYARG1</span><span class=\"p\">,</span> <span class=\"n\">MYARG2</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">):</span>\n\t<span class=\"c1\"># first 4 features are obligatory, but you can add other arguments.</span>\n\t<span class=\"c1\"># Arguments other than the first 4 must be provided to add_step function in</span>\n\t<span class=\"c1\"># parameter proc_params as a dictionary</span>\n\n\t<span class=\"c1\"># Preprocessing, FE, ... (Mutate train, test)</span>\n\n\t<span class=\"k\">return</span> <span class=\"n\">cols_not_to_model</span><span class=\"p\">,</span> <span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span>\n</pre>\n<p><strong>another example:</strong></p>\n<pre><span class=\"k\">def</span> <span class=\"nf\">my_step</span><span class=\"p\">(</span><span class=\"n\">feature_properties</span><span class=\"p\">,</span> <span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span><span class=\"p\">,</span> <span class=\"n\">label_name</span><span class=\"p\">):</span>\n\n\t<span class=\"c1\"># Add a new column to train, test</span>\n\t<span class=\"n\">train</span><span class=\"p\">[</span><span class=\"s1\">'mycol'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">train</span><span class=\"p\">[</span><span class=\"s1\">'a'</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">train</span><span class=\"p\">[</span><span class=\"s1\">'b'</span><span class=\"p\">]</span>\n\t<span class=\"n\">test</span><span class=\"p\">[</span><span class=\"s1\">'mycol'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">test</span><span class=\"p\">[</span><span class=\"s1\">'a'</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">test</span><span class=\"p\">[</span><span class=\"s1\">'b'</span><span class=\"p\">]</span>\n\n\t <span class=\"c1\"># Add absolute value of a</span>\n\t<span class=\"k\">for</span> <span class=\"n\">df</span> <span class=\"ow\">in</span> <span class=\"p\">[</span><span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span><span class=\"p\">]:</span>\n\t\t<span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'abs_a'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'a'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">abs</span><span class=\"p\">()</span>\n\n\t<span class=\"c1\"># We don't want 'a' to be used in training. If it will be used in future, don't drop 'a'.</span>\n\t<span class=\"c1\"># Instead, add it to cols_not_to_model. </span>\n\t<span class=\"c1\"># If all columns will be used, place [ ] in cols_not_to_model.</span>\n\t<span class=\"n\">cols_not_to_model</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'a'</span><span class=\"p\">]</span>\n\n\t<span class=\"k\">return</span> <span class=\"n\">cols_not_to_model</span><span class=\"p\">,</span> <span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span>\n</pre>\n<p><strong>example from titanic:</strong></p>\n<pre><span class=\"c1\"># Extract title from Name</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">add_title</span><span class=\"p\">(</span><span class=\"n\">feature_properties</span><span class=\"p\">,</span> <span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span><span class=\"p\">,</span> <span class=\"n\">label_name</span><span class=\"p\">):</span>\n    <span class=\"c1\"># From: https://www.kaggle.com/kpacocha/top-5-titanic-machine-learning-from-disaster</span>\n    <span class=\"k\">def</span> <span class=\"nf\">fe_title</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">,</span> <span class=\"n\">col</span><span class=\"p\">):</span>\n        <span class=\"n\">title_col</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">Name</span><span class=\"o\">.</span><span class=\"n\">str</span><span class=\"o\">.</span><span class=\"n\">extract</span><span class=\"p\">(</span><span class=\"s1\">' ([A-Za-z]+)\\.'</span><span class=\"p\">,</span> <span class=\"n\">expand</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n        <span class=\"n\">title_col</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">where</span><span class=\"p\">((</span><span class=\"n\">title_col</span><span class=\"o\">==</span><span class=\"s1\">'Capt'</span><span class=\"p\">)</span> <span class=\"o\">|</span> <span class=\"p\">(</span><span class=\"n\">title_col</span><span class=\"o\">==</span><span class=\"s1\">'Countess'</span><span class=\"p\">)</span>\n                           <span class=\"o\">|</span> <span class=\"p\">(</span><span class=\"n\">title_col</span><span class=\"o\">==</span><span class=\"s1\">'Don'</span><span class=\"p\">)</span> <span class=\"o\">|</span> <span class=\"p\">(</span><span class=\"n\">title_col</span><span class=\"o\">==</span><span class=\"s1\">'Dona'</span><span class=\"p\">)</span>\n                           <span class=\"o\">|</span> <span class=\"p\">(</span><span class=\"n\">title_col</span><span class=\"o\">==</span><span class=\"s1\">'Jonkheer'</span><span class=\"p\">)</span> <span class=\"o\">|</span> <span class=\"p\">(</span><span class=\"n\">title_col</span><span class=\"o\">==</span><span class=\"s1\">'Lady'</span><span class=\"p\">)</span>\n                           <span class=\"o\">|</span> <span class=\"p\">(</span><span class=\"n\">title_col</span><span class=\"o\">==</span><span class=\"s1\">'Sir'</span><span class=\"p\">)</span> <span class=\"o\">|</span> <span class=\"p\">(</span><span class=\"n\">title_col</span><span class=\"o\">==</span><span class=\"s1\">'Major'</span><span class=\"p\">)</span>\n                           <span class=\"o\">|</span> <span class=\"p\">(</span><span class=\"n\">title_col</span><span class=\"o\">==</span><span class=\"s1\">'Rev'</span><span class=\"p\">)</span> <span class=\"o\">|</span> <span class=\"p\">(</span><span class=\"n\">title_col</span><span class=\"o\">==</span><span class=\"s1\">'Col'</span><span class=\"p\">),</span>\n                           <span class=\"s1\">'Other'</span><span class=\"p\">,</span><span class=\"n\">title_col</span><span class=\"p\">)</span>\n\n        <span class=\"n\">title_col</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">Series</span><span class=\"p\">(</span><span class=\"n\">title_col</span><span class=\"p\">)</span>\n        <span class=\"n\">title_col</span> <span class=\"o\">=</span> <span class=\"n\">title_col</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"s1\">'Ms'</span><span class=\"p\">,</span><span class=\"s1\">'Miss'</span><span class=\"p\">)</span>\n        <span class=\"n\">title_col</span> <span class=\"o\">=</span> <span class=\"n\">title_col</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"s1\">'Mlle'</span><span class=\"p\">,</span><span class=\"s1\">'Miss'</span><span class=\"p\">)</span>\n        <span class=\"n\">title_col</span> <span class=\"o\">=</span> <span class=\"n\">title_col</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"s1\">'Mme'</span><span class=\"p\">,</span><span class=\"s1\">'Mrs'</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">title_col</span>\n\n    <span class=\"c1\"># utils.utilize is a python decorator that transforms a function from:</span>\n    <span class=\"c1\"># - takes dataframe, column name as input, returns pd.Series</span>\n    <span class=\"c1\"># to:</span>\n    <span class=\"c1\"># - takes multiple dataframes, can return a pd.Series, can add new column to</span>\n    <span class=\"c1\">#   dataframes with a new name or replaces the original.</span>\n    <span class=\"c1\">#   This behavior is controlled by 'mode' argument.</span>\n    <span class=\"c1\">#  mode:</span>\n    <span class=\"c1\">#  - 'add': add resulting column to the dataframe with a generated name</span>\n    <span class=\"c1\">#  - 'replace': replace original column. </span>\n    <span class=\"c1\">#  - 'return' : return pd.Series for each df.</span>\n    <span class=\"c1\">#  </span>\n    <span class=\"c1\"># utilize also has join_dfs argument (default=True)</span>\n    <span class=\"c1\"># if join_dfs = True, operation is carried out after concatenating the column</span>\n    <span class=\"c1\"># from dataframes.</span>\n\n    <span class=\"c1\"># Process name, append result to train and test.</span>\n    <span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">utilize</span><span class=\"p\">(</span><span class=\"n\">mode</span> <span class=\"o\">=</span> <span class=\"s1\">'add'</span><span class=\"p\">)(</span><span class=\"n\">fe_title</span><span class=\"p\">)([</span><span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span><span class=\"p\">],</span> <span class=\"s1\">'Name'</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># This is the name of the added column.</span>\n    <span class=\"c1\"># Names are generated by utilize using this template:</span>\n    <span class=\"c1\">#     '{function_name}_{col}'</span>\n    <span class=\"c1\">#</span>\n    <span class=\"c1\"># (This is if col is a single string. It can be a list)</span>\n\n    <span class=\"n\">new_name</span> <span class=\"o\">=</span> <span class=\"s1\">'fe_title_Name'</span>\n\n    <span class=\"c1\"># Label encode new column and replace it.</span>\n    <span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">utilize</span><span class=\"p\">(</span><span class=\"n\">mode</span> <span class=\"o\">=</span> <span class=\"s1\">'replace'</span><span class=\"p\">)(</span><span class=\"n\">prep</span><span class=\"o\">.</span><span class=\"n\">label_encode</span><span class=\"p\">)([</span><span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span><span class=\"p\">],</span> <span class=\"n\">new_name</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># One hot encode new column</span>\n    <span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span> <span class=\"o\">=</span> <span class=\"n\">prep</span><span class=\"o\">.</span><span class=\"n\">one_hot_encode</span><span class=\"p\">([</span><span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span><span class=\"p\">],</span> <span class=\"n\">col</span> <span class=\"o\">=</span> <span class=\"n\">new_name</span><span class=\"p\">,</span> <span class=\"n\">sparse</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"p\">[],</span> <span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span>\n</pre>\n<h4>Try a new step:</h4>\n<pre><span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"n\">lr_pipeline</span><span class=\"o\">.</span><span class=\"n\">add_step_apply_if_useful</span><span class=\"p\">(</span><span class=\"n\">proc</span> <span class=\"o\">=</span> <span class=\"n\">add_title</span><span class=\"p\">)</span>\n</pre>\n<p><strong>output: (details can be viewed by clicking on add_title)</strong>\n<img alt=\"steps4\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/72582ab8ac3d9ac6112855884c935d9f635ba518/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f34303233383332342f37303036373932382d31666632333730302d313630302d313165612d393065372d6465636164376237326362392e504e47\"></p>\n<p><strong>create a kaggle submission:</strong></p>\n<pre><span class=\"n\">make_submission</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"mf\">0.7335</span><span class=\"p\">)</span>\n</pre>\n<h4>Try mutually exclusive steps:</h4>\n<p>Some steps are mutually excusive, which means that you will only apply one of them,\neven if more than one is useful. For example, different methods of imputations are mutually exclusive.</p>\n<details>\n<summary>Code</summary>\n<pre><span class=\"k\">def</span> <span class=\"nf\">add_prefix</span><span class=\"p\">(</span><span class=\"n\">feature_properties</span><span class=\"p\">,</span> <span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span><span class=\"p\">,</span> <span class=\"n\">label_name</span><span class=\"p\">,</span> <span class=\"n\">col_name</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">prefix</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">,</span> <span class=\"n\">col</span><span class=\"p\">):</span>\n        <span class=\"k\">def</span> <span class=\"nf\">get_prefix</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">):</span>\n            <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n            <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"mi\">1</span><span class=\"p\">:</span>\n                <span class=\"k\">return</span> <span class=\"n\">x</span>\n            <span class=\"k\">else</span><span class=\"p\">:</span>\n                <span class=\"k\">return</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s1\">' '</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n        <span class=\"k\">return</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">col</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">apply</span><span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">get_prefix</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">))</span>\n\n    <span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">utilize</span><span class=\"p\">(</span><span class=\"n\">mode</span> <span class=\"o\">=</span> <span class=\"s1\">'add'</span><span class=\"p\">)(</span><span class=\"n\">prefix</span><span class=\"p\">)([</span><span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span><span class=\"p\">],</span> <span class=\"n\">col_name</span><span class=\"p\">)</span>\n    <span class=\"n\">new_name</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s1\">'prefix_</span><span class=\"si\">{</span><span class=\"n\">col_name</span><span class=\"si\">}</span><span class=\"s1\">'</span>\n    <span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">utilize</span><span class=\"p\">(</span><span class=\"n\">mode</span> <span class=\"o\">=</span> <span class=\"s1\">'replace'</span><span class=\"p\">)(</span><span class=\"n\">prep</span><span class=\"o\">.</span><span class=\"n\">label_encode</span><span class=\"p\">)([</span><span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span><span class=\"p\">],</span> <span class=\"n\">new_name</span><span class=\"p\">)</span>\n    <span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span> <span class=\"o\">=</span> <span class=\"n\">prep</span><span class=\"o\">.</span><span class=\"n\">one_hot_encode</span><span class=\"p\">([</span><span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span><span class=\"p\">],</span>\n                                      <span class=\"n\">col</span> <span class=\"o\">=</span> <span class=\"n\">new_name</span><span class=\"p\">,</span>\n                                      <span class=\"n\">mode</span> <span class=\"o\">=</span> <span class=\"s1\">'replace'</span><span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"p\">[],</span> <span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">add_prefix_group_outliers</span><span class=\"p\">(</span>\n        <span class=\"n\">feature_properties</span><span class=\"p\">,</span> <span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span><span class=\"p\">,</span>\n        <span class=\"n\">label_name</span><span class=\"p\">,</span> <span class=\"n\">col_name</span><span class=\"p\">,</span> <span class=\"n\">limit</span> <span class=\"o\">=</span> <span class=\"mi\">10</span><span class=\"p\">):</span>\n    <span class=\"nd\">@utils</span><span class=\"o\">.</span><span class=\"n\">utilize</span><span class=\"p\">(</span><span class=\"n\">mode</span> <span class=\"o\">=</span> <span class=\"s1\">'add'</span><span class=\"p\">)</span>\n    <span class=\"k\">def</span> <span class=\"nf\">prefix</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">,</span> <span class=\"n\">col</span><span class=\"p\">):</span>\n        <span class=\"k\">def</span> <span class=\"nf\">get_prefix</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">):</span>\n            <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n            <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"mi\">1</span><span class=\"p\">:</span>\n                <span class=\"k\">return</span> <span class=\"n\">x</span>\n            <span class=\"k\">else</span><span class=\"p\">:</span>\n                <span class=\"k\">return</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s1\">' '</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n        <span class=\"k\">return</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">col</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">apply</span><span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">get_prefix</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">))</span>\n\n    <span class=\"n\">prefix</span><span class=\"p\">([</span><span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span><span class=\"p\">],</span> <span class=\"n\">col_name</span><span class=\"p\">)</span>\n    <span class=\"n\">new_name</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s1\">'prefix_</span><span class=\"si\">{</span><span class=\"n\">col_name</span><span class=\"si\">}</span><span class=\"s1\">'</span>\n    <span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">utilize</span><span class=\"p\">(</span><span class=\"n\">mode</span> <span class=\"o\">=</span> <span class=\"s1\">'replace'</span><span class=\"p\">)(</span><span class=\"n\">prep</span><span class=\"o\">.</span><span class=\"n\">label_encode</span><span class=\"p\">)([</span><span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span><span class=\"p\">],</span> <span class=\"n\">new_name</span><span class=\"p\">)</span>\n    <span class=\"n\">prep</span><span class=\"o\">.</span><span class=\"n\">group_outliers_replace</span><span class=\"p\">([</span><span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span><span class=\"p\">],</span> <span class=\"n\">new_name</span><span class=\"p\">,</span> <span class=\"n\">limit</span> <span class=\"o\">=</span> <span class=\"n\">limit</span><span class=\"p\">)</span>\n    <span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span> <span class=\"o\">=</span> <span class=\"n\">prep</span><span class=\"o\">.</span><span class=\"n\">one_hot_encode</span><span class=\"p\">([</span><span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span><span class=\"p\">],</span>\n                                      <span class=\"n\">col</span> <span class=\"o\">=</span> <span class=\"n\">new_name</span><span class=\"p\">,</span>\n                                      <span class=\"n\">mode</span> <span class=\"o\">=</span> <span class=\"s1\">'add'</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># Don't drop the original column, but don't use it in training</span>\n    <span class=\"k\">return</span> <span class=\"p\">[</span><span class=\"n\">col_name</span><span class=\"p\">],</span> <span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span>\n\n<span class=\"n\">lr_pipeline</span><span class=\"o\">.</span><span class=\"n\">add_step</span><span class=\"p\">(</span><span class=\"n\">proc</span> <span class=\"o\">=</span> <span class=\"n\">add_prefix</span><span class=\"p\">,</span>\n                     <span class=\"n\">group</span> <span class=\"o\">=</span> <span class=\"s1\">'prefix_ticket'</span><span class=\"p\">,</span>\n                     <span class=\"n\">proc_params</span><span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'col_name'</span><span class=\"p\">:</span> <span class=\"s1\">'Ticket'</span><span class=\"p\">})</span>\n\n<span class=\"n\">lr_pipeline</span><span class=\"o\">.</span><span class=\"n\">add_step</span><span class=\"p\">(</span><span class=\"n\">proc</span> <span class=\"o\">=</span> <span class=\"n\">add_prefix_group_outliers</span><span class=\"p\">,</span>\n                     <span class=\"n\">group</span> <span class=\"o\">=</span> <span class=\"s1\">'prefix_ticket'</span><span class=\"p\">,</span>\n                     <span class=\"n\">proc_params</span><span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'col_name'</span><span class=\"p\">:</span> <span class=\"s1\">'Ticket'</span><span class=\"p\">})</span>\n\n<span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"n\">lr_pipeline</span><span class=\"o\">.</span><span class=\"n\">group_apply_useful</span><span class=\"p\">(</span><span class=\"s1\">'prefix_ticket'</span><span class=\"p\">)</span>\n</pre>\n</details>\n<p><strong>output:</strong>\n<img alt=\"steps5\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b758249dc53a0bd76a47dd5b455b78d5255d1b9c/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f34303233383332342f37303036383431392d30343362363038302d313630312d313165612d393639622d6436333430643934396564352e504e47\"></p>\n<p>No need to generate a submission for this one, as nothing was changed in the data.</p>\n<h3>Train other models (or train from scratch using bayesian search)</h3>\n<hr>\n<p>Train baseline model. (using hparams determined in line search)\n(Training baseline is necessary only if you will stack/blend)</p>\n<p><strong>train baseline:</strong></p>\n<pre><span class=\"c1\"># When model is not specified, it is the baseline model</span>\n<span class=\"n\">lr_pipeline</span><span class=\"o\">.</span><span class=\"n\">add_model</span><span class=\"p\">(</span><span class=\"s1\">'lr'</span><span class=\"p\">)</span>\n<span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"n\">lr_pipeline</span><span class=\"o\">.</span><span class=\"n\">run_model</span><span class=\"p\">(</span><span class=\"s1\">'lr'</span><span class=\"p\">,</span>\n                            <span class=\"n\">hyperparam_search</span> <span class=\"o\">=</span> <span class=\"kc\">False</span><span class=\"p\">,</span>\n                            <span class=\"n\">return_pred</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">,</span>\n                            <span class=\"n\">use_final_params</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<p><strong>output:</strong>\n<img alt=\"models1\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/76f6f2c8b13c8929444dfa3272f31e3a1099ab51/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f34303233383332342f37303036393133322d35353938316638302d313630322d313165612d383534352d3665333662616531633834302e504e47\"></p>\n<hr>\n<p><strong>train svm:</strong>\nfixed_hparams and search_hparams can be used in other projects as they are.\n(I will add them to the library soon.)</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">sklearn.svm</span> <span class=\"kn\">import</span> <span class=\"n\">SVC</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.metrics</span> <span class=\"kn\">import</span> <span class=\"n\">accuracy_score</span>\n\n<span class=\"n\">fixed_hparams</span> <span class=\"o\">=</span> <span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">SVC</span><span class=\"p\">,</span>\n                     <span class=\"n\">probability</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">,</span>\n                     <span class=\"n\">random_state</span> <span class=\"o\">=</span> <span class=\"mi\">42</span><span class=\"p\">,</span>\n                     <span class=\"n\">score</span> <span class=\"o\">=</span> <span class=\"n\">accuracy_score</span><span class=\"p\">,</span>\n                     <span class=\"n\">max_iter</span> <span class=\"o\">=</span> <span class=\"mi\">2000</span><span class=\"p\">,</span>\n                     <span class=\"n\">folds</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">KFold</span><span class=\"p\">(</span><span class=\"n\">n_splits</span><span class=\"o\">=</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">shuffle</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">random_state</span> <span class=\"o\">=</span> <span class=\"mi\">42</span><span class=\"p\">),</span>\n                              <span class=\"n\">KFold</span><span class=\"p\">(</span><span class=\"n\">n_splits</span><span class=\"o\">=</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">shuffle</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">random_state</span> <span class=\"o\">=</span> <span class=\"mi\">13</span><span class=\"p\">),</span>\n                              <span class=\"n\">KFold</span><span class=\"p\">(</span><span class=\"n\">n_splits</span><span class=\"o\">=</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">shuffle</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">random_state</span> <span class=\"o\">=</span> <span class=\"mi\">100</span><span class=\"p\">)</span>\n                              <span class=\"p\">])</span>\n\n\n<span class=\"n\">search_hparams</span> <span class=\"o\">=</span> <span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">C</span> <span class=\"o\">=</span> <span class=\"n\">hp</span><span class=\"o\">.</span><span class=\"n\">loguniform</span><span class=\"p\">(</span><span class=\"s1\">'C'</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">),</span>\n                      <span class=\"n\">gamma</span> <span class=\"o\">=</span> <span class=\"n\">hp</span><span class=\"o\">.</span><span class=\"n\">loguniform</span><span class=\"p\">(</span><span class=\"s1\">'gamma'</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">),</span>\n                      <span class=\"n\">class_weight</span> <span class=\"o\">=</span>  <span class=\"n\">hp</span><span class=\"o\">.</span><span class=\"n\">choice</span><span class=\"p\">(</span><span class=\"s1\">'class_weight'</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s1\">'balanced'</span><span class=\"p\">,</span> <span class=\"kc\">None</span><span class=\"p\">]),</span>\n                      <span class=\"n\">kernel</span> <span class=\"o\">=</span> <span class=\"n\">hp</span><span class=\"o\">.</span><span class=\"n\">choice</span><span class=\"p\">(</span><span class=\"s1\">'kernel'</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s1\">'linear'</span><span class=\"p\">,</span> <span class=\"s1\">'rbf'</span><span class=\"p\">,</span> <span class=\"s1\">'poly'</span><span class=\"p\">])</span>\n                      <span class=\"p\">)</span>\n\n<span class=\"n\">lr_pipeline</span><span class=\"o\">.</span><span class=\"n\">add_model</span><span class=\"p\">(</span><span class=\"s1\">'svc'</span><span class=\"p\">,</span>\n                      <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">pmodels</span><span class=\"o\">.</span><span class=\"n\">train_sklearn_pipeline</span><span class=\"p\">,</span>\n                      <span class=\"n\">fixed_hparams</span> <span class=\"o\">=</span> <span class=\"n\">fixed_hparams</span><span class=\"p\">,</span>\n                      <span class=\"n\">search_hparams</span> <span class=\"o\">=</span> <span class=\"n\">search_hparams</span><span class=\"p\">)</span>\n\n<span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"n\">lr_pipeline</span><span class=\"o\">.</span><span class=\"n\">run_model</span><span class=\"p\">(</span><span class=\"s1\">'svc'</span><span class=\"p\">,</span> <span class=\"n\">return_pred</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">hyperparam_search</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<p><strong>create submission:</strong>\nYou should test each model before stacking/blending.</p>\n<pre><span class=\"n\">make_submission</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"mf\">0.675</span><span class=\"p\">)</span>\n</pre>\n<hr>\n<p><strong>train kneighbors:</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">sklearn.neighbors</span> <span class=\"kn\">import</span> <span class=\"n\">KNeighborsClassifier</span>\n\n<span class=\"n\">fixed_hparams</span> <span class=\"o\">=</span> <span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">KNeighborsClassifier</span><span class=\"p\">,</span>\n                     <span class=\"n\">folds</span> <span class=\"o\">=</span> <span class=\"n\">lr_pipeline</span><span class=\"o\">.</span><span class=\"n\">baseline_step</span><span class=\"p\">[</span><span class=\"s1\">'model_params'</span><span class=\"p\">][</span><span class=\"s1\">'folds'</span><span class=\"p\">],</span>\n                     <span class=\"n\">score</span> <span class=\"o\">=</span> <span class=\"n\">accuracy_score</span><span class=\"p\">)</span>\n\n\n<span class=\"n\">search_hparams</span> <span class=\"o\">=</span> <span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">n_neighbors</span>  <span class=\"o\">=</span> <span class=\"n\">hp</span><span class=\"o\">.</span><span class=\"n\">choice</span><span class=\"p\">(</span><span class=\"s1\">'n_neighbors'</span><span class=\"p\">,</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">,</span><span class=\"mi\">25</span><span class=\"p\">)),</span>\n                      <span class=\"n\">leaf_size</span> <span class=\"o\">=</span> <span class=\"n\">hp</span><span class=\"o\">.</span><span class=\"n\">choice</span><span class=\"p\">(</span><span class=\"s1\">'leaf_size'</span><span class=\"p\">,</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">15</span><span class=\"p\">,</span><span class=\"mi\">50</span><span class=\"p\">)))</span>\n\n<span class=\"n\">lr_pipeline</span><span class=\"o\">.</span><span class=\"n\">add_model</span><span class=\"p\">(</span><span class=\"s1\">'kn'</span><span class=\"p\">,</span>\n                      <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">pmodels</span><span class=\"o\">.</span><span class=\"n\">train_sklearn_pipeline</span><span class=\"p\">,</span>\n                      <span class=\"n\">fixed_hparams</span> <span class=\"o\">=</span> <span class=\"n\">fixed_hparams</span><span class=\"p\">,</span>\n                      <span class=\"n\">search_hparams</span> <span class=\"o\">=</span> <span class=\"n\">search_hparams</span><span class=\"p\">)</span>\n\n<span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"n\">lr_pipeline</span><span class=\"o\">.</span><span class=\"n\">run_model</span><span class=\"p\">(</span><span class=\"s1\">'kn'</span><span class=\"p\">,</span> <span class=\"n\">hyperparam_search</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<p><strong>output:</strong>\n<img alt=\"steps6\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/201b1e469c67c7d9a5eaacdc7790a4ec606a2b4e/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f34303233383332342f37303036393438332d65353364636530302d313630322d313165612d383263312d3633343131356361623364662e504e47\"></p>\n<p><strong>create submission:</strong></p>\n<pre><span class=\"n\">make_submission</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"mf\">0.675</span><span class=\"p\">)</span>\n</pre>\n<hr>\n<h3>Blending</h3>\n<p>(Stacking will be also available.)</p>\n<p><strong>blend predictions in a directory:</strong></p>\n<pre><span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"p\">{}</span>\n<span class=\"n\">res</span><span class=\"p\">[</span><span class=\"s1\">'test_preds'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">putils</span><span class=\"o\">.</span><span class=\"n\">blend_from_csv</span><span class=\"p\">(</span><span class=\"n\">directory</span> <span class=\"o\">=</span> <span class=\"n\">lr_pipeline</span><span class=\"o\">.</span><span class=\"n\">test_preds_path</span><span class=\"p\">)</span>\n</pre>\n<p><strong>create submission:</strong></p>\n<pre><span class=\"n\">make_submission</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"mf\">0.7</span><span class=\"p\">)</span>\n</pre>\n<p><strong>save project:</strong></p>\n<pre><span class=\"n\">lr_pipeline</span><span class=\"o\">.</span><span class=\"n\">save_project</span><span class=\"p\">()</span>\n</pre>\n<h3>Note:</h3>\n<p>Ideally, you should place each new experiment/step in a new notebook and save project after each useful step. In Titanic example, baseline is in its own notebook, but following steps are in a second one, to keep the example simpler.</p>\n\n          </div>"}, "last_serial": 6236356, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "a3990a669fe82806cf403b1db0959821", "sha256": "9aa52bcd57b25e12df01a06945394bbdb6a2f38928c6302a47972f7d59e0fbee"}, "downloads": -1, "filename": "mlpl-0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "a3990a669fe82806cf403b1db0959821", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 150183, "upload_time": "2019-12-02T09:01:20", "upload_time_iso_8601": "2019-12-02T09:01:20.731382Z", "url": "https://files.pythonhosted.org/packages/e8/8c/e347e287b43f5905405ddc44f852f346c10d70aef26a58e727fdbe61325a/mlpl-0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3b7ad0c79171730d020065503bf39550", "sha256": "7816d8a22d2fa51c9705ae2de22a503b9695c70d96c0edbab17294e0a4836a34"}, "downloads": -1, "filename": "mlpl-0.1.tar.gz", "has_sig": false, "md5_digest": "3b7ad0c79171730d020065503bf39550", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 63923, "upload_time": "2019-12-02T09:01:23", "upload_time_iso_8601": "2019-12-02T09:01:23.988668Z", "url": "https://files.pythonhosted.org/packages/8b/b4/0845a3c64e4d00889260589b8613795dcfed17490f9ca083869a475cb535/mlpl-0.1.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "6f41d1e755538c75038917c4403bdb1f", "sha256": "1ef18e3f32101beefc1fffd747b73f7d012c36e95560e22446fc4c3d938a0ffb"}, "downloads": -1, "filename": "mlpl-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "6f41d1e755538c75038917c4403bdb1f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 153878, "upload_time": "2019-12-03T17:52:38", "upload_time_iso_8601": "2019-12-03T17:52:38.995974Z", "url": "https://files.pythonhosted.org/packages/3b/ee/85e94f592932d0b20dd9c6eee29215fcb3ef4cc4e73097ac202aa7f4ed14/mlpl-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6ad7e5760546eaf1ea4456a8fcec4e6a", "sha256": "5214b90bce42b985a606b7f5e50a580e542e25053bffa9ece8b12ceb5aab0d45"}, "downloads": -1, "filename": "mlpl-0.1.1.tar.gz", "has_sig": false, "md5_digest": "6ad7e5760546eaf1ea4456a8fcec4e6a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 68873, "upload_time": "2019-12-03T17:52:41", "upload_time_iso_8601": "2019-12-03T17:52:41.794014Z", "url": "https://files.pythonhosted.org/packages/24/ec/3f9ab57d9155c0dfea17308ae651fb0a352d994697efa23710c79944f67b/mlpl-0.1.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "6f41d1e755538c75038917c4403bdb1f", "sha256": "1ef18e3f32101beefc1fffd747b73f7d012c36e95560e22446fc4c3d938a0ffb"}, "downloads": -1, "filename": "mlpl-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "6f41d1e755538c75038917c4403bdb1f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 153878, "upload_time": "2019-12-03T17:52:38", "upload_time_iso_8601": "2019-12-03T17:52:38.995974Z", "url": "https://files.pythonhosted.org/packages/3b/ee/85e94f592932d0b20dd9c6eee29215fcb3ef4cc4e73097ac202aa7f4ed14/mlpl-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6ad7e5760546eaf1ea4456a8fcec4e6a", "sha256": "5214b90bce42b985a606b7f5e50a580e542e25053bffa9ece8b12ceb5aab0d45"}, "downloads": -1, "filename": "mlpl-0.1.1.tar.gz", "has_sig": false, "md5_digest": "6ad7e5760546eaf1ea4456a8fcec4e6a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 68873, "upload_time": "2019-12-03T17:52:41", "upload_time_iso_8601": "2019-12-03T17:52:41.794014Z", "url": "https://files.pythonhosted.org/packages/24/ec/3f9ab57d9155c0dfea17308ae651fb0a352d994697efa23710c79944f67b/mlpl-0.1.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:53:24 2020"}