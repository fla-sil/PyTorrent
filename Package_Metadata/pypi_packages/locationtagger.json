{"info": {"author": "Kaushik Soni", "author_email": "kaushiksoni10@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python :: 3", "Topic :: Text Processing"], "description": "# locationtagger\n**version 0.0.1**\n\nDetect and extract locations (Countries, Regions/States & Cities) from text or URL. Also, find relationships among countries, regions & cities.\n\n---\n## About Project\nIn the field of [Natural Lauguage Processing](https://en.wikipedia.org/wiki/Natural_language_processing), many algorithms have been derived for different types of syntactic & semantic analysis of the textual data. NER ([Named Entity Recognition](https://en.wikipedia.org/wiki/Named-entity_recognition)) is one of the best & frequently needed tasks in real-world problems of text mining that follows some grammer-based rules & statistical modelling approaches. An entity extracted from NER can be a name of person, place, organization or product. [locationtagger](https://github.com/kaushiksoni10/locationtagger) is a further process of tagging & filter out place names (locations) amongst all the entities found with NER.\n\nApproach followed is given below in the picture;\n\nhttps://github.com/kaushiksoni10/locationtagger/blob/master/locationtagger/data/diagram.jpg?raw=true\n![Approach](locationtagger/data/diagram.jpg)\n\n---\n## Install and Setup\n**(Environment: python >= 3.5)**\n\nInstall the package using pip -\n\n`pip install locationtagger`\n\nBut before we install the package, we need to install some useful libraries given below,\n\n`nltk`\n\n`spacy`\n\n`newspaper3k`\n\n`pycountry`\n\nAfter installing these packages, there are some important nltk & spacy modules that need to be downloaded using commands given in `/locationtagger/bin/locationtagger-nltk-spacy` on IPython shell or Jupyter notebook.\n\n---\n## Usage\nAfter proper installation of the package, import the module and give some text/URL as input;\n\n### Text as input\n\n\n```python\nimport locationtagger\n\ntext = \"Unlike India and Japan, A winter weather advisory remains in effect through 5 PM along and east of a line from Blue Earth, to Red Wing line in Minnesota and continuing to along an Ellsworth, to Menomonie, and Chippewa Falls line in Wisconsin.\"\n\nentities = locationtagger.find_locations(text = text)\n```\n\\\nNow we can grab all the place names present in above text,\n\n```python\nentities.countries\n```\n`['India', 'Japan']`\n\n```python\nentities.regions\n```\n`['Minnesota', 'Wisconsin']`\n\n```python\nentities.cities\n```\n`['Ellsworth', 'Red Wing', 'Blue Earth', 'Chippewa Falls', 'Menomonie']`\n\n\\\nApart from above places extracted from the text, we can also find the countries where these extracted `cities`, `regions` belong to,\n\n```python\nentities.country_regions\n```\n`{'United States': ['Minnesota', 'Wisconsin']}`\n\n```python\nentities.country_cities\n```\n`{'United States': ['Ellsworth',\n  'Red Wing',\n  'Blue Earth',\n  'Chippewa Falls',\n  'Menomonie']}`\n\n \\\n  Since \"United States\" is a country but not present in the text still came from the relations to the `cities` & `regions` present in the text, we can find it in `other_countries`,\n\n  ```python\n  entities.other_countries\n  ```\n  `['United States']`\n\n \\\n  If we are really serious about the `cities` we got in the text we can find which regions in the world it may fall in, \n\n  ```python\n  entities.region_cities\n  ```\n  `{'Maine': ['Ellsworth'],\n 'Minnesota': ['Red Wing', 'Blue Earth'],\n 'Wisconsin': ['Ellsworth', 'Chippewa Falls', 'Menomonie'],\n 'Pennsylvania': ['Ellsworth'],\n 'Michigan': ['Ellsworth'],\n 'Illinois': ['Ellsworth'],\n 'Kansas': ['Ellsworth'],\n 'Iowa': ['Ellsworth']}`\n\n\\\nAnd obviously, we'll put these regions in `other_regions` since they are not present in original text,\n\n```python\nentities.other_regions\n```\n`['Maine',\n 'Minnesota',\n 'Wisconsin',\n 'Pennsylvania',\n 'Michigan',\n 'Illinois',\n 'Kansas',\n 'Iowa']`\n\n\\\n Whatever words nltk & spacy both grabbed from the original text as [named entity](https://en.wikipedia.org/wiki/Named_entity) , most of them are stored in `cities`, `regions` & `countries`. But the remaining words (not recognized as place name) will be stored in `other`.\n\n ```python\n entities.other\n ```\n `['winter', 'PM', 'Chippewa']` \n\n### URL as Input \nSimilarly, It can grab places from urls too, \n\n```python\nURL = 'https://edition.cnn.com/2020/01/14/americas/staggering-number-of-human-rights-defenders-killed-in-colombia-the-un-says/index.html'\nentities2 = locationtagger.find_locations(url = URL)\n```\n\\\noutputs we get:\ncountries;\n\n```python\nentities2.countries\n```\n`['Switzerland', 'Colombia']`\n\n\\\nregions;\n\n```python\nentities2.regions\n```\n`['Geneva']`\n\n\\\ncities;\n\n```pyhton\nentities2.cities\n```\n`['Geneva', 'Colombia']`\n\n\\\nNow, if we want to check how many times a place has been mentioned or most common places which have been mentioned in the whole page of the URL, we can have an idea about what location that page is talking about;\n\nhence, most commonly mentioned countries;\n\n```python\nentities2.country_mentions\n```\n`[('Colombia', 3), ('Switzerland', 1), ('United States', 1), ('Mexico', 1)]`\n\n\\\nand most commonly mentioned cities;\n\n```python\nentities2.city_mentions\n```\n`[('Colombia', 3), ('Geneva', 1)]`\n\n---\n\n## Credits\n[locationtagger](https://github.com/kaushiksoni10/locationtagger) uses data from following source for country, region & city lookups,\n\n[GEOLITE2 free downloadable database](https://dev.maxmind.com/geoip/geoip2/geolite2/)\n\nApart from famous nlp libraries [NLTK](http://www.nltk.org/) & [spacy](https://spacy.io/), [locationtagger](https://github.com/kaushiksoni10/locationtagger) uses following very useful libraries;\n\n[pycountry](https://github.com/flyingcircusio/pycountry)\n\n[newspaper3k](https://github.com/codelucas/newspaper)\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/kaushiksoni10/locationtagger", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "locationtagger", "package_url": "https://pypi.org/project/locationtagger/", "platform": "", "project_url": "https://pypi.org/project/locationtagger/", "project_urls": {"Homepage": "https://github.com/kaushiksoni10/locationtagger"}, "release_url": "https://pypi.org/project/locationtagger/0.0.1/", "requires_dist": ["nltk", "spacy", "newspaper3k", "pycountry"], "requires_python": ">=3.5", "summary": "Detect & Extract locations from text or URL and find relationships among locations", "version": "0.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>locationtagger</h1>\n<p><strong>version 0.0.1</strong></p>\n<p>Detect and extract locations (Countries, Regions/States &amp; Cities) from text or URL. Also, find relationships among countries, regions &amp; cities.</p>\n<hr>\n<h2>About Project</h2>\n<p>In the field of <a href=\"https://en.wikipedia.org/wiki/Natural_language_processing\" rel=\"nofollow\">Natural Lauguage Processing</a>, many algorithms have been derived for different types of syntactic &amp; semantic analysis of the textual data. NER (<a href=\"https://en.wikipedia.org/wiki/Named-entity_recognition\" rel=\"nofollow\">Named Entity Recognition</a>) is one of the best &amp; frequently needed tasks in real-world problems of text mining that follows some grammer-based rules &amp; statistical modelling approaches. An entity extracted from NER can be a name of person, place, organization or product. <a href=\"https://github.com/kaushiksoni10/locationtagger\" rel=\"nofollow\">locationtagger</a> is a further process of tagging &amp; filter out place names (locations) amongst all the entities found with NER.</p>\n<p>Approach followed is given below in the picture;</p>\n<p><a href=\"https://github.com/kaushiksoni10/locationtagger/blob/master/locationtagger/data/diagram.jpg?raw=true\" rel=\"nofollow\">https://github.com/kaushiksoni10/locationtagger/blob/master/locationtagger/data/diagram.jpg?raw=true</a>\n<img alt=\"Approach\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a5b47d345f7a4e04bac87039617cb8c8c841843c/6c6f636174696f6e7461676765722f646174612f6469616772616d2e6a7067\"></p>\n<hr>\n<h2>Install and Setup</h2>\n<p><strong>(Environment: python &gt;= 3.5)</strong></p>\n<p>Install the package using pip -</p>\n<p><code>pip install locationtagger</code></p>\n<p>But before we install the package, we need to install some useful libraries given below,</p>\n<p><code>nltk</code></p>\n<p><code>spacy</code></p>\n<p><code>newspaper3k</code></p>\n<p><code>pycountry</code></p>\n<p>After installing these packages, there are some important nltk &amp; spacy modules that need to be downloaded using commands given in <code>/locationtagger/bin/locationtagger-nltk-spacy</code> on IPython shell or Jupyter notebook.</p>\n<hr>\n<h2>Usage</h2>\n<p>After proper installation of the package, import the module and give some text/URL as input;</p>\n<h3>Text as input</h3>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">locationtagger</span>\n\n<span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"s2\">\"Unlike India and Japan, A winter weather advisory remains in effect through 5 PM along and east of a line from Blue Earth, to Red Wing line in Minnesota and continuing to along an Ellsworth, to Menomonie, and Chippewa Falls line in Wisconsin.\"</span>\n\n<span class=\"n\">entities</span> <span class=\"o\">=</span> <span class=\"n\">locationtagger</span><span class=\"o\">.</span><span class=\"n\">find_locations</span><span class=\"p\">(</span><span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"n\">text</span><span class=\"p\">)</span>\n</pre>\n<p><br>\nNow we can grab all the place names present in above text,</p>\n<pre><span class=\"n\">entities</span><span class=\"o\">.</span><span class=\"n\">countries</span>\n</pre>\n<p><code>['India', 'Japan']</code></p>\n<pre><span class=\"n\">entities</span><span class=\"o\">.</span><span class=\"n\">regions</span>\n</pre>\n<p><code>['Minnesota', 'Wisconsin']</code></p>\n<pre><span class=\"n\">entities</span><span class=\"o\">.</span><span class=\"n\">cities</span>\n</pre>\n<p><code>['Ellsworth', 'Red Wing', 'Blue Earth', 'Chippewa Falls', 'Menomonie']</code></p>\n<p><br>\nApart from above places extracted from the text, we can also find the countries where these extracted <code>cities</code>, <code>regions</code> belong to,</p>\n<pre><span class=\"n\">entities</span><span class=\"o\">.</span><span class=\"n\">country_regions</span>\n</pre>\n<p><code>{'United States': ['Minnesota', 'Wisconsin']}</code></p>\n<pre><span class=\"n\">entities</span><span class=\"o\">.</span><span class=\"n\">country_cities</span>\n</pre>\n<p><code>{'United States': ['Ellsworth', 'Red Wing', 'Blue Earth', 'Chippewa Falls', 'Menomonie']}</code></p>\n<p><br>\nSince \"United States\" is a country but not present in the text still came from the relations to the <code>cities</code> &amp; <code>regions</code> present in the text, we can find it in <code>other_countries</code>,</p>\n<pre><span class=\"n\">entities</span><span class=\"o\">.</span><span class=\"n\">other_countries</span>\n</pre>\n<p><code>['United States']</code></p>\n<p><br>\nIf we are really serious about the <code>cities</code> we got in the text we can find which regions in the world it may fall in,</p>\n<pre><span class=\"n\">entities</span><span class=\"o\">.</span><span class=\"n\">region_cities</span>\n</pre>\n<p><code>{'Maine': ['Ellsworth'], 'Minnesota': ['Red Wing', 'Blue Earth'], 'Wisconsin': ['Ellsworth', 'Chippewa Falls', 'Menomonie'], 'Pennsylvania': ['Ellsworth'], 'Michigan': ['Ellsworth'], 'Illinois': ['Ellsworth'], 'Kansas': ['Ellsworth'], 'Iowa': ['Ellsworth']}</code></p>\n<p><br>\nAnd obviously, we'll put these regions in <code>other_regions</code> since they are not present in original text,</p>\n<pre><span class=\"n\">entities</span><span class=\"o\">.</span><span class=\"n\">other_regions</span>\n</pre>\n<p><code>['Maine', 'Minnesota', 'Wisconsin', 'Pennsylvania', 'Michigan', 'Illinois', 'Kansas', 'Iowa']</code></p>\n<p><br>\nWhatever words nltk &amp; spacy both grabbed from the original text as <a href=\"https://en.wikipedia.org/wiki/Named_entity\" rel=\"nofollow\">named entity</a> , most of them are stored in <code>cities</code>, <code>regions</code> &amp; <code>countries</code>. But the remaining words (not recognized as place name) will be stored in <code>other</code>.</p>\n<pre><span class=\"n\">entities</span><span class=\"o\">.</span><span class=\"n\">other</span>\n</pre>\n<p><code>['winter', 'PM', 'Chippewa']</code></p>\n<h3>URL as Input</h3>\n<p>Similarly, It can grab places from urls too,</p>\n<pre><span class=\"n\">URL</span> <span class=\"o\">=</span> <span class=\"s1\">'https://edition.cnn.com/2020/01/14/americas/staggering-number-of-human-rights-defenders-killed-in-colombia-the-un-says/index.html'</span>\n<span class=\"n\">entities2</span> <span class=\"o\">=</span> <span class=\"n\">locationtagger</span><span class=\"o\">.</span><span class=\"n\">find_locations</span><span class=\"p\">(</span><span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">URL</span><span class=\"p\">)</span>\n</pre>\n<p><br>\noutputs we get:\ncountries;</p>\n<pre><span class=\"n\">entities2</span><span class=\"o\">.</span><span class=\"n\">countries</span>\n</pre>\n<p><code>['Switzerland', 'Colombia']</code></p>\n<p><br>\nregions;</p>\n<pre><span class=\"n\">entities2</span><span class=\"o\">.</span><span class=\"n\">regions</span>\n</pre>\n<p><code>['Geneva']</code></p>\n<p><br>\ncities;</p>\n<pre>entities2.cities\n</pre>\n<p><code>['Geneva', 'Colombia']</code></p>\n<p><br>\nNow, if we want to check how many times a place has been mentioned or most common places which have been mentioned in the whole page of the URL, we can have an idea about what location that page is talking about;</p>\n<p>hence, most commonly mentioned countries;</p>\n<pre><span class=\"n\">entities2</span><span class=\"o\">.</span><span class=\"n\">country_mentions</span>\n</pre>\n<p><code>[('Colombia', 3), ('Switzerland', 1), ('United States', 1), ('Mexico', 1)]</code></p>\n<p><br>\nand most commonly mentioned cities;</p>\n<pre><span class=\"n\">entities2</span><span class=\"o\">.</span><span class=\"n\">city_mentions</span>\n</pre>\n<p><code>[('Colombia', 3), ('Geneva', 1)]</code></p>\n<hr>\n<h2>Credits</h2>\n<p><a href=\"https://github.com/kaushiksoni10/locationtagger\" rel=\"nofollow\">locationtagger</a> uses data from following source for country, region &amp; city lookups,</p>\n<p><a href=\"https://dev.maxmind.com/geoip/geoip2/geolite2/\" rel=\"nofollow\">GEOLITE2 free downloadable database</a></p>\n<p>Apart from famous nlp libraries <a href=\"http://www.nltk.org/\" rel=\"nofollow\">NLTK</a> &amp; <a href=\"https://spacy.io/\" rel=\"nofollow\">spacy</a>, <a href=\"https://github.com/kaushiksoni10/locationtagger\" rel=\"nofollow\">locationtagger</a> uses following very useful libraries;</p>\n<p><a href=\"https://github.com/flyingcircusio/pycountry\" rel=\"nofollow\">pycountry</a></p>\n<p><a href=\"https://github.com/codelucas/newspaper\" rel=\"nofollow\">newspaper3k</a></p>\n\n          </div>"}, "last_serial": 6519957, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "1e753e7e13dbc789373088aefe660542", "sha256": "e6e653f8f298f66cfc6e1c3dc391d9139090a5d551a6ef5eaa61f3f017fce90d"}, "downloads": -1, "filename": "locationtagger-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "1e753e7e13dbc789373088aefe660542", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 1605742, "upload_time": "2020-01-25T20:58:55", "upload_time_iso_8601": "2020-01-25T20:58:55.734389Z", "url": "https://files.pythonhosted.org/packages/b9/39/8605ba7c1729160e98727b85d98239d234772799a766293c37a53ec42724/locationtagger-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9fbcff56b16e62baa52ce21a7f24ae37", "sha256": "f87a16a076341eceb827f1b375b714386d7b886b3fec449a9464a972955325a8"}, "downloads": -1, "filename": "locationtagger-0.0.1.tar.gz", "has_sig": false, "md5_digest": "9fbcff56b16e62baa52ce21a7f24ae37", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 1539981, "upload_time": "2020-01-25T20:59:05", "upload_time_iso_8601": "2020-01-25T20:59:05.242466Z", "url": "https://files.pythonhosted.org/packages/48/fb/9b7a5f874fe5d54b6de8aeb9ff0fd86e720a38716e7c444b1f3683601ba8/locationtagger-0.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "1e753e7e13dbc789373088aefe660542", "sha256": "e6e653f8f298f66cfc6e1c3dc391d9139090a5d551a6ef5eaa61f3f017fce90d"}, "downloads": -1, "filename": "locationtagger-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "1e753e7e13dbc789373088aefe660542", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 1605742, "upload_time": "2020-01-25T20:58:55", "upload_time_iso_8601": "2020-01-25T20:58:55.734389Z", "url": "https://files.pythonhosted.org/packages/b9/39/8605ba7c1729160e98727b85d98239d234772799a766293c37a53ec42724/locationtagger-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9fbcff56b16e62baa52ce21a7f24ae37", "sha256": "f87a16a076341eceb827f1b375b714386d7b886b3fec449a9464a972955325a8"}, "downloads": -1, "filename": "locationtagger-0.0.1.tar.gz", "has_sig": false, "md5_digest": "9fbcff56b16e62baa52ce21a7f24ae37", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 1539981, "upload_time": "2020-01-25T20:59:05", "upload_time_iso_8601": "2020-01-25T20:59:05.242466Z", "url": "https://files.pythonhosted.org/packages/48/fb/9b7a5f874fe5d54b6de8aeb9ff0fd86e720a38716e7c444b1f3683601ba8/locationtagger-0.0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:44:34 2020"}