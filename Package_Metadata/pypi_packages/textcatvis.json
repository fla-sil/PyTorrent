{"info": {"author": "cod3licious", "author_email": "cod3licious@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "textcatvis\n==========\n\nFaced with a collection of texts, sorted into the categories \"C1\"-\"C23\" and no idea what those could be? Got a dump of text documents and need to figure out what they are about and which of those you should have a closer look at?\nCode is here to help!\n\nThis repository contains tools, which help in getting a quick overview of a text dataset by creating word clouds of the relevant words for each class or identified cluster as well as code to highlight these words in the individual texts, e.g. to better understand classifier decisions. Further details can be found in the corresponding paper (short_ and long_).\n\nIf any of this code was helpful for your research, please consider citing it: ::\n\n    @article{horn2017exploring,\n      title     = {Exploring text datasets by visualizing relevant words},\n      author    = {Horn, Franziska and Arras, Leila and Montavon, Gr{\\'e}goire and M{\\\"u}ller, Klaus-Robert and Samek, Wojciech},\n      journal   = {arXiv preprint arXiv:1707.05261},\n      year      = {2017}\n    }\n\n\nor ::\n\n    @article{horn2017discovering,\n      title     = {Discovering topics in text datasets by visualizing relevant words},\n      author    = {Horn, Franziska and Arras, Leila and Montavon, Gr{\\'e}goire and M{\\\"u}ller, Klaus-Robert and Samek, Wojciech},\n      journal   = {arXiv preprint arXiv:1707.06100},\n      year      = {2017}\n    }\n\n.. _short: http://arxiv.org/abs/1707.06100\n.. _long: http://arxiv.org/abs/1707.05261\n\n\nThe code is intended for research purposes. It was programmed for Python 2.7, but should theoretically also run on newer Python 3 versions - no guarantees on this though (open an issue if you find a bug, please)!\n\nquick start\n-----------\nTo install, either download the code from here and include the textcatvis folder in your ``$PYTHONPATH`` or install (the library components only) via pip:\n\n    ``$ pip install textcatvis``\n\n\nIf you have text data available as a collection of ``.txt`` files either in a single folder or in multiple folders (in case of texts already sorted in different categories), you can call the script ``analyze_relevantwords.py`` with the path to the folder (or parent directory of multiple folders) to load this data and create word clouds for it.\n\ntextcatvis library components\n-----------------------------\n\ndependencies: numpy, scipy, matplotlib, sklearn, wordcloud, nlputils_\n\n.. _nlputils: https://github.com/cod3licious/nlputils\n\n- ``data_utils.py``: contains a function to load a text dataset (organized in a folder with subdirectories for each class containing .txt documents) in the form required by the other functions.\n- ``cluster.py``: contains a function to cluster a collection of text documents with the DBSCAN algorithm from sklearn.\n- ``check_query.py``: contains functions to formulate queries and check how often a term occurs in texts of a given category.\n- ``vis_utils.py``: contains functions to create the word clouds and highlight relevant words in individual texts.\n- ``distinctive_words.py``: contains code to examine a text dataset and identify \"distinctive words\" by comparing how often a word occurs in one category compared to all others.\n- ``visualize_relevantwords.py``: contains 3 functions to generate word clouds and highlight words in individual documents based on tf-idf features, distinctive words, as well as the classification scores obtained with a linear SVM.\n\nexamples\n--------\n\n- ``analyze_relevantwords.py``: can be called with a path to a dataset to carry out the analysis for this dataset, i.e. create word clouds for different classes etc.\n- in ``experiments_cancer.py``, the above mentioned tools are tested on the `cancer papers dataset`_ to create the results reported in the paper. (You need to download this dataset first.)\n- in ``experiments_nytimes.py``, the above mentioned tools are tested on articles downloaded with the NYTimes API. (Make sure you have an API key stored in ``nytimes_apikey.txt``.)\n\n.. _`cancer papers dataset`: https://github.com/cod3licious/cancer_papers\n\nIf you have any questions please don't hesitate to send me an `email <mailto:cod3licious@gmail.com>`_ and of course if you should find any bugs or want to contribute other improvements, pull requests are very welcome!\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/cod3licious/textcatvis", "keywords": "natural language processing text processing visualization wordcloud lrp", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "textcatvis", "package_url": "https://pypi.org/project/textcatvis/", "platform": "", "project_url": "https://pypi.org/project/textcatvis/", "project_urls": {"Homepage": "https://github.com/cod3licious/textcatvis"}, "release_url": "https://pypi.org/project/textcatvis/1.0.4/", "requires_dist": ["future", "numpy", "scipy", "scikit-learn", "matplotlib", "wordcloud", "nlputils"], "requires_python": "", "summary": "Text Dataset Categories/Clusters Visualization with Word Clouds", "version": "1.0.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>Faced with a collection of texts, sorted into the categories \u201cC1\u201d-\u201cC23\u201d and no idea what those could be? Got a dump of text documents and need to figure out what they are about and which of those you should have a closer look at?\nCode is here to help!</p>\n<p>This repository contains tools, which help in getting a quick overview of a text dataset by creating word clouds of the relevant words for each class or identified cluster as well as code to highlight these words in the individual texts, e.g. to better understand classifier decisions. Further details can be found in the corresponding paper (<a href=\"http://arxiv.org/abs/1707.06100\" rel=\"nofollow\">short</a> and <a href=\"http://arxiv.org/abs/1707.05261\" rel=\"nofollow\">long</a>).</p>\n<p>If any of this code was helpful for your research, please consider citing it:</p>\n<pre>@article{horn2017exploring,\n  title     = {Exploring text datasets by visualizing relevant words},\n  author    = {Horn, Franziska and Arras, Leila and Montavon, Gr{\\'e}goire and M{\\\"u}ller, Klaus-Robert and Samek, Wojciech},\n  journal   = {arXiv preprint arXiv:1707.05261},\n  year      = {2017}\n}\n</pre>\n<p>or</p>\n<pre>@article{horn2017discovering,\n  title     = {Discovering topics in text datasets by visualizing relevant words},\n  author    = {Horn, Franziska and Arras, Leila and Montavon, Gr{\\'e}goire and M{\\\"u}ller, Klaus-Robert and Samek, Wojciech},\n  journal   = {arXiv preprint arXiv:1707.06100},\n  year      = {2017}\n}\n</pre>\n<p>The code is intended for research purposes. It was programmed for Python 2.7, but should theoretically also run on newer Python 3 versions - no guarantees on this though (open an issue if you find a bug, please)!</p>\n<div id=\"quick-start\">\n<h2>quick start</h2>\n<p>To install, either download the code from here and include the textcatvis folder in your <tt>$PYTHONPATH</tt> or install (the library components only) via pip:</p>\n<blockquote>\n<tt>$ pip install textcatvis</tt></blockquote>\n<p>If you have text data available as a collection of <tt>.txt</tt> files either in a single folder or in multiple folders (in case of texts already sorted in different categories), you can call the script <tt>analyze_relevantwords.py</tt> with the path to the folder (or parent directory of multiple folders) to load this data and create word clouds for it.</p>\n</div>\n<div id=\"textcatvis-library-components\">\n<h2>textcatvis library components</h2>\n<p>dependencies: numpy, scipy, matplotlib, sklearn, wordcloud, <a href=\"https://github.com/cod3licious/nlputils\" rel=\"nofollow\">nlputils</a></p>\n<ul>\n<li><tt>data_utils.py</tt>: contains a function to load a text dataset (organized in a folder with subdirectories for each class containing .txt documents) in the form required by the other functions.</li>\n<li><tt>cluster.py</tt>: contains a function to cluster a collection of text documents with the DBSCAN algorithm from sklearn.</li>\n<li><tt>check_query.py</tt>: contains functions to formulate queries and check how often a term occurs in texts of a given category.</li>\n<li><tt>vis_utils.py</tt>: contains functions to create the word clouds and highlight relevant words in individual texts.</li>\n<li><tt>distinctive_words.py</tt>: contains code to examine a text dataset and identify \u201cdistinctive words\u201d by comparing how often a word occurs in one category compared to all others.</li>\n<li><tt>visualize_relevantwords.py</tt>: contains 3 functions to generate word clouds and highlight words in individual documents based on tf-idf features, distinctive words, as well as the classification scores obtained with a linear SVM.</li>\n</ul>\n</div>\n<div id=\"examples\">\n<h2>examples</h2>\n<ul>\n<li><tt>analyze_relevantwords.py</tt>: can be called with a path to a dataset to carry out the analysis for this dataset, i.e. create word clouds for different classes etc.</li>\n<li>in <tt>experiments_cancer.py</tt>, the above mentioned tools are tested on the <a href=\"https://github.com/cod3licious/cancer_papers\" rel=\"nofollow\">cancer papers dataset</a> to create the results reported in the paper. (You need to download this dataset first.)</li>\n<li>in <tt>experiments_nytimes.py</tt>, the above mentioned tools are tested on articles downloaded with the NYTimes API. (Make sure you have an API key stored in <tt>nytimes_apikey.txt</tt>.)</li>\n</ul>\n<p>If you have any questions please don\u2019t hesitate to send me an <a href=\"mailto:cod3licious%40gmail.com\">email</a> and of course if you should find any bugs or want to contribute other improvements, pull requests are very welcome!</p>\n</div>\n\n          </div>"}, "last_serial": 3881199, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "b641494216d3dcc0a5d203bd73768261", "sha256": "2e2f8dc07854ef2601e7971cfcf144b2c26bc51ed4b8ead0afcdc5be87f9b862"}, "downloads": -1, "filename": "textcatvis-1.0.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "b641494216d3dcc0a5d203bd73768261", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 16461, "upload_time": "2017-09-12T14:25:02", "upload_time_iso_8601": "2017-09-12T14:25:02.655082Z", "url": "https://files.pythonhosted.org/packages/fc/aa/94d6bba24b27186429848f34fb4d2e40f64b8ebe1e187b535193653be47f/textcatvis-1.0.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d2738b3f8b419828977879b8beac2bfb", "sha256": "c7cc1a05595ca9a184e5439f3657e33d5e30c6d905a0fa83316fa526831ca9db"}, "downloads": -1, "filename": "textcatvis-1.0.0.tar.gz", "has_sig": false, "md5_digest": "d2738b3f8b419828977879b8beac2bfb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15130, "upload_time": "2017-09-12T14:25:05", "upload_time_iso_8601": "2017-09-12T14:25:05.590692Z", "url": "https://files.pythonhosted.org/packages/5e/a1/98841efa8054dd9fd4c80637ae4117d84c169f115f0a6a5753ac68ce9fcd/textcatvis-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "fd67724dc7d9057b00d0a14a47015028", "sha256": "b73421004385ee0f9bc714ec56d332717aa858e8fcfa870b6d8d7805c564ce41"}, "downloads": -1, "filename": "textcatvis-1.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "fd67724dc7d9057b00d0a14a47015028", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 16510, "upload_time": "2018-01-11T17:08:30", "upload_time_iso_8601": "2018-01-11T17:08:30.690897Z", "url": "https://files.pythonhosted.org/packages/0b/e3/6d24c04a09e21a25a65ff7d55809ef8f91cc23bdb4a57a5fa7e1e267f11d/textcatvis-1.0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9ec4b623a224e5f14560c93674c631e1", "sha256": "626075743a0194ba0df93bdfd8dc0d96e6e36c8a9425c8170a0ba5046e2aa332"}, "downloads": -1, "filename": "textcatvis-1.0.1.tar.gz", "has_sig": false, "md5_digest": "9ec4b623a224e5f14560c93674c631e1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15121, "upload_time": "2018-01-11T17:08:32", "upload_time_iso_8601": "2018-01-11T17:08:32.132499Z", "url": "https://files.pythonhosted.org/packages/2f/44/a802dbcbbd39933708becf4672d7131744fb2cbccc6711d9b72e01f633ed/textcatvis-1.0.1.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "600f94938bef794d3b08be4ea0613fb8", "sha256": "2aa7ca92b6a0b84288d2652545faa56e1463ba6dd5f489d9f9063836abc41008"}, "downloads": -1, "filename": "textcatvis-1.0.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "600f94938bef794d3b08be4ea0613fb8", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 17016, "upload_time": "2018-05-17T11:48:58", "upload_time_iso_8601": "2018-05-17T11:48:58.133893Z", "url": "https://files.pythonhosted.org/packages/af/f4/28cb1d4862770d248205dfcd515eb71e735f6fe1522e59890ed38e0112d4/textcatvis-1.0.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f88b59463f52aa8076e697b8d5af3efa", "sha256": "8abb7abe45eae799dbbdb487402a966d7672571b97a29fd78ccfd2fda0bced7f"}, "downloads": -1, "filename": "textcatvis-1.0.2.tar.gz", "has_sig": false, "md5_digest": "f88b59463f52aa8076e697b8d5af3efa", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15654, "upload_time": "2018-05-17T11:49:00", "upload_time_iso_8601": "2018-05-17T11:49:00.022370Z", "url": "https://files.pythonhosted.org/packages/3d/70/fa1b695da585f9f2c50da9fd7c4e421f58c6272cd8308c21b35262b9ad23/textcatvis-1.0.2.tar.gz", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "47ed1a634e2a01380932f9b6a61f0011", "sha256": "3ba1a7fb4058aef6bc695a3bf4a646a92d974a28239b0aff25544949a1146844"}, "downloads": -1, "filename": "textcatvis-1.0.3-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "47ed1a634e2a01380932f9b6a61f0011", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 17150, "upload_time": "2018-05-20T16:17:18", "upload_time_iso_8601": "2018-05-20T16:17:18.839934Z", "url": "https://files.pythonhosted.org/packages/50/8b/b3956acead30451d3234a2074134ee1b066ff03f5c75357e468c36fe7ad5/textcatvis-1.0.3-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d7a5edda099affbd335a3634965264d2", "sha256": "726fd4eef04c0ae34172c221960e878695d81b3476bd6f38e4575cefdbc1cffe"}, "downloads": -1, "filename": "textcatvis-1.0.3.tar.gz", "has_sig": false, "md5_digest": "d7a5edda099affbd335a3634965264d2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15618, "upload_time": "2018-05-20T16:17:20", "upload_time_iso_8601": "2018-05-20T16:17:20.277400Z", "url": "https://files.pythonhosted.org/packages/e4/01/c9a791ba3edf71a22072bdd56e4f2f0dbb68fa9a617fee8ffa536a76aaf0/textcatvis-1.0.3.tar.gz", "yanked": false}], "1.0.4": [{"comment_text": "", "digests": {"md5": "ab107742e8cdec6b3e9e1984ebf291ef", "sha256": "ddcaec87ee77dd4bf32d0d6731bcf2e00ad38450fa4751714c1c65f7987c57f1"}, "downloads": -1, "filename": "textcatvis-1.0.4-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "ab107742e8cdec6b3e9e1984ebf291ef", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 17161, "upload_time": "2018-05-20T16:54:33", "upload_time_iso_8601": "2018-05-20T16:54:33.934828Z", "url": "https://files.pythonhosted.org/packages/15/af/9eee0dbf0bc9764fd39583fb08f95b93ea7ad6c81e22f66894589171dfb4/textcatvis-1.0.4-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "76ec5f6007d6629fed671b40c1bfc889", "sha256": "726b476bc9789ce03cba77948473e7a305d01d7d33cac97950e75c594583f496"}, "downloads": -1, "filename": "textcatvis-1.0.4.tar.gz", "has_sig": false, "md5_digest": "76ec5f6007d6629fed671b40c1bfc889", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15638, "upload_time": "2018-05-20T16:54:35", "upload_time_iso_8601": "2018-05-20T16:54:35.743151Z", "url": "https://files.pythonhosted.org/packages/c3/29/48893dbae00c28cc2f0c1c1db7c7433f6939be495aad89524fdb37c153c3/textcatvis-1.0.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ab107742e8cdec6b3e9e1984ebf291ef", "sha256": "ddcaec87ee77dd4bf32d0d6731bcf2e00ad38450fa4751714c1c65f7987c57f1"}, "downloads": -1, "filename": "textcatvis-1.0.4-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "ab107742e8cdec6b3e9e1984ebf291ef", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 17161, "upload_time": "2018-05-20T16:54:33", "upload_time_iso_8601": "2018-05-20T16:54:33.934828Z", "url": "https://files.pythonhosted.org/packages/15/af/9eee0dbf0bc9764fd39583fb08f95b93ea7ad6c81e22f66894589171dfb4/textcatvis-1.0.4-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "76ec5f6007d6629fed671b40c1bfc889", "sha256": "726b476bc9789ce03cba77948473e7a305d01d7d33cac97950e75c594583f496"}, "downloads": -1, "filename": "textcatvis-1.0.4.tar.gz", "has_sig": false, "md5_digest": "76ec5f6007d6629fed671b40c1bfc889", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15638, "upload_time": "2018-05-20T16:54:35", "upload_time_iso_8601": "2018-05-20T16:54:35.743151Z", "url": "https://files.pythonhosted.org/packages/c3/29/48893dbae00c28cc2f0c1c1db7c7433f6939be495aad89524fdb37c153c3/textcatvis-1.0.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:55:05 2020"}