{"info": {"author": "sarthfrey", "author_email": "sarth.frey@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 1 - Planning", "Intended Audience :: Developers", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python :: 3", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Software Development :: Libraries :: Python Modules", "Topic :: Software Development :: Version Control :: Git"], "description": "# Spark TensorFlow Distributor\n\nThis package helps users do distributed training with TensorFlow on their Spark clusters.\n\n## Installation\n\nThis package requires Python 3.6+, `tensorflow>=2.1.0` and `pyspark>=3.0.0` to run.\nTo install `spark-tensorflow-distributor`, run:\n\n```bash\npip install spark-tensorflow-distributor\n```\n\nThe installation does not install PySpark because for most users, PySpark is already installed.\nIf you do not have PySpark installed, you can install it directly:\n\n```bash\npip install pyspark>=3.0.*\n```\n\nNote also that in order to use many features of this package, you must set up Spark custom\nresource scheduling for GPUs on your cluster. See the Spark docs for this.\n\n## Running Tests\n\nFor integration tests, first build the master and worker images and then run the test script.\n\n```bash\ndocker-compose build --build-arg PYTHON_INSTALL_VERSION=3.7\n./tests/integration/run.sh\n```\n\nFor linting, run the following.\n\n```bash\n./tests/lint.sh\n```\n\nTo use the autoformatter, run the following.\n\n```bash\nyapf --recursive --in-place spark_tensorflow_distributor\n```\n\n## Examples\n\nRun following example code in `pyspark` shell:\n\n```python\nfrom spark_tensorflow_distributor import MirroredStrategyRunner\n\n\n# Taken from https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras\ndef train():\n    import tensorflow_datasets as tfds\n    import tensorflow as tf\n    BUFFER_SIZE = 10000\n    BATCH_SIZE = 64\n\n    def make_datasets_unbatched():\n        # Scaling MNIST data from (0, 255] to (0., 1.]\n        def scale(image, label):\n            image = tf.cast(image, tf.float32)\n            image /= 255\n            return image, label\n        datasets, info = tfds.load(\n            name='mnist',\n            with_info=True,\n            as_supervised=True,\n        )\n        return datasets['train'].map(scale).cache().shuffle(BUFFER_SIZE)\n\n    def build_and_compile_cnn_model():\n        model = tf.keras.Sequential([\n            tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n            tf.keras.layers.MaxPooling2D(),\n            tf.keras.layers.Flatten(),\n            tf.keras.layers.Dense(64, activation='relu'),\n            tf.keras.layers.Dense(10, activation='softmax'),\n        ])\n        model.compile(\n            loss=tf.keras.losses.sparse_categorical_crossentropy,\n            optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n            metrics=['accuracy'],\n        )\n        return model\n\n    GLOBAL_BATCH_SIZE = 64 * 8\n    train_datasets = make_datasets_unbatched().batch(GLOBAL_BATCH_SIZE).repeat()\n    options = tf.data.Options()\n    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n    train_datasets = train_datasets.with_options(options)\n    multi_worker_model = build_and_compile_cnn_model()\n    multi_worker_model.fit(x=train_datasets, epochs=3, steps_per_epoch=5)\n    return tf.config.experimental.list_physical_devices('GPU')\n\nMirroredStrategyRunner(num_slots=4).run(train)\n```\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/tensorflow/ecosystem/tree/master/spark/spark-tensorflow-distributor", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "spark-tensorflow-distributor", "package_url": "https://pypi.org/project/spark-tensorflow-distributor/", "platform": "", "project_url": "https://pypi.org/project/spark-tensorflow-distributor/", "project_urls": {"Homepage": "https://github.com/tensorflow/ecosystem/tree/master/spark/spark-tensorflow-distributor"}, "release_url": "https://pypi.org/project/spark-tensorflow-distributor/0.0.3/", "requires_dist": ["tensorflow (>=2.1.0)"], "requires_python": ">=3.6", "summary": "This package helps users do distributed training with TensorFlow on their Spark clusters.", "version": "0.0.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Spark TensorFlow Distributor</h1>\n<p>This package helps users do distributed training with TensorFlow on their Spark clusters.</p>\n<h2>Installation</h2>\n<p>This package requires Python 3.6+, <code>tensorflow&gt;=2.1.0</code> and <code>pyspark&gt;=3.0.0</code> to run.\nTo install <code>spark-tensorflow-distributor</code>, run:</p>\n<pre>pip install spark-tensorflow-distributor\n</pre>\n<p>The installation does not install PySpark because for most users, PySpark is already installed.\nIf you do not have PySpark installed, you can install it directly:</p>\n<pre>pip install pyspark&gt;<span class=\"o\">=</span><span class=\"m\">3</span>.0.*\n</pre>\n<p>Note also that in order to use many features of this package, you must set up Spark custom\nresource scheduling for GPUs on your cluster. See the Spark docs for this.</p>\n<h2>Running Tests</h2>\n<p>For integration tests, first build the master and worker images and then run the test script.</p>\n<pre>docker-compose build --build-arg <span class=\"nv\">PYTHON_INSTALL_VERSION</span><span class=\"o\">=</span><span class=\"m\">3</span>.7\n./tests/integration/run.sh\n</pre>\n<p>For linting, run the following.</p>\n<pre>./tests/lint.sh\n</pre>\n<p>To use the autoformatter, run the following.</p>\n<pre>yapf --recursive --in-place spark_tensorflow_distributor\n</pre>\n<h2>Examples</h2>\n<p>Run following example code in <code>pyspark</code> shell:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">spark_tensorflow_distributor</span> <span class=\"kn\">import</span> <span class=\"n\">MirroredStrategyRunner</span>\n\n\n<span class=\"c1\"># Taken from https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras</span>\n<span class=\"k\">def</span> <span class=\"nf\">train</span><span class=\"p\">():</span>\n    <span class=\"kn\">import</span> <span class=\"nn\">tensorflow_datasets</span> <span class=\"k\">as</span> <span class=\"nn\">tfds</span>\n    <span class=\"kn\">import</span> <span class=\"nn\">tensorflow</span> <span class=\"k\">as</span> <span class=\"nn\">tf</span>\n    <span class=\"n\">BUFFER_SIZE</span> <span class=\"o\">=</span> <span class=\"mi\">10000</span>\n    <span class=\"n\">BATCH_SIZE</span> <span class=\"o\">=</span> <span class=\"mi\">64</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">make_datasets_unbatched</span><span class=\"p\">():</span>\n        <span class=\"c1\"># Scaling MNIST data from (0, 255] to (0., 1.]</span>\n        <span class=\"k\">def</span> <span class=\"nf\">scale</span><span class=\"p\">(</span><span class=\"n\">image</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"p\">):</span>\n            <span class=\"n\">image</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">cast</span><span class=\"p\">(</span><span class=\"n\">image</span><span class=\"p\">,</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n            <span class=\"n\">image</span> <span class=\"o\">/=</span> <span class=\"mi\">255</span>\n            <span class=\"k\">return</span> <span class=\"n\">image</span><span class=\"p\">,</span> <span class=\"n\">label</span>\n        <span class=\"n\">datasets</span><span class=\"p\">,</span> <span class=\"n\">info</span> <span class=\"o\">=</span> <span class=\"n\">tfds</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span>\n            <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'mnist'</span><span class=\"p\">,</span>\n            <span class=\"n\">with_info</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n            <span class=\"n\">as_supervised</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n        <span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">datasets</span><span class=\"p\">[</span><span class=\"s1\">'train'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">map</span><span class=\"p\">(</span><span class=\"n\">scale</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">shuffle</span><span class=\"p\">(</span><span class=\"n\">BUFFER_SIZE</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">build_and_compile_cnn_model</span><span class=\"p\">():</span>\n        <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">([</span>\n            <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Conv2D</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">'relu'</span><span class=\"p\">,</span> <span class=\"n\">input_shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)),</span>\n            <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">MaxPooling2D</span><span class=\"p\">(),</span>\n            <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Flatten</span><span class=\"p\">(),</span>\n            <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">'relu'</span><span class=\"p\">),</span>\n            <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">'softmax'</span><span class=\"p\">),</span>\n        <span class=\"p\">])</span>\n        <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span>\n            <span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">losses</span><span class=\"o\">.</span><span class=\"n\">sparse_categorical_crossentropy</span><span class=\"p\">,</span>\n            <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">optimizers</span><span class=\"o\">.</span><span class=\"n\">SGD</span><span class=\"p\">(</span><span class=\"n\">learning_rate</span><span class=\"o\">=</span><span class=\"mf\">0.001</span><span class=\"p\">),</span>\n            <span class=\"n\">metrics</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'accuracy'</span><span class=\"p\">],</span>\n        <span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">model</span>\n\n    <span class=\"n\">GLOBAL_BATCH_SIZE</span> <span class=\"o\">=</span> <span class=\"mi\">64</span> <span class=\"o\">*</span> <span class=\"mi\">8</span>\n    <span class=\"n\">train_datasets</span> <span class=\"o\">=</span> <span class=\"n\">make_datasets_unbatched</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">batch</span><span class=\"p\">(</span><span class=\"n\">GLOBAL_BATCH_SIZE</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">repeat</span><span class=\"p\">()</span>\n    <span class=\"n\">options</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Options</span><span class=\"p\">()</span>\n    <span class=\"n\">options</span><span class=\"o\">.</span><span class=\"n\">experimental_distribute</span><span class=\"o\">.</span><span class=\"n\">auto_shard_policy</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">experimental</span><span class=\"o\">.</span><span class=\"n\">AutoShardPolicy</span><span class=\"o\">.</span><span class=\"n\">DATA</span>\n    <span class=\"n\">train_datasets</span> <span class=\"o\">=</span> <span class=\"n\">train_datasets</span><span class=\"o\">.</span><span class=\"n\">with_options</span><span class=\"p\">(</span><span class=\"n\">options</span><span class=\"p\">)</span>\n    <span class=\"n\">multi_worker_model</span> <span class=\"o\">=</span> <span class=\"n\">build_and_compile_cnn_model</span><span class=\"p\">()</span>\n    <span class=\"n\">multi_worker_model</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">=</span><span class=\"n\">train_datasets</span><span class=\"p\">,</span> <span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">steps_per_epoch</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"o\">.</span><span class=\"n\">experimental</span><span class=\"o\">.</span><span class=\"n\">list_physical_devices</span><span class=\"p\">(</span><span class=\"s1\">'GPU'</span><span class=\"p\">)</span>\n\n<span class=\"n\">MirroredStrategyRunner</span><span class=\"p\">(</span><span class=\"n\">num_slots</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"p\">)</span>\n</pre>\n\n          </div>"}, "last_serial": 7115140, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "958660042e07481ad4226063ebac54a7", "sha256": "de0b1aa75110826d774298a02bc30189f97b9b98f9695adc131b1efb36f4c287"}, "downloads": -1, "filename": "spark_tensorflow_distributor-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "958660042e07481ad4226063ebac54a7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 7729, "upload_time": "2020-04-01T22:05:45", "upload_time_iso_8601": "2020-04-01T22:05:45.236964Z", "url": "https://files.pythonhosted.org/packages/f7/86/7a7d542e4541ea0f89a280c8423d3eec4528a7a8ebff034124bc5b108ef3/spark_tensorflow_distributor-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5a8e544d1894dba6a26db8bac970c4e9", "sha256": "73a361b9410f105537c853f452a45511fd59c0afc228871967e2060ce3cac26b"}, "downloads": -1, "filename": "spark_tensorflow_distributor-0.0.1.tar.gz", "has_sig": false, "md5_digest": "5a8e544d1894dba6a26db8bac970c4e9", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 7223, "upload_time": "2020-04-01T22:05:47", "upload_time_iso_8601": "2020-04-01T22:05:47.658171Z", "url": "https://files.pythonhosted.org/packages/71/92/63018f588da56949ba67f859888bd2e62cf3db8b25f172e523e1355e4604/spark_tensorflow_distributor-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "bb02653e9cc7f52cd289ee031e879017", "sha256": "3d4c3e004f0e64dfa3d224bd19361af1fc66a084e51487d8f6d1f52a204d6a07"}, "downloads": -1, "filename": "spark_tensorflow_distributor-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "bb02653e9cc7f52cd289ee031e879017", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 8842, "upload_time": "2020-04-24T00:16:29", "upload_time_iso_8601": "2020-04-24T00:16:29.185618Z", "url": "https://files.pythonhosted.org/packages/1d/e2/b51226113c1c60e88f1eefd17b74356c1aba93e460b7047120db3277e80b/spark_tensorflow_distributor-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f6681f8616b16309c23623af64151d96", "sha256": "08f34ace5dd5107de924b8cbbfbb37fad8e98edec30d1e550d6c9d9b001f6ce8"}, "downloads": -1, "filename": "spark_tensorflow_distributor-0.0.2.tar.gz", "has_sig": false, "md5_digest": "f6681f8616b16309c23623af64151d96", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 8419, "upload_time": "2020-04-24T00:16:30", "upload_time_iso_8601": "2020-04-24T00:16:30.338084Z", "url": "https://files.pythonhosted.org/packages/ce/2b/c99f9cee88b83ef6b5e4d28d8581fce6a87381deb41bdc947c20255f7db4/spark_tensorflow_distributor-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "a7d8c6dd8f9940872ee1e70d1724af8f", "sha256": "188317766a0db2a6f61f2af4423241cb9231e57e16a82f60a618b20d5eb6fbd1"}, "downloads": -1, "filename": "spark_tensorflow_distributor-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "a7d8c6dd8f9940872ee1e70d1724af8f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 8849, "upload_time": "2020-04-24T00:27:37", "upload_time_iso_8601": "2020-04-24T00:27:37.750259Z", "url": "https://files.pythonhosted.org/packages/c6/d7/97fee5bfba62cac047ca928bee5e0ac1bfd98aed0b74481aadcbd1ef1285/spark_tensorflow_distributor-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8432ac961e6d98b96c7836568487783b", "sha256": "50434b9705f3e52817dda64d9f648869ef8f602f55c6d8ba083899e280d44368"}, "downloads": -1, "filename": "spark_tensorflow_distributor-0.0.3.tar.gz", "has_sig": false, "md5_digest": "8432ac961e6d98b96c7836568487783b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 8424, "upload_time": "2020-04-24T00:27:38", "upload_time_iso_8601": "2020-04-24T00:27:38.794161Z", "url": "https://files.pythonhosted.org/packages/fc/22/fe3ec5196b2d9a2c51841844266bfd866dbe89f2afdf723de8f94447807b/spark_tensorflow_distributor-0.0.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "a7d8c6dd8f9940872ee1e70d1724af8f", "sha256": "188317766a0db2a6f61f2af4423241cb9231e57e16a82f60a618b20d5eb6fbd1"}, "downloads": -1, "filename": "spark_tensorflow_distributor-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "a7d8c6dd8f9940872ee1e70d1724af8f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 8849, "upload_time": "2020-04-24T00:27:37", "upload_time_iso_8601": "2020-04-24T00:27:37.750259Z", "url": "https://files.pythonhosted.org/packages/c6/d7/97fee5bfba62cac047ca928bee5e0ac1bfd98aed0b74481aadcbd1ef1285/spark_tensorflow_distributor-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8432ac961e6d98b96c7836568487783b", "sha256": "50434b9705f3e52817dda64d9f648869ef8f602f55c6d8ba083899e280d44368"}, "downloads": -1, "filename": "spark_tensorflow_distributor-0.0.3.tar.gz", "has_sig": false, "md5_digest": "8432ac961e6d98b96c7836568487783b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 8424, "upload_time": "2020-04-24T00:27:38", "upload_time_iso_8601": "2020-04-24T00:27:38.794161Z", "url": "https://files.pythonhosted.org/packages/fc/22/fe3ec5196b2d9a2c51841844266bfd866dbe89f2afdf723de8f94447807b/spark_tensorflow_distributor-0.0.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:05:52 2020"}