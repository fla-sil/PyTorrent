{"info": {"author": "Derrick Gilland", "author_email": "dgilland@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules", "Topic :: System :: Filesystems"], "description": "******\nHashFS\n******\n\n|version| |travis| |coveralls| |license|\n\n\nHashFS is a content-addressable file management system. What does that mean? Simply, that HashFS manages a directory where files are saved based on the file's hash.\n\nTypical use cases for this kind of system are ones where:\n\n- Files are written once and never change (e.g. image storage).\n- It's desirable to have no duplicate files (e.g. user uploads).\n- File metadata is stored elsewhere (e.g. in a database).\n\n\nFeatures\n========\n\n- Files are stored once and never duplicated.\n- Uses an efficient folder structure optimized for a large number of files. File paths are based on the content hash and are nested based on the first ``n`` number of characters.\n- Can save files from local file paths or readable objects (open file handlers, IO buffers, etc).\n- Able to repair the root folder by reindexing all files. Useful if the hashing algorithm or folder structure options change or to initialize existing files.\n- Supports any hashing algorithm available via ``hashlib.new``.\n- Python 2.7+/3.3+ compatible.\n\n\nLinks\n=====\n\n- Project: https://github.com/dgilland/hashfs\n- Documentation: http://hashfs.readthedocs.org\n- PyPI: https://pypi.python.org/pypi/hashfs/\n- TravisCI: https://travis-ci.org/dgilland/hashfs\n\n\nQuickstart\n==========\n\nInstall using pip:\n\n\n::\n\n    pip install hashfs\n\n\nInitialization\n--------------\n\n.. code-block:: python\n\n    from hashfs import HashFS\n\n\nDesignate a root folder for ``HashFS``. If the folder doesn't already exist, it will be created.\n\n\n.. code-block:: python\n\n    # Set the `depth` to the number of subfolders the file's hash should be split when saving.\n    # Set the `width` to the desired width of each subfolder.\n    fs = HashFS('temp_hashfs', depth=4, width=1, algorithm='sha256')\n\n    # With depth=4 and width=1, files will be saved in the following pattern:\n    # temp_hashfs/a/b/c/d/efghijklmnopqrstuvwxyz\n\n    # With depth=3 and width=2, files will be saved in the following pattern:\n    # temp_hashfs/ab/cd/ef/ghijklmnopqrstuvwxyz\n\n\n**NOTE:** The ``algorithm`` value should be a valid string argument to ``hashlib.new()``.\n\n\nBasic Usage\n===========\n\n``HashFS`` supports basic file storage, retrieval, and removal as well as some more advanced features like file repair.\n\n\nStoring Content\n---------------\n\nAdd content to the folder using either readable objects (e.g. ``StringIO``) or file paths (e.g. ``'a/path/to/some/file'``).\n\n\n.. code-block:: python\n\n    from io import StringIO\n\n    some_content = StringIO('some content')\n\n    address = fs.put(some_content)\n\n    # Or if you'd like to save the file with an extension...\n    address = fs.put(some_content, '.txt')\n\n    # The id of the file (i.e. the hexdigest of its contents).\n    address.id\n\n    # The absolute path where the file was saved.\n    address.abspath\n\n    # The path relative to fs.root.\n    address.relpath\n\n    # Whether the file previously existed.\n    address.is_duplicate\n\n\nRetrieving File Address\n-----------------------\n\nGet a file's ``HashAddress`` by address ID or path. This address would be identical to the address returned by ``put()``.\n\n.. code-block:: python\n\n    assert fs.get(address.id) == address\n    assert fs.get(address.relpath) == address\n    assert fs.get(address.abspath) == address\n    assert fs.get('invalid') is None\n\n\nRetrieving Content\n------------------\n\nGet a ``BufferedReader`` handler for an existing file by address ID or path.\n\n\n.. code-block:: python\n\n    fileio = fs.open(address.id)\n\n    # Or using the full path...\n    fileio = fs.open(address.abspath)\n\n    # Or using a path relative to fs.root\n    fileio = fs.open(address.relpath)\n\n\n**NOTE:** When getting a file that was saved with an extension, it's not necessary to supply the extension. Extensions are ignored when looking for a file based on the ID or path.\n\n\nRemoving Content\n----------------\n\nDelete a file by address ID or path.\n\n\n.. code-block:: python\n\n    fs.delete(address.id)\n    fs.delete(address.abspath)\n    fs.delete(address.relpath)\n\n\n**NOTE:** When a file is deleted, any parent directories above the file will also be deleted if they are empty directories.\n\n\nAdvanced Usage\n==============\n\nBelow are some of the more advanced features of ``HashFS``.\n\n\nRepairing Files\n---------------\n\nThe ``HashFS`` files may not always be in sync with it's ``depth``, ``width``, or ``algorithm`` settings (e.g. if ``HashFS`` takes ownership of a directory that wasn't previously stored using content hashes or if the ``HashFS`` settings change). These files can be easily reindexed using ``repair()``.\n\n\n.. code-block:: python\n\n    repaired = fs.repair()\n\n    # Or if you want to drop file extensions...\n    repaired = fs.repair(extensions=False)\n\n\n**WARNING:** It's recommended that a backup of the directory be made before repairing just in case something goes wrong.\n\n\nWalking Corrupted Files\n-----------------------\n\nInstead of actually repairing the files, you can iterate over them for custom processing.\n\n\n.. code-block:: python\n\n    for corrupted_path, expected_address in fs.corrupted():\n        # do something\n\n\n**WARNING:** ``HashFS.corrupted()`` is a generator so be aware that modifying the file system while iterating could have unexpected results.\n\n\nWalking All Files\n-----------------\n\nIterate over files.\n\n\n.. code-block:: python\n\n    for file in fs.files():\n        # do something\n\n    # Or using the class' iter method...\n    for file in fs:\n        # do something\n\n\nIterate over folders that contain files (i.e. ignore the nested subfolders that only contain folders).\n\n\n.. code-block:: python\n\n    for folder in fs.folders():\n        # do something\n\n\nComputing Size\n--------------\n\nCompute the size in bytes of all files in the ``root`` directory.\n\n\n.. code-block:: python\n\n    total_bytes = fs.size()\n\n\nCount the total number of files.\n\n\n.. code-block:: python\n\n    total_files = fs.count()\n\n    # Or via len()...\n    total_files = len(fs)\n\n\nFor more details, please see the full documentation at http://hashfs.readthedocs.org.\n\n\n\n.. |version| image:: http://img.shields.io/pypi/v/hashfs.svg?style=flat-square\n    :target: https://pypi.python.org/pypi/hashfs/\n\n.. |travis| image:: http://img.shields.io/travis/dgilland/hashfs/master.svg?style=flat-square\n    :target: https://travis-ci.org/dgilland/hashfs\n\n.. |coveralls| image:: http://img.shields.io/coveralls/dgilland/hashfs/master.svg?style=flat-square\n    :target: https://coveralls.io/r/dgilland/hashfs\n\n.. |license| image:: http://img.shields.io/pypi/l/hashfs.svg?style=flat-square\n    :target: https://pypi.python.org/pypi/hashfs/\n\n\nChangelog\n=========\n\n\nv0.7.2 (2019-10-24)\n-------------------\n\n- Fix out-of-memory issue when computing file ID hashes of large files.\n\n\nv0.7.1 (2018-10-13)\n-------------------\n\n- Replace usage of ``distutils.dir_util.mkpath`` with ``os.path.makedirs``.\n\n\nv0.7.0 (2016-04-19)\n-------------------\n\n- Use ``shutil.move`` instead of ``shutil.copy`` to move temporary file created during ``put`` operation to ``HashFS`` directory.\n\n\nv0.6.0 (2015-10-19)\n-------------------\n\n- Add faster ``scandir`` package for iterating over files/folders when platform is Python < 3.5. Scandir implementation was added to ``os`` module starting with Python 3.5.\n\n\nv0.5.0 (2015-07-02)\n-------------------\n\n- Rename private method ``HashFS.copy`` to ``HashFS._copy``.\n- Add ``is_duplicate`` attribute to ``HashAddress``.\n- Make ``HashFS.put()`` return ``HashAddress`` with ``is_duplicate=True`` when file with same hash already exists on disk.\n\n\nv0.4.0 (2015-06-03)\n-------------------\n\n- Add ``HashFS.size()`` method that returns the size of all files in bytes.\n- Add ``HashFS.count()``/``HashFS.__len__()`` methods that return the count of all files.\n- Add ``HashFS.__iter__()`` method to support iteration. Proxies to ``HashFS.files()``.\n- Add ``HashFS.__contains__()`` method to support ``in`` operator. Proxies to ``HashFS.exists()``.\n- Don't create the root directory (if it doesn't exist) until at least one file has been added.\n- Fix ``HashFS.repair()`` not using ``extensions`` argument properly.\n\n\nv0.3.0 (2015-06-02)\n-------------------\n\n- Rename ``HashFS.length`` parameter/property to ``width``. (**breaking change**)\n\n\nv0.2.0 (2015-05-29)\n-------------------\n\n- Rename ``HashFS.get`` to ``HashFS.open``. (**breaking change**)\n- Add ``HashFS.get()`` method that returns a ``HashAddress`` or ``None`` given a file ID or path.\n\n\nv0.1.0 (2015-05-28)\n-------------------\n\n- Add ``HashFS.get()`` method that retrieves a reader object given a file ID or path.\n- Add ``HashFS.delete()`` method that deletes a file ID or path.\n- Add ``HashFS.folders()`` method that returns the folder paths that directly contain files (i.e. subpaths that only contain folders are ignored).\n- Add ``HashFS.detokenize()`` method that returns the file ID contained in a file path.\n- Add ``HashFS.repair()`` method that reindexes any files under root directory whose file path doesn't not match its tokenized file ID.\n- Rename ``Address`` classs to ``HashAddress``. (**breaking change**)\n- Rename ``HashAddress.digest`` to ``HashAddress.id``. (**breaking change**)\n- Rename ``HashAddress.path`` to ``HashAddress.abspath``. (**breaking change**)\n- Add ``HashAddress.relpath`` which represents path relative to ``HashFS.root``.\n\n\nv0.0.1 (2015-05-27)\n-------------------\n\n- First release.\n- Add ``HashFS`` class.\n- Add ``HashFS.put()`` method that saves a file path or file-like object by content hash.\n- Add ``HashFS.files()`` method that returns all files under root directory.\n- Add ``HashFS.exists()`` which checks either a file hash or file path for existence.\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/dgilland/hashfs", "keywords": "hashfs hash file system content addressable fixed storage", "license": "MIT License", "maintainer": "", "maintainer_email": "", "name": "hashfs", "package_url": "https://pypi.org/project/hashfs/", "platform": "", "project_url": "https://pypi.org/project/hashfs/", "project_urls": {"Homepage": "https://github.com/dgilland/hashfs"}, "release_url": "https://pypi.org/project/hashfs/0.7.2/", "requires_dist": null, "requires_python": "", "summary": "A content-addressable file management system.", "version": "0.7.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://pypi.python.org/pypi/hashfs/\" rel=\"nofollow\"><img alt=\"version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/70c5fe3d8a2599d71932d01d15a6a91829f8f34f/687474703a2f2f696d672e736869656c64732e696f2f707970692f762f6861736866732e7376673f7374796c653d666c61742d737175617265\"></a> <a href=\"https://travis-ci.org/dgilland/hashfs\" rel=\"nofollow\"><img alt=\"travis\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2acca4bed73830fd729f76a74b1666e398a0943d/687474703a2f2f696d672e736869656c64732e696f2f7472617669732f6467696c6c616e642f6861736866732f6d61737465722e7376673f7374796c653d666c61742d737175617265\"></a> <a href=\"https://coveralls.io/r/dgilland/hashfs\" rel=\"nofollow\"><img alt=\"coveralls\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9f7d02caa5196d34a5d07f4a5da139764a77625e/687474703a2f2f696d672e736869656c64732e696f2f636f766572616c6c732f6467696c6c616e642f6861736866732f6d61737465722e7376673f7374796c653d666c61742d737175617265\"></a> <a href=\"https://pypi.python.org/pypi/hashfs/\" rel=\"nofollow\"><img alt=\"license\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/32a1f1a0584b436ed0dd1376f75c7288802d7c15/687474703a2f2f696d672e736869656c64732e696f2f707970692f6c2f6861736866732e7376673f7374796c653d666c61742d737175617265\"></a></p>\n<p>HashFS is a content-addressable file management system. What does that mean? Simply, that HashFS manages a directory where files are saved based on the file\u2019s hash.</p>\n<p>Typical use cases for this kind of system are ones where:</p>\n<ul>\n<li>Files are written once and never change (e.g. image storage).</li>\n<li>It\u2019s desirable to have no duplicate files (e.g. user uploads).</li>\n<li>File metadata is stored elsewhere (e.g. in a database).</li>\n</ul>\n<div id=\"features\">\n<h2>Features</h2>\n<ul>\n<li>Files are stored once and never duplicated.</li>\n<li>Uses an efficient folder structure optimized for a large number of files. File paths are based on the content hash and are nested based on the first <tt>n</tt> number of characters.</li>\n<li>Can save files from local file paths or readable objects (open file handlers, IO buffers, etc).</li>\n<li>Able to repair the root folder by reindexing all files. Useful if the hashing algorithm or folder structure options change or to initialize existing files.</li>\n<li>Supports any hashing algorithm available via <tt>hashlib.new</tt>.</li>\n<li>Python 2.7+/3.3+ compatible.</li>\n</ul>\n</div>\n<div id=\"links\">\n<h2>Links</h2>\n<ul>\n<li>Project: <a href=\"https://github.com/dgilland/hashfs\" rel=\"nofollow\">https://github.com/dgilland/hashfs</a></li>\n<li>Documentation: <a href=\"http://hashfs.readthedocs.org\" rel=\"nofollow\">http://hashfs.readthedocs.org</a></li>\n<li>PyPI: <a href=\"https://pypi.python.org/pypi/hashfs/\" rel=\"nofollow\">https://pypi.python.org/pypi/hashfs/</a></li>\n<li>TravisCI: <a href=\"https://travis-ci.org/dgilland/hashfs\" rel=\"nofollow\">https://travis-ci.org/dgilland/hashfs</a></li>\n</ul>\n</div>\n<div id=\"quickstart\">\n<h2>Quickstart</h2>\n<p>Install using pip:</p>\n<pre>pip install hashfs\n</pre>\n<div id=\"initialization\">\n<h3>Initialization</h3>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">hashfs</span> <span class=\"kn\">import</span> <span class=\"n\">HashFS</span>\n</pre>\n<p>Designate a root folder for <tt>HashFS</tt>. If the folder doesn\u2019t already exist, it will be created.</p>\n<pre><span class=\"c1\"># Set the `depth` to the number of subfolders the file's hash should be split when saving.</span>\n<span class=\"c1\"># Set the `width` to the desired width of each subfolder.</span>\n<span class=\"n\">fs</span> <span class=\"o\">=</span> <span class=\"n\">HashFS</span><span class=\"p\">(</span><span class=\"s1\">'temp_hashfs'</span><span class=\"p\">,</span> <span class=\"n\">depth</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">width</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">algorithm</span><span class=\"o\">=</span><span class=\"s1\">'sha256'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># With depth=4 and width=1, files will be saved in the following pattern:</span>\n<span class=\"c1\"># temp_hashfs/a/b/c/d/efghijklmnopqrstuvwxyz</span>\n\n<span class=\"c1\"># With depth=3 and width=2, files will be saved in the following pattern:</span>\n<span class=\"c1\"># temp_hashfs/ab/cd/ef/ghijklmnopqrstuvwxyz</span>\n</pre>\n<p><strong>NOTE:</strong> The <tt>algorithm</tt> value should be a valid string argument to <tt>hashlib.new()</tt>.</p>\n</div>\n</div>\n<div id=\"basic-usage\">\n<h2>Basic Usage</h2>\n<p><tt>HashFS</tt> supports basic file storage, retrieval, and removal as well as some more advanced features like file repair.</p>\n<div id=\"storing-content\">\n<h3>Storing Content</h3>\n<p>Add content to the folder using either readable objects (e.g. <tt>StringIO</tt>) or file paths (e.g. <tt>'a/path/to/some/file'</tt>).</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">io</span> <span class=\"kn\">import</span> <span class=\"n\">StringIO</span>\n\n<span class=\"n\">some_content</span> <span class=\"o\">=</span> <span class=\"n\">StringIO</span><span class=\"p\">(</span><span class=\"s1\">'some content'</span><span class=\"p\">)</span>\n\n<span class=\"n\">address</span> <span class=\"o\">=</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">put</span><span class=\"p\">(</span><span class=\"n\">some_content</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Or if you'd like to save the file with an extension...</span>\n<span class=\"n\">address</span> <span class=\"o\">=</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">put</span><span class=\"p\">(</span><span class=\"n\">some_content</span><span class=\"p\">,</span> <span class=\"s1\">'.txt'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># The id of the file (i.e. the hexdigest of its contents).</span>\n<span class=\"n\">address</span><span class=\"o\">.</span><span class=\"n\">id</span>\n\n<span class=\"c1\"># The absolute path where the file was saved.</span>\n<span class=\"n\">address</span><span class=\"o\">.</span><span class=\"n\">abspath</span>\n\n<span class=\"c1\"># The path relative to fs.root.</span>\n<span class=\"n\">address</span><span class=\"o\">.</span><span class=\"n\">relpath</span>\n\n<span class=\"c1\"># Whether the file previously existed.</span>\n<span class=\"n\">address</span><span class=\"o\">.</span><span class=\"n\">is_duplicate</span>\n</pre>\n</div>\n<div id=\"retrieving-file-address\">\n<h3>Retrieving File Address</h3>\n<p>Get a file\u2019s <tt>HashAddress</tt> by address ID or path. This address would be identical to the address returned by <tt>put()</tt>.</p>\n<pre><span class=\"k\">assert</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">address</span><span class=\"o\">.</span><span class=\"n\">id</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"n\">address</span>\n<span class=\"k\">assert</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">address</span><span class=\"o\">.</span><span class=\"n\">relpath</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"n\">address</span>\n<span class=\"k\">assert</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">address</span><span class=\"o\">.</span><span class=\"n\">abspath</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"n\">address</span>\n<span class=\"k\">assert</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'invalid'</span><span class=\"p\">)</span> <span class=\"ow\">is</span> <span class=\"kc\">None</span>\n</pre>\n</div>\n<div id=\"retrieving-content\">\n<h3>Retrieving Content</h3>\n<p>Get a <tt>BufferedReader</tt> handler for an existing file by address ID or path.</p>\n<pre><span class=\"n\">fileio</span> <span class=\"o\">=</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">open</span><span class=\"p\">(</span><span class=\"n\">address</span><span class=\"o\">.</span><span class=\"n\">id</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Or using the full path...</span>\n<span class=\"n\">fileio</span> <span class=\"o\">=</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">open</span><span class=\"p\">(</span><span class=\"n\">address</span><span class=\"o\">.</span><span class=\"n\">abspath</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Or using a path relative to fs.root</span>\n<span class=\"n\">fileio</span> <span class=\"o\">=</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">open</span><span class=\"p\">(</span><span class=\"n\">address</span><span class=\"o\">.</span><span class=\"n\">relpath</span><span class=\"p\">)</span>\n</pre>\n<p><strong>NOTE:</strong> When getting a file that was saved with an extension, it\u2019s not necessary to supply the extension. Extensions are ignored when looking for a file based on the ID or path.</p>\n</div>\n<div id=\"removing-content\">\n<h3>Removing Content</h3>\n<p>Delete a file by address ID or path.</p>\n<pre><span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">delete</span><span class=\"p\">(</span><span class=\"n\">address</span><span class=\"o\">.</span><span class=\"n\">id</span><span class=\"p\">)</span>\n<span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">delete</span><span class=\"p\">(</span><span class=\"n\">address</span><span class=\"o\">.</span><span class=\"n\">abspath</span><span class=\"p\">)</span>\n<span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">delete</span><span class=\"p\">(</span><span class=\"n\">address</span><span class=\"o\">.</span><span class=\"n\">relpath</span><span class=\"p\">)</span>\n</pre>\n<p><strong>NOTE:</strong> When a file is deleted, any parent directories above the file will also be deleted if they are empty directories.</p>\n</div>\n</div>\n<div id=\"advanced-usage\">\n<h2>Advanced Usage</h2>\n<p>Below are some of the more advanced features of <tt>HashFS</tt>.</p>\n<div id=\"repairing-files\">\n<h3>Repairing Files</h3>\n<p>The <tt>HashFS</tt> files may not always be in sync with it\u2019s <tt>depth</tt>, <tt>width</tt>, or <tt>algorithm</tt> settings (e.g. if <tt>HashFS</tt> takes ownership of a directory that wasn\u2019t previously stored using content hashes or if the <tt>HashFS</tt> settings change). These files can be easily reindexed using <tt>repair()</tt>.</p>\n<pre><span class=\"n\">repaired</span> <span class=\"o\">=</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">repair</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># Or if you want to drop file extensions...</span>\n<span class=\"n\">repaired</span> <span class=\"o\">=</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">repair</span><span class=\"p\">(</span><span class=\"n\">extensions</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n</pre>\n<p><strong>WARNING:</strong> It\u2019s recommended that a backup of the directory be made before repairing just in case something goes wrong.</p>\n</div>\n<div id=\"walking-corrupted-files\">\n<h3>Walking Corrupted Files</h3>\n<p>Instead of actually repairing the files, you can iterate over them for custom processing.</p>\n<pre><span class=\"k\">for</span> <span class=\"n\">corrupted_path</span><span class=\"p\">,</span> <span class=\"n\">expected_address</span> <span class=\"ow\">in</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">corrupted</span><span class=\"p\">():</span>\n    <span class=\"c1\"># do something</span>\n</pre>\n<p><strong>WARNING:</strong> <tt>HashFS.corrupted()</tt> is a generator so be aware that modifying the file system while iterating could have unexpected results.</p>\n</div>\n<div id=\"walking-all-files\">\n<h3>Walking All Files</h3>\n<p>Iterate over files.</p>\n<pre><span class=\"k\">for</span> <span class=\"n\">file</span> <span class=\"ow\">in</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">files</span><span class=\"p\">():</span>\n    <span class=\"c1\"># do something</span>\n\n<span class=\"c1\"># Or using the class' iter method...</span>\n<span class=\"k\">for</span> <span class=\"n\">file</span> <span class=\"ow\">in</span> <span class=\"n\">fs</span><span class=\"p\">:</span>\n    <span class=\"c1\"># do something</span>\n</pre>\n<p>Iterate over folders that contain files (i.e. ignore the nested subfolders that only contain folders).</p>\n<pre><span class=\"k\">for</span> <span class=\"n\">folder</span> <span class=\"ow\">in</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">folders</span><span class=\"p\">():</span>\n    <span class=\"c1\"># do something</span>\n</pre>\n</div>\n<div id=\"computing-size\">\n<h3>Computing Size</h3>\n<p>Compute the size in bytes of all files in the <tt>root</tt> directory.</p>\n<pre><span class=\"n\">total_bytes</span> <span class=\"o\">=</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">()</span>\n</pre>\n<p>Count the total number of files.</p>\n<pre><span class=\"n\">total_files</span> <span class=\"o\">=</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">count</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># Or via len()...</span>\n<span class=\"n\">total_files</span> <span class=\"o\">=</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">fs</span><span class=\"p\">)</span>\n</pre>\n<p>For more details, please see the full documentation at <a href=\"http://hashfs.readthedocs.org\" rel=\"nofollow\">http://hashfs.readthedocs.org</a>.</p>\n</div>\n</div>\n<div id=\"changelog\">\n<h2>Changelog</h2>\n<div id=\"v0-7-2-2019-10-24\">\n<h3>v0.7.2 (2019-10-24)</h3>\n<ul>\n<li>Fix out-of-memory issue when computing file ID hashes of large files.</li>\n</ul>\n</div>\n<div id=\"v0-7-1-2018-10-13\">\n<h3>v0.7.1 (2018-10-13)</h3>\n<ul>\n<li>Replace usage of <tt>distutils.dir_util.mkpath</tt> with <tt>os.path.makedirs</tt>.</li>\n</ul>\n</div>\n<div id=\"v0-7-0-2016-04-19\">\n<h3>v0.7.0 (2016-04-19)</h3>\n<ul>\n<li>Use <tt>shutil.move</tt> instead of <tt>shutil.copy</tt> to move temporary file created during <tt>put</tt> operation to <tt>HashFS</tt> directory.</li>\n</ul>\n</div>\n<div id=\"v0-6-0-2015-10-19\">\n<h3>v0.6.0 (2015-10-19)</h3>\n<ul>\n<li>Add faster <tt>scandir</tt> package for iterating over files/folders when platform is Python &lt; 3.5. Scandir implementation was added to <tt>os</tt> module starting with Python 3.5.</li>\n</ul>\n</div>\n<div id=\"v0-5-0-2015-07-02\">\n<h3>v0.5.0 (2015-07-02)</h3>\n<ul>\n<li>Rename private method <tt>HashFS.copy</tt> to <tt>HashFS._copy</tt>.</li>\n<li>Add <tt>is_duplicate</tt> attribute to <tt>HashAddress</tt>.</li>\n<li>Make <tt>HashFS.put()</tt> return <tt>HashAddress</tt> with <tt>is_duplicate=True</tt> when file with same hash already exists on disk.</li>\n</ul>\n</div>\n<div id=\"v0-4-0-2015-06-03\">\n<h3>v0.4.0 (2015-06-03)</h3>\n<ul>\n<li>Add <tt>HashFS.size()</tt> method that returns the size of all files in bytes.</li>\n<li>Add <tt>HashFS.count()</tt>/<tt>HashFS.__len__()</tt> methods that return the count of all files.</li>\n<li>Add <tt>HashFS.__iter__()</tt> method to support iteration. Proxies to <tt>HashFS.files()</tt>.</li>\n<li>Add <tt>HashFS.__contains__()</tt> method to support <tt>in</tt> operator. Proxies to <tt>HashFS.exists()</tt>.</li>\n<li>Don\u2019t create the root directory (if it doesn\u2019t exist) until at least one file has been added.</li>\n<li>Fix <tt>HashFS.repair()</tt> not using <tt>extensions</tt> argument properly.</li>\n</ul>\n</div>\n<div id=\"v0-3-0-2015-06-02\">\n<h3>v0.3.0 (2015-06-02)</h3>\n<ul>\n<li>Rename <tt>HashFS.length</tt> parameter/property to <tt>width</tt>. (<strong>breaking change</strong>)</li>\n</ul>\n</div>\n<div id=\"v0-2-0-2015-05-29\">\n<h3>v0.2.0 (2015-05-29)</h3>\n<ul>\n<li>Rename <tt>HashFS.get</tt> to <tt>HashFS.open</tt>. (<strong>breaking change</strong>)</li>\n<li>Add <tt>HashFS.get()</tt> method that returns a <tt>HashAddress</tt> or <tt>None</tt> given a file ID or path.</li>\n</ul>\n</div>\n<div id=\"v0-1-0-2015-05-28\">\n<h3>v0.1.0 (2015-05-28)</h3>\n<ul>\n<li>Add <tt>HashFS.get()</tt> method that retrieves a reader object given a file ID or path.</li>\n<li>Add <tt>HashFS.delete()</tt> method that deletes a file ID or path.</li>\n<li>Add <tt>HashFS.folders()</tt> method that returns the folder paths that directly contain files (i.e. subpaths that only contain folders are ignored).</li>\n<li>Add <tt>HashFS.detokenize()</tt> method that returns the file ID contained in a file path.</li>\n<li>Add <tt>HashFS.repair()</tt> method that reindexes any files under root directory whose file path doesn\u2019t not match its tokenized file ID.</li>\n<li>Rename <tt>Address</tt> classs to <tt>HashAddress</tt>. (<strong>breaking change</strong>)</li>\n<li>Rename <tt>HashAddress.digest</tt> to <tt>HashAddress.id</tt>. (<strong>breaking change</strong>)</li>\n<li>Rename <tt>HashAddress.path</tt> to <tt>HashAddress.abspath</tt>. (<strong>breaking change</strong>)</li>\n<li>Add <tt>HashAddress.relpath</tt> which represents path relative to <tt>HashFS.root</tt>.</li>\n</ul>\n</div>\n<div id=\"v0-0-1-2015-05-27\">\n<h3>v0.0.1 (2015-05-27)</h3>\n<ul>\n<li>First release.</li>\n<li>Add <tt>HashFS</tt> class.</li>\n<li>Add <tt>HashFS.put()</tt> method that saves a file path or file-like object by content hash.</li>\n<li>Add <tt>HashFS.files()</tt> method that returns all files under root directory.</li>\n<li>Add <tt>HashFS.exists()</tt> which checks either a file hash or file path for existence.</li>\n</ul>\n</div>\n</div>\n\n          </div>"}, "last_serial": 6027373, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "e0447abcbd6b647c5913d81b4757928a", "sha256": "5aebb3fbd8f5b903d04b55462cbfbd4950a1863cb8de7463339ae72af6fe9ab0"}, "downloads": -1, "filename": "hashfs-0.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e0447abcbd6b647c5913d81b4757928a", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 7615, "upload_time": "2015-05-27T14:05:45", "upload_time_iso_8601": "2015-05-27T14:05:45.417942Z", "url": "https://files.pythonhosted.org/packages/33/a5/50211b5fbe4dc196cf6f525b7888d44e01a3c3c10a28116e53f8b8e484b5/hashfs-0.0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cb7703e2c5df472413e6c9fa264eac11", "sha256": "66b69cf4834aca996778f22de5ca8e2161e519f900189f0af1d0c287ed42d6a3"}, "downloads": -1, "filename": "hashfs-0.0.1.tar.gz", "has_sig": false, "md5_digest": "cb7703e2c5df472413e6c9fa264eac11", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14693, "upload_time": "2015-05-27T14:05:48", "upload_time_iso_8601": "2015-05-27T14:05:48.363729Z", "url": "https://files.pythonhosted.org/packages/41/1c/59ee02fe026d7b23fd8db1727fb04215c2320edbed218cd6d5882117b554/hashfs-0.0.1.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "c148dc84bcb9266a5dbefb3b4b8c063d", "sha256": "a5040bdc5ceea4914618f2cfabf3bd8ab11c5e56f309566c3ff58c1edf5d364a"}, "downloads": -1, "filename": "hashfs-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "c148dc84bcb9266a5dbefb3b4b8c063d", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 11618, "upload_time": "2015-05-28T04:02:19", "upload_time_iso_8601": "2015-05-28T04:02:19.060555Z", "url": "https://files.pythonhosted.org/packages/45/00/28ca8fd415a0fb868db71d5e230f209122d0500e27bee5ac38bcc643bb6a/hashfs-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4124ebb352ad4d8da10cd6a2e19225e6", "sha256": "d767a21bb9fd5509bf781d6d45fb8e91148a207ab94f4597d883b073376164a4"}, "downloads": -1, "filename": "hashfs-0.1.0.tar.gz", "has_sig": false, "md5_digest": "4124ebb352ad4d8da10cd6a2e19225e6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18503, "upload_time": "2015-05-28T04:02:22", "upload_time_iso_8601": "2015-05-28T04:02:22.482444Z", "url": "https://files.pythonhosted.org/packages/ee/ea/68214b49ac38b3102bc0b86c0b420be745728ad1efcfe6610abbfc6c87a4/hashfs-0.1.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "cb348e0eaa9b65a7d35bd4db04f91264", "sha256": "6dd41fde90345cb08861e78b603b350b5f345db41f14d60099b788b7e222ee4b"}, "downloads": -1, "filename": "hashfs-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "cb348e0eaa9b65a7d35bd4db04f91264", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 12034, "upload_time": "2015-05-29T22:13:27", "upload_time_iso_8601": "2015-05-29T22:13:27.425977Z", "url": "https://files.pythonhosted.org/packages/48/9a/737c63f40fc95558039b193d33410a9aa5dab69131e5639b9c7e06b0825a/hashfs-0.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1253f8ef2a2deb9d463ffb2bc778f1aa", "sha256": "95c175fb202fa05008fee79d374ee3d52c39908b773cf72b00801e2817c61ada"}, "downloads": -1, "filename": "hashfs-0.2.0.tar.gz", "has_sig": false, "md5_digest": "1253f8ef2a2deb9d463ffb2bc778f1aa", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18871, "upload_time": "2015-05-29T22:13:30", "upload_time_iso_8601": "2015-05-29T22:13:30.734686Z", "url": "https://files.pythonhosted.org/packages/dd/97/8feeae0e3af5c8945f903e75f5ccf91fef8c4ae692d29e7901a29180d635/hashfs-0.2.0.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "875e64084837d31963bf9141b51c8bc4", "sha256": "a408ad2c43ead8151908f927b8ad2d7408c42f192af5a58ea88eab663c734d4e"}, "downloads": -1, "filename": "hashfs-0.3.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "875e64084837d31963bf9141b51c8bc4", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 12528, "upload_time": "2015-06-02T20:26:34", "upload_time_iso_8601": "2015-06-02T20:26:34.538397Z", "url": "https://files.pythonhosted.org/packages/ec/d7/15ba8fa200f80db44d92dab11212dbd9f82040ea9112777ca1e91e14a899/hashfs-0.3.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2c911e5cfab692469e89bd8893c4cb75", "sha256": "4b5434ca12df36859850acaa0a19dab10b1112ed891d0eacfc3bf84070e1a0f1"}, "downloads": -1, "filename": "hashfs-0.3.0.tar.gz", "has_sig": false, "md5_digest": "2c911e5cfab692469e89bd8893c4cb75", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20458, "upload_time": "2015-06-02T20:26:37", "upload_time_iso_8601": "2015-06-02T20:26:37.385530Z", "url": "https://files.pythonhosted.org/packages/8f/66/789eb06b5288ee6a3db0473cc9603c92e64f20c4f02b21b6baca1541df2c/hashfs-0.3.0.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "8050734b7c23ed6bc52e4dacb87a631a", "sha256": "c68b96c3e56421b3a4950c3bdff32821bf42377a8c1945c848ce88f6e2c3a60c"}, "downloads": -1, "filename": "hashfs-0.4.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "8050734b7c23ed6bc52e4dacb87a631a", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 13848, "upload_time": "2015-06-03T19:54:23", "upload_time_iso_8601": "2015-06-03T19:54:23.748119Z", "url": "https://files.pythonhosted.org/packages/38/ac/0322e043141deb5c470514f7cbd7e27bc88bf3350105adad05110a0a6fde/hashfs-0.4.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7d6e1f7cc100730687f6d5822ba3cbeb", "sha256": "5cb02b7c26f966b64af4fa8b32808b1f91d0dcfbf2121e215cc229f485c305fe"}, "downloads": -1, "filename": "hashfs-0.4.0.tar.gz", "has_sig": false, "md5_digest": "7d6e1f7cc100730687f6d5822ba3cbeb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22028, "upload_time": "2015-06-03T19:54:26", "upload_time_iso_8601": "2015-06-03T19:54:26.779138Z", "url": "https://files.pythonhosted.org/packages/d8/22/dc30dd8b0b9eefe1919598c022365d58c35189bfa9b9b59dd5325bb63ce4/hashfs-0.4.0.tar.gz", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "bb787be78bb37a33d6b0602a199ed874", "sha256": "b325cfc012260e545be0cd37a59485647ba3fcdc2448ad4436da7ff3004d926c"}, "downloads": -1, "filename": "hashfs-0.5.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "bb787be78bb37a33d6b0602a199ed874", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 14218, "upload_time": "2015-07-02T14:36:23", "upload_time_iso_8601": "2015-07-02T14:36:23.140674Z", "url": "https://files.pythonhosted.org/packages/32/8a/b84d5797bee06abc911be947540967563adb0523e2799fc65f79a86a5c7e/hashfs-0.5.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "829fb800db21956fb886be40bf16a2c1", "sha256": "ed2e7b5c3caa79ee099d0328d3da08ed1ee38f01ae6c2d0e74af65000d5734d1"}, "downloads": -1, "filename": "hashfs-0.5.0.tar.gz", "has_sig": false, "md5_digest": "829fb800db21956fb886be40bf16a2c1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22392, "upload_time": "2015-07-02T14:36:26", "upload_time_iso_8601": "2015-07-02T14:36:26.496481Z", "url": "https://files.pythonhosted.org/packages/52/a3/22649ad5f5f09752814d2dd85f339fa50b8ca6b704fb731e8df262fe9720/hashfs-0.5.0.tar.gz", "yanked": false}], "0.6.0": [{"comment_text": "", "digests": {"md5": "9a15ff1d906a74a00b658fef11a5ab90", "sha256": "994e6160b127ab0826c595970b104fe610b9c27b234bb8348ae7840e2549d373"}, "downloads": -1, "filename": "hashfs-0.6.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "9a15ff1d906a74a00b658fef11a5ab90", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 14576, "upload_time": "2015-10-19T22:00:39", "upload_time_iso_8601": "2015-10-19T22:00:39.568424Z", "url": "https://files.pythonhosted.org/packages/93/28/b5afd55092a90588c4cbb108c5bb0d2a3382929c2842ffa4971e8a0677ba/hashfs-0.6.0-py2.py3-none-any.whl", "yanked": false}], "0.7.0": [{"comment_text": "", "digests": {"md5": "3d05b4d87d5905c2aaba12006586417f", "sha256": "4d5e97afb0df0c6d2d15660d64b9960c4bf667ea983a5726379ffdbdda6b0736"}, "downloads": -1, "filename": "hashfs-0.7.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "3d05b4d87d5905c2aaba12006586417f", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 14570, "upload_time": "2016-04-20T01:09:24", "upload_time_iso_8601": "2016-04-20T01:09:24.715982Z", "url": "https://files.pythonhosted.org/packages/c8/a1/7404220f92f897557a76ffec820daed3f47de05ee89f2726c48e103229e5/hashfs-0.7.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ebf6a977025ec6203dc9eb7c22bf34ef", "sha256": "1535ed7673d87d90faa52f83534e2110d91fabc7177d16bab1a96cd16f17513a"}, "downloads": -1, "filename": "hashfs-0.7.0.tar.gz", "has_sig": false, "md5_digest": "ebf6a977025ec6203dc9eb7c22bf34ef", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23302, "upload_time": "2016-04-20T01:09:35", "upload_time_iso_8601": "2016-04-20T01:09:35.714737Z", "url": "https://files.pythonhosted.org/packages/73/30/ccae256a9a090affa81b9b65ac1b8103552a1cf5b2042265d6f681fddb52/hashfs-0.7.0.tar.gz", "yanked": false}], "0.7.1": [{"comment_text": "", "digests": {"md5": "5db03f5f54f931d17bb93e79743d1ea9", "sha256": "e53b45e3a83ccb941219b41d8ebf3ea50d6cd6edfaaecc829e51fd5d81576e14"}, "downloads": -1, "filename": "hashfs-0.7.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "5db03f5f54f931d17bb93e79743d1ea9", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 11651, "upload_time": "2018-10-14T02:55:34", "upload_time_iso_8601": "2018-10-14T02:55:34.152386Z", "url": "https://files.pythonhosted.org/packages/ca/29/a068a2ef8bb57e4fedc582f4a27e2867abad46099a88d1af711a7d5423dd/hashfs-0.7.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "059e7150082dd6e770972f421f0d06e3", "sha256": "0fe7f310906e808d0e776d029b0c925cbcce5d8706f56bb9dd6a95a05be3dab3"}, "downloads": -1, "filename": "hashfs-0.7.1.tar.gz", "has_sig": false, "md5_digest": "059e7150082dd6e770972f421f0d06e3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23569, "upload_time": "2018-10-14T02:55:35", "upload_time_iso_8601": "2018-10-14T02:55:35.378239Z", "url": "https://files.pythonhosted.org/packages/50/fb/9e125a44a508acd9fde5f8a712048d1c3818b360dfdec16de8462802c449/hashfs-0.7.1.tar.gz", "yanked": false}], "0.7.2": [{"comment_text": "", "digests": {"md5": "682153f898e0759ec40cbf60feaab57f", "sha256": "3014a9b8dfafd1989cb9727c8b44c871f5b040bc144ec26aed3282ce519349b1"}, "downloads": -1, "filename": "hashfs-0.7.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "682153f898e0759ec40cbf60feaab57f", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 11723, "upload_time": "2019-10-25T03:43:50", "upload_time_iso_8601": "2019-10-25T03:43:50.851413Z", "url": "https://files.pythonhosted.org/packages/1d/b4/f6b0c5f77e745c816814e388e18be4cab28d174da5ffd436099129152657/hashfs-0.7.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "45f0bdcbdec6b0b78084bec6354a2022", "sha256": "b0986e66eb8500a7e963c0555731fec6b723e6a08e4ad228d29ad3dbf9428bf5"}, "downloads": -1, "filename": "hashfs-0.7.2.tar.gz", "has_sig": false, "md5_digest": "45f0bdcbdec6b0b78084bec6354a2022", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23642, "upload_time": "2019-10-25T03:43:52", "upload_time_iso_8601": "2019-10-25T03:43:52.266953Z", "url": "https://files.pythonhosted.org/packages/12/b7/17e950399dc6ca4d158906c85899fdc15c7bcb549f8a939f3214a4bc34e6/hashfs-0.7.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "682153f898e0759ec40cbf60feaab57f", "sha256": "3014a9b8dfafd1989cb9727c8b44c871f5b040bc144ec26aed3282ce519349b1"}, "downloads": -1, "filename": "hashfs-0.7.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "682153f898e0759ec40cbf60feaab57f", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 11723, "upload_time": "2019-10-25T03:43:50", "upload_time_iso_8601": "2019-10-25T03:43:50.851413Z", "url": "https://files.pythonhosted.org/packages/1d/b4/f6b0c5f77e745c816814e388e18be4cab28d174da5ffd436099129152657/hashfs-0.7.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "45f0bdcbdec6b0b78084bec6354a2022", "sha256": "b0986e66eb8500a7e963c0555731fec6b723e6a08e4ad228d29ad3dbf9428bf5"}, "downloads": -1, "filename": "hashfs-0.7.2.tar.gz", "has_sig": false, "md5_digest": "45f0bdcbdec6b0b78084bec6354a2022", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23642, "upload_time": "2019-10-25T03:43:52", "upload_time_iso_8601": "2019-10-25T03:43:52.266953Z", "url": "https://files.pythonhosted.org/packages/12/b7/17e950399dc6ca4d158906c85899fdc15c7bcb549f8a939f3214a4bc34e6/hashfs-0.7.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:52:21 2020"}