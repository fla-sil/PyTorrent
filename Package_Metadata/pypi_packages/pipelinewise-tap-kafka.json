{"info": {"author": "TransferWise", "author_email": "", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: GNU Affero General Public License v3", "Programming Language :: Python :: 3 :: Only"], "description": "# pipelinewise-tap-kafka\n\n[![PyPI version](https://badge.fury.io/py/pipelinewise-tap-kafka.svg)](https://badge.fury.io/py/pipelinewise-tap-kafka)\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/pipelinewise-tap-kafka.svg)](https://pypi.org/project/pipelinewise-tap-kafka/)\n[![License: MIT](https://img.shields.io/badge/License-GPLv3-yellow.svg)](https://opensource.org/licenses/GPL-3.0)\n\nThis is a [Singer](https://singer.io) tap that reads data from Kafka topic and produces JSON-formatted data following the [Singer spec](https://github.com/singer-io/getting-started/blob/master/SPEC.md).\n\nThis is a [PipelineWise](https://transferwise.github.io/pipelinewise) compatible target connector.\n\n## How to use it\n\nThe recommended method of running this tap is to use it from [PipelineWise](https://transferwise.github.io/pipelinewise). When running it from PipelineWise you don't need to configure this tap with JSON files and most of things are automated. Please check the related documentation at [Kafka](https://transferwise.github.io/pipelinewise/connectors/taps/kafka.html)\n\nIf you want to run this [Singer Tap](https://singer.io) independently please read further.\n\n## Install and Run\n\nFirst, make sure Python 3 is installed on your system or follow these\ninstallation instructions for [Mac](http://docs.python-guide.org/en/latest/starting/install3/osx/) or\n[Ubuntu](https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-local-programming-environment-on-ubuntu-16-04).\n\nIt's recommended to use a virtualenv:\n\n```bash\n  python3 -m venv venv\n  pip install pipelinewise-tap-kafka\n```\n\nor\n\n```bash\n  python3 -m venv venv\n  . venv/bin/activate\n  pip install --upgrade pip\n  pip install .\n```\n\n### Configuration\n\n### Create a config.json\n\n```\n{\n  \"bootstrap_servers\": \"foo.com,bar.com\",\n  \"group_id\": \"my_group\",\n  \"topic\": \"my_topic\",\n  \"primary_keys\": {\n    \"id\": \"$.jsonpath.to.primary_key\"\n  }\n}\n```\n\nFull list of options in `config.json`:\n\n| Property                            | Type    | Required?  | Description                                                   |\n|-------------------------------------|---------|------------|---------------------------------------------------------------|\n| bootstrap_servers                   | String  | Yes        | `host[:port]` string (or list of comma separated `host[:port]` strings) that the consumer should contact to bootstrap initial cluster metadata. |\n| group_id                            | String  | Yes        | The name of the consumer group to join for dynamic partition assignment (if enabled), and to use for fetching and committing offsets. |\n| topic                               | String  | Yes        | Name of kafka topics to subscribe to |\n| primary_keys                        | Object  |            | Optionally you can define primary key for the consumed messages. It requires a column name and JSONPath selector to extract the value from the kafka messages. The extracted column will be added to every output singer message. |\n| max_runtime_ms                      | Integer |            | (Default: 300000) The maximum time for the tap to collect new messages from Kafka topic. If this time exceeds it will flush the batch and close kafka connection. |\n| batch_size_rows                     | Integer |            | (Default: 1000) Consumed kafka messages are transformed to batches and batches written to STDOUT in singer message format *only* when the batch is full. Set this value low to have more realtime experience. |\n| batch_flush_interval_ms             | Integer |            | (Default: 60000) The maximum delay between flushing batches. Exceeding this time will force flushing singer messages to STDOUT even if the batch is not full. |\n| consumer_timeout_ms                 | Integer |            | (Default: 10000) KafkaConsumer setting. Number of milliseconds to block during message iteration before raising StopIteration            |\n| session_timeout_ms                  | Integer |            | (Default: 30000) KafkaConsumer setting. The timeout used to detect failures when using Kafka\u2019s group management facilities. |                                      |\n| heartbeat_interval_ms               | Integer |            | (Default: 10000) KafkaConsumer setting. The expected time in milliseconds between heartbeats to the consumer coordinator when using Kafka\u2019s group management facilities. |\n| max_poll_records                    | Integer |            | (Default: 500) KafkaConsumer setting. The maximum number of records returned in a single call to poll(). |\n| max_poll_interval_ms                | Integer |            | (Default: 300000) KafkaConsumer setting. The maximum delay between invocations of poll() when using consumer group management. |\n| local_store_dir                     | String  |            | (Default: current working dir) tap-kafka maintains an intermediate file based local storage. Every consumed message first added into this store and periodically flushing the content to STDOUT for other singer components. This mechanism allows to send commit messages quickly to Kafka brokers and avoid unexpected re-balancing caused by long running message consumptions. |\n\n\nThis tap reads Kafka messages and generating singer compatible SCHEMA and RECORD messages in the following format.\n\n| Property Name               | Description                                                                         |\n|-----------------------------|-------------------------------------------------------------------------------------|\n| MESSAGE_TIMESTAMP           | Timestamp extracted from the kafka metadata                                         |\n| MESSAGE_OFFSET              | Offset extracted from the kafka metadata                                            |\n| MESSAGE_PARTITION           | Partition extracted from the kafka metadata                                         |\n| MESSAGE                     | The original Kafka message                                                          |\n| DYNAMIC_PRIMARY_KEY(S)      | (Optional) Dynamically added primary key values, extracted from the Kafka message   |\n\n\n### Run the tap in Discovery Mode\n\n```\ntap-kafka --config config.json --discover                # Should dump a Catalog to stdout\ntap-kafka --config config.json --discover > catalog.json # Capture the Catalog\n```\n\n### Add Metadata to the Catalog\n\nEach entry under the Catalog's \"stream\" key will need the following metadata:\n\n```\n{\n  \"streams\": [\n    {\n      \"stream_name\": \"my_topic\"\n      \"metadata\": [{\n        \"breadcrumb\": [],\n        \"metadata\": {\n          \"selected\": true,\n        }\n      }]\n    }\n  ]\n}\n```\n\n### Run the tap in Sync Mode\n\n```\ntap-kafka --config config.json --properties catalog.json\n```\n\nThe tap will write bookmarks to stdout which can be captured and passed as an optional `--state state.json` parameter to the tap for the next sync.\n\n## To run tests:\n\n1. Install python test dependencies in a virtual env and run nose unit and integration tests\n```\n  python3 -m venv venv\n  . venv/bin/activate\n  pip install --upgrade pip\n  pip install .[test]\n```\n\n2. To run tests:\n```\n  pytest tests\n```\n\n## To run pylint:\n\n1. Install python dependencies and run python linter\n```\n  python3 -m venv venv\n  . venv/bin/activate\n  pip install --upgrade pip\n  pip install .[test]\n  pylint tap_kafka -d C,W,unexpected-keyword-arg,duplicate-code\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://singer.io", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "pipelinewise-tap-kafka", "package_url": "https://pypi.org/project/pipelinewise-tap-kafka/", "platform": "", "project_url": "https://pypi.org/project/pipelinewise-tap-kafka/", "project_urls": {"Homepage": "https://singer.io"}, "release_url": "https://pypi.org/project/pipelinewise-tap-kafka/3.1.0/", "requires_dist": ["kafka-python (==2.0.1)", "pipelinewise-singer-python (==1.*)", "jsonpath-ng (==1.4.3)", "filelock (==3.0.12)", "pytest (==5.0.1) ; extra == 'test'", "nose (==1.3.7) ; extra == 'test'", "pylint (==2.4.2) ; extra == 'test'"], "requires_python": "", "summary": "Singer.io tap for extracting data from Kafka topic - PipelineWise compatible", "version": "3.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>pipelinewise-tap-kafka</h1>\n<p><a href=\"https://badge.fury.io/py/pipelinewise-tap-kafka\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/162778fd70ef98dc6fdf86bb111c3f2a36842c2d/68747470733a2f2f62616467652e667572792e696f2f70792f706970656c696e65776973652d7461702d6b61666b612e737667\"></a>\n<a href=\"https://pypi.org/project/pipelinewise-tap-kafka/\" rel=\"nofollow\"><img alt=\"PyPI - Python Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0a07e5f614c2feb869919a39667936564d8f8646/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f706970656c696e65776973652d7461702d6b61666b612e737667\"></a>\n<a href=\"https://opensource.org/licenses/GPL-3.0\" rel=\"nofollow\"><img alt=\"License: MIT\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8f103c9b4ae6eaa684967bbaee8c507c609ff5ca/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d47504c76332d79656c6c6f772e737667\"></a></p>\n<p>This is a <a href=\"https://singer.io\" rel=\"nofollow\">Singer</a> tap that reads data from Kafka topic and produces JSON-formatted data following the <a href=\"https://github.com/singer-io/getting-started/blob/master/SPEC.md\" rel=\"nofollow\">Singer spec</a>.</p>\n<p>This is a <a href=\"https://transferwise.github.io/pipelinewise\" rel=\"nofollow\">PipelineWise</a> compatible target connector.</p>\n<h2>How to use it</h2>\n<p>The recommended method of running this tap is to use it from <a href=\"https://transferwise.github.io/pipelinewise\" rel=\"nofollow\">PipelineWise</a>. When running it from PipelineWise you don't need to configure this tap with JSON files and most of things are automated. Please check the related documentation at <a href=\"https://transferwise.github.io/pipelinewise/connectors/taps/kafka.html\" rel=\"nofollow\">Kafka</a></p>\n<p>If you want to run this <a href=\"https://singer.io\" rel=\"nofollow\">Singer Tap</a> independently please read further.</p>\n<h2>Install and Run</h2>\n<p>First, make sure Python 3 is installed on your system or follow these\ninstallation instructions for <a href=\"http://docs.python-guide.org/en/latest/starting/install3/osx/\" rel=\"nofollow\">Mac</a> or\n<a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-local-programming-environment-on-ubuntu-16-04\" rel=\"nofollow\">Ubuntu</a>.</p>\n<p>It's recommended to use a virtualenv:</p>\n<pre>  python3 -m venv venv\n  pip install pipelinewise-tap-kafka\n</pre>\n<p>or</p>\n<pre>  python3 -m venv venv\n  . venv/bin/activate\n  pip install --upgrade pip\n  pip install .\n</pre>\n<h3>Configuration</h3>\n<h3>Create a config.json</h3>\n<pre><code>{\n  \"bootstrap_servers\": \"foo.com,bar.com\",\n  \"group_id\": \"my_group\",\n  \"topic\": \"my_topic\",\n  \"primary_keys\": {\n    \"id\": \"$.jsonpath.to.primary_key\"\n  }\n}\n</code></pre>\n<p>Full list of options in <code>config.json</code>:</p>\n<table>\n<thead>\n<tr>\n<th>Property</th>\n<th>Type</th>\n<th>Required?</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>bootstrap_servers</td>\n<td>String</td>\n<td>Yes</td>\n<td><code>host[:port]</code> string (or list of comma separated <code>host[:port]</code> strings) that the consumer should contact to bootstrap initial cluster metadata.</td>\n</tr>\n<tr>\n<td>group_id</td>\n<td>String</td>\n<td>Yes</td>\n<td>The name of the consumer group to join for dynamic partition assignment (if enabled), and to use for fetching and committing offsets.</td>\n</tr>\n<tr>\n<td>topic</td>\n<td>String</td>\n<td>Yes</td>\n<td>Name of kafka topics to subscribe to</td>\n</tr>\n<tr>\n<td>primary_keys</td>\n<td>Object</td>\n<td></td>\n<td>Optionally you can define primary key for the consumed messages. It requires a column name and JSONPath selector to extract the value from the kafka messages. The extracted column will be added to every output singer message.</td>\n</tr>\n<tr>\n<td>max_runtime_ms</td>\n<td>Integer</td>\n<td></td>\n<td>(Default: 300000) The maximum time for the tap to collect new messages from Kafka topic. If this time exceeds it will flush the batch and close kafka connection.</td>\n</tr>\n<tr>\n<td>batch_size_rows</td>\n<td>Integer</td>\n<td></td>\n<td>(Default: 1000) Consumed kafka messages are transformed to batches and batches written to STDOUT in singer message format <em>only</em> when the batch is full. Set this value low to have more realtime experience.</td>\n</tr>\n<tr>\n<td>batch_flush_interval_ms</td>\n<td>Integer</td>\n<td></td>\n<td>(Default: 60000) The maximum delay between flushing batches. Exceeding this time will force flushing singer messages to STDOUT even if the batch is not full.</td>\n</tr>\n<tr>\n<td>consumer_timeout_ms</td>\n<td>Integer</td>\n<td></td>\n<td>(Default: 10000) KafkaConsumer setting. Number of milliseconds to block during message iteration before raising StopIteration</td>\n</tr>\n<tr>\n<td>session_timeout_ms</td>\n<td>Integer</td>\n<td></td>\n<td>(Default: 30000) KafkaConsumer setting. The timeout used to detect failures when using Kafka\u2019s group management facilities.</td>\n</tr>\n<tr>\n<td>heartbeat_interval_ms</td>\n<td>Integer</td>\n<td></td>\n<td>(Default: 10000) KafkaConsumer setting. The expected time in milliseconds between heartbeats to the consumer coordinator when using Kafka\u2019s group management facilities.</td>\n</tr>\n<tr>\n<td>max_poll_records</td>\n<td>Integer</td>\n<td></td>\n<td>(Default: 500) KafkaConsumer setting. The maximum number of records returned in a single call to poll().</td>\n</tr>\n<tr>\n<td>max_poll_interval_ms</td>\n<td>Integer</td>\n<td></td>\n<td>(Default: 300000) KafkaConsumer setting. The maximum delay between invocations of poll() when using consumer group management.</td>\n</tr>\n<tr>\n<td>local_store_dir</td>\n<td>String</td>\n<td></td>\n<td>(Default: current working dir) tap-kafka maintains an intermediate file based local storage. Every consumed message first added into this store and periodically flushing the content to STDOUT for other singer components. This mechanism allows to send commit messages quickly to Kafka brokers and avoid unexpected re-balancing caused by long running message consumptions.</td>\n</tr></tbody></table>\n<p>This tap reads Kafka messages and generating singer compatible SCHEMA and RECORD messages in the following format.</p>\n<table>\n<thead>\n<tr>\n<th>Property Name</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>MESSAGE_TIMESTAMP</td>\n<td>Timestamp extracted from the kafka metadata</td>\n</tr>\n<tr>\n<td>MESSAGE_OFFSET</td>\n<td>Offset extracted from the kafka metadata</td>\n</tr>\n<tr>\n<td>MESSAGE_PARTITION</td>\n<td>Partition extracted from the kafka metadata</td>\n</tr>\n<tr>\n<td>MESSAGE</td>\n<td>The original Kafka message</td>\n</tr>\n<tr>\n<td>DYNAMIC_PRIMARY_KEY(S)</td>\n<td>(Optional) Dynamically added primary key values, extracted from the Kafka message</td>\n</tr></tbody></table>\n<h3>Run the tap in Discovery Mode</h3>\n<pre><code>tap-kafka --config config.json --discover                # Should dump a Catalog to stdout\ntap-kafka --config config.json --discover &gt; catalog.json # Capture the Catalog\n</code></pre>\n<h3>Add Metadata to the Catalog</h3>\n<p>Each entry under the Catalog's \"stream\" key will need the following metadata:</p>\n<pre><code>{\n  \"streams\": [\n    {\n      \"stream_name\": \"my_topic\"\n      \"metadata\": [{\n        \"breadcrumb\": [],\n        \"metadata\": {\n          \"selected\": true,\n        }\n      }]\n    }\n  ]\n}\n</code></pre>\n<h3>Run the tap in Sync Mode</h3>\n<pre><code>tap-kafka --config config.json --properties catalog.json\n</code></pre>\n<p>The tap will write bookmarks to stdout which can be captured and passed as an optional <code>--state state.json</code> parameter to the tap for the next sync.</p>\n<h2>To run tests:</h2>\n<ol>\n<li>Install python test dependencies in a virtual env and run nose unit and integration tests</li>\n</ol>\n<pre><code>  python3 -m venv venv\n  . venv/bin/activate\n  pip install --upgrade pip\n  pip install .[test]\n</code></pre>\n<ol>\n<li>To run tests:</li>\n</ol>\n<pre><code>  pytest tests\n</code></pre>\n<h2>To run pylint:</h2>\n<ol>\n<li>Install python dependencies and run python linter</li>\n</ol>\n<pre><code>  python3 -m venv venv\n  . venv/bin/activate\n  pip install --upgrade pip\n  pip install .[test]\n  pylint tap_kafka -d C,W,unexpected-keyword-arg,duplicate-code\n</code></pre>\n\n          </div>"}, "last_serial": 7066095, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "7b449e75565193b38351f67cebe28892", "sha256": "ec36736e0c1935b01a666653ddddb850608b5f04f0d6d29c90ed808c8e855678"}, "downloads": -1, "filename": "pipelinewise-tap-kafka-1.0.0.tar.gz", "has_sig": false, "md5_digest": "7b449e75565193b38351f67cebe28892", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4391, "upload_time": "2019-06-02T23:32:04", "upload_time_iso_8601": "2019-06-02T23:32:04.605528Z", "url": "https://files.pythonhosted.org/packages/74/b5/e98a6866706021fc89dcf5b972202bf5c894c089a7ab0181d4bab9898e73/pipelinewise-tap-kafka-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "ad33c87b04b9616d26ad3bf810af080a", "sha256": "17abc01a79d7d496c832b41d781a9981e1e276edf0888a60cf1cda209c06cf00"}, "downloads": -1, "filename": "pipelinewise-tap-kafka-1.0.1.tar.gz", "has_sig": false, "md5_digest": "ad33c87b04b9616d26ad3bf810af080a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4454, "upload_time": "2019-08-16T15:54:04", "upload_time_iso_8601": "2019-08-16T15:54:04.920717Z", "url": "https://files.pythonhosted.org/packages/eb/c4/474e349dc3b6cb342a0b70a95e4a4de573fe167aac64c9b134e7462726e5/pipelinewise-tap-kafka-1.0.1.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "882932ad44a5aeb22f077fd29fe67fdf", "sha256": "940ca7069544bfb008ba08b30cf2f27d85a6084f114253506896d877e6f4526e"}, "downloads": -1, "filename": "pipelinewise_tap_kafka-1.0.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "882932ad44a5aeb22f077fd29fe67fdf", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 15817, "upload_time": "2019-11-25T17:59:30", "upload_time_iso_8601": "2019-11-25T17:59:30.242192Z", "url": "https://files.pythonhosted.org/packages/b3/74/58206958851a04c80a507b6eb89aaa94c6deb7dc62421dd410edb171a4a6/pipelinewise_tap_kafka-1.0.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7c290ecb76477b2d421dc8fedf496f0f", "sha256": "7ccdb2091c905f0aa8e57eed54b27701f3e67734b2f50b6f6843d78870f2e93e"}, "downloads": -1, "filename": "pipelinewise-tap-kafka-1.0.2.tar.gz", "has_sig": false, "md5_digest": "7c290ecb76477b2d421dc8fedf496f0f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4492, "upload_time": "2019-11-25T17:59:31", "upload_time_iso_8601": "2019-11-25T17:59:31.904933Z", "url": "https://files.pythonhosted.org/packages/7f/f3/f0623d36b297cf977fb25cb43986c5d414a06a66d52d482646c2dc49aa68/pipelinewise-tap-kafka-1.0.2.tar.gz", "yanked": false}], "2.0.0": [{"comment_text": "", "digests": {"md5": "7f0e84ce725294d74b85627c715e9a46", "sha256": "41161cb7c4f76dd7ad64eb41c4ac43761a5eeb19af686c7f08d85cfadbc95d6b"}, "downloads": -1, "filename": "pipelinewise-tap-kafka-2.0.0.tar.gz", "has_sig": false, "md5_digest": "7f0e84ce725294d74b85627c715e9a46", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4958, "upload_time": "2020-01-07T09:46:10", "upload_time_iso_8601": "2020-01-07T09:46:10.250506Z", "url": "https://files.pythonhosted.org/packages/3a/11/528b0661e7b8be3a42c8daafc91ecc8c08732faf2460334a8dc7a04eec16/pipelinewise-tap-kafka-2.0.0.tar.gz", "yanked": false}], "2.1.0": [{"comment_text": "", "digests": {"md5": "9f572ef76c70046d278dc98423098876", "sha256": "376a9372ecafb963c2d400105f8c707397343bce6d3b2fbdb4ac13dfdea83e9a"}, "downloads": -1, "filename": "pipelinewise_tap_kafka-2.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "9f572ef76c70046d278dc98423098876", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 17685, "upload_time": "2020-02-18T13:45:00", "upload_time_iso_8601": "2020-02-18T13:45:00.821202Z", "url": "https://files.pythonhosted.org/packages/75/ec/e30cb936f1f14b274775a453cb9cb13e496c42c2dc3a238a305b0f57346b/pipelinewise_tap_kafka-2.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1e9f19208a686267697870fa20d103de", "sha256": "ef5852fd010afe4931e61dc25e650e209aa46b9e2cd15c85d63c3c5d58032469"}, "downloads": -1, "filename": "pipelinewise-tap-kafka-2.1.0.tar.gz", "has_sig": false, "md5_digest": "1e9f19208a686267697870fa20d103de", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5681, "upload_time": "2020-02-18T13:45:02", "upload_time_iso_8601": "2020-02-18T13:45:02.163197Z", "url": "https://files.pythonhosted.org/packages/9e/60/4b1614a396c44e82593405f64a58819b5e9b839ba039c25fbd298943ece2/pipelinewise-tap-kafka-2.1.0.tar.gz", "yanked": false}], "2.1.1": [{"comment_text": "", "digests": {"md5": "3515ba9dfa7389c05c17695e05fde564", "sha256": "e06dbb3d4bb64a3d37df5f807c4e0ca60f9255957be410c0a932a002df2d06a8"}, "downloads": -1, "filename": "pipelinewise_tap_kafka-2.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "3515ba9dfa7389c05c17695e05fde564", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 18157, "upload_time": "2020-03-23T09:54:38", "upload_time_iso_8601": "2020-03-23T09:54:38.750810Z", "url": "https://files.pythonhosted.org/packages/be/d4/63e76fddc315e9624b634aa9a931a41250e2503e52245ef0ecef777ffe61/pipelinewise_tap_kafka-2.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "176a9c0d69a6a680ec9138b6af66a578", "sha256": "220088380febe0c953cfb4c9b7dd695295e815d1138a67915386bde415c5a822"}, "downloads": -1, "filename": "pipelinewise-tap-kafka-2.1.1.tar.gz", "has_sig": false, "md5_digest": "176a9c0d69a6a680ec9138b6af66a578", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6117, "upload_time": "2020-03-23T09:54:40", "upload_time_iso_8601": "2020-03-23T09:54:40.022037Z", "url": "https://files.pythonhosted.org/packages/1d/44/2723dfe338636946d5cb524bc51364a7fd540b04e9a2ed703a94785e1906/pipelinewise-tap-kafka-2.1.1.tar.gz", "yanked": false}], "3.0.0": [{"comment_text": "", "digests": {"md5": "f327c942b6994be2fae67aff800a4fb5", "sha256": "707f357c29b57561172afd0b4642f15078cae6ed68f13d82c3653a78edee7d05"}, "downloads": -1, "filename": "pipelinewise_tap_kafka-3.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "f327c942b6994be2fae67aff800a4fb5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 22494, "upload_time": "2020-04-03T10:52:12", "upload_time_iso_8601": "2020-04-03T10:52:12.425011Z", "url": "https://files.pythonhosted.org/packages/12/45/c73b537f28bec48089b27ae8754a0ff68b96148c0029d3014b7c620eb8f7/pipelinewise_tap_kafka-3.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d78ba7bc03819ac9ad6ed2fd367a7200", "sha256": "556d3f9fd50c6a61a228d89a1681e636bc92b401020a551a4df56b0f2b1bee20"}, "downloads": -1, "filename": "pipelinewise-tap-kafka-3.0.0.tar.gz", "has_sig": false, "md5_digest": "d78ba7bc03819ac9ad6ed2fd367a7200", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10030, "upload_time": "2020-04-03T10:52:13", "upload_time_iso_8601": "2020-04-03T10:52:13.752492Z", "url": "https://files.pythonhosted.org/packages/f7/9d/192253e25aec5acb2ca127a26b5e1482f6af775dbb5f76c30f32d9f64980/pipelinewise-tap-kafka-3.0.0.tar.gz", "yanked": false}], "3.1.0": [{"comment_text": "", "digests": {"md5": "9005e563ff794b75a4f5de6808e85007", "sha256": "59199e0e1f8be5cf2f804d6a9a5b0cee6f113e4e706d7e2995e7c33ba55e70cf"}, "downloads": -1, "filename": "pipelinewise_tap_kafka-3.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "9005e563ff794b75a4f5de6808e85007", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 22570, "upload_time": "2020-04-21T07:35:33", "upload_time_iso_8601": "2020-04-21T07:35:33.814215Z", "url": "https://files.pythonhosted.org/packages/fa/2b/820d0ac4cd4dee900bf15be37d6629fdd0c6d4b17bf9ad8208ba335ef608/pipelinewise_tap_kafka-3.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6b739eb08827bd2877facc08f24997ed", "sha256": "44243684b285ca4cbb27cad115388d9ea10e209f5bc9319bb53f02e1a3157d71"}, "downloads": -1, "filename": "pipelinewise-tap-kafka-3.1.0.tar.gz", "has_sig": false, "md5_digest": "6b739eb08827bd2877facc08f24997ed", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10096, "upload_time": "2020-04-21T07:35:34", "upload_time_iso_8601": "2020-04-21T07:35:34.776651Z", "url": "https://files.pythonhosted.org/packages/0e/a3/bd98e9ee281b385283c4968f721d47180135a97b35c7eeebd68e41b46bcf/pipelinewise-tap-kafka-3.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "9005e563ff794b75a4f5de6808e85007", "sha256": "59199e0e1f8be5cf2f804d6a9a5b0cee6f113e4e706d7e2995e7c33ba55e70cf"}, "downloads": -1, "filename": "pipelinewise_tap_kafka-3.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "9005e563ff794b75a4f5de6808e85007", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 22570, "upload_time": "2020-04-21T07:35:33", "upload_time_iso_8601": "2020-04-21T07:35:33.814215Z", "url": "https://files.pythonhosted.org/packages/fa/2b/820d0ac4cd4dee900bf15be37d6629fdd0c6d4b17bf9ad8208ba335ef608/pipelinewise_tap_kafka-3.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6b739eb08827bd2877facc08f24997ed", "sha256": "44243684b285ca4cbb27cad115388d9ea10e209f5bc9319bb53f02e1a3157d71"}, "downloads": -1, "filename": "pipelinewise-tap-kafka-3.1.0.tar.gz", "has_sig": false, "md5_digest": "6b739eb08827bd2877facc08f24997ed", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10096, "upload_time": "2020-04-21T07:35:34", "upload_time_iso_8601": "2020-04-21T07:35:34.776651Z", "url": "https://files.pythonhosted.org/packages/0e/a3/bd98e9ee281b385283c4968f721d47180135a97b35c7eeebd68e41b46bcf/pipelinewise-tap-kafka-3.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:54:19 2020"}