{"info": {"author": "Dhruv Bansal", "author_email": "dhruv@unchained-capital.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Topic :: Utilities"], "description": "# Celery Enqueue\n\n[Celery](http://www.celeryproject.org/) is a distributed task queue\nfor Python that uses [RabbitMQ](https://www.rabbitmq.com/) (or\n[Redis](https://redis.io/)) for state.\n\nThe usual pattern in Celery is to have task implementations and the\ncode which enqueues/schedules tasks within the same application:\n\n```python\n# in tasks.py\n\ndef doit(arg):\n\t...\n```\n\n```python\n# in app.py\nfrom tasks import *\nresult = doit.delay(123)\n```\n\nSometimes it is useful to be able to split these functions across\ntotally different hosts/applications, using Celery's state (e.g. -\nRabbitMQ) to connect them.  Unfortunately, Celery doesn't make it as\neasy as it could be to schedule the `doit` task without having the\n`tasks.py` file available locally.\n\nThe `celery-enqueue` program included with this library makes this\neasy.\n\n# Installation\n\nVia `pip`:\n\n```\n$ pip install celery-enqueue\n```\n\nVia source:\n\n```\n$ git clone https://github.com/unchained-capital/celery-enqueue\n$ cd celery-enqueue\n$ make\n```\n\n# Usage\n\n## Command-Line\n\nAssuming you installed via `pip`, the `celery-enqueue` command should\nbe installed.  Try running it with the `-h` flag to see more details:\n\n```\n$ celery-enqueue -h\n```\n\nIf you have a RabbitMQ server running locally at the default port with\nno custom vhosts, users, or security, you can run:\n\n```\n$ celery-enqueue my_app.tasks.my_task arg1 arg2\n```\n\nto enqueue the task `my_app.tasks.my_task` with arguments `('arg1',\n'arg2')` into the local RabbitMQ broker's `celery` queue.  This should\nbe identical to having run `my_app.tasks.my_task.delay(\"arg1\",\n\"arg2\")` from within your application.\n\nThis behavior can be configured on the command-line as well as via a\nconfiguration file.\n\n## Python\n\nAssuming that your `PYTHONPATH` is properly set up (this is handled\nfor you if you installed using `pip`), and you have a RabbitMQ server\nrunning locally at the default port with no custom vhosts, users, or\nsecurity, you can run:\n\n```python\nfrom celery_enqueue import enqueue\nenqueue(\"my_app.tasks.my_task\", [\"arg1\", \"arg2\"])\n```\n\nto enqueue the task `my_app.tasks.my_task` with arguments `('arg1',\n'arg2')` into the local RabbitMQ broker's `celery` queue.  This should\nbe identical to having run `my_app.tasks.my_task.delay(\"arg1\",\n\"arg2\")` from within your application.\n\nThis behavior can be configured at runtime:\n\n```python\nfrom celery_enqueue import enqueue, set_config\nset_config({'host': 'rabbitmq.internal'})\nenqueue(\"my_app.tasks.my_task\", [\"arg1\", \"arg2\"])\n```\n\n# Configuration\n\nSee `example/celery-enqueue.yml` in this repository for an example\nconfiguration file you can copy and modify.\n\n## RabbitMQ\n\nSome configuration is needed to find your RabbitMQ server and to\nensure data is enqueued so your Celery tasks will find it.\n\nBy default, the scripts will attempt to connect to the vhost `/` on a\nlocal RabbitMQ server on the default port (5672) with no\nauthentication.\n\nThe following configuration settings affect this default behavior:\n\n* `user` -- the name of the RabbitMQ user\n* `password` -- the password of the RabbitMQ user\n* `host` -- the hostname or IP of the RabbitMQ broker\n* `port` -- the port of the RabbitMQ broker\n* `vhost` -- the RabbitMQ vhost used by Celery\n* `queue` -- the RabbitMQ queue used by Celery\n\nThese settings can be provided on the command-line, via a\nconfiguration file, or by calling `set_config`.\n\n## Error handling\n\nIn case of an uncaught exception, the default behavior is for\n`celery-enqueue` to print a Python stacktrace and exit with a nonzero\nreturn code.\n\nThe following configuration settings affect this default behavior:\n\n* `success` -- make `celery-enqueue` always exit successfully with a return code of 0\n* `error_command` -- run this command.  The following strings will be interpolated:\n * `%e` -- the error message of the exception\n * `%u` -- the (masked) URL of the RabbitMQ broker\n * `%t` -- the name of the task\n * `%a` -- the arguments to the task\n\n(The `error_command` will only run if `success` is also set.)\n\nA simple example, handled via a configuration file:\n\n```yaml\n# in config.yml\nerror_command: |\t\n\techo 'ERROR: Failed to enqueue task %t(%a) at broker %u. (%e)'\n```\n\nAnd invoked like this:\n\n```\n  $ celery-enqueue -c config.yml my_app.tasks.my_task arg1 arg2\n```", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/unchained-capital/celery-enqueue", "keywords": "celery rabbitmq", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "celery-enqueue", "package_url": "https://pypi.org/project/celery-enqueue/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/celery-enqueue/", "project_urls": {"Homepage": "https://github.com/unchained-capital/celery-enqueue"}, "release_url": "https://pypi.org/project/celery-enqueue/1.0.1/", "requires_dist": ["PyYAML", "celery (>=4)"], "requires_python": "", "summary": "Command-line program to enqueue tasks within RabbitMQ for processing by Celery", "version": "1.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            # Celery Enqueue<br><br>[Celery](http://www.celeryproject.org/) is a distributed task queue<br>for Python that uses [RabbitMQ](https://www.rabbitmq.com/) (or<br>[Redis](https://redis.io/)) for state.<br><br>The usual pattern in Celery is to have task implementations and the<br>code which enqueues/schedules tasks within the same application:<br><br>```python<br># in tasks.py<br><br>def doit(arg):<br>\t...<br>```<br><br>```python<br># in app.py<br>from tasks import *<br>result = doit.delay(123)<br>```<br><br>Sometimes it is useful to be able to split these functions across<br>totally different hosts/applications, using Celery's state (e.g. -<br>RabbitMQ) to connect them.  Unfortunately, Celery doesn't make it as<br>easy as it could be to schedule the `doit` task without having the<br>`tasks.py` file available locally.<br><br>The `celery-enqueue` program included with this library makes this<br>easy.<br><br># Installation<br><br>Via `pip`:<br><br>```<br>$ pip install celery-enqueue<br>```<br><br>Via source:<br><br>```<br>$ git clone https://github.com/unchained-capital/celery-enqueue<br>$ cd celery-enqueue<br>$ make<br>```<br><br># Usage<br><br>## Command-Line<br><br>Assuming you installed via `pip`, the `celery-enqueue` command should<br>be installed.  Try running it with the `-h` flag to see more details:<br><br>```<br>$ celery-enqueue -h<br>```<br><br>If you have a RabbitMQ server running locally at the default port with<br>no custom vhosts, users, or security, you can run:<br><br>```<br>$ celery-enqueue my_app.tasks.my_task arg1 arg2<br>```<br><br>to enqueue the task `my_app.tasks.my_task` with arguments `('arg1',<br>'arg2')` into the local RabbitMQ broker's `celery` queue.  This should<br>be identical to having run `my_app.tasks.my_task.delay(\"arg1\",<br>\"arg2\")` from within your application.<br><br>This behavior can be configured on the command-line as well as via a<br>configuration file.<br><br>## Python<br><br>Assuming that your `PYTHONPATH` is properly set up (this is handled<br>for you if you installed using `pip`), and you have a RabbitMQ server<br>running locally at the default port with no custom vhosts, users, or<br>security, you can run:<br><br>```python<br>from celery_enqueue import enqueue<br>enqueue(\"my_app.tasks.my_task\", [\"arg1\", \"arg2\"])<br>```<br><br>to enqueue the task `my_app.tasks.my_task` with arguments `('arg1',<br>'arg2')` into the local RabbitMQ broker's `celery` queue.  This should<br>be identical to having run `my_app.tasks.my_task.delay(\"arg1\",<br>\"arg2\")` from within your application.<br><br>This behavior can be configured at runtime:<br><br>```python<br>from celery_enqueue import enqueue, set_config<br>set_config({'host': 'rabbitmq.internal'})<br>enqueue(\"my_app.tasks.my_task\", [\"arg1\", \"arg2\"])<br>```<br><br># Configuration<br><br>See `example/celery-enqueue.yml` in this repository for an example<br>configuration file you can copy and modify.<br><br>## RabbitMQ<br><br>Some configuration is needed to find your RabbitMQ server and to<br>ensure data is enqueued so your Celery tasks will find it.<br><br>By default, the scripts will attempt to connect to the vhost `/` on a<br>local RabbitMQ server on the default port (5672) with no<br>authentication.<br><br>The following configuration settings affect this default behavior:<br><br>* `user` -- the name of the RabbitMQ user<br>* `password` -- the password of the RabbitMQ user<br>* `host` -- the hostname or IP of the RabbitMQ broker<br>* `port` -- the port of the RabbitMQ broker<br>* `vhost` -- the RabbitMQ vhost used by Celery<br>* `queue` -- the RabbitMQ queue used by Celery<br><br>These settings can be provided on the command-line, via a<br>configuration file, or by calling `set_config`.<br><br>## Error handling<br><br>In case of an uncaught exception, the default behavior is for<br>`celery-enqueue` to print a Python stacktrace and exit with a nonzero<br>return code.<br><br>The following configuration settings affect this default behavior:<br><br>* `success` -- make `celery-enqueue` always exit successfully with a return code of 0<br>* `error_command` -- run this command.  The following strings will be interpolated:<br> * `%e` -- the error message of the exception<br> * `%u` -- the (masked) URL of the RabbitMQ broker<br> * `%t` -- the name of the task<br> * `%a` -- the arguments to the task<br><br>(The `error_command` will only run if `success` is also set.)<br><br>A simple example, handled via a configuration file:<br><br>```yaml<br># in config.yml<br>error_command: |\t<br>\techo 'ERROR: Failed to enqueue task %t(%a) at broker %u. (%e)'<br>```<br><br>And invoked like this:<br><br>```<br>  $ celery-enqueue -c config.yml my_app.tasks.my_task arg1 arg2<br>```\n          </div>"}, "last_serial": 2699653, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "d64b3aa983833f6f04d0399037392638", "sha256": "9d42f1f7258d01d2a8deb4c0640ca433ade4575b60a415f5ea7214c1c23e7fa8"}, "downloads": -1, "filename": "celery_enqueue-1.0.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "d64b3aa983833f6f04d0399037392638", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 9440, "upload_time": "2017-03-11T20:59:54", "upload_time_iso_8601": "2017-03-11T20:59:54.445457Z", "url": "https://files.pythonhosted.org/packages/77/c9/c8d545915d44a393e393c9afd0d80fb0d62b45c432e8524813413a6b9d21/celery_enqueue-1.0.0-py2.py3-none-any.whl", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "d8cac2c38f215d487132207a08b8726b", "sha256": "90ac20bd51b194fc0eb742e815f3f79fd519920c71307709b31e67a6e57b5f34"}, "downloads": -1, "filename": "celery_enqueue-1.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "d8cac2c38f215d487132207a08b8726b", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 9437, "upload_time": "2017-03-11T21:07:26", "upload_time_iso_8601": "2017-03-11T21:07:26.630363Z", "url": "https://files.pythonhosted.org/packages/0d/da/16eaeb73615c18e5e303d0dd116720d27a7f35c6e9229f213e60975b8ec5/celery_enqueue-1.0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d5dfd9d7c20e5c88aef08b9aec492d29", "sha256": "ba9ae92ac07cf8826c33e18811cace9e5e1fa9b15e78ff6ddce4c827e2b98d47"}, "downloads": -1, "filename": "celery-enqueue-1.0.1.tar.gz", "has_sig": false, "md5_digest": "d5dfd9d7c20e5c88aef08b9aec492d29", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6606, "upload_time": "2017-03-11T21:07:28", "upload_time_iso_8601": "2017-03-11T21:07:28.582404Z", "url": "https://files.pythonhosted.org/packages/bd/05/c24beb45c6b6279bab9d3e3b2600e6e6a53b8ba643a33bb7c2e2770a237e/celery-enqueue-1.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "d8cac2c38f215d487132207a08b8726b", "sha256": "90ac20bd51b194fc0eb742e815f3f79fd519920c71307709b31e67a6e57b5f34"}, "downloads": -1, "filename": "celery_enqueue-1.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "d8cac2c38f215d487132207a08b8726b", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 9437, "upload_time": "2017-03-11T21:07:26", "upload_time_iso_8601": "2017-03-11T21:07:26.630363Z", "url": "https://files.pythonhosted.org/packages/0d/da/16eaeb73615c18e5e303d0dd116720d27a7f35c6e9229f213e60975b8ec5/celery_enqueue-1.0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d5dfd9d7c20e5c88aef08b9aec492d29", "sha256": "ba9ae92ac07cf8826c33e18811cace9e5e1fa9b15e78ff6ddce4c827e2b98d47"}, "downloads": -1, "filename": "celery-enqueue-1.0.1.tar.gz", "has_sig": false, "md5_digest": "d5dfd9d7c20e5c88aef08b9aec492d29", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6606, "upload_time": "2017-03-11T21:07:28", "upload_time_iso_8601": "2017-03-11T21:07:28.582404Z", "url": "https://files.pythonhosted.org/packages/bd/05/c24beb45c6b6279bab9d3e3b2600e6e6a53b8ba643a33bb7c2e2770a237e/celery-enqueue-1.0.1.tar.gz", "yanked": false}], "timestamp": "Thu May  7 22:34:52 2020"}