{"info": {"author": "chimera0", "author_email": "ai-brain-lab@accel-brain.com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Framework :: Robot Framework", "Intended Audience :: Information Technology", "Intended Audience :: Science/Research", "License :: OSI Approved :: GNU General Public License v2 (GPLv2)", "Programming Language :: Python :: 3", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "# Generative Adversarial Networks Library: pygan\n\n`pygan` is Python library to implement Generative Adversarial Networks(GANs), *Conditional* GANs, Adversarial Auto-Encoders(AAEs), and Energy-based Generative Adversarial Network(EBGAN).\n\nThis library makes it possible to design the Generative models based on the Statistical machine learning problems in relation to Generative Adversarial Networks(GANs), *Conditional* GANs, Adversarial Auto-Encoders(AAEs), and Energy-based Generative Adversarial Network(EBGAN) to practice algorithm design for semi-supervised learning. But this library provides components for designers, not for end-users of state-of-the-art black boxes. Briefly speaking the philosophy of this library, *give user hype-driven blackboxes and you feed him for a day; show him how to design algorithms and you feed him for a lifetime.* So algorithm is power.\n\nSee also ...\n\n- [Algorithmic Composition or Automatic Composition Library: pycomposer](https://github.com/chimera0/accel-brain-code/tree/master/Algorithmic-Composition)\n   * If you want to implement the Algorithmic Composer based on Generative Adversarial Networks(GANs) and the *Conditional* GANs by using `pygan` as components for Generative models based on the Statistical machine learning problems.\n\n## Installation\n\nInstall using pip:\n\n```sh\npip install pygan\n```\n\n### Source code\n\nThe source code is currently hosted on GitHub.\n\n- [accel-brain-code/Generative-Adversarial-Networks](https://github.com/chimera0/accel-brain-code/tree/master/Generative-Adversarial-Networks)\n\n### Python package index(PyPI)\n\nInstallers for the latest released version are available at the Python package index.\n\n- [pygan : Python Package Index](https://pypi.python.org/pypi/pygan/)\n\n### Dependencies\n\n- numpy: v1.13.3 or higher.\n\n#### Option\n\n- [pydbm](https://github.com/chimera0/accel-brain-code/tree/master/Deep-Learning-by-means-of-Design-Pattern): v1.4.9 or higher.\n    * Only if you want to implement the components based on this library.\n\n## Documentation\n\nFull documentation is available on [https://code.accel-brain.com/Generative-Adversarial-Networks/](https://code.accel-brain.com/Generative-Adversarial-Networks/) . This document contains information on functionally reusability, functional scalability and functional extensibility.\n\n## Description\n\n`pygan` is Python library to implement Generative Adversarial Networks(GANs), *Conditional* GANs, Adversarial Auto-Encoders(AAEs), and Energy-based Generative Adversarial Network(EBGAN).\n\nThe Generative Adversarial Networks(GANs) (Goodfellow et al., 2014) framework establishes a\nmin-max adversarial game between two neural networks \u2013 a generative model, `G`, and a discriminative\nmodel, `D`. The discriminator model, `D(x)`, is a neural network that computes the probability that\na observed data point `x` in data space is a sample from the data distribution (positive samples) that we are trying to model, rather than a sample from our generative model (negative samples). Concurrently, the generator uses a function `G(z)` that maps samples `z` from the prior `p(z)` to the data space. `G(z)` is trained to maximally confuse the discriminator into believing that samples it generates come from the data distribution. The generator is trained by leveraging the gradient of `D(x)` w.r.t. `x`, and using that to modify its parameters.\n\n### Structural extension for *Conditional* GANs (or cGANs).\n\nThe *Conditional* GANs (or cGANs) is a simple extension of the basic GAN model which allows the model to condition on external information. This makes it possible to engage the learned generative model in different \"modes\" by providing it with different contextual information (Gauthier, J. 2014).\n\nThis model can be constructed by simply feeding the data, `y`, to condition on to both the generator and discriminator. In an unconditioned generative model, because the maps samples `z` from the prior `p(z)` are drawn from uniform or normal distribution, there is no control on modes of the data being generated. On the other hand, it is possible to direct the data generation process by conditioning the model on additional information (Mirza, M., & Osindero, S. 2014).\n\n### Structural extension for Adversarial Auto-Encoders(AAEs).\n\nThis library also provides the Adversarial Auto-Encoders(AAEs), which is a probabilistic Auto-Encoder that uses GANs to perform variational inference by matching the aggregated posterior of the feature points in hidden layer of the Auto-Encoder with an arbitrary prior distribution(Makhzani, A., et al., 2015). Matching the aggregated posterior to the prior ensures that generating from any part of prior space results in meaningful samples. As a result, the decoder of the Adversarial Auto-Encoder learns a deep generative model that maps the imposed prior to the data distribution.\n\n### Structural extension for Energy-based Generative Adversarial Network(EBGAN).\n\nReusing the Auto-Encoders, this library introduces the Energy-based Generative Adversarial Network (EBGAN) model(Zhao, J., et al., 2016) which views the discriminator as an energy function that attributes low energies to the regions near the data manifold and higher energies to other regions. THe Auto-Encoders have traditionally been used to represent energy-based models. When trained with some regularization terms, the Auto-Encoders have the ability to learn an energy manifold without supervision or negative examples. This means that even when an energy-based Auto-Encoding model is trained to reconstruct a real sample, the model contributes to discovering the data manifold by itself.\n\n### The Commonality/Variability Analysis in order to practice object-oriented design.\n\nFrom perspective of *commonality/variability* analysis in order to practice object-oriented design, the concepts of GANs and AAEs can be organized as follows:\n\n<div>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/draw.io/pygan_class_diagram_20190603.png\">\n</div>\n\nThe configuration is based on the `Strategy Pattern`, which provides a way to define a family of algorithms implemented by inheriting the interface or abstract class such as `TrueSampler`, `NoiseSampler`, `GenerativeModel`, and `DiscriminativeModel`, where ...\n    - `TrueSampler` is the interface to provide `x` by drawing from the `true` distributions.\n    - `GenerativeModel` is the abstract class to generate `G(z)` by drawing from the `fake` distributions with `NoiseSampler` which provides `z`.\n    - `DiscriminativeModel` is the interface to inference that observed data points are `true` or `fake` as a `D(x)`.\n\nThis pattern is encapsulate each one as an object, and make them interchangeable from the point of view of functionally equivalent. This library provides sub classes such as Neural Networks, Convolutional Neural Networks, and LSTM networks. Althogh those models are variable from the view points of learning algorithms, but as a `GenerativeModel` or a `DiscriminativeModel` those models have common function.\n\n`GenerativeAdversarialNetworks` is a *Context* in the `Strategy Pattern`, controlling the objects of `TrueSampler`, `GenerativeModel`, and `DiscriminativeModel` in order to train `G(z)` and `D(x)`. This *context* class also calls the object of `GANsValueFunction`, whose function is computing the rewards or gradients in GANs framework.\n\nThe structural extension from GANs to AAEs is achieved by the inheritance of two classes: `GenerativeModel` and `GenerativeAdversarialNetworks`. One of the main concepts of AAEs, which is worthy of special mention, can be considered that *the Auto-Encoders can be transformed into the generative Models*. Therefore this library firstly implements a `AutoEncoderModel` by inheriting `GenerativeModel`. Next, this library watches closely that the difference between GANs and AAEs brings us different *context* in the `Strategy Pattern` in relation to the learning algorithm of Auto-Encoders. By the addition of the `AutoEncoderModel`'s learning method, this library provieds `AdversarialAutoEncoders` which is-a `GenerativeAdversarialNetworks` and makes it possible to train not only `GenerativeModel` and `DiscriminativeModel` but also `AutoEncoderModel`.\n\nFurthermore, `FeatureMatching` is a value function with so-called Feature matching technic, which addresses the instability of GANs by specifying a new objective for the generator that prevents it from overtraining on the current discriminator(Salimans, T., et al., 2016).\n\n<div>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/draw.io/pygan_class_diagram--ConditionalGANs.png\">\n</div>\n\nLike Yang, L. C., et al. (2017), this library implements the `Conditioner` to conditon on external information. As class configuration in this library, the `Conditioner` is divided into two, `ConditionalGenerativeModel` and `ConditionalTrueSampler`. This library consider that the `ConditionalGenerativeModel` and `ConditionalTrueSampler` contain `Conditioner` of the *Conditional* GANs to reduce the burden of architectural design. The controller `GenerativeAdversarialNetworks` functionally uses the conditions in a black boxed state.\n\n## Usecase: Generating Sine Waves by GANs.\n\nSet hyperparameters.\n\n```python\n# Batch size\nbatch_size = 20\n# The length of sequences.\nseq_len = 30\n# The dimension of observed or feature points.\ndim = 5\n```\n\nImport Python modules.\n\n```python\n# is-a `TrueSampler`.\nfrom pygan.truesampler.sine_wave_true_sampler import SineWaveTrueSampler\n# is-a `NoiseSampler`.\nfrom pygan.noisesampler.uniform_noise_sampler import UniformNoiseSampler\n# is-a `GenerativeModel`.\nfrom pygan.generativemodel.lstm_model import LSTMModel\n# is-a `DiscriminativeModel`.\nfrom pygan.discriminativemodel.nn_model import NNModel\n# is-a `GANsValueFunction`.\nfrom pygan.gansvaluefunction.mini_max import MiniMax\n# GANs framework.\nfrom pygan.generative_adversarial_networks import GenerativeAdversarialNetworks\n```\n\nSetup `TrueSampler`.\n\n```python\ntrue_sampler = SineWaveTrueSampler(\n    batch_size=batch_size,\n    seq_len=seq_len,\n    dim=dim\n)\n```\n\nSetup `NoiseSampler` and `GenerativeModel`.\n\n```python\nnoise_sampler = UniformNoiseSampler(\n    # Lower boundary of the output interval.\n    low=-1, \n    # Upper boundary of the output interval.\n    high=1, \n    # Output shape.\n    output_shape=(batch_size, 1, dim)\n)\n\ngenerative_model = LSTMModel(\n    batch_size=batch_size,\n    seq_len=seq_len,\n    input_neuron_count=dim,\n    hidden_neuron_count=dim\n)\ngenerative_model.noise_sampler = noise_sampler\n```\n\nSetup `DiscriminativeModel` with [pydbm](https://github.com/chimera0/accel-brain-code/tree/master/Deep-Learning-by-means-of-Design-Pattern) library.\n\n```python\n# Computation graph for Neural network.\nfrom pydbm.synapse.nn_graph import NNGraph\n# Layer object of Neural network.\nfrom pydbm.nn.nn_layer import NNLayer\n#$ Logistic function or Sigmoid function which is-a `ActivatingFunctionInterface`.\nfrom pydbm.activation.logistic_function import LogisticFunction\n\nnn_layer = NNLayer(\n    graph=NNGraph(\n        activation_function=LogisticFunction(),\n        # The number of units in hidden layer.\n        hidden_neuron_count=seq_len * dim,\n        # The number of units in output layer.\n        output_neuron_count=1\n    )\n)\n\ndiscriminative_model = NNModel(\n    # `list` of `NNLayer`.\n    nn_layer_list=[nn_layer],\n    batch_size=batch_size\n)\n```\n\nSetup the value function.\n\n```python\ngans_value_function = MiniMax()\n```\n\nSetup GANs framework.\n\n```python\nGAN = GenerativeAdversarialNetworks(\n    gans_value_function=gans_value_function\n)\n```\n\nIf you want to setup GNAs framework with so-called feature matching technic, which is effective in situations where regular GAN becomes unstable(Salimans, T., et al., 2016), setup GANs framework as follows:\n\n```python\nGAN = GenerativeAdversarialNetworks(\n    gans_value_function=gans_value_function,\n    feature_matching=FeatureMatching(\n        # Weight for results of standard feature matching.\n        lambda1=0.01, \n        # Weight for results of difference between generated data points and true samples.\n        lambda2=0.99\n    )\n)\n```\n\nwhere `lambda1` and `lambda2` are trade-off parameters. `lambda1` means a weight for results of standard feature matching and `lambda2` means a weight for results of difference between generated data points and true samples(Yang, L. C., et al., 2017).\n\nStart training.\n\n```python\ngenerative_model, discriminative_model = GAN.train(\n    true_sampler,\n    generative_model,\n    discriminative_model,\n    # The number of training iterations.\n    iter_n=100,\n    # The number of learning of the discriminative_model.\n    k_step=10\n)\n```\n\n#### Visualization.\n\nCheck the rewards or losses.\n\n```python\nd_logs_list, g_logs_list = GAN.extract_logs_tuple()\n```\n\n`d_logs_list` is a `list` of probabilities inferenced by the `discriminator` (mean) in the `discriminator`'s update turn and `g_logs_list` is a `list` of probabilities inferenced by the `discriminator` (mean) in the `generator`'s update turn.\n\nVisualize the values of `d_logs_list`.\n\n```python\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%config InlineBackend.figure_format = \"retina\"\nplt.style.use(\"fivethirtyeight\")\nplt.figure(figsize=(20, 10))\nplt.plot(d_logs_list)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.show()\n```\n\n<div>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/logs/probability_in_D_LSTM.png\">\n</div>\n\nSimilarly, visualize the values of `g_logs_list`.\n\n```python\nplt.figure(figsize=(20, 10))\nplt.plot(g_logs_list)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.show()\n```\n\n<div>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/logs/probability_in_G_LSTM.png\">\n</div>\n\nAs the training progresses, the values are close to `0.5`.\n\n#### Generation.\n\nPlot a true distribution and generated data points to check how the `discriminator` was *confused* by the `generator`.\n\n```python\ntrue_arr = true_sampler.draw()\n\nplt.style.use(\"fivethirtyeight\")\nplt.figure(figsize=(20, 10))\nplt.plot(true_arr[0])\nplt.show()\n```\n\n<div>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/sinewave/sine_wave_true.png\">\n</div>\n\n```python\ngenerated_arr = generative_model.draw()\n\nplt.style.use(\"fivethirtyeight\")\nplt.figure(figsize=(20, 10))\nplt.plot(generated_arr[0])\nplt.show()\n```\n\n<div>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/sinewave/sine_wave_fake.png\">\n</div>\n\n### Usecase: Generating images by AAEs.\n\nIn this demonstration, we use image dataset in [the Weizmann horse dataset](https://avaminzhang.wordpress.com/2012/12/07/%E3%80%90dataset%E3%80%91weizmann-horses/). [pydbm](https://github.com/chimera0/accel-brain-code/tree/master/Deep-Learning-by-means-of-Design-Pattern) library used this dataset to demonstrate for [observing reconstruction images by Convolutional Auto-Encoder.](https://github.com/chimera0/accel-brain-code/blob/master/Deep-Learning-by-means-of-Design-Pattern/demo/demo_convolutional_auto_encoder.ipynb) and Shape boltzmann machines as follows.\n\n<table border=\"0\">\n    <tr>\n        <td>\n            <img src=\"https://storage.googleapis.com/accel-brain-code/Deep-Learning-by-means-of-Design-Pattern/img/horse099.jpg\" />\n        <p>Image in <a href=\"https://avaminzhang.wordpress.com/2012/12/07/%E3%80%90dataset%E3%80%91weizmann-horses/\" target=\"_blank\">the Weizmann horse dataset</a>.</p>\n        </td>\n        <td>\n            <img src=\"https://storage.googleapis.com/accel-brain-code/Deep-Learning-by-means-of-Design-Pattern/img/reconstructed_horse099.gif\" />\n            <p>Reconstructed image by <strong>Shape-BM</strong>.</p>\n        </td>\n        <td>\n            <img src=\"https://storage.googleapis.com/accel-brain-code/Deep-Learning-by-means-of-Design-Pattern/img/reconstructed_by_CAE.gif\" />\n            <p>Reconstructed image by <strong>Convolutional Auto-Encoder</strong>.</p>\n        </td>\n    </tr>\n</table>\n\nThis library also provides the Convolutional Auto-Encoder, which can be functionally re-used as `AutoEncoderModel`, loosely coupling with `AdversarialAutoEncoders`.\n\nSet hyperparameters and directory path that stores your image files.\n\n```python\nbatch_size = 20\n# Width of images.\nwidth = 100\n# height of images.\nheight = 100\n# Channel of images.\nchannel = 1\n# Path to your image files.\nimage_dir = \"your/path/to/images/\"\n# The length of sequneces. If `None`, the objects will ignore sequneces.\nseq_len = None\n# Gray scale or not.\ngray_scale_flag = True\n# The tuple of width and height.\nwh_size_tuple = (width, height)\n# How to normalize pixel values of images.\n#   - `z_score`: Z-Score normalization.\n#   - `min_max`: Min-max normalization.\n#   - `tanh`: Normalization by tanh function.\nnorm_mode = \"z_score\"\n```\n\nImport Python modules.\n\n```python\n# is-a `TrueSampler`.\nfrom pygan.truesampler.image_true_sampler import ImageTrueSampler\n# is-a `NoiseSampler`.\nfrom pygan.noisesampler.image_noise_sampler import ImageNoiseSampler\n# is-a `AutoencoderModel`.\nfrom pygan.generativemodel.autoencodermodel.convolutional_auto_encoder import ConvolutionalAutoEncoder as Generator\n# is-a `DiscriminativeModel`.\nfrom pygan.discriminativemodel.cnn_model import CNNModel as Discriminator\n# `AdversarialAutoEncoders` which is-a `GenerativeAdversarialNetworks`.\nfrom pygan.generativeadversarialnetworks.adversarial_auto_encoders import AdversarialAutoEncoders\n# Value function.\nfrom pygan.gansvaluefunction.mini_max import MiniMax\n# Feature Matching.\nfrom pygan.feature_matching import FeatureMatching\n```\n\nImport [pydbm](https://github.com/chimera0/accel-brain-code/tree/master/Deep-Learning-by-means-of-Design-Pattern) modules.\n\n```python\n# Convolution layer.\nfrom pydbm.cnn.layerablecnn.convolution_layer import ConvolutionLayer\n# Computation graph in output layer.\nfrom pydbm.synapse.cnn_output_graph import CNNOutputGraph\n# Computation graph for convolution layer.\nfrom pydbm.synapse.cnn_graph import CNNGraph\n# Logistic Function as activation function.\nfrom pydbm.activation.logistic_function import LogisticFunction\n# Tanh Function as activation function.\nfrom pydbm.activation.tanh_function import TanhFunction\n# ReLu Function as activation function.\nfrom pydbm.activation.relu_function import ReLuFunction\n# SGD optimizer.\nfrom pydbm.optimization.optparams.sgd import SGD\n# Adam optimizer.\nfrom pydbm.optimization.optparams.adam import Adam\n# MSE.\nfrom pydbm.loss.mean_squared_error import MeanSquaredError\n# Convolutional Auto-Encoder.\nfrom pydbm.cnn.convolutionalneuralnetwork.convolutional_auto_encoder import ConvolutionalAutoEncoder as CAE\n# Deconvolution layer.\nfrom pydbm.cnn.layerablecnn.convolutionlayer.deconvolution_layer import DeconvolutionLayer\n# Verification object.\nfrom pydbm.verification.verificate_function_approximation import VerificateFunctionApproximation\n```\n\nSetup `TrueSampler`.\n\n```python\ntrue_sampler = ImageTrueSampler(\n    batch_size=batch_size,\n    image_dir=image_dir,\n    seq_len=seq_len,\n    gray_scale_flag=gray_scale_flag,\n    wh_size_tuple=wh_size_tuple,\n    norm_mode=norm_mode\n)\n```\n\nSetup `NoiseSampler` and `AutoEncoderModel`.\n\n```python\nnoise_sampler = ImageNoiseSampler(\n    batch_size,\n    image_dir,\n    seq_len=seq_len,\n    gray_scale_flag=gray_scale_flag,\n    wh_size_tuple=wh_size_tuple,\n    norm_mode=norm_mode\n)\n\nif gray_scale_flag is True:\n    channel = 1\nelse:\n    channel = 3\nscale = 0.1\n\nconv1 = ConvolutionLayer(\n    CNNGraph(\n        activation_function=TanhFunction(),\n        # The number of filters.\n        filter_num=batch_size,\n        channel=channel,\n        # Kernel size.\n        kernel_size=3,\n        scale=scale,\n        # The number of strides.\n        stride=1,\n        # The number of zero-padding.\n        pad=1\n    )\n)\n\nconv2 = ConvolutionLayer(\n    CNNGraph(\n        activation_function=TanhFunction(),\n        filter_num=batch_size,\n        channel=batch_size,\n        kernel_size=3,\n        scale=scale,\n        stride=1,\n        pad=1\n    )\n)\n\ndeconvolution_layer_list = [\n    DeconvolutionLayer(\n        CNNGraph(\n            activation_function=TanhFunction(),\n            filter_num=batch_size,\n            channel=channel,\n            kernel_size=5,\n            scale=scale,\n            stride=1,\n            pad=1\n        )\n    )\n]\n\nopt_params = Adam()\n# The probability of dropout.\nopt_params.dropout_rate = 0.0\n\nconvolutional_auto_encoder = CAE(\n    layerable_cnn_list=[\n        conv1, \n        conv2\n    ],\n    epochs=100,\n    batch_size=batch_size,\n    learning_rate=1e-05,\n    # # Attenuate the `learning_rate` by a factor of this value every `attenuate_epoch`.\n    learning_attenuate_rate=0.1,\n    # # Attenuate the `learning_rate` by a factor of `learning_attenuate_rate` every `attenuate_epoch`.\n    attenuate_epoch=25,\n    computable_loss=MeanSquaredError(),\n    opt_params=opt_params,\n    verificatable_result=VerificateFunctionApproximation(),\n    # # Size of Test data set. If this value is `0`, the validation will not be executed.\n    test_size_rate=0.3,\n    # Tolerance for the optimization.\n    # When the loss or score is not improving by at least tol \n    # for two consecutive iterations, convergence is considered \n    # to be reached and training stops.\n    tol=1e-15\n)\n\ngenerator = Generator(\n    batch_size=batch_size,\n    learning_rate=1e-05,\n    convolutional_auto_encoder=convolutional_auto_encoder,\n    deconvolution_layer_list=deconvolution_layer_list,\n    gray_scale_flag=gray_scale_flag\n)\ngenerator.noise_sampler = noise_sampler\n```\n\nSetup `DiscriminativeModel`.\n\n```python\nconvD = ConvolutionLayer(\n    CNNGraph(\n        activation_function=TanhFunction(),\n        filter_num=batch_size,\n        channel=channel,\n        kernel_size=3,\n        scale=0.001,\n        stride=3,\n        pad=1\n    )\n)\n\nlayerable_cnn_list=[\n    convD\n]\n\nopt_params = Adam()\nopt_params.dropout_rate = 0.0\n\ncnn_output_graph = CNNOutputGraph(\n    # The number of units in hidden layer.\n    hidden_dim=23120, \n    # The number of units in output layer.\n    output_dim=1, \n    activating_function=LogisticFunction(), \n    scale=0.01\n)\n\ndiscriminator = Discriminator(\n    batch_size=batch_size,\n    layerable_cnn_list=layerable_cnn_list,\n    cnn_output_graph=cnn_output_graph,\n    learning_rate=1e-05,\n    opt_params=opt_params\n)\n```\n\nSetup AAEs framework.\n\n```python\nAAE = AdversarialAutoEncoders(\n    gans_value_function=MiniMax(),\n    feature_matching=FeatureMatching(\n        # Weight for results of standard feature matching.\n        lambda1=0.01, \n        # Weight for results of difference between generated data points and true samples.\n        lambda2=0.99\n    )\n)\n```\n\nStart pre-training.\n\n```python\ngenerator.pre_learn(true_sampler=true_sampler, epochs=1000)\n```\n\nStart training.\n\n```python\ngenerator, discriminator = AAE.train(\n    true_sampler=true_sampler,\n    generative_model=generator,\n    discriminative_model=discriminator,\n    iter_n=1000,\n    k_step=5\n)\n```\n\n#### Visualization.\n\nCheck the rewards or losses.\n\n##### Result of pre-training.\n\n```python\nplt.figure(figsize=(20, 10))\nplt.title(\"The reconstruction errors.\")\nplt.plot(generator.pre_loss_arr)\nplt.show()\nplt.close()\n```\n\n<div><img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/logs/AAE_pre_learning.png\"></div>\n\n##### Result of training.\n\n```python\na_logs_list, d_logs_list, g_logs_list = AAE.extract_logs_tuple()\n```\n\n`a_logs_list` is a `list` of the reconstruction errors.\n\nVisualize the values of `a_logs_list`.\n\n```python\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%config InlineBackend.figure_format = \"retina\"\nplt.figure(figsize=(20, 10))\nplt.title(\"The reconstruction errors.\")\nplt.plot(a_logs_list)\nplt.show()\nplt.close()\n```\n\n<div><img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/logs/all_reconstruction_errors.png\"></div>\n\nThe error is not decreasing in steps toward the lower side. Initially, the error is monotonically increased probably due to the side effects of `GeneratorModel` and `DiscriminativeModel` learning in GANs framework. However, as learning as an Auto-Encoder progresses gradually in AAEs framework, it converges after showing the tendency of the monotonous phenomenon.\n\nVisualize the values of `d_logs_list`.\n\n```python\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%config InlineBackend.figure_format = \"retina\"\nplt.style.use(\"fivethirtyeight\")\nplt.figure(figsize=(20, 10))\nplt.plot(d_logs_list)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.show()\n```\n\n<div>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/logs/probability_in_D.png\">\n</div>\n\nSimilarly, visualize the values of `g_logs_list`.\n\n```python\nplt.figure(figsize=(20, 10))\nplt.plot(g_logs_list)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.show()\n```\n\n<div>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/logs/probability_in_G.png\">\n</div>\n\nAs the training progresses, the values are close to not `0.5` but about `0.55`.\n\nApparently it was not perfect. But we can take heart from the generated images.\n\n#### Generation.\n\nLet's define a helper function for plotting.\n\n```python\ndef plot(arr):\n    '''\n    Plot three gray scaled images.\n\n    Args:\n        arr:    mini-batch data.\n\n    '''\n    for i in range(3):\n        plt.imshow(arr[i, 0], cmap=\"gray\");\n        plt.show()\n        plt.close()\n```\n\nDraw from a true distribution of images and input it to `plot` function.\n\n```python\narr = true_sampler.draw()\nplot(arr)\n```\n<div>\n<table>\n<tbody>\n<tr>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/observed/sample1.png\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/observed/sample2.png\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/observed/sample3.png\">\n</td>\n</tr>\n</tbody>\n</table>\n\n\nInput the generated `np.ndarray` to `plot` function.\n\n```python\narr = generator.draw()\nplot(arr)\n```\n\n<div>\n<table>\n<tbody>\n<tr>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/generated/after1500train/sample1.png\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/generated/after1500train/sample2.png\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/generated/after1500train/sample3.png\">\n</td>\n</tr>\n</tbody>\n</table>\n\nNext, observe the true images and reconstructed images.\n\n```python\nobserved_arr = generator.noise_sampler.generate()\ndecoded_arr = generator.inference(observed_arr)\nplot(observed_arr)\nplot(decoded_arr)\n```\n\n<div>\n<table>\n<tbody>\n<tr>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after1500train/input_sample1.png\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after1500train/input_sample2.png\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after1500train/input_sample3.png\">\n</td>\n</tr>\n<tr>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after1500train/decoded_sample1.png\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after1500train/decoded_sample2.png\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after1500train/decoded_sample3.png\">\n</td>\n</tr>\n</tbody>\n</table>\n\n#### About the progress of learning\n\nJust observing the results of learning does not tell how learning of each model is progressing. In the following, the progress of each learning step is confirmed from the generated images and the reconstructed images.\n\n##### Generated images in 500 step.\n\n```python\narr = generator.draw()\nplot(arr)\n```\n\n<div>\n<table>\n<tbody>\n<tr>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/generated/after500train/sample1.png\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/generated/after500train/sample2.png\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/generated/after500train/sample3.png\">\n</td>\n</tr>\n</tbody>\n</table>\n\n##### Generated images in 1000 step.\n\n```python\narr = generator.draw()\nplot(arr)\n```\n\n<div>\n<table>\n<tbody>\n<tr>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/generated/after1000train/sample1.png\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/generated/after1000train/sample2.png\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/generated/after1000train/sample3.png\">\n</td>\n</tr>\n</tbody>\n</table>\n\n##### Generated images in 1500 step.\n\n```python\narr = generator.draw()\nplot(arr)\n```\n\n<div>\n<table>\n<tbody>\n<tr>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/generated/after1500train/sample1.png\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/generated/after1500train/sample2.png\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/generated/after1500train/sample3.png\">\n</td>\n</tr>\n</tbody>\n</table>\n\n##### Reconstructed images in 500 step.\n\n```python\nobserved_arr = generator.noise_sampler.generate()\ndecoded_arr = generator.inference(observed_arr)\nplot(observed_arr)\nplot(decoded_arr)\n```\n\n<div>\n<table>\n<tbody>\n<tr>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after500train/input_sample4.png\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after500train/input_sample5.png\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after500train/input_sample6.png\">\n</td>\n</tr>\n<tr>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after500train/decoded_sample4.png\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after500train/decoded_sample5.png\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after500train/decoded_sample6.png\">\n</td>\n</tr>\n</tbody>\n</table>\n\n##### Reconstructed images in 1000 step.\n\n```python\nobserved_arr = generator.noise_sampler.generate()\ndecoded_arr = generator.inference(observed_arr)\nplot(observed_arr)\nplot(decoded_arr)\n```\n\n<div>\n<table>\n<tbody>\n<tr>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after1000train/input_sample1.png?1\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after1000train/input_sample2.png?1\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after1000train/input_sample3.png?1\">\n</td>\n</tr>\n<tr>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after1000train/decoded_sample1.png?1\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after1000train/decoded_sample2.png?1\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after1000train/decoded_sample3.png?1\">\n</td>\n</tr>\n</tbody>\n</table>\n\n##### Reconstructed images in 1500 step.\n\n```python\nobserved_arr = generator.noise_sampler.generate()\ndecoded_arr = generator.inference(observed_arr)\nplot(observed_arr)\nplot(decoded_arr)\n```\n\n<div>\n<table>\n<tbody>\n<tr>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after1500train/input_sample1.png\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after1500train/input_sample2.png\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after1500train/input_sample3.png\">\n</td>\n</tr>\n<tr>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after1500train/decoded_sample1.png\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after1500train/decoded_sample2.png\">\n</td>\n<td>\n<img src=\"https://storage.googleapis.com/accel-brain-code/Generative-Adversarial-Networks/decoded/after1500train/decoded_sample3.png\">\n</td>\n</tr>\n</tbody>\n</table>\n\n## References\n\n- Fang, W., Zhang, F., Sheng, V. S., & Ding, Y. (2018). A method for improving CNN-based image recognition using DCGAN. Comput. Mater. Contin, 57, 167-178.\n- Gauthier, J. (2014). Conditional generative adversarial nets for convolutional face generation. Class Project for Stanford CS231N: Convolutional Neural Networks for Visual Recognition, Winter semester, 2014(5), 2.\n- Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014). Generative adversarial nets. In Advances in neural information processing systems (pp. 2672-2680).\n- Long, J., Shelhamer, E., & Darrell, T. (2015). Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3431-3440).\n- Makhzani, A., Shlens, J., Jaitly, N., Goodfellow, I., & Frey, B. (2015). Adversarial autoencoders. arXiv preprint arXiv:1511.05644.\n- Mirza, M., & Osindero, S. (2014). Conditional generative adversarial nets. arXiv preprint arXiv:1411.1784.\n- Mogren, O. (2016). C-RNN-GAN: Continuous recurrent neural networks with adversarial training. arXiv preprint arXiv:1611.09904.\n- Rifai, S., Vincent, P., Muller, X., Glorot, X., & Bengio, Y. (2011, June). Contractive auto-encoders: Explicit invariance during feature extraction. In Proceedings of the 28th International Conference on International Conference on Machine Learning (pp. 833-840). Omnipress.\n- Rifai, S., Mesnil, G., Vincent, P., Muller, X., Bengio, Y., Dauphin, Y., & Glorot, X. (2011, September). Higher order contractive auto-encoder. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases (pp. 645-660). Springer, Berlin, Heidelberg.\n- Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., & Chen, X. (2016). Improved techniques for training gans. In Advances in neural information processing systems (pp. 2234-2242).\n- Yang, L. C., Chou, S. Y., & Yang, Y. H. (2017). MidiNet: A convolutional generative adversarial network for symbolic-domain music generation. arXiv preprint arXiv:1703.10847.\n- Zhao, J., Mathieu, M., & LeCun, Y. (2016). Energy-based generative adversarial network. arXiv preprint arXiv:1609.03126.\n- Warde-Farley, D., & Bengio, Y. (2016). Improving generative adversarial networks with denoising feature matching.\n\n### Related PoC\n\n- [\u6df1\u5c64\u5f37\u5316\u5b66\u7fd2\u306e\u30d9\u30a4\u30ba\u4e3b\u7fa9\u7684\u306a\u60c5\u5831\u63a2\u7d22\u306b\u99c6\u52d5\u3055\u308c\u305f\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\u306e\u610f\u5473\u8ad6](https://accel-brain.com/semantics-of-natural-language-processing-driven-by-bayesian-information-search-by-deep-reinforcement-learning/) (Japanese)\n    - [\u6b63\u5247\u5316\u554f\u984c\u306b\u304a\u3051\u308b\u6575\u5bfe\u7684\u751f\u6210\u30cd\u30c3\u30c8\u30ef\u30fc\u30af(GANs)\u3068\u6575\u5bfe\u7684\u81ea\u5df1\u7b26\u53f7\u5316\u5668(AAEs)\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u69cb\u9020](https://accel-brain.com/semantics-of-natural-language-processing-driven-by-bayesian-information-search-by-deep-reinforcement-learning/regularisierungsproblem-und-gan/)\n    - [\u968e\u5c64\u7684\u6f5c\u5728\u5909\u6570\u30e2\u30c7\u30eb\u3092\u30e1\u30c7\u30a3\u30a2\u3068\u3057\u305f\u30e9\u30c0\u30fc\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u534a\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u5f62\u5f0f\u3001\u30ce\u30a4\u30ba\u9664\u53bb\u578b\u81ea\u5df1\u7b26\u53f7\u5316\u5668\u306e\u6a5f\u80fd](https://accel-brain.com/semantics-of-natural-language-processing-driven-by-bayesian-information-search-by-deep-reinforcement-learning/hierarchical-latent-variable-model-as-media-and-semi-supervised-learning-of-ladder-network-as-a-form/)\n    - [\u30a8\u30cd\u30eb\u30ae\u30fc\u30d9\u30fc\u30b9\u30e2\u30c7\u30eb\u3068\u3057\u3066\u306e\u6575\u5bfe\u7684\u751f\u6210\u30cd\u30c3\u30c8\u30ef\u30fc\u30af(GAN)\u3068\u81ea\u5df1\u7b26\u53f7\u5316\u5668\u306b\u304a\u3051\u308b\u30ea\u30a2\u30d7\u30ce\u30d5\u5b89\u5b9a](https://accel-brain.com/semantics-of-natural-language-processing-driven-by-bayesian-information-search-by-deep-reinforcement-learning/lyaponov-stability-optimization-in-gan-and-auto-encoder-in-energy-based-models/)\n- [\u300c\u4eba\u5de5\u306e\u7406\u60f3\u300d\u3092\u80cc\u666f\u3068\u3057\u305f\u300c\u4e07\u7269\u7167\u5fdc\u300d\u306e\u30c7\u30fc\u30bf\u30e2\u30c7\u30ea\u30f3\u30b0](https://accel-brain.com/data-modeling-von-korrespondenz-in-artificial-paradise/) (Japanese)\n    - [\u30e9\u30f3\u30c0\u30e0\u30a6\u30a9\u30fc\u30af\u306e\u793e\u4f1a\u69cb\u9020\u3068\u30c0\u30a6\u7406\u8ad6\u306e\u610f\u5473\u8ad6\u3001\u518d\u5e30\u7684\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u4fa1\u683c\u5909\u52d5\u30e2\u30c7\u30eb\u304b\u3089\u6575\u5bfe\u7684\u751f\u6210\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\uff08GAN\uff09\u3078](https://accel-brain.com/data-modeling-von-korrespondenz-in-artificial-paradise/sozialstruktur-von-random-walk-und-semantik-der-dow-theorie/)\n\n## Author\n\n- chimera0(RUM)\n\n## Author URI\n\n- http://accel-brain.com/\n\n## License\n\n- GNU General Public License v2.0", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/chimera0/accel-brain-code/tree/master/Generative-Adversarial-Networks/", "keywords": "Generative Adversarial Networks Adversarial Auto-Encoders autoencoder auto-encoder convolution deconvolution encoder decoder LSTM", "license": "GPL2", "maintainer": "", "maintainer_email": "", "name": "pygan", "package_url": "https://pypi.org/project/pygan/", "platform": "", "project_url": "https://pypi.org/project/pygan/", "project_urls": {"Homepage": "https://github.com/chimera0/accel-brain-code/tree/master/Generative-Adversarial-Networks/"}, "release_url": "https://pypi.org/project/pygan/1.0.8/", "requires_dist": null, "requires_python": "", "summary": "pygan is Python library to implement Generative Adversarial Networks(GANs), Conditional GANs, Adversarial Auto-Encoders(AAEs), and Energy-based Generative Adversarial Network(EBGAN).", "version": "1.0.8", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Generative Adversarial Networks Library: pygan</h1>\n<p><code>pygan</code> is Python library to implement Generative Adversarial Networks(GANs), <em>Conditional</em> GANs, Adversarial Auto-Encoders(AAEs), and Energy-based Generative Adversarial Network(EBGAN).</p>\n<p>This library makes it possible to design the Generative models based on the Statistical machine learning problems in relation to Generative Adversarial Networks(GANs), <em>Conditional</em> GANs, Adversarial Auto-Encoders(AAEs), and Energy-based Generative Adversarial Network(EBGAN) to practice algorithm design for semi-supervised learning. But this library provides components for designers, not for end-users of state-of-the-art black boxes. Briefly speaking the philosophy of this library, <em>give user hype-driven blackboxes and you feed him for a day; show him how to design algorithms and you feed him for a lifetime.</em> So algorithm is power.</p>\n<p>See also ...</p>\n<ul>\n<li><a href=\"https://github.com/chimera0/accel-brain-code/tree/master/Algorithmic-Composition\" rel=\"nofollow\">Algorithmic Composition or Automatic Composition Library: pycomposer</a>\n<ul>\n<li>If you want to implement the Algorithmic Composer based on Generative Adversarial Networks(GANs) and the <em>Conditional</em> GANs by using <code>pygan</code> as components for Generative models based on the Statistical machine learning problems.</li>\n</ul>\n</li>\n</ul>\n<h2>Installation</h2>\n<p>Install using pip:</p>\n<pre>pip install pygan\n</pre>\n<h3>Source code</h3>\n<p>The source code is currently hosted on GitHub.</p>\n<ul>\n<li><a href=\"https://github.com/chimera0/accel-brain-code/tree/master/Generative-Adversarial-Networks\" rel=\"nofollow\">accel-brain-code/Generative-Adversarial-Networks</a></li>\n</ul>\n<h3>Python package index(PyPI)</h3>\n<p>Installers for the latest released version are available at the Python package index.</p>\n<ul>\n<li><a href=\"https://pypi.python.org/pypi/pygan/\" rel=\"nofollow\">pygan : Python Package Index</a></li>\n</ul>\n<h3>Dependencies</h3>\n<ul>\n<li>numpy: v1.13.3 or higher.</li>\n</ul>\n<h4>Option</h4>\n<ul>\n<li><a href=\"https://github.com/chimera0/accel-brain-code/tree/master/Deep-Learning-by-means-of-Design-Pattern\" rel=\"nofollow\">pydbm</a>: v1.4.9 or higher.\n<ul>\n<li>Only if you want to implement the components based on this library.</li>\n</ul>\n</li>\n</ul>\n<h2>Documentation</h2>\n<p>Full documentation is available on <a href=\"https://code.accel-brain.com/Generative-Adversarial-Networks/\" rel=\"nofollow\">https://code.accel-brain.com/Generative-Adversarial-Networks/</a> . This document contains information on functionally reusability, functional scalability and functional extensibility.</p>\n<h2>Description</h2>\n<p><code>pygan</code> is Python library to implement Generative Adversarial Networks(GANs), <em>Conditional</em> GANs, Adversarial Auto-Encoders(AAEs), and Energy-based Generative Adversarial Network(EBGAN).</p>\n<p>The Generative Adversarial Networks(GANs) (Goodfellow et al., 2014) framework establishes a\nmin-max adversarial game between two neural networks \u2013 a generative model, <code>G</code>, and a discriminative\nmodel, <code>D</code>. The discriminator model, <code>D(x)</code>, is a neural network that computes the probability that\na observed data point <code>x</code> in data space is a sample from the data distribution (positive samples) that we are trying to model, rather than a sample from our generative model (negative samples). Concurrently, the generator uses a function <code>G(z)</code> that maps samples <code>z</code> from the prior <code>p(z)</code> to the data space. <code>G(z)</code> is trained to maximally confuse the discriminator into believing that samples it generates come from the data distribution. The generator is trained by leveraging the gradient of <code>D(x)</code> w.r.t. <code>x</code>, and using that to modify its parameters.</p>\n<h3>Structural extension for <em>Conditional</em> GANs (or cGANs).</h3>\n<p>The <em>Conditional</em> GANs (or cGANs) is a simple extension of the basic GAN model which allows the model to condition on external information. This makes it possible to engage the learned generative model in different \"modes\" by providing it with different contextual information (Gauthier, J. 2014).</p>\n<p>This model can be constructed by simply feeding the data, <code>y</code>, to condition on to both the generator and discriminator. In an unconditioned generative model, because the maps samples <code>z</code> from the prior <code>p(z)</code> are drawn from uniform or normal distribution, there is no control on modes of the data being generated. On the other hand, it is possible to direct the data generation process by conditioning the model on additional information (Mirza, M., &amp; Osindero, S. 2014).</p>\n<h3>Structural extension for Adversarial Auto-Encoders(AAEs).</h3>\n<p>This library also provides the Adversarial Auto-Encoders(AAEs), which is a probabilistic Auto-Encoder that uses GANs to perform variational inference by matching the aggregated posterior of the feature points in hidden layer of the Auto-Encoder with an arbitrary prior distribution(Makhzani, A., et al., 2015). Matching the aggregated posterior to the prior ensures that generating from any part of prior space results in meaningful samples. As a result, the decoder of the Adversarial Auto-Encoder learns a deep generative model that maps the imposed prior to the data distribution.</p>\n<h3>Structural extension for Energy-based Generative Adversarial Network(EBGAN).</h3>\n<p>Reusing the Auto-Encoders, this library introduces the Energy-based Generative Adversarial Network (EBGAN) model(Zhao, J., et al., 2016) which views the discriminator as an energy function that attributes low energies to the regions near the data manifold and higher energies to other regions. THe Auto-Encoders have traditionally been used to represent energy-based models. When trained with some regularization terms, the Auto-Encoders have the ability to learn an energy manifold without supervision or negative examples. This means that even when an energy-based Auto-Encoding model is trained to reconstruct a real sample, the model contributes to discovering the data manifold by itself.</p>\n<h3>The Commonality/Variability Analysis in order to practice object-oriented design.</h3>\n<p>From perspective of <em>commonality/variability</em> analysis in order to practice object-oriented design, the concepts of GANs and AAEs can be organized as follows:</p>\n<div>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1061633e38f4207802c8690bb5acb11ea51b40ba/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f647261772e696f2f707967616e5f636c6173735f6469616772616d5f32303139303630332e706e67\">\n</div>\n<p>The configuration is based on the <code>Strategy Pattern</code>, which provides a way to define a family of algorithms implemented by inheriting the interface or abstract class such as <code>TrueSampler</code>, <code>NoiseSampler</code>, <code>GenerativeModel</code>, and <code>DiscriminativeModel</code>, where ...\n- <code>TrueSampler</code> is the interface to provide <code>x</code> by drawing from the <code>true</code> distributions.\n- <code>GenerativeModel</code> is the abstract class to generate <code>G(z)</code> by drawing from the <code>fake</code> distributions with <code>NoiseSampler</code> which provides <code>z</code>.\n- <code>DiscriminativeModel</code> is the interface to inference that observed data points are <code>true</code> or <code>fake</code> as a <code>D(x)</code>.</p>\n<p>This pattern is encapsulate each one as an object, and make them interchangeable from the point of view of functionally equivalent. This library provides sub classes such as Neural Networks, Convolutional Neural Networks, and LSTM networks. Althogh those models are variable from the view points of learning algorithms, but as a <code>GenerativeModel</code> or a <code>DiscriminativeModel</code> those models have common function.</p>\n<p><code>GenerativeAdversarialNetworks</code> is a <em>Context</em> in the <code>Strategy Pattern</code>, controlling the objects of <code>TrueSampler</code>, <code>GenerativeModel</code>, and <code>DiscriminativeModel</code> in order to train <code>G(z)</code> and <code>D(x)</code>. This <em>context</em> class also calls the object of <code>GANsValueFunction</code>, whose function is computing the rewards or gradients in GANs framework.</p>\n<p>The structural extension from GANs to AAEs is achieved by the inheritance of two classes: <code>GenerativeModel</code> and <code>GenerativeAdversarialNetworks</code>. One of the main concepts of AAEs, which is worthy of special mention, can be considered that <em>the Auto-Encoders can be transformed into the generative Models</em>. Therefore this library firstly implements a <code>AutoEncoderModel</code> by inheriting <code>GenerativeModel</code>. Next, this library watches closely that the difference between GANs and AAEs brings us different <em>context</em> in the <code>Strategy Pattern</code> in relation to the learning algorithm of Auto-Encoders. By the addition of the <code>AutoEncoderModel</code>'s learning method, this library provieds <code>AdversarialAutoEncoders</code> which is-a <code>GenerativeAdversarialNetworks</code> and makes it possible to train not only <code>GenerativeModel</code> and <code>DiscriminativeModel</code> but also <code>AutoEncoderModel</code>.</p>\n<p>Furthermore, <code>FeatureMatching</code> is a value function with so-called Feature matching technic, which addresses the instability of GANs by specifying a new objective for the generator that prevents it from overtraining on the current discriminator(Salimans, T., et al., 2016).</p>\n<div>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/abaedd2db89b8da016000cd39221fe9771c956b4/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f647261772e696f2f707967616e5f636c6173735f6469616772616d2d2d436f6e646974696f6e616c47414e732e706e67\">\n</div>\n<p>Like Yang, L. C., et al. (2017), this library implements the <code>Conditioner</code> to conditon on external information. As class configuration in this library, the <code>Conditioner</code> is divided into two, <code>ConditionalGenerativeModel</code> and <code>ConditionalTrueSampler</code>. This library consider that the <code>ConditionalGenerativeModel</code> and <code>ConditionalTrueSampler</code> contain <code>Conditioner</code> of the <em>Conditional</em> GANs to reduce the burden of architectural design. The controller <code>GenerativeAdversarialNetworks</code> functionally uses the conditions in a black boxed state.</p>\n<h2>Usecase: Generating Sine Waves by GANs.</h2>\n<p>Set hyperparameters.</p>\n<pre><span class=\"c1\"># Batch size</span>\n<span class=\"n\">batch_size</span> <span class=\"o\">=</span> <span class=\"mi\">20</span>\n<span class=\"c1\"># The length of sequences.</span>\n<span class=\"n\">seq_len</span> <span class=\"o\">=</span> <span class=\"mi\">30</span>\n<span class=\"c1\"># The dimension of observed or feature points.</span>\n<span class=\"n\">dim</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>\n</pre>\n<p>Import Python modules.</p>\n<pre><span class=\"c1\"># is-a `TrueSampler`.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pygan.truesampler.sine_wave_true_sampler</span> <span class=\"kn\">import</span> <span class=\"n\">SineWaveTrueSampler</span>\n<span class=\"c1\"># is-a `NoiseSampler`.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pygan.noisesampler.uniform_noise_sampler</span> <span class=\"kn\">import</span> <span class=\"n\">UniformNoiseSampler</span>\n<span class=\"c1\"># is-a `GenerativeModel`.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pygan.generativemodel.lstm_model</span> <span class=\"kn\">import</span> <span class=\"n\">LSTMModel</span>\n<span class=\"c1\"># is-a `DiscriminativeModel`.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pygan.discriminativemodel.nn_model</span> <span class=\"kn\">import</span> <span class=\"n\">NNModel</span>\n<span class=\"c1\"># is-a `GANsValueFunction`.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pygan.gansvaluefunction.mini_max</span> <span class=\"kn\">import</span> <span class=\"n\">MiniMax</span>\n<span class=\"c1\"># GANs framework.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pygan.generative_adversarial_networks</span> <span class=\"kn\">import</span> <span class=\"n\">GenerativeAdversarialNetworks</span>\n</pre>\n<p>Setup <code>TrueSampler</code>.</p>\n<pre><span class=\"n\">true_sampler</span> <span class=\"o\">=</span> <span class=\"n\">SineWaveTrueSampler</span><span class=\"p\">(</span>\n    <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"n\">batch_size</span><span class=\"p\">,</span>\n    <span class=\"n\">seq_len</span><span class=\"o\">=</span><span class=\"n\">seq_len</span><span class=\"p\">,</span>\n    <span class=\"n\">dim</span><span class=\"o\">=</span><span class=\"n\">dim</span>\n<span class=\"p\">)</span>\n</pre>\n<p>Setup <code>NoiseSampler</code> and <code>GenerativeModel</code>.</p>\n<pre><span class=\"n\">noise_sampler</span> <span class=\"o\">=</span> <span class=\"n\">UniformNoiseSampler</span><span class=\"p\">(</span>\n    <span class=\"c1\"># Lower boundary of the output interval.</span>\n    <span class=\"n\">low</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">,</span> \n    <span class=\"c1\"># Upper boundary of the output interval.</span>\n    <span class=\"n\">high</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> \n    <span class=\"c1\"># Output shape.</span>\n    <span class=\"n\">output_shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">batch_size</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"p\">)</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">generative_model</span> <span class=\"o\">=</span> <span class=\"n\">LSTMModel</span><span class=\"p\">(</span>\n    <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"n\">batch_size</span><span class=\"p\">,</span>\n    <span class=\"n\">seq_len</span><span class=\"o\">=</span><span class=\"n\">seq_len</span><span class=\"p\">,</span>\n    <span class=\"n\">input_neuron_count</span><span class=\"o\">=</span><span class=\"n\">dim</span><span class=\"p\">,</span>\n    <span class=\"n\">hidden_neuron_count</span><span class=\"o\">=</span><span class=\"n\">dim</span>\n<span class=\"p\">)</span>\n<span class=\"n\">generative_model</span><span class=\"o\">.</span><span class=\"n\">noise_sampler</span> <span class=\"o\">=</span> <span class=\"n\">noise_sampler</span>\n</pre>\n<p>Setup <code>DiscriminativeModel</code> with <a href=\"https://github.com/chimera0/accel-brain-code/tree/master/Deep-Learning-by-means-of-Design-Pattern\" rel=\"nofollow\">pydbm</a> library.</p>\n<pre><span class=\"c1\"># Computation graph for Neural network.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pydbm.synapse.nn_graph</span> <span class=\"kn\">import</span> <span class=\"n\">NNGraph</span>\n<span class=\"c1\"># Layer object of Neural network.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pydbm.nn.nn_layer</span> <span class=\"kn\">import</span> <span class=\"n\">NNLayer</span>\n<span class=\"c1\">#$ Logistic function or Sigmoid function which is-a `ActivatingFunctionInterface`.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pydbm.activation.logistic_function</span> <span class=\"kn\">import</span> <span class=\"n\">LogisticFunction</span>\n\n<span class=\"n\">nn_layer</span> <span class=\"o\">=</span> <span class=\"n\">NNLayer</span><span class=\"p\">(</span>\n    <span class=\"n\">graph</span><span class=\"o\">=</span><span class=\"n\">NNGraph</span><span class=\"p\">(</span>\n        <span class=\"n\">activation_function</span><span class=\"o\">=</span><span class=\"n\">LogisticFunction</span><span class=\"p\">(),</span>\n        <span class=\"c1\"># The number of units in hidden layer.</span>\n        <span class=\"n\">hidden_neuron_count</span><span class=\"o\">=</span><span class=\"n\">seq_len</span> <span class=\"o\">*</span> <span class=\"n\">dim</span><span class=\"p\">,</span>\n        <span class=\"c1\"># The number of units in output layer.</span>\n        <span class=\"n\">output_neuron_count</span><span class=\"o\">=</span><span class=\"mi\">1</span>\n    <span class=\"p\">)</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">discriminative_model</span> <span class=\"o\">=</span> <span class=\"n\">NNModel</span><span class=\"p\">(</span>\n    <span class=\"c1\"># `list` of `NNLayer`.</span>\n    <span class=\"n\">nn_layer_list</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">nn_layer</span><span class=\"p\">],</span>\n    <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"n\">batch_size</span>\n<span class=\"p\">)</span>\n</pre>\n<p>Setup the value function.</p>\n<pre><span class=\"n\">gans_value_function</span> <span class=\"o\">=</span> <span class=\"n\">MiniMax</span><span class=\"p\">()</span>\n</pre>\n<p>Setup GANs framework.</p>\n<pre><span class=\"n\">GAN</span> <span class=\"o\">=</span> <span class=\"n\">GenerativeAdversarialNetworks</span><span class=\"p\">(</span>\n    <span class=\"n\">gans_value_function</span><span class=\"o\">=</span><span class=\"n\">gans_value_function</span>\n<span class=\"p\">)</span>\n</pre>\n<p>If you want to setup GNAs framework with so-called feature matching technic, which is effective in situations where regular GAN becomes unstable(Salimans, T., et al., 2016), setup GANs framework as follows:</p>\n<pre><span class=\"n\">GAN</span> <span class=\"o\">=</span> <span class=\"n\">GenerativeAdversarialNetworks</span><span class=\"p\">(</span>\n    <span class=\"n\">gans_value_function</span><span class=\"o\">=</span><span class=\"n\">gans_value_function</span><span class=\"p\">,</span>\n    <span class=\"n\">feature_matching</span><span class=\"o\">=</span><span class=\"n\">FeatureMatching</span><span class=\"p\">(</span>\n        <span class=\"c1\"># Weight for results of standard feature matching.</span>\n        <span class=\"n\">lambda1</span><span class=\"o\">=</span><span class=\"mf\">0.01</span><span class=\"p\">,</span> \n        <span class=\"c1\"># Weight for results of difference between generated data points and true samples.</span>\n        <span class=\"n\">lambda2</span><span class=\"o\">=</span><span class=\"mf\">0.99</span>\n    <span class=\"p\">)</span>\n<span class=\"p\">)</span>\n</pre>\n<p>where <code>lambda1</code> and <code>lambda2</code> are trade-off parameters. <code>lambda1</code> means a weight for results of standard feature matching and <code>lambda2</code> means a weight for results of difference between generated data points and true samples(Yang, L. C., et al., 2017).</p>\n<p>Start training.</p>\n<pre><span class=\"n\">generative_model</span><span class=\"p\">,</span> <span class=\"n\">discriminative_model</span> <span class=\"o\">=</span> <span class=\"n\">GAN</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span>\n    <span class=\"n\">true_sampler</span><span class=\"p\">,</span>\n    <span class=\"n\">generative_model</span><span class=\"p\">,</span>\n    <span class=\"n\">discriminative_model</span><span class=\"p\">,</span>\n    <span class=\"c1\"># The number of training iterations.</span>\n    <span class=\"n\">iter_n</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span>\n    <span class=\"c1\"># The number of learning of the discriminative_model.</span>\n    <span class=\"n\">k_step</span><span class=\"o\">=</span><span class=\"mi\">10</span>\n<span class=\"p\">)</span>\n</pre>\n<h4>Visualization.</h4>\n<p>Check the rewards or losses.</p>\n<pre><span class=\"n\">d_logs_list</span><span class=\"p\">,</span> <span class=\"n\">g_logs_list</span> <span class=\"o\">=</span> <span class=\"n\">GAN</span><span class=\"o\">.</span><span class=\"n\">extract_logs_tuple</span><span class=\"p\">()</span>\n</pre>\n<p><code>d_logs_list</code> is a <code>list</code> of probabilities inferenced by the <code>discriminator</code> (mean) in the <code>discriminator</code>'s update turn and <code>g_logs_list</code> is a <code>list</code> of probabilities inferenced by the <code>discriminator</code> (mean) in the <code>generator</code>'s update turn.</p>\n<p>Visualize the values of <code>d_logs_list</code>.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"k\">as</span> <span class=\"nn\">plt</span>\n<span class=\"kn\">import</span> <span class=\"nn\">seaborn</span> <span class=\"k\">as</span> <span class=\"nn\">sns</span>\n<span class=\"o\">%</span><span class=\"n\">config</span> <span class=\"n\">InlineBackend</span><span class=\"o\">.</span><span class=\"n\">figure_format</span> <span class=\"o\">=</span> <span class=\"s2\">\"retina\"</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">style</span><span class=\"o\">.</span><span class=\"n\">use</span><span class=\"p\">(</span><span class=\"s2\">\"fivethirtyeight\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">figure</span><span class=\"p\">(</span><span class=\"n\">figsize</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">))</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">d_logs_list</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">xlabel</span><span class=\"p\">(</span><span class=\"s2\">\"Epochs\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">ylabel</span><span class=\"p\">(</span><span class=\"s2\">\"Loss\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n</pre>\n<div>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ec97c16b289d6692822bb3901392562fc01ba493/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6c6f67732f70726f626162696c6974795f696e5f445f4c53544d2e706e67\">\n</div>\n<p>Similarly, visualize the values of <code>g_logs_list</code>.</p>\n<pre><span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">figure</span><span class=\"p\">(</span><span class=\"n\">figsize</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">))</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">g_logs_list</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">xlabel</span><span class=\"p\">(</span><span class=\"s2\">\"Epochs\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">ylabel</span><span class=\"p\">(</span><span class=\"s2\">\"Loss\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n</pre>\n<div>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5fb8011e3f05eb478f40db26e9f0d62aa9f78507/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6c6f67732f70726f626162696c6974795f696e5f475f4c53544d2e706e67\">\n</div>\n<p>As the training progresses, the values are close to <code>0.5</code>.</p>\n<h4>Generation.</h4>\n<p>Plot a true distribution and generated data points to check how the <code>discriminator</code> was <em>confused</em> by the <code>generator</code>.</p>\n<pre><span class=\"n\">true_arr</span> <span class=\"o\">=</span> <span class=\"n\">true_sampler</span><span class=\"o\">.</span><span class=\"n\">draw</span><span class=\"p\">()</span>\n\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">style</span><span class=\"o\">.</span><span class=\"n\">use</span><span class=\"p\">(</span><span class=\"s2\">\"fivethirtyeight\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">figure</span><span class=\"p\">(</span><span class=\"n\">figsize</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">))</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">true_arr</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n</pre>\n<div>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/036c15696a9a535f2c7fcc860929d9d50368d93b/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f73696e65776176652f73696e655f776176655f747275652e706e67\">\n</div>\n<pre><span class=\"n\">generated_arr</span> <span class=\"o\">=</span> <span class=\"n\">generative_model</span><span class=\"o\">.</span><span class=\"n\">draw</span><span class=\"p\">()</span>\n\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">style</span><span class=\"o\">.</span><span class=\"n\">use</span><span class=\"p\">(</span><span class=\"s2\">\"fivethirtyeight\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">figure</span><span class=\"p\">(</span><span class=\"n\">figsize</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">))</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">generated_arr</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n</pre>\n<div>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3baed47d0fa63a00a63acaec3f9e434f4698b0db/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f73696e65776176652f73696e655f776176655f66616b652e706e67\">\n</div>\n<h3>Usecase: Generating images by AAEs.</h3>\n<p>In this demonstration, we use image dataset in <a href=\"https://avaminzhang.wordpress.com/2012/12/07/%E3%80%90dataset%E3%80%91weizmann-horses/\" rel=\"nofollow\">the Weizmann horse dataset</a>. <a href=\"https://github.com/chimera0/accel-brain-code/tree/master/Deep-Learning-by-means-of-Design-Pattern\" rel=\"nofollow\">pydbm</a> library used this dataset to demonstrate for <a href=\"https://github.com/chimera0/accel-brain-code/blob/master/Deep-Learning-by-means-of-Design-Pattern/demo/demo_convolutional_auto_encoder.ipynb\" rel=\"nofollow\">observing reconstruction images by Convolutional Auto-Encoder.</a> and Shape boltzmann machines as follows.</p>\n<table>\n    <tr>\n        <td>\n            <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b37a308d7d4b3908e31f5a99a4d863f6b324d68a/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f446565702d4c6561726e696e672d62792d6d65616e732d6f662d44657369676e2d5061747465726e2f696d672f686f7273653039392e6a7067\">\n        <p>Image in <a href=\"https://avaminzhang.wordpress.com/2012/12/07/%E3%80%90dataset%E3%80%91weizmann-horses/\" rel=\"nofollow\">the Weizmann horse dataset</a>.</p>\n        </td>\n        <td>\n            <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/df01ef314a15955900c8887f4e4f81e9f9512169/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f446565702d4c6561726e696e672d62792d6d65616e732d6f662d44657369676e2d5061747465726e2f696d672f7265636f6e73747275637465645f686f7273653039392e676966\">\n            <p>Reconstructed image by <strong>Shape-BM</strong>.</p>\n        </td>\n        <td>\n            <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/90be2bd8e01cd62609ad78f0c60090c4f5054a76/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f446565702d4c6561726e696e672d62792d6d65616e732d6f662d44657369676e2d5061747465726e2f696d672f7265636f6e73747275637465645f62795f4341452e676966\">\n            <p>Reconstructed image by <strong>Convolutional Auto-Encoder</strong>.</p>\n        </td>\n    </tr>\n</table>\n<p>This library also provides the Convolutional Auto-Encoder, which can be functionally re-used as <code>AutoEncoderModel</code>, loosely coupling with <code>AdversarialAutoEncoders</code>.</p>\n<p>Set hyperparameters and directory path that stores your image files.</p>\n<pre><span class=\"n\">batch_size</span> <span class=\"o\">=</span> <span class=\"mi\">20</span>\n<span class=\"c1\"># Width of images.</span>\n<span class=\"n\">width</span> <span class=\"o\">=</span> <span class=\"mi\">100</span>\n<span class=\"c1\"># height of images.</span>\n<span class=\"n\">height</span> <span class=\"o\">=</span> <span class=\"mi\">100</span>\n<span class=\"c1\"># Channel of images.</span>\n<span class=\"n\">channel</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>\n<span class=\"c1\"># Path to your image files.</span>\n<span class=\"n\">image_dir</span> <span class=\"o\">=</span> <span class=\"s2\">\"your/path/to/images/\"</span>\n<span class=\"c1\"># The length of sequneces. If `None`, the objects will ignore sequneces.</span>\n<span class=\"n\">seq_len</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>\n<span class=\"c1\"># Gray scale or not.</span>\n<span class=\"n\">gray_scale_flag</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n<span class=\"c1\"># The tuple of width and height.</span>\n<span class=\"n\">wh_size_tuple</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">width</span><span class=\"p\">,</span> <span class=\"n\">height</span><span class=\"p\">)</span>\n<span class=\"c1\"># How to normalize pixel values of images.</span>\n<span class=\"c1\">#   - `z_score`: Z-Score normalization.</span>\n<span class=\"c1\">#   - `min_max`: Min-max normalization.</span>\n<span class=\"c1\">#   - `tanh`: Normalization by tanh function.</span>\n<span class=\"n\">norm_mode</span> <span class=\"o\">=</span> <span class=\"s2\">\"z_score\"</span>\n</pre>\n<p>Import Python modules.</p>\n<pre><span class=\"c1\"># is-a `TrueSampler`.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pygan.truesampler.image_true_sampler</span> <span class=\"kn\">import</span> <span class=\"n\">ImageTrueSampler</span>\n<span class=\"c1\"># is-a `NoiseSampler`.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pygan.noisesampler.image_noise_sampler</span> <span class=\"kn\">import</span> <span class=\"n\">ImageNoiseSampler</span>\n<span class=\"c1\"># is-a `AutoencoderModel`.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pygan.generativemodel.autoencodermodel.convolutional_auto_encoder</span> <span class=\"kn\">import</span> <span class=\"n\">ConvolutionalAutoEncoder</span> <span class=\"k\">as</span> <span class=\"n\">Generator</span>\n<span class=\"c1\"># is-a `DiscriminativeModel`.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pygan.discriminativemodel.cnn_model</span> <span class=\"kn\">import</span> <span class=\"n\">CNNModel</span> <span class=\"k\">as</span> <span class=\"n\">Discriminator</span>\n<span class=\"c1\"># `AdversarialAutoEncoders` which is-a `GenerativeAdversarialNetworks`.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pygan.generativeadversarialnetworks.adversarial_auto_encoders</span> <span class=\"kn\">import</span> <span class=\"n\">AdversarialAutoEncoders</span>\n<span class=\"c1\"># Value function.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pygan.gansvaluefunction.mini_max</span> <span class=\"kn\">import</span> <span class=\"n\">MiniMax</span>\n<span class=\"c1\"># Feature Matching.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pygan.feature_matching</span> <span class=\"kn\">import</span> <span class=\"n\">FeatureMatching</span>\n</pre>\n<p>Import <a href=\"https://github.com/chimera0/accel-brain-code/tree/master/Deep-Learning-by-means-of-Design-Pattern\" rel=\"nofollow\">pydbm</a> modules.</p>\n<pre><span class=\"c1\"># Convolution layer.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pydbm.cnn.layerablecnn.convolution_layer</span> <span class=\"kn\">import</span> <span class=\"n\">ConvolutionLayer</span>\n<span class=\"c1\"># Computation graph in output layer.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pydbm.synapse.cnn_output_graph</span> <span class=\"kn\">import</span> <span class=\"n\">CNNOutputGraph</span>\n<span class=\"c1\"># Computation graph for convolution layer.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pydbm.synapse.cnn_graph</span> <span class=\"kn\">import</span> <span class=\"n\">CNNGraph</span>\n<span class=\"c1\"># Logistic Function as activation function.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pydbm.activation.logistic_function</span> <span class=\"kn\">import</span> <span class=\"n\">LogisticFunction</span>\n<span class=\"c1\"># Tanh Function as activation function.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pydbm.activation.tanh_function</span> <span class=\"kn\">import</span> <span class=\"n\">TanhFunction</span>\n<span class=\"c1\"># ReLu Function as activation function.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pydbm.activation.relu_function</span> <span class=\"kn\">import</span> <span class=\"n\">ReLuFunction</span>\n<span class=\"c1\"># SGD optimizer.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pydbm.optimization.optparams.sgd</span> <span class=\"kn\">import</span> <span class=\"n\">SGD</span>\n<span class=\"c1\"># Adam optimizer.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pydbm.optimization.optparams.adam</span> <span class=\"kn\">import</span> <span class=\"n\">Adam</span>\n<span class=\"c1\"># MSE.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pydbm.loss.mean_squared_error</span> <span class=\"kn\">import</span> <span class=\"n\">MeanSquaredError</span>\n<span class=\"c1\"># Convolutional Auto-Encoder.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pydbm.cnn.convolutionalneuralnetwork.convolutional_auto_encoder</span> <span class=\"kn\">import</span> <span class=\"n\">ConvolutionalAutoEncoder</span> <span class=\"k\">as</span> <span class=\"n\">CAE</span>\n<span class=\"c1\"># Deconvolution layer.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pydbm.cnn.layerablecnn.convolutionlayer.deconvolution_layer</span> <span class=\"kn\">import</span> <span class=\"n\">DeconvolutionLayer</span>\n<span class=\"c1\"># Verification object.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pydbm.verification.verificate_function_approximation</span> <span class=\"kn\">import</span> <span class=\"n\">VerificateFunctionApproximation</span>\n</pre>\n<p>Setup <code>TrueSampler</code>.</p>\n<pre><span class=\"n\">true_sampler</span> <span class=\"o\">=</span> <span class=\"n\">ImageTrueSampler</span><span class=\"p\">(</span>\n    <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"n\">batch_size</span><span class=\"p\">,</span>\n    <span class=\"n\">image_dir</span><span class=\"o\">=</span><span class=\"n\">image_dir</span><span class=\"p\">,</span>\n    <span class=\"n\">seq_len</span><span class=\"o\">=</span><span class=\"n\">seq_len</span><span class=\"p\">,</span>\n    <span class=\"n\">gray_scale_flag</span><span class=\"o\">=</span><span class=\"n\">gray_scale_flag</span><span class=\"p\">,</span>\n    <span class=\"n\">wh_size_tuple</span><span class=\"o\">=</span><span class=\"n\">wh_size_tuple</span><span class=\"p\">,</span>\n    <span class=\"n\">norm_mode</span><span class=\"o\">=</span><span class=\"n\">norm_mode</span>\n<span class=\"p\">)</span>\n</pre>\n<p>Setup <code>NoiseSampler</code> and <code>AutoEncoderModel</code>.</p>\n<pre><span class=\"n\">noise_sampler</span> <span class=\"o\">=</span> <span class=\"n\">ImageNoiseSampler</span><span class=\"p\">(</span>\n    <span class=\"n\">batch_size</span><span class=\"p\">,</span>\n    <span class=\"n\">image_dir</span><span class=\"p\">,</span>\n    <span class=\"n\">seq_len</span><span class=\"o\">=</span><span class=\"n\">seq_len</span><span class=\"p\">,</span>\n    <span class=\"n\">gray_scale_flag</span><span class=\"o\">=</span><span class=\"n\">gray_scale_flag</span><span class=\"p\">,</span>\n    <span class=\"n\">wh_size_tuple</span><span class=\"o\">=</span><span class=\"n\">wh_size_tuple</span><span class=\"p\">,</span>\n    <span class=\"n\">norm_mode</span><span class=\"o\">=</span><span class=\"n\">norm_mode</span>\n<span class=\"p\">)</span>\n\n<span class=\"k\">if</span> <span class=\"n\">gray_scale_flag</span> <span class=\"ow\">is</span> <span class=\"kc\">True</span><span class=\"p\">:</span>\n    <span class=\"n\">channel</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>\n<span class=\"k\">else</span><span class=\"p\">:</span>\n    <span class=\"n\">channel</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>\n<span class=\"n\">scale</span> <span class=\"o\">=</span> <span class=\"mf\">0.1</span>\n\n<span class=\"n\">conv1</span> <span class=\"o\">=</span> <span class=\"n\">ConvolutionLayer</span><span class=\"p\">(</span>\n    <span class=\"n\">CNNGraph</span><span class=\"p\">(</span>\n        <span class=\"n\">activation_function</span><span class=\"o\">=</span><span class=\"n\">TanhFunction</span><span class=\"p\">(),</span>\n        <span class=\"c1\"># The number of filters.</span>\n        <span class=\"n\">filter_num</span><span class=\"o\">=</span><span class=\"n\">batch_size</span><span class=\"p\">,</span>\n        <span class=\"n\">channel</span><span class=\"o\">=</span><span class=\"n\">channel</span><span class=\"p\">,</span>\n        <span class=\"c1\"># Kernel size.</span>\n        <span class=\"n\">kernel_size</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span>\n        <span class=\"n\">scale</span><span class=\"o\">=</span><span class=\"n\">scale</span><span class=\"p\">,</span>\n        <span class=\"c1\"># The number of strides.</span>\n        <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span>\n        <span class=\"c1\"># The number of zero-padding.</span>\n        <span class=\"n\">pad</span><span class=\"o\">=</span><span class=\"mi\">1</span>\n    <span class=\"p\">)</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">conv2</span> <span class=\"o\">=</span> <span class=\"n\">ConvolutionLayer</span><span class=\"p\">(</span>\n    <span class=\"n\">CNNGraph</span><span class=\"p\">(</span>\n        <span class=\"n\">activation_function</span><span class=\"o\">=</span><span class=\"n\">TanhFunction</span><span class=\"p\">(),</span>\n        <span class=\"n\">filter_num</span><span class=\"o\">=</span><span class=\"n\">batch_size</span><span class=\"p\">,</span>\n        <span class=\"n\">channel</span><span class=\"o\">=</span><span class=\"n\">batch_size</span><span class=\"p\">,</span>\n        <span class=\"n\">kernel_size</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span>\n        <span class=\"n\">scale</span><span class=\"o\">=</span><span class=\"n\">scale</span><span class=\"p\">,</span>\n        <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span>\n        <span class=\"n\">pad</span><span class=\"o\">=</span><span class=\"mi\">1</span>\n    <span class=\"p\">)</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">deconvolution_layer_list</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n    <span class=\"n\">DeconvolutionLayer</span><span class=\"p\">(</span>\n        <span class=\"n\">CNNGraph</span><span class=\"p\">(</span>\n            <span class=\"n\">activation_function</span><span class=\"o\">=</span><span class=\"n\">TanhFunction</span><span class=\"p\">(),</span>\n            <span class=\"n\">filter_num</span><span class=\"o\">=</span><span class=\"n\">batch_size</span><span class=\"p\">,</span>\n            <span class=\"n\">channel</span><span class=\"o\">=</span><span class=\"n\">channel</span><span class=\"p\">,</span>\n            <span class=\"n\">kernel_size</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span>\n            <span class=\"n\">scale</span><span class=\"o\">=</span><span class=\"n\">scale</span><span class=\"p\">,</span>\n            <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span>\n            <span class=\"n\">pad</span><span class=\"o\">=</span><span class=\"mi\">1</span>\n        <span class=\"p\">)</span>\n    <span class=\"p\">)</span>\n<span class=\"p\">]</span>\n\n<span class=\"n\">opt_params</span> <span class=\"o\">=</span> <span class=\"n\">Adam</span><span class=\"p\">()</span>\n<span class=\"c1\"># The probability of dropout.</span>\n<span class=\"n\">opt_params</span><span class=\"o\">.</span><span class=\"n\">dropout_rate</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>\n\n<span class=\"n\">convolutional_auto_encoder</span> <span class=\"o\">=</span> <span class=\"n\">CAE</span><span class=\"p\">(</span>\n    <span class=\"n\">layerable_cnn_list</span><span class=\"o\">=</span><span class=\"p\">[</span>\n        <span class=\"n\">conv1</span><span class=\"p\">,</span> \n        <span class=\"n\">conv2</span>\n    <span class=\"p\">],</span>\n    <span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span>\n    <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"n\">batch_size</span><span class=\"p\">,</span>\n    <span class=\"n\">learning_rate</span><span class=\"o\">=</span><span class=\"mf\">1e-05</span><span class=\"p\">,</span>\n    <span class=\"c1\"># # Attenuate the `learning_rate` by a factor of this value every `attenuate_epoch`.</span>\n    <span class=\"n\">learning_attenuate_rate</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">,</span>\n    <span class=\"c1\"># # Attenuate the `learning_rate` by a factor of `learning_attenuate_rate` every `attenuate_epoch`.</span>\n    <span class=\"n\">attenuate_epoch</span><span class=\"o\">=</span><span class=\"mi\">25</span><span class=\"p\">,</span>\n    <span class=\"n\">computable_loss</span><span class=\"o\">=</span><span class=\"n\">MeanSquaredError</span><span class=\"p\">(),</span>\n    <span class=\"n\">opt_params</span><span class=\"o\">=</span><span class=\"n\">opt_params</span><span class=\"p\">,</span>\n    <span class=\"n\">verificatable_result</span><span class=\"o\">=</span><span class=\"n\">VerificateFunctionApproximation</span><span class=\"p\">(),</span>\n    <span class=\"c1\"># # Size of Test data set. If this value is `0`, the validation will not be executed.</span>\n    <span class=\"n\">test_size_rate</span><span class=\"o\">=</span><span class=\"mf\">0.3</span><span class=\"p\">,</span>\n    <span class=\"c1\"># Tolerance for the optimization.</span>\n    <span class=\"c1\"># When the loss or score is not improving by at least tol </span>\n    <span class=\"c1\"># for two consecutive iterations, convergence is considered </span>\n    <span class=\"c1\"># to be reached and training stops.</span>\n    <span class=\"n\">tol</span><span class=\"o\">=</span><span class=\"mf\">1e-15</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">generator</span> <span class=\"o\">=</span> <span class=\"n\">Generator</span><span class=\"p\">(</span>\n    <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"n\">batch_size</span><span class=\"p\">,</span>\n    <span class=\"n\">learning_rate</span><span class=\"o\">=</span><span class=\"mf\">1e-05</span><span class=\"p\">,</span>\n    <span class=\"n\">convolutional_auto_encoder</span><span class=\"o\">=</span><span class=\"n\">convolutional_auto_encoder</span><span class=\"p\">,</span>\n    <span class=\"n\">deconvolution_layer_list</span><span class=\"o\">=</span><span class=\"n\">deconvolution_layer_list</span><span class=\"p\">,</span>\n    <span class=\"n\">gray_scale_flag</span><span class=\"o\">=</span><span class=\"n\">gray_scale_flag</span>\n<span class=\"p\">)</span>\n<span class=\"n\">generator</span><span class=\"o\">.</span><span class=\"n\">noise_sampler</span> <span class=\"o\">=</span> <span class=\"n\">noise_sampler</span>\n</pre>\n<p>Setup <code>DiscriminativeModel</code>.</p>\n<pre><span class=\"n\">convD</span> <span class=\"o\">=</span> <span class=\"n\">ConvolutionLayer</span><span class=\"p\">(</span>\n    <span class=\"n\">CNNGraph</span><span class=\"p\">(</span>\n        <span class=\"n\">activation_function</span><span class=\"o\">=</span><span class=\"n\">TanhFunction</span><span class=\"p\">(),</span>\n        <span class=\"n\">filter_num</span><span class=\"o\">=</span><span class=\"n\">batch_size</span><span class=\"p\">,</span>\n        <span class=\"n\">channel</span><span class=\"o\">=</span><span class=\"n\">channel</span><span class=\"p\">,</span>\n        <span class=\"n\">kernel_size</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span>\n        <span class=\"n\">scale</span><span class=\"o\">=</span><span class=\"mf\">0.001</span><span class=\"p\">,</span>\n        <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span>\n        <span class=\"n\">pad</span><span class=\"o\">=</span><span class=\"mi\">1</span>\n    <span class=\"p\">)</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">layerable_cnn_list</span><span class=\"o\">=</span><span class=\"p\">[</span>\n    <span class=\"n\">convD</span>\n<span class=\"p\">]</span>\n\n<span class=\"n\">opt_params</span> <span class=\"o\">=</span> <span class=\"n\">Adam</span><span class=\"p\">()</span>\n<span class=\"n\">opt_params</span><span class=\"o\">.</span><span class=\"n\">dropout_rate</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>\n\n<span class=\"n\">cnn_output_graph</span> <span class=\"o\">=</span> <span class=\"n\">CNNOutputGraph</span><span class=\"p\">(</span>\n    <span class=\"c1\"># The number of units in hidden layer.</span>\n    <span class=\"n\">hidden_dim</span><span class=\"o\">=</span><span class=\"mi\">23120</span><span class=\"p\">,</span> \n    <span class=\"c1\"># The number of units in output layer.</span>\n    <span class=\"n\">output_dim</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> \n    <span class=\"n\">activating_function</span><span class=\"o\">=</span><span class=\"n\">LogisticFunction</span><span class=\"p\">(),</span> \n    <span class=\"n\">scale</span><span class=\"o\">=</span><span class=\"mf\">0.01</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">discriminator</span> <span class=\"o\">=</span> <span class=\"n\">Discriminator</span><span class=\"p\">(</span>\n    <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"n\">batch_size</span><span class=\"p\">,</span>\n    <span class=\"n\">layerable_cnn_list</span><span class=\"o\">=</span><span class=\"n\">layerable_cnn_list</span><span class=\"p\">,</span>\n    <span class=\"n\">cnn_output_graph</span><span class=\"o\">=</span><span class=\"n\">cnn_output_graph</span><span class=\"p\">,</span>\n    <span class=\"n\">learning_rate</span><span class=\"o\">=</span><span class=\"mf\">1e-05</span><span class=\"p\">,</span>\n    <span class=\"n\">opt_params</span><span class=\"o\">=</span><span class=\"n\">opt_params</span>\n<span class=\"p\">)</span>\n</pre>\n<p>Setup AAEs framework.</p>\n<pre><span class=\"n\">AAE</span> <span class=\"o\">=</span> <span class=\"n\">AdversarialAutoEncoders</span><span class=\"p\">(</span>\n    <span class=\"n\">gans_value_function</span><span class=\"o\">=</span><span class=\"n\">MiniMax</span><span class=\"p\">(),</span>\n    <span class=\"n\">feature_matching</span><span class=\"o\">=</span><span class=\"n\">FeatureMatching</span><span class=\"p\">(</span>\n        <span class=\"c1\"># Weight for results of standard feature matching.</span>\n        <span class=\"n\">lambda1</span><span class=\"o\">=</span><span class=\"mf\">0.01</span><span class=\"p\">,</span> \n        <span class=\"c1\"># Weight for results of difference between generated data points and true samples.</span>\n        <span class=\"n\">lambda2</span><span class=\"o\">=</span><span class=\"mf\">0.99</span>\n    <span class=\"p\">)</span>\n<span class=\"p\">)</span>\n</pre>\n<p>Start pre-training.</p>\n<pre><span class=\"n\">generator</span><span class=\"o\">.</span><span class=\"n\">pre_learn</span><span class=\"p\">(</span><span class=\"n\">true_sampler</span><span class=\"o\">=</span><span class=\"n\">true_sampler</span><span class=\"p\">,</span> <span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">1000</span><span class=\"p\">)</span>\n</pre>\n<p>Start training.</p>\n<pre><span class=\"n\">generator</span><span class=\"p\">,</span> <span class=\"n\">discriminator</span> <span class=\"o\">=</span> <span class=\"n\">AAE</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span>\n    <span class=\"n\">true_sampler</span><span class=\"o\">=</span><span class=\"n\">true_sampler</span><span class=\"p\">,</span>\n    <span class=\"n\">generative_model</span><span class=\"o\">=</span><span class=\"n\">generator</span><span class=\"p\">,</span>\n    <span class=\"n\">discriminative_model</span><span class=\"o\">=</span><span class=\"n\">discriminator</span><span class=\"p\">,</span>\n    <span class=\"n\">iter_n</span><span class=\"o\">=</span><span class=\"mi\">1000</span><span class=\"p\">,</span>\n    <span class=\"n\">k_step</span><span class=\"o\">=</span><span class=\"mi\">5</span>\n<span class=\"p\">)</span>\n</pre>\n<h4>Visualization.</h4>\n<p>Check the rewards or losses.</p>\n<h5>Result of pre-training.</h5>\n<pre><span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">figure</span><span class=\"p\">(</span><span class=\"n\">figsize</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">))</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">title</span><span class=\"p\">(</span><span class=\"s2\">\"The reconstruction errors.\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">generator</span><span class=\"o\">.</span><span class=\"n\">pre_loss_arr</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span>\n</pre>\n<div><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/afa56da09a28da0dd3b84c8133d6716a7b42d25a/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6c6f67732f4141455f7072655f6c6561726e696e672e706e67\"></div>\n<h5>Result of training.</h5>\n<pre><span class=\"n\">a_logs_list</span><span class=\"p\">,</span> <span class=\"n\">d_logs_list</span><span class=\"p\">,</span> <span class=\"n\">g_logs_list</span> <span class=\"o\">=</span> <span class=\"n\">AAE</span><span class=\"o\">.</span><span class=\"n\">extract_logs_tuple</span><span class=\"p\">()</span>\n</pre>\n<p><code>a_logs_list</code> is a <code>list</code> of the reconstruction errors.</p>\n<p>Visualize the values of <code>a_logs_list</code>.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"k\">as</span> <span class=\"nn\">plt</span>\n<span class=\"kn\">import</span> <span class=\"nn\">seaborn</span> <span class=\"k\">as</span> <span class=\"nn\">sns</span>\n<span class=\"o\">%</span><span class=\"n\">config</span> <span class=\"n\">InlineBackend</span><span class=\"o\">.</span><span class=\"n\">figure_format</span> <span class=\"o\">=</span> <span class=\"s2\">\"retina\"</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">figure</span><span class=\"p\">(</span><span class=\"n\">figsize</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">))</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">title</span><span class=\"p\">(</span><span class=\"s2\">\"The reconstruction errors.\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">a_logs_list</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span>\n</pre>\n<div><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/de859a3a48d7c6b0ea27068a57b9c3ab2c319b44/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6c6f67732f616c6c5f7265636f6e737472756374696f6e5f6572726f72732e706e67\"></div>\n<p>The error is not decreasing in steps toward the lower side. Initially, the error is monotonically increased probably due to the side effects of <code>GeneratorModel</code> and <code>DiscriminativeModel</code> learning in GANs framework. However, as learning as an Auto-Encoder progresses gradually in AAEs framework, it converges after showing the tendency of the monotonous phenomenon.</p>\n<p>Visualize the values of <code>d_logs_list</code>.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"k\">as</span> <span class=\"nn\">plt</span>\n<span class=\"kn\">import</span> <span class=\"nn\">seaborn</span> <span class=\"k\">as</span> <span class=\"nn\">sns</span>\n<span class=\"o\">%</span><span class=\"n\">config</span> <span class=\"n\">InlineBackend</span><span class=\"o\">.</span><span class=\"n\">figure_format</span> <span class=\"o\">=</span> <span class=\"s2\">\"retina\"</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">style</span><span class=\"o\">.</span><span class=\"n\">use</span><span class=\"p\">(</span><span class=\"s2\">\"fivethirtyeight\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">figure</span><span class=\"p\">(</span><span class=\"n\">figsize</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">))</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">d_logs_list</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">xlabel</span><span class=\"p\">(</span><span class=\"s2\">\"Epochs\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">ylabel</span><span class=\"p\">(</span><span class=\"s2\">\"Loss\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n</pre>\n<div>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/14f0c409758ff5a2137458b691e07517a0c8dac6/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6c6f67732f70726f626162696c6974795f696e5f442e706e67\">\n</div>\n<p>Similarly, visualize the values of <code>g_logs_list</code>.</p>\n<pre><span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">figure</span><span class=\"p\">(</span><span class=\"n\">figsize</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">))</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">g_logs_list</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">xlabel</span><span class=\"p\">(</span><span class=\"s2\">\"Epochs\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">ylabel</span><span class=\"p\">(</span><span class=\"s2\">\"Loss\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n</pre>\n<div>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/527f6deff6bcc2f192eecb0a4602f28c799c034d/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6c6f67732f70726f626162696c6974795f696e5f472e706e67\">\n</div>\n<p>As the training progresses, the values are close to not <code>0.5</code> but about <code>0.55</code>.</p>\n<p>Apparently it was not perfect. But we can take heart from the generated images.</p>\n<h4>Generation.</h4>\n<p>Let's define a helper function for plotting.</p>\n<pre><span class=\"k\">def</span> <span class=\"nf\">plot</span><span class=\"p\">(</span><span class=\"n\">arr</span><span class=\"p\">):</span>\n    <span class=\"sd\">'''</span>\n<span class=\"sd\">    Plot three gray scaled images.</span>\n\n<span class=\"sd\">    Args:</span>\n<span class=\"sd\">        arr:    mini-batch data.</span>\n\n<span class=\"sd\">    '''</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">):</span>\n        <span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">imshow</span><span class=\"p\">(</span><span class=\"n\">arr</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"n\">cmap</span><span class=\"o\">=</span><span class=\"s2\">\"gray\"</span><span class=\"p\">);</span>\n        <span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n        <span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span>\n</pre>\n<p>Draw from a true distribution of images and input it to <code>plot</code> function.</p>\n<pre><span class=\"n\">arr</span> <span class=\"o\">=</span> <span class=\"n\">true_sampler</span><span class=\"o\">.</span><span class=\"n\">draw</span><span class=\"p\">()</span>\n<span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">arr</span><span class=\"p\">)</span>\n</pre>\n<div>\n<table>\n<tbody>\n<tr>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d708972b783594f16944c7623e8bdbe0031d8b4c/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6f627365727665642f73616d706c65312e706e67\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/621a1f696f687dce53a8ab3464be5a7f094ddaac/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6f627365727665642f73616d706c65322e706e67\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/06ced30d14de7d1367572175eb05df7a8067920a/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6f627365727665642f73616d706c65332e706e67\">\n</td>\n</tr>\n</tbody>\n</table>\n<p>Input the generated <code>np.ndarray</code> to <code>plot</code> function.</p>\n<pre><span class=\"n\">arr</span> <span class=\"o\">=</span> <span class=\"n\">generator</span><span class=\"o\">.</span><span class=\"n\">draw</span><span class=\"p\">()</span>\n<span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">arr</span><span class=\"p\">)</span>\n</pre>\n<div>\n<table>\n<tbody>\n<tr>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8798a847b5385179b3c910edb325398ae94f8978/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f67656e6572617465642f616674657231353030747261696e2f73616d706c65312e706e67\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3ea26844ce19645edc9391767291d976ffe49e9d/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f67656e6572617465642f616674657231353030747261696e2f73616d706c65322e706e67\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/70e6e3b45c5aab2b89c3906c65c25002d97069b6/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f67656e6572617465642f616674657231353030747261696e2f73616d706c65332e706e67\">\n</td>\n</tr>\n</tbody>\n</table>\n<p>Next, observe the true images and reconstructed images.</p>\n<pre><span class=\"n\">observed_arr</span> <span class=\"o\">=</span> <span class=\"n\">generator</span><span class=\"o\">.</span><span class=\"n\">noise_sampler</span><span class=\"o\">.</span><span class=\"n\">generate</span><span class=\"p\">()</span>\n<span class=\"n\">decoded_arr</span> <span class=\"o\">=</span> <span class=\"n\">generator</span><span class=\"o\">.</span><span class=\"n\">inference</span><span class=\"p\">(</span><span class=\"n\">observed_arr</span><span class=\"p\">)</span>\n<span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">observed_arr</span><span class=\"p\">)</span>\n<span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">decoded_arr</span><span class=\"p\">)</span>\n</pre>\n<div>\n<table>\n<tbody>\n<tr>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1b28141934535296b2253c91de3843d1d72e7d05/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f616674657231353030747261696e2f696e7075745f73616d706c65312e706e67\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1ed785113f18200ca7e69c76d61e5c0d13ea2a0a/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f616674657231353030747261696e2f696e7075745f73616d706c65322e706e67\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f38c2eddc0304c1bbf9869e353e7dbdeff1cb1ff/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f616674657231353030747261696e2f696e7075745f73616d706c65332e706e67\">\n</td>\n</tr>\n<tr>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/259bd72d06fe61fa3e63e503e74f4d2f09b2faed/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f616674657231353030747261696e2f6465636f6465645f73616d706c65312e706e67\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/477b7698c2fc81ad91c1de0e774d276f43da1577/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f616674657231353030747261696e2f6465636f6465645f73616d706c65322e706e67\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/35de85d53d1074e99cba7202600af693d2ce29dc/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f616674657231353030747261696e2f6465636f6465645f73616d706c65332e706e67\">\n</td>\n</tr>\n</tbody>\n</table>\n<h4>About the progress of learning</h4>\n<p>Just observing the results of learning does not tell how learning of each model is progressing. In the following, the progress of each learning step is confirmed from the generated images and the reconstructed images.</p>\n<h5>Generated images in 500 step.</h5>\n<pre><span class=\"n\">arr</span> <span class=\"o\">=</span> <span class=\"n\">generator</span><span class=\"o\">.</span><span class=\"n\">draw</span><span class=\"p\">()</span>\n<span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">arr</span><span class=\"p\">)</span>\n</pre>\n<div>\n<table>\n<tbody>\n<tr>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/14bfc42e5e62e81c8c616a686d3796151aeed48e/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f67656e6572617465642f6166746572353030747261696e2f73616d706c65312e706e67\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c5622e5cf6df4a40f3ce8e66d05beb0f1066c722/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f67656e6572617465642f6166746572353030747261696e2f73616d706c65322e706e67\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1788dd701ac1fe6416246fa7327aefc4fe1f22b2/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f67656e6572617465642f6166746572353030747261696e2f73616d706c65332e706e67\">\n</td>\n</tr>\n</tbody>\n</table>\n<h5>Generated images in 1000 step.</h5>\n<pre><span class=\"n\">arr</span> <span class=\"o\">=</span> <span class=\"n\">generator</span><span class=\"o\">.</span><span class=\"n\">draw</span><span class=\"p\">()</span>\n<span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">arr</span><span class=\"p\">)</span>\n</pre>\n<div>\n<table>\n<tbody>\n<tr>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f8a3b7b43e9e2fdacc61df37dfad72c811bd836c/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f67656e6572617465642f616674657231303030747261696e2f73616d706c65312e706e67\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/aeddc92427f5e33b4a7cf10e7da0cdf7aab7d7fc/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f67656e6572617465642f616674657231303030747261696e2f73616d706c65322e706e67\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6728e4845b61699ec6ef164b455fdad4c19fe2e3/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f67656e6572617465642f616674657231303030747261696e2f73616d706c65332e706e67\">\n</td>\n</tr>\n</tbody>\n</table>\n<h5>Generated images in 1500 step.</h5>\n<pre><span class=\"n\">arr</span> <span class=\"o\">=</span> <span class=\"n\">generator</span><span class=\"o\">.</span><span class=\"n\">draw</span><span class=\"p\">()</span>\n<span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">arr</span><span class=\"p\">)</span>\n</pre>\n<div>\n<table>\n<tbody>\n<tr>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8798a847b5385179b3c910edb325398ae94f8978/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f67656e6572617465642f616674657231353030747261696e2f73616d706c65312e706e67\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3ea26844ce19645edc9391767291d976ffe49e9d/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f67656e6572617465642f616674657231353030747261696e2f73616d706c65322e706e67\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/70e6e3b45c5aab2b89c3906c65c25002d97069b6/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f67656e6572617465642f616674657231353030747261696e2f73616d706c65332e706e67\">\n</td>\n</tr>\n</tbody>\n</table>\n<h5>Reconstructed images in 500 step.</h5>\n<pre><span class=\"n\">observed_arr</span> <span class=\"o\">=</span> <span class=\"n\">generator</span><span class=\"o\">.</span><span class=\"n\">noise_sampler</span><span class=\"o\">.</span><span class=\"n\">generate</span><span class=\"p\">()</span>\n<span class=\"n\">decoded_arr</span> <span class=\"o\">=</span> <span class=\"n\">generator</span><span class=\"o\">.</span><span class=\"n\">inference</span><span class=\"p\">(</span><span class=\"n\">observed_arr</span><span class=\"p\">)</span>\n<span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">observed_arr</span><span class=\"p\">)</span>\n<span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">decoded_arr</span><span class=\"p\">)</span>\n</pre>\n<div>\n<table>\n<tbody>\n<tr>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/401c69d730a00ed3cee88d16abf1f3048499234a/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f6166746572353030747261696e2f696e7075745f73616d706c65342e706e67\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/333525571f8aeb9b1c7ee8308d71d8bd7ec78713/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f6166746572353030747261696e2f696e7075745f73616d706c65352e706e67\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/add9b8e1d9dcdb18e0076c6deedb639dd0da2bf9/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f6166746572353030747261696e2f696e7075745f73616d706c65362e706e67\">\n</td>\n</tr>\n<tr>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8d06b78a86a8fd96c04704a1081374947e6c2fad/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f6166746572353030747261696e2f6465636f6465645f73616d706c65342e706e67\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bb06a46eaf9e7bd5d2cac2884763a9b473eacfca/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f6166746572353030747261696e2f6465636f6465645f73616d706c65352e706e67\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/dad929c241849b240d5c178ac14e078a53fa6636/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f6166746572353030747261696e2f6465636f6465645f73616d706c65362e706e67\">\n</td>\n</tr>\n</tbody>\n</table>\n<h5>Reconstructed images in 1000 step.</h5>\n<pre><span class=\"n\">observed_arr</span> <span class=\"o\">=</span> <span class=\"n\">generator</span><span class=\"o\">.</span><span class=\"n\">noise_sampler</span><span class=\"o\">.</span><span class=\"n\">generate</span><span class=\"p\">()</span>\n<span class=\"n\">decoded_arr</span> <span class=\"o\">=</span> <span class=\"n\">generator</span><span class=\"o\">.</span><span class=\"n\">inference</span><span class=\"p\">(</span><span class=\"n\">observed_arr</span><span class=\"p\">)</span>\n<span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">observed_arr</span><span class=\"p\">)</span>\n<span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">decoded_arr</span><span class=\"p\">)</span>\n</pre>\n<div>\n<table>\n<tbody>\n<tr>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/800e9f3826e96c6f9aa517b29767d242eeb37f80/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f616674657231303030747261696e2f696e7075745f73616d706c65312e706e673f31\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/184e27378d7e3a422030265ae7154c5dcd5f126a/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f616674657231303030747261696e2f696e7075745f73616d706c65322e706e673f31\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bff12a53d43cdd061b3a78fdf2af6cd54bcd387b/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f616674657231303030747261696e2f696e7075745f73616d706c65332e706e673f31\">\n</td>\n</tr>\n<tr>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/032116d6058fc2edb30c9d6a9e42a9ad3eeb32aa/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f616674657231303030747261696e2f6465636f6465645f73616d706c65312e706e673f31\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5177f6a36e97c1e3bf90c886a4204d6c93f3437f/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f616674657231303030747261696e2f6465636f6465645f73616d706c65322e706e673f31\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8b3de3be1623cb6ea9d06bb50e31af50eb866550/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f616674657231303030747261696e2f6465636f6465645f73616d706c65332e706e673f31\">\n</td>\n</tr>\n</tbody>\n</table>\n<h5>Reconstructed images in 1500 step.</h5>\n<pre><span class=\"n\">observed_arr</span> <span class=\"o\">=</span> <span class=\"n\">generator</span><span class=\"o\">.</span><span class=\"n\">noise_sampler</span><span class=\"o\">.</span><span class=\"n\">generate</span><span class=\"p\">()</span>\n<span class=\"n\">decoded_arr</span> <span class=\"o\">=</span> <span class=\"n\">generator</span><span class=\"o\">.</span><span class=\"n\">inference</span><span class=\"p\">(</span><span class=\"n\">observed_arr</span><span class=\"p\">)</span>\n<span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">observed_arr</span><span class=\"p\">)</span>\n<span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">decoded_arr</span><span class=\"p\">)</span>\n</pre>\n<div>\n<table>\n<tbody>\n<tr>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1b28141934535296b2253c91de3843d1d72e7d05/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f616674657231353030747261696e2f696e7075745f73616d706c65312e706e67\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1ed785113f18200ca7e69c76d61e5c0d13ea2a0a/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f616674657231353030747261696e2f696e7075745f73616d706c65322e706e67\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f38c2eddc0304c1bbf9869e353e7dbdeff1cb1ff/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f616674657231353030747261696e2f696e7075745f73616d706c65332e706e67\">\n</td>\n</tr>\n<tr>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/259bd72d06fe61fa3e63e503e74f4d2f09b2faed/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f616674657231353030747261696e2f6465636f6465645f73616d706c65312e706e67\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/477b7698c2fc81ad91c1de0e774d276f43da1577/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f616674657231353030747261696e2f6465636f6465645f73616d706c65322e706e67\">\n</td>\n<td>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/35de85d53d1074e99cba7202600af693d2ce29dc/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f616363656c2d627261696e2d636f64652f47656e657261746976652d416476657273617269616c2d4e6574776f726b732f6465636f6465642f616674657231353030747261696e2f6465636f6465645f73616d706c65332e706e67\">\n</td>\n</tr>\n</tbody>\n</table>\n<h2>References</h2>\n<ul>\n<li>Fang, W., Zhang, F., Sheng, V. S., &amp; Ding, Y. (2018). A method for improving CNN-based image recognition using DCGAN. Comput. Mater. Contin, 57, 167-178.</li>\n<li>Gauthier, J. (2014). Conditional generative adversarial nets for convolutional face generation. Class Project for Stanford CS231N: Convolutional Neural Networks for Visual Recognition, Winter semester, 2014(5), 2.</li>\n<li>Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... &amp; Bengio, Y. (2014). Generative adversarial nets. In Advances in neural information processing systems (pp. 2672-2680).</li>\n<li>Long, J., Shelhamer, E., &amp; Darrell, T. (2015). Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3431-3440).</li>\n<li>Makhzani, A., Shlens, J., Jaitly, N., Goodfellow, I., &amp; Frey, B. (2015). Adversarial autoencoders. arXiv preprint arXiv:1511.05644.</li>\n<li>Mirza, M., &amp; Osindero, S. (2014). Conditional generative adversarial nets. arXiv preprint arXiv:1411.1784.</li>\n<li>Mogren, O. (2016). C-RNN-GAN: Continuous recurrent neural networks with adversarial training. arXiv preprint arXiv:1611.09904.</li>\n<li>Rifai, S., Vincent, P., Muller, X., Glorot, X., &amp; Bengio, Y. (2011, June). Contractive auto-encoders: Explicit invariance during feature extraction. In Proceedings of the 28th International Conference on International Conference on Machine Learning (pp. 833-840). Omnipress.</li>\n<li>Rifai, S., Mesnil, G., Vincent, P., Muller, X., Bengio, Y., Dauphin, Y., &amp; Glorot, X. (2011, September). Higher order contractive auto-encoder. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases (pp. 645-660). Springer, Berlin, Heidelberg.</li>\n<li>Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., &amp; Chen, X. (2016). Improved techniques for training gans. In Advances in neural information processing systems (pp. 2234-2242).</li>\n<li>Yang, L. C., Chou, S. Y., &amp; Yang, Y. H. (2017). MidiNet: A convolutional generative adversarial network for symbolic-domain music generation. arXiv preprint arXiv:1703.10847.</li>\n<li>Zhao, J., Mathieu, M., &amp; LeCun, Y. (2016). Energy-based generative adversarial network. arXiv preprint arXiv:1609.03126.</li>\n<li>Warde-Farley, D., &amp; Bengio, Y. (2016). Improving generative adversarial networks with denoising feature matching.</li>\n</ul>\n<h3>Related PoC</h3>\n<ul>\n<li><a href=\"https://accel-brain.com/semantics-of-natural-language-processing-driven-by-bayesian-information-search-by-deep-reinforcement-learning/\" rel=\"nofollow\">\u6df1\u5c64\u5f37\u5316\u5b66\u7fd2\u306e\u30d9\u30a4\u30ba\u4e3b\u7fa9\u7684\u306a\u60c5\u5831\u63a2\u7d22\u306b\u99c6\u52d5\u3055\u308c\u305f\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\u306e\u610f\u5473\u8ad6</a> (Japanese)\n<ul>\n<li><a href=\"https://accel-brain.com/semantics-of-natural-language-processing-driven-by-bayesian-information-search-by-deep-reinforcement-learning/regularisierungsproblem-und-gan/\" rel=\"nofollow\">\u6b63\u5247\u5316\u554f\u984c\u306b\u304a\u3051\u308b\u6575\u5bfe\u7684\u751f\u6210\u30cd\u30c3\u30c8\u30ef\u30fc\u30af(GANs)\u3068\u6575\u5bfe\u7684\u81ea\u5df1\u7b26\u53f7\u5316\u5668(AAEs)\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u69cb\u9020</a></li>\n<li><a href=\"https://accel-brain.com/semantics-of-natural-language-processing-driven-by-bayesian-information-search-by-deep-reinforcement-learning/hierarchical-latent-variable-model-as-media-and-semi-supervised-learning-of-ladder-network-as-a-form/\" rel=\"nofollow\">\u968e\u5c64\u7684\u6f5c\u5728\u5909\u6570\u30e2\u30c7\u30eb\u3092\u30e1\u30c7\u30a3\u30a2\u3068\u3057\u305f\u30e9\u30c0\u30fc\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u534a\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u5f62\u5f0f\u3001\u30ce\u30a4\u30ba\u9664\u53bb\u578b\u81ea\u5df1\u7b26\u53f7\u5316\u5668\u306e\u6a5f\u80fd</a></li>\n<li><a href=\"https://accel-brain.com/semantics-of-natural-language-processing-driven-by-bayesian-information-search-by-deep-reinforcement-learning/lyaponov-stability-optimization-in-gan-and-auto-encoder-in-energy-based-models/\" rel=\"nofollow\">\u30a8\u30cd\u30eb\u30ae\u30fc\u30d9\u30fc\u30b9\u30e2\u30c7\u30eb\u3068\u3057\u3066\u306e\u6575\u5bfe\u7684\u751f\u6210\u30cd\u30c3\u30c8\u30ef\u30fc\u30af(GAN)\u3068\u81ea\u5df1\u7b26\u53f7\u5316\u5668\u306b\u304a\u3051\u308b\u30ea\u30a2\u30d7\u30ce\u30d5\u5b89\u5b9a</a></li>\n</ul>\n</li>\n<li><a href=\"https://accel-brain.com/data-modeling-von-korrespondenz-in-artificial-paradise/\" rel=\"nofollow\">\u300c\u4eba\u5de5\u306e\u7406\u60f3\u300d\u3092\u80cc\u666f\u3068\u3057\u305f\u300c\u4e07\u7269\u7167\u5fdc\u300d\u306e\u30c7\u30fc\u30bf\u30e2\u30c7\u30ea\u30f3\u30b0</a> (Japanese)\n<ul>\n<li><a href=\"https://accel-brain.com/data-modeling-von-korrespondenz-in-artificial-paradise/sozialstruktur-von-random-walk-und-semantik-der-dow-theorie/\" rel=\"nofollow\">\u30e9\u30f3\u30c0\u30e0\u30a6\u30a9\u30fc\u30af\u306e\u793e\u4f1a\u69cb\u9020\u3068\u30c0\u30a6\u7406\u8ad6\u306e\u610f\u5473\u8ad6\u3001\u518d\u5e30\u7684\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u4fa1\u683c\u5909\u52d5\u30e2\u30c7\u30eb\u304b\u3089\u6575\u5bfe\u7684\u751f\u6210\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\uff08GAN\uff09\u3078</a></li>\n</ul>\n</li>\n</ul>\n<h2>Author</h2>\n<ul>\n<li>chimera0(RUM)</li>\n</ul>\n<h2>Author URI</h2>\n<ul>\n<li><a href=\"http://accel-brain.com/\" rel=\"nofollow\">http://accel-brain.com/</a></li>\n</ul>\n<h2>License</h2>\n<ul>\n<li>GNU General Public License v2.0</li>\n</ul>\n</div></div></div></div></div></div></div></div></div>\n          </div>"}, "last_serial": 5902487, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "b7a4cbde9ceb3626015373e3542b1f05", "sha256": "08529584be51cf440837574362a4f40d49e22a8afcd95e1a4efeb492e8ab738b"}, "downloads": -1, "filename": "pygan-0.0.1.linux-x86_64.tar.gz", "has_sig": false, "md5_digest": "b7a4cbde9ceb3626015373e3542b1f05", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 30914, "upload_time": "2019-02-17T06:58:10", "upload_time_iso_8601": "2019-02-17T06:58:10.797265Z", "url": "https://files.pythonhosted.org/packages/32/b7/5c7fdc9755a6cb6ae0d68399683b5ceef33c8ef1e4a7a0b50c0248880e46/pygan-0.0.1.linux-x86_64.tar.gz", "yanked": false}, {"comment_text": "", "digests": {"md5": "b25fb055bd705e2add6f375179f8453a", "sha256": "8caff411dacd6d978eba3d8b951e4532440a0666e3fff0716b6f2ac45e9e8b04"}, "downloads": -1, "filename": "pygan-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "b25fb055bd705e2add6f375179f8453a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 26664, "upload_time": "2019-02-17T06:49:23", "upload_time_iso_8601": "2019-02-17T06:49:23.437077Z", "url": "https://files.pythonhosted.org/packages/22/cc/ff67db84432b0d1b3e03fef53b1d8ec3e08eddb976f40addde2517215726/pygan-0.0.1-py3-none-any.whl", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "5a5bf38c93966d8aec6254b0ae2e8c69", "sha256": "2cfe1cd2fd7a6d24bdbeb5f61f54abd4b1078e09094cdcfed19984577ae573ec"}, "downloads": -1, "filename": "pygan-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "5a5bf38c93966d8aec6254b0ae2e8c69", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 26658, "upload_time": "2019-02-17T07:01:53", "upload_time_iso_8601": "2019-02-17T07:01:53.159934Z", "url": "https://files.pythonhosted.org/packages/70/76/015fc10ec8526714a823a77eeaf77cc0e85549b45e419352d800ad2b6ecf/pygan-0.0.2-py3-none-any.whl", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "75916503aa2b2129a2dcf64a28564231", "sha256": "61ed5ce89fc2a0effe3d5ed7335b5442d24912d07037b9d4949baa2f779e3392"}, "downloads": -1, "filename": "pygan-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "75916503aa2b2129a2dcf64a28564231", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 50264, "upload_time": "2019-03-02T13:28:21", "upload_time_iso_8601": "2019-03-02T13:28:21.613742Z", "url": "https://files.pythonhosted.org/packages/09/99/21c01105e838e5ff4cd728db38bbabeaf652abead13f73ea052c0b3d0129/pygan-0.0.3-py3-none-any.whl", "yanked": false}], "1.0.0": [{"comment_text": "", "digests": {"md5": "6ca9e30654eb51de5b9259536716e395", "sha256": "40fa56ea35834e205a5ddeb8a523a43cf4d4bdc72d9ae92542ab89f9f68710d7"}, "downloads": -1, "filename": "pygan-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "6ca9e30654eb51de5b9259536716e395", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 58705, "upload_time": "2019-03-23T15:17:48", "upload_time_iso_8601": "2019-03-23T15:17:48.237462Z", "url": "https://files.pythonhosted.org/packages/d4/9f/23e77dfd7a1fd8f3093916dd9e7e92f2c08b0bfcee9195c0ef51cebf08eb/pygan-1.0.0-py3-none-any.whl", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "536c00d231488a3b302d401f3b02790d", "sha256": "c88ccb50520bf233945fee689f3b3eae9977471d7940e9507b538d129b35de4c"}, "downloads": -1, "filename": "pygan-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "536c00d231488a3b302d401f3b02790d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 58778, "upload_time": "2019-04-07T03:16:20", "upload_time_iso_8601": "2019-04-07T03:16:20.028010Z", "url": "https://files.pythonhosted.org/packages/33/20/ee05dc7daeebd89b76d6c1cd34f0a8f57d6cc8a315d115c00b4edfb8a15a/pygan-1.0.1-py3-none-any.whl", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "11a389a2823eb4f8897566cb403ec2ae", "sha256": "9af944879056c93c11b487bce112cbc2640ecd1635cf194437a27ae0e0139fef"}, "downloads": -1, "filename": "pygan-1.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "11a389a2823eb4f8897566cb403ec2ae", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 66602, "upload_time": "2019-04-20T15:28:28", "upload_time_iso_8601": "2019-04-20T15:28:28.730863Z", "url": "https://files.pythonhosted.org/packages/40/1c/041014fbafb6bc3e9be0f2e95ec4da5d173c3cacf7ab0c05df89d1869185/pygan-1.0.2-py3-none-any.whl", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "15ed2108298f0cc008a70335fa367a91", "sha256": "4defbfa7c5d53d4305666ba8601fb298bb2ff563e997fa59b1c9bb33938c5191"}, "downloads": -1, "filename": "pygan-1.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "15ed2108298f0cc008a70335fa367a91", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 73824, "upload_time": "2019-06-03T13:32:21", "upload_time_iso_8601": "2019-06-03T13:32:21.752673Z", "url": "https://files.pythonhosted.org/packages/87/eb/5c5aef27825088c3826a476d95a0b7e461e0ce1e9205a06afdfb8c9adc51/pygan-1.0.3-py3-none-any.whl", "yanked": false}], "1.0.4": [{"comment_text": "", "digests": {"md5": "29fc9f6748b17583234369e048836f71", "sha256": "622a3d0a3643aaa3d12c86b53714b11082cf90f0329f90ef7118a840e773d38d"}, "downloads": -1, "filename": "pygan-1.0.4.tar.gz", "has_sig": false, "md5_digest": "29fc9f6748b17583234369e048836f71", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 49859, "upload_time": "2019-06-08T15:31:36", "upload_time_iso_8601": "2019-06-08T15:31:36.588626Z", "url": "https://files.pythonhosted.org/packages/32/35/13d6d340fad62d9a3aa01ebd5d92c409474e5eea3720de1f578d43445a8a/pygan-1.0.4.tar.gz", "yanked": false}], "1.0.5": [{"comment_text": "", "digests": {"md5": "555a2fcb6f6f63931a4df53324df471e", "sha256": "c350f2084b5751382ecb0b54e5070b832e798c74d421ce501197dbf991907c70"}, "downloads": -1, "filename": "pygan-1.0.5.tar.gz", "has_sig": false, "md5_digest": "555a2fcb6f6f63931a4df53324df471e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 52368, "upload_time": "2019-06-23T11:28:22", "upload_time_iso_8601": "2019-06-23T11:28:22.302788Z", "url": "https://files.pythonhosted.org/packages/c8/a7/64faab941481d417ba53f775bcf2be16548f48e0eb38120f2dcd238d5599/pygan-1.0.5.tar.gz", "yanked": false}], "1.0.6": [{"comment_text": "", "digests": {"md5": "c86e3da8cf4c09345da1531ba094affe", "sha256": "1bee19f7dccc65dec79da64121b70cd266540f616e7fe83f7738739a92369a74"}, "downloads": -1, "filename": "pygan-1.0.6.tar.gz", "has_sig": false, "md5_digest": "c86e3da8cf4c09345da1531ba094affe", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 53059, "upload_time": "2019-06-30T08:42:30", "upload_time_iso_8601": "2019-06-30T08:42:30.548930Z", "url": "https://files.pythonhosted.org/packages/c8/3d/aed88c8403277f3f624f1c19dcb9b7a0d3457ff027213a403dc6e5b9967f/pygan-1.0.6.tar.gz", "yanked": false}], "1.0.7": [{"comment_text": "", "digests": {"md5": "9e1e1229a1e2b888b9cf0c6bfef8628a", "sha256": "cc3f5ca0b400d74c1aa3d4830dc9f64b105069ef8f5af56f1a47e75ed41b7244"}, "downloads": -1, "filename": "pygan-1.0.7.tar.gz", "has_sig": false, "md5_digest": "9e1e1229a1e2b888b9cf0c6bfef8628a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 55557, "upload_time": "2019-07-21T14:11:48", "upload_time_iso_8601": "2019-07-21T14:11:48.590376Z", "url": "https://files.pythonhosted.org/packages/96/f9/d960fed6e2268884b18f794e8b1d8aa65a261a2da6b00a5bef7267151f0b/pygan-1.0.7.tar.gz", "yanked": false}], "1.0.8": [{"comment_text": "", "digests": {"md5": "8bceed57e88dad4dd552d505f7ccd8ff", "sha256": "73e251a199919cabd7c9eaef71e97a0703cfb316cce679dbf2fa1dc31d255dc1"}, "downloads": -1, "filename": "pygan-1.0.8.tar.gz", "has_sig": false, "md5_digest": "8bceed57e88dad4dd552d505f7ccd8ff", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 58923, "upload_time": "2019-09-29T12:13:25", "upload_time_iso_8601": "2019-09-29T12:13:25.418087Z", "url": "https://files.pythonhosted.org/packages/1f/82/37db74b0acd7dc1fc7eb9f2cb03f6b810ae6a9d5020427b0ec248d095df2/pygan-1.0.8.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "8bceed57e88dad4dd552d505f7ccd8ff", "sha256": "73e251a199919cabd7c9eaef71e97a0703cfb316cce679dbf2fa1dc31d255dc1"}, "downloads": -1, "filename": "pygan-1.0.8.tar.gz", "has_sig": false, "md5_digest": "8bceed57e88dad4dd552d505f7ccd8ff", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 58923, "upload_time": "2019-09-29T12:13:25", "upload_time_iso_8601": "2019-09-29T12:13:25.418087Z", "url": "https://files.pythonhosted.org/packages/1f/82/37db74b0acd7dc1fc7eb9f2cb03f6b810ae6a9d5020427b0ec248d095df2/pygan-1.0.8.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:05:18 2020"}