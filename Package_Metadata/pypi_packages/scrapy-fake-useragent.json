{"info": {"author": "Alexander Afanasyev", "author_email": "me@alecxe.me", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Framework :: Scrapy", "Intended Audience :: Developers", "License :: OSI Approved :: BSD License", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8", "Topic :: Internet :: WWW/HTTP"], "description": ".. image:: https://travis-ci.org/alecxe/scrapy-fake-useragent.svg?branch=master\n    :target: https://travis-ci.org/alecxe/scrapy-fake-useragent\n\n.. image:: https://codecov.io/gh/alecxe/scrapy-fake-useragent/branch/master/graph/badge.svg\n  :target: https://codecov.io/gh/alecxe/scrapy-fake-useragent\n\n.. image:: https://img.shields.io/pypi/pyversions/scrapy-fake-useragent.svg\n     :target: https://pypi.python.org/pypi/scrapy-fake-useragent\n     :alt: PyPI version\n\n.. image:: https://badge.fury.io/py/scrapy-fake-useragent.svg\n     :target: http://badge.fury.io/py/scrapy-fake-useragent\n     :alt: PyPI version\n\n.. image:: https://requires.io/github/alecxe/scrapy-fake-useragent/requirements.svg?branch=master\n     :target: https://requires.io/github/alecxe/scrapy-fake-useragent/requirements/?branch=master\n     :alt: Requirements Status\n\n\nscrapy-fake-useragent\n=====================\n\nRandom User-Agent middleware based on\n`fake-useragent <https://pypi.python.org/pypi/fake-useragent>`__. It\npicks up ``User-Agent`` strings based on `usage\nstatistics <http://www.w3schools.com/browsers/browsers_stats.asp>`__\nfrom a `real world database <http://useragentstring.com/>`__.\n\nInstallation\n-------------\n\nThe simplest way is to install it via `pip`:\n\n    pip install scrapy-fake-useragent\n\nConfiguration\n-------------\n\nTurn off the built-in ``UserAgentMiddleware`` and ``RetryMiddleware`` and add\n``RandomUserAgentMiddleware`` and ``RetryUserAgentMiddleware``.\n\nIn Scrapy >=1.0:\n\n.. code:: python\n\n    DOWNLOADER_MIDDLEWARES = {\n        'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': None,\n        'scrapy.downloadermiddlewares.retry.RetryMiddleware': None,\n        'scrapy_fake_useragent.middleware.RandomUserAgentMiddleware': 400,\n        'scrapy_fake_useragent.middleware.RetryUserAgentMiddleware': 401,\n    }\n\nIn Scrapy <1.0:\n\n.. code:: python\n\n    DOWNLOADER_MIDDLEWARES = {\n        'scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware': None,\n        'scrapy.contrib.downloadermiddleware.retry.RetryMiddleware': None,\n        'scrapy_fake_useragent.middleware.RandomUserAgentMiddleware': 400,\n        'scrapy_fake_useragent.middleware.RetryUserAgentMiddleware': 401,\n    }\n\nConfiguring User-Agent type\n---------------------------\n\nThere's a configuration parameter ``RANDOM_UA_TYPE`` defaulting to ``random`` which is passed verbatim to the fake-user-agent. Therefore you can set it to say ``firefox`` to mimic only firefox browsers. Most useful though would be to use ``desktop`` or ``mobile`` values to send desktop or mobile strings respectively.\n\nUsage with `scrapy-proxies`\n---------------------------\n\nTo use with middlewares of random proxy such as `scrapy-proxies <https://github.com/aivarsk/scrapy-proxies>`_, you need:\n\n1. set ``RANDOM_UA_PER_PROXY`` to True to allow switch per proxy\n\n2. set priority of ``RandomUserAgentMiddleware`` to be greater than ``scrapy-proxies``, so that proxy is set before handle UA\n\n\n.. |GitHub version| image:: https://badge.fury.io/gh/alecxe%2Fscrapy-fake-useragent.svg\n   :target: http://badge.fury.io/gh/alecxe%2Fscrapy-fake-useragent\n.. |Requirements Status| image:: https://requires.io/github/alecxe/scrapy-fake-useragent/requirements.svg?branch=master\n   :target: https://requires.io/github/alecxe/scrapy-fake-useragent/requirements/?branch=master\n\nConfiguring Fake-UserAgent fallback\n-----------------------------------\n\nThere's a configuration parameter ``FAKEUSERAGENT_FALLBACK`` defaulting to\n``None``. You can set it to a string value, for example ``Mozilla`` or\n``Your favorite browser``, this configuration can completely disable any\nannoying exception that may happen if `fake-useragent` failed to retrieve a random UA string.\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/alecxe/scrapy-fake-useragent", "keywords": "scrapy proxy user-agent web-scraping", "license": "New BSD License", "maintainer": "Alexander Afanasyev", "maintainer_email": "me@alecxe.me", "name": "scrapy-fake-useragent", "package_url": "https://pypi.org/project/scrapy-fake-useragent/", "platform": "", "project_url": "https://pypi.org/project/scrapy-fake-useragent/", "project_urls": {"Homepage": "https://github.com/alecxe/scrapy-fake-useragent"}, "release_url": "https://pypi.org/project/scrapy-fake-useragent/1.2.0/", "requires_dist": ["fake-useragent"], "requires_python": "", "summary": "Use a random User-Agent provided by fake-useragent for every request", "version": "1.2.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://travis-ci.org/alecxe/scrapy-fake-useragent\" rel=\"nofollow\"><img alt=\"https://travis-ci.org/alecxe/scrapy-fake-useragent.svg?branch=master\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/21697b0c341574deed125daaa3e2acf2807e327e/68747470733a2f2f7472617669732d63692e6f72672f616c656378652f7363726170792d66616b652d757365726167656e742e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://codecov.io/gh/alecxe/scrapy-fake-useragent\" rel=\"nofollow\"><img alt=\"https://codecov.io/gh/alecxe/scrapy-fake-useragent/branch/master/graph/badge.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/11e3713dace143fea63d25a00ebf4745471f3aa6/68747470733a2f2f636f6465636f762e696f2f67682f616c656378652f7363726170792d66616b652d757365726167656e742f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a>\n<a href=\"https://pypi.python.org/pypi/scrapy-fake-useragent\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4f024aa77b1c95b30db4a4b814dd37c1f62a9a31/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f7363726170792d66616b652d757365726167656e742e737667\"></a>\n<a href=\"http://badge.fury.io/py/scrapy-fake-useragent\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/cf50ea983851fd040f1015eedd00a8cb003938fa/68747470733a2f2f62616467652e667572792e696f2f70792f7363726170792d66616b652d757365726167656e742e737667\"></a>\n<a href=\"https://requires.io/github/alecxe/scrapy-fake-useragent/requirements/?branch=master\" rel=\"nofollow\"><img alt=\"Requirements Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bc35547189659e4796702226e4fb4d8ebf4e6b91/68747470733a2f2f72657175697265732e696f2f6769746875622f616c656378652f7363726170792d66616b652d757365726167656e742f726571756972656d656e74732e7376673f6272616e63683d6d6173746572\"></a>\n<div id=\"scrapy-fake-useragent\">\n<h2>scrapy-fake-useragent</h2>\n<p>Random User-Agent middleware based on\n<a href=\"https://pypi.python.org/pypi/fake-useragent\" rel=\"nofollow\">fake-useragent</a>. It\npicks up <tt><span class=\"pre\">User-Agent</span></tt> strings based on <a href=\"http://www.w3schools.com/browsers/browsers_stats.asp\" rel=\"nofollow\">usage\nstatistics</a>\nfrom a <a href=\"http://useragentstring.com/\" rel=\"nofollow\">real world database</a>.</p>\n<div id=\"installation\">\n<h3>Installation</h3>\n<p>The simplest way is to install it via <cite>pip</cite>:</p>\n<blockquote>\npip install scrapy-fake-useragent</blockquote>\n</div>\n<div id=\"configuration\">\n<h3>Configuration</h3>\n<p>Turn off the built-in <tt>UserAgentMiddleware</tt> and <tt>RetryMiddleware</tt> and add\n<tt>RandomUserAgentMiddleware</tt> and <tt>RetryUserAgentMiddleware</tt>.</p>\n<p>In Scrapy &gt;=1.0:</p>\n<pre><span class=\"n\">DOWNLOADER_MIDDLEWARES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.retry.RetryMiddleware'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy_fake_useragent.middleware.RandomUserAgentMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">400</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy_fake_useragent.middleware.RetryUserAgentMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">401</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre>\n<p>In Scrapy &lt;1.0:</p>\n<pre><span class=\"n\">DOWNLOADER_MIDDLEWARES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.contrib.downloadermiddleware.retry.RetryMiddleware'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy_fake_useragent.middleware.RandomUserAgentMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">400</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy_fake_useragent.middleware.RetryUserAgentMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">401</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre>\n</div>\n<div id=\"configuring-user-agent-type\">\n<h3>Configuring User-Agent type</h3>\n<p>There\u2019s a configuration parameter <tt>RANDOM_UA_TYPE</tt> defaulting to <tt>random</tt> which is passed verbatim to the fake-user-agent. Therefore you can set it to say <tt>firefox</tt> to mimic only firefox browsers. Most useful though would be to use <tt>desktop</tt> or <tt>mobile</tt> values to send desktop or mobile strings respectively.</p>\n</div>\n<div id=\"usage-with-scrapy-proxies\">\n<h3>Usage with <cite>scrapy-proxies</cite></h3>\n<p>To use with middlewares of random proxy such as <a href=\"https://github.com/aivarsk/scrapy-proxies\" rel=\"nofollow\">scrapy-proxies</a>, you need:</p>\n<ol>\n<li>set <tt>RANDOM_UA_PER_PROXY</tt> to True to allow switch per proxy</li>\n<li>set priority of <tt>RandomUserAgentMiddleware</tt> to be greater than <tt><span class=\"pre\">scrapy-proxies</span></tt>, so that proxy is set before handle UA</li>\n</ol>\n</div>\n<div id=\"configuring-fake-useragent-fallback\">\n<h3>Configuring Fake-UserAgent fallback</h3>\n<p>There\u2019s a configuration parameter <tt>FAKEUSERAGENT_FALLBACK</tt> defaulting to\n<tt>None</tt>. You can set it to a string value, for example <tt>Mozilla</tt> or\n<tt>Your favorite browser</tt>, this configuration can completely disable any\nannoying exception that may happen if <cite>fake-useragent</cite> failed to retrieve a random UA string.</p>\n</div>\n</div>\n\n          </div>"}, "last_serial": 6359593, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "e35b567fa3532fa0eb1e2706754852ba", "sha256": "697281fc0954fd29d7fc9e5ead74a6288d86e062db6fa419e980707d4da96eb5"}, "downloads": -1, "filename": "scrapy_fake_useragent-0.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e35b567fa3532fa0eb1e2706754852ba", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 3797, "upload_time": "2015-06-21T04:19:55", "upload_time_iso_8601": "2015-06-21T04:19:55.513131Z", "url": "https://files.pythonhosted.org/packages/98/82/8158eed69fb3cca8bf5f960aa9156ae8b95b4af00e26d1deb7b8ff9e0964/scrapy_fake_useragent-0.0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "304005fd14a21856b48c3cf13b2a82a7", "sha256": "88e557917164a22a4b85db4554f9016fbe0c245bea3d7a57a4adcd6d992213c4"}, "downloads": -1, "filename": "scrapy-fake-useragent-0.0.1.tar.gz", "has_sig": false, "md5_digest": "304005fd14a21856b48c3cf13b2a82a7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 1832, "upload_time": "2015-06-21T04:12:35", "upload_time_iso_8601": "2015-06-21T04:12:35.846094Z", "url": "https://files.pythonhosted.org/packages/93/ed/5579d4e2cfffdc82503bd76b5b1ec60a73f85de612a85a8550eb6020cd20/scrapy-fake-useragent-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "7f127d2e18ade59b0151529a59650a98", "sha256": "cec0677675761d4677b018161926a353a52185752690181d100c12dc5a015e88"}, "downloads": -1, "filename": "scrapy_fake_useragent-0.0.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "7f127d2e18ade59b0151529a59650a98", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 4384, "upload_time": "2016-09-23T14:14:35", "upload_time_iso_8601": "2016-09-23T14:14:35.677892Z", "url": "https://files.pythonhosted.org/packages/5b/b2/e658fc92548883709990b72acb6115ad0305881ca6b513382e516ceb1a01/scrapy_fake_useragent-0.0.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4fef19a59493d9194223804635ad5b5f", "sha256": "e8cd95c6274256faeda2fb48511e2f4f1eaf9f7dd6c48992d2cfe2a780e2d5ff"}, "downloads": -1, "filename": "scrapy-fake-useragent-0.0.2.tar.gz", "has_sig": false, "md5_digest": "4fef19a59493d9194223804635ad5b5f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2245, "upload_time": "2016-09-23T14:15:25", "upload_time_iso_8601": "2016-09-23T14:15:25.269830Z", "url": "https://files.pythonhosted.org/packages/73/72/389d98e183f238b845ecf1f0865bf42f2055ad1481be58adbef1a93660a6/scrapy-fake-useragent-0.0.2.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "065eed0a6df8106fcd029f1717270c66", "sha256": "f1a9b4cb51eb3337672b364fd5022ba0116d9f1e8631fa0935e69d9f70e86bc7"}, "downloads": -1, "filename": "scrapy_fake_useragent-1.0.2.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "065eed0a6df8106fcd029f1717270c66", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 4446, "upload_time": "2017-05-27T15:58:36", "upload_time_iso_8601": "2017-05-27T15:58:36.337154Z", "url": "https://files.pythonhosted.org/packages/47/61/9018a06f5e65019f473c2f9c07b98c516c849913253e9b5cc7549b8b3075/scrapy_fake_useragent-1.0.2.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "11c1e4d83f08bad13d189a62b2b1971c", "sha256": "a8f6c6feeba04b4ea9c67509c8cdab836707b37dec7c90dfa30822e5a97a2318"}, "downloads": -1, "filename": "scrapy-fake-useragent-1.0.2.1.tar.gz", "has_sig": false, "md5_digest": "11c1e4d83f08bad13d189a62b2b1971c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2309, "upload_time": "2017-05-27T15:58:49", "upload_time_iso_8601": "2017-05-27T15:58:49.914724Z", "url": "https://files.pythonhosted.org/packages/7e/08/e87cbaa473ba2c9d13c1555d181f64657778a8aacd5036401b8ba1514614/scrapy-fake-useragent-1.0.2.1.tar.gz", "yanked": false}], "1.0.4": [{"comment_text": "", "digests": {"md5": "51e477d4d6980305f7796af98637be93", "sha256": "7b7ab0854dfc443b974ff19816784b571a54170c396ed9f27e5180edce4a8492"}, "downloads": -1, "filename": "scrapy_fake_useragent-1.0.4.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "51e477d4d6980305f7796af98637be93", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 4895, "upload_time": "2017-05-27T16:03:35", "upload_time_iso_8601": "2017-05-27T16:03:35.747017Z", "url": "https://files.pythonhosted.org/packages/72/68/a888e1150da52672b95983df33a7cbac04085b0bac39f92722663f420adc/scrapy_fake_useragent-1.0.4.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "944fb1424262e8a58fdc63a7e64bf5a1", "sha256": "c618285777b605b4fe2ad4157e214233c9e1be91d7f73712fa3546f09b4bc818"}, "downloads": -1, "filename": "scrapy-fake-useragent-1.0.4.1.tar.gz", "has_sig": false, "md5_digest": "944fb1424262e8a58fdc63a7e64bf5a1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2621, "upload_time": "2017-05-27T16:03:25", "upload_time_iso_8601": "2017-05-27T16:03:25.211434Z", "url": "https://files.pythonhosted.org/packages/b8/d3/8987cfabc2b72b68f732c973c4f7389514160b524af7b7d2ec89a8e1ccfd/scrapy-fake-useragent-1.0.4.1.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "61d223b4a2d67ba4450bae720cf6b4f1", "sha256": "4898772a7c5e6f7c58269c895ade39aab87038d2efea73fbe15a4aab1335f0b6"}, "downloads": -1, "filename": "scrapy_fake_useragent-1.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "61d223b4a2d67ba4450bae720cf6b4f1", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 5282, "upload_time": "2017-06-16T16:39:49", "upload_time_iso_8601": "2017-06-16T16:39:49.027622Z", "url": "https://files.pythonhosted.org/packages/0d/1b/c9e5f1917c87a09787271933dcd4bface93ee60248a6a85cc98f2fd58e2c/scrapy_fake_useragent-1.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8200cad1a93e9b68311d3f1252b2c168", "sha256": "cf004a651545585f2f05f0bd66cfe8c9df35778babf53bdfd856092d8b3b4068"}, "downloads": -1, "filename": "scrapy-fake-useragent-1.1.0.tar.gz", "has_sig": false, "md5_digest": "8200cad1a93e9b68311d3f1252b2c168", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2853, "upload_time": "2017-06-16T16:37:26", "upload_time_iso_8601": "2017-06-16T16:37:26.527053Z", "url": "https://files.pythonhosted.org/packages/bd/66/2daceedbf66a879e799a7405988842f917d4f8655475b707b9944304e103/scrapy-fake-useragent-1.1.0.tar.gz", "yanked": false}], "1.2.0": [{"comment_text": "", "digests": {"md5": "2b8105d387816d2508fdb20ac6d912c9", "sha256": "8dcf4c8cffd745d669c88ce59fc5daab550945c5dbae4c2b50985e5d12d735c5"}, "downloads": -1, "filename": "scrapy_fake_useragent-1.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "2b8105d387816d2508fdb20ac6d912c9", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4777, "upload_time": "2019-12-25T21:24:50", "upload_time_iso_8601": "2019-12-25T21:24:50.922839Z", "url": "https://files.pythonhosted.org/packages/cc/8d/faa730b8d1cb5114cb8d314b078167694d17c3d394992490551c2308928d/scrapy_fake_useragent-1.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ea080e27a699d4788e03d75eb7d79767", "sha256": "7480c9487304775601d8d1b81f89caf97dc2a664f2f42b7909b46d02d0f4aa0a"}, "downloads": -1, "filename": "scrapy-fake-useragent-1.2.0.tar.gz", "has_sig": false, "md5_digest": "ea080e27a699d4788e03d75eb7d79767", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3380, "upload_time": "2019-12-25T21:24:52", "upload_time_iso_8601": "2019-12-25T21:24:52.923874Z", "url": "https://files.pythonhosted.org/packages/5c/7c/d0169ce7302191cc5ba2d1fd255a63303c82789849d23dc692f0a8f92c09/scrapy-fake-useragent-1.2.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "2b8105d387816d2508fdb20ac6d912c9", "sha256": "8dcf4c8cffd745d669c88ce59fc5daab550945c5dbae4c2b50985e5d12d735c5"}, "downloads": -1, "filename": "scrapy_fake_useragent-1.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "2b8105d387816d2508fdb20ac6d912c9", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4777, "upload_time": "2019-12-25T21:24:50", "upload_time_iso_8601": "2019-12-25T21:24:50.922839Z", "url": "https://files.pythonhosted.org/packages/cc/8d/faa730b8d1cb5114cb8d314b078167694d17c3d394992490551c2308928d/scrapy_fake_useragent-1.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ea080e27a699d4788e03d75eb7d79767", "sha256": "7480c9487304775601d8d1b81f89caf97dc2a664f2f42b7909b46d02d0f4aa0a"}, "downloads": -1, "filename": "scrapy-fake-useragent-1.2.0.tar.gz", "has_sig": false, "md5_digest": "ea080e27a699d4788e03d75eb7d79767", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3380, "upload_time": "2019-12-25T21:24:52", "upload_time_iso_8601": "2019-12-25T21:24:52.923874Z", "url": "https://files.pythonhosted.org/packages/5c/7c/d0169ce7302191cc5ba2d1fd255a63303c82789849d23dc692f0a8f92c09/scrapy-fake-useragent-1.2.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:56:47 2020"}