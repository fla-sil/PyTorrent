{"info": {"author": "Stephen OShea", "author_email": "stephenlmoshea@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Topic :: Software Development :: Build Tools"], "description": "# Neural network\nArtificial neural network for Python. Features online backpropagtion learning using gradient descent, momentum, the sigmoid and hyperbolic tangent activation function.\n\n## About\nThe library allows you to build and train multi-layer neural networks. You first define the structure for the network. The number of input, output, layers and hidden nodes. The network is then constructed. Interconnection strengths are represented using an adjacency matrix and initialised to small random values.  Traning data is then presented to the network incrementally. The neural network uses an online backpropagation training algorithm that uses gradient descent to descend the error curve to adjust interconnection strengths. The aim of the training algorithm is to adjust the interconnection strengths in order to reduce the global error. The global error for the network is calculated using the mean sqaured error. \n\nYou can provide a learning rate and momentum parameter.  The learning rate will affect the speed at which the neural network converges to an optimal solution. The momentum parameter will help gradient descent to avoid converging to a non optimal solution on the error curve called local minima.  The correct size for the momentum parameter will help to find the global minima but too large a value will prevent the neural network from ever converging to a solution.\n\nTrained neural networks can be saved to file and loaded back for later activation.\n\n## Installation\n```bash\n$  pip install neuralnetwork\n```\n## Examples\n### Training XOR function on three layer neural network with two inputs and one output\n```py\nfrom neuralnetwork.FeedForward import FeedForward\nfrom neuralnetwork.Sigmoid import Sigmoid\nfrom neuralnetwork.Backpropagation import Backpropagation\n\nsigmoid = Sigmoid()\n\nnetworkLayer = [2,2,1]\n\nfeedForward = FeedForward(networkLayer, sigmoid)\n\nbackpropagation = Backpropagation(feedForward,0.7,0.3)\n\ntrainingSet = [\n    [0,0,0],\n    [0,1,1],\n    [1,0,1],\n    [1,1,0]\n]\n\nwhile True:\n    backpropagation.initialise()\n    result = backpropagation.train(trainingSet)\n\n    if(result):\n        break\n\nfeedForward.activate([0,0])\noutputs = feedForward.getOutputs()\nprint(outputs[0])\n\nfeedForward.activate([0,1])\noutputs = feedForward.getOutputs()\nprint(outputs[0])\n\nfeedForward.activate([1,0])\noutputs = feedForward.getOutputs()\nprint(outputs[0])\n\nfeedForward.activate([1,1])\noutputs = feedForward.getOutputs()\nprint(outputs[0])\n```\n\n### Training XOR function on three layer neural network using Hyperbolic Tangent\n```py\nfrom neuralnetwork.FeedForward import FeedForward\nfrom neuralnetwork.HyperbolicTangent import HyperbolicTanget\nfrom neuralnetwork.Backpropagation import Backpropagation\n\nhyperbolicTangent = HyperbolicTangent()\n\nnetworkLayer = [2,2,1]\n\nfeedForward = FeedForward(networkLayer, hyperbolicTangent)\n\nbackpropagation = Backpropagation(feedForward,0.7,0.3,0.001)\n\ntrainingSet = [\n                    [-1,-1,-1],\n                    [-1,1,1],\n                    [1,-1,1],\n                    [1,1,-1]\n                ];\n\nwhile True:\n    backpropagation.initialise()\n    result = backpropagation.train(trainingSet)\n\n    if(result):\n        break\n\nfeedForward.activate([-1,-1])\noutputs = feedForward.getOutputs()\nprint(outputs[0])\n\nfeedForward.activate([-1,1])\noutputs = feedForward.getOutputs()\nprint(outputs[0])\n\nfeedForward.activate([1,-1])\noutputs = feedForward.getOutputs()\nprint(outputs[0])\n\nfeedForward.activate([1,1])\noutputs = feedForward.getOutputs()\nprint(outputs[0])\n```\n\n### Saving trained neural network to file\n```py\nfrom neuralnetwork.FeedForward import FeedForward\nfrom neuralnetwork.Sigmoid import Sigmoid\nfrom neuralnetwork.Backpropagation import Backpropagation\n\nsigmoid = Sigmoid()\n\nnetworkLayer = [2,2,1]\n\nfeedForward = FeedForward(networkLayer, sigmoid)\n\nbackpropagation = Backpropagation(feedForward,0.7,0.3)\n\ntrainingSet = [\n    [0,0,0],\n    [0,1,1],\n    [1,0,1],\n    [1,1,0]\n]\n\nwhile True:\n    backpropagation.initialise()\n    result = backpropagation.train(trainingSet)\n\n    if(result):\n        break\n\nfeedForward.save('./network.txt')\n```\n\n### Load trained neural network from file\n```py\nfrom neuralnetwork.FeedForward import FeedForward\nfrom neuralnetwork.Sigmoid import Sigmoid\nfrom neuralnetwork.Backpropagation import Backpropagation\n\nfeedForward = FeedForward.load('./network.txt')\n\nfeedForward.activate([0,0])\noutputs = feedForward.getOutputs()\nprint(outputs[0])\n\nfeedForward.activate([0,1])\noutputs = feedForward.getOutputs()\nprint(outputs[0])\n\nfeedForward.activate([1,0])\noutputs = feedForward.getOutputs()\nprint(outputs[0])\n\nfeedForward.activate([1,1])\noutputs = feedForward.getOutputs()\nprint(outputs[0])\n```\n\n## Training Neural Network to Predict Diabetes\nFor this example we will train a neural network to predict whether a patient will develop diabetes within the next five years given various health measurements such as number of times pregnant, glucose plasma, blood pressure diastolic, skin fold thickness, serum insulin, body mass index, diabetes pedigree function, and age.\n\nThe dataset for this project is hosted by Kaggle. To download the necessary dataset for this example, please follow the instructions below.\n\n1. Go to https://www.kaggle.com/uciml/pima-indians-diabetes-database\n\n2. Click on the 'Download All' button\n\n3. Kaggle will prompt you to sign in or to register. If you do not have a Kaggle account, you can register for one.\n\n4. Upon signing in, the download will start automatically.\n\n5. After the download is complete, unzip the zip file and move the file 'diabetes.csv' into your project folder.\n\nFor this example we first preprocess the data to ensure we have no missing or zero values.  We then scale or normalise the inputs before passing into the neural network.\n\nWe then split the data into a training and validation set which we use to test the accuracy of the trained neural network.\n\nWe then construct a neural network with 8 inputs, 32 nodes in the first hidden layer, 16 nodes in the second hidden layer, and finally one node in the output layer.\n\nThe neural network will output a 1 if the patient will develop diabetes and a 0 otherwise.\n\nWe then train the neural network using the training set.\n\nFinally we test the trained neural network using the validation set and output and acurracy percetange.\n\n```py\nimport matplotlib\nmatplotlib.use(\"TkAgg\")\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve\nimport numpy as np\nfrom neuralnetwork.FeedForward import FeedForward\nfrom neuralnetwork.Sigmoid import Sigmoid\nfrom neuralnetwork.Backpropagation import Backpropagation\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import preprocessing\nnp.random.seed(16)\n\ndef preprocess(df):\n    print('----------------------------------------------')\n    print(\"Before preprocessing\")\n    print(\"Number of rows with 0 values for each variable\")\n    for col in df.columns:\n        missing_rows = df.loc[df[col]==0].shape[0]\n        print(col + \": \" + str(missing_rows))\n    print('----------------------------------------------')\n\n    # Replace 0 values with the mean of the existing values\n    df['Glucose'] = df['Glucose'].replace(0, np.nan)\n    df['BloodPressure'] = df['BloodPressure'].replace(0, np.nan)\n    df['SkinThickness'] = df['SkinThickness'].replace(0, np.nan)\n    df['Insulin'] = df['Insulin'].replace(0, np.nan)\n    df['BMI'] = df['BMI'].replace(0, np.nan)\n    df['Glucose'] = df['Glucose'].fillna(df['Glucose'].mean())\n    df['BloodPressure'] = df['BloodPressure'].fillna(df['BloodPressure'].mean())\n    df['SkinThickness'] = df['SkinThickness'].fillna(df['SkinThickness'].mean())\n    df['Insulin'] = df['Insulin'].fillna(df['Insulin'].mean())\n    df['BMI'] = df['BMI'].fillna(df['BMI'].mean())\n\n    print('----------------------------------------------')\n    print(\"After preprocessing\")\n    print(\"Number of rows with 0 values for each variable\")\n    for col in df.columns:\n        missing_rows = df.loc[df[col]==0].shape[0]\n        print(col + \": \" + str(missing_rows))\n    print('----------------------------------------------')\n\n    # Standardization\n    df_scaled = preprocessing.scale(df)\n    df_scaled = pd.DataFrame(df_scaled, columns=df.columns)\n    df_scaled['Outcome'] = df['Outcome']\n    df = df_scaled\n    \n\n    return df\n\n\n\ntry:\n    df = pd.read_csv('diabetes.csv')\nexcept:\n    print(\"\"\"\n      Dataset not found in your computer.\n      Please follow the instructions in the link below to download the dataset:\n      hhttps://github.com/stephenlmoshea/neural-network-to-predict-diabetes/blob/master/how_to_download_the_dataset.txt\n      \"\"\")\n    quit()\n\n# Perform preprocessing and feature engineering\ndf = preprocess(df)\n\ntrainingSet = df.loc[:]\n\ntrain, test = train_test_split(trainingSet, test_size=0.2)\n\nsigmoid = Sigmoid()\n\nnetworkLayer = [8,32,16,1]\n\nfeedForward = FeedForward(networkLayer, sigmoid)\n\nbackpropagation = Backpropagation(feedForward,0.7,0.8, 0.05, 2000)\n\nbackpropagation.initialise()\nresult = backpropagation.train(train.values)\n\nfeedForward.save('./network.txt')\n\nfeedForward = FeedForward.load('./network.txt')\n\ntotalCorrect = 0\nfor num,row in enumerate(test.values):\n    feedForward.activate(row[:8])\n    outputs = feedForward.getOutputs()\n    print(\"Expected: {}, Actual: {}\".format(int(row[8]),round(outputs[0])))\n    if(int(row[8]) == int(round(outputs[0]))):\n        totalCorrect = totalCorrect +1\n    \n\npercentageCorrect = totalCorrect/len(test.values) * 100\n\nprint(totalCorrect)\n\nprint(\"Percentage correct: {}%\".format(percentageCorrect))\n\n```", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/stephenlmoshea/python-neuralnetwork/archive/v0.9.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/stephenlmoshea/python-neuralnetwork", "keywords": "NEURAL NETWORK,BACKPROPAGATION,GRADIENT DESCENT,SIGMOID,HYPERBOLIC TANGENT", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "neuralnetwork", "package_url": "https://pypi.org/project/neuralnetwork/", "platform": "", "project_url": "https://pypi.org/project/neuralnetwork/", "project_urls": {"Download": "https://github.com/stephenlmoshea/python-neuralnetwork/archive/v0.9.tar.gz", "Homepage": "https://github.com/stephenlmoshea/python-neuralnetwork"}, "release_url": "https://pypi.org/project/neuralnetwork/0.9/", "requires_dist": null, "requires_python": "", "summary": "Artificial Neural Network", "version": "0.9", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Neural network</h1>\n<p>Artificial neural network for Python. Features online backpropagtion learning using gradient descent, momentum, the sigmoid and hyperbolic tangent activation function.</p>\n<h2>About</h2>\n<p>The library allows you to build and train multi-layer neural networks. You first define the structure for the network. The number of input, output, layers and hidden nodes. The network is then constructed. Interconnection strengths are represented using an adjacency matrix and initialised to small random values.  Traning data is then presented to the network incrementally. The neural network uses an online backpropagation training algorithm that uses gradient descent to descend the error curve to adjust interconnection strengths. The aim of the training algorithm is to adjust the interconnection strengths in order to reduce the global error. The global error for the network is calculated using the mean sqaured error.</p>\n<p>You can provide a learning rate and momentum parameter.  The learning rate will affect the speed at which the neural network converges to an optimal solution. The momentum parameter will help gradient descent to avoid converging to a non optimal solution on the error curve called local minima.  The correct size for the momentum parameter will help to find the global minima but too large a value will prevent the neural network from ever converging to a solution.</p>\n<p>Trained neural networks can be saved to file and loaded back for later activation.</p>\n<h2>Installation</h2>\n<pre>$  pip install neuralnetwork\n</pre>\n<h2>Examples</h2>\n<h3>Training XOR function on three layer neural network with two inputs and one output</h3>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">neuralnetwork.FeedForward</span> <span class=\"kn\">import</span> <span class=\"n\">FeedForward</span>\n<span class=\"kn\">from</span> <span class=\"nn\">neuralnetwork.Sigmoid</span> <span class=\"kn\">import</span> <span class=\"n\">Sigmoid</span>\n<span class=\"kn\">from</span> <span class=\"nn\">neuralnetwork.Backpropagation</span> <span class=\"kn\">import</span> <span class=\"n\">Backpropagation</span>\n\n<span class=\"n\">sigmoid</span> <span class=\"o\">=</span> <span class=\"n\">Sigmoid</span><span class=\"p\">()</span>\n\n<span class=\"n\">networkLayer</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n\n<span class=\"n\">feedForward</span> <span class=\"o\">=</span> <span class=\"n\">FeedForward</span><span class=\"p\">(</span><span class=\"n\">networkLayer</span><span class=\"p\">,</span> <span class=\"n\">sigmoid</span><span class=\"p\">)</span>\n\n<span class=\"n\">backpropagation</span> <span class=\"o\">=</span> <span class=\"n\">Backpropagation</span><span class=\"p\">(</span><span class=\"n\">feedForward</span><span class=\"p\">,</span><span class=\"mf\">0.7</span><span class=\"p\">,</span><span class=\"mf\">0.3</span><span class=\"p\">)</span>\n\n<span class=\"n\">trainingSet</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n    <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">],</span>\n    <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span>\n    <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span>\n    <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n<span class=\"p\">]</span>\n\n<span class=\"k\">while</span> <span class=\"kc\">True</span><span class=\"p\">:</span>\n    <span class=\"n\">backpropagation</span><span class=\"o\">.</span><span class=\"n\">initialise</span><span class=\"p\">()</span>\n    <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">backpropagation</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span><span class=\"n\">trainingSet</span><span class=\"p\">)</span>\n\n    <span class=\"k\">if</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"p\">):</span>\n        <span class=\"k\">break</span>\n\n<span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">activate</span><span class=\"p\">([</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n<span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">getOutputs</span><span class=\"p\">()</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n\n<span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">activate</span><span class=\"p\">([</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">])</span>\n<span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">getOutputs</span><span class=\"p\">()</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n\n<span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">activate</span><span class=\"p\">([</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n<span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">getOutputs</span><span class=\"p\">()</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n\n<span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">activate</span><span class=\"p\">([</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">])</span>\n<span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">getOutputs</span><span class=\"p\">()</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n</pre>\n<h3>Training XOR function on three layer neural network using Hyperbolic Tangent</h3>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">neuralnetwork.FeedForward</span> <span class=\"kn\">import</span> <span class=\"n\">FeedForward</span>\n<span class=\"kn\">from</span> <span class=\"nn\">neuralnetwork.HyperbolicTangent</span> <span class=\"kn\">import</span> <span class=\"n\">HyperbolicTanget</span>\n<span class=\"kn\">from</span> <span class=\"nn\">neuralnetwork.Backpropagation</span> <span class=\"kn\">import</span> <span class=\"n\">Backpropagation</span>\n\n<span class=\"n\">hyperbolicTangent</span> <span class=\"o\">=</span> <span class=\"n\">HyperbolicTangent</span><span class=\"p\">()</span>\n\n<span class=\"n\">networkLayer</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n\n<span class=\"n\">feedForward</span> <span class=\"o\">=</span> <span class=\"n\">FeedForward</span><span class=\"p\">(</span><span class=\"n\">networkLayer</span><span class=\"p\">,</span> <span class=\"n\">hyperbolicTangent</span><span class=\"p\">)</span>\n\n<span class=\"n\">backpropagation</span> <span class=\"o\">=</span> <span class=\"n\">Backpropagation</span><span class=\"p\">(</span><span class=\"n\">feedForward</span><span class=\"p\">,</span><span class=\"mf\">0.7</span><span class=\"p\">,</span><span class=\"mf\">0.3</span><span class=\"p\">,</span><span class=\"mf\">0.001</span><span class=\"p\">)</span>\n\n<span class=\"n\">trainingSet</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n                    <span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">],</span>\n                    <span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span>\n                    <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span>\n                    <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n                <span class=\"p\">];</span>\n\n<span class=\"k\">while</span> <span class=\"kc\">True</span><span class=\"p\">:</span>\n    <span class=\"n\">backpropagation</span><span class=\"o\">.</span><span class=\"n\">initialise</span><span class=\"p\">()</span>\n    <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">backpropagation</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span><span class=\"n\">trainingSet</span><span class=\"p\">)</span>\n\n    <span class=\"k\">if</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"p\">):</span>\n        <span class=\"k\">break</span>\n\n<span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">activate</span><span class=\"p\">([</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">])</span>\n<span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">getOutputs</span><span class=\"p\">()</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n\n<span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">activate</span><span class=\"p\">([</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">])</span>\n<span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">getOutputs</span><span class=\"p\">()</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n\n<span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">activate</span><span class=\"p\">([</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">])</span>\n<span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">getOutputs</span><span class=\"p\">()</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n\n<span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">activate</span><span class=\"p\">([</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">])</span>\n<span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">getOutputs</span><span class=\"p\">()</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n</pre>\n<h3>Saving trained neural network to file</h3>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">neuralnetwork.FeedForward</span> <span class=\"kn\">import</span> <span class=\"n\">FeedForward</span>\n<span class=\"kn\">from</span> <span class=\"nn\">neuralnetwork.Sigmoid</span> <span class=\"kn\">import</span> <span class=\"n\">Sigmoid</span>\n<span class=\"kn\">from</span> <span class=\"nn\">neuralnetwork.Backpropagation</span> <span class=\"kn\">import</span> <span class=\"n\">Backpropagation</span>\n\n<span class=\"n\">sigmoid</span> <span class=\"o\">=</span> <span class=\"n\">Sigmoid</span><span class=\"p\">()</span>\n\n<span class=\"n\">networkLayer</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n\n<span class=\"n\">feedForward</span> <span class=\"o\">=</span> <span class=\"n\">FeedForward</span><span class=\"p\">(</span><span class=\"n\">networkLayer</span><span class=\"p\">,</span> <span class=\"n\">sigmoid</span><span class=\"p\">)</span>\n\n<span class=\"n\">backpropagation</span> <span class=\"o\">=</span> <span class=\"n\">Backpropagation</span><span class=\"p\">(</span><span class=\"n\">feedForward</span><span class=\"p\">,</span><span class=\"mf\">0.7</span><span class=\"p\">,</span><span class=\"mf\">0.3</span><span class=\"p\">)</span>\n\n<span class=\"n\">trainingSet</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n    <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">],</span>\n    <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span>\n    <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span>\n    <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n<span class=\"p\">]</span>\n\n<span class=\"k\">while</span> <span class=\"kc\">True</span><span class=\"p\">:</span>\n    <span class=\"n\">backpropagation</span><span class=\"o\">.</span><span class=\"n\">initialise</span><span class=\"p\">()</span>\n    <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">backpropagation</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span><span class=\"n\">trainingSet</span><span class=\"p\">)</span>\n\n    <span class=\"k\">if</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"p\">):</span>\n        <span class=\"k\">break</span>\n\n<span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"s1\">'./network.txt'</span><span class=\"p\">)</span>\n</pre>\n<h3>Load trained neural network from file</h3>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">neuralnetwork.FeedForward</span> <span class=\"kn\">import</span> <span class=\"n\">FeedForward</span>\n<span class=\"kn\">from</span> <span class=\"nn\">neuralnetwork.Sigmoid</span> <span class=\"kn\">import</span> <span class=\"n\">Sigmoid</span>\n<span class=\"kn\">from</span> <span class=\"nn\">neuralnetwork.Backpropagation</span> <span class=\"kn\">import</span> <span class=\"n\">Backpropagation</span>\n\n<span class=\"n\">feedForward</span> <span class=\"o\">=</span> <span class=\"n\">FeedForward</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s1\">'./network.txt'</span><span class=\"p\">)</span>\n\n<span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">activate</span><span class=\"p\">([</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n<span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">getOutputs</span><span class=\"p\">()</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n\n<span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">activate</span><span class=\"p\">([</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">])</span>\n<span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">getOutputs</span><span class=\"p\">()</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n\n<span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">activate</span><span class=\"p\">([</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n<span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">getOutputs</span><span class=\"p\">()</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n\n<span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">activate</span><span class=\"p\">([</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">])</span>\n<span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">getOutputs</span><span class=\"p\">()</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n</pre>\n<h2>Training Neural Network to Predict Diabetes</h2>\n<p>For this example we will train a neural network to predict whether a patient will develop diabetes within the next five years given various health measurements such as number of times pregnant, glucose plasma, blood pressure diastolic, skin fold thickness, serum insulin, body mass index, diabetes pedigree function, and age.</p>\n<p>The dataset for this project is hosted by Kaggle. To download the necessary dataset for this example, please follow the instructions below.</p>\n<ol>\n<li>\n<p>Go to <a href=\"https://www.kaggle.com/uciml/pima-indians-diabetes-database\" rel=\"nofollow\">https://www.kaggle.com/uciml/pima-indians-diabetes-database</a></p>\n</li>\n<li>\n<p>Click on the 'Download All' button</p>\n</li>\n<li>\n<p>Kaggle will prompt you to sign in or to register. If you do not have a Kaggle account, you can register for one.</p>\n</li>\n<li>\n<p>Upon signing in, the download will start automatically.</p>\n</li>\n<li>\n<p>After the download is complete, unzip the zip file and move the file 'diabetes.csv' into your project folder.</p>\n</li>\n</ol>\n<p>For this example we first preprocess the data to ensure we have no missing or zero values.  We then scale or normalise the inputs before passing into the neural network.</p>\n<p>We then split the data into a training and validation set which we use to test the accuracy of the trained neural network.</p>\n<p>We then construct a neural network with 8 inputs, 32 nodes in the first hidden layer, 16 nodes in the second hidden layer, and finally one node in the output layer.</p>\n<p>The neural network will output a 1 if the patient will develop diabetes and a 0 otherwise.</p>\n<p>We then train the neural network using the training set.</p>\n<p>Finally we test the trained neural network using the validation set and output and acurracy percetange.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">matplotlib</span>\n<span class=\"n\">matplotlib</span><span class=\"o\">.</span><span class=\"n\">use</span><span class=\"p\">(</span><span class=\"s2\">\"TkAgg\"</span><span class=\"p\">)</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n<span class=\"kn\">import</span> <span class=\"nn\">seaborn</span> <span class=\"k\">as</span> <span class=\"nn\">sns</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.metrics</span> <span class=\"kn\">import</span> <span class=\"n\">confusion_matrix</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.metrics</span> <span class=\"kn\">import</span> <span class=\"n\">roc_curve</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">from</span> <span class=\"nn\">neuralnetwork.FeedForward</span> <span class=\"kn\">import</span> <span class=\"n\">FeedForward</span>\n<span class=\"kn\">from</span> <span class=\"nn\">neuralnetwork.Sigmoid</span> <span class=\"kn\">import</span> <span class=\"n\">Sigmoid</span>\n<span class=\"kn\">from</span> <span class=\"nn\">neuralnetwork.Backpropagation</span> <span class=\"kn\">import</span> <span class=\"n\">Backpropagation</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.preprocessing</span> <span class=\"kn\">import</span> <span class=\"n\">StandardScaler</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn</span> <span class=\"kn\">import</span> <span class=\"n\">preprocessing</span>\n<span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">)</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">preprocess</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">):</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'----------------------------------------------'</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"Before preprocessing\"</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"Number of rows with 0 values for each variable\"</span><span class=\"p\">)</span>\n    <span class=\"k\">for</span> <span class=\"n\">col</span> <span class=\"ow\">in</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">columns</span><span class=\"p\">:</span>\n        <span class=\"n\">missing_rows</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">loc</span><span class=\"p\">[</span><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">col</span><span class=\"p\">]</span><span class=\"o\">==</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">col</span> <span class=\"o\">+</span> <span class=\"s2\">\": \"</span> <span class=\"o\">+</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">missing_rows</span><span class=\"p\">))</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'----------------------------------------------'</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># Replace 0 values with the mean of the existing values</span>\n    <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'Glucose'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'Glucose'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">nan</span><span class=\"p\">)</span>\n    <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'BloodPressure'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'BloodPressure'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">nan</span><span class=\"p\">)</span>\n    <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'SkinThickness'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'SkinThickness'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">nan</span><span class=\"p\">)</span>\n    <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'Insulin'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'Insulin'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">nan</span><span class=\"p\">)</span>\n    <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'BMI'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'BMI'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">nan</span><span class=\"p\">)</span>\n    <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'Glucose'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'Glucose'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">fillna</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'Glucose'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">())</span>\n    <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'BloodPressure'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'BloodPressure'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">fillna</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'BloodPressure'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">())</span>\n    <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'SkinThickness'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'SkinThickness'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">fillna</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'SkinThickness'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">())</span>\n    <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'Insulin'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'Insulin'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">fillna</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'Insulin'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">())</span>\n    <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'BMI'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'BMI'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">fillna</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'BMI'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">())</span>\n\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'----------------------------------------------'</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"After preprocessing\"</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"Number of rows with 0 values for each variable\"</span><span class=\"p\">)</span>\n    <span class=\"k\">for</span> <span class=\"n\">col</span> <span class=\"ow\">in</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">columns</span><span class=\"p\">:</span>\n        <span class=\"n\">missing_rows</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">loc</span><span class=\"p\">[</span><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">col</span><span class=\"p\">]</span><span class=\"o\">==</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">col</span> <span class=\"o\">+</span> <span class=\"s2\">\": \"</span> <span class=\"o\">+</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">missing_rows</span><span class=\"p\">))</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'----------------------------------------------'</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># Standardization</span>\n    <span class=\"n\">df_scaled</span> <span class=\"o\">=</span> <span class=\"n\">preprocessing</span><span class=\"o\">.</span><span class=\"n\">scale</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">)</span>\n    <span class=\"n\">df_scaled</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">(</span><span class=\"n\">df_scaled</span><span class=\"p\">,</span> <span class=\"n\">columns</span><span class=\"o\">=</span><span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">columns</span><span class=\"p\">)</span>\n    <span class=\"n\">df_scaled</span><span class=\"p\">[</span><span class=\"s1\">'Outcome'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'Outcome'</span><span class=\"p\">]</span>\n    <span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">df_scaled</span>\n    \n\n    <span class=\"k\">return</span> <span class=\"n\">df</span>\n\n\n\n<span class=\"k\">try</span><span class=\"p\">:</span>\n    <span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s1\">'diabetes.csv'</span><span class=\"p\">)</span>\n<span class=\"k\">except</span><span class=\"p\">:</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"\"\"</span>\n<span class=\"s2\">      Dataset not found in your computer.</span>\n<span class=\"s2\">      Please follow the instructions in the link below to download the dataset:</span>\n<span class=\"s2\">      hhttps://github.com/stephenlmoshea/neural-network-to-predict-diabetes/blob/master/how_to_download_the_dataset.txt</span>\n<span class=\"s2\">      \"\"\"</span><span class=\"p\">)</span>\n    <span class=\"n\">quit</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># Perform preprocessing and feature engineering</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">preprocess</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">)</span>\n\n<span class=\"n\">trainingSet</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">loc</span><span class=\"p\">[:]</span>\n\n<span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span> <span class=\"o\">=</span> <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">trainingSet</span><span class=\"p\">,</span> <span class=\"n\">test_size</span><span class=\"o\">=</span><span class=\"mf\">0.2</span><span class=\"p\">)</span>\n\n<span class=\"n\">sigmoid</span> <span class=\"o\">=</span> <span class=\"n\">Sigmoid</span><span class=\"p\">()</span>\n\n<span class=\"n\">networkLayer</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">8</span><span class=\"p\">,</span><span class=\"mi\">32</span><span class=\"p\">,</span><span class=\"mi\">16</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n\n<span class=\"n\">feedForward</span> <span class=\"o\">=</span> <span class=\"n\">FeedForward</span><span class=\"p\">(</span><span class=\"n\">networkLayer</span><span class=\"p\">,</span> <span class=\"n\">sigmoid</span><span class=\"p\">)</span>\n\n<span class=\"n\">backpropagation</span> <span class=\"o\">=</span> <span class=\"n\">Backpropagation</span><span class=\"p\">(</span><span class=\"n\">feedForward</span><span class=\"p\">,</span><span class=\"mf\">0.7</span><span class=\"p\">,</span><span class=\"mf\">0.8</span><span class=\"p\">,</span> <span class=\"mf\">0.05</span><span class=\"p\">,</span> <span class=\"mi\">2000</span><span class=\"p\">)</span>\n\n<span class=\"n\">backpropagation</span><span class=\"o\">.</span><span class=\"n\">initialise</span><span class=\"p\">()</span>\n<span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">backpropagation</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">values</span><span class=\"p\">)</span>\n\n<span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"s1\">'./network.txt'</span><span class=\"p\">)</span>\n\n<span class=\"n\">feedForward</span> <span class=\"o\">=</span> <span class=\"n\">FeedForward</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s1\">'./network.txt'</span><span class=\"p\">)</span>\n\n<span class=\"n\">totalCorrect</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n<span class=\"k\">for</span> <span class=\"n\">num</span><span class=\"p\">,</span><span class=\"n\">row</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">test</span><span class=\"o\">.</span><span class=\"n\">values</span><span class=\"p\">):</span>\n    <span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">activate</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"p\">[:</span><span class=\"mi\">8</span><span class=\"p\">])</span>\n    <span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">feedForward</span><span class=\"o\">.</span><span class=\"n\">getOutputs</span><span class=\"p\">()</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"Expected: </span><span class=\"si\">{}</span><span class=\"s2\">, Actual: </span><span class=\"si\">{}</span><span class=\"s2\">\"</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"p\">[</span><span class=\"mi\">8</span><span class=\"p\">]),</span><span class=\"nb\">round</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])))</span>\n    <span class=\"k\">if</span><span class=\"p\">(</span><span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"p\">[</span><span class=\"mi\">8</span><span class=\"p\">])</span> <span class=\"o\">==</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"nb\">round</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]))):</span>\n        <span class=\"n\">totalCorrect</span> <span class=\"o\">=</span> <span class=\"n\">totalCorrect</span> <span class=\"o\">+</span><span class=\"mi\">1</span>\n    \n\n<span class=\"n\">percentageCorrect</span> <span class=\"o\">=</span> <span class=\"n\">totalCorrect</span><span class=\"o\">/</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">test</span><span class=\"o\">.</span><span class=\"n\">values</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"mi\">100</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">totalCorrect</span><span class=\"p\">)</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"Percentage correct: </span><span class=\"si\">{}</span><span class=\"s2\">%\"</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">percentageCorrect</span><span class=\"p\">))</span>\n</pre>\n\n          </div>"}, "last_serial": 6105370, "releases": {"0.6": [{"comment_text": "", "digests": {"md5": "651c69cc2e4f1981dcd267ff08b56dc2", "sha256": "5ea62508b0afa3166b7dfd27af489e5bdc853602feafcd1f0477b1cb889ae5e0"}, "downloads": -1, "filename": "neuralnetwork-0.6.tar.gz", "has_sig": false, "md5_digest": "651c69cc2e4f1981dcd267ff08b56dc2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5019, "upload_time": "2019-11-07T08:57:30", "upload_time_iso_8601": "2019-11-07T08:57:30.303345Z", "url": "https://files.pythonhosted.org/packages/54/1b/70cb99fbd6d383987d8dea9ac31df6bcdd33dd3b4238504e82f0f64e92b4/neuralnetwork-0.6.tar.gz", "yanked": false}], "0.7": [{"comment_text": "", "digests": {"md5": "3c19eb2ed4d7eb2410e04b3b7fdabfaf", "sha256": "8d19ee66d4e905321bb55547216a28303f77c83ab9a1ee1d8dc063a400a8a266"}, "downloads": -1, "filename": "neuralnetwork-0.7.tar.gz", "has_sig": false, "md5_digest": "3c19eb2ed4d7eb2410e04b3b7fdabfaf", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5120, "upload_time": "2019-11-08T14:22:04", "upload_time_iso_8601": "2019-11-08T14:22:04.592461Z", "url": "https://files.pythonhosted.org/packages/3a/ec/482fbe9907c59434206bb45a066ed71fb67f1b580fc3cc50ec49f8d0ce53/neuralnetwork-0.7.tar.gz", "yanked": false}], "0.8": [{"comment_text": "", "digests": {"md5": "d723a9393e07b488995c073416c5a62c", "sha256": "033252824a45a829961a49dda89aed562266c129aae2d6ec7aa85360a70446da"}, "downloads": -1, "filename": "neuralnetwork-0.8.tar.gz", "has_sig": false, "md5_digest": "d723a9393e07b488995c073416c5a62c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8263, "upload_time": "2019-11-08T19:08:14", "upload_time_iso_8601": "2019-11-08T19:08:14.671384Z", "url": "https://files.pythonhosted.org/packages/d2/29/1037e489fcacba743c2f6134317be8c835103f3ae60aa7b1984ca00a1e0f/neuralnetwork-0.8.tar.gz", "yanked": false}], "0.9": [{"comment_text": "", "digests": {"md5": "0adf778a141591944060fc816dd9938b", "sha256": "f2e4ead3c8a1f5a4db1cb65b15d7bde095448b3de9be4dbb6ca0e4cb5b02357b"}, "downloads": -1, "filename": "neuralnetwork-0.9.tar.gz", "has_sig": false, "md5_digest": "0adf778a141591944060fc816dd9938b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8254, "upload_time": "2019-11-09T10:55:53", "upload_time_iso_8601": "2019-11-09T10:55:53.267791Z", "url": "https://files.pythonhosted.org/packages/a6/d0/0d3963546f0982ea8943a7f7dfe3139ccc344bc80b088714118972f70866/neuralnetwork-0.9.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "0adf778a141591944060fc816dd9938b", "sha256": "f2e4ead3c8a1f5a4db1cb65b15d7bde095448b3de9be4dbb6ca0e4cb5b02357b"}, "downloads": -1, "filename": "neuralnetwork-0.9.tar.gz", "has_sig": false, "md5_digest": "0adf778a141591944060fc816dd9938b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8254, "upload_time": "2019-11-09T10:55:53", "upload_time_iso_8601": "2019-11-09T10:55:53.267791Z", "url": "https://files.pythonhosted.org/packages/a6/d0/0d3963546f0982ea8943a7f7dfe3139ccc344bc80b088714118972f70866/neuralnetwork-0.9.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:45:48 2020"}