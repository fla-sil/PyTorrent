{"info": {"author": "Anuj Shah", "author_email": "anujonline645@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: GNU General Public License v3 (GPLv3)", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# pytorchvis\nA library to visualize CNN in PyTorch.\n## Installation\n\n```\npip install pytorchvis\ngit clone https://github.com/anujshah1003/pytorchvis\n```\n## Usage\n\nThe demo notebook - [demo.ipynb](https://github.com/anujshah1003/pytorchvis/blob/master/demo.ipynb)\n\n```\n  from pytorchvis.visualize_layers import VisualizeLayers\n\n  # create an object of VisualizeLayers and initialize it with the model and \n  # the layers whose output you want to visualize        \n  vis = VisualizeLayers(model,layers='conv')\n\n  # pass the input and get the output\n  output = model(x)\n\n  # get the intermediate layers output which was passed during initialization\n  interm_output = vis.get_interm_output()\n\n  # plot the featuremap of the layer which you want,\n  vis.plot_featuremaps(interm_output[layer_name],name='fmaps',savefig=True)\n\n```\n##### interm_output is the dictionary which stores the intermediate putput. It's keys are the layer names and its values are the respective output of the intermediate layers.\n\n## Example\n### Using Pretrained Alexnet\n```\n  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n  # load the Pytorch model\n  model = models.alexnet(pretrained=True).to(device)\n  # create an object of VisualizeLayers and initialize it with the model and \n  # the layers whose output you want to visualize\n\n  vis = VisualizeLayers(model,layers='conv')\n  # load the input\n  x = torch.randn([1,3,224,224]).to(device)\n  # pass the input and get the output\n  output = model(x)\n  # get the intermediate layers output which was passed during initialization\n  interm_output = vis.get_interm_output()\n\n  # plot the featuremap of the layer which you want, to see what are the layers\n  # saved simply call vis.get_saved_layer_names\n  vis.get_saved_layer_names() # the key values of the dictionary interm_output\n  vis.plot_featuremaps(interm_output['features.0_conv_Conv2d'],name='fmaps',savefig=True)\n\n```\n#### the 64 featurmap from the first conv layer with a random input\n![](https://github.com/anujshah1003/pytorchvis/blob/master/pytorchvis/output_imgs/noise_inpt_fmap-1.jpg)\n\n## options for plot_featuremaps\nsavefig = True - it will save the feature map as given in name in the folder output_imgs\n\nyou can plot the colored version of the feature map with argument of color_map = 'gray' or 'color'\n```\nvis.plot_featuremaps(interm_output['features.0_conv_Conv2d'],name='fmaps_color',color_map ='color',savefig=True)\n```\n![](https://github.com/anujshah1003/pytorchvis/blob/master/pytorchvis/output_imgs/noise_inpt_color_fmap-1.jpg)\n\n## Naming convention of the saved intermediate layers\n\nlayer name and its sublayers are separated by . (dot) for e.g\n```\n  features.0  - layer 0 is a sub layer of layer features.\n  features.feat1.conv1 - conv1 is the layer name whic is a sub layer of feat1 which further\n  is the sub layer of features.\n```\nthe class and type of layer is given by underscore after the layer name for e.g.\n```\nfeatures._feat1.conv1_conv_Conv2D - this layer name is conv1 and its is from class conv and its type is Conv2d\nfeatures.0_conv_Conv2D - this layer name is 0 and its from class conv and its type is Conv2D\n```\nAnother example, say you have an alex net model and then you print the model to see all the layers\n```\n  model = models.alexnet(pretrained=True)\n  print(model)\n\n  # this are your layers in the Alexnet model\n\n  AlexNet(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (0): Dropout(p=0.5)\n    (1): Linear(in_features=9216, out_features=4096, bias=True)\n    (2): ReLU(inplace)\n    (3): Dropout(p=0.5)\n    (4): Linear(in_features=4096, out_features=4096, bias=True)\n    (5): ReLU(inplace)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)\n\n Now if you call \n vis = VisualizeLayers(model,layers='conv')\n\n The layer names that are registered as below and depending on the layers argument in \n VisualizeLayers(layers='all' or layers='conv' or layers='activation'), the respective intermediate \n layers output will be saved in interm_output = vis.get_interm_output() \n\n features_container_Sequential\n         features.0_conv_Conv2d\n         features.1_activation_ReLU\n         features.2_pooling_MaxPool2d\n         features.3_conv_Conv2d\n         features.4_activation_ReLU\n         features.5_pooling_MaxPool2d\n         features.6_conv_Conv2d\n         features.7_activation_ReLU\n         features.8_conv_Conv2d\n         features.9_activation_ReLU\n         features.10_conv_Conv2d\n         features.11_activation_ReLU\n         features.12_pooling_MaxPool2d\navgpool_pooling_AdaptiveAvgPool2d\nclassifier_container_Sequential\n         classifier.0_dropout_Dropout\n         classifier.1_linear_Linear\n         classifier.2_activation_ReLU\n         classifier.3_dropout_Dropout\n         classifier.4_linear_Linear\n         classifier.5_activation_ReLU\n         classifier.6_linear_Linear\n```\nTo get the saved layer names\n```\nvis = VisualizeLayers(model,layers='conv')\nvis.get_saved_layer_names()\n\n['features.0_conv_Conv2d',\n 'features.3_conv_Conv2d',\n 'features.6_conv_Conv2d',\n 'features.8_conv_Conv2d',\n 'features.10_conv_Conv2d']\n\n```\n\n## Reference:\n\nptrblck hook function from - https://discuss.pytorch.org/t/visualize-feature-map/29597\n\nLibrary Motivation - https://github.com/sksq96/pytorch-summary\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/anujshah1003/pytorchvis", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "pytorchvis", "package_url": "https://pypi.org/project/pytorchvis/", "platform": "", "project_url": "https://pypi.org/project/pytorchvis/", "project_urls": {"Homepage": "https://github.com/anujshah1003/pytorchvis"}, "release_url": "https://pypi.org/project/pytorchvis/0.0.4/", "requires_dist": null, "requires_python": ">=3.6", "summary": "A package to visualize CNN in PyTorch", "version": "0.0.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>pytorchvis</h1>\n<p>A library to visualize CNN in PyTorch.</p>\n<h2>Installation</h2>\n<pre><code>pip install pytorchvis\ngit clone https://github.com/anujshah1003/pytorchvis\n</code></pre>\n<h2>Usage</h2>\n<p>The demo notebook - <a href=\"https://github.com/anujshah1003/pytorchvis/blob/master/demo.ipynb\" rel=\"nofollow\">demo.ipynb</a></p>\n<pre><code>  from pytorchvis.visualize_layers import VisualizeLayers\n\n  # create an object of VisualizeLayers and initialize it with the model and \n  # the layers whose output you want to visualize        \n  vis = VisualizeLayers(model,layers='conv')\n\n  # pass the input and get the output\n  output = model(x)\n\n  # get the intermediate layers output which was passed during initialization\n  interm_output = vis.get_interm_output()\n\n  # plot the featuremap of the layer which you want,\n  vis.plot_featuremaps(interm_output[layer_name],name='fmaps',savefig=True)\n\n</code></pre>\n<h5>interm_output is the dictionary which stores the intermediate putput. It's keys are the layer names and its values are the respective output of the intermediate layers.</h5>\n<h2>Example</h2>\n<h3>Using Pretrained Alexnet</h3>\n<pre><code>  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n  # load the Pytorch model\n  model = models.alexnet(pretrained=True).to(device)\n  # create an object of VisualizeLayers and initialize it with the model and \n  # the layers whose output you want to visualize\n\n  vis = VisualizeLayers(model,layers='conv')\n  # load the input\n  x = torch.randn([1,3,224,224]).to(device)\n  # pass the input and get the output\n  output = model(x)\n  # get the intermediate layers output which was passed during initialization\n  interm_output = vis.get_interm_output()\n\n  # plot the featuremap of the layer which you want, to see what are the layers\n  # saved simply call vis.get_saved_layer_names\n  vis.get_saved_layer_names() # the key values of the dictionary interm_output\n  vis.plot_featuremaps(interm_output['features.0_conv_Conv2d'],name='fmaps',savefig=True)\n\n</code></pre>\n<h4>the 64 featurmap from the first conv layer with a random input</h4>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/338168816f91eb2259dbb2300b7bc738c5785628/68747470733a2f2f6769746875622e636f6d2f616e756a73686168313030332f7079746f7263687669732f626c6f622f6d61737465722f7079746f7263687669732f6f75747075745f696d67732f6e6f6973655f696e70745f666d61702d312e6a7067\"></p>\n<h2>options for plot_featuremaps</h2>\n<p>savefig = True - it will save the feature map as given in name in the folder output_imgs</p>\n<p>you can plot the colored version of the feature map with argument of color_map = 'gray' or 'color'</p>\n<pre><code>vis.plot_featuremaps(interm_output['features.0_conv_Conv2d'],name='fmaps_color',color_map ='color',savefig=True)\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/737b1ec7147fbf138a5f5a2d386d078fa6a15eb3/68747470733a2f2f6769746875622e636f6d2f616e756a73686168313030332f7079746f7263687669732f626c6f622f6d61737465722f7079746f7263687669732f6f75747075745f696d67732f6e6f6973655f696e70745f636f6c6f725f666d61702d312e6a7067\"></p>\n<h2>Naming convention of the saved intermediate layers</h2>\n<p>layer name and its sublayers are separated by . (dot) for e.g</p>\n<pre><code>  features.0  - layer 0 is a sub layer of layer features.\n  features.feat1.conv1 - conv1 is the layer name whic is a sub layer of feat1 which further\n  is the sub layer of features.\n</code></pre>\n<p>the class and type of layer is given by underscore after the layer name for e.g.</p>\n<pre><code>features._feat1.conv1_conv_Conv2D - this layer name is conv1 and its is from class conv and its type is Conv2d\nfeatures.0_conv_Conv2D - this layer name is 0 and its from class conv and its type is Conv2D\n</code></pre>\n<p>Another example, say you have an alex net model and then you print the model to see all the layers</p>\n<pre><code>  model = models.alexnet(pretrained=True)\n  print(model)\n\n  # this are your layers in the Alexnet model\n\n  AlexNet(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (0): Dropout(p=0.5)\n    (1): Linear(in_features=9216, out_features=4096, bias=True)\n    (2): ReLU(inplace)\n    (3): Dropout(p=0.5)\n    (4): Linear(in_features=4096, out_features=4096, bias=True)\n    (5): ReLU(inplace)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)\n\n Now if you call \n vis = VisualizeLayers(model,layers='conv')\n\n The layer names that are registered as below and depending on the layers argument in \n VisualizeLayers(layers='all' or layers='conv' or layers='activation'), the respective intermediate \n layers output will be saved in interm_output = vis.get_interm_output() \n\n features_container_Sequential\n         features.0_conv_Conv2d\n         features.1_activation_ReLU\n         features.2_pooling_MaxPool2d\n         features.3_conv_Conv2d\n         features.4_activation_ReLU\n         features.5_pooling_MaxPool2d\n         features.6_conv_Conv2d\n         features.7_activation_ReLU\n         features.8_conv_Conv2d\n         features.9_activation_ReLU\n         features.10_conv_Conv2d\n         features.11_activation_ReLU\n         features.12_pooling_MaxPool2d\navgpool_pooling_AdaptiveAvgPool2d\nclassifier_container_Sequential\n         classifier.0_dropout_Dropout\n         classifier.1_linear_Linear\n         classifier.2_activation_ReLU\n         classifier.3_dropout_Dropout\n         classifier.4_linear_Linear\n         classifier.5_activation_ReLU\n         classifier.6_linear_Linear\n</code></pre>\n<p>To get the saved layer names</p>\n<pre><code>vis = VisualizeLayers(model,layers='conv')\nvis.get_saved_layer_names()\n\n['features.0_conv_Conv2d',\n 'features.3_conv_Conv2d',\n 'features.6_conv_Conv2d',\n 'features.8_conv_Conv2d',\n 'features.10_conv_Conv2d']\n\n</code></pre>\n<h2>Reference:</h2>\n<p>ptrblck hook function from - <a href=\"https://discuss.pytorch.org/t/visualize-feature-map/29597\" rel=\"nofollow\">https://discuss.pytorch.org/t/visualize-feature-map/29597</a></p>\n<p>Library Motivation - <a href=\"https://github.com/sksq96/pytorch-summary\" rel=\"nofollow\">https://github.com/sksq96/pytorch-summary</a></p>\n\n          </div>"}, "last_serial": 6144561, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "898ffda0d946701e73066eca28ef4684", "sha256": "9bf11643626145a0efceb6a8064af8ba94f6d6b5e41ef2c9b031c1fe9ae976f4"}, "downloads": -1, "filename": "pytorchvis-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "898ffda0d946701e73066eca28ef4684", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 13909, "upload_time": "2019-11-09T07:03:07", "upload_time_iso_8601": "2019-11-09T07:03:07.459870Z", "url": "https://files.pythonhosted.org/packages/dc/6d/5d807acf513e86825fedebe2e97fb362fe1ddf87065ecdc610d61d9be7e1/pytorchvis-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0985e584f183fa42b1d92a9f7ccc649a", "sha256": "81b2077f82e989ba1d81898a55eb9718e2cc15e1355749c8474cfef1648ab170"}, "downloads": -1, "filename": "pytorchvis-0.0.1.tar.gz", "has_sig": false, "md5_digest": "0985e584f183fa42b1d92a9f7ccc649a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 1078, "upload_time": "2019-11-09T07:03:08", "upload_time_iso_8601": "2019-11-09T07:03:08.999457Z", "url": "https://files.pythonhosted.org/packages/6a/90/71e1c595d38477eff4937b065464dfab226be02fa261b0cb6f9010e9beba/pytorchvis-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "2c093018ef2c6a1fd792515f653f4584", "sha256": "9a68cee5afa93197c09461c5654dcd01dec131129173ac617a6226872b5652de"}, "downloads": -1, "filename": "pytorchvis-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "2c093018ef2c6a1fd792515f653f4584", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 16242, "upload_time": "2019-11-09T11:53:17", "upload_time_iso_8601": "2019-11-09T11:53:17.188620Z", "url": "https://files.pythonhosted.org/packages/c6/f8/d59e1effc9b94748453e6d1594167b8f8f41d37cad0f521c23f88cfc41be/pytorchvis-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5bd78d8b4ec777d9652fd96c48c10332", "sha256": "483df5a9e78f1253b6d8bbbf4473e36f9df371b0b7bc5214f41e9b7c3e75fd4f"}, "downloads": -1, "filename": "pytorchvis-0.0.2.tar.gz", "has_sig": false, "md5_digest": "5bd78d8b4ec777d9652fd96c48c10332", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 3082, "upload_time": "2019-11-09T11:53:19", "upload_time_iso_8601": "2019-11-09T11:53:19.988467Z", "url": "https://files.pythonhosted.org/packages/1f/43/0636f2ac0cf372f92709883073f987904b35a18921e9e610c241771dbd7d/pytorchvis-0.0.2.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "f78bbad6c259354916d44ed7f26b1a29", "sha256": "6106e7136176735add52212073228c172ec6f2d1b662d0876f2d6a2044cb217b"}, "downloads": -1, "filename": "pytorchvis-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "f78bbad6c259354916d44ed7f26b1a29", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 17441, "upload_time": "2019-11-15T19:08:03", "upload_time_iso_8601": "2019-11-15T19:08:03.217906Z", "url": "https://files.pythonhosted.org/packages/9f/ce/bd41fdd56288465d7081bce6c9b458adb0a5696a032c9633f4241684fafd/pytorchvis-0.0.4-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "f78bbad6c259354916d44ed7f26b1a29", "sha256": "6106e7136176735add52212073228c172ec6f2d1b662d0876f2d6a2044cb217b"}, "downloads": -1, "filename": "pytorchvis-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "f78bbad6c259354916d44ed7f26b1a29", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 17441, "upload_time": "2019-11-15T19:08:03", "upload_time_iso_8601": "2019-11-15T19:08:03.217906Z", "url": "https://files.pythonhosted.org/packages/9f/ce/bd41fdd56288465d7081bce6c9b458adb0a5696a032c9633f4241684fafd/pytorchvis-0.0.4-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 03:13:30 2020"}