{"info": {"author": "Jason Antman", "author_email": "jason@jasonantman.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Environment :: Console", "Intended Audience :: Developers", "License :: OSI Approved :: GNU Affero General Public License v3 or later (AGPLv3+)", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Topic :: Internet :: Log Analysis", "Topic :: Software Development", "Topic :: Utilities"], "description": "pypi-download-stats\n========================\n\n.. image:: https://img.shields.io/github/forks/jantman/pypi-download-stats.svg\n   :alt: GitHub Forks\n   :target: https://github.com/jantman/pypi-download-stats/network\n\n.. image:: https://img.shields.io/github/issues/jantman/pypi-download-stats.svg\n   :alt: GitHub Open Issues\n   :target: https://github.com/jantman/pypi-download-stats/issues\n\n.. image:: https://landscape.io/github/jantman/pypi-download-stats/master/landscape.svg\n   :target: https://landscape.io/github/jantman/pypi-download-stats/master\n   :alt: Code Health\n\n.. image:: https://secure.travis-ci.org/jantman/pypi-download-stats.png?branch=master\n   :target: http://travis-ci.org/jantman/pypi-download-stats\n   :alt: travis-ci for master branch\n\n.. image:: https://codecov.io/github/jantman/pypi-download-stats/coverage.svg?branch=master\n   :target: https://codecov.io/github/jantman/pypi-download-stats?branch=master\n   :alt: coverage report for master branch\n\n.. image:: https://readthedocs.org/projects/pypi-download-stats/badge/?version=latest\n   :target: https://readthedocs.org/projects/pypi-download-stats/?badge=latest\n   :alt: sphinx documentation for latest release\n\n.. image:: http://www.repostatus.org/badges/latest/active.svg\n   :alt: Project Status: Active - The project has reached a stable, usable state and is being actively developed.\n   :target: http://www.repostatus.org/#active\n\nIntroduction\n------------\n\nThis package retrieves download statistics from Google BigQuery for one or more\n`PyPI <https://pypi.python.org/pypi>`_ packages, caches them locally, and then\ngenerates download count badges as well as an HTML page of raw data and graphs\n(generated by `bokeh <http://bokeh.pydata.org/en/latest/>`_ ). It's intended to\nbe run on a schedule (i.e. daily) and have the results uploaded somewhere.\n\nIt would certainly be nice to make this into a real service (and some extension\npoints for that have been included), but at the moment\nI have neither the time to dedicate to that, the money to cover some sort\nof hosting and bandwidth, nor the desire to handle how to architect this for\nover 85,000 projects as opposed to my few.\n\nHopefully stats like these will eventually end up in the official PyPI; see\nwarehouse `#699 <https://github.com/pypa/warehouse/issues/699>`_,\n`#188 <https://github.com/pypa/warehouse/issues/188>`_ and\n`#787 <https://github.com/pypa/warehouse/issues/787>`_ for reference on that work.\nFor the time being, I want to (a) give myself a way to get simple download stats\nand badges like the old PyPI legacy (downloads per day, week and month) as well\nas (b) enable some higher-granularity analysis.\n\n**Note** this package is *very* young; I wrote it as an evening/weekend project,\nhoping to only take a few days on it. Though writing this makes me want to bathe\nimmediately, it has no tests. If people start using it, I'll change that.\n\nFor a live example of exactly how the output looks, you can see the download\nstats page for my awslimitchecker project, generated by a cronjob on my desktop,\nat: `http://jantman-personal-public.s3-website-us-east-1.amazonaws.com/pypi-stats/awslimitchecker/index.html <http://jantman-personal-public.s3-website-us-east-1.amazonaws.com/pypi-stats/awslimitchecker/index.html>`_.\n\nBackground\n----------\n\nSometime in February 2016, `download stats <https://bitbucket.org/pypa/pypi/issues/396/download-stats-have-stopped-working-again>`_\nstopped working on pypi.python.org. As I later learned, what we currently (August 2016)\nknow as pypi is really the `pypi-legacy <https://github.com/pypa/pypi-legacy>`_ codebase,\nand is far from a stable hands-off service. The `small team of interpid souls <https://caremad.io/2016/05/powering-pypi/>`_\nwho keep it running have their hands full simply keeping it online, while also working\non its replacement, `warehouse <https://github.com/pypa/warehouse>`_ (which as of August 2016 is available online\nat `https://pypi.io/ <https://pypi.io/>`_). While the actual pypi.python.org web UI hasn't been\nswitched over to the warehouse code yet (it's still under development), the current Warehouse\nservice does provide full access to pypi. It's completely understandable that, given all this\nand the \"life support\" status of the legacy pypi codebase, download stats in a legacy codebase\nare their last concern.\n\nHowever, current download statistics (actually the raw log information) since January 22, 2016\nare `available in a Google BigQuery public dataset <https://mail.python.org/pipermail/distutils-sig/2016-May/028986.html>`_\nand being updated in near-real-time. There may be download statistics functionality\n\nRequirements\n------------\n\n* Python 2.7+ (currently tested with 2.7, 3.2, 3.3, 3.4)\n* Python `VirtualEnv <http://www.virtualenv.org/>`_ and ``pip`` (recommended installation method; your OS/distribution should have packages for these)\n\npypi-download-stats relies on `bokeh <http://bokeh.pydata.org/en/latest/>`_ to generate\npretty SVG charts that work offline, and\n`google-api-python-client <https://github.com/google/google-api-python-client/>`_\nfor querying BigQuery. Each of those have additional dependencies.\n\nInstallation\n------------\n\nIt's recommended that you install into a virtual environment (virtualenv /\nvenv). See the `virtualenv usage documentation <http://www.virtualenv.org/en/latest/>`_\nfor information on how to create a venv.\n\nThis isn't on pypi yet, ironically. Until it is:\n\n.. code-block:: bash\n\n    $ pip install git+https://github.com/jantman/pypi-download-stats.git\n\nConfiguration\n-------------\n\nYou'll need Google Cloud credentials for a project that has the BigQuery API\nenabled. The recommended method is to generate system account credentials;\ndownload the JSON file for the credentials and export the path to it as the\n``GOOGLE_APPLICATION_CREDENTIALS`` environment variable. The system account\nwill need to be added as a Project Member.\n\nUsage\n-----\n\nRun with ``-h`` for command-line help::\n\n    usage: pypi-download-stats [-h] [-V] [-v] [-Q | -G] [-o OUT_DIR]\n                               [-p PROJECT_ID] [-c CACHE_DIR] [-B BACKFILL_DAYS]\n                               [-P PROJECT | -U USER]\n\n    pypi-download-stats - Calculate detailed download stats and generate HTML and\n    badges for PyPI packages - <https://github.com/jantman/pypi-download-stats>\n\n    optional arguments:\n      -h, --help            show this help message and exit\n      -V, --version         show program's version number and exit\n      -v, --verbose         verbose output. specify twice for debug-level output.\n      -Q, --no-query        do not query; just generate output from cached data\n      -G, --no-generate     do not generate output; just query data and cache\n                            results\n      -o OUT_DIR, --out-dir OUT_DIR\n                            output directory (default: ./pypi-stats\n      -p PROJECT_ID, --project-id PROJECT_ID\n                            ProjectID for your Google Cloud user, if not using\n                            service account credentials JSON file\n      -c CACHE_DIR, --cache-dir CACHE_DIR\n                            stats cache directory (default: ./pypi-stats-cache)\n      -B BACKFILL_DAYS, --backfill-num-days BACKFILL_DAYS\n                            number of days of historical data to backfill, if\n                            missing (defaut: 7). Note this may incur BigQuery\n                            charges. Set to -1 to backfill all available history.\n      -P PROJECT, --project PROJECT\n                            project name to query/generate stats for (can be\n                            specified more than once; this will reduce query cost\n                            for multiple projects)\n      -U USER, --user USER  Run for all PyPI projects owned by the specifieduser.\n\nTo run queries and generate reports for PyPI projects \"foo\" and \"bar\", using a\nGoogle Cloud credentials JSON file at ``foo.json``:\n\n.. code-block:: bash\n\n    $ export GOOGLE_APPLICATION_CREDENTIALS=/foo.json\n    $ pypi-download-stats -P foo -P bar\n\nTo run queries but *not* generate reports for all PyPI projects owned by user\n\"myname\":\n\n.. code-block:: bash\n\n    $ export GOOGLE_APPLICATION_CREDENTIALS=/foo.json\n    $ pypi-download-stats -G -U myname\n\nTo generate reports against cached query data for the project \"foo\":\n\n.. code-block:: bash\n\n    $ export GOOGLE_APPLICATION_CREDENTIALS=/foo.json\n    $ pypi-download-stats -Q -P foo\n\nTo run nightly and upload results to a website-hosting S3 bucket, I use the\nfollowing script via cron (note the paths are specific to my purpose; also note\nthe two commands, as ``s3cmd`` does not seem to set the MIME type for the SVG\nimages correctly):\n\n.. code-block:: bash\n\n    #!/bin/bash -x\n\n    export GOOGLE_APPLICATION_CREDENTIALS=/home/jantman/.ssh/pypi-bigquery.json\n    cd /home/jantman/GIT/pypi-download-stats\n    bin/pypi-download-stats -vv -U jantman\n\n    # sync html files\n    ~/venvs/foo/bin/s3cmd -r --delete-removed --stats --exclude='*.svg' sync pypi-stats s3://jantman-personal-public/\n    # sync SVG and set mime-type, since s3cmd gets it wrong\n    ~/venvs/foo/bin/s3cmd -r --delete-removed --stats --exclude='*.html' --mime-type='image/svg+xml' sync pypi-stats s3://jantman-personal-public/\n\nCost\n++++\n\nAt this point... I have no idea. Some of the download tables are 3+ GB per day.\nI imagine that backfilling historical data from the beginning of what's currently\nthere (20160122) might incur quite a bit of data cost.\n\nBugs and Feature Requests\n-------------------------\n\nBug reports and feature requests are happily accepted via the `GitHub Issue Tracker <https://github.com/jantman/pypi-download-stats/issues>`_. Pull requests are\nwelcome. Issues that don't have an accompanying pull request will be worked on\nas my time and priority allows.\n\nDevelopment\n===========\n\nTo install for development:\n\n1. Fork the `pypi-download-stats <https://github.com/jantman/pypi-download-stats>`_ repository on GitHub\n2. Create a new branch off of master in your fork.\n\n.. code-block:: bash\n\n    $ virtualenv pypi-download-stats\n    $ cd pypi-download-stats && source bin/activate\n    $ pip install -e git+git@github.com:YOURNAME/pypi-download-stats.git@BRANCHNAME#egg=pypi-download-stats\n    $ cd src/pypi-download-stats\n\nThe git clone you're now in will probably be checked out to a specific commit,\nso you may want to ``git checkout BRANCHNAME``.\n\nGuidelines\n----------\n\n* pep8 compliant with some exceptions (see pytest.ini)\n\nTesting\n-------\n\nThere isn't any right now. I'm bad. If people actually start using this, I'll\nrefactor and add tests, but for now this started as a one-night project.\n\nRelease Checklist\n-----------------\n\n1. Open an issue for the release; cut a branch off master for that issue.\n2. Confirm that there are CHANGES.rst entries for all major changes.\n3. Ensure that Travis tests passing in all environments.\n4. Ensure that test coverage is no less than the last release (ideally, 100%).\n5. Increment the version number in pypi-download-stats/version.py and add version and release date to CHANGES.rst, then push to GitHub.\n6. Confirm that README.rst renders correctly on GitHub.\n7. Upload package to testpypi:\n\n   * Make sure your ~/.pypirc file is correct (a repo called ``test`` for https://testpypi.python.org/pypi)\n   * ``rm -Rf dist``\n   * ``python setup.py register -r https://testpypi.python.org/pypi``\n   * ``python setup.py sdist bdist_wheel``\n   * ``twine upload -r test dist/*``\n   * Check that the README renders at https://testpypi.python.org/pypi/pypi-download-stats\n\n8. Create a pull request for the release to be merged into master. Upon successful Travis build, merge it.\n9. Tag the release in Git, push tag to GitHub:\n\n   * tag the release. for now the message is quite simple: ``git tag -a X.Y.Z -m 'X.Y.Z released YYYY-MM-DD'``\n   * push the tag to GitHub: ``git push origin X.Y.Z``\n\n11. Upload package to live pypi:\n\n    * ``twine upload dist/*``\n\n10. make sure any GH issues fixed in the release were closed.\n\n\n", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/jantman/pypi-download-stats", "keywords": "pypi warehouse download stats badge", "license": "", "maintainer": "", "maintainer_email": "", "name": "pypi-download-stats", "package_url": "https://pypi.org/project/pypi-download-stats/", "platform": "", "project_url": "https://pypi.org/project/pypi-download-stats/", "project_urls": {"Homepage": "https://github.com/jantman/pypi-download-stats"}, "release_url": "https://pypi.org/project/pypi-download-stats/0.2.1/", "requires_dist": ["iso3166", "bokeh (==0.12.1)", "google-api-python-client (>=1.5.0)", "oauth2client (>=3.0.0)", "pandas (<1.0,>=0.18)", "pytz", "requests (<3.0,>2.0)", "tzlocal"], "requires_python": "", "summary": "Calculate detailed download stats and generate HTML and badges for PyPI packages", "version": "0.2.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"pypi-download-stats\">\n<h2>pypi-download-stats</h2>\n<a href=\"https://github.com/jantman/pypi-download-stats/network\" rel=\"nofollow\"><img alt=\"GitHub Forks\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/95b99e93e39de6c0e1cf8bbe136b30a761eb97ac/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f666f726b732f6a616e746d616e2f707970692d646f776e6c6f61642d73746174732e737667\"></a>\n<a href=\"https://github.com/jantman/pypi-download-stats/issues\" rel=\"nofollow\"><img alt=\"GitHub Open Issues\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/7a34a4152a6fa434b5db9d914f3833ec3269c36f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f6a616e746d616e2f707970692d646f776e6c6f61642d73746174732e737667\"></a>\n<a href=\"https://landscape.io/github/jantman/pypi-download-stats/master\" rel=\"nofollow\"><img alt=\"Code Health\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/240c5eb4e22d15cb70d202bf57caa777afdf7429/68747470733a2f2f6c616e6473636170652e696f2f6769746875622f6a616e746d616e2f707970692d646f776e6c6f61642d73746174732f6d61737465722f6c616e6473636170652e737667\"></a>\n<a href=\"http://travis-ci.org/jantman/pypi-download-stats\" rel=\"nofollow\"><img alt=\"travis-ci for master branch\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e1367a8f7fbb35660d548e7954d5f6c15b4d72a9/68747470733a2f2f7365637572652e7472617669732d63692e6f72672f6a616e746d616e2f707970692d646f776e6c6f61642d73746174732e706e673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://codecov.io/github/jantman/pypi-download-stats?branch=master\" rel=\"nofollow\"><img alt=\"coverage report for master branch\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c8cfc755a7845b6d51b459540551244b988094e1/68747470733a2f2f636f6465636f762e696f2f6769746875622f6a616e746d616e2f707970692d646f776e6c6f61642d73746174732f636f7665726167652e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://readthedocs.org/projects/pypi-download-stats/?badge=latest\" rel=\"nofollow\"><img alt=\"sphinx documentation for latest release\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/87142898f0dd6def6d532b30e6cb070547fe2f99/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f707970692d646f776e6c6f61642d73746174732f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<a href=\"http://www.repostatus.org/#active\" rel=\"nofollow\"><img alt=\"Project Status: Active - The project has reached a stable, usable state and is being actively developed.\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/51adb09f202aea47725eca73a3fcf5e1ab47f2e9/687474703a2f2f7777772e7265706f7374617475732e6f72672f6261646765732f6c61746573742f6163746976652e737667\"></a>\n<div id=\"introduction\">\n<h3>Introduction</h3>\n<p>This package retrieves download statistics from Google BigQuery for one or more\n<a href=\"https://pypi.python.org/pypi\" rel=\"nofollow\">PyPI</a> packages, caches them locally, and then\ngenerates download count badges as well as an HTML page of raw data and graphs\n(generated by <a href=\"http://bokeh.pydata.org/en/latest/\" rel=\"nofollow\">bokeh</a> ). It\u2019s intended to\nbe run on a schedule (i.e. daily) and have the results uploaded somewhere.</p>\n<p>It would certainly be nice to make this into a real service (and some extension\npoints for that have been included), but at the moment\nI have neither the time to dedicate to that, the money to cover some sort\nof hosting and bandwidth, nor the desire to handle how to architect this for\nover 85,000 projects as opposed to my few.</p>\n<p>Hopefully stats like these will eventually end up in the official PyPI; see\nwarehouse <a href=\"https://github.com/pypa/warehouse/issues/699\" rel=\"nofollow\">#699</a>,\n<a href=\"https://github.com/pypa/warehouse/issues/188\" rel=\"nofollow\">#188</a> and\n<a href=\"https://github.com/pypa/warehouse/issues/787\" rel=\"nofollow\">#787</a> for reference on that work.\nFor the time being, I want to (a) give myself a way to get simple download stats\nand badges like the old PyPI legacy (downloads per day, week and month) as well\nas (b) enable some higher-granularity analysis.</p>\n<p><strong>Note</strong> this package is <em>very</em> young; I wrote it as an evening/weekend project,\nhoping to only take a few days on it. Though writing this makes me want to bathe\nimmediately, it has no tests. If people start using it, I\u2019ll change that.</p>\n<p>For a live example of exactly how the output looks, you can see the download\nstats page for my awslimitchecker project, generated by a cronjob on my desktop,\nat: <a href=\"http://jantman-personal-public.s3-website-us-east-1.amazonaws.com/pypi-stats/awslimitchecker/index.html\" rel=\"nofollow\">http://jantman-personal-public.s3-website-us-east-1.amazonaws.com/pypi-stats/awslimitchecker/index.html</a>.</p>\n</div>\n<div id=\"background\">\n<h3>Background</h3>\n<p>Sometime in February 2016, <a href=\"https://bitbucket.org/pypa/pypi/issues/396/download-stats-have-stopped-working-again\" rel=\"nofollow\">download stats</a>\nstopped working on pypi.python.org. As I later learned, what we currently (August 2016)\nknow as pypi is really the <a href=\"https://github.com/pypa/pypi-legacy\" rel=\"nofollow\">pypi-legacy</a> codebase,\nand is far from a stable hands-off service. The <a href=\"https://caremad.io/2016/05/powering-pypi/\" rel=\"nofollow\">small team of interpid souls</a>\nwho keep it running have their hands full simply keeping it online, while also working\non its replacement, <a href=\"https://github.com/pypa/warehouse\" rel=\"nofollow\">warehouse</a> (which as of August 2016 is available online\nat <a href=\"https://pypi.io/\" rel=\"nofollow\">https://pypi.io/</a>). While the actual pypi.python.org web UI hasn\u2019t been\nswitched over to the warehouse code yet (it\u2019s still under development), the current Warehouse\nservice does provide full access to pypi. It\u2019s completely understandable that, given all this\nand the \u201clife support\u201d status of the legacy pypi codebase, download stats in a legacy codebase\nare their last concern.</p>\n<p>However, current download statistics (actually the raw log information) since January 22, 2016\nare <a href=\"https://mail.python.org/pipermail/distutils-sig/2016-May/028986.html\" rel=\"nofollow\">available in a Google BigQuery public dataset</a>\nand being updated in near-real-time. There may be download statistics functionality</p>\n</div>\n<div id=\"requirements\">\n<h3>Requirements</h3>\n<ul>\n<li>Python 2.7+ (currently tested with 2.7, 3.2, 3.3, 3.4)</li>\n<li>Python <a href=\"http://www.virtualenv.org/\" rel=\"nofollow\">VirtualEnv</a> and <tt>pip</tt> (recommended installation method; your OS/distribution should have packages for these)</li>\n</ul>\n<p>pypi-download-stats relies on <a href=\"http://bokeh.pydata.org/en/latest/\" rel=\"nofollow\">bokeh</a> to generate\npretty SVG charts that work offline, and\n<a href=\"https://github.com/google/google-api-python-client/\" rel=\"nofollow\">google-api-python-client</a>\nfor querying BigQuery. Each of those have additional dependencies.</p>\n</div>\n<div id=\"installation\">\n<h3>Installation</h3>\n<p>It\u2019s recommended that you install into a virtual environment (virtualenv /\nvenv). See the <a href=\"http://www.virtualenv.org/en/latest/\" rel=\"nofollow\">virtualenv usage documentation</a>\nfor information on how to create a venv.</p>\n<p>This isn\u2019t on pypi yet, ironically. Until it is:</p>\n<pre>$ pip install git+https://github.com/jantman/pypi-download-stats.git\n</pre>\n</div>\n<div id=\"configuration\">\n<h3>Configuration</h3>\n<p>You\u2019ll need Google Cloud credentials for a project that has the BigQuery API\nenabled. The recommended method is to generate system account credentials;\ndownload the JSON file for the credentials and export the path to it as the\n<tt>GOOGLE_APPLICATION_CREDENTIALS</tt> environment variable. The system account\nwill need to be added as a Project Member.</p>\n</div>\n<div id=\"usage\">\n<h3>Usage</h3>\n<p>Run with <tt><span class=\"pre\">-h</span></tt> for command-line help:</p>\n<pre>usage: pypi-download-stats [-h] [-V] [-v] [-Q | -G] [-o OUT_DIR]\n                           [-p PROJECT_ID] [-c CACHE_DIR] [-B BACKFILL_DAYS]\n                           [-P PROJECT | -U USER]\n\npypi-download-stats - Calculate detailed download stats and generate HTML and\nbadges for PyPI packages - &lt;https://github.com/jantman/pypi-download-stats&gt;\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -V, --version         show program's version number and exit\n  -v, --verbose         verbose output. specify twice for debug-level output.\n  -Q, --no-query        do not query; just generate output from cached data\n  -G, --no-generate     do not generate output; just query data and cache\n                        results\n  -o OUT_DIR, --out-dir OUT_DIR\n                        output directory (default: ./pypi-stats\n  -p PROJECT_ID, --project-id PROJECT_ID\n                        ProjectID for your Google Cloud user, if not using\n                        service account credentials JSON file\n  -c CACHE_DIR, --cache-dir CACHE_DIR\n                        stats cache directory (default: ./pypi-stats-cache)\n  -B BACKFILL_DAYS, --backfill-num-days BACKFILL_DAYS\n                        number of days of historical data to backfill, if\n                        missing (defaut: 7). Note this may incur BigQuery\n                        charges. Set to -1 to backfill all available history.\n  -P PROJECT, --project PROJECT\n                        project name to query/generate stats for (can be\n                        specified more than once; this will reduce query cost\n                        for multiple projects)\n  -U USER, --user USER  Run for all PyPI projects owned by the specifieduser.\n</pre>\n<p>To run queries and generate reports for PyPI projects \u201cfoo\u201d and \u201cbar\u201d, using a\nGoogle Cloud credentials JSON file at <tt>foo.json</tt>:</p>\n<pre>$ <span class=\"nb\">export</span> <span class=\"nv\">GOOGLE_APPLICATION_CREDENTIALS</span><span class=\"o\">=</span>/foo.json\n$ pypi-download-stats -P foo -P bar\n</pre>\n<p>To run queries but <em>not</em> generate reports for all PyPI projects owned by user\n\u201cmyname\u201d:</p>\n<pre>$ <span class=\"nb\">export</span> <span class=\"nv\">GOOGLE_APPLICATION_CREDENTIALS</span><span class=\"o\">=</span>/foo.json\n$ pypi-download-stats -G -U myname\n</pre>\n<p>To generate reports against cached query data for the project \u201cfoo\u201d:</p>\n<pre>$ <span class=\"nb\">export</span> <span class=\"nv\">GOOGLE_APPLICATION_CREDENTIALS</span><span class=\"o\">=</span>/foo.json\n$ pypi-download-stats -Q -P foo\n</pre>\n<p>To run nightly and upload results to a website-hosting S3 bucket, I use the\nfollowing script via cron (note the paths are specific to my purpose; also note\nthe two commands, as <tt>s3cmd</tt> does not seem to set the MIME type for the SVG\nimages correctly):</p>\n<pre><span class=\"ch\">#!/bin/bash -x\n</span>\n<span class=\"nb\">export</span> <span class=\"nv\">GOOGLE_APPLICATION_CREDENTIALS</span><span class=\"o\">=</span>/home/jantman/.ssh/pypi-bigquery.json\n<span class=\"nb\">cd</span> /home/jantman/GIT/pypi-download-stats\nbin/pypi-download-stats -vv -U jantman\n\n<span class=\"c1\"># sync html files\n</span>~/venvs/foo/bin/s3cmd -r --delete-removed --stats --exclude<span class=\"o\">=</span><span class=\"s1\">'*.svg'</span> sync pypi-stats s3://jantman-personal-public/\n<span class=\"c1\"># sync SVG and set mime-type, since s3cmd gets it wrong\n</span>~/venvs/foo/bin/s3cmd -r --delete-removed --stats --exclude<span class=\"o\">=</span><span class=\"s1\">'*.html'</span> --mime-type<span class=\"o\">=</span><span class=\"s1\">'image/svg+xml'</span> sync pypi-stats s3://jantman-personal-public/\n</pre>\n<div id=\"cost\">\n<h4>Cost</h4>\n<p>At this point\u2026 I have no idea. Some of the download tables are 3+ GB per day.\nI imagine that backfilling historical data from the beginning of what\u2019s currently\nthere (20160122) might incur quite a bit of data cost.</p>\n</div>\n</div>\n<div id=\"bugs-and-feature-requests\">\n<h3>Bugs and Feature Requests</h3>\n<p>Bug reports and feature requests are happily accepted via the <a href=\"https://github.com/jantman/pypi-download-stats/issues\" rel=\"nofollow\">GitHub Issue Tracker</a>. Pull requests are\nwelcome. Issues that don\u2019t have an accompanying pull request will be worked on\nas my time and priority allows.</p>\n</div>\n</div>\n<div id=\"development\">\n<h2>Development</h2>\n<p>To install for development:</p>\n<ol>\n<li>Fork the <a href=\"https://github.com/jantman/pypi-download-stats\" rel=\"nofollow\">pypi-download-stats</a> repository on GitHub</li>\n<li>Create a new branch off of master in your fork.</li>\n</ol>\n<pre>$ virtualenv pypi-download-stats\n$ <span class=\"nb\">cd</span> pypi-download-stats <span class=\"o\">&amp;&amp;</span> <span class=\"nb\">source</span> bin/activate\n$ pip install -e git+git@github.com:YOURNAME/pypi-download-stats.git@BRANCHNAME#egg<span class=\"o\">=</span>pypi-download-stats\n$ <span class=\"nb\">cd</span> src/pypi-download-stats\n</pre>\n<p>The git clone you\u2019re now in will probably be checked out to a specific commit,\nso you may want to <tt>git checkout BRANCHNAME</tt>.</p>\n<div id=\"guidelines\">\n<h3>Guidelines</h3>\n<ul>\n<li>pep8 compliant with some exceptions (see pytest.ini)</li>\n</ul>\n</div>\n<div id=\"testing\">\n<h3>Testing</h3>\n<p>There isn\u2019t any right now. I\u2019m bad. If people actually start using this, I\u2019ll\nrefactor and add tests, but for now this started as a one-night project.</p>\n</div>\n<div id=\"release-checklist\">\n<h3>Release Checklist</h3>\n<ol>\n<li>Open an issue for the release; cut a branch off master for that issue.</li>\n<li>Confirm that there are CHANGES.rst entries for all major changes.</li>\n<li>Ensure that Travis tests passing in all environments.</li>\n<li>Ensure that test coverage is no less than the last release (ideally, 100%).</li>\n<li>Increment the version number in pypi-download-stats/version.py and add version and release date to CHANGES.rst, then push to GitHub.</li>\n<li>Confirm that README.rst renders correctly on GitHub.</li>\n<li>Upload package to testpypi:<ul>\n<li>Make sure your ~/.pypirc file is correct (a repo called <tt>test</tt> for <a href=\"https://testpypi.python.org/pypi\" rel=\"nofollow\">https://testpypi.python.org/pypi</a>)</li>\n<li><tt>rm <span class=\"pre\">-Rf</span> dist</tt></li>\n<li><tt>python setup.py register <span class=\"pre\">-r</span> <span class=\"pre\">https://testpypi.python.org/pypi</span></tt></li>\n<li><tt>python setup.py sdist bdist_wheel</tt></li>\n<li><tt>twine upload <span class=\"pre\">-r</span> test dist/*</tt></li>\n<li>Check that the README renders at <a href=\"https://testpypi.python.org/pypi/pypi-download-stats\" rel=\"nofollow\">https://testpypi.python.org/pypi/pypi-download-stats</a></li>\n</ul>\n</li>\n<li>Create a pull request for the release to be merged into master. Upon successful Travis build, merge it.</li>\n<li>Tag the release in Git, push tag to GitHub:<ul>\n<li>tag the release. for now the message is quite simple: <tt>git tag <span class=\"pre\">-a</span> X.Y.Z <span class=\"pre\">-m</span> 'X.Y.Z released <span class=\"pre\">YYYY-MM-DD'</span></tt></li>\n<li>push the tag to GitHub: <tt>git push origin X.Y.Z</tt></li>\n</ul>\n</li>\n</ol>\n<ol>\n<li>Upload package to live pypi:<ul>\n<li><tt>twine upload dist/*</tt></li>\n</ul>\n</li>\n</ol>\n<ol>\n<li>make sure any GH issues fixed in the release were closed.</li>\n</ol>\n</div>\n</div>\n\n          </div>"}, "last_serial": 2349338, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "61fa2f935c04ba2f40bbe744e97fc866", "sha256": "ac115391b957403d0c7ec3ccaf373a214e893db8e3313453117eae7601fd8856"}, "downloads": -1, "filename": "pypi_download_stats-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "61fa2f935c04ba2f40bbe744e97fc866", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 40137, "upload_time": "2016-09-02T21:13:31", "upload_time_iso_8601": "2016-09-02T21:13:31.864891Z", "url": "https://files.pythonhosted.org/packages/13/e7/712bc8ca27c11848d42b3d3478eb5fc76f3532df860433e8d289e627d893/pypi_download_stats-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "65aafaaac3064ae3a56e18c63b9fbbd7", "sha256": "39d86e147348d3fed4d0dc822845eebd40069f4b45ed22f9c9343b28b3eb0a31"}, "downloads": -1, "filename": "pypi-download-stats-0.1.0.tar.gz", "has_sig": false, "md5_digest": "65aafaaac3064ae3a56e18c63b9fbbd7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 40100, "upload_time": "2016-09-02T21:13:35", "upload_time_iso_8601": "2016-09-02T21:13:35.479211Z", "url": "https://files.pythonhosted.org/packages/8f/ba/475e19f8e4c544ba291ce076eb2442de5d8a70cfd517f39c0984436861af/pypi-download-stats-0.1.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "0ccd01b1a9e2ff1474b11195b14cbd0e", "sha256": "8f76d86c17c0a8200b3600b07027d0cedf3e2ba82aeb8fcd3a9e2b5f1c4fe926"}, "downloads": -1, "filename": "pypi_download_stats-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "0ccd01b1a9e2ff1474b11195b14cbd0e", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 44559, "upload_time": "2016-09-18T11:15:38", "upload_time_iso_8601": "2016-09-18T11:15:38.114644Z", "url": "https://files.pythonhosted.org/packages/05/0f/02b2fd88f78f1bdfd183aad3aea49a1ad155110fa2a664224dc38293d0ee/pypi_download_stats-0.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "72dda801ec714d634da349391e844c5f", "sha256": "c47f10b8cb782341b5cca6706260492d20ac144e16b7f56efef399cbdd697cce"}, "downloads": -1, "filename": "pypi-download-stats-0.2.0.tar.gz", "has_sig": false, "md5_digest": "72dda801ec714d634da349391e844c5f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 43743, "upload_time": "2016-09-18T11:15:40", "upload_time_iso_8601": "2016-09-18T11:15:40.671796Z", "url": "https://files.pythonhosted.org/packages/61/74/d5aa85a42611c27d9eb0c2d2d13c9b19f4ceebb8f99b434b41b8490791d4/pypi-download-stats-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "77641092ef870155fac851505d3bca12", "sha256": "bdc2ae538899710d694be604128e746d9f582a94af57751a46c4a207f9c936c1"}, "downloads": -1, "filename": "pypi_download_stats-0.2.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "77641092ef870155fac851505d3bca12", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 44854, "upload_time": "2016-09-18T16:32:03", "upload_time_iso_8601": "2016-09-18T16:32:03.204531Z", "url": "https://files.pythonhosted.org/packages/6e/5a/e3ab4a74fa9f32cf876cbb380500727008f963769ece8f165918f4e2fb65/pypi_download_stats-0.2.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a1f1edfa738c463ccb9e910fa13631ea", "sha256": "ad625ffcff140374a9467dc0ea1a00947271433cc43130fb294336f5dd7f40a2"}, "downloads": -1, "filename": "pypi-download-stats-0.2.1.tar.gz", "has_sig": false, "md5_digest": "a1f1edfa738c463ccb9e910fa13631ea", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 44074, "upload_time": "2016-09-18T16:32:05", "upload_time_iso_8601": "2016-09-18T16:32:05.256818Z", "url": "https://files.pythonhosted.org/packages/15/1c/4650876b03388ad2fc9a530036e820974b36a0f601a04eef68318c39a1f5/pypi-download-stats-0.2.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "77641092ef870155fac851505d3bca12", "sha256": "bdc2ae538899710d694be604128e746d9f582a94af57751a46c4a207f9c936c1"}, "downloads": -1, "filename": "pypi_download_stats-0.2.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "77641092ef870155fac851505d3bca12", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 44854, "upload_time": "2016-09-18T16:32:03", "upload_time_iso_8601": "2016-09-18T16:32:03.204531Z", "url": "https://files.pythonhosted.org/packages/6e/5a/e3ab4a74fa9f32cf876cbb380500727008f963769ece8f165918f4e2fb65/pypi_download_stats-0.2.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a1f1edfa738c463ccb9e910fa13631ea", "sha256": "ad625ffcff140374a9467dc0ea1a00947271433cc43130fb294336f5dd7f40a2"}, "downloads": -1, "filename": "pypi-download-stats-0.2.1.tar.gz", "has_sig": false, "md5_digest": "a1f1edfa738c463ccb9e910fa13631ea", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 44074, "upload_time": "2016-09-18T16:32:05", "upload_time_iso_8601": "2016-09-18T16:32:05.256818Z", "url": "https://files.pythonhosted.org/packages/15/1c/4650876b03388ad2fc9a530036e820974b36a0f601a04eef68318c39a1f5/pypi-download-stats-0.2.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:59:35 2020"}