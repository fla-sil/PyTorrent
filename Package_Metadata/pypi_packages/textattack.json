{"info": {"author": "QData Lab at the University of Virginia", "author_email": "jm8wx@virginia.edu", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "<h1 align=\"center\">TextAttack \ud83d\udc19</h1>\n\n<p align=\"center\">Generating adversarial examples for NLP models</p>\n\n<p align=\"center\">\n  <a href=\"#about\">About</a> \u2022\n  <a href=\"#setup\">Setup</a> \u2022\n  <a href=\"#usage\">Usage</a> \u2022\n  <a href=\"#design\">Design</a> \n  <br> <br>\n  <a target=\"_blank\" href=\"https://travis-ci.com/UVA-MachineLearningBioinformatics/TextAttack\">\n    <img src=\"https://travis-ci.com/UVA-MachineLearningBioinformatics/TextAttack.svg?token=Kpx8qxw1sbsdXyhVxRq3&branch=master\" alt=\"Coverage Status\">\n  </a>\n\n</p>\n\n## About\n\nTextAttack is a library for running adversarial attacks against NLP models. These may be useful for evaluating attack methods and evaluating model robustness. TextAttack is designed in order to be easily extensible to new NLP tasks, models, attack methods, and attack constraints. The separation between these aspects of an adversarial attack and standardization of constraint evaluation allows for easier ablation studies. TextAttack supports attacks on models trained for classification and entailment.\n\n## Setup\n\n### Installation\n\nYou should be running Python 3.6+ to use this package. A CUDA-compatible GPU is optional but will greatly improve code speed. After cloning this git repository, run the following commands to install the `textattack` page a `conda` environment:\n\n```\nconda create -n text-attack python=3.7\nconda activate text-attack\npip install -e .\n```\n\nWe use the NLTK package for its list of stopwords and access to the WordNet lexical database. To download them run in Python shell:\n\n```\nimport nltk\nnltk.download('stopwords')\nnltk.download('wordnet')\n```\n\nWe use spaCy's English model. To download it, after installing spaCy run:\n\n```\npython -m spacy download en\n```\n\n### Cache\nTextAttack provides pretrained models and datasets for user convenience. By default, all this stuff is downloaded to `~/.cache`. You can change this location by editing the `CACHE_DIR` field in `config.json`.\n\n### Common Errors\n\n#### Errors regarding GCC\nIf you see an error that GCC is incompatible, make sure your system has an up-to-date version of the GCC compiler.\n\n#### Errors regarding Java\nUsing the LanguageTool constraint relies on Java 8 internally (it's not ideal, we know). Please install Java 8 if you're interested in using the LanguageTool grammaticality constraint.\n\n## Usage\n\n### Basic Usage\n\n![TextAttack Demo GIF](https://i.imgur.com/hOCDhQf.gif)\n\nWe have a command-line interface for running different attacks on different datasets. Run it with default arguments with `python scripts/run_attack.py`. See help info and list of arguments with `python scripts/run_attack.py --help`.\n\n### Attack Recipes\n\nWe include attack recipes which build an attack such that only one command line argument has to be passed. To run an attack recipes, run `python scripts/run_attack.py --recipe [recipe_name]`\nCurrently, we include four recipes, each for synonym substitution-based classification and entailment attacks:\n- **deepwordbug**: Replace-1 scoring and multi-transformation character-swap attack ([\"Black-box Generation of Adversarial Text Sequences to Evade Deep Learning Classifiers\"](https://arxiv.org/abs/1801.04354))\n- **textfooler**: Greedy attack with word importance ranking ([\"Is Bert Really Robust?\" (Jin et al., 2019)](https://arxiv.org/abs/1907.11932))\n- **alzantot**: Genetic algorithm attack from ([\"Generating Natural Language Adversarial Examples\" (Alzantot et al., 2018)](https://arxiv.org/abs/1804.07998))\n- **tf-adjusted**: TextFooler attack with constraint thresholds adjusted based on human evaluation and grammaticality enforced.\n- **alz-adjusted**: Alzantot's attack adjusted to follow the same constraints as tf-adjusted such that the only difference is the search method.\n\n### Adding to TextAttack\n\nClone the repository, add your code, and run run\\_attack to get results. If you would like your contribution to be added to the library, submit a pull request. Instructions for using TextAttack as a pip library coming soon!\n\n## Design\n\n### TokenizedText\n\nTo allow for word replacement after a sequence has been tokenized, we include a TokenizedText object which maintains both a list of tokens and the original text, with punctuation. We use this object in favor of a list of words or just raw text.\n\n### Models and Datasets\n\nWe've included a few pretrained models that you can download and run out-of-the-box. However, TextAttack is model agnostic! Anything that overrides \\_\\_call\\_\\_, takes in tokenized text, and outputs probabilities works. \n\n### Attacks\n\nAttacks all take as input a TokenizedText, and output either an AttackResult if it succeeds or a FailedAttackResult if it fails. We split attacks into black box, which only have access to the model\u2019s call function, and white box, which have access to the whole model. For standardization and ease of ablation, we formulate an attack as a series of transformations in a search space, subject to certain constraints. An attack may call get\\_transformations for a given transformation to get a list of possible transformations filtered by meeting all of the attack\u2019s constraints.\n\n### Transformations\n\nTransformations take as input a TokenizedText and return a list of possible transformed TokenizedTexts. For example, a transformation might return all possible synonym replacements.\n\n### Constraints\n\nConstraints take as input an original TokenizedText, and a list of transformed TokenizedTexts. For each transformed option, the constraint returns a boolean representing whether the constraint is met.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/QData/textattack", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "textattack", "package_url": "https://pypi.org/project/textattack/", "platform": "", "project_url": "https://pypi.org/project/textattack/", "project_urls": {"Homepage": "https://github.com/QData/textattack"}, "release_url": "https://pypi.org/project/textattack/0.0.1.7/", "requires_dist": ["editdistance", "filelock", "language-tool-python", "lru-dict", "nltk", "numpy", "pandas", "scikit-learn", "scipy", "sentence-transformers", "spacy", "torch", "transformers (>=2.5.1)", "tensorflow (>=2)", "tensorflow-hub", "terminaltables", "tqdm", "visdom"], "requires_python": ">=3.6", "summary": "A library for generating text adversarial examples", "version": "0.0.1.7", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>TextAttack \ud83d\udc19</h1>\n<p align=\"center\">Generating adversarial examples for NLP models</p>\n<p align=\"center\">\n  <a href=\"#about\" rel=\"nofollow\">About</a> \u2022\n  <a href=\"#setup\" rel=\"nofollow\">Setup</a> \u2022\n  <a href=\"#usage\" rel=\"nofollow\">Usage</a> \u2022\n  <a href=\"#design\" rel=\"nofollow\">Design</a> \n  <br> <br>\n  <a href=\"https://travis-ci.com/UVA-MachineLearningBioinformatics/TextAttack\" rel=\"nofollow\">\n    <img alt=\"Coverage Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/25a7f35cb0f211d441602da444c9dd5d42f88ebb/68747470733a2f2f7472617669732d63692e636f6d2f5556412d4d616368696e654c6561726e696e6742696f696e666f726d61746963732f5465787441747461636b2e7376673f746f6b656e3d4b70783871787731736273645879685678527133266272616e63683d6d6173746572\">\n  </a>\n</p>\n<h2>About</h2>\n<p>TextAttack is a library for running adversarial attacks against NLP models. These may be useful for evaluating attack methods and evaluating model robustness. TextAttack is designed in order to be easily extensible to new NLP tasks, models, attack methods, and attack constraints. The separation between these aspects of an adversarial attack and standardization of constraint evaluation allows for easier ablation studies. TextAttack supports attacks on models trained for classification and entailment.</p>\n<h2>Setup</h2>\n<h3>Installation</h3>\n<p>You should be running Python 3.6+ to use this package. A CUDA-compatible GPU is optional but will greatly improve code speed. After cloning this git repository, run the following commands to install the <code>textattack</code> page a <code>conda</code> environment:</p>\n<pre><code>conda create -n text-attack python=3.7\nconda activate text-attack\npip install -e .\n</code></pre>\n<p>We use the NLTK package for its list of stopwords and access to the WordNet lexical database. To download them run in Python shell:</p>\n<pre><code>import nltk\nnltk.download('stopwords')\nnltk.download('wordnet')\n</code></pre>\n<p>We use spaCy's English model. To download it, after installing spaCy run:</p>\n<pre><code>python -m spacy download en\n</code></pre>\n<h3>Cache</h3>\n<p>TextAttack provides pretrained models and datasets for user convenience. By default, all this stuff is downloaded to <code>~/.cache</code>. You can change this location by editing the <code>CACHE_DIR</code> field in <code>config.json</code>.</p>\n<h3>Common Errors</h3>\n<h4>Errors regarding GCC</h4>\n<p>If you see an error that GCC is incompatible, make sure your system has an up-to-date version of the GCC compiler.</p>\n<h4>Errors regarding Java</h4>\n<p>Using the LanguageTool constraint relies on Java 8 internally (it's not ideal, we know). Please install Java 8 if you're interested in using the LanguageTool grammaticality constraint.</p>\n<h2>Usage</h2>\n<h3>Basic Usage</h3>\n<p><img alt=\"TextAttack Demo GIF\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0f7e1b797a4a706b99b1a2a6389ecba92df77fe1/68747470733a2f2f692e696d6775722e636f6d2f684f43446851662e676966\"></p>\n<p>We have a command-line interface for running different attacks on different datasets. Run it with default arguments with <code>python scripts/run_attack.py</code>. See help info and list of arguments with <code>python scripts/run_attack.py --help</code>.</p>\n<h3>Attack Recipes</h3>\n<p>We include attack recipes which build an attack such that only one command line argument has to be passed. To run an attack recipes, run <code>python scripts/run_attack.py --recipe [recipe_name]</code>\nCurrently, we include four recipes, each for synonym substitution-based classification and entailment attacks:</p>\n<ul>\n<li><strong>deepwordbug</strong>: Replace-1 scoring and multi-transformation character-swap attack (<a href=\"https://arxiv.org/abs/1801.04354\" rel=\"nofollow\">\"Black-box Generation of Adversarial Text Sequences to Evade Deep Learning Classifiers\"</a>)</li>\n<li><strong>textfooler</strong>: Greedy attack with word importance ranking (<a href=\"https://arxiv.org/abs/1907.11932\" rel=\"nofollow\">\"Is Bert Really Robust?\" (Jin et al., 2019)</a>)</li>\n<li><strong>alzantot</strong>: Genetic algorithm attack from (<a href=\"https://arxiv.org/abs/1804.07998\" rel=\"nofollow\">\"Generating Natural Language Adversarial Examples\" (Alzantot et al., 2018)</a>)</li>\n<li><strong>tf-adjusted</strong>: TextFooler attack with constraint thresholds adjusted based on human evaluation and grammaticality enforced.</li>\n<li><strong>alz-adjusted</strong>: Alzantot's attack adjusted to follow the same constraints as tf-adjusted such that the only difference is the search method.</li>\n</ul>\n<h3>Adding to TextAttack</h3>\n<p>Clone the repository, add your code, and run run_attack to get results. If you would like your contribution to be added to the library, submit a pull request. Instructions for using TextAttack as a pip library coming soon!</p>\n<h2>Design</h2>\n<h3>TokenizedText</h3>\n<p>To allow for word replacement after a sequence has been tokenized, we include a TokenizedText object which maintains both a list of tokens and the original text, with punctuation. We use this object in favor of a list of words or just raw text.</p>\n<h3>Models and Datasets</h3>\n<p>We've included a few pretrained models that you can download and run out-of-the-box. However, TextAttack is model agnostic! Anything that overrides __call__, takes in tokenized text, and outputs probabilities works.</p>\n<h3>Attacks</h3>\n<p>Attacks all take as input a TokenizedText, and output either an AttackResult if it succeeds or a FailedAttackResult if it fails. We split attacks into black box, which only have access to the model\u2019s call function, and white box, which have access to the whole model. For standardization and ease of ablation, we formulate an attack as a series of transformations in a search space, subject to certain constraints. An attack may call get_transformations for a given transformation to get a list of possible transformations filtered by meeting all of the attack\u2019s constraints.</p>\n<h3>Transformations</h3>\n<p>Transformations take as input a TokenizedText and return a list of possible transformed TokenizedTexts. For example, a transformation might return all possible synonym replacements.</p>\n<h3>Constraints</h3>\n<p>Constraints take as input an original TokenizedText, and a list of transformed TokenizedTexts. For each transformed option, the constraint returns a boolean representing whether the constraint is met.</p>\n\n          </div>"}, "last_serial": 7145778, "releases": {"0.0.1.7": [{"comment_text": "", "digests": {"md5": "f0303227e9e6061947fa32136e3fdca8", "sha256": "9322333080602a101ea58bf77a83625b2de223cf0ed50bada5cc1a1a196cafdc"}, "downloads": -1, "filename": "textattack-0.0.1.7-py3-none-any.whl", "has_sig": false, "md5_digest": "f0303227e9e6061947fa32136e3fdca8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 113975, "upload_time": "2020-05-01T15:21:42", "upload_time_iso_8601": "2020-05-01T15:21:42.124855Z", "url": "https://files.pythonhosted.org/packages/5a/d8/ab3bc220fbbb07931f76e076b614739631ed1270e90703be0a55bad7d8b1/textattack-0.0.1.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3ebd36fd18820bddce6ef7876272016b", "sha256": "abafcb9eedf64206d0f33e3f5e200893245be9c4121cefb4b8fe0e7371a0a5e5"}, "downloads": -1, "filename": "textattack-0.0.1.7.tar.gz", "has_sig": false, "md5_digest": "3ebd36fd18820bddce6ef7876272016b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 65945, "upload_time": "2020-05-01T15:21:43", "upload_time_iso_8601": "2020-05-01T15:21:43.308359Z", "url": "https://files.pythonhosted.org/packages/d9/4c/7f20e51d4ffa810ab5322988d8fd7283642eb1171361e9dae3b7b60ec5f2/textattack-0.0.1.7.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "f0303227e9e6061947fa32136e3fdca8", "sha256": "9322333080602a101ea58bf77a83625b2de223cf0ed50bada5cc1a1a196cafdc"}, "downloads": -1, "filename": "textattack-0.0.1.7-py3-none-any.whl", "has_sig": false, "md5_digest": "f0303227e9e6061947fa32136e3fdca8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 113975, "upload_time": "2020-05-01T15:21:42", "upload_time_iso_8601": "2020-05-01T15:21:42.124855Z", "url": "https://files.pythonhosted.org/packages/5a/d8/ab3bc220fbbb07931f76e076b614739631ed1270e90703be0a55bad7d8b1/textattack-0.0.1.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3ebd36fd18820bddce6ef7876272016b", "sha256": "abafcb9eedf64206d0f33e3f5e200893245be9c4121cefb4b8fe0e7371a0a5e5"}, "downloads": -1, "filename": "textattack-0.0.1.7.tar.gz", "has_sig": false, "md5_digest": "3ebd36fd18820bddce6ef7876272016b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 65945, "upload_time": "2020-05-01T15:21:43", "upload_time_iso_8601": "2020-05-01T15:21:43.308359Z", "url": "https://files.pythonhosted.org/packages/d9/4c/7f20e51d4ffa810ab5322988d8fd7283642eb1171361e9dae3b7b60ec5f2/textattack-0.0.1.7.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:55:07 2020"}