{"info": {"author": "m8r0wn", "author_email": "m8r0wn@protonmail.com", "bugtrack_url": null, "classifiers": ["Environment :: Console", "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)", "Operating System :: Unix", "Programming Language :: Python :: 3", "Topic :: Security"], "description": "# pymeta\n![](https://img.shields.io/badge/Python-3.6+-blue.svg)&nbsp;&nbsp;\n![](https://img.shields.io/badge/License-GPL%203.0-green.svg)\n\n\nPymeta is a Python3 rewrite of the tool [PowerMeta](https://github.com/dafthack/PowerMeta), created by [dafthack](https://twitter.com/dafthack) in PowerShell. It uses specially crafted search queries to identify and download the following file types (pdf, xls, xlsx, csv, doc, docx, ppt, pptx) from a given domain using Google and Bing scraping. Once downloaded, metadata is extracted from these files using Phil Harvey's [exiftool](https://sno.phy.queensu.ca/~phil/exiftool/) and added to a ```.csv``` report. Metadata is a common place for penetration testers to find internal domain names, usernames, software/version numbers, and help identify an organization's naming convention.\n\nPymeta can also be pointed at a directory to extract metadata from files manually downloaded using the ```-dir``` command line argument. See the [Usage](#Usage), or [All Options](#All-Options) section for more information. \n\n\n## Install\n* PyPi (last release)\n```\npip3 install pymetadata\n```\n\n* GitHub (latest code)\n```\ngit clone https://github.com/m8r0wn/pymeta\ncd pymeta\npython3 setup.py install\n```\n\n## Usage\n* Search Google and Bing for files within example.com and extract metadata to a csv report:<br>\n```pymeta -d example.com```\n\n* Extract metadata from files within the given directory and create csv report:<br>\n```pymeta -dir Downloads/```\n\n\n## All Options\n```\nTarget Options:\n  -d DOMAIN             Target domain\n  -dir FILE_DIR         Pre-existing directory of files\n\nSearch Options:\n  -s {google,bing,all}  Search engine(s) to scrape (Default: all)\n  -m MAX_RESULTS        Max results per file type, per search engine (Default: 50)\n  -j JITTER             Seconds between search requests (Default: 2)\n\nOutput Options:\n  -o OUTPUT_DIR         Path to store PyMeta's download folder (Default: ./)\n  -f FILENAME           Custom report path/name.csv (Optional)\n  --debug               Show links as they are collected during scraping\n```\n    \n## Credit\n- Beau Bullock [(@dafthack)](https://twitter.com/dafthack) - [https://github.com/dafthack/PowerMeta](https://github.com/dafthack/PowerMeta)\n- Phil Harvey - [https://sno.phy.queensu.ca/~phil/exiftool/](https://sno.phy.queensu.ca/~phil/exiftool/)", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/m8r0wn/pymeta", "keywords": "", "license": "GPLv3", "maintainer": "", "maintainer_email": "", "name": "pymetadata", "package_url": "https://pypi.org/project/pymetadata/", "platform": "Unix", "project_url": "https://pypi.org/project/pymetadata/", "project_urls": {"Homepage": "https://github.com/m8r0wn/pymeta"}, "release_url": "https://pypi.org/project/pymetadata/1.0.4/", "requires_dist": null, "requires_python": "", "summary": "Web scraper to download and extract file metadata", "version": "1.0.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>pymeta</h1>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/27b9ffa6a30c02fbf99c079c370e052fa9190e49/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f507974686f6e2d332e362b2d626c75652e737667\">\u00a0\u00a0\n<img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b7ed4f30ffe74ede8bb99c0ace4f24a5632dffb9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d47504c253230332e302d677265656e2e737667\"></p>\n<p>Pymeta is a Python3 rewrite of the tool <a href=\"https://github.com/dafthack/PowerMeta\" rel=\"nofollow\">PowerMeta</a>, created by <a href=\"https://twitter.com/dafthack\" rel=\"nofollow\">dafthack</a> in PowerShell. It uses specially crafted search queries to identify and download the following file types (pdf, xls, xlsx, csv, doc, docx, ppt, pptx) from a given domain using Google and Bing scraping. Once downloaded, metadata is extracted from these files using Phil Harvey's <a href=\"https://sno.phy.queensu.ca/%7Ephil/exiftool/\" rel=\"nofollow\">exiftool</a> and added to a <code>.csv</code> report. Metadata is a common place for penetration testers to find internal domain names, usernames, software/version numbers, and help identify an organization's naming convention.</p>\n<p>Pymeta can also be pointed at a directory to extract metadata from files manually downloaded using the <code>-dir</code> command line argument. See the <a href=\"#Usage\" rel=\"nofollow\">Usage</a>, or <a href=\"#All-Options\" rel=\"nofollow\">All Options</a> section for more information.</p>\n<h2>Install</h2>\n<ul>\n<li>PyPi (last release)</li>\n</ul>\n<pre><code>pip3 install pymetadata\n</code></pre>\n<ul>\n<li>GitHub (latest code)</li>\n</ul>\n<pre><code>git clone https://github.com/m8r0wn/pymeta\ncd pymeta\npython3 setup.py install\n</code></pre>\n<h2>Usage</h2>\n<ul>\n<li>\n<p>Search Google and Bing for files within example.com and extract metadata to a csv report:<br>\n<code>pymeta -d example.com</code></p>\n</li>\n<li>\n<p>Extract metadata from files within the given directory and create csv report:<br>\n<code>pymeta -dir Downloads/</code></p>\n</li>\n</ul>\n<h2>All Options</h2>\n<pre><code>Target Options:\n  -d DOMAIN             Target domain\n  -dir FILE_DIR         Pre-existing directory of files\n\nSearch Options:\n  -s {google,bing,all}  Search engine(s) to scrape (Default: all)\n  -m MAX_RESULTS        Max results per file type, per search engine (Default: 50)\n  -j JITTER             Seconds between search requests (Default: 2)\n\nOutput Options:\n  -o OUTPUT_DIR         Path to store PyMeta's download folder (Default: ./)\n  -f FILENAME           Custom report path/name.csv (Optional)\n  --debug               Show links as they are collected during scraping\n</code></pre>\n<h2>Credit</h2>\n<ul>\n<li>Beau Bullock <a href=\"https://twitter.com/dafthack\" rel=\"nofollow\">(@dafthack)</a> - <a href=\"https://github.com/dafthack/PowerMeta\" rel=\"nofollow\">https://github.com/dafthack/PowerMeta</a></li>\n<li>Phil Harvey - <a href=\"https://sno.phy.queensu.ca/%7Ephil/exiftool/\" rel=\"nofollow\">https://sno.phy.queensu.ca/~phil/exiftool/</a></li>\n</ul>\n\n          </div>"}, "last_serial": 6912428, "releases": {"1.0.2": [{"comment_text": "", "digests": {"md5": "545e5bfb0f6498911bf5692b52a1313b", "sha256": "967750dde9f4a3061ec6c35b8450325f3ad04d34b537a3ee72975b0b6fa5cff2"}, "downloads": -1, "filename": "pymetadata-1.0.2.tar.gz", "has_sig": false, "md5_digest": "545e5bfb0f6498911bf5692b52a1313b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 92449, "upload_time": "2020-01-12T20:14:29", "upload_time_iso_8601": "2020-01-12T20:14:29.646981Z", "url": "https://files.pythonhosted.org/packages/30/cc/a269a6dc215b0121f760beb376b69a730a812c7ddc24ba1d4e0fb2ca5393/pymetadata-1.0.2.tar.gz", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "f59956dae73146563b47f1f4f5c8efdc", "sha256": "a1ab6dea6159183ae8a0752c00029f0e73afe487b366f03a9c5a0bdca3ad167b"}, "downloads": -1, "filename": "pymetadata-1.0.3.tar.gz", "has_sig": false, "md5_digest": "f59956dae73146563b47f1f4f5c8efdc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 92257, "upload_time": "2020-01-16T20:54:25", "upload_time_iso_8601": "2020-01-16T20:54:25.994150Z", "url": "https://files.pythonhosted.org/packages/91/d5/f11c2cade47b57f90f82ebd6d0bb292916750657c3246cbb1a30dd0f8272/pymetadata-1.0.3.tar.gz", "yanked": false}], "1.0.4": [{"comment_text": "", "digests": {"md5": "6709de78ff1bb06725b654b3a9413855", "sha256": "997eaf288d3374fd1cfa72c6949725c9d91757e2e06b2570cd683df5584eb7d1"}, "downloads": -1, "filename": "pymetadata-1.0.4.tar.gz", "has_sig": false, "md5_digest": "6709de78ff1bb06725b654b3a9413855", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 92717, "upload_time": "2020-03-30T12:15:27", "upload_time_iso_8601": "2020-03-30T12:15:27.467284Z", "url": "https://files.pythonhosted.org/packages/bd/07/1ec2a1b529531dd2f0f9f9e66c557899c4e23f06f6fe4bb3e56d1c439248/pymetadata-1.0.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "6709de78ff1bb06725b654b3a9413855", "sha256": "997eaf288d3374fd1cfa72c6949725c9d91757e2e06b2570cd683df5584eb7d1"}, "downloads": -1, "filename": "pymetadata-1.0.4.tar.gz", "has_sig": false, "md5_digest": "6709de78ff1bb06725b654b3a9413855", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 92717, "upload_time": "2020-03-30T12:15:27", "upload_time_iso_8601": "2020-03-30T12:15:27.467284Z", "url": "https://files.pythonhosted.org/packages/bd/07/1ec2a1b529531dd2f0f9f9e66c557899c4e23f06f6fe4bb3e56d1c439248/pymetadata-1.0.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:02:12 2020"}