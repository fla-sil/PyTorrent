{"info": {"author": "ZhouYang Luo", "author_email": "zhouyang.luo@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3.6"], "description": "# datasets\nA dataset utils repository based on `tf.data`. **For tensorflow>=2.0 only!**\n\n## Requirements\n\n* python 3.6\n* tensorflow>=2.0\n\n## Installation\n\n```bash\npip install nlp-datasets\n```\n\n## Usage\n\n### seq2seq models\n\nThese models has an source sequence `x` and an target sequence `y`.\n\n```python\nfrom nlp_datasets import Seq2SeqDataset\nfrom nlp_datasets import SpaceTokenizer\nfrom nlp_datasets.utils import data_dir_utils as utils\n\nfiles = [\n    utils.get_data_file('iwslt15.tst2013.100.envi'),\n    utils.get_data_file('iwslt15.tst2013.100.envi'),\n]\nx_tokenizer = SpaceTokenizer()\nx_tokenizer.build_from_corpus([utils.get_data_file('iwslt15.tst2013.100.en')])\ny_tokenizer = SpaceTokenizer()\ny_tokenizer.build_from_corpus([utils.get_data_file('iwslt15.tst2013.100.vi')])\nconfig = {\n    'train_batch_size': 2,\n    'predict_batch_size': 2,\n    'eval_batch_size': 2,\n    'buffer_size': 100\n}\ndataset = Seq2SeqDataset(x_tokenizer, y_tokenizer, config)\n\ntrain_dataset = dataset.build_train_dataset(files)\nprint(next(iter(train_dataset)))\nprint('=' * 120)\n\neval_dataset = dataset.build_eval_dataset(files)\nprint(next(iter(eval_dataset)))\nprint('=' * 120)\n\npredict_files = [utils.get_data_file('iwslt15.tst2013.100.envi')]\npredict_dataset = dataset.build_predict_dataset(predict_files)\nprint(next(iter(predict_dataset)))\nprint('=' * 120)\n```\n\n### sequence match models\n\nThese models has two sequences as input, `x` and `y`, and has an label `z`.\n\n```python\nfrom nlp_datasets import SeqMatchDataset\nfrom nlp_datasets import SpaceTokenizer\nfrom nlp_datasets.utils import data_dir_utils as utils\n\nfiles = [\n    utils.get_data_file('dssm.query.doc.label.txt'),\n    utils.get_data_file('dssm.query.doc.label.txt'),\n]\nx_tokenizer = SpaceTokenizer()\nx_tokenizer.build_from_vocab(utils.get_data_file('dssm.vocab.txt'))\ny_tokenizer = SpaceTokenizer()\ny_tokenizer.build_from_vocab(utils.get_data_file('dssm.vocab.txt'))\n\nconfig = {\n    'train_batch_size': 2,\n    'eval_batch_size': 2,\n    'predict_batch_size': 2,\n    'buffer_size': 100,\n}\ndataset = SeqMatchDataset(x_tokenizer, y_tokenizer, config)\n\ntrain_dataset = dataset.build_train_dataset(files)\nprint(next(iter(train_dataset)))\nprint('=' * 120)\n\neval_dataset = dataset.build_eval_dataset(files)\nprint(next(iter(eval_dataset)))\nprint('=' * 120)\n\npredict_files = [utils.get_data_file('dssm.query.doc.label.txt')]\npredict_dataset = dataset.build_predict_dataset(predict_files)\nprint(next(iter(predict_dataset)))\nprint('=' * 120)\n```\n\n### sequence classify model\n\nThese models has a input sequence `x`, and a output label `y`.\n\n```python\nfrom nlp_datasets import SeqClassifyDataset\nfrom nlp_datasets import SpaceTokenizer\nfrom nlp_datasets.utils import data_dir_utils as utils\n\nfiles = [\n    utils.get_data_file('classify.seq.label.txt')\n]\nx_tokenizer = SpaceTokenizer()\nx_tokenizer.build_from_corpus([utils.get_data_file('classify.seq.txt')])\n\nconfig = {\n    'train_batch_size': 2,\n    'eval_batch_size': 2,\n    'predict_batch_size': 2,\n    'buffer_size': 100\n}\ndataset = SeqClassifyDataset(x_tokenizer, config)\n\ntrain_dataset = dataset.build_train_dataset(files)\nprint(next(iter(train_dataset)))\nprint('=' * 120)\n\neval_dataset = dataset.build_eval_dataset(files)\nprint(next(iter(eval_dataset)))\nprint('=' * 120)\n\npredict_files = [utils.get_data_file('classify.seq.txt')]\npredict_dataset = dataset.build_predict_dataset(predict_files)\nprint(next(iter(predict_dataset)))\nprint('=' * 120)\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/luozhouyang/nlp-datasets", "keywords": "", "license": "MIT License", "maintainer": "", "maintainer_email": "", "name": "nlp-datasets", "package_url": "https://pypi.org/project/nlp-datasets/", "platform": "", "project_url": "https://pypi.org/project/nlp-datasets/", "project_urls": {"Homepage": "https://github.com/luozhouyang/nlp-datasets"}, "release_url": "https://pypi.org/project/nlp-datasets/1.3.0/", "requires_dist": null, "requires_python": "", "summary": "A dataset utils repository based on tf.data. For tensorflow 2.x only!", "version": "1.3.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>datasets</h1>\n<p>A dataset utils repository based on <code>tf.data</code>. <strong>For tensorflow&gt;=2.0 only!</strong></p>\n<h2>Requirements</h2>\n<ul>\n<li>python 3.6</li>\n<li>tensorflow&gt;=2.0</li>\n</ul>\n<h2>Installation</h2>\n<pre>pip install nlp-datasets\n</pre>\n<h2>Usage</h2>\n<h3>seq2seq models</h3>\n<p>These models has an source sequence <code>x</code> and an target sequence <code>y</code>.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">nlp_datasets</span> <span class=\"kn\">import</span> <span class=\"n\">Seq2SeqDataset</span>\n<span class=\"kn\">from</span> <span class=\"nn\">nlp_datasets</span> <span class=\"kn\">import</span> <span class=\"n\">SpaceTokenizer</span>\n<span class=\"kn\">from</span> <span class=\"nn\">nlp_datasets.utils</span> <span class=\"kn\">import</span> <span class=\"n\">data_dir_utils</span> <span class=\"k\">as</span> <span class=\"n\">utils</span>\n\n<span class=\"n\">files</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n    <span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">get_data_file</span><span class=\"p\">(</span><span class=\"s1\">'iwslt15.tst2013.100.envi'</span><span class=\"p\">),</span>\n    <span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">get_data_file</span><span class=\"p\">(</span><span class=\"s1\">'iwslt15.tst2013.100.envi'</span><span class=\"p\">),</span>\n<span class=\"p\">]</span>\n<span class=\"n\">x_tokenizer</span> <span class=\"o\">=</span> <span class=\"n\">SpaceTokenizer</span><span class=\"p\">()</span>\n<span class=\"n\">x_tokenizer</span><span class=\"o\">.</span><span class=\"n\">build_from_corpus</span><span class=\"p\">([</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">get_data_file</span><span class=\"p\">(</span><span class=\"s1\">'iwslt15.tst2013.100.en'</span><span class=\"p\">)])</span>\n<span class=\"n\">y_tokenizer</span> <span class=\"o\">=</span> <span class=\"n\">SpaceTokenizer</span><span class=\"p\">()</span>\n<span class=\"n\">y_tokenizer</span><span class=\"o\">.</span><span class=\"n\">build_from_corpus</span><span class=\"p\">([</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">get_data_file</span><span class=\"p\">(</span><span class=\"s1\">'iwslt15.tst2013.100.vi'</span><span class=\"p\">)])</span>\n<span class=\"n\">config</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'train_batch_size'</span><span class=\"p\">:</span> <span class=\"mi\">2</span><span class=\"p\">,</span>\n    <span class=\"s1\">'predict_batch_size'</span><span class=\"p\">:</span> <span class=\"mi\">2</span><span class=\"p\">,</span>\n    <span class=\"s1\">'eval_batch_size'</span><span class=\"p\">:</span> <span class=\"mi\">2</span><span class=\"p\">,</span>\n    <span class=\"s1\">'buffer_size'</span><span class=\"p\">:</span> <span class=\"mi\">100</span>\n<span class=\"p\">}</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">Seq2SeqDataset</span><span class=\"p\">(</span><span class=\"n\">x_tokenizer</span><span class=\"p\">,</span> <span class=\"n\">y_tokenizer</span><span class=\"p\">,</span> <span class=\"n\">config</span><span class=\"p\">)</span>\n\n<span class=\"n\">train_dataset</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">build_train_dataset</span><span class=\"p\">(</span><span class=\"n\">files</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"nb\">next</span><span class=\"p\">(</span><span class=\"nb\">iter</span><span class=\"p\">(</span><span class=\"n\">train_dataset</span><span class=\"p\">)))</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'='</span> <span class=\"o\">*</span> <span class=\"mi\">120</span><span class=\"p\">)</span>\n\n<span class=\"n\">eval_dataset</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">build_eval_dataset</span><span class=\"p\">(</span><span class=\"n\">files</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"nb\">next</span><span class=\"p\">(</span><span class=\"nb\">iter</span><span class=\"p\">(</span><span class=\"n\">eval_dataset</span><span class=\"p\">)))</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'='</span> <span class=\"o\">*</span> <span class=\"mi\">120</span><span class=\"p\">)</span>\n\n<span class=\"n\">predict_files</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">get_data_file</span><span class=\"p\">(</span><span class=\"s1\">'iwslt15.tst2013.100.envi'</span><span class=\"p\">)]</span>\n<span class=\"n\">predict_dataset</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">build_predict_dataset</span><span class=\"p\">(</span><span class=\"n\">predict_files</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"nb\">next</span><span class=\"p\">(</span><span class=\"nb\">iter</span><span class=\"p\">(</span><span class=\"n\">predict_dataset</span><span class=\"p\">)))</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'='</span> <span class=\"o\">*</span> <span class=\"mi\">120</span><span class=\"p\">)</span>\n</pre>\n<h3>sequence match models</h3>\n<p>These models has two sequences as input, <code>x</code> and <code>y</code>, and has an label <code>z</code>.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">nlp_datasets</span> <span class=\"kn\">import</span> <span class=\"n\">SeqMatchDataset</span>\n<span class=\"kn\">from</span> <span class=\"nn\">nlp_datasets</span> <span class=\"kn\">import</span> <span class=\"n\">SpaceTokenizer</span>\n<span class=\"kn\">from</span> <span class=\"nn\">nlp_datasets.utils</span> <span class=\"kn\">import</span> <span class=\"n\">data_dir_utils</span> <span class=\"k\">as</span> <span class=\"n\">utils</span>\n\n<span class=\"n\">files</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n    <span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">get_data_file</span><span class=\"p\">(</span><span class=\"s1\">'dssm.query.doc.label.txt'</span><span class=\"p\">),</span>\n    <span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">get_data_file</span><span class=\"p\">(</span><span class=\"s1\">'dssm.query.doc.label.txt'</span><span class=\"p\">),</span>\n<span class=\"p\">]</span>\n<span class=\"n\">x_tokenizer</span> <span class=\"o\">=</span> <span class=\"n\">SpaceTokenizer</span><span class=\"p\">()</span>\n<span class=\"n\">x_tokenizer</span><span class=\"o\">.</span><span class=\"n\">build_from_vocab</span><span class=\"p\">(</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">get_data_file</span><span class=\"p\">(</span><span class=\"s1\">'dssm.vocab.txt'</span><span class=\"p\">))</span>\n<span class=\"n\">y_tokenizer</span> <span class=\"o\">=</span> <span class=\"n\">SpaceTokenizer</span><span class=\"p\">()</span>\n<span class=\"n\">y_tokenizer</span><span class=\"o\">.</span><span class=\"n\">build_from_vocab</span><span class=\"p\">(</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">get_data_file</span><span class=\"p\">(</span><span class=\"s1\">'dssm.vocab.txt'</span><span class=\"p\">))</span>\n\n<span class=\"n\">config</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'train_batch_size'</span><span class=\"p\">:</span> <span class=\"mi\">2</span><span class=\"p\">,</span>\n    <span class=\"s1\">'eval_batch_size'</span><span class=\"p\">:</span> <span class=\"mi\">2</span><span class=\"p\">,</span>\n    <span class=\"s1\">'predict_batch_size'</span><span class=\"p\">:</span> <span class=\"mi\">2</span><span class=\"p\">,</span>\n    <span class=\"s1\">'buffer_size'</span><span class=\"p\">:</span> <span class=\"mi\">100</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">SeqMatchDataset</span><span class=\"p\">(</span><span class=\"n\">x_tokenizer</span><span class=\"p\">,</span> <span class=\"n\">y_tokenizer</span><span class=\"p\">,</span> <span class=\"n\">config</span><span class=\"p\">)</span>\n\n<span class=\"n\">train_dataset</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">build_train_dataset</span><span class=\"p\">(</span><span class=\"n\">files</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"nb\">next</span><span class=\"p\">(</span><span class=\"nb\">iter</span><span class=\"p\">(</span><span class=\"n\">train_dataset</span><span class=\"p\">)))</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'='</span> <span class=\"o\">*</span> <span class=\"mi\">120</span><span class=\"p\">)</span>\n\n<span class=\"n\">eval_dataset</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">build_eval_dataset</span><span class=\"p\">(</span><span class=\"n\">files</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"nb\">next</span><span class=\"p\">(</span><span class=\"nb\">iter</span><span class=\"p\">(</span><span class=\"n\">eval_dataset</span><span class=\"p\">)))</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'='</span> <span class=\"o\">*</span> <span class=\"mi\">120</span><span class=\"p\">)</span>\n\n<span class=\"n\">predict_files</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">get_data_file</span><span class=\"p\">(</span><span class=\"s1\">'dssm.query.doc.label.txt'</span><span class=\"p\">)]</span>\n<span class=\"n\">predict_dataset</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">build_predict_dataset</span><span class=\"p\">(</span><span class=\"n\">predict_files</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"nb\">next</span><span class=\"p\">(</span><span class=\"nb\">iter</span><span class=\"p\">(</span><span class=\"n\">predict_dataset</span><span class=\"p\">)))</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'='</span> <span class=\"o\">*</span> <span class=\"mi\">120</span><span class=\"p\">)</span>\n</pre>\n<h3>sequence classify model</h3>\n<p>These models has a input sequence <code>x</code>, and a output label <code>y</code>.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">nlp_datasets</span> <span class=\"kn\">import</span> <span class=\"n\">SeqClassifyDataset</span>\n<span class=\"kn\">from</span> <span class=\"nn\">nlp_datasets</span> <span class=\"kn\">import</span> <span class=\"n\">SpaceTokenizer</span>\n<span class=\"kn\">from</span> <span class=\"nn\">nlp_datasets.utils</span> <span class=\"kn\">import</span> <span class=\"n\">data_dir_utils</span> <span class=\"k\">as</span> <span class=\"n\">utils</span>\n\n<span class=\"n\">files</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n    <span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">get_data_file</span><span class=\"p\">(</span><span class=\"s1\">'classify.seq.label.txt'</span><span class=\"p\">)</span>\n<span class=\"p\">]</span>\n<span class=\"n\">x_tokenizer</span> <span class=\"o\">=</span> <span class=\"n\">SpaceTokenizer</span><span class=\"p\">()</span>\n<span class=\"n\">x_tokenizer</span><span class=\"o\">.</span><span class=\"n\">build_from_corpus</span><span class=\"p\">([</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">get_data_file</span><span class=\"p\">(</span><span class=\"s1\">'classify.seq.txt'</span><span class=\"p\">)])</span>\n\n<span class=\"n\">config</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'train_batch_size'</span><span class=\"p\">:</span> <span class=\"mi\">2</span><span class=\"p\">,</span>\n    <span class=\"s1\">'eval_batch_size'</span><span class=\"p\">:</span> <span class=\"mi\">2</span><span class=\"p\">,</span>\n    <span class=\"s1\">'predict_batch_size'</span><span class=\"p\">:</span> <span class=\"mi\">2</span><span class=\"p\">,</span>\n    <span class=\"s1\">'buffer_size'</span><span class=\"p\">:</span> <span class=\"mi\">100</span>\n<span class=\"p\">}</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">SeqClassifyDataset</span><span class=\"p\">(</span><span class=\"n\">x_tokenizer</span><span class=\"p\">,</span> <span class=\"n\">config</span><span class=\"p\">)</span>\n\n<span class=\"n\">train_dataset</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">build_train_dataset</span><span class=\"p\">(</span><span class=\"n\">files</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"nb\">next</span><span class=\"p\">(</span><span class=\"nb\">iter</span><span class=\"p\">(</span><span class=\"n\">train_dataset</span><span class=\"p\">)))</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'='</span> <span class=\"o\">*</span> <span class=\"mi\">120</span><span class=\"p\">)</span>\n\n<span class=\"n\">eval_dataset</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">build_eval_dataset</span><span class=\"p\">(</span><span class=\"n\">files</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"nb\">next</span><span class=\"p\">(</span><span class=\"nb\">iter</span><span class=\"p\">(</span><span class=\"n\">eval_dataset</span><span class=\"p\">)))</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'='</span> <span class=\"o\">*</span> <span class=\"mi\">120</span><span class=\"p\">)</span>\n\n<span class=\"n\">predict_files</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">get_data_file</span><span class=\"p\">(</span><span class=\"s1\">'classify.seq.txt'</span><span class=\"p\">)]</span>\n<span class=\"n\">predict_dataset</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">build_predict_dataset</span><span class=\"p\">(</span><span class=\"n\">predict_files</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"nb\">next</span><span class=\"p\">(</span><span class=\"nb\">iter</span><span class=\"p\">(</span><span class=\"n\">predict_dataset</span><span class=\"p\">)))</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'='</span> <span class=\"o\">*</span> <span class=\"mi\">120</span><span class=\"p\">)</span>\n</pre>\n\n          </div>"}, "last_serial": 6378419, "releases": {"0.0.7": [{"comment_text": "", "digests": {"md5": "3fecbae6bbf429efff191421873c8b93", "sha256": "bc79abe9818a3395a5af6b4b9304c5c6ea2e6f3aee145a25fd9f44d23cef57ed"}, "downloads": -1, "filename": "nlp_datasets-0.0.7-py3-none-any.whl", "has_sig": false, "md5_digest": "3fecbae6bbf429efff191421873c8b93", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 27244, "upload_time": "2019-09-19T08:08:23", "upload_time_iso_8601": "2019-09-19T08:08:23.398163Z", "url": "https://files.pythonhosted.org/packages/a4/c6/94b8e5ce99d445cef2f080396e4f516fc8078518faf762a9fa91be78f260/nlp_datasets-0.0.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e79fc4b8d0a30bdb1fb2d9c8561df7a2", "sha256": "3299ada2a73ce0b4d08abad96303347913bb1652991749a829dbf13fabdbdfa7"}, "downloads": -1, "filename": "nlp_datasets-0.0.7.tar.gz", "has_sig": false, "md5_digest": "e79fc4b8d0a30bdb1fb2d9c8561df7a2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11964, "upload_time": "2019-09-19T08:08:26", "upload_time_iso_8601": "2019-09-19T08:08:26.266787Z", "url": "https://files.pythonhosted.org/packages/da/57/650946a6be4420f272d72862ad77fd696fb30b776a097a5d2a097f374477/nlp_datasets-0.0.7.tar.gz", "yanked": false}], "0.0.8": [{"comment_text": "", "digests": {"md5": "c3850635b0af878c58faa25eab1b418a", "sha256": "45017d4f0ef4da1305a0da1c00f2cc56d9aff40e1a1caa8aed29e981d8f7ce7f"}, "downloads": -1, "filename": "nlp_datasets-0.0.8-py3-none-any.whl", "has_sig": false, "md5_digest": "c3850635b0af878c58faa25eab1b418a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 27269, "upload_time": "2019-09-19T08:34:05", "upload_time_iso_8601": "2019-09-19T08:34:05.451688Z", "url": "https://files.pythonhosted.org/packages/68/f6/85a3de9748f214eeb1379b627065d7eb5a8e74975f012be82a7058cbdb73/nlp_datasets-0.0.8-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7855b79866f24560a7e9b42d6d740e26", "sha256": "70b56c6763cab9a7724cbe72104c81ff5648d415c0ab8de4e4c1865543f1015a"}, "downloads": -1, "filename": "nlp_datasets-0.0.8.tar.gz", "has_sig": false, "md5_digest": "7855b79866f24560a7e9b42d6d740e26", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11990, "upload_time": "2019-09-19T08:34:07", "upload_time_iso_8601": "2019-09-19T08:34:07.545685Z", "url": "https://files.pythonhosted.org/packages/a4/43/265835b62f9b46a9ef7c176dbc5776276bb3cfd0bf8a8f1f8acfada7e9bc/nlp_datasets-0.0.8.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "7b0d951b029d84a0eb16cb60f86a3470", "sha256": "bd2d61035ebac6dea8ddf3c5f8829ee6d876030a32bc333ca0f04b2300ed86b6"}, "downloads": -1, "filename": "nlp_datasets-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "7b0d951b029d84a0eb16cb60f86a3470", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 15015, "upload_time": "2019-09-24T07:12:48", "upload_time_iso_8601": "2019-09-24T07:12:48.943539Z", "url": "https://files.pythonhosted.org/packages/60/b3/2e012785890f0488b3702dc420e71f00c9bef00a632ee8790d74a6d20451/nlp_datasets-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0be195584dff3ae4999e5055286b609e", "sha256": "87d75e788b7c5e23d62cb8bee4f04491252bdd17541cde6f39333da1a73bcfd0"}, "downloads": -1, "filename": "nlp_datasets-0.1.0.tar.gz", "has_sig": false, "md5_digest": "0be195584dff3ae4999e5055286b609e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6727, "upload_time": "2019-09-24T07:12:50", "upload_time_iso_8601": "2019-09-24T07:12:50.778653Z", "url": "https://files.pythonhosted.org/packages/b2/c6/3acf3fc371af0886eb1b6cbba0d64e3327d7244611a7047e777eb9b7d5f5/nlp_datasets-0.1.0.tar.gz", "yanked": false}], "1.0.0": [{"comment_text": "", "digests": {"md5": "ab986e8036bb30f207d36652c2d618f8", "sha256": "40712ce259c4ceaa6881c6e401895c43a43ad6befb56b05dbd9d139170268c3e"}, "downloads": -1, "filename": "nlp_datasets-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "ab986e8036bb30f207d36652c2d618f8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 15026, "upload_time": "2019-10-01T04:49:27", "upload_time_iso_8601": "2019-10-01T04:49:27.176089Z", "url": "https://files.pythonhosted.org/packages/b1/92/98db35f683042f37f125efd7635d49df9986920805c395f8f23e22fb940e/nlp_datasets-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5feb594486432ba2a6ccada07962cb4a", "sha256": "ae9531d1180e430970eba420eac217ee08eb287515813954ea9fb8d2a39b027b"}, "downloads": -1, "filename": "nlp_datasets-1.0.0.tar.gz", "has_sig": false, "md5_digest": "5feb594486432ba2a6ccada07962cb4a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6736, "upload_time": "2019-10-01T04:49:29", "upload_time_iso_8601": "2019-10-01T04:49:29.888981Z", "url": "https://files.pythonhosted.org/packages/5a/4e/8753c2ed42964b5f84ad17852f5cbb5b6cd3ec0f3799deca2e8bc76ab60a/nlp_datasets-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "0c5200d7667e5156e4a54f16d65aa5dc", "sha256": "57cb0e97db595f5e517807ba33336d170e27c9ecb9bc1557d11589fa07ea298b"}, "downloads": -1, "filename": "nlp_datasets-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "0c5200d7667e5156e4a54f16d65aa5dc", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 15243, "upload_time": "2019-10-10T06:49:21", "upload_time_iso_8601": "2019-10-10T06:49:21.243999Z", "url": "https://files.pythonhosted.org/packages/0c/3a/8b23023bb8a008c6680a8c434a6d1d1386bdf0d3dc7fe4ec836e011b0516/nlp_datasets-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "10e85249155cbb7f6340b42b2e5f0adb", "sha256": "90d2f58a6aff40ff4a3f8f41c3c134fe6646589504e9210ffba23f6585fa5cb8"}, "downloads": -1, "filename": "nlp_datasets-1.0.1.tar.gz", "has_sig": false, "md5_digest": "10e85249155cbb7f6340b42b2e5f0adb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6898, "upload_time": "2019-10-10T06:49:23", "upload_time_iso_8601": "2019-10-10T06:49:23.010708Z", "url": "https://files.pythonhosted.org/packages/36/77/9d87461da18b068a6c3925de247403ac04d8f4c569b32b41c97e8d92c8b5/nlp_datasets-1.0.1.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "efec1afb80747d2b7efe68701e7d4e00", "sha256": "00140086a4df9f09cf23d8603ca5c997d5fe223c4e0521d11fa48874936b23d4"}, "downloads": -1, "filename": "nlp_datasets-1.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "efec1afb80747d2b7efe68701e7d4e00", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 15465, "upload_time": "2019-10-12T03:42:37", "upload_time_iso_8601": "2019-10-12T03:42:37.937707Z", "url": "https://files.pythonhosted.org/packages/cd/fe/0d41c6d8bffcedcb018875da416ba6e5249a6a7a0121c1ee4fe6584767b8/nlp_datasets-1.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "acb24ba691558ad09972f5bae99fc7d3", "sha256": "2ed9ecec284b7f4110fef68d5c5c27cd8d31057bb92a34953d883d93fa824fa2"}, "downloads": -1, "filename": "nlp_datasets-1.0.2.tar.gz", "has_sig": false, "md5_digest": "acb24ba691558ad09972f5bae99fc7d3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7016, "upload_time": "2019-10-12T03:42:39", "upload_time_iso_8601": "2019-10-12T03:42:39.857790Z", "url": "https://files.pythonhosted.org/packages/ab/0a/8f2e6dd73481b83f8c97eaea1c56a96cd93f626c1135694ebdef3a065d5f/nlp_datasets-1.0.2.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "15faeb5c0e639a54d0444c03358a2d3c", "sha256": "ddf813ed5780befbd9090fd2656b6b225c12863dfeaa68f317f29b02705a69fc"}, "downloads": -1, "filename": "nlp_datasets-1.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "15faeb5c0e639a54d0444c03358a2d3c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 16034, "upload_time": "2019-10-14T09:51:11", "upload_time_iso_8601": "2019-10-14T09:51:11.639915Z", "url": "https://files.pythonhosted.org/packages/e4/bc/ae5dd46fb7630108279438138e894a5b5005cfa4cf63770f7296725b4d63/nlp_datasets-1.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0751899740042a0e1021d6d6953d6daf", "sha256": "83294be9961ce95f428f0199ab291dcba13d39d8108805a29f354d99800cefec"}, "downloads": -1, "filename": "nlp_datasets-1.1.0.tar.gz", "has_sig": false, "md5_digest": "0751899740042a0e1021d6d6953d6daf", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7325, "upload_time": "2019-10-14T09:51:13", "upload_time_iso_8601": "2019-10-14T09:51:13.847736Z", "url": "https://files.pythonhosted.org/packages/5c/93/e7f3b34e5a0b43297262e6443ea6ddfd9d68586b21bd0f8edf9fb60f64de/nlp_datasets-1.1.0.tar.gz", "yanked": false}], "1.1.1": [{"comment_text": "", "digests": {"md5": "de9173657ed4538cc0911fac8f83565f", "sha256": "0c1fab7fcbeec7f86925bae4b84ac1f036f065669dfffcf2bdd1159dee652973"}, "downloads": -1, "filename": "nlp_datasets-1.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "de9173657ed4538cc0911fac8f83565f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 16058, "upload_time": "2019-10-15T07:22:49", "upload_time_iso_8601": "2019-10-15T07:22:49.810579Z", "url": "https://files.pythonhosted.org/packages/07/32/20d1375368df8bfb77a76df5180292fa739082525ec101c973727d1d8904/nlp_datasets-1.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4808d475d49ab3d1b5ef3184687b833e", "sha256": "c1ce431590315f961f0934f432892e634929563dfd734944a96f65ceb9395b8b"}, "downloads": -1, "filename": "nlp_datasets-1.1.1.tar.gz", "has_sig": false, "md5_digest": "4808d475d49ab3d1b5ef3184687b833e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7360, "upload_time": "2019-10-15T07:22:51", "upload_time_iso_8601": "2019-10-15T07:22:51.333764Z", "url": "https://files.pythonhosted.org/packages/80/ae/ba6ddc8c0d2f7373feb799bff33d7b7ab9354607232821aa67a0f6156ba1/nlp_datasets-1.1.1.tar.gz", "yanked": false}], "1.2.0": [{"comment_text": "", "digests": {"md5": "bf95ff1e68559a3f4d9bcc854a45e85d", "sha256": "e7ac41b51674e321d0727c698f0d5c63d6d68d08c5481e9ddc3826140f3df158"}, "downloads": -1, "filename": "nlp_datasets-1.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "bf95ff1e68559a3f4d9bcc854a45e85d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 15834, "upload_time": "2019-11-08T07:25:04", "upload_time_iso_8601": "2019-11-08T07:25:04.729159Z", "url": "https://files.pythonhosted.org/packages/a1/0a/e57f734a5e5cd9cbb4c12f601f4467c8b5d3631ed7a1449cadd218912eae/nlp_datasets-1.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3426ad7bf075f43e885fe53eb07efac6", "sha256": "3a69ba47f66ebb46211162f8a8245744fb07a8d9f37f486d76e5d291ddbb21ca"}, "downloads": -1, "filename": "nlp_datasets-1.2.0.tar.gz", "has_sig": false, "md5_digest": "3426ad7bf075f43e885fe53eb07efac6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7186, "upload_time": "2019-11-08T07:25:06", "upload_time_iso_8601": "2019-11-08T07:25:06.938776Z", "url": "https://files.pythonhosted.org/packages/08/29/697befb99882c42eddd1fe4690bd45369c29dd4e85a5257b2c91baf19156/nlp_datasets-1.2.0.tar.gz", "yanked": false}], "1.2.1": [{"comment_text": "", "digests": {"md5": "9e7df63cad71d03c8efcfea65faa17e0", "sha256": "d0b930fc9cb08f4b14905902073f32a3ba218664173b2364d7dafd6c5cdc90d4"}, "downloads": -1, "filename": "nlp_datasets-1.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "9e7df63cad71d03c8efcfea65faa17e0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 16338, "upload_time": "2019-11-16T09:33:05", "upload_time_iso_8601": "2019-11-16T09:33:05.858717Z", "url": "https://files.pythonhosted.org/packages/a1/d4/800e32a1f4cde4eccf4c2fe453641425dfe51d5116b5a77a04fea2d06e01/nlp_datasets-1.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "637bf24170a32b28638c93a59ba0f887", "sha256": "47dec156991bb3232b438a2ec799278921492bdee3836e297e2ad2ebafa4cbbd"}, "downloads": -1, "filename": "nlp_datasets-1.2.1.tar.gz", "has_sig": false, "md5_digest": "637bf24170a32b28638c93a59ba0f887", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7714, "upload_time": "2019-11-16T09:33:07", "upload_time_iso_8601": "2019-11-16T09:33:07.712949Z", "url": "https://files.pythonhosted.org/packages/fe/c8/018db464d42ae4fe496b9be9fc40b38374db673be651ee2b48fe64d8d183/nlp_datasets-1.2.1.tar.gz", "yanked": false}], "1.3.0": [{"comment_text": "", "digests": {"md5": "5b325c9f771ad388eb93b49fd1a4014c", "sha256": "94763d7aed480fe08b613e65045622b6cb8be34f145dbdbd342389a5cb7cd4ad"}, "downloads": -1, "filename": "nlp_datasets-1.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "5b325c9f771ad388eb93b49fd1a4014c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 20759, "upload_time": "2019-12-31T07:24:30", "upload_time_iso_8601": "2019-12-31T07:24:30.129394Z", "url": "https://files.pythonhosted.org/packages/69/40/77c7748eaa1a22f478bc0f86092a696708cb371420026637605d85bc92a9/nlp_datasets-1.3.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b6769c9b10c8d05ec8d9b57d437600ad", "sha256": "3c8f94180cd245587756ca55fa45d20093b82cc469e81dec4fa7cd4f443e48aa"}, "downloads": -1, "filename": "nlp_datasets-1.3.0.tar.gz", "has_sig": false, "md5_digest": "b6769c9b10c8d05ec8d9b57d437600ad", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8574, "upload_time": "2019-12-31T07:24:31", "upload_time_iso_8601": "2019-12-31T07:24:31.869529Z", "url": "https://files.pythonhosted.org/packages/fc/f7/516d1a01b83d15fc299842452d686c68d1d89dfd53747db260d22daa0bfa/nlp_datasets-1.3.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "5b325c9f771ad388eb93b49fd1a4014c", "sha256": "94763d7aed480fe08b613e65045622b6cb8be34f145dbdbd342389a5cb7cd4ad"}, "downloads": -1, "filename": "nlp_datasets-1.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "5b325c9f771ad388eb93b49fd1a4014c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 20759, "upload_time": "2019-12-31T07:24:30", "upload_time_iso_8601": "2019-12-31T07:24:30.129394Z", "url": "https://files.pythonhosted.org/packages/69/40/77c7748eaa1a22f478bc0f86092a696708cb371420026637605d85bc92a9/nlp_datasets-1.3.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b6769c9b10c8d05ec8d9b57d437600ad", "sha256": "3c8f94180cd245587756ca55fa45d20093b82cc469e81dec4fa7cd4f443e48aa"}, "downloads": -1, "filename": "nlp_datasets-1.3.0.tar.gz", "has_sig": false, "md5_digest": "b6769c9b10c8d05ec8d9b57d437600ad", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8574, "upload_time": "2019-12-31T07:24:31", "upload_time_iso_8601": "2019-12-31T07:24:31.869529Z", "url": "https://files.pythonhosted.org/packages/fc/f7/516d1a01b83d15fc299842452d686c68d1d89dfd53747db260d22daa0bfa/nlp_datasets-1.3.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:45:11 2020"}