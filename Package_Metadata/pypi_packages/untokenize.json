{"info": {"author": "Steven Myint", "author_email": "UNKNOWN", "bugtrack_url": null, "classifiers": ["Environment :: Console", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 2.6", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3"], "description": "============\nuntokenize\n============\n\n*untokenize* transforms tokens into source code. Unlike the standard library's\n``tokenize.untokenize()``, it preserves the original whitespace between tokens.\n\n.. image:: https://travis-ci.org/myint/untokenize.png?branch=master\n    :target: https://travis-ci.org/myint/untokenize\n    :alt: Build status\n\n\nUsage\n=====\n\n.. code-block:: python\n\n    import untokenize\n    source_code = untokenize.untokenize(tokens)\n\n\nTests\n=====\n\nTo run the unit tests::\n\n    $ ./test_untokenize.py\n\nThere is also an acid test. It tokenizes Python code and confirms that the code\ngenerated by untokenize exactly matches the original source code from before\ntokenization::\n\n    $ ./test_acid.py", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/myint/untokenize", "keywords": "tokenize,untokenize,transform,generate", "license": "Expat License", "maintainer": null, "maintainer_email": null, "name": "untokenize", "package_url": "https://pypi.org/project/untokenize/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/untokenize/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/myint/untokenize"}, "release_url": "https://pypi.org/project/untokenize/0.1.1/", "requires_dist": null, "requires_python": null, "summary": "Transforms tokens into original source code (while preserving whitespace).", "version": "0.1.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><em>untokenize</em> transforms tokens into source code. Unlike the standard library\u2019s\n<tt>tokenize.untokenize()</tt>, it preserves the original whitespace between tokens.</p>\n<a href=\"https://travis-ci.org/myint/untokenize\" rel=\"nofollow\"><img alt=\"Build status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fcf9f3167fbd6aa4d8f5dadb1229fb22bacd63c0/68747470733a2f2f7472617669732d63692e6f72672f6d79696e742f756e746f6b656e697a652e706e673f6272616e63683d6d6173746572\"></a>\n<div id=\"usage\">\n<h2>Usage</h2>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">untokenize</span>\n<span class=\"n\">source_code</span> <span class=\"o\">=</span> <span class=\"n\">untokenize</span><span class=\"o\">.</span><span class=\"n\">untokenize</span><span class=\"p\">(</span><span class=\"n\">tokens</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"tests\">\n<h2>Tests</h2>\n<p>To run the unit tests:</p>\n<pre>$ ./test_untokenize.py\n</pre>\n<p>There is also an acid test. It tokenizes Python code and confirms that the code\ngenerated by untokenize exactly matches the original source code from before\ntokenization:</p>\n<pre>$ ./test_acid.py\n</pre>\n</div>\n\n          </div>"}, "last_serial": 994436, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "1642edb4623fd643219a7338e51abd4d", "sha256": "0c894df1bedea633faea9e6f77229add67b01727770bbc1fd3d016e201d4af4c"}, "downloads": -1, "filename": "untokenize-0.1.tar.gz", "has_sig": false, "md5_digest": "1642edb4623fd643219a7338e51abd4d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2092, "upload_time": "2013-07-03T15:14:26", "upload_time_iso_8601": "2013-07-03T15:14:26.807409Z", "url": "https://files.pythonhosted.org/packages/72/2b/571f6a7e5606373190de1812eb2ab3a3380b235a8883c0d20f9e2ba9a6f0/untokenize-0.1.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "50d325dff09208c624cc603fad33bb0d", "sha256": "3865dbbbb8efb4bb5eaa72f1be7f3e0be00ea8b7f125c69cbd1f5fda926f37a2"}, "downloads": -1, "filename": "untokenize-0.1.1.tar.gz", "has_sig": false, "md5_digest": "50d325dff09208c624cc603fad33bb0d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3099, "upload_time": "2014-02-08T16:30:40", "upload_time_iso_8601": "2014-02-08T16:30:40.631383Z", "url": "https://files.pythonhosted.org/packages/f7/46/e7cea8159199096e1df52da20a57a6665da80c37fb8aeb848a3e47442c32/untokenize-0.1.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "50d325dff09208c624cc603fad33bb0d", "sha256": "3865dbbbb8efb4bb5eaa72f1be7f3e0be00ea8b7f125c69cbd1f5fda926f37a2"}, "downloads": -1, "filename": "untokenize-0.1.1.tar.gz", "has_sig": false, "md5_digest": "50d325dff09208c624cc603fad33bb0d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3099, "upload_time": "2014-02-08T16:30:40", "upload_time_iso_8601": "2014-02-08T16:30:40.631383Z", "url": "https://files.pythonhosted.org/packages/f7/46/e7cea8159199096e1df52da20a57a6665da80c37fb8aeb848a3e47442c32/untokenize-0.1.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:40:02 2020"}