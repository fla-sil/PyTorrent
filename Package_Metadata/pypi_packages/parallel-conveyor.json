{"info": {"author": "Conveyor Team", "author_email": "", "bugtrack_url": null, "classifiers": ["Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# Conveyor - simple, intuitive pipelining\nConveyor is a multiprocessing framework to facilitate writing data pipelines and job systems in Python. The Conveyor provides five main features a developer can make use of: __processors, pipes, replicated forks, balanced forks__  and __joins__.\n\n### Processors\n__Processors__ are the Conveyor's logical compute cores. Each processor will take in some data as input, transform that input and optionally return an output. Processors can maintain an internal state. Each of these processors is user-defined and wrapped in its own Python instance, allowing parallel execution of multiple processors at the same time. A user can specify sets of processors that should execute serially as joined by pipes or sets of processors that should act in parallel as defined by forks.\n\n### Pipes\n__Pipes__ serve as links between processors. They act as a stream, transporting data from one point in the pipeline to another. Pipes are implemented as a producer-consumer buffer where a leading processor acts as the producer and a trailing processor acts as a consumer.\n\n### Replicated Forks\n__Replicated Forks__ allow one processor to split output data into multiple copies so that multiple processors can then perform operations using the entire output data. This will allow multiple different ML models to be trained and tested in parallel. The input-output numbering of the many-to-one relationship of forks is primarily user defined.\n\n### Balanced Forks\n__Balanced Forks__ allow one processor to balance a stream of data over multiple consumer processors. This will serve to minimize the effect of pipe stalling for larger data sets. The input-output numbering of the many-to-one relationship of forks is primarily determined by pipe stalling detected at runtime and the number of physical cores available.\n\n### Joins\n__Joins__ allow multiple processors to combine their data streams into one logical pipe. The combined stream can then be forked again for the next step of the pipeline, processed by a single processor, or serve as output at the end of the pipeline.\n\n# Rules for constructing pipelines\nIn order to allow developers to use the pipeline however they see fit, Conveyor attempts to be unopinionated, however there must be some rules to keep the pipelines from becoming nonsensical or a programming language of it's own. The pipeline should be kept simple and most of the program's logic should be done in the processor steps.\n- All elements in the pipeline must be Conveyor Types\n- A Pipeline must start with a process\n- If not starting the pipeline, every Processor must be preceded by a Pipe, Fork, or Join\n    - If a Pipe is not explicitly created, it will be automatically inserted, however a warning will be raised\n- Every Fork and Join must be preceded by a pipe\n\n# Testing\nTo run the tests, ensure nose is installed and run nosetests from the project directory\n\n`pip3 install nose && nosetests`\n\n# Building from source\nTo build the distribution archives, you will need the latest version of setuptools and wheel.\n\n`python3 -m pip install --user --upgrade setuptools wheel`\n\nRun `setup.py` to build using the following command:\n\n`python3 setup.py sdist bdist_wheel`\n\nThe compiled `.whl` and `.tar.gz` files will be in the `/dist` directory.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/DanielKrolopp/Conveyor", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "parallel-conveyor", "package_url": "https://pypi.org/project/parallel-conveyor/", "platform": "", "project_url": "https://pypi.org/project/parallel-conveyor/", "project_urls": {"Homepage": "https://github.com/DanielKrolopp/Conveyor"}, "release_url": "https://pypi.org/project/parallel-conveyor/0.0.2/", "requires_dist": null, "requires_python": ">=3.8", "summary": "Simple, intuitive pipelining in Python", "version": "0.0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Conveyor - simple, intuitive pipelining</h1>\n<p>Conveyor is a multiprocessing framework to facilitate writing data pipelines and job systems in Python. The Conveyor provides five main features a developer can make use of: <strong>processors, pipes, replicated forks, balanced forks</strong>  and <strong>joins</strong>.</p>\n<h3>Processors</h3>\n<p><strong>Processors</strong> are the Conveyor's logical compute cores. Each processor will take in some data as input, transform that input and optionally return an output. Processors can maintain an internal state. Each of these processors is user-defined and wrapped in its own Python instance, allowing parallel execution of multiple processors at the same time. A user can specify sets of processors that should execute serially as joined by pipes or sets of processors that should act in parallel as defined by forks.</p>\n<h3>Pipes</h3>\n<p><strong>Pipes</strong> serve as links between processors. They act as a stream, transporting data from one point in the pipeline to another. Pipes are implemented as a producer-consumer buffer where a leading processor acts as the producer and a trailing processor acts as a consumer.</p>\n<h3>Replicated Forks</h3>\n<p><strong>Replicated Forks</strong> allow one processor to split output data into multiple copies so that multiple processors can then perform operations using the entire output data. This will allow multiple different ML models to be trained and tested in parallel. The input-output numbering of the many-to-one relationship of forks is primarily user defined.</p>\n<h3>Balanced Forks</h3>\n<p><strong>Balanced Forks</strong> allow one processor to balance a stream of data over multiple consumer processors. This will serve to minimize the effect of pipe stalling for larger data sets. The input-output numbering of the many-to-one relationship of forks is primarily determined by pipe stalling detected at runtime and the number of physical cores available.</p>\n<h3>Joins</h3>\n<p><strong>Joins</strong> allow multiple processors to combine their data streams into one logical pipe. The combined stream can then be forked again for the next step of the pipeline, processed by a single processor, or serve as output at the end of the pipeline.</p>\n<h1>Rules for constructing pipelines</h1>\n<p>In order to allow developers to use the pipeline however they see fit, Conveyor attempts to be unopinionated, however there must be some rules to keep the pipelines from becoming nonsensical or a programming language of it's own. The pipeline should be kept simple and most of the program's logic should be done in the processor steps.</p>\n<ul>\n<li>All elements in the pipeline must be Conveyor Types</li>\n<li>A Pipeline must start with a process</li>\n<li>If not starting the pipeline, every Processor must be preceded by a Pipe, Fork, or Join\n<ul>\n<li>If a Pipe is not explicitly created, it will be automatically inserted, however a warning will be raised</li>\n</ul>\n</li>\n<li>Every Fork and Join must be preceded by a pipe</li>\n</ul>\n<h1>Testing</h1>\n<p>To run the tests, ensure nose is installed and run nosetests from the project directory</p>\n<p><code>pip3 install nose &amp;&amp; nosetests</code></p>\n<h1>Building from source</h1>\n<p>To build the distribution archives, you will need the latest version of setuptools and wheel.</p>\n<p><code>python3 -m pip install --user --upgrade setuptools wheel</code></p>\n<p>Run <code>setup.py</code> to build using the following command:</p>\n<p><code>python3 setup.py sdist bdist_wheel</code></p>\n<p>The compiled <code>.whl</code> and <code>.tar.gz</code> files will be in the <code>/dist</code> directory.</p>\n\n          </div>"}, "last_serial": 7142032, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "80feb4b9a4d79a2c47d0e02f0788d434", "sha256": "cf9d5099146c41336017d256aedc9d4ab8e2ccfac75ec872f719ea303e904bb0"}, "downloads": -1, "filename": "parallel_conveyor-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "80feb4b9a4d79a2c47d0e02f0788d434", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 16598, "upload_time": "2020-05-01T01:10:23", "upload_time_iso_8601": "2020-05-01T01:10:23.533033Z", "url": "https://files.pythonhosted.org/packages/0c/80/f032d2eee0866038c6df670e3d705c257762f23800bdc478e68230570fc2/parallel_conveyor-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "37c388f257b84f84774adb943037a38a", "sha256": "47b5dbbd87f62c2e30db0d9029cffd21cc2d4bd10887ace24758b65330db6e92"}, "downloads": -1, "filename": "parallel-conveyor-0.0.1.tar.gz", "has_sig": false, "md5_digest": "37c388f257b84f84774adb943037a38a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 10655, "upload_time": "2020-04-30T06:27:19", "upload_time_iso_8601": "2020-04-30T06:27:19.192758Z", "url": "https://files.pythonhosted.org/packages/34/59/80435a18f8f871a845c16df9357597bec8a1822ffd9fbca26369159739b2/parallel-conveyor-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "331c9df568f3468a55edcabe2a04ba3f", "sha256": "63ed38c9d1984bda0a6b426e486a56b5eab413c5e8002ff65ba34e4274542ecb"}, "downloads": -1, "filename": "parallel_conveyor-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "331c9df568f3468a55edcabe2a04ba3f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.8", "size": 16600, "upload_time": "2020-05-01T01:12:10", "upload_time_iso_8601": "2020-05-01T01:12:10.701072Z", "url": "https://files.pythonhosted.org/packages/cb/49/b9dc609a8f2f215447b0e4252de9bdbc6f4caba8c6d648472fd38bebdd36/parallel_conveyor-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "110ada202ababf90d297ef4a4ebfcd79", "sha256": "081cf1b2af9b9edbdad02a9fb01d3ebec6a8c53c32bae09d36aa35c4b96f2c1c"}, "downloads": -1, "filename": "parallel-conveyor-0.0.2.tar.gz", "has_sig": false, "md5_digest": "110ada202ababf90d297ef4a4ebfcd79", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.8", "size": 10575, "upload_time": "2020-05-01T01:12:11", "upload_time_iso_8601": "2020-05-01T01:12:11.887029Z", "url": "https://files.pythonhosted.org/packages/fb/65/f220aca039362f90304aaaf2b15096476fb9baedb2c477c00d985c8d4249/parallel-conveyor-0.0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "331c9df568f3468a55edcabe2a04ba3f", "sha256": "63ed38c9d1984bda0a6b426e486a56b5eab413c5e8002ff65ba34e4274542ecb"}, "downloads": -1, "filename": "parallel_conveyor-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "331c9df568f3468a55edcabe2a04ba3f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.8", "size": 16600, "upload_time": "2020-05-01T01:12:10", "upload_time_iso_8601": "2020-05-01T01:12:10.701072Z", "url": "https://files.pythonhosted.org/packages/cb/49/b9dc609a8f2f215447b0e4252de9bdbc6f4caba8c6d648472fd38bebdd36/parallel_conveyor-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "110ada202ababf90d297ef4a4ebfcd79", "sha256": "081cf1b2af9b9edbdad02a9fb01d3ebec6a8c53c32bae09d36aa35c4b96f2c1c"}, "downloads": -1, "filename": "parallel-conveyor-0.0.2.tar.gz", "has_sig": false, "md5_digest": "110ada202ababf90d297ef4a4ebfcd79", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.8", "size": 10575, "upload_time": "2020-05-01T01:12:11", "upload_time_iso_8601": "2020-05-01T01:12:11.887029Z", "url": "https://files.pythonhosted.org/packages/fb/65/f220aca039362f90304aaaf2b15096476fb9baedb2c477c00d985c8d4249/parallel-conveyor-0.0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:58:39 2020"}