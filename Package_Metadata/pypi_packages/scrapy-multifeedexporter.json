{"info": {"author": "Gabriel Birke", "author_email": "gb@birke-software.de", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: No Input/Output (Daemon)", "Framework :: Scrapy", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python"], "description": "scrapy-multifeedexporter\n========================\n\nThis `Scrapy <http://scrapy.org/>`__ extension exports scraped items of\ndifferent types to multiple feeds. By default each item gets its own\nfeed.\n\nInstallation\n------------\n\n.. code-block:: bash\n\n    $ pip install scrapy-multifeedexporter\n\nConfiguration\n-------------\n\nYou'll have to switch the default ``FeedExporter`` with\n``MultiFeedExporter`` by adding the following lines to the\n``settings.py`` file of your spider:\n\n.. code:: python\n\n    from multifeedexporter import MultiFeedExporter\n\n    EXTENSIONS = {\n        'scrapy.contrib.feedexport.FeedExporter': None,\n        'multifeedexporter.MultiFeedExporter': 500,\n    }\n\n    # Automatically configure available item names from your module\n    MULTIFEEDEXPORTER_ITEMS = MultiFeedExporter.get_bot_items(BOT_NAME)\n\nUsage\n-----\n\nWhen calling ``scrapy crawl`` you need to use the ``%(item_name)s``\nplaceholder in the output file/URI name. The following calls to\n``scrapy crawl`` demonstrate the placeholder:\n\n.. code:: bash\n\n    $ scrapy crawl -o \"spider_name_%(item_name)s.csv\" -t csv spider_name\n    $ scrapy crawl -o \"ftp://foo:bar@example.com/spider_name_%(item_name)s.csv\" -t csv spider_name\n\nIf you omit the placeholder, all items will be placed in one file.\n\nLicense\n-------\n\nscrapy-multifeedexporter is published under MIT license", "description_content_type": null, "docs_url": null, "download_url": null, "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://github.com/gbirke/scrapy-multifeedexporter", "keywords": "scrapy crawl scraping", "license": "The MIT License (MIT)", "maintainer": null, "maintainer_email": null, "name": "scrapy-multifeedexporter", "package_url": "https://pypi.org/project/scrapy-multifeedexporter/", "platform": "Any", "project_url": "https://pypi.org/project/scrapy-multifeedexporter/", "project_urls": {"Homepage": "http://github.com/gbirke/scrapy-multifeedexporter"}, "release_url": "https://pypi.org/project/scrapy-multifeedexporter/0.1.1/", "requires_dist": null, "requires_python": null, "summary": "Export scraped items of different types to multiple feeds.", "version": "0.1.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>This <a href=\"http://scrapy.org/\" rel=\"nofollow\">Scrapy</a> extension exports scraped items of\ndifferent types to multiple feeds. By default each item gets its own\nfeed.</p>\n<div id=\"installation\">\n<h2>Installation</h2>\n<pre>$ pip install scrapy-multifeedexporter\n</pre>\n</div>\n<div id=\"configuration\">\n<h2>Configuration</h2>\n<p>You\u2019ll have to switch the default <tt>FeedExporter</tt> with\n<tt>MultiFeedExporter</tt> by adding the following lines to the\n<tt>settings.py</tt> file of your spider:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">multifeedexporter</span> <span class=\"kn\">import</span> <span class=\"n\">MultiFeedExporter</span>\n\n<span class=\"n\">EXTENSIONS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.contrib.feedexport.FeedExporter'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n    <span class=\"s1\">'multifeedexporter.MultiFeedExporter'</span><span class=\"p\">:</span> <span class=\"mi\">500</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n\n<span class=\"c1\"># Automatically configure available item names from your module</span>\n<span class=\"n\">MULTIFEEDEXPORTER_ITEMS</span> <span class=\"o\">=</span> <span class=\"n\">MultiFeedExporter</span><span class=\"o\">.</span><span class=\"n\">get_bot_items</span><span class=\"p\">(</span><span class=\"n\">BOT_NAME</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"usage\">\n<h2>Usage</h2>\n<p>When calling <tt>scrapy crawl</tt> you need to use the <tt>%(item_name)s</tt>\nplaceholder in the output file/URI name. The following calls to\n<tt>scrapy crawl</tt> demonstrate the placeholder:</p>\n<pre>$ scrapy crawl -o <span class=\"s2\">\"spider_name_%(item_name)s.csv\"</span> -t csv spider_name\n$ scrapy crawl -o <span class=\"s2\">\"ftp://foo:bar@example.com/spider_name_%(item_name)s.csv\"</span> -t csv spider_name\n</pre>\n<p>If you omit the placeholder, all items will be placed in one file.</p>\n</div>\n<div id=\"license\">\n<h2>License</h2>\n<p>scrapy-multifeedexporter is published under MIT license</p>\n</div>\n\n          </div>"}, "last_serial": 1250560, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "47f9382d1863b2389159b0479ce9114a", "sha256": "fc19904e4e956b5f2ce785a1f85a328aef54f00a3f1f31062a3a7c1843ae2386"}, "downloads": -1, "filename": "scrapy-multifeedexporter-0.1.0.tar.gz", "has_sig": false, "md5_digest": "47f9382d1863b2389159b0479ce9114a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2655, "upload_time": "2014-09-04T11:42:51", "upload_time_iso_8601": "2014-09-04T11:42:51.394951Z", "url": "https://files.pythonhosted.org/packages/aa/db/d39ff24f9bec5bdc63fc05a87d5106b7d4a0df684045e9129490aa215367/scrapy-multifeedexporter-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "235617822829e0ae92424e76633aceff", "sha256": "6bf3fc7d192b68dbe1b33d823da89298a234af95f7b346cbb2cf3edf9c6378d3"}, "downloads": -1, "filename": "scrapy-multifeedexporter-0.1.1.tar.gz", "has_sig": false, "md5_digest": "235617822829e0ae92424e76633aceff", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2659, "upload_time": "2014-10-07T13:25:51", "upload_time_iso_8601": "2014-10-07T13:25:51.300985Z", "url": "https://files.pythonhosted.org/packages/49/95/9956776a86f0c2318a0ab33fa7b3897bb571e0932bad39f79db809b6bdd7/scrapy-multifeedexporter-0.1.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "235617822829e0ae92424e76633aceff", "sha256": "6bf3fc7d192b68dbe1b33d823da89298a234af95f7b346cbb2cf3edf9c6378d3"}, "downloads": -1, "filename": "scrapy-multifeedexporter-0.1.1.tar.gz", "has_sig": false, "md5_digest": "235617822829e0ae92424e76633aceff", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2659, "upload_time": "2014-10-07T13:25:51", "upload_time_iso_8601": "2014-10-07T13:25:51.300985Z", "url": "https://files.pythonhosted.org/packages/49/95/9956776a86f0c2318a0ab33fa7b3897bb571e0932bad39f79db809b6bdd7/scrapy-multifeedexporter-0.1.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:56:45 2020"}