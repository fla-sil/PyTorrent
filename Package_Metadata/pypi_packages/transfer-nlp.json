{"info": {"author": "Peter Martigny", "author_email": "peter.martigny@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3.6", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "<img src=\"https://github.com/feedly/transfer-nlp/blob/v0.1/data/images/TransferNLP_Logo.jpg\" width=\"1000\">\n\nWelcome to the Transfer NLP library, a framework built on top of PyTorch whose goal is to progressively achieve 2 kinds of Transfer:\n\n- **easy transfer of code**: the framework should be modular enough so that you don't have to re-write everything each time you experiment with a new architecture / a new kind of task\n- **easy transfer learning**: the framework should be able to easily interact with pre-trained models and manipulate them in order to fine-tune some of their parts.\n\nYou can have an overview of the high-level API on this [Colab Notebook](https://colab.research.google.com/drive/1DtC31eUejz1T0DsaEfHq_DOxEfanmrG1#scrollTo=Xzu3HPdGrnza), which shows how to use the framework on several examples.\nAll examples on these notebooks embed in-cell Tensorboard training monitoring!\n\nFor an example of pre-trained model finetuning, we provide a short executable tutorial on BertClassifier finetuning on this [Colab Notebook](https://colab.research.google.com/drive/10Toyi0V4fp0Sn33RSPCkoPrtf5FVpm3q#scrollTo=PXJFfulWkEl6)\n\n# Set up your environment\n\n```\nmkvirtualenv transfernlp\nworkon transfernlp\n\ngit clone https://github.com/feedly/transfer-nlp.git\ncd transfer-nlp\npip install -r requirements.txt\n```\n\n- create a virtual environment: `mkvirtualenv YourEnvName` (with mkvirtualenv or your choice of virtual env manager)\n- clone the repository: `git clone https://github.com/feedly/transfer-nlp.git`\n- Install requirements: `pip install -r requirements.txt`\n\nThe library is available on [Pypi](https://pypi.org/project/transfer-nlp/) but ```pip install transfer-nlp``` is not recommended yet.\n\n# Documentation\nAPI documentation and an overview of the library can be found [here](https://transfer-nlp.readthedocs.io/en/latest/)\n\n# High-Level usage of the library\n\nYou can have a look at the [Colab Notebook](https://colab.research.google.com/drive/1DtC31eUejz1T0DsaEfHq_DOxEfanmrG1#scrollTo=IuBcpSdZtcmo) to get a simple sense of the library usage.\n\nThe core of the library is made of an experiment builder: you define the different objects that your experiment needs, and the configuration loader builds them in a nice way:\n\n```\nfrom transfer_nlp.plugins.config import ExperimentConfig\n\n# Launch an experiment\nconfig_file  = {...}  # Dictionary config file, or str/Path to a json config file\nexperiment = ExperimentConfig(experiment=config_file)\n\n# Interaact with the experiment's objects, e.g. launch a training job of a `trainer` object\nexperiment['trainer'].train()\n\n# Another use of experiment object: use the `predictor` object for inference\ninput_json = {\"inputs\": [Some Examples]}\noutput_json = experiment['predictor'].json_to_json(input_json=input_json)\n```\n\n# How to experiment with the library?\nFor reproducible research and easy ablation studies, the library enforces the use of configuration files for experiments.\n\nIn Transfer-NLP, an experiment config file contains all the necessary information to define entirely the experiment.\nThis is where you will insert names of the different components your experiment will use.\nTransfer-NLP makes use of the Inversion of Control pattern, which allows you to define any kind of classes you could need, and the `ExperimentConfig.from_json` method will create a dictionnary and instatiate your objects accordingly.\n\nTo use your own classes inside Transfer-NLP, you need to register them using the `@register_plugin` decorator. Instead of using a different registry for each kind of component (Models, Data loaders, Vectorizers, Optimizers, ...), only a single registry is used here, in order to enforce total customization.\n\nCurrently, the config file logic has 3 kinds of components:\n\n- simple parameters: those are parameters which you know the value in advance: \n```\n{\"initial_learning_rate\": 0.01,\n\"embedding_dim\": 100,...}\n```\n- simple lists: similar to simple parameters, but as a list:\n```\n{\"layers_dropout\": [0.1, 0.2, 0.3], ...}\n```\n- Complex config: this is where the library instantiates your objects: every object needs to have its `_name` specified (the name of a class that you have register through the `@register_plugin` decorator), and its parameters defined. If your class has default parameters and your config file doesn't contain them, objects will be instantiated as default. Otherwise the parameters have to be present in the config file. Sometimes, initialization parameters are not available before launching the experiment. E.g., suppose your Model object needs a Vocabulary size as init input. The config file logic here makes it easy to deal with this while keeping the library code very general. \n\nYou can have a look at the [tests](https://github.com/feedly/transfer-nlp/blob/master/tests/plugins/test_config.py) for examples of experiment settings the config loader can build.\nAdditionally we provide runnable experiments in [`experiments/`](https://github.com/feedly/transfer-nlp/tree/master/experiments).\n\n# Usage Pipeline\nThe goal of the config file is to load different objects and run your experiment from it. \n\nA very common object to use is trainer, which you will run during your experiment. We provide a `BasicTrainer` in [`transfer_nlp.plugins.trainers.py`](https://github.com/feedly/transfer-nlp/blob/master/transfer_nlp/plugins/trainers.py).\nThis basic trainer will take a model and some data as input, and run a whole training pipeline. We make use of the [PyTorch-Ignite](https://github.com/pytorch/ignite) library to monitor events during training (logging some metrics, manipulating learning rates, checkpointing models, etc...). Tensorboard logs are also included as an option, you will have to specify a `tensorboard_logs` simple parameters path in the config file. Then just run `tensorboard --logdir=path/to/logs` in a terminal and you can monitor your experiment while it's training!\nTensorboard comes with very nice utilities to keep track of the norms of your model weights, histograms, distributions, visualizing embeddings, etc so we really recommend using it.\n\n<img src=\"https://github.com/feedly/transfer-nlp/blob/v0.1/data/images/tensorboard.png\" width=\"1000\">\n\n# Slack integration\nWhile experimenting with your own models / data, the training might take some time. To get notified when your training finishes or crashes, you can use the simple library [knockknock](https://github.com/huggingface/knockknock) by folks at HuggingFace, which add a simple decorator to your running function to notify you via Slack, E-mail, etc.\n\n\n# Some objectives to reach:\n - Include examples using state of the art pre-trained models\n - Include linguistic properties to models\n - Experiment with RL for sequential tasks\n - Include probing tasks to try to understand the properties that are learned by the models\n\n# Acknowledgment\nThe library has been inspired by the reading of <cite>[\"Natural Language Processing with PyTorch\"](https://www.amazon.com/dp/1491978236/)<cite> by Delip Rao and Brian McMahan.\nExperiments in [`experiments`](https://github.com/feedly/transfer-nlp/tree/master/experiments/deep_learning_with_pytorch), the Vocabulary building block and embeddings nearest neighbors are taken or adapted from the code provided in the book.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/feedly/transfer-nlp/archive/v0.1.5.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/feedly/transfer-nlp", "keywords": "NLP,transfer learning,language models,NLU", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "transfer-nlp", "package_url": "https://pypi.org/project/transfer-nlp/", "platform": "", "project_url": "https://pypi.org/project/transfer-nlp/", "project_urls": {"Download": "https://github.com/feedly/transfer-nlp/archive/v0.1.5.tar.gz", "Homepage": "https://github.com/feedly/transfer-nlp"}, "release_url": "https://pypi.org/project/transfer-nlp/0.1.5/", "requires_dist": null, "requires_python": "", "summary": "NLP library designed for flexible research and development", "version": "0.1.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/256d59352cd8fc16b30d0c66037224fe30b3002c/68747470733a2f2f6769746875622e636f6d2f666565646c792f7472616e736665722d6e6c702f626c6f622f76302e312f646174612f696d616765732f5472616e736665724e4c505f4c6f676f2e6a7067\" width=\"1000\">\n<p>Welcome to the Transfer NLP library, a framework built on top of PyTorch whose goal is to progressively achieve 2 kinds of Transfer:</p>\n<ul>\n<li><strong>easy transfer of code</strong>: the framework should be modular enough so that you don't have to re-write everything each time you experiment with a new architecture / a new kind of task</li>\n<li><strong>easy transfer learning</strong>: the framework should be able to easily interact with pre-trained models and manipulate them in order to fine-tune some of their parts.</li>\n</ul>\n<p>You can have an overview of the high-level API on this <a href=\"https://colab.research.google.com/drive/1DtC31eUejz1T0DsaEfHq_DOxEfanmrG1#scrollTo=Xzu3HPdGrnza\" rel=\"nofollow\">Colab Notebook</a>, which shows how to use the framework on several examples.\nAll examples on these notebooks embed in-cell Tensorboard training monitoring!</p>\n<p>For an example of pre-trained model finetuning, we provide a short executable tutorial on BertClassifier finetuning on this <a href=\"https://colab.research.google.com/drive/10Toyi0V4fp0Sn33RSPCkoPrtf5FVpm3q#scrollTo=PXJFfulWkEl6\" rel=\"nofollow\">Colab Notebook</a></p>\n<h1>Set up your environment</h1>\n<pre><code>mkvirtualenv transfernlp\nworkon transfernlp\n\ngit clone https://github.com/feedly/transfer-nlp.git\ncd transfer-nlp\npip install -r requirements.txt\n</code></pre>\n<ul>\n<li>create a virtual environment: <code>mkvirtualenv YourEnvName</code> (with mkvirtualenv or your choice of virtual env manager)</li>\n<li>clone the repository: <code>git clone https://github.com/feedly/transfer-nlp.git</code></li>\n<li>Install requirements: <code>pip install -r requirements.txt</code></li>\n</ul>\n<p>The library is available on <a href=\"https://pypi.org/project/transfer-nlp/\" rel=\"nofollow\">Pypi</a> but <code>pip install transfer-nlp</code> is not recommended yet.</p>\n<h1>Documentation</h1>\n<p>API documentation and an overview of the library can be found <a href=\"https://transfer-nlp.readthedocs.io/en/latest/\" rel=\"nofollow\">here</a></p>\n<h1>High-Level usage of the library</h1>\n<p>You can have a look at the <a href=\"https://colab.research.google.com/drive/1DtC31eUejz1T0DsaEfHq_DOxEfanmrG1#scrollTo=IuBcpSdZtcmo\" rel=\"nofollow\">Colab Notebook</a> to get a simple sense of the library usage.</p>\n<p>The core of the library is made of an experiment builder: you define the different objects that your experiment needs, and the configuration loader builds them in a nice way:</p>\n<pre><code>from transfer_nlp.plugins.config import ExperimentConfig\n\n# Launch an experiment\nconfig_file  = {...}  # Dictionary config file, or str/Path to a json config file\nexperiment = ExperimentConfig(experiment=config_file)\n\n# Interaact with the experiment's objects, e.g. launch a training job of a `trainer` object\nexperiment['trainer'].train()\n\n# Another use of experiment object: use the `predictor` object for inference\ninput_json = {\"inputs\": [Some Examples]}\noutput_json = experiment['predictor'].json_to_json(input_json=input_json)\n</code></pre>\n<h1>How to experiment with the library?</h1>\n<p>For reproducible research and easy ablation studies, the library enforces the use of configuration files for experiments.</p>\n<p>In Transfer-NLP, an experiment config file contains all the necessary information to define entirely the experiment.\nThis is where you will insert names of the different components your experiment will use.\nTransfer-NLP makes use of the Inversion of Control pattern, which allows you to define any kind of classes you could need, and the <code>ExperimentConfig.from_json</code> method will create a dictionnary and instatiate your objects accordingly.</p>\n<p>To use your own classes inside Transfer-NLP, you need to register them using the <code>@register_plugin</code> decorator. Instead of using a different registry for each kind of component (Models, Data loaders, Vectorizers, Optimizers, ...), only a single registry is used here, in order to enforce total customization.</p>\n<p>Currently, the config file logic has 3 kinds of components:</p>\n<ul>\n<li>simple parameters: those are parameters which you know the value in advance:</li>\n</ul>\n<pre><code>{\"initial_learning_rate\": 0.01,\n\"embedding_dim\": 100,...}\n</code></pre>\n<ul>\n<li>simple lists: similar to simple parameters, but as a list:</li>\n</ul>\n<pre><code>{\"layers_dropout\": [0.1, 0.2, 0.3], ...}\n</code></pre>\n<ul>\n<li>Complex config: this is where the library instantiates your objects: every object needs to have its <code>_name</code> specified (the name of a class that you have register through the <code>@register_plugin</code> decorator), and its parameters defined. If your class has default parameters and your config file doesn't contain them, objects will be instantiated as default. Otherwise the parameters have to be present in the config file. Sometimes, initialization parameters are not available before launching the experiment. E.g., suppose your Model object needs a Vocabulary size as init input. The config file logic here makes it easy to deal with this while keeping the library code very general.</li>\n</ul>\n<p>You can have a look at the <a href=\"https://github.com/feedly/transfer-nlp/blob/master/tests/plugins/test_config.py\" rel=\"nofollow\">tests</a> for examples of experiment settings the config loader can build.\nAdditionally we provide runnable experiments in <a href=\"https://github.com/feedly/transfer-nlp/tree/master/experiments\" rel=\"nofollow\"><code>experiments/</code></a>.</p>\n<h1>Usage Pipeline</h1>\n<p>The goal of the config file is to load different objects and run your experiment from it.</p>\n<p>A very common object to use is trainer, which you will run during your experiment. We provide a <code>BasicTrainer</code> in <a href=\"https://github.com/feedly/transfer-nlp/blob/master/transfer_nlp/plugins/trainers.py\" rel=\"nofollow\"><code>transfer_nlp.plugins.trainers.py</code></a>.\nThis basic trainer will take a model and some data as input, and run a whole training pipeline. We make use of the <a href=\"https://github.com/pytorch/ignite\" rel=\"nofollow\">PyTorch-Ignite</a> library to monitor events during training (logging some metrics, manipulating learning rates, checkpointing models, etc...). Tensorboard logs are also included as an option, you will have to specify a <code>tensorboard_logs</code> simple parameters path in the config file. Then just run <code>tensorboard --logdir=path/to/logs</code> in a terminal and you can monitor your experiment while it's training!\nTensorboard comes with very nice utilities to keep track of the norms of your model weights, histograms, distributions, visualizing embeddings, etc so we really recommend using it.</p>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8e597a62a90425f9e76a05a2be7c08df3fda52ea/68747470733a2f2f6769746875622e636f6d2f666565646c792f7472616e736665722d6e6c702f626c6f622f76302e312f646174612f696d616765732f74656e736f72626f6172642e706e67\" width=\"1000\">\n<h1>Slack integration</h1>\n<p>While experimenting with your own models / data, the training might take some time. To get notified when your training finishes or crashes, you can use the simple library <a href=\"https://github.com/huggingface/knockknock\" rel=\"nofollow\">knockknock</a> by folks at HuggingFace, which add a simple decorator to your running function to notify you via Slack, E-mail, etc.</p>\n<h1>Some objectives to reach:</h1>\n<ul>\n<li>Include examples using state of the art pre-trained models</li>\n<li>Include linguistic properties to models</li>\n<li>Experiment with RL for sequential tasks</li>\n<li>Include probing tasks to try to understand the properties that are learned by the models</li>\n</ul>\n<h1>Acknowledgment</h1>\n<p>The library has been inspired by the reading of <cite><a href=\"https://www.amazon.com/dp/1491978236/\" rel=\"nofollow\">\"Natural Language Processing with PyTorch\"</a><cite> by Delip Rao and Brian McMahan.\nExperiments in <a href=\"https://github.com/feedly/transfer-nlp/tree/master/experiments/deep_learning_with_pytorch\" rel=\"nofollow\"><code>experiments</code></a>, the Vocabulary building block and embeddings nearest neighbors are taken or adapted from the code provided in the book.</cite></cite></p>\n\n          </div>"}, "last_serial": 5447448, "releases": {"0.0.2": [{"comment_text": "", "digests": {"md5": "9050c1146f3a59e030b521acde676a26", "sha256": "207d949adea2ddbea79d20128cde42adfbd8104fc5e0db5503a3e8fd913a1df5"}, "downloads": -1, "filename": "transfer_nlp-0.0.2.tar.gz", "has_sig": false, "md5_digest": "9050c1146f3a59e030b521acde676a26", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2256, "upload_time": "2019-04-06T06:19:52", "upload_time_iso_8601": "2019-04-06T06:19:52.895486Z", "url": "https://files.pythonhosted.org/packages/e2/87/db65dd78497fe511da96d184140b119768bd8689abe826eb05fc00bff7a5/transfer_nlp-0.0.2.tar.gz", "yanked": false}], "0.1": [{"comment_text": "", "digests": {"md5": "33bcb0f1844f1c5ad0fb97d762372824", "sha256": "12feffaa371df82840c7d225c5ef0e42f3b7d124607f3450e286e554368aee90"}, "downloads": -1, "filename": "transfer_nlp-0.1.tar.gz", "has_sig": false, "md5_digest": "33bcb0f1844f1c5ad0fb97d762372824", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4952, "upload_time": "2019-05-28T21:39:03", "upload_time_iso_8601": "2019-05-28T21:39:03.360071Z", "url": "https://files.pythonhosted.org/packages/8d/94/bad2e47a0ed1edcf0079ef77bebf8bb6b4170fc70a4ae84935dea6ef863b/transfer_nlp-0.1.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "b50fcd09768f098e99fe883879878442", "sha256": "6bcd3e5efa9d62cf5b656c3d62e60d5282a65c1601648795f6c5f908be0b9b37"}, "downloads": -1, "filename": "transfer_nlp-0.1.1.tar.gz", "has_sig": false, "md5_digest": "b50fcd09768f098e99fe883879878442", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4950, "upload_time": "2019-05-28T21:52:31", "upload_time_iso_8601": "2019-05-28T21:52:31.260342Z", "url": "https://files.pythonhosted.org/packages/10/0a/bd25c7ee411f1840c279f1fa920a2f72073f53a2e84f5162ca478f822f0f/transfer_nlp-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "7d83062c49d1c7943d27e9a4e305e074", "sha256": "219d394fb5cea7d2ef84d3985f7b419a571641c112a6adc5cbf3b76cf677df48"}, "downloads": -1, "filename": "transfer_nlp-0.1.2.tar.gz", "has_sig": false, "md5_digest": "7d83062c49d1c7943d27e9a4e305e074", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23892, "upload_time": "2019-05-28T23:46:42", "upload_time_iso_8601": "2019-05-28T23:46:42.415411Z", "url": "https://files.pythonhosted.org/packages/21/16/128b96f55d7b38d424c88f449acba4540d3633323697d384d7d5bc947b03/transfer_nlp-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "4479eedc3caf53ab5aa90094299810f3", "sha256": "041808694bfc727f1c45b08afaebc30c0de0d4dd79f54ac08d142f1bd1671948"}, "downloads": -1, "filename": "transfer_nlp-0.1.3.tar.gz", "has_sig": false, "md5_digest": "4479eedc3caf53ab5aa90094299810f3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23912, "upload_time": "2019-05-29T01:10:35", "upload_time_iso_8601": "2019-05-29T01:10:35.624803Z", "url": "https://files.pythonhosted.org/packages/0c/13/0b8e6c1a0e83cef742927ea7d5a37a0ebba65e72847c7c552fd39f4ed593/transfer_nlp-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "44019fbf9b8843413cb3af5a46cbe800", "sha256": "093ca7bfd28ff29609eabff2fbdc4481655e85b680b28a8f0ce02b32560f313c"}, "downloads": -1, "filename": "transfer_nlp-0.1.4.tar.gz", "has_sig": false, "md5_digest": "44019fbf9b8843413cb3af5a46cbe800", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23915, "upload_time": "2019-05-29T02:54:01", "upload_time_iso_8601": "2019-05-29T02:54:01.380898Z", "url": "https://files.pythonhosted.org/packages/84/49/6db4a3594074ad51deefa7b72a58f189694e8298a4d0804e38bf08a59272/transfer_nlp-0.1.4.tar.gz", "yanked": false}], "0.1.5": [{"comment_text": "", "digests": {"md5": "edbe233a3432add9ee3960e131e83a2b", "sha256": "4798bcc8814e749564f041c212be77e845bc3731795b0055825fad7171bd6f25"}, "downloads": -1, "filename": "transfer_nlp-0.1.5.tar.gz", "has_sig": false, "md5_digest": "edbe233a3432add9ee3960e131e83a2b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 25519, "upload_time": "2019-06-25T17:34:12", "upload_time_iso_8601": "2019-06-25T17:34:12.072701Z", "url": "https://files.pythonhosted.org/packages/61/e1/0521b59dd9f425139d4c4db093cda63ad85b1ef0ca35cfd7abdff573e8f7/transfer_nlp-0.1.5.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "edbe233a3432add9ee3960e131e83a2b", "sha256": "4798bcc8814e749564f041c212be77e845bc3731795b0055825fad7171bd6f25"}, "downloads": -1, "filename": "transfer_nlp-0.1.5.tar.gz", "has_sig": false, "md5_digest": "edbe233a3432add9ee3960e131e83a2b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 25519, "upload_time": "2019-06-25T17:34:12", "upload_time_iso_8601": "2019-06-25T17:34:12.072701Z", "url": "https://files.pythonhosted.org/packages/61/e1/0521b59dd9f425139d4c4db093cda63ad85b1ef0ca35cfd7abdff573e8f7/transfer_nlp-0.1.5.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:48:19 2020"}