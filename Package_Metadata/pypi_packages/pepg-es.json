{"info": {"author": "G\u00f6ktu\u011f Karaka\u015fl\u0131", "author_email": "karakasligk@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: POSIX :: Linux", "Programming Language :: Python :: 3"], "description": "Parameter-exploring Policy Gradients\n=======================================================\n\nPython Implementation of Parameter-exploring Policy Gradients <a href=\"#sehnke2010\">[3]</a> Evolution Strategy \n\n## Requirements\n* Python >= 3.6\n* Numpy\n\n### Optional\n* gym\n* mpi4py\n\n## Install\n\n- From PyPI\n\n``` bash\npip3 install pepg-es\n```\n\n- From Source\n\n``` bash\ngit clone https://github.com/goktug97/PEPG-ES\ncd PEPG-ES\npython3 setup.py install --user\n```\n\n## About Implementation\n\nI implemented several things differently from the original paper;\n\n- Applied rank transformation <a href=\"#wierstra14a\">[1]</a> to the fitness scores.\n- Used Adam <a href=\"#kingma2014adam\">[2]</a> optimizer to update the mean.\n- Weight decay is applied to the mean, similar to <a href=\"#salimans2017evolution\">[4]</a>.\n\n## Usage\n\nRefer to [PEPG-ES/examples](https://github.com/goktug97/PEPG-ES/blob/master/examples)\nfolder for more complete examples.\n\n### XOR Example\n\n* Find Neural Network parameters for XOR Gate. \n* Black-box optimization algorithms like PEPG are competitive in the\n  area of reinforcement learning because they don't require\n  backpropagation to calculate the gradients.  In supervised learning\n  using backpropagation is faster and more reliable. Thus, using backpropagation\n  to solve the XOR problem would be faster. I demonstrated library by solving XOR\n  because it was easy and understandable.\n\n``` python\nfrom pepg import PEPG, NeuralNetwork, Adam, sigmoid\n\nimport numpy as np\n\n\nnetwork = NeuralNetwork(input_size = 2, output_size = 1, hidden_sizes = [2],\n                        hidden_activation = sigmoid,\n                        output_activation = sigmoid)\n\n# Adam Optimizer is the default optimizer, it is written for the example\noptimizer_kwargs = {'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-08} # Adam Parameters\n\nes = PEPG(population_size = 100, theta_size = network.number_of_parameters,\n          mu_init = 0, sigma_init = 2.0,\n          mu_lr = 0.3, sigma_lr = 0.2, optimizer = Adam,\n          optimizer_kwargs = optimizer_kwargs)\n\ntruth_table = [[0, 1],[1, 0]]\nsolution_found = False\n\nwhile True:\n    print(f'Step: {es.step}')\n    solutions = es.get_parameters()\n    rewards = []\n    for solution in solutions:\n        network.weights = solution\n        error = 0\n        for input_1 in range(len(truth_table)):\n            for input_2 in range(len(truth_table[0])):\n                output = int(round(network([input_1, input_2])[0]))\n                error += abs(truth_table[input_1][input_2] - output)\n        reward = (4 - error) ** 2\n        rewards.append(reward)\n    es.update(rewards)\n    if es.best_fitness == 16:\n        print('Solution Found')\n        print(f'Parameters: {es.best_theta}')\n        break\n```\n\n* Output:\n\n``` bash\nStep: 233\nStep: 234\nStep: 235\nStep: 236\nStep: 237\nSolution Found\nParameters: [ 1.25863047 -0.73151503 -2.53377723  1.01802355  3.02723507  1.23112726\n -2.00288859 -3.66789242  4.56593794]\n```\n\n## Documentation\n\n### PEPG Class\n\n``` python\n\nes = PEPG(self, population_size, theta_size,\n          mu_init, sigma_init, mu_lr,\n          sigma_lr, l2_coeff = 0.005,\n          optimizer = Adam, optimizer_kwargs = {})\n\n```\n\n* **Parameters:**\n    - **population_size:** int: Population size of the evolution strategy.\n    - **theta_size** int: Number of parameters that will be optimized.\n    - **mu_init** float: Initial mean.\n    - **sigma_init** float: Initial sigma.\n    - **mu_lr** float: Learning rate for the mean.\n    - **sigma_lr** float: Learning rate for the sigma.\n    - **l2_coeff** float: Weight decay coefficient.\n    - **optimizer** Optimizer: Optimizer to use\n    - **optimizer_kwargs** Dict[str, Any]: Parameters for optimizer except learning rate.\n\n___\n\n``` python\nsolutions = self.get_parameters(self)\n```\n\n- Creates symmetric samples around the mean and returns a numpy array with the size of\n**[population_size, theta_size]**\n\n___\n\n``` python\nself.update(self, rewards)\n```\n\n* **Parameters:**\n    - **rewards:** List[float]: Rewards for the given solutions.\n    \n- Update the mean and the sigma.\n\n___\n\n``` python\nself.save_checkpoint(self)\n```\n\n- Creates a checkpoint and save it into created time.time().checkpoint file.\n\n___\n\n``` python\nes = PEPG.load_checkpoint(cls, filename)\n```\n\n- Creates a new PEPG class and loads the checkpoint.\n___\n\n``` python\nself.save_best(self, filename)\n```\n\n- Saves the best theta and the mu and the sigma that used to create the best theta.\n\n___\n\n``` python\ntheta, mu, sigma = PEPG.load_best(cls, filename)\n```\n\n- Load the theta, the mu, and the sigma arrays from the given file.\n\n### NeuralNetwork Class\n\n``` python\n\nNeuralNetwork(self, input_size, output_size, hidden_sizes = [],\n              hidden_activation = lambda x: x,\n              output_activation = lambda x: x,\n              bias = True):\n\n```\n\n* **Parameters:**\n    - **input_size:** int: Input size of network.\n    - **output_size:** int: Output size of the network.\n    - **hidden_sizes:** List[int]: Sizes for the hidden layers.\n    - **hidden_activation:** Callable[[float], float]: Activation function used in hidden layers.\n    - **output_activation:** Callable[[float], float]: Activation function used at the output.\n    - **bias:** bool: Add bias node.\n___\n\n``` python\nself.save_network(self, filename)\n```\n\n- Save the network to a file.\n\n___\n\n``` python\nnetwork = NeuralNetwork.load_network(cls, filename)\n```\n\n- Creates a new NeuralNetwork class and loads the given network file.\n    \n### Custom Optimizer Example\n\n``` python\nfrom pepg import PEPG, Optimizer, NeuralNetwork\n\nclass CustomOptimizer(Optimizer):\n    def __init__(self, alpha, parameter, another_parameter):\n        self.alpha = alpha\n        self.parameter = parameter\n        self.another_parameter = another_parameter\n\n    def __call__(self, gradients):\n        gradients = (gradients + self.parameter) * self.another_parameter\n        return -self.alpha * gradients\n\nnetwork = NeuralNetwork(input_size = 2, output_size = 1)\n\noptimizer_kwargs = {'parameter': 0.3, 'another_parameter': 0.2}\nes = PEPG(population_size = 100, theta_size = network.number_of_parameters,\n          mu_init = 0.0, sigma_init = 2.0,\n          mu_lr = 0.3, sigma_lr = 0.2, optimizer = CustomOptimizer,\n          optimizer_kwargs = optimizer_kwargs)\n```\n\n## References\n1. <a id=\"wierstra14a\"></a>Daan Wierstra, Tom Schaul, Tobias Glasmachers, Yi Sun, Jan Peters and Jurgen Schmidhuber. Natural Evolution Strategies. 2014\n2. <a id=\"kingma2014adam\"></a>Diederik P. Kingma and Jimmy Ba. Adam: A Method for Stochastic Optimization. 2014\n3. <a id=\"sehnke2010\"></a>F. Sehnke, C. Osendorfer, T. Ruckstiess, A. Graves, J. Peters and J. Schmidhuber. Parameter-exploring policy gradients. 2010\n4. <a id=\"salimans2017evolution\"></a>Tim Salimans, Jonathan Ho, Xi Chen, Szymon Sidor and Ilya Sutskever. Evolution Strategies as a Scalable Alternative to Reinforcement Learning. 2017", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/goktug97/PEPG-ES/archive/v0.0.5.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/goktug97/PEPG-ES", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "pepg-es", "package_url": "https://pypi.org/project/pepg-es/", "platform": "", "project_url": "https://pypi.org/project/pepg-es/", "project_urls": {"Download": "https://github.com/goktug97/PEPG-ES/archive/v0.0.5.tar.gz", "Homepage": "https://github.com/goktug97/PEPG-ES"}, "release_url": "https://pypi.org/project/pepg-es/0.0.5/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Python Implementation of Parameter-exploring Policy Gradients Evolution Strategy", "version": "0.0.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Parameter-exploring Policy Gradients</h1>\n<p>Python Implementation of Parameter-exploring Policy Gradients <a href=\"#sehnke2010\" rel=\"nofollow\">[3]</a> Evolution Strategy</p>\n<h2>Requirements</h2>\n<ul>\n<li>Python &gt;= 3.6</li>\n<li>Numpy</li>\n</ul>\n<h3>Optional</h3>\n<ul>\n<li>gym</li>\n<li>mpi4py</li>\n</ul>\n<h2>Install</h2>\n<ul>\n<li>From PyPI</li>\n</ul>\n<pre>pip3 install pepg-es\n</pre>\n<ul>\n<li>From Source</li>\n</ul>\n<pre>git clone https://github.com/goktug97/PEPG-ES\n<span class=\"nb\">cd</span> PEPG-ES\npython3 setup.py install --user\n</pre>\n<h2>About Implementation</h2>\n<p>I implemented several things differently from the original paper;</p>\n<ul>\n<li>Applied rank transformation <a href=\"#wierstra14a\" rel=\"nofollow\">[1]</a> to the fitness scores.</li>\n<li>Used Adam <a href=\"#kingma2014adam\" rel=\"nofollow\">[2]</a> optimizer to update the mean.</li>\n<li>Weight decay is applied to the mean, similar to <a href=\"#salimans2017evolution\" rel=\"nofollow\">[4]</a>.</li>\n</ul>\n<h2>Usage</h2>\n<p>Refer to <a href=\"https://github.com/goktug97/PEPG-ES/blob/master/examples\" rel=\"nofollow\">PEPG-ES/examples</a>\nfolder for more complete examples.</p>\n<h3>XOR Example</h3>\n<ul>\n<li>Find Neural Network parameters for XOR Gate.</li>\n<li>Black-box optimization algorithms like PEPG are competitive in the\narea of reinforcement learning because they don't require\nbackpropagation to calculate the gradients.  In supervised learning\nusing backpropagation is faster and more reliable. Thus, using backpropagation\nto solve the XOR problem would be faster. I demonstrated library by solving XOR\nbecause it was easy and understandable.</li>\n</ul>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pepg</span> <span class=\"kn\">import</span> <span class=\"n\">PEPG</span><span class=\"p\">,</span> <span class=\"n\">NeuralNetwork</span><span class=\"p\">,</span> <span class=\"n\">Adam</span><span class=\"p\">,</span> <span class=\"n\">sigmoid</span>\n\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n\n\n<span class=\"n\">network</span> <span class=\"o\">=</span> <span class=\"n\">NeuralNetwork</span><span class=\"p\">(</span><span class=\"n\">input_size</span> <span class=\"o\">=</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">output_size</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">hidden_sizes</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">],</span>\n                        <span class=\"n\">hidden_activation</span> <span class=\"o\">=</span> <span class=\"n\">sigmoid</span><span class=\"p\">,</span>\n                        <span class=\"n\">output_activation</span> <span class=\"o\">=</span> <span class=\"n\">sigmoid</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Adam Optimizer is the default optimizer, it is written for the example</span>\n<span class=\"n\">optimizer_kwargs</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'beta_1'</span><span class=\"p\">:</span> <span class=\"mf\">0.9</span><span class=\"p\">,</span> <span class=\"s1\">'beta_2'</span><span class=\"p\">:</span> <span class=\"mf\">0.999</span><span class=\"p\">,</span> <span class=\"s1\">'epsilon'</span><span class=\"p\">:</span> <span class=\"mf\">1e-08</span><span class=\"p\">}</span> <span class=\"c1\"># Adam Parameters</span>\n\n<span class=\"n\">es</span> <span class=\"o\">=</span> <span class=\"n\">PEPG</span><span class=\"p\">(</span><span class=\"n\">population_size</span> <span class=\"o\">=</span> <span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">theta_size</span> <span class=\"o\">=</span> <span class=\"n\">network</span><span class=\"o\">.</span><span class=\"n\">number_of_parameters</span><span class=\"p\">,</span>\n          <span class=\"n\">mu_init</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">sigma_init</span> <span class=\"o\">=</span> <span class=\"mf\">2.0</span><span class=\"p\">,</span>\n          <span class=\"n\">mu_lr</span> <span class=\"o\">=</span> <span class=\"mf\">0.3</span><span class=\"p\">,</span> <span class=\"n\">sigma_lr</span> <span class=\"o\">=</span> <span class=\"mf\">0.2</span><span class=\"p\">,</span> <span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">Adam</span><span class=\"p\">,</span>\n          <span class=\"n\">optimizer_kwargs</span> <span class=\"o\">=</span> <span class=\"n\">optimizer_kwargs</span><span class=\"p\">)</span>\n\n<span class=\"n\">truth_table</span> <span class=\"o\">=</span> <span class=\"p\">[[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]]</span>\n<span class=\"n\">solution_found</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>\n\n<span class=\"k\">while</span> <span class=\"kc\">True</span><span class=\"p\">:</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">'Step: </span><span class=\"si\">{</span><span class=\"n\">es</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"si\">}</span><span class=\"s1\">'</span><span class=\"p\">)</span>\n    <span class=\"n\">solutions</span> <span class=\"o\">=</span> <span class=\"n\">es</span><span class=\"o\">.</span><span class=\"n\">get_parameters</span><span class=\"p\">()</span>\n    <span class=\"n\">rewards</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n    <span class=\"k\">for</span> <span class=\"n\">solution</span> <span class=\"ow\">in</span> <span class=\"n\">solutions</span><span class=\"p\">:</span>\n        <span class=\"n\">network</span><span class=\"o\">.</span><span class=\"n\">weights</span> <span class=\"o\">=</span> <span class=\"n\">solution</span>\n        <span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n        <span class=\"k\">for</span> <span class=\"n\">input_1</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">truth_table</span><span class=\"p\">)):</span>\n            <span class=\"k\">for</span> <span class=\"n\">input_2</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">truth_table</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])):</span>\n                <span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"nb\">round</span><span class=\"p\">(</span><span class=\"n\">network</span><span class=\"p\">([</span><span class=\"n\">input_1</span><span class=\"p\">,</span> <span class=\"n\">input_2</span><span class=\"p\">])[</span><span class=\"mi\">0</span><span class=\"p\">]))</span>\n                <span class=\"n\">error</span> <span class=\"o\">+=</span> <span class=\"nb\">abs</span><span class=\"p\">(</span><span class=\"n\">truth_table</span><span class=\"p\">[</span><span class=\"n\">input_1</span><span class=\"p\">][</span><span class=\"n\">input_2</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">output</span><span class=\"p\">)</span>\n        <span class=\"n\">reward</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"mi\">4</span> <span class=\"o\">-</span> <span class=\"n\">error</span><span class=\"p\">)</span> <span class=\"o\">**</span> <span class=\"mi\">2</span>\n        <span class=\"n\">rewards</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">reward</span><span class=\"p\">)</span>\n    <span class=\"n\">es</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">rewards</span><span class=\"p\">)</span>\n    <span class=\"k\">if</span> <span class=\"n\">es</span><span class=\"o\">.</span><span class=\"n\">best_fitness</span> <span class=\"o\">==</span> <span class=\"mi\">16</span><span class=\"p\">:</span>\n        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Solution Found'</span><span class=\"p\">)</span>\n        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">'Parameters: </span><span class=\"si\">{</span><span class=\"n\">es</span><span class=\"o\">.</span><span class=\"n\">best_theta</span><span class=\"si\">}</span><span class=\"s1\">'</span><span class=\"p\">)</span>\n        <span class=\"k\">break</span>\n</pre>\n<ul>\n<li>Output:</li>\n</ul>\n<pre>Step: <span class=\"m\">233</span>\nStep: <span class=\"m\">234</span>\nStep: <span class=\"m\">235</span>\nStep: <span class=\"m\">236</span>\nStep: <span class=\"m\">237</span>\nSolution Found\nParameters: <span class=\"o\">[</span> <span class=\"m\">1</span>.25863047 -0.73151503 -2.53377723  <span class=\"m\">1</span>.01802355  <span class=\"m\">3</span>.02723507  <span class=\"m\">1</span>.23112726\n -2.00288859 -3.66789242  <span class=\"m\">4</span>.56593794<span class=\"o\">]</span>\n</pre>\n<h2>Documentation</h2>\n<h3>PEPG Class</h3>\n<pre><span class=\"n\">es</span> <span class=\"o\">=</span> <span class=\"n\">PEPG</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">population_size</span><span class=\"p\">,</span> <span class=\"n\">theta_size</span><span class=\"p\">,</span>\n          <span class=\"n\">mu_init</span><span class=\"p\">,</span> <span class=\"n\">sigma_init</span><span class=\"p\">,</span> <span class=\"n\">mu_lr</span><span class=\"p\">,</span>\n          <span class=\"n\">sigma_lr</span><span class=\"p\">,</span> <span class=\"n\">l2_coeff</span> <span class=\"o\">=</span> <span class=\"mf\">0.005</span><span class=\"p\">,</span>\n          <span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">Adam</span><span class=\"p\">,</span> <span class=\"n\">optimizer_kwargs</span> <span class=\"o\">=</span> <span class=\"p\">{})</span>\n</pre>\n<ul>\n<li><strong>Parameters:</strong>\n<ul>\n<li><strong>population_size:</strong> int: Population size of the evolution strategy.</li>\n<li><strong>theta_size</strong> int: Number of parameters that will be optimized.</li>\n<li><strong>mu_init</strong> float: Initial mean.</li>\n<li><strong>sigma_init</strong> float: Initial sigma.</li>\n<li><strong>mu_lr</strong> float: Learning rate for the mean.</li>\n<li><strong>sigma_lr</strong> float: Learning rate for the sigma.</li>\n<li><strong>l2_coeff</strong> float: Weight decay coefficient.</li>\n<li><strong>optimizer</strong> Optimizer: Optimizer to use</li>\n<li><strong>optimizer_kwargs</strong> Dict[str, Any]: Parameters for optimizer except learning rate.</li>\n</ul>\n</li>\n</ul>\n<hr>\n<pre><span class=\"n\">solutions</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">get_parameters</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span>\n</pre>\n<ul>\n<li>Creates symmetric samples around the mean and returns a numpy array with the size of\n<strong>[population_size, theta_size]</strong></li>\n</ul>\n<hr>\n<pre><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">rewards</span><span class=\"p\">)</span>\n</pre>\n<ul>\n<li><strong>Parameters:</strong>\n<ul>\n<li><strong>rewards:</strong> List[float]: Rewards for the given solutions.</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>Update the mean and the sigma.</li>\n</ul>\n<hr>\n<pre><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">save_checkpoint</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span>\n</pre>\n<ul>\n<li>Creates a checkpoint and save it into created time.time().checkpoint file.</li>\n</ul>\n<hr>\n<pre><span class=\"n\">es</span> <span class=\"o\">=</span> <span class=\"n\">PEPG</span><span class=\"o\">.</span><span class=\"n\">load_checkpoint</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">filename</span><span class=\"p\">)</span>\n</pre>\n<ul>\n<li>Creates a new PEPG class and loads the checkpoint.</li>\n</ul>\n<hr>\n<pre><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">save_best</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">filename</span><span class=\"p\">)</span>\n</pre>\n<ul>\n<li>Saves the best theta and the mu and the sigma that used to create the best theta.</li>\n</ul>\n<hr>\n<pre><span class=\"n\">theta</span><span class=\"p\">,</span> <span class=\"n\">mu</span><span class=\"p\">,</span> <span class=\"n\">sigma</span> <span class=\"o\">=</span> <span class=\"n\">PEPG</span><span class=\"o\">.</span><span class=\"n\">load_best</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">filename</span><span class=\"p\">)</span>\n</pre>\n<ul>\n<li>Load the theta, the mu, and the sigma arrays from the given file.</li>\n</ul>\n<h3>NeuralNetwork Class</h3>\n<pre><span class=\"n\">NeuralNetwork</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">input_size</span><span class=\"p\">,</span> <span class=\"n\">output_size</span><span class=\"p\">,</span> <span class=\"n\">hidden_sizes</span> <span class=\"o\">=</span> <span class=\"p\">[],</span>\n              <span class=\"n\">hidden_activation</span> <span class=\"o\">=</span> <span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">x</span><span class=\"p\">,</span>\n              <span class=\"n\">output_activation</span> <span class=\"o\">=</span> <span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">x</span><span class=\"p\">,</span>\n              <span class=\"n\">bias</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">):</span>\n</pre>\n<ul>\n<li><strong>Parameters:</strong>\n<ul>\n<li><strong>input_size:</strong> int: Input size of network.</li>\n<li><strong>output_size:</strong> int: Output size of the network.</li>\n<li><strong>hidden_sizes:</strong> List[int]: Sizes for the hidden layers.</li>\n<li><strong>hidden_activation:</strong> Callable[[float], float]: Activation function used in hidden layers.</li>\n<li><strong>output_activation:</strong> Callable[[float], float]: Activation function used at the output.</li>\n<li><strong>bias:</strong> bool: Add bias node.</li>\n</ul>\n</li>\n</ul>\n<hr>\n<pre><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">save_network</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">filename</span><span class=\"p\">)</span>\n</pre>\n<ul>\n<li>Save the network to a file.</li>\n</ul>\n<hr>\n<pre><span class=\"n\">network</span> <span class=\"o\">=</span> <span class=\"n\">NeuralNetwork</span><span class=\"o\">.</span><span class=\"n\">load_network</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">filename</span><span class=\"p\">)</span>\n</pre>\n<ul>\n<li>Creates a new NeuralNetwork class and loads the given network file.</li>\n</ul>\n<h3>Custom Optimizer Example</h3>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pepg</span> <span class=\"kn\">import</span> <span class=\"n\">PEPG</span><span class=\"p\">,</span> <span class=\"n\">Optimizer</span><span class=\"p\">,</span> <span class=\"n\">NeuralNetwork</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">CustomOptimizer</span><span class=\"p\">(</span><span class=\"n\">Optimizer</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">alpha</span><span class=\"p\">,</span> <span class=\"n\">parameter</span><span class=\"p\">,</span> <span class=\"n\">another_parameter</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">alpha</span> <span class=\"o\">=</span> <span class=\"n\">alpha</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parameter</span> <span class=\"o\">=</span> <span class=\"n\">parameter</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">another_parameter</span> <span class=\"o\">=</span> <span class=\"n\">another_parameter</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__call__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">gradients</span><span class=\"p\">):</span>\n        <span class=\"n\">gradients</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">gradients</span> <span class=\"o\">+</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parameter</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">another_parameter</span>\n        <span class=\"k\">return</span> <span class=\"o\">-</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">alpha</span> <span class=\"o\">*</span> <span class=\"n\">gradients</span>\n\n<span class=\"n\">network</span> <span class=\"o\">=</span> <span class=\"n\">NeuralNetwork</span><span class=\"p\">(</span><span class=\"n\">input_size</span> <span class=\"o\">=</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">output_size</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"n\">optimizer_kwargs</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'parameter'</span><span class=\"p\">:</span> <span class=\"mf\">0.3</span><span class=\"p\">,</span> <span class=\"s1\">'another_parameter'</span><span class=\"p\">:</span> <span class=\"mf\">0.2</span><span class=\"p\">}</span>\n<span class=\"n\">es</span> <span class=\"o\">=</span> <span class=\"n\">PEPG</span><span class=\"p\">(</span><span class=\"n\">population_size</span> <span class=\"o\">=</span> <span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">theta_size</span> <span class=\"o\">=</span> <span class=\"n\">network</span><span class=\"o\">.</span><span class=\"n\">number_of_parameters</span><span class=\"p\">,</span>\n          <span class=\"n\">mu_init</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"n\">sigma_init</span> <span class=\"o\">=</span> <span class=\"mf\">2.0</span><span class=\"p\">,</span>\n          <span class=\"n\">mu_lr</span> <span class=\"o\">=</span> <span class=\"mf\">0.3</span><span class=\"p\">,</span> <span class=\"n\">sigma_lr</span> <span class=\"o\">=</span> <span class=\"mf\">0.2</span><span class=\"p\">,</span> <span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">CustomOptimizer</span><span class=\"p\">,</span>\n          <span class=\"n\">optimizer_kwargs</span> <span class=\"o\">=</span> <span class=\"n\">optimizer_kwargs</span><span class=\"p\">)</span>\n</pre>\n<h2>References</h2>\n<ol>\n<li><a id=\"wierstra14a\"></a>Daan Wierstra, Tom Schaul, Tobias Glasmachers, Yi Sun, Jan Peters and Jurgen Schmidhuber. Natural Evolution Strategies. 2014</li>\n<li><a id=\"kingma2014adam\"></a>Diederik P. Kingma and Jimmy Ba. Adam: A Method for Stochastic Optimization. 2014</li>\n<li><a id=\"sehnke2010\"></a>F. Sehnke, C. Osendorfer, T. Ruckstiess, A. Graves, J. Peters and J. Schmidhuber. Parameter-exploring policy gradients. 2010</li>\n<li><a id=\"salimans2017evolution\"></a>Tim Salimans, Jonathan Ho, Xi Chen, Szymon Sidor and Ilya Sutskever. Evolution Strategies as a Scalable Alternative to Reinforcement Learning. 2017</li>\n</ol>\n\n          </div>"}, "last_serial": 6923366, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "8f2ee43cd6bb561b51c564cb60036d11", "sha256": "58ccede8652b6a61fe5ac51e0cb8b9425fbc5374b08eac5816f337c0bfb6a5dc"}, "downloads": -1, "filename": "pepg_es-0.0.1-py3.6.egg", "has_sig": false, "md5_digest": "8f2ee43cd6bb561b51c564cb60036d11", "packagetype": "bdist_egg", "python_version": "3.6", "requires_python": ">=3.6", "size": 11354, "upload_time": "2020-03-30T18:40:31", "upload_time_iso_8601": "2020-03-30T18:40:31.931342Z", "url": "https://files.pythonhosted.org/packages/13/a0/0759fe78ca9f1bdecb384b4d9bf1bb2358f46cc458cb631f287000590a51/pepg_es-0.0.1-py3.6.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "cb2912a5c045385315905356b946d946", "sha256": "db252b1a75441e62636d3bcd615b4d19526e3fe1b205a086da512a10c00c3be6"}, "downloads": -1, "filename": "pepg_es-0.0.1-py3.8.egg", "has_sig": false, "md5_digest": "cb2912a5c045385315905356b946d946", "packagetype": "bdist_egg", "python_version": "3.8", "requires_python": ">=3.6", "size": 11020, "upload_time": "2020-03-30T18:40:34", "upload_time_iso_8601": "2020-03-30T18:40:34.575917Z", "url": "https://files.pythonhosted.org/packages/a8/ce/082b86a7c09b4a6637b5b1fa300422136737c1a5759832bd9ce7de84cf47/pepg_es-0.0.1-py3.8.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "cf7239a0ba407e9324c2cb0b315befa6", "sha256": "ee5cbf0dcb2960f803cb0a5ed333e37119e3ca4f268a6167ef992a01b367615e"}, "downloads": -1, "filename": "pepg-es-0.0.1.tar.gz", "has_sig": false, "md5_digest": "cf7239a0ba407e9324c2cb0b315befa6", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 7481, "upload_time": "2020-03-30T18:40:35", "upload_time_iso_8601": "2020-03-30T18:40:35.880922Z", "url": "https://files.pythonhosted.org/packages/c8/10/c36b33bea870d9173cf8d3b0c1ecd0587bf191ee2b158bc7f42926e492ab/pepg-es-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "73e502e62bf0e120d79f3123eccf478e", "sha256": "d926c52421b3fe5d9d1754e790db4b9befc491e80efda86e7cfc847c44e674e9"}, "downloads": -1, "filename": "pepg-es-0.0.2.tar.gz", "has_sig": false, "md5_digest": "73e502e62bf0e120d79f3123eccf478e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 7530, "upload_time": "2020-03-31T15:16:29", "upload_time_iso_8601": "2020-03-31T15:16:29.344454Z", "url": "https://files.pythonhosted.org/packages/6c/d0/01bbfc16da48349e28cf636843356e08e1b5cd6fc020a79004c78773296d/pepg-es-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "94bfa259bbbe2d64ee2ac123b8deaaaf", "sha256": "c824000468923f156a017a816e30aff87eb4f7852ad3f502e20762c710f477a3"}, "downloads": -1, "filename": "pepg-es-0.0.3.tar.gz", "has_sig": false, "md5_digest": "94bfa259bbbe2d64ee2ac123b8deaaaf", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 7598, "upload_time": "2020-03-31T15:24:16", "upload_time_iso_8601": "2020-03-31T15:24:16.083724Z", "url": "https://files.pythonhosted.org/packages/27/39/94890f87679c806529b9180ae688fefd0a18d8f0e22c537b471923c3b796/pepg-es-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "8b2ed167d06c635a35be13c6558cffbd", "sha256": "7cc593ee40147259f000b1fd27bd198d85d56c90857fefac42a633829f18cba3"}, "downloads": -1, "filename": "pepg_es-0.0.4-py3.6.egg", "has_sig": false, "md5_digest": "8b2ed167d06c635a35be13c6558cffbd", "packagetype": "bdist_egg", "python_version": "3.6", "requires_python": ">=3.6", "size": 12065, "upload_time": "2020-03-31T20:56:26", "upload_time_iso_8601": "2020-03-31T20:56:26.228659Z", "url": "https://files.pythonhosted.org/packages/a2/74/6bdb394b11d95802b798ab58ba58923d5efb34de37d33ad02cb1d7ea5e91/pepg_es-0.0.4-py3.6.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "f048d29e425a93ea6a9ee70ff1910e45", "sha256": "fe67b38f28f94a09eb4224dfe94f94b790a2dbb623eb91ffb137e14ca2be45f0"}, "downloads": -1, "filename": "pepg-es-0.0.4.tar.gz", "has_sig": false, "md5_digest": "f048d29e425a93ea6a9ee70ff1910e45", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 7783, "upload_time": "2020-03-31T20:53:09", "upload_time_iso_8601": "2020-03-31T20:53:09.797356Z", "url": "https://files.pythonhosted.org/packages/5d/91/bbbf744f1aa995c4c57082bc8e7f5f791e9e89308dd4c69b6ce29da5a098/pepg-es-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "48cc93926bf58ad4aa6ef58b17217d8b", "sha256": "b1a8b198f5aa12b096deb16b3efc6c6cf4bd6a367f8db03e71a30f723232fca8"}, "downloads": -1, "filename": "pepg_es-0.0.5-py3.6.egg", "has_sig": false, "md5_digest": "48cc93926bf58ad4aa6ef58b17217d8b", "packagetype": "bdist_egg", "python_version": "3.6", "requires_python": ">=3.6", "size": 12050, "upload_time": "2020-03-31T20:56:28", "upload_time_iso_8601": "2020-03-31T20:56:28.862493Z", "url": "https://files.pythonhosted.org/packages/f4/63/1743dbc56bbadc26f8087498dceeb779499eb5107835da63fcdd2458f138/pepg_es-0.0.5-py3.6.egg", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "48cc93926bf58ad4aa6ef58b17217d8b", "sha256": "b1a8b198f5aa12b096deb16b3efc6c6cf4bd6a367f8db03e71a30f723232fca8"}, "downloads": -1, "filename": "pepg_es-0.0.5-py3.6.egg", "has_sig": false, "md5_digest": "48cc93926bf58ad4aa6ef58b17217d8b", "packagetype": "bdist_egg", "python_version": "3.6", "requires_python": ">=3.6", "size": 12050, "upload_time": "2020-03-31T20:56:28", "upload_time_iso_8601": "2020-03-31T20:56:28.862493Z", "url": "https://files.pythonhosted.org/packages/f4/63/1743dbc56bbadc26f8087498dceeb779499eb5107835da63fcdd2458f138/pepg_es-0.0.5-py3.6.egg", "yanked": false}], "timestamp": "Fri May  8 02:56:25 2020"}