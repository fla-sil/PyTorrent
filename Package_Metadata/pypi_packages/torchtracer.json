{"info": {"author": "OIdiotLin", "author_email": "oidiotlin@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# torchtracer\n\n[![Build Status](https://travis-ci.com/OIdiotLin/torchtracer.svg?branch=master)](https://travis-ci.com/OIdiotLin/torchtracer)\n![](https://img.shields.io/badge/python-3.6-blue.svg)\n![](https://img.shields.io/badge/pytorch-0.4.1-orange.svg)\n\n`torchtracer` is a tool package for visualization and storage management in pytorch AI task.\n\n## Getting Started\n\n### PyTorch Required\n\nThis tool is developed for PyTorch AI task. Thus, PyTorch is needed of course.\n\n### Installing\n\nYou can use `pip` to install `torchtracer`.\n\n```bash\npip install torchtracer\n``` \n\n## How to use?\n\n### Import `torchtracer`\n\n```python\nfrom torchtracer import Tracer\n```\n\n### Create an instance of `Tracer`\n\nAssume that the root is `./checkpoints` and current task id is `lmmnb`.\n\n***Avoiding messing working directory, you should make root directory manually.***\n\n```python\ntracer = Tracer('checkpoints').attach('lmmnb')\n```\n\nThis step will create a directory `checkpoints` inside which is a directory `lmmnb` for current AI task.\n\nAlso, you could call `.attach()` without task id. **Datetime will be used as task id.**\n\n```python\ntracer = Tracer('checkpoints').attach()\n```\n\n### Saving config\n\nRaw config should be a `dict` like this:\n\n```python\n# `net` is a defined nn.Module\nargs = {'epoch_n': 120,\n        'batch_size': 10,\n        'criterion': nn.MSELoss(),\n        'optimizer': torch.optim.RMSprop(net.parameters(), lr=1e-3)}\n```\n\nThe config dict should be wrapped with `torchtracer.data.Config`\n\n```python\ncfg = Config(args)\ntracer.store(cfg)\n```\n\nThis step will create `config.json` in `./checkpoints/lmmnb/`, which contains JSON information like this:\n\n```json\n{\n  \"epoch_n\": 120,\n  \"batch_size\": 10,\n  \"criterion\": \"MSELoss\",\n  \"optimizer\": {\n    \"lr\": 0.001,\n    \"momentum\": 0,\n    \"alpha\": 0.99,\n    \"eps\": 1e-08,\n    \"centered\": false,\n    \"weight_decay\": 0,\n    \"name\": \"RMSprop\"\n  }\n}\n```\n\n### Logging\n\nDuring the training iteration, you could print any information you want by using `Tracer.log(msg, file)`.\n\nIf `file` not specified, it will output `msg` to `./checkpoints/lmmnb/log`. Otherwise, it will be `./checkpoints/lmmnb/something.log`.\n\n```python\ntracer.log(msg='Epoch #{:03d}\\ttrain_loss: {:.4f}\\tvalid_loss: {:.4f}'.format(epoch, train_loss, valid_loss),\n           file='losses')\n```\n\nThis step will create a log file `losses.log` in `./checkpoints/lmmnb/`, which contains logs like:\n\n```text\nEpoch #001\ttrain_loss: 18.6356\tvalid_loss: 21.3882\nEpoch #002\ttrain_loss: 19.1731\tvalid_loss: 17.8482\nEpoch #003\ttrain_loss: 19.6756\tvalid_loss: 19.1418\nEpoch #004\ttrain_loss: 20.0638\tvalid_loss: 18.3875\nEpoch #005\ttrain_loss: 18.4679\tvalid_loss: 19.6304\n...\n```\n\n### Saving model\n\nThe model object should be wrapped with `torchtracer.data.Model`\n\nIf `file` not specified, it will generates model files `model.txt`. Otherwise, it will be `somename.txt`\n\n```python\ntracer.store(Model(model), file='somename')\n```\n\nThis step will create 2 files: \n\n- **description**: `somename.txt`\n\n```text\nSequential\nSequential(\n  (0): Linear(in_features=1, out_features=6, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=6, out_features=12, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=12, out_features=12, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=12, out_features=1, bias=True)\n)\n```\n\n- **parameters**: `somename.pth`\n\n### Saving matplotlib images\n\nUse `tracer.store(figure, file)` to save matplotlib figure in `images/`\n\n```python\n# assume that `train_losses` and `valid_losses` are lists of losses. \n# create figure manually.\nplt.plot(train_losses, label='train loss', c='b')\nplt.plot(valid_losses, label='valid loss', c='r')\nplt.title('Demo Learning on SQRT')\nplt.legend()\n# save figure. remember to call `plt.gcf()`\ntracer.store(plt.gcf(), 'losses.png')\n```\n\nThis step will save a png file `losses.png` representing losses curves.\n\n### Progress bar for epochs\n\nUse `tracer.epoch_bar_init(total)` to initialize a progress bar.\n\n```python\ntracer.epoch_bar_init(epoch_n)\n```\n\nUse `tracer.epoch_bar.update(n=1, **params)` to update postfix of the progress bar.\n\n```python\ntracer.epoch_bar.update(train_loss=train_loss, valid_loss=train_loss)\n```\n\n```plain\n(THIS IS A DEMO) \nTracer start at /home/oidiotlin/projects/torchtracer/checkpoints\nTracer attached with task: rabbit\nEpoch: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 120/120 [00:02<00:00, 41.75it/s, train_loss=0.417, valid_loss=0.417]\n```\n\n**DO NOT FORGET TO CALL** `tracer.epoch_bar.close()` to finish the bar.\n\n## Contribute\n\nIf you like this project, welcome to pull request & create issues.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/OIdiotLin/torchtracer", "keywords": "", "license": "MIT License", "maintainer": "OIdiotLin", "maintainer_email": "oidiotlin@gmail.com", "name": "torchtracer", "package_url": "https://pypi.org/project/torchtracer/", "platform": "", "project_url": "https://pypi.org/project/torchtracer/", "project_urls": {"Homepage": "https://github.com/OIdiotLin/torchtracer"}, "release_url": "https://pypi.org/project/torchtracer/0.2.0/", "requires_dist": null, "requires_python": "", "summary": "A python package for visualization and storage management in a pytorch AI task.", "version": "0.2.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>torchtracer</h1>\n<p><a href=\"https://travis-ci.com/OIdiotLin/torchtracer\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a17f22e6140aba1d09b6c94c9194b433bc122b91/68747470733a2f2f7472617669732d63692e636f6d2f4f4964696f744c696e2f746f7263687472616365722e7376673f6272616e63683d6d6173746572\"></a>\n<img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/01419d339114693587408dd14856677a4789006a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e362d626c75652e737667\">\n<img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/167910d15bbc1d3193260a4533da8cb86c4170ae/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7079746f7263682d302e342e312d6f72616e67652e737667\"></p>\n<p><code>torchtracer</code> is a tool package for visualization and storage management in pytorch AI task.</p>\n<h2>Getting Started</h2>\n<h3>PyTorch Required</h3>\n<p>This tool is developed for PyTorch AI task. Thus, PyTorch is needed of course.</p>\n<h3>Installing</h3>\n<p>You can use <code>pip</code> to install <code>torchtracer</code>.</p>\n<pre>pip install torchtracer\n</pre>\n<h2>How to use?</h2>\n<h3>Import <code>torchtracer</code></h3>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchtracer</span> <span class=\"kn\">import</span> <span class=\"n\">Tracer</span>\n</pre>\n<h3>Create an instance of <code>Tracer</code></h3>\n<p>Assume that the root is <code>./checkpoints</code> and current task id is <code>lmmnb</code>.</p>\n<p><em><strong>Avoiding messing working directory, you should make root directory manually.</strong></em></p>\n<pre><span class=\"n\">tracer</span> <span class=\"o\">=</span> <span class=\"n\">Tracer</span><span class=\"p\">(</span><span class=\"s1\">'checkpoints'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">attach</span><span class=\"p\">(</span><span class=\"s1\">'lmmnb'</span><span class=\"p\">)</span>\n</pre>\n<p>This step will create a directory <code>checkpoints</code> inside which is a directory <code>lmmnb</code> for current AI task.</p>\n<p>Also, you could call <code>.attach()</code> without task id. <strong>Datetime will be used as task id.</strong></p>\n<pre><span class=\"n\">tracer</span> <span class=\"o\">=</span> <span class=\"n\">Tracer</span><span class=\"p\">(</span><span class=\"s1\">'checkpoints'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">attach</span><span class=\"p\">()</span>\n</pre>\n<h3>Saving config</h3>\n<p>Raw config should be a <code>dict</code> like this:</p>\n<pre><span class=\"c1\"># `net` is a defined nn.Module</span>\n<span class=\"n\">args</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'epoch_n'</span><span class=\"p\">:</span> <span class=\"mi\">120</span><span class=\"p\">,</span>\n        <span class=\"s1\">'batch_size'</span><span class=\"p\">:</span> <span class=\"mi\">10</span><span class=\"p\">,</span>\n        <span class=\"s1\">'criterion'</span><span class=\"p\">:</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">MSELoss</span><span class=\"p\">(),</span>\n        <span class=\"s1\">'optimizer'</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">RMSprop</span><span class=\"p\">(</span><span class=\"n\">net</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">(),</span> <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">1e-3</span><span class=\"p\">)}</span>\n</pre>\n<p>The config dict should be wrapped with <code>torchtracer.data.Config</code></p>\n<pre><span class=\"n\">cfg</span> <span class=\"o\">=</span> <span class=\"n\">Config</span><span class=\"p\">(</span><span class=\"n\">args</span><span class=\"p\">)</span>\n<span class=\"n\">tracer</span><span class=\"o\">.</span><span class=\"n\">store</span><span class=\"p\">(</span><span class=\"n\">cfg</span><span class=\"p\">)</span>\n</pre>\n<p>This step will create <code>config.json</code> in <code>./checkpoints/lmmnb/</code>, which contains JSON information like this:</p>\n<pre><span class=\"p\">{</span>\n  <span class=\"nt\">\"epoch_n\"</span><span class=\"p\">:</span> <span class=\"mi\">120</span><span class=\"p\">,</span>\n  <span class=\"nt\">\"batch_size\"</span><span class=\"p\">:</span> <span class=\"mi\">10</span><span class=\"p\">,</span>\n  <span class=\"nt\">\"criterion\"</span><span class=\"p\">:</span> <span class=\"s2\">\"MSELoss\"</span><span class=\"p\">,</span>\n  <span class=\"nt\">\"optimizer\"</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n    <span class=\"nt\">\"lr\"</span><span class=\"p\">:</span> <span class=\"mf\">0.001</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"momentum\"</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"alpha\"</span><span class=\"p\">:</span> <span class=\"mf\">0.99</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"eps\"</span><span class=\"p\">:</span> <span class=\"mf\">1e-08</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"centered\"</span><span class=\"p\">:</span> <span class=\"kc\">false</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"weight_decay\"</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"name\"</span><span class=\"p\">:</span> <span class=\"s2\">\"RMSprop\"</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</pre>\n<h3>Logging</h3>\n<p>During the training iteration, you could print any information you want by using <code>Tracer.log(msg, file)</code>.</p>\n<p>If <code>file</code> not specified, it will output <code>msg</code> to <code>./checkpoints/lmmnb/log</code>. Otherwise, it will be <code>./checkpoints/lmmnb/something.log</code>.</p>\n<pre><span class=\"n\">tracer</span><span class=\"o\">.</span><span class=\"n\">log</span><span class=\"p\">(</span><span class=\"n\">msg</span><span class=\"o\">=</span><span class=\"s1\">'Epoch #</span><span class=\"si\">{:03d}</span><span class=\"se\">\\t</span><span class=\"s1\">train_loss: </span><span class=\"si\">{:.4f}</span><span class=\"se\">\\t</span><span class=\"s1\">valid_loss: </span><span class=\"si\">{:.4f}</span><span class=\"s1\">'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">epoch</span><span class=\"p\">,</span> <span class=\"n\">train_loss</span><span class=\"p\">,</span> <span class=\"n\">valid_loss</span><span class=\"p\">),</span>\n           <span class=\"n\">file</span><span class=\"o\">=</span><span class=\"s1\">'losses'</span><span class=\"p\">)</span>\n</pre>\n<p>This step will create a log file <code>losses.log</code> in <code>./checkpoints/lmmnb/</code>, which contains logs like:</p>\n<pre>Epoch #001\ttrain_loss: 18.6356\tvalid_loss: 21.3882\nEpoch #002\ttrain_loss: 19.1731\tvalid_loss: 17.8482\nEpoch #003\ttrain_loss: 19.6756\tvalid_loss: 19.1418\nEpoch #004\ttrain_loss: 20.0638\tvalid_loss: 18.3875\nEpoch #005\ttrain_loss: 18.4679\tvalid_loss: 19.6304\n...\n</pre>\n<h3>Saving model</h3>\n<p>The model object should be wrapped with <code>torchtracer.data.Model</code></p>\n<p>If <code>file</code> not specified, it will generates model files <code>model.txt</code>. Otherwise, it will be <code>somename.txt</code></p>\n<pre><span class=\"n\">tracer</span><span class=\"o\">.</span><span class=\"n\">store</span><span class=\"p\">(</span><span class=\"n\">Model</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">),</span> <span class=\"n\">file</span><span class=\"o\">=</span><span class=\"s1\">'somename'</span><span class=\"p\">)</span>\n</pre>\n<p>This step will create 2 files:</p>\n<ul>\n<li><strong>description</strong>: <code>somename.txt</code></li>\n</ul>\n<pre>Sequential\nSequential(\n  (0): Linear(in_features=1, out_features=6, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=6, out_features=12, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=12, out_features=12, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=12, out_features=1, bias=True)\n)\n</pre>\n<ul>\n<li><strong>parameters</strong>: <code>somename.pth</code></li>\n</ul>\n<h3>Saving matplotlib images</h3>\n<p>Use <code>tracer.store(figure, file)</code> to save matplotlib figure in <code>images/</code></p>\n<pre><span class=\"c1\"># assume that `train_losses` and `valid_losses` are lists of losses. </span>\n<span class=\"c1\"># create figure manually.</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">train_losses</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"s1\">'train loss'</span><span class=\"p\">,</span> <span class=\"n\">c</span><span class=\"o\">=</span><span class=\"s1\">'b'</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">valid_losses</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"s1\">'valid loss'</span><span class=\"p\">,</span> <span class=\"n\">c</span><span class=\"o\">=</span><span class=\"s1\">'r'</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">title</span><span class=\"p\">(</span><span class=\"s1\">'Demo Learning on SQRT'</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">legend</span><span class=\"p\">()</span>\n<span class=\"c1\"># save figure. remember to call `plt.gcf()`</span>\n<span class=\"n\">tracer</span><span class=\"o\">.</span><span class=\"n\">store</span><span class=\"p\">(</span><span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">gcf</span><span class=\"p\">(),</span> <span class=\"s1\">'losses.png'</span><span class=\"p\">)</span>\n</pre>\n<p>This step will save a png file <code>losses.png</code> representing losses curves.</p>\n<h3>Progress bar for epochs</h3>\n<p>Use <code>tracer.epoch_bar_init(total)</code> to initialize a progress bar.</p>\n<pre><span class=\"n\">tracer</span><span class=\"o\">.</span><span class=\"n\">epoch_bar_init</span><span class=\"p\">(</span><span class=\"n\">epoch_n</span><span class=\"p\">)</span>\n</pre>\n<p>Use <code>tracer.epoch_bar.update(n=1, **params)</code> to update postfix of the progress bar.</p>\n<pre><span class=\"n\">tracer</span><span class=\"o\">.</span><span class=\"n\">epoch_bar</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">train_loss</span><span class=\"o\">=</span><span class=\"n\">train_loss</span><span class=\"p\">,</span> <span class=\"n\">valid_loss</span><span class=\"o\">=</span><span class=\"n\">train_loss</span><span class=\"p\">)</span>\n</pre>\n<pre>(THIS IS A DEMO) \nTracer start at /home/oidiotlin/projects/torchtracer/checkpoints\nTracer attached with task: rabbit\nEpoch: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 120/120 [00:02&lt;00:00, 41.75it/s, train_loss=0.417, valid_loss=0.417]\n</pre>\n<p><strong>DO NOT FORGET TO CALL</strong> <code>tracer.epoch_bar.close()</code> to finish the bar.</p>\n<h2>Contribute</h2>\n<p>If you like this project, welcome to pull request &amp; create issues.</p>\n\n          </div>"}, "last_serial": 4484801, "releases": {"0.1.4": [{"comment_text": "", "digests": {"md5": "5f40cc4acc7da975d2ecfa79894279fe", "sha256": "8b7f34b655bff5975819d0cb97f711d3de4a7d021a354e3aa9b3473bb2689e46"}, "downloads": -1, "filename": "torchtracer-0.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "5f40cc4acc7da975d2ecfa79894279fe", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6116, "upload_time": "2018-09-20T07:02:38", "upload_time_iso_8601": "2018-09-20T07:02:38.566021Z", "url": "https://files.pythonhosted.org/packages/6c/f1/ec6787592bdc04d03cb1059d7a4618af3b6b2d6582aeb1f7923e16189b64/torchtracer-0.1.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "973fb505cd71e9175bcda7a5255cbbf4", "sha256": "2483667aaab8e63401176cc2a0a6ebfc444c0b91e08630025a923d817ce7a9f8"}, "downloads": -1, "filename": "torchtracer-0.1.4.tar.gz", "has_sig": false, "md5_digest": "973fb505cd71e9175bcda7a5255cbbf4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4905, "upload_time": "2018-09-20T07:02:39", "upload_time_iso_8601": "2018-09-20T07:02:39.855455Z", "url": "https://files.pythonhosted.org/packages/fe/73/6d631297835d46ce7e6c5d87c60eaaac2fb22ec5ae164944341cd85a28c4/torchtracer-0.1.4.tar.gz", "yanked": false}], "0.1.5": [{"comment_text": "", "digests": {"md5": "4d1098fe6b03d35cfa7d4b0e23fa519a", "sha256": "36a670dcdca2133df135fe9c333d58ffd31bdbaf97cc3032a5d48b8c450971de"}, "downloads": -1, "filename": "torchtracer-0.1.5-py3-none-any.whl", "has_sig": false, "md5_digest": "4d1098fe6b03d35cfa7d4b0e23fa519a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6151, "upload_time": "2018-09-21T03:58:35", "upload_time_iso_8601": "2018-09-21T03:58:35.056075Z", "url": "https://files.pythonhosted.org/packages/3e/fd/1654fa7452a7216caed4372170d7daf948db500feb285719bc9f00fa0188/torchtracer-0.1.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4fbe15cd303ceceb5e216634300d9653", "sha256": "84ed9692feb482b773a8b42de831ba9354b87b5a70f22083e754d22c521c6766"}, "downloads": -1, "filename": "torchtracer-0.1.5.tar.gz", "has_sig": false, "md5_digest": "4fbe15cd303ceceb5e216634300d9653", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4938, "upload_time": "2018-09-21T03:58:37", "upload_time_iso_8601": "2018-09-21T03:58:37.157746Z", "url": "https://files.pythonhosted.org/packages/32/f5/03c6ad3300c0a1ce8942b4c4fe2c4c95a476097d6530c7eba9c2e99328e6/torchtracer-0.1.5.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "8386af1b6f2c8e5389752ceef4ace959", "sha256": "8193ef47f4bcfc15cc91cd54dddc079d9b59f819a5831a763844367ebcd46ae3"}, "downloads": -1, "filename": "torchtracer-0.2.0.tar.gz", "has_sig": false, "md5_digest": "8386af1b6f2c8e5389752ceef4ace959", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5628, "upload_time": "2018-11-14T09:00:12", "upload_time_iso_8601": "2018-11-14T09:00:12.735986Z", "url": "https://files.pythonhosted.org/packages/cc/32/148381ba901e60822c5624235d5111bcff529a52cc72ab5d9bcd0281fbd1/torchtracer-0.2.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "8386af1b6f2c8e5389752ceef4ace959", "sha256": "8193ef47f4bcfc15cc91cd54dddc079d9b59f819a5831a763844367ebcd46ae3"}, "downloads": -1, "filename": "torchtracer-0.2.0.tar.gz", "has_sig": false, "md5_digest": "8386af1b6f2c8e5389752ceef4ace959", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5628, "upload_time": "2018-11-14T09:00:12", "upload_time_iso_8601": "2018-11-14T09:00:12.735986Z", "url": "https://files.pythonhosted.org/packages/cc/32/148381ba901e60822c5624235d5111bcff529a52cc72ab5d9bcd0281fbd1/torchtracer-0.2.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:50:06 2020"}