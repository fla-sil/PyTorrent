{"info": {"author": "Bilal Khan", "author_email": "bk@tinymanager.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "<h1 align='center'>\n    Pytorch Zoo\n</h1>\n\n<h4 align='center'>\n    A collection of useful modules and utilities (especially helpful for kaggling) not available in <a href=\"https://pytorch.org\">Pytorch</a>\n</h4>\n\n<p align='center'>\n    <a href=\"https://forthebadge.com\">\n        <img src=\"https://forthebadge.com/images/badges/made-with-python.svg\" alt=\"forthebadge\">\n    </a>\n    <a href=\"https://lgtm.com/projects/g/bkkaggle/pytorch_zoo/context:python\">\n        <img alt=\"Language grade: Python\" src=\"https://img.shields.io/lgtm/grade/python/g/bkkaggle/pytorch_zoo.svg?logo=lgtm&logoWidth=18\"/>\n    </a>\n    <a href=\"https://lgtm.com/projects/g/bkkaggle/pytorch_zoo/alerts/\">\n        <img alt=\"Total alerts\" src=\"https://img.shields.io/lgtm/alerts/g/bkkaggle/pytorch_zoo.svg?logo=lgtm&logoWidth=18\"/>\n    </a>\n    <a href=\"https://github.com/prettier/prettier\">\n        <img src=\"https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square\" alt=\"code style: prettier\" />\n    </a>\n    <a href=\"https://opensource.org/licenses/MIT\">\n        <img src=\"https://img.shields.io/badge/License-MIT-yellow.svg\" alt=\"License: MIT\">\n    </a>\n    <a href=\"http://makeapullrequest.com\">\n        <img src=\"https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square\" alt=\"PRs Welcome\">\n    </a>\n    <a href=\"https://github.com/bkkaggle/pytorch_zoo/issues\">\n        <img alt=\"GitHub issues\" src=\"https://img.shields.io/github/issues/bkkaggle/pytorch_zoo.svg?style=flat\">\n    </a>\n    <a href=\"https://github.com/bkkaggle/pytorch_zoo/pulls\">\n        <img alt=\"GitHub pull requests\" src=\"https://img.shields.io/github/issues-pr/bkkaggle/pytorch_zoo.svg\">\n    </a>\n    <a href=\"https://github.com/bkkaggle/pytorch_zoo/issues\">\n        <img alt=\"GitHub last commit\" src=\"https://img.shields.io/github/last-commit/bkkaggle/pytorch_zoo.svg\">\n    </a>\n\n</p>\n\n<p align='center'>\n    <a href='#overview'>Overview</a> \u2022\n    <a href='#installation'>Installation</a> \u2022\n    <a href='#documentation'>Documentation</a> \u2022\n    <a href='#contributing'>Contributing</a> \u2022\n    <a href='#authors'>Authors</a> \u2022\n    <a href='#license'>License</a> \u2022\n    <a href='#acknowledgements'>Acknowledgements</a>\n</p>\n\n<div>\n    <img src=\"./screenshot.png\" />\n</div>\n\n<p align='center'><strong>Made by <a href='https://github.com/bkkaggle'>Bilal Khan</a> \u2022 https://bilal.software</strong></p>\n\n<!-- START doctoc generated TOC please keep comment here to allow auto update -->\n<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->\n\n- [Installation](#installation)\n- [Documentation](#documentation)\n  - [Notifications](#notifications)\n    - [Sending yourself notifications when your models finish training](#sending-yourself-notifications-when-your-models-finish-training)\n    - [Viewing training progress with tensorboard in a kaggle kernel](#viewing-training-progress-with-tensorboard-in-a-kaggle-kernel)\n  - [Data](#data)\n      - [DynamicSampler(sampler, batch_size=32)](#dynamicsamplersampler-batch_size32)\n      - [trim_tensors(tensors)](#trim_tensorstensors)\n  - [Loss](#loss)\n      - [lovasz_hinge(logits, labels, per_image=True)](#lovasz_hingelogits-labels-per_imagetrue)\n      - [DiceLoss()](#diceloss)\n  - [Metrics](#metrics)\n  - [Modules](#modules)\n      - [SqueezeAndExcitation(in_ch, r=16)](#squeezeandexcitationin_ch-r16)\n      - [ChannelSqueezeAndSpatialExcitation(in_ch)](#channelsqueezeandspatialexcitationin_ch)\n      - [ConcurrentSpatialAndChannelSqueezeAndChannelExcitation(in_ch)](#concurrentspatialandchannelsqueezeandchannelexcitationin_ch)\n      - [GaussianNoise(0.1)](#gaussiannoise01)\n  - [Schedulers](#schedulers)\n      - [CyclicalMomentum(optimizer, base_momentum=0.8, max_momentum=0.9, step_size=2000, mode=\"triangular\")](#cyclicalmomentumoptimizer-base_momentum08-max_momentum09-step_size2000-modetriangular)\n  - [Utils](#utils)\n      - [notify({'value1': 'Notification title', 'value2': 'Notification body'}, key)](#notifyvalue1-notification-title-value2-notification-body-key)\n      - [seed_environment(seed=42)](#seed_environmentseed42)\n      - [gpu_usage(device, digits=4)](#gpu_usagedevice-digits4)\n      - [n_params(model)](#n_paramsmodel)\n      - [save_model(model, fold=0)](#save_modelmodel-fold0)\n      - [load_model(model, fold=0)](#load_modelmodel-fold0)\n      - [save(obj, 'obj.pkl')](#saveobj-objpkl)\n      - [load('obj.pkl')](#loadobjpkl)\n      - [masked_softmax(logits, mask, dim=-1)](#masked_softmaxlogits-mask-dim-1)\n      - [masked_log_softmax(logits, mask, dim=-1)](#masked_log_softmaxlogits-mask-dim-1)\n- [Contributing](#contributing)\n- [Authors](#authors)\n- [License](#license)\n- [Acknowledgements](#acknowledgements)\n\n<!-- END doctoc generated TOC please keep comment here to allow auto update -->\n\n## Installation\n\npytorch_zoo can be installed from pip\n\n```\npip install pytorch_zoo\n```\n\n## Documentation\n\n### Notifications\n\n#### Sending yourself notifications when your models finish training\n\nIFTTT allows you to easily do this. Follow https://medium.com/datadriveninvestor/monitor-progress-of-your-training-remotely-f9404d71b720 to setup an IFTTT webhook and get a secret key.\n\nOnce you have a key, you can send yourself a notification with:\n\n```python\nfrom pytorch_zoo.utils import notify\n\nmessage = f'Validation loss: {val_loss}'\nobj = {'value1': 'Training Finished', 'value2': message}\n\nnotify(obj, [YOUR_SECRET_KEY_HERE])\n```\n\n#### Viewing training progress with tensorboard in a kaggle kernel\n\nMake sure tensorboard is installed in the kernel and run the following in a code cell near the beginning of your kernel:\n\n```python\n!mkdir logs\n!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n!unzip -o ngrok-stable-linux-amd64.zip\nLOG_DIR = './logs'\nget_ipython().system_raw(\n    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n    .format(LOG_DIR)\n)\nget_ipython().system_raw('./ngrok http 6006 &')\n\n!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n\ntemp = !curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys,json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n\nfrom pytorch_zoo.utils import notify\n\nobj = {'value1': 'Tensorboard URL', 'value2': temp[0]}\nnotify(obj, [YOUR_SECRET_KEY_HERE])\n\n!rm ngrok\n!rm ngrok-stable-linux-amd64.zip\n```\n\nThis will start tensorboard, set up a http tunnel, and send you a notification with a url where you can access tensorboard.\n\n### Data\n\n##### [DynamicSampler(sampler, batch_size=32)](./pytorch_zoo/data.py#L4)\n\nA dynamic batch length data sampler. To be used with `trim_tensors`.\n\nImplementation adapted from https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/discussion/94779 and https://github.com/pytorch/pytorch/blob/master/torch/utils/data/sampler.py\n\n```python\ntrain_dataset = data.TensorDataset(data)\nsampler = data.RandomSampler(train_dataset)\nsampler = DynamicSampler(sampler, batch_size=32, drop_last=False)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_sampler=len_sampler)\n\nfor epoch in range(10):\n    for batch in train_loader:\n        batch = trim_tensors(batch)\n        train_batch(...)\n```\n\n_Arguments_:  \n`sampler` (torch.utils.data.Sampler): Base sampler.  \n`batch_size` (int): Size of minibatch.  \n`drop_last` (bool): If `True`, the sampler will drop the last batch if its size would be less than `batch_size`.\n\n##### [trim_tensors(tensors)](./pytorch_zoo/data.py#L48)\n\nTrim padding off of a batch of tensors to the smallest possible length. To be used with `DynamicSampler`.\n\nImplementation adapted from https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/discussion/94779\n\n```python\ntrain_dataset = data.TensorDataset(data)\nsampler = data.RandomSampler(train_dataset)\nsampler = DynamicSampler(sampler, batch_size=32, drop_last=False)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_sampler=len_sampler)\n\nfor epoch in range(10):\n    for batch in train_loader:\n        batch = trim_tensors(batch)\n        train_batch(...)\n```\n\n_Arguments_:  \n`tensors` ([torch.tensor]): list of tensors to trim.\n\n_Returns_:  \n([torch.tensor]): list of trimmed tensors.\n\n### Loss\n\n##### [lovasz_hinge(logits, labels, per_image=True)](./pytorch_zoo/loss.py#L84)\n\nThe binary Lovasz Hinge loss for semantic segmentation.\n\nImplementation adapted from https://github.com/bermanmaxim/LovaszSoftmax\n\n```python\nloss = lovasz_hinge(logits, labels)\n```\n\n_Arguments_:  \n`logits` (torch.tensor): Logits at each pixel (between -\\infty and +\\infty).  \n`labels` (torch.tensor): Binary ground truth masks (0 or 1).  \n`per_image` (bool, optional): Compute the loss per image instead of per batch. Defaults to True.\n\n_Shape_:\n\n-   Input:\n    -   logits: (batch, height, width)\n    -   labels: (batch, height, width)\n-   Output: (batch)\n\n_Returns_:  \n(torch.tensor): The lovasz hinge loss\n\n##### [DiceLoss()](./pytorch_zoo/loss.py#L115)\n\nThe dice loss for semantic segmentation\n\nImplementation adapted from https://www.kaggle.com/soulmachine/siim-deeplabv3\n\n```python\ncriterion = DiceLoss()\nloss = criterion(logits, targets)\n```\n\n_Shape_:\n\n-   Input:\n    -   logits: (batch, \\*)\n    -   targets: (batch, \\*) _same as logits_\n-   Output: (1)\n\n_Returns_:  \n(torch.tensor): The dice loss\n\n### Metrics\n\n### Modules\n\n##### [SqueezeAndExcitation(in_ch, r=16)](./pytorch_zoo/modules.py#L6)\n\nThe channel-wise SE (Squeeze and Excitation) block from the [Squeeze-and-Excitation Networks](https://arxiv.org/abs/1709.01507) paper.\n\nImplementation adapted from https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/65939 and https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/66178\n\n```python\n# in __init__()\nself.SE = SqueezeAndExcitation(in_ch, r=16)\n\n# in forward()\nx = self.SE(x)\n```\n\n_Arguments_:  \n`in_ch` (int): The number of channels in the feature map of the input.  \n`r` (int): The reduction ratio of the intermidiate channels. Default: 16.\n\n_Shape_:\n\n-   Input: (batch, channels, height, width)\n-   Output: (batch, channels, height, width) (same shape as input)\n\n##### [ChannelSqueezeAndSpatialExcitation(in_ch)](./pytorch_zoo/modules.py#L41)\n\nThe sSE (Channel Squeeze and Spatial Excitation) block from the [Concurrent Spatial and Channel \u2018Squeeze & Excitation\u2019 in Fully Convolutional Networks](https://arxiv.org/abs/1803.02579) paper.\n\nImplementation adapted from https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/66178\n\n```python\n# in __init__()\nself.sSE = ChannelSqueezeAndSpatialExcitation(in_ch)\n\n# in forward()\nx = self.sSE(x)\n```\n\n_Arguments_:  \n`in_ch` (int): The number of channels in the feature map of the input.\n\n_Shape_:\n\n-   Input: (batch, channels, height, width)\n-   Output: (batch, channels, height, width) (same shape as input)\n\n##### [ConcurrentSpatialAndChannelSqueezeAndChannelExcitation(in_ch)](./pytorch_zoo/modules.py#L71)\n\nThe scSE (Concurrent Spatial and Channel Squeeze and Channel Excitation) block from the [Concurrent Spatial and Channel \u2018Squeeze & Excitation\u2019 in Fully Convolutional Networks](https://arxiv.org/abs/1803.02579) paper.\n\nImplementation adapted from https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/66178\n\n```python\n# in __init__()\nself.scSE = ConcurrentSpatialAndChannelSqueezeAndChannelExcitation(in_ch, r=16)\n\n# in forward()\nx = self.scSE(x)\n```\n\n_Arguments_:  \n`in_ch` (int): The number of channels in the feature map of the input.  \n`r` (int): The reduction ratio of the intermidiate channels. Default: 16.\n\n_Shape_:\n\n-   Input: (batch, channels, height, width)\n-   Output: (batch, channels, height, width) (same shape as input)\n\n##### [GaussianNoise(0.1)](./pytorch_zoo/modules.py#L104)\n\nA gaussian noise module.\n\n```python\n# in __init__()\nself.gaussian_noise = GaussianNoise(0.1)\n\n# in forward()\nif self.training:\n    x = self.gaussian_noise(x)\n```\n\n_Arguments_:  \n`stddev` (float): The standard deviation of the normal distribution. Default: 0.1.\n\n_Shape_:\n\n-   Input: (batch, \\*)\n-   Output: (batch, \\*) (same shape as input)\n\n### Schedulers\n\n##### [CyclicalMomentum(optimizer, base_momentum=0.8, max_momentum=0.9, step_size=2000, mode=\"triangular\")](./pytorch_zoo/schedulers.py#L7)\n\nPytorch's [cyclical learning rates](https://github.com/pytorch/pytorch/blob/master/torch/optim/lr_scheduler.py), but for momentum, which leads to better results when used with cyclic learning rates, as shown in [A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay](https://arxiv.org/abs/1803.09820).\n\n```python\noptimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\nscheduler = torch.optim.CyclicMomentum(optimizer)\ndata_loader = torch.utils.data.DataLoader(...)\nfor epoch in range(10):\n    for batch in data_loader:\n        scheduler.batch_step()\n        train_batch(...)\n```\n\n_Arguments_:  \n`optimizer` (Optimizer): Wrapped optimizer.  \n`base_momentum` (float or list): Initial momentum which is the lower boundary in the cycle for each param groups. Default: 0.8  \n`max_momentum` (float or list): Upper boundaries in the cycle for each parameter group. scaling function. Default: 0.9  \n`step_size` (int): Number of training iterations per half cycle. Authors suggest setting step_size 2-8 x training iterations in epoch. Default: 2000  \n`mode` (str): One of {triangular, triangular2, exp_range}. Default: 'triangular'  \n`gamma` (float): Constant in 'exp_range' scaling function. Default: 1.0  \n`scale_fn` (function): Custom scaling policy defined by a single argument lambda function. Mode paramater is ignored Default: None  \n`scale_mode` (str): {'cycle', 'iterations'}. Defines whether scale_fn is evaluated on cycle number or cycle iterations (training iterations since start of cycle). Default: 'cycle'  \n`last_batch_iteration` (int): The index of the last batch. Default: -1\n\n### Utils\n\n##### [notify({'value1': 'Notification title', 'value2': 'Notification body'}, key)](./pytorch_zoo/utils.py#L13)\n\nSend a notification to your phone with IFTTT\n\nSetup a IFTTT webhook with https://medium.com/datadriveninvestor/monitor-progress-of-your-training-remotely-f9404d71b720\n\n```python\nnotify({'value1': 'Notification title', 'value2': 'Notification body'}, key=[YOUR_PRIVATE_KEY_HERE])\n```\n\n_Arguments_:  \n`obj` (Object): Object to send to IFTTT  \n`key` ([type]): IFTTT webhook key\n\n##### [seed_environment(seed=42)](./pytorch_zoo/utils.py#L25)\n\nSet random seeds for python, numpy, and pytorch to ensure reproducible research.\n\n```python\nseed_envirionment(42)\n```\n\n_Arguments_:  \n`seed` (int): The random seed to set.\n\n##### [gpu_usage(device, digits=4)](./pytorch_zoo/utils.py#L39)\n\nPrints the amount of GPU memory currently allocated in GB.\n\n```python\ngpu_usage(device, digits=4)\n```\n\n_Arguments_:  \n`device` (torch.device, optional): The device you want to check. Defaults to device.  \n`digits` (int, optional): The number of digits of precision. Defaults to 4.\n\n##### [n_params(model)](./pytorch_zoo/utils.py#L53)\n\nReturn the number of parameters in a pytorch model.\n\n```python\nprint(n_params(model))\n```\n\n_Arguments_:  \n`model` (nn.Module): The model to analyze.\n\n_Returns_:  \n(int): The number of parameters in the model.\n\n##### [save_model(model, fold=0)](./pytorch_zoo/utils.py#L71)\n\nSave a trained pytorch model on a particular cross-validation fold to disk.\n\nImplementation adapted from https://github.com/floydhub/save-and-resume.\n\n```python\nsave_model(model, fold=0)\n```\n\n_Arguments_:  \n`model` (nn.Module): The model to save.  \n`fold` (int): The cross-validation fold the model was trained on.\n\n##### [load_model(model, fold=0)](./pytorch_zoo/utils.py#L84)\n\nLoad a trained pytorch model saved to disk using `save_model`.\n\n```python\nmodel = load_model(model, fold=0)\n```\n\n_Arguments_:\n`model` (nn.Module): The model to save.  \n`fold` (int): Which saved model fold to load.\n\n_Returns_:  \n(nn.Module): The same model that was passed in, but with the pretrained weights loaded.\n\n##### [save(obj, 'obj.pkl')](./pytorch_zoo/utils.py#L99)\n\nSave an object to disk.\n\n```python\nsave(tokenizer, 'tokenizer.pkl')\n```\n\n_Arguments_:  \n`obj` (Object): The object to save.  \n`filename` (String): The name of the file to save the object to.\n\n##### [load('obj.pkl')](./pytorch_zoo/utils.py#L110)\n\nLoad an object saved to disk with `save`.\n\n```python\ntokenizer = load('tokenizer.pkl')\n```\n\n_Arguments_:  \n`path` (String): The path to the saved object.\n\n_Returns_:  \n(Object): The loaded object.\n\n##### [masked_softmax(logits, mask, dim=-1)](./pytorch_zoo/utils.py#L124)\n\nA masked softmax module to correctly implement attention in Pytorch.\n\nImplementation adapted from: https://github.com/allenai/allennlp/blob/master/allennlp/nn/util.py\n\n```python\nout = masked_softmax(logits, mask, dim=-1)\n```\n\n_Arguments_:  \n`vector` (torch.tensor): The tensor to softmax.  \n`mask` (torch.tensor): The tensor to indicate which indices are to be masked and not included in the softmax operation.  \n`dim` (int, optional): The dimension to softmax over. Defaults to -1.  \n`memory_efficient` (bool, optional): Whether to use a less precise, but more memory efficient implementation of masked softmax. Defaults to False.  \n`mask_fill_value` ([type], optional): The value to fill masked values with if `memory_efficient` is `True`. Defaults to -1e32.\n\n_Returns_:  \n(torch.tensor): The masked softmaxed output\n\n##### [masked_log_softmax(logits, mask, dim=-1)](./pytorch_zoo/utils.py#L175)\n\nA masked log-softmax module to correctly implement attention in Pytorch.\n\nImplementation adapted from: https://github.com/allenai/allennlp/blob/master/allennlp/nn/util.py\n\n```python\nout = masked_log_softmax(logits, mask, dim=-1)\n```\n\n_Arguments_:  \n`vector` (torch.tensor): The tensor to log-softmax.  \n`mask` (torch.tensor): The tensor to indicate which indices are to be masked and not included in the log-softmax operation.  \n`dim` (int, optional): The dimension to log-softmax over. Defaults to -1.\n\n_Returns_:  \n(torch.tensor): The masked log-softmaxed output\n\n## Contributing\n\nThis repository is still a work in progress, so if you find a bug, think there is something missing, or have any suggestions for new features or modules, feel free to open an issue or a pull request. Feel free to use the library or code from it in your own projects, and if you feel that some code used in this project hasn't been properly accredited, please open an issue.\n\n## Authors\n\n-   _Bilal Khan_ - _Initial work_\n\n## License\n\nThis project is licensed under the MIT License - see the [license](LICENSE) file for details\n\n## Acknowledgements\n\nThis project contains code adapted from:\n\n-   https://github.com/bermanmaxim/LovaszSoftmax\n-   https://www.kaggle.com/aglotero/another-iou-metric\n-   https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/66178\n-   https://github.com/bckenstler/CLR\n-   https://github.com/floydhub/save-and-resume\n-   https://github.com/allenai/allennlp\n-   https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/discussion/94779\n\nThis README is based on:\n\n-   https://github.com/mxbi/mlcrate\n-   https://github.com/athityakumar/colorls\n-   https://github.com/amitmerchant1990/electron-markdownify/blob/master/README.md\n-   https://github.com/rish-16/gpt2client\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/bkahn-github/pytorch_zoo", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "pytorch-zoo", "package_url": "https://pypi.org/project/pytorch-zoo/", "platform": "", "project_url": "https://pypi.org/project/pytorch-zoo/", "project_urls": {"Homepage": "https://github.com/bkahn-github/pytorch_zoo"}, "release_url": "https://pypi.org/project/pytorch-zoo/1.2.2/", "requires_dist": null, "requires_python": "", "summary": "A collection of useful modules and utilities for kaggle not available in Pytorch", "version": "1.2.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>\n    Pytorch Zoo\n</h1>\n<h4>\n    A collection of useful modules and utilities (especially helpful for kaggling) not available in <a href=\"https://pytorch.org\" rel=\"nofollow\">Pytorch</a>\n</h4>\n<p align=\"center\">\n    <a href=\"https://forthebadge.com\" rel=\"nofollow\">\n        <img alt=\"forthebadge\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/7cefdfa620eb623843291a3c32383f169b6a60e0/68747470733a2f2f666f7274686562616467652e636f6d2f696d616765732f6261646765732f6d6164652d776974682d707974686f6e2e737667\">\n    </a>\n    <a href=\"https://lgtm.com/projects/g/bkkaggle/pytorch_zoo/context:python\" rel=\"nofollow\">\n        <img alt=\"Language grade: Python\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ecd72170a2707d0f833d81da3aeb5770a7e09b2d/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f67726164652f707974686f6e2f672f626b6b6167676c652f7079746f7263685f7a6f6f2e7376673f6c6f676f3d6c67746d266c6f676f57696474683d3138\">\n    </a>\n    <a href=\"https://lgtm.com/projects/g/bkkaggle/pytorch_zoo/alerts/\" rel=\"nofollow\">\n        <img alt=\"Total alerts\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b9dbd3aa296f5a4ac2c1e53cca8eca030a2770bf/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f616c657274732f672f626b6b6167676c652f7079746f7263685f7a6f6f2e7376673f6c6f676f3d6c67746d266c6f676f57696474683d3138\">\n    </a>\n    <a href=\"https://github.com/prettier/prettier\" rel=\"nofollow\">\n        <img alt=\"code style: prettier\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/abef8dea253d36d32e0b3668748c16fef99e6e8d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64655f7374796c652d70726574746965722d6666363962342e7376673f7374796c653d666c61742d737175617265\">\n    </a>\n    <a href=\"https://opensource.org/licenses/MIT\" rel=\"nofollow\">\n        <img alt=\"License: MIT\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8645b002dd7ec1b54275a80574942e7a318e03c6/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d79656c6c6f772e737667\">\n    </a>\n    <a href=\"http://makeapullrequest.com\" rel=\"nofollow\">\n        <img alt=\"PRs Welcome\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a8897c5f5e8a5eacb8ddf983bb640b73cc10464c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5052732d77656c636f6d652d627269676874677265656e2e7376673f7374796c653d666c61742d737175617265\">\n    </a>\n    <a href=\"https://github.com/bkkaggle/pytorch_zoo/issues\" rel=\"nofollow\">\n        <img alt=\"GitHub issues\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/44a4b0a93891fabd47ef87f0e3b56e52e884ac72/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f626b6b6167676c652f7079746f7263685f7a6f6f2e7376673f7374796c653d666c6174\">\n    </a>\n    <a href=\"https://github.com/bkkaggle/pytorch_zoo/pulls\" rel=\"nofollow\">\n        <img alt=\"GitHub pull requests\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1194a179a4a1db3e98f6cf08687a10082bcc8a9e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f626b6b6167676c652f7079746f7263685f7a6f6f2e737667\">\n    </a>\n    <a href=\"https://github.com/bkkaggle/pytorch_zoo/issues\" rel=\"nofollow\">\n        <img alt=\"GitHub last commit\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a7ea71e4ca7e8fcd81fd666d689a1350c099c465/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6173742d636f6d6d69742f626b6b6167676c652f7079746f7263685f7a6f6f2e737667\">\n    </a>\n</p>\n<p align=\"center\">\n    <a href=\"#overview\" rel=\"nofollow\">Overview</a> \u2022\n    <a href=\"#installation\" rel=\"nofollow\">Installation</a> \u2022\n    <a href=\"#documentation\" rel=\"nofollow\">Documentation</a> \u2022\n    <a href=\"#contributing\" rel=\"nofollow\">Contributing</a> \u2022\n    <a href=\"#authors\" rel=\"nofollow\">Authors</a> \u2022\n    <a href=\"#license\" rel=\"nofollow\">License</a> \u2022\n    <a href=\"#acknowledgements\" rel=\"nofollow\">Acknowledgements</a>\n</p>\n<div>\n    <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/05c16a086a8e30adf42daa3b4eee692a72f61901/2e2f73637265656e73686f742e706e67\">\n</div>\n<p align=\"center\"><strong>Made by <a href=\"https://github.com/bkkaggle\" rel=\"nofollow\">Bilal Khan</a> \u2022 https://bilal.software</strong></p>\n\n\n<ul>\n<li><a href=\"#installation\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#documentation\" rel=\"nofollow\">Documentation</a>\n<ul>\n<li><a href=\"#notifications\" rel=\"nofollow\">Notifications</a>\n<ul>\n<li><a href=\"#sending-yourself-notifications-when-your-models-finish-training\" rel=\"nofollow\">Sending yourself notifications when your models finish training</a></li>\n<li><a href=\"#viewing-training-progress-with-tensorboard-in-a-kaggle-kernel\" rel=\"nofollow\">Viewing training progress with tensorboard in a kaggle kernel</a></li>\n</ul>\n</li>\n<li><a href=\"#data\" rel=\"nofollow\">Data</a>\n<ul>\n<li><a href=\"#dynamicsamplersampler-batch_size32\" rel=\"nofollow\">DynamicSampler(sampler, batch_size=32)</a></li>\n<li><a href=\"#trim_tensorstensors\" rel=\"nofollow\">trim_tensors(tensors)</a></li>\n</ul>\n</li>\n<li><a href=\"#loss\" rel=\"nofollow\">Loss</a>\n<ul>\n<li><a href=\"#lovasz_hingelogits-labels-per_imagetrue\" rel=\"nofollow\">lovasz_hinge(logits, labels, per_image=True)</a></li>\n<li><a href=\"#diceloss\" rel=\"nofollow\">DiceLoss()</a></li>\n</ul>\n</li>\n<li><a href=\"#metrics\" rel=\"nofollow\">Metrics</a></li>\n<li><a href=\"#modules\" rel=\"nofollow\">Modules</a>\n<ul>\n<li><a href=\"#squeezeandexcitationin_ch-r16\" rel=\"nofollow\">SqueezeAndExcitation(in_ch, r=16)</a></li>\n<li><a href=\"#channelsqueezeandspatialexcitationin_ch\" rel=\"nofollow\">ChannelSqueezeAndSpatialExcitation(in_ch)</a></li>\n<li><a href=\"#concurrentspatialandchannelsqueezeandchannelexcitationin_ch\" rel=\"nofollow\">ConcurrentSpatialAndChannelSqueezeAndChannelExcitation(in_ch)</a></li>\n<li><a href=\"#gaussiannoise01\" rel=\"nofollow\">GaussianNoise(0.1)</a></li>\n</ul>\n</li>\n<li><a href=\"#schedulers\" rel=\"nofollow\">Schedulers</a>\n<ul>\n<li><a href=\"#cyclicalmomentumoptimizer-base_momentum08-max_momentum09-step_size2000-modetriangular\" rel=\"nofollow\">CyclicalMomentum(optimizer, base_momentum=0.8, max_momentum=0.9, step_size=2000, mode=\"triangular\")</a></li>\n</ul>\n</li>\n<li><a href=\"#utils\" rel=\"nofollow\">Utils</a>\n<ul>\n<li><a href=\"#notifyvalue1-notification-title-value2-notification-body-key\" rel=\"nofollow\">notify({'value1': 'Notification title', 'value2': 'Notification body'}, key)</a></li>\n<li><a href=\"#seed_environmentseed42\" rel=\"nofollow\">seed_environment(seed=42)</a></li>\n<li><a href=\"#gpu_usagedevice-digits4\" rel=\"nofollow\">gpu_usage(device, digits=4)</a></li>\n<li><a href=\"#n_paramsmodel\" rel=\"nofollow\">n_params(model)</a></li>\n<li><a href=\"#save_modelmodel-fold0\" rel=\"nofollow\">save_model(model, fold=0)</a></li>\n<li><a href=\"#load_modelmodel-fold0\" rel=\"nofollow\">load_model(model, fold=0)</a></li>\n<li><a href=\"#saveobj-objpkl\" rel=\"nofollow\">save(obj, 'obj.pkl')</a></li>\n<li><a href=\"#loadobjpkl\" rel=\"nofollow\">load('obj.pkl')</a></li>\n<li><a href=\"#masked_softmaxlogits-mask-dim-1\" rel=\"nofollow\">masked_softmax(logits, mask, dim=-1)</a></li>\n<li><a href=\"#masked_log_softmaxlogits-mask-dim-1\" rel=\"nofollow\">masked_log_softmax(logits, mask, dim=-1)</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"#contributing\" rel=\"nofollow\">Contributing</a></li>\n<li><a href=\"#authors\" rel=\"nofollow\">Authors</a></li>\n<li><a href=\"#license\" rel=\"nofollow\">License</a></li>\n<li><a href=\"#acknowledgements\" rel=\"nofollow\">Acknowledgements</a></li>\n</ul>\n\n<h2>Installation</h2>\n<p>pytorch_zoo can be installed from pip</p>\n<pre><code>pip install pytorch_zoo\n</code></pre>\n<h2>Documentation</h2>\n<h3>Notifications</h3>\n<h4>Sending yourself notifications when your models finish training</h4>\n<p>IFTTT allows you to easily do this. Follow <a href=\"https://medium.com/datadriveninvestor/monitor-progress-of-your-training-remotely-f9404d71b720\" rel=\"nofollow\">https://medium.com/datadriveninvestor/monitor-progress-of-your-training-remotely-f9404d71b720</a> to setup an IFTTT webhook and get a secret key.</p>\n<p>Once you have a key, you can send yourself a notification with:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pytorch_zoo.utils</span> <span class=\"kn\">import</span> <span class=\"n\">notify</span>\n\n<span class=\"n\">message</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s1\">'Validation loss: </span><span class=\"si\">{</span><span class=\"n\">val_loss</span><span class=\"si\">}</span><span class=\"s1\">'</span>\n<span class=\"n\">obj</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'value1'</span><span class=\"p\">:</span> <span class=\"s1\">'Training Finished'</span><span class=\"p\">,</span> <span class=\"s1\">'value2'</span><span class=\"p\">:</span> <span class=\"n\">message</span><span class=\"p\">}</span>\n\n<span class=\"n\">notify</span><span class=\"p\">(</span><span class=\"n\">obj</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">YOUR_SECRET_KEY_HERE</span><span class=\"p\">])</span>\n</pre>\n<h4>Viewing training progress with tensorboard in a kaggle kernel</h4>\n<p>Make sure tensorboard is installed in the kernel and run the following in a code cell near the beginning of your kernel:</p>\n<pre><span class=\"err\">!</span><span class=\"n\">mkdir</span> <span class=\"n\">logs</span>\n<span class=\"err\">!</span><span class=\"n\">wget</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"nb\">bin</span><span class=\"o\">.</span><span class=\"n\">equinox</span><span class=\"o\">.</span><span class=\"n\">io</span><span class=\"o\">/</span><span class=\"n\">c</span><span class=\"o\">/</span><span class=\"mi\">4</span><span class=\"n\">VmDzA7iaHb</span><span class=\"o\">/</span><span class=\"n\">ngrok</span><span class=\"o\">-</span><span class=\"n\">stable</span><span class=\"o\">-</span><span class=\"n\">linux</span><span class=\"o\">-</span><span class=\"n\">amd64</span><span class=\"o\">.</span><span class=\"n\">zip</span>\n<span class=\"err\">!</span><span class=\"n\">unzip</span> <span class=\"o\">-</span><span class=\"n\">o</span> <span class=\"n\">ngrok</span><span class=\"o\">-</span><span class=\"n\">stable</span><span class=\"o\">-</span><span class=\"n\">linux</span><span class=\"o\">-</span><span class=\"n\">amd64</span><span class=\"o\">.</span><span class=\"n\">zip</span>\n<span class=\"n\">LOG_DIR</span> <span class=\"o\">=</span> <span class=\"s1\">'./logs'</span>\n<span class=\"n\">get_ipython</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">system_raw</span><span class=\"p\">(</span>\n    <span class=\"s1\">'tensorboard --logdir </span><span class=\"si\">{}</span><span class=\"s1\"> --host 0.0.0.0 --port 6006 &amp;'</span>\n    <span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">LOG_DIR</span><span class=\"p\">)</span>\n<span class=\"p\">)</span>\n<span class=\"n\">get_ipython</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">system_raw</span><span class=\"p\">(</span><span class=\"s1\">'./ngrok http 6006 &amp;'</span><span class=\"p\">)</span>\n\n<span class=\"err\">!</span><span class=\"n\">curl</span> <span class=\"o\">-</span><span class=\"n\">s</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">localhost</span><span class=\"p\">:</span><span class=\"mi\">4040</span><span class=\"o\">/</span><span class=\"n\">api</span><span class=\"o\">/</span><span class=\"n\">tunnels</span> <span class=\"o\">|</span> <span class=\"n\">python3</span> <span class=\"o\">-</span><span class=\"n\">c</span> \\\n    <span class=\"s2\">\"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"</span>\n\n<span class=\"n\">temp</span> <span class=\"o\">=</span> <span class=\"err\">!</span><span class=\"n\">curl</span> <span class=\"o\">-</span><span class=\"n\">s</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">localhost</span><span class=\"p\">:</span><span class=\"mi\">4040</span><span class=\"o\">/</span><span class=\"n\">api</span><span class=\"o\">/</span><span class=\"n\">tunnels</span> <span class=\"o\">|</span> <span class=\"n\">python3</span> <span class=\"o\">-</span><span class=\"n\">c</span> <span class=\"s2\">\"import sys,json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">pytorch_zoo.utils</span> <span class=\"kn\">import</span> <span class=\"n\">notify</span>\n\n<span class=\"n\">obj</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'value1'</span><span class=\"p\">:</span> <span class=\"s1\">'Tensorboard URL'</span><span class=\"p\">,</span> <span class=\"s1\">'value2'</span><span class=\"p\">:</span> <span class=\"n\">temp</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]}</span>\n<span class=\"n\">notify</span><span class=\"p\">(</span><span class=\"n\">obj</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">YOUR_SECRET_KEY_HERE</span><span class=\"p\">])</span>\n\n<span class=\"err\">!</span><span class=\"n\">rm</span> <span class=\"n\">ngrok</span>\n<span class=\"err\">!</span><span class=\"n\">rm</span> <span class=\"n\">ngrok</span><span class=\"o\">-</span><span class=\"n\">stable</span><span class=\"o\">-</span><span class=\"n\">linux</span><span class=\"o\">-</span><span class=\"n\">amd64</span><span class=\"o\">.</span><span class=\"n\">zip</span>\n</pre>\n<p>This will start tensorboard, set up a http tunnel, and send you a notification with a url where you can access tensorboard.</p>\n<h3>Data</h3>\n<h5><a href=\"./pytorch_zoo/data.py#L4\" rel=\"nofollow\">DynamicSampler(sampler, batch_size=32)</a></h5>\n<p>A dynamic batch length data sampler. To be used with <code>trim_tensors</code>.</p>\n<p>Implementation adapted from <a href=\"https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/discussion/94779\" rel=\"nofollow\">https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/discussion/94779</a> and <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/utils/data/sampler.py\" rel=\"nofollow\">https://github.com/pytorch/pytorch/blob/master/torch/utils/data/sampler.py</a></p>\n<pre><span class=\"n\">train_dataset</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">TensorDataset</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">)</span>\n<span class=\"n\">sampler</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">RandomSampler</span><span class=\"p\">(</span><span class=\"n\">train_dataset</span><span class=\"p\">)</span>\n<span class=\"n\">sampler</span> <span class=\"o\">=</span> <span class=\"n\">DynamicSampler</span><span class=\"p\">(</span><span class=\"n\">sampler</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"n\">drop_last</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n<span class=\"n\">train_loader</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"n\">train_dataset</span><span class=\"p\">,</span> <span class=\"n\">batch_sampler</span><span class=\"o\">=</span><span class=\"n\">len_sampler</span><span class=\"p\">)</span>\n\n<span class=\"k\">for</span> <span class=\"n\">epoch</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">):</span>\n    <span class=\"k\">for</span> <span class=\"n\">batch</span> <span class=\"ow\">in</span> <span class=\"n\">train_loader</span><span class=\"p\">:</span>\n        <span class=\"n\">batch</span> <span class=\"o\">=</span> <span class=\"n\">trim_tensors</span><span class=\"p\">(</span><span class=\"n\">batch</span><span class=\"p\">)</span>\n        <span class=\"n\">train_batch</span><span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">)</span>\n</pre>\n<p><em>Arguments</em>:<br>\n<code>sampler</code> (torch.utils.data.Sampler): Base sampler.<br>\n<code>batch_size</code> (int): Size of minibatch.<br>\n<code>drop_last</code> (bool): If <code>True</code>, the sampler will drop the last batch if its size would be less than <code>batch_size</code>.</p>\n<h5><a href=\"./pytorch_zoo/data.py#L48\" rel=\"nofollow\">trim_tensors(tensors)</a></h5>\n<p>Trim padding off of a batch of tensors to the smallest possible length. To be used with <code>DynamicSampler</code>.</p>\n<p>Implementation adapted from <a href=\"https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/discussion/94779\" rel=\"nofollow\">https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/discussion/94779</a></p>\n<pre><span class=\"n\">train_dataset</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">TensorDataset</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">)</span>\n<span class=\"n\">sampler</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">RandomSampler</span><span class=\"p\">(</span><span class=\"n\">train_dataset</span><span class=\"p\">)</span>\n<span class=\"n\">sampler</span> <span class=\"o\">=</span> <span class=\"n\">DynamicSampler</span><span class=\"p\">(</span><span class=\"n\">sampler</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"n\">drop_last</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n<span class=\"n\">train_loader</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"n\">train_dataset</span><span class=\"p\">,</span> <span class=\"n\">batch_sampler</span><span class=\"o\">=</span><span class=\"n\">len_sampler</span><span class=\"p\">)</span>\n\n<span class=\"k\">for</span> <span class=\"n\">epoch</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">):</span>\n    <span class=\"k\">for</span> <span class=\"n\">batch</span> <span class=\"ow\">in</span> <span class=\"n\">train_loader</span><span class=\"p\">:</span>\n        <span class=\"n\">batch</span> <span class=\"o\">=</span> <span class=\"n\">trim_tensors</span><span class=\"p\">(</span><span class=\"n\">batch</span><span class=\"p\">)</span>\n        <span class=\"n\">train_batch</span><span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">)</span>\n</pre>\n<p><em>Arguments</em>:<br>\n<code>tensors</code> ([torch.tensor]): list of tensors to trim.</p>\n<p><em>Returns</em>:<br>\n([torch.tensor]): list of trimmed tensors.</p>\n<h3>Loss</h3>\n<h5><a href=\"./pytorch_zoo/loss.py#L84\" rel=\"nofollow\">lovasz_hinge(logits, labels, per_image=True)</a></h5>\n<p>The binary Lovasz Hinge loss for semantic segmentation.</p>\n<p>Implementation adapted from <a href=\"https://github.com/bermanmaxim/LovaszSoftmax\" rel=\"nofollow\">https://github.com/bermanmaxim/LovaszSoftmax</a></p>\n<pre><span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">lovasz_hinge</span><span class=\"p\">(</span><span class=\"n\">logits</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">)</span>\n</pre>\n<p><em>Arguments</em>:<br>\n<code>logits</code> (torch.tensor): Logits at each pixel (between -\\infty and +\\infty).<br>\n<code>labels</code> (torch.tensor): Binary ground truth masks (0 or 1).<br>\n<code>per_image</code> (bool, optional): Compute the loss per image instead of per batch. Defaults to True.</p>\n<p><em>Shape</em>:</p>\n<ul>\n<li>Input:\n<ul>\n<li>logits: (batch, height, width)</li>\n<li>labels: (batch, height, width)</li>\n</ul>\n</li>\n<li>Output: (batch)</li>\n</ul>\n<p><em>Returns</em>:<br>\n(torch.tensor): The lovasz hinge loss</p>\n<h5><a href=\"./pytorch_zoo/loss.py#L115\" rel=\"nofollow\">DiceLoss()</a></h5>\n<p>The dice loss for semantic segmentation</p>\n<p>Implementation adapted from <a href=\"https://www.kaggle.com/soulmachine/siim-deeplabv3\" rel=\"nofollow\">https://www.kaggle.com/soulmachine/siim-deeplabv3</a></p>\n<pre><span class=\"n\">criterion</span> <span class=\"o\">=</span> <span class=\"n\">DiceLoss</span><span class=\"p\">()</span>\n<span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">criterion</span><span class=\"p\">(</span><span class=\"n\">logits</span><span class=\"p\">,</span> <span class=\"n\">targets</span><span class=\"p\">)</span>\n</pre>\n<p><em>Shape</em>:</p>\n<ul>\n<li>Input:\n<ul>\n<li>logits: (batch, *)</li>\n<li>targets: (batch, *) <em>same as logits</em></li>\n</ul>\n</li>\n<li>Output: (1)</li>\n</ul>\n<p><em>Returns</em>:<br>\n(torch.tensor): The dice loss</p>\n<h3>Metrics</h3>\n<h3>Modules</h3>\n<h5><a href=\"./pytorch_zoo/modules.py#L6\" rel=\"nofollow\">SqueezeAndExcitation(in_ch, r=16)</a></h5>\n<p>The channel-wise SE (Squeeze and Excitation) block from the <a href=\"https://arxiv.org/abs/1709.01507\" rel=\"nofollow\">Squeeze-and-Excitation Networks</a> paper.</p>\n<p>Implementation adapted from <a href=\"https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/65939\" rel=\"nofollow\">https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/65939</a> and <a href=\"https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/66178\" rel=\"nofollow\">https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/66178</a></p>\n<pre><span class=\"c1\"># in __init__()</span>\n<span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">SE</span> <span class=\"o\">=</span> <span class=\"n\">SqueezeAndExcitation</span><span class=\"p\">(</span><span class=\"n\">in_ch</span><span class=\"p\">,</span> <span class=\"n\">r</span><span class=\"o\">=</span><span class=\"mi\">16</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># in forward()</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">SE</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n</pre>\n<p><em>Arguments</em>:<br>\n<code>in_ch</code> (int): The number of channels in the feature map of the input.<br>\n<code>r</code> (int): The reduction ratio of the intermidiate channels. Default: 16.</p>\n<p><em>Shape</em>:</p>\n<ul>\n<li>Input: (batch, channels, height, width)</li>\n<li>Output: (batch, channels, height, width) (same shape as input)</li>\n</ul>\n<h5><a href=\"./pytorch_zoo/modules.py#L41\" rel=\"nofollow\">ChannelSqueezeAndSpatialExcitation(in_ch)</a></h5>\n<p>The sSE (Channel Squeeze and Spatial Excitation) block from the <a href=\"https://arxiv.org/abs/1803.02579\" rel=\"nofollow\">Concurrent Spatial and Channel \u2018Squeeze &amp; Excitation\u2019 in Fully Convolutional Networks</a> paper.</p>\n<p>Implementation adapted from <a href=\"https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/66178\" rel=\"nofollow\">https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/66178</a></p>\n<pre><span class=\"c1\"># in __init__()</span>\n<span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">sSE</span> <span class=\"o\">=</span> <span class=\"n\">ChannelSqueezeAndSpatialExcitation</span><span class=\"p\">(</span><span class=\"n\">in_ch</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># in forward()</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">sSE</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n</pre>\n<p><em>Arguments</em>:<br>\n<code>in_ch</code> (int): The number of channels in the feature map of the input.</p>\n<p><em>Shape</em>:</p>\n<ul>\n<li>Input: (batch, channels, height, width)</li>\n<li>Output: (batch, channels, height, width) (same shape as input)</li>\n</ul>\n<h5><a href=\"./pytorch_zoo/modules.py#L71\" rel=\"nofollow\">ConcurrentSpatialAndChannelSqueezeAndChannelExcitation(in_ch)</a></h5>\n<p>The scSE (Concurrent Spatial and Channel Squeeze and Channel Excitation) block from the <a href=\"https://arxiv.org/abs/1803.02579\" rel=\"nofollow\">Concurrent Spatial and Channel \u2018Squeeze &amp; Excitation\u2019 in Fully Convolutional Networks</a> paper.</p>\n<p>Implementation adapted from <a href=\"https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/66178\" rel=\"nofollow\">https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/66178</a></p>\n<pre><span class=\"c1\"># in __init__()</span>\n<span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">scSE</span> <span class=\"o\">=</span> <span class=\"n\">ConcurrentSpatialAndChannelSqueezeAndChannelExcitation</span><span class=\"p\">(</span><span class=\"n\">in_ch</span><span class=\"p\">,</span> <span class=\"n\">r</span><span class=\"o\">=</span><span class=\"mi\">16</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># in forward()</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">scSE</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n</pre>\n<p><em>Arguments</em>:<br>\n<code>in_ch</code> (int): The number of channels in the feature map of the input.<br>\n<code>r</code> (int): The reduction ratio of the intermidiate channels. Default: 16.</p>\n<p><em>Shape</em>:</p>\n<ul>\n<li>Input: (batch, channels, height, width)</li>\n<li>Output: (batch, channels, height, width) (same shape as input)</li>\n</ul>\n<h5><a href=\"./pytorch_zoo/modules.py#L104\" rel=\"nofollow\">GaussianNoise(0.1)</a></h5>\n<p>A gaussian noise module.</p>\n<pre><span class=\"c1\"># in __init__()</span>\n<span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">gaussian_noise</span> <span class=\"o\">=</span> <span class=\"n\">GaussianNoise</span><span class=\"p\">(</span><span class=\"mf\">0.1</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># in forward()</span>\n<span class=\"k\">if</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"p\">:</span>\n    <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">gaussian_noise</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n</pre>\n<p><em>Arguments</em>:<br>\n<code>stddev</code> (float): The standard deviation of the normal distribution. Default: 0.1.</p>\n<p><em>Shape</em>:</p>\n<ul>\n<li>Input: (batch, *)</li>\n<li>Output: (batch, *) (same shape as input)</li>\n</ul>\n<h3>Schedulers</h3>\n<h5><a href=\"./pytorch_zoo/schedulers.py#L7\" rel=\"nofollow\">CyclicalMomentum(optimizer, base_momentum=0.8, max_momentum=0.9, step_size=2000, mode=\"triangular\")</a></h5>\n<p>Pytorch's <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/optim/lr_scheduler.py\" rel=\"nofollow\">cyclical learning rates</a>, but for momentum, which leads to better results when used with cyclic learning rates, as shown in <a href=\"https://arxiv.org/abs/1803.09820\" rel=\"nofollow\">A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay</a>.</p>\n<pre><span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">SGD</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">(),</span> <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">,</span> <span class=\"n\">momentum</span><span class=\"o\">=</span><span class=\"mf\">0.9</span><span class=\"p\">)</span>\n<span class=\"n\">scheduler</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">CyclicMomentum</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"p\">)</span>\n<span class=\"n\">data_loader</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">epoch</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">):</span>\n    <span class=\"k\">for</span> <span class=\"n\">batch</span> <span class=\"ow\">in</span> <span class=\"n\">data_loader</span><span class=\"p\">:</span>\n        <span class=\"n\">scheduler</span><span class=\"o\">.</span><span class=\"n\">batch_step</span><span class=\"p\">()</span>\n        <span class=\"n\">train_batch</span><span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">)</span>\n</pre>\n<p><em>Arguments</em>:<br>\n<code>optimizer</code> (Optimizer): Wrapped optimizer.<br>\n<code>base_momentum</code> (float or list): Initial momentum which is the lower boundary in the cycle for each param groups. Default: 0.8<br>\n<code>max_momentum</code> (float or list): Upper boundaries in the cycle for each parameter group. scaling function. Default: 0.9<br>\n<code>step_size</code> (int): Number of training iterations per half cycle. Authors suggest setting step_size 2-8 x training iterations in epoch. Default: 2000<br>\n<code>mode</code> (str): One of {triangular, triangular2, exp_range}. Default: 'triangular'<br>\n<code>gamma</code> (float): Constant in 'exp_range' scaling function. Default: 1.0<br>\n<code>scale_fn</code> (function): Custom scaling policy defined by a single argument lambda function. Mode paramater is ignored Default: None<br>\n<code>scale_mode</code> (str): {'cycle', 'iterations'}. Defines whether scale_fn is evaluated on cycle number or cycle iterations (training iterations since start of cycle). Default: 'cycle'<br>\n<code>last_batch_iteration</code> (int): The index of the last batch. Default: -1</p>\n<h3>Utils</h3>\n<h5><a href=\"./pytorch_zoo/utils.py#L13\" rel=\"nofollow\">notify({'value1': 'Notification title', 'value2': 'Notification body'}, key)</a></h5>\n<p>Send a notification to your phone with IFTTT</p>\n<p>Setup a IFTTT webhook with <a href=\"https://medium.com/datadriveninvestor/monitor-progress-of-your-training-remotely-f9404d71b720\" rel=\"nofollow\">https://medium.com/datadriveninvestor/monitor-progress-of-your-training-remotely-f9404d71b720</a></p>\n<pre><span class=\"n\">notify</span><span class=\"p\">({</span><span class=\"s1\">'value1'</span><span class=\"p\">:</span> <span class=\"s1\">'Notification title'</span><span class=\"p\">,</span> <span class=\"s1\">'value2'</span><span class=\"p\">:</span> <span class=\"s1\">'Notification body'</span><span class=\"p\">},</span> <span class=\"n\">key</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">YOUR_PRIVATE_KEY_HERE</span><span class=\"p\">])</span>\n</pre>\n<p><em>Arguments</em>:<br>\n<code>obj</code> (Object): Object to send to IFTTT<br>\n<code>key</code> ([type]): IFTTT webhook key</p>\n<h5><a href=\"./pytorch_zoo/utils.py#L25\" rel=\"nofollow\">seed_environment(seed=42)</a></h5>\n<p>Set random seeds for python, numpy, and pytorch to ensure reproducible research.</p>\n<pre><span class=\"n\">seed_envirionment</span><span class=\"p\">(</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n</pre>\n<p><em>Arguments</em>:<br>\n<code>seed</code> (int): The random seed to set.</p>\n<h5><a href=\"./pytorch_zoo/utils.py#L39\" rel=\"nofollow\">gpu_usage(device, digits=4)</a></h5>\n<p>Prints the amount of GPU memory currently allocated in GB.</p>\n<pre><span class=\"n\">gpu_usage</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"n\">digits</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">)</span>\n</pre>\n<p><em>Arguments</em>:<br>\n<code>device</code> (torch.device, optional): The device you want to check. Defaults to device.<br>\n<code>digits</code> (int, optional): The number of digits of precision. Defaults to 4.</p>\n<h5><a href=\"./pytorch_zoo/utils.py#L53\" rel=\"nofollow\">n_params(model)</a></h5>\n<p>Return the number of parameters in a pytorch model.</p>\n<pre><span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">n_params</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">))</span>\n</pre>\n<p><em>Arguments</em>:<br>\n<code>model</code> (nn.Module): The model to analyze.</p>\n<p><em>Returns</em>:<br>\n(int): The number of parameters in the model.</p>\n<h5><a href=\"./pytorch_zoo/utils.py#L71\" rel=\"nofollow\">save_model(model, fold=0)</a></h5>\n<p>Save a trained pytorch model on a particular cross-validation fold to disk.</p>\n<p>Implementation adapted from <a href=\"https://github.com/floydhub/save-and-resume\" rel=\"nofollow\">https://github.com/floydhub/save-and-resume</a>.</p>\n<pre><span class=\"n\">save_model</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">fold</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n</pre>\n<p><em>Arguments</em>:<br>\n<code>model</code> (nn.Module): The model to save.<br>\n<code>fold</code> (int): The cross-validation fold the model was trained on.</p>\n<h5><a href=\"./pytorch_zoo/utils.py#L84\" rel=\"nofollow\">load_model(model, fold=0)</a></h5>\n<p>Load a trained pytorch model saved to disk using <code>save_model</code>.</p>\n<pre><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">load_model</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">fold</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n</pre>\n<p><em>Arguments</em>:\n<code>model</code> (nn.Module): The model to save.<br>\n<code>fold</code> (int): Which saved model fold to load.</p>\n<p><em>Returns</em>:<br>\n(nn.Module): The same model that was passed in, but with the pretrained weights loaded.</p>\n<h5><a href=\"./pytorch_zoo/utils.py#L99\" rel=\"nofollow\">save(obj, 'obj.pkl')</a></h5>\n<p>Save an object to disk.</p>\n<pre><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"n\">tokenizer</span><span class=\"p\">,</span> <span class=\"s1\">'tokenizer.pkl'</span><span class=\"p\">)</span>\n</pre>\n<p><em>Arguments</em>:<br>\n<code>obj</code> (Object): The object to save.<br>\n<code>filename</code> (String): The name of the file to save the object to.</p>\n<h5><a href=\"./pytorch_zoo/utils.py#L110\" rel=\"nofollow\">load('obj.pkl')</a></h5>\n<p>Load an object saved to disk with <code>save</code>.</p>\n<pre><span class=\"n\">tokenizer</span> <span class=\"o\">=</span> <span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s1\">'tokenizer.pkl'</span><span class=\"p\">)</span>\n</pre>\n<p><em>Arguments</em>:<br>\n<code>path</code> (String): The path to the saved object.</p>\n<p><em>Returns</em>:<br>\n(Object): The loaded object.</p>\n<h5><a href=\"./pytorch_zoo/utils.py#L124\" rel=\"nofollow\">masked_softmax(logits, mask, dim=-1)</a></h5>\n<p>A masked softmax module to correctly implement attention in Pytorch.</p>\n<p>Implementation adapted from: <a href=\"https://github.com/allenai/allennlp/blob/master/allennlp/nn/util.py\" rel=\"nofollow\">https://github.com/allenai/allennlp/blob/master/allennlp/nn/util.py</a></p>\n<pre><span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"n\">masked_softmax</span><span class=\"p\">(</span><span class=\"n\">logits</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</pre>\n<p><em>Arguments</em>:<br>\n<code>vector</code> (torch.tensor): The tensor to softmax.<br>\n<code>mask</code> (torch.tensor): The tensor to indicate which indices are to be masked and not included in the softmax operation.<br>\n<code>dim</code> (int, optional): The dimension to softmax over. Defaults to -1.<br>\n<code>memory_efficient</code> (bool, optional): Whether to use a less precise, but more memory efficient implementation of masked softmax. Defaults to False.<br>\n<code>mask_fill_value</code> ([type], optional): The value to fill masked values with if <code>memory_efficient</code> is <code>True</code>. Defaults to -1e32.</p>\n<p><em>Returns</em>:<br>\n(torch.tensor): The masked softmaxed output</p>\n<h5><a href=\"./pytorch_zoo/utils.py#L175\" rel=\"nofollow\">masked_log_softmax(logits, mask, dim=-1)</a></h5>\n<p>A masked log-softmax module to correctly implement attention in Pytorch.</p>\n<p>Implementation adapted from: <a href=\"https://github.com/allenai/allennlp/blob/master/allennlp/nn/util.py\" rel=\"nofollow\">https://github.com/allenai/allennlp/blob/master/allennlp/nn/util.py</a></p>\n<pre><span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"n\">masked_log_softmax</span><span class=\"p\">(</span><span class=\"n\">logits</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</pre>\n<p><em>Arguments</em>:<br>\n<code>vector</code> (torch.tensor): The tensor to log-softmax.<br>\n<code>mask</code> (torch.tensor): The tensor to indicate which indices are to be masked and not included in the log-softmax operation.<br>\n<code>dim</code> (int, optional): The dimension to log-softmax over. Defaults to -1.</p>\n<p><em>Returns</em>:<br>\n(torch.tensor): The masked log-softmaxed output</p>\n<h2>Contributing</h2>\n<p>This repository is still a work in progress, so if you find a bug, think there is something missing, or have any suggestions for new features or modules, feel free to open an issue or a pull request. Feel free to use the library or code from it in your own projects, and if you feel that some code used in this project hasn't been properly accredited, please open an issue.</p>\n<h2>Authors</h2>\n<ul>\n<li><em>Bilal Khan</em> - <em>Initial work</em></li>\n</ul>\n<h2>License</h2>\n<p>This project is licensed under the MIT License - see the <a href=\"LICENSE\" rel=\"nofollow\">license</a> file for details</p>\n<h2>Acknowledgements</h2>\n<p>This project contains code adapted from:</p>\n<ul>\n<li><a href=\"https://github.com/bermanmaxim/LovaszSoftmax\" rel=\"nofollow\">https://github.com/bermanmaxim/LovaszSoftmax</a></li>\n<li><a href=\"https://www.kaggle.com/aglotero/another-iou-metric\" rel=\"nofollow\">https://www.kaggle.com/aglotero/another-iou-metric</a></li>\n<li><a href=\"https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/66178\" rel=\"nofollow\">https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/66178</a></li>\n<li><a href=\"https://github.com/bckenstler/CLR\" rel=\"nofollow\">https://github.com/bckenstler/CLR</a></li>\n<li><a href=\"https://github.com/floydhub/save-and-resume\" rel=\"nofollow\">https://github.com/floydhub/save-and-resume</a></li>\n<li><a href=\"https://github.com/allenai/allennlp\" rel=\"nofollow\">https://github.com/allenai/allennlp</a></li>\n<li><a href=\"https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/discussion/94779\" rel=\"nofollow\">https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/discussion/94779</a></li>\n</ul>\n<p>This README is based on:</p>\n<ul>\n<li><a href=\"https://github.com/mxbi/mlcrate\" rel=\"nofollow\">https://github.com/mxbi/mlcrate</a></li>\n<li><a href=\"https://github.com/athityakumar/colorls\" rel=\"nofollow\">https://github.com/athityakumar/colorls</a></li>\n<li><a href=\"https://github.com/amitmerchant1990/electron-markdownify/blob/master/README.md\" rel=\"nofollow\">https://github.com/amitmerchant1990/electron-markdownify/blob/master/README.md</a></li>\n<li><a href=\"https://github.com/rish-16/gpt2client\" rel=\"nofollow\">https://github.com/rish-16/gpt2client</a></li>\n</ul>\n\n          </div>"}, "last_serial": 6222041, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "19d584281a4d05a6c53a404c776ea95f", "sha256": "d3dc83aed47618e29ce19efbe14c0161a9167f359f2cd64ab20e55641da950c1"}, "downloads": -1, "filename": "pytorch_zoo-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "19d584281a4d05a6c53a404c776ea95f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 15965, "upload_time": "2019-06-07T23:30:45", "upload_time_iso_8601": "2019-06-07T23:30:45.217919Z", "url": "https://files.pythonhosted.org/packages/02/db/88323bd09fd8448148b276ad7127940e86893bb11cb13ad44164fafcb4de/pytorch_zoo-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "651cc673e5305399299f08e2a6011968", "sha256": "04596c9f4a0cc2717730cda11764d853fee88b6ba415e1e8c53301609b8e71a2"}, "downloads": -1, "filename": "pytorch_zoo-1.0.0.tar.gz", "has_sig": false, "md5_digest": "651cc673e5305399299f08e2a6011968", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16338, "upload_time": "2019-06-07T23:30:47", "upload_time_iso_8601": "2019-06-07T23:30:47.612896Z", "url": "https://files.pythonhosted.org/packages/2d/a8/3d864612c04540e18d4add01405c0407e3c3ef10db3cbe8948cf8301071d/pytorch_zoo-1.0.0.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "2311f3cfc5dcd418fcfdf22e15202bc3", "sha256": "6f3ae88a0a97ac7d1c4ce87c1c64c1360d0373e31764d151d32421cad893b8cc"}, "downloads": -1, "filename": "pytorch_zoo-1.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "2311f3cfc5dcd418fcfdf22e15202bc3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 17325, "upload_time": "2019-06-08T15:52:54", "upload_time_iso_8601": "2019-06-08T15:52:54.744465Z", "url": "https://files.pythonhosted.org/packages/34/c3/c2460d8525436bdeab5509fc8a7dd36420a2b2bfb590b7a8fccad563e367/pytorch_zoo-1.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6fcefe3beba5c2c3c2c170f23ecc2905", "sha256": "7cdf7dc176632f1c5694f112cc7ebc24ffafdd5098c570261de5c70eb11b6c4d"}, "downloads": -1, "filename": "pytorch_zoo-1.1.0.tar.gz", "has_sig": false, "md5_digest": "6fcefe3beba5c2c3c2c170f23ecc2905", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17843, "upload_time": "2019-06-08T15:52:56", "upload_time_iso_8601": "2019-06-08T15:52:56.530971Z", "url": "https://files.pythonhosted.org/packages/a6/43/674d0837d8ce324c32a7ff858ff0a0e199f442e78a9725bea8bbb04bc6fc/pytorch_zoo-1.1.0.tar.gz", "yanked": false}], "1.1.1": [{"comment_text": "", "digests": {"md5": "704d10d5f402020261247cc549c0e1c0", "sha256": "35389ee3871ffb9260251628d150f31433e1365fa6e72e74b559c80d7d678a3b"}, "downloads": -1, "filename": "pytorch_zoo-1.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "704d10d5f402020261247cc549c0e1c0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 17325, "upload_time": "2019-06-08T15:55:12", "upload_time_iso_8601": "2019-06-08T15:55:12.642009Z", "url": "https://files.pythonhosted.org/packages/85/6c/a93e3b6b7f11de888be8e940ffff19438f0ef7e8d9c4c03cad47dc04915b/pytorch_zoo-1.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "09119bc268104e6fb99abea61a5b1d8c", "sha256": "c7c3f8ae79b724f06c2a55adcc00603d51d3da8ea6b68e3f6b0e2721bea148ba"}, "downloads": -1, "filename": "pytorch_zoo-1.1.1.tar.gz", "has_sig": false, "md5_digest": "09119bc268104e6fb99abea61a5b1d8c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17843, "upload_time": "2019-06-08T15:55:14", "upload_time_iso_8601": "2019-06-08T15:55:14.416295Z", "url": "https://files.pythonhosted.org/packages/ea/69/dbb5e42bf6326dd8497cf292859db93ce1fedc5cf94ba2c7c0f6c9d5a56d/pytorch_zoo-1.1.1.tar.gz", "yanked": false}], "1.1.2": [{"comment_text": "", "digests": {"md5": "7dc8b82beeec4cbde127333054233fa4", "sha256": "a401d60359d0ffa859799198405662956d512fc4a2d14018323117adeabd61e4"}, "downloads": -1, "filename": "pytorch_zoo-1.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "7dc8b82beeec4cbde127333054233fa4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 17642, "upload_time": "2019-07-18T22:14:23", "upload_time_iso_8601": "2019-07-18T22:14:23.807879Z", "url": "https://files.pythonhosted.org/packages/14/56/d9bb4aa1d2a95f08e107df547e7c3d2ed1dd3b91734250d9047776dd3f1f/pytorch_zoo-1.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2b7e365b000f3858e59bca0396599be9", "sha256": "130213b09ac88b913d977f42ce0453a8c9d050535908553d40b39805016cefff"}, "downloads": -1, "filename": "pytorch_zoo-1.1.2.tar.gz", "has_sig": false, "md5_digest": "2b7e365b000f3858e59bca0396599be9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18385, "upload_time": "2019-07-18T22:14:25", "upload_time_iso_8601": "2019-07-18T22:14:25.160494Z", "url": "https://files.pythonhosted.org/packages/cf/17/30e1623b52e562d06c529a5963366c13548e566a236e2e97bdb239e2731f/pytorch_zoo-1.1.2.tar.gz", "yanked": false}], "1.1.3": [{"comment_text": "", "digests": {"md5": "e9a47018528ea087c3e6ee8a1710509a", "sha256": "dec258ac69015629b4284f54703e559226e4dddecfda5a6a886bae96d533d5fb"}, "downloads": -1, "filename": "pytorch_zoo-1.1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "e9a47018528ea087c3e6ee8a1710509a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 17723, "upload_time": "2019-07-19T01:13:38", "upload_time_iso_8601": "2019-07-19T01:13:38.832584Z", "url": "https://files.pythonhosted.org/packages/77/16/d5c7468db80396cb430ec9f2d68e81711aa69d0af22d64db9ccdad276f3c/pytorch_zoo-1.1.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "374a4b0552801ea759177c9bfe9463a2", "sha256": "e0c44ea5ae400eec551c25a4051c91558c6637c3fc54849c85698b734c89839c"}, "downloads": -1, "filename": "pytorch_zoo-1.1.3.tar.gz", "has_sig": false, "md5_digest": "374a4b0552801ea759177c9bfe9463a2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18832, "upload_time": "2019-07-19T01:13:42", "upload_time_iso_8601": "2019-07-19T01:13:42.401252Z", "url": "https://files.pythonhosted.org/packages/f0/f0/d92e9ea7ca2ec37253cab95ee8869d42db8681a4338bac680846c5e79606/pytorch_zoo-1.1.3.tar.gz", "yanked": false}], "1.2.0": [{"comment_text": "", "digests": {"md5": "94a4e267b14805195d8c493ea31958a5", "sha256": "9cce8447411cca35a7db7b2de3f8a56199cc9c0bfab2bc8d9b4eeb3e194fe51f"}, "downloads": -1, "filename": "pytorch_zoo-1.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "94a4e267b14805195d8c493ea31958a5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 16948, "upload_time": "2019-08-24T16:00:27", "upload_time_iso_8601": "2019-08-24T16:00:27.520292Z", "url": "https://files.pythonhosted.org/packages/10/cb/1364369f87cf138a6bd9d3e202c2a59ef43d4c9acb4de2f9a34e539bcb08/pytorch_zoo-1.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "624e814624d22f87ab49ff842fc724c5", "sha256": "555efede8bdfb63541d00f06bda54cdd0f9e25bee3e5b94d6a9784da97c316cd"}, "downloads": -1, "filename": "pytorch_zoo-1.2.0.tar.gz", "has_sig": false, "md5_digest": "624e814624d22f87ab49ff842fc724c5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18098, "upload_time": "2019-08-24T16:00:28", "upload_time_iso_8601": "2019-08-24T16:00:28.992243Z", "url": "https://files.pythonhosted.org/packages/c0/97/3e53a5a73d83f2bfc347e720f6d4bea85c048d4fb3e1f53cc056f7b60509/pytorch_zoo-1.2.0.tar.gz", "yanked": false}], "1.2.1": [{"comment_text": "", "digests": {"md5": "2307a411dc7c2f6a9d833614242255fc", "sha256": "1f0c20c8b129c3584f8b100139e34b92eb18f1b1bffd218e938c0357316486f1"}, "downloads": -1, "filename": "pytorch_zoo-1.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "2307a411dc7c2f6a9d833614242255fc", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 16945, "upload_time": "2019-08-24T16:07:36", "upload_time_iso_8601": "2019-08-24T16:07:36.500108Z", "url": "https://files.pythonhosted.org/packages/22/7c/9059455b04cc341652e0166bba3b98f273fd0dbc24dd89edc6dbd6b94c18/pytorch_zoo-1.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "04ca07470db76d8b307d93048454eabd", "sha256": "0416a493af738812b7105a3bb1f7a55f92947814da43cc150251f96793abe510"}, "downloads": -1, "filename": "pytorch_zoo-1.2.1.tar.gz", "has_sig": false, "md5_digest": "04ca07470db76d8b307d93048454eabd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18077, "upload_time": "2019-08-24T16:07:38", "upload_time_iso_8601": "2019-08-24T16:07:38.643985Z", "url": "https://files.pythonhosted.org/packages/5d/d0/f590c7e2ff993ba5db9517cade0e9f252029bc1317bb0d43400cfa5ca0f8/pytorch_zoo-1.2.1.tar.gz", "yanked": false}], "1.2.2": [{"comment_text": "", "digests": {"md5": "43d0caef07e33e7afa447f70528e28d1", "sha256": "6044fad6b6e2b1fa2f297e2e44448753636732f6458c258c377e3ac8780433f4"}, "downloads": -1, "filename": "pytorch_zoo-1.2.2-py3-none-any.whl", "has_sig": false, "md5_digest": "43d0caef07e33e7afa447f70528e28d1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 16973, "upload_time": "2019-11-30T17:17:41", "upload_time_iso_8601": "2019-11-30T17:17:41.613378Z", "url": "https://files.pythonhosted.org/packages/5c/9b/bd9065c8971b950c6e5b979f97ce057b5e774dabbcc87a8790ee681b5215/pytorch_zoo-1.2.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cfdb717e80f9313a230de91f0622e337", "sha256": "d81711ea67aea4064b21d3a3822c8ff43a11ebdb041c41faa60a19240668be20"}, "downloads": -1, "filename": "pytorch_zoo-1.2.2.tar.gz", "has_sig": false, "md5_digest": "cfdb717e80f9313a230de91f0622e337", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18166, "upload_time": "2019-11-30T17:17:43", "upload_time_iso_8601": "2019-11-30T17:17:43.173888Z", "url": "https://files.pythonhosted.org/packages/a5/70/17351c8ae69a5e6588534a5b4c2f9a2cf8dc7dfc20375483fddf25088e5f/pytorch_zoo-1.2.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "43d0caef07e33e7afa447f70528e28d1", "sha256": "6044fad6b6e2b1fa2f297e2e44448753636732f6458c258c377e3ac8780433f4"}, "downloads": -1, "filename": "pytorch_zoo-1.2.2-py3-none-any.whl", "has_sig": false, "md5_digest": "43d0caef07e33e7afa447f70528e28d1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 16973, "upload_time": "2019-11-30T17:17:41", "upload_time_iso_8601": "2019-11-30T17:17:41.613378Z", "url": "https://files.pythonhosted.org/packages/5c/9b/bd9065c8971b950c6e5b979f97ce057b5e774dabbcc87a8790ee681b5215/pytorch_zoo-1.2.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cfdb717e80f9313a230de91f0622e337", "sha256": "d81711ea67aea4064b21d3a3822c8ff43a11ebdb041c41faa60a19240668be20"}, "downloads": -1, "filename": "pytorch_zoo-1.2.2.tar.gz", "has_sig": false, "md5_digest": "cfdb717e80f9313a230de91f0622e337", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18166, "upload_time": "2019-11-30T17:17:43", "upload_time_iso_8601": "2019-11-30T17:17:43.173888Z", "url": "https://files.pythonhosted.org/packages/a5/70/17351c8ae69a5e6588534a5b4c2f9a2cf8dc7dfc20375483fddf25088e5f/pytorch_zoo-1.2.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:13:29 2020"}