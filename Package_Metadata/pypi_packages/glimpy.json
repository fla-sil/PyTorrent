{"info": {"author": "Kyle Safran", "author_email": "ksafran356@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "# Glimpy\n[![CircleCI](https://circleci.com/gh/KSafran/glimpy.svg?style=svg)](https://circleci.com/gh/KSafran/glimpy)  \n\nglimpy is a Python module for fitting generalized linear models. It's based on the [scikit-learn](https://scikit-learn.org/stable/index.html) API to facilitate use with other scikit-learn tools (pipelines, cross-validation, etc.). Models are fit using the [statsmodels](https://www.statsmodels.org/stable/glm.html) package.\n\n## Installation\n`pip install glimpy`\n\n## Important Notes\nglimpy makes a few important departures from the scikit-learn API \n\n#### Don't Regularize by Default\n`sklearn.linear_model.LogisticRegression` regularizes by default. Its \nregularization paramater `C` is modeled after the SVM regularization parameter \nso lower values imply more regularization. \n\nGlimpy does use the `C` parameter to regularize, so lower values imply\nmore regularization.\n**Glimpy does not regularize by default.**\n\n#### Don't Penalize Intercept Coefficient\nScikit-Learn and statsmodels penalize the intercept coefficient. **Glimpy does not penalize the intercept coefficient** when fit with `intercept=True`. If you want the intercept coefficient to be penalized add an intercept term to your dataset `X` and fit with `intercept=False`\n\n## Getting Started\nHere is an example of a poisson GLM to help get you started\n\nWe will simulate an experiment where we want to determine how an individual's age and weight influence the number of hospital visits they can expect to have in a given year.  \n\nStart with basic imports and setup \n```python\n>>> import numpy as np\n>>> from scipy.stats import poisson\n>>> from glimpy import GLM, Poisson\n>>>\n>>> np.random.seed(10)\n>>> n_samples = 1000\n```\n  \nNow we will simulate some data where observed individuals have ages ranging from 30 to 70, and weights normally distributed centered around 150 lbs.\n```python  \n>>> age = np.random.uniform(30, 70, n_samples)\n>>> weight = np.random.normal(150, 20, n_samples)\n```\n  \nThen we will have the expected number of hospital visits vary according to the following equation. We will sample from a poisson distribution with those means to get a sample of observed hospital visits\n```python\n>>> expected_visits = np.exp(-10 + age * 0.05 + weight * 0.08)\n>>> observed_visits = poisson.rvs(expected_visits)\n```\n  \nNow we can fit a `GLM` object to try to recover the formula we specified above\n```python\n>>> X = np.vstack([age, weight]).T\n>>> y = observed_visits\n>>> pglm = GLM(fit_intercept=True, family=Poisson())\n>>> pglm.fit(X, y)\n>>> print(pglm.summary())\n                 Generalized Linear Model Regression Results\n==============================================================================\nDep. Variable:                      y   No. Observations:                 1000\nModel:                            GLM   Df Residuals:                      997\nModel Family:                 Poisson   Df Model:                            2\nLink Function:                    log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3619.1\nDate:                Thu, 09 Jan 2020   Deviance:                       967.43\nTime:                        22:31:35   Pearson chi2:                     961.\nNo. Iterations:                     6\nCovariance Type:            nonrobust\n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst        -10.0132      0.020   -509.601      0.000     -10.052      -9.975\nx1             0.0499      0.000    301.142      0.000       0.050       0.050\nx2             0.0801      0.000    800.720      0.000       0.080       0.080\n==============================================================================\n```\n\n## Scikit-Learn Integration\nThe upshot of glimpy is that you can use easily use your favorite scikit-learn tools with glimpy GLMs. For example, you can use the scikit-learn `cross_val_score`\n```python\n>>> from sklearn.model_selection import cross_val_score\n>>> print(cross_val_score(pglm, X, y, cv=4))\n[-263.11969239 -288.58713533 -205.7032204  -220.68304592]\n```\n  \nThe following example demonstrates how to use glimpy alongside scikit-learn to perform grid search over elastic-net hyperparameters\n\n```python\n>>> import statsmodels.api as sm\n>>> from glimpy import GLM, Gamma\n>>> from sklearn.preprocessing import StandardScaler\n>>> from sklearn.pipeline import Pipeline\n>>> from sklearn import datasets\n>>> from sklearn.model_selection import GridSearchCV\n>>> \n>>> diabetes = datasets.load_diabetes()\n>>> \n>>> scaler = StandardScaler()\n>>> gamma_glm = GLM(fit_intercept=True, family=Gamma(sm.families.links.log()), penalty='elasticnet')\n>>> gamma_pipeline = Pipeline([('scaler', scaler), ('glm', gamma_glm)])\n>>> grid_search = GridSearchCV(gamma_pipeline,\n>>>     param_grid=[{\n>>>         'glm__C': [1e4, 1e5, 1e6],\n>>>         'glm__l1_ratio': [0.1, 0.5, 0.9]\n>>>     }],\n>>>     cv=3\n>>> )\n>>> \n>>> grid_search.fit(diabetes['data'], diabetes['target'])\n>>> print(grid_search.best_params_)\n{'glm__C': 1000000.0, 'glm__l1_ratio': 0.1}\n```", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/KSafran/glimpy/archive/0.1.0.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/KSafran/glimpy", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "glimpy", "package_url": "https://pypi.org/project/glimpy/", "platform": "", "project_url": "https://pypi.org/project/glimpy/", "project_urls": {"Download": "https://github.com/KSafran/glimpy/archive/0.1.0.tar.gz", "Homepage": "https://github.com/KSafran/glimpy"}, "release_url": "https://pypi.org/project/glimpy/0.1.0/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Generalized Linear Models in Python", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Glimpy</h1>\n<p><a href=\"https://circleci.com/gh/KSafran/glimpy\" rel=\"nofollow\"><img alt=\"CircleCI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2edf3f6f917361242c815e9c7850acdfa1f31377/68747470733a2f2f636972636c6563692e636f6d2f67682f4b53616672616e2f676c696d70792e7376673f7374796c653d737667\"></a></p>\n<p>glimpy is a Python module for fitting generalized linear models. It's based on the <a href=\"https://scikit-learn.org/stable/index.html\" rel=\"nofollow\">scikit-learn</a> API to facilitate use with other scikit-learn tools (pipelines, cross-validation, etc.). Models are fit using the <a href=\"https://www.statsmodels.org/stable/glm.html\" rel=\"nofollow\">statsmodels</a> package.</p>\n<h2>Installation</h2>\n<p><code>pip install glimpy</code></p>\n<h2>Important Notes</h2>\n<p>glimpy makes a few important departures from the scikit-learn API</p>\n<h4>Don't Regularize by Default</h4>\n<p><code>sklearn.linear_model.LogisticRegression</code> regularizes by default. Its\nregularization paramater <code>C</code> is modeled after the SVM regularization parameter\nso lower values imply more regularization.</p>\n<p>Glimpy does use the <code>C</code> parameter to regularize, so lower values imply\nmore regularization.\n<strong>Glimpy does not regularize by default.</strong></p>\n<h4>Don't Penalize Intercept Coefficient</h4>\n<p>Scikit-Learn and statsmodels penalize the intercept coefficient. <strong>Glimpy does not penalize the intercept coefficient</strong> when fit with <code>intercept=True</code>. If you want the intercept coefficient to be penalized add an intercept term to your dataset <code>X</code> and fit with <code>intercept=False</code></p>\n<h2>Getting Started</h2>\n<p>Here is an example of a poisson GLM to help get you started</p>\n<p>We will simulate an experiment where we want to determine how an individual's age and weight influence the number of hospital visits they can expect to have in a given year.</p>\n<p>Start with basic imports and setup</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">scipy.stats</span> <span class=\"kn\">import</span> <span class=\"n\">poisson</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">glimpy</span> <span class=\"kn\">import</span> <span class=\"n\">GLM</span><span class=\"p\">,</span> <span class=\"n\">Poisson</span>\n<span class=\"o\">&gt;&gt;&gt;</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">n_samples</span> <span class=\"o\">=</span> <span class=\"mi\">1000</span>\n</pre>\n<p>Now we will simulate some data where observed individuals have ages ranging from 30 to 70, and weights normally distributed centered around 150 lbs.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">age</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">uniform</span><span class=\"p\">(</span><span class=\"mi\">30</span><span class=\"p\">,</span> <span class=\"mi\">70</span><span class=\"p\">,</span> <span class=\"n\">n_samples</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">weight</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">normal</span><span class=\"p\">(</span><span class=\"mi\">150</span><span class=\"p\">,</span> <span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"n\">n_samples</span><span class=\"p\">)</span>\n</pre>\n<p>Then we will have the expected number of hospital visits vary according to the following equation. We will sample from a poisson distribution with those means to get a sample of observed hospital visits</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">expected_visits</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">exp</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">10</span> <span class=\"o\">+</span> <span class=\"n\">age</span> <span class=\"o\">*</span> <span class=\"mf\">0.05</span> <span class=\"o\">+</span> <span class=\"n\">weight</span> <span class=\"o\">*</span> <span class=\"mf\">0.08</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">observed_visits</span> <span class=\"o\">=</span> <span class=\"n\">poisson</span><span class=\"o\">.</span><span class=\"n\">rvs</span><span class=\"p\">(</span><span class=\"n\">expected_visits</span><span class=\"p\">)</span>\n</pre>\n<p>Now we can fit a <code>GLM</code> object to try to recover the formula we specified above</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">vstack</span><span class=\"p\">([</span><span class=\"n\">age</span><span class=\"p\">,</span> <span class=\"n\">weight</span><span class=\"p\">])</span><span class=\"o\">.</span><span class=\"n\">T</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">observed_visits</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">pglm</span> <span class=\"o\">=</span> <span class=\"n\">GLM</span><span class=\"p\">(</span><span class=\"n\">fit_intercept</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">family</span><span class=\"o\">=</span><span class=\"n\">Poisson</span><span class=\"p\">())</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">pglm</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">pglm</span><span class=\"o\">.</span><span class=\"n\">summary</span><span class=\"p\">())</span>\n                 <span class=\"n\">Generalized</span> <span class=\"n\">Linear</span> <span class=\"n\">Model</span> <span class=\"n\">Regression</span> <span class=\"n\">Results</span>\n<span class=\"o\">==============================================================================</span>\n<span class=\"n\">Dep</span><span class=\"o\">.</span> <span class=\"n\">Variable</span><span class=\"p\">:</span>                      <span class=\"n\">y</span>   <span class=\"n\">No</span><span class=\"o\">.</span> <span class=\"n\">Observations</span><span class=\"p\">:</span>                 <span class=\"mi\">1000</span>\n<span class=\"n\">Model</span><span class=\"p\">:</span>                            <span class=\"n\">GLM</span>   <span class=\"n\">Df</span> <span class=\"n\">Residuals</span><span class=\"p\">:</span>                      <span class=\"mi\">997</span>\n<span class=\"n\">Model</span> <span class=\"n\">Family</span><span class=\"p\">:</span>                 <span class=\"n\">Poisson</span>   <span class=\"n\">Df</span> <span class=\"n\">Model</span><span class=\"p\">:</span>                            <span class=\"mi\">2</span>\n<span class=\"n\">Link</span> <span class=\"n\">Function</span><span class=\"p\">:</span>                    <span class=\"n\">log</span>   <span class=\"n\">Scale</span><span class=\"p\">:</span>                          <span class=\"mf\">1.0000</span>\n<span class=\"n\">Method</span><span class=\"p\">:</span>                          <span class=\"n\">IRLS</span>   <span class=\"n\">Log</span><span class=\"o\">-</span><span class=\"n\">Likelihood</span><span class=\"p\">:</span>                <span class=\"o\">-</span><span class=\"mf\">3619.1</span>\n<span class=\"n\">Date</span><span class=\"p\">:</span>                <span class=\"n\">Thu</span><span class=\"p\">,</span> <span class=\"mi\">09</span> <span class=\"n\">Jan</span> <span class=\"mi\">2020</span>   <span class=\"n\">Deviance</span><span class=\"p\">:</span>                       <span class=\"mf\">967.43</span>\n<span class=\"n\">Time</span><span class=\"p\">:</span>                        <span class=\"mi\">22</span><span class=\"p\">:</span><span class=\"mi\">31</span><span class=\"p\">:</span><span class=\"mi\">35</span>   <span class=\"n\">Pearson</span> <span class=\"n\">chi2</span><span class=\"p\">:</span>                     <span class=\"mf\">961.</span>\n<span class=\"n\">No</span><span class=\"o\">.</span> <span class=\"n\">Iterations</span><span class=\"p\">:</span>                     <span class=\"mi\">6</span>\n<span class=\"n\">Covariance</span> <span class=\"n\">Type</span><span class=\"p\">:</span>            <span class=\"n\">nonrobust</span>\n<span class=\"o\">==============================================================================</span>\n                 <span class=\"n\">coef</span>    <span class=\"n\">std</span> <span class=\"n\">err</span>          <span class=\"n\">z</span>      <span class=\"n\">P</span><span class=\"o\">&gt;|</span><span class=\"n\">z</span><span class=\"o\">|</span>      <span class=\"p\">[</span><span class=\"mf\">0.025</span>      <span class=\"mf\">0.975</span><span class=\"p\">]</span>\n<span class=\"o\">------------------------------------------------------------------------------</span>\n<span class=\"n\">const</span>        <span class=\"o\">-</span><span class=\"mf\">10.0132</span>      <span class=\"mf\">0.020</span>   <span class=\"o\">-</span><span class=\"mf\">509.601</span>      <span class=\"mf\">0.000</span>     <span class=\"o\">-</span><span class=\"mf\">10.052</span>      <span class=\"o\">-</span><span class=\"mf\">9.975</span>\n<span class=\"n\">x1</span>             <span class=\"mf\">0.0499</span>      <span class=\"mf\">0.000</span>    <span class=\"mf\">301.142</span>      <span class=\"mf\">0.000</span>       <span class=\"mf\">0.050</span>       <span class=\"mf\">0.050</span>\n<span class=\"n\">x2</span>             <span class=\"mf\">0.0801</span>      <span class=\"mf\">0.000</span>    <span class=\"mf\">800.720</span>      <span class=\"mf\">0.000</span>       <span class=\"mf\">0.080</span>       <span class=\"mf\">0.080</span>\n<span class=\"o\">==============================================================================</span>\n</pre>\n<h2>Scikit-Learn Integration</h2>\n<p>The upshot of glimpy is that you can use easily use your favorite scikit-learn tools with glimpy GLMs. For example, you can use the scikit-learn <code>cross_val_score</code></p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">cross_val_score</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">cross_val_score</span><span class=\"p\">(</span><span class=\"n\">pglm</span><span class=\"p\">,</span> <span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">cv</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">))</span>\n<span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mf\">263.11969239</span> <span class=\"o\">-</span><span class=\"mf\">288.58713533</span> <span class=\"o\">-</span><span class=\"mf\">205.7032204</span>  <span class=\"o\">-</span><span class=\"mf\">220.68304592</span><span class=\"p\">]</span>\n</pre>\n<p>The following example demonstrates how to use glimpy alongside scikit-learn to perform grid search over elastic-net hyperparameters</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">statsmodels.api</span> <span class=\"k\">as</span> <span class=\"nn\">sm</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">glimpy</span> <span class=\"kn\">import</span> <span class=\"n\">GLM</span><span class=\"p\">,</span> <span class=\"n\">Gamma</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">sklearn.preprocessing</span> <span class=\"kn\">import</span> <span class=\"n\">StandardScaler</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">sklearn.pipeline</span> <span class=\"kn\">import</span> <span class=\"n\">Pipeline</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">sklearn</span> <span class=\"kn\">import</span> <span class=\"n\">datasets</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">GridSearchCV</span>\n<span class=\"o\">&gt;&gt;&gt;</span> \n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">diabetes</span> <span class=\"o\">=</span> <span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">load_diabetes</span><span class=\"p\">()</span>\n<span class=\"o\">&gt;&gt;&gt;</span> \n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">scaler</span> <span class=\"o\">=</span> <span class=\"n\">StandardScaler</span><span class=\"p\">()</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">gamma_glm</span> <span class=\"o\">=</span> <span class=\"n\">GLM</span><span class=\"p\">(</span><span class=\"n\">fit_intercept</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">family</span><span class=\"o\">=</span><span class=\"n\">Gamma</span><span class=\"p\">(</span><span class=\"n\">sm</span><span class=\"o\">.</span><span class=\"n\">families</span><span class=\"o\">.</span><span class=\"n\">links</span><span class=\"o\">.</span><span class=\"n\">log</span><span class=\"p\">()),</span> <span class=\"n\">penalty</span><span class=\"o\">=</span><span class=\"s1\">'elasticnet'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">gamma_pipeline</span> <span class=\"o\">=</span> <span class=\"n\">Pipeline</span><span class=\"p\">([(</span><span class=\"s1\">'scaler'</span><span class=\"p\">,</span> <span class=\"n\">scaler</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'glm'</span><span class=\"p\">,</span> <span class=\"n\">gamma_glm</span><span class=\"p\">)])</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">grid_search</span> <span class=\"o\">=</span> <span class=\"n\">GridSearchCV</span><span class=\"p\">(</span><span class=\"n\">gamma_pipeline</span><span class=\"p\">,</span>\n<span class=\"o\">&gt;&gt;&gt;</span>     <span class=\"n\">param_grid</span><span class=\"o\">=</span><span class=\"p\">[{</span>\n<span class=\"o\">&gt;&gt;&gt;</span>         <span class=\"s1\">'glm__C'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mf\">1e4</span><span class=\"p\">,</span> <span class=\"mf\">1e5</span><span class=\"p\">,</span> <span class=\"mf\">1e6</span><span class=\"p\">],</span>\n<span class=\"o\">&gt;&gt;&gt;</span>         <span class=\"s1\">'glm__l1_ratio'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mf\">0.1</span><span class=\"p\">,</span> <span class=\"mf\">0.5</span><span class=\"p\">,</span> <span class=\"mf\">0.9</span><span class=\"p\">]</span>\n<span class=\"o\">&gt;&gt;&gt;</span>     <span class=\"p\">}],</span>\n<span class=\"o\">&gt;&gt;&gt;</span>     <span class=\"n\">cv</span><span class=\"o\">=</span><span class=\"mi\">3</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> \n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">grid_search</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">diabetes</span><span class=\"p\">[</span><span class=\"s1\">'data'</span><span class=\"p\">],</span> <span class=\"n\">diabetes</span><span class=\"p\">[</span><span class=\"s1\">'target'</span><span class=\"p\">])</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">grid_search</span><span class=\"o\">.</span><span class=\"n\">best_params_</span><span class=\"p\">)</span>\n<span class=\"p\">{</span><span class=\"s1\">'glm__C'</span><span class=\"p\">:</span> <span class=\"mf\">1000000.0</span><span class=\"p\">,</span> <span class=\"s1\">'glm__l1_ratio'</span><span class=\"p\">:</span> <span class=\"mf\">0.1</span><span class=\"p\">}</span>\n</pre>\n\n          </div>"}, "last_serial": 6482754, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "d0db6bbcdf466157ba42c60353725a71", "sha256": "8b0042c2d1f9a9f60bcf554d00581f542db2749e8f6161eb97e8caba9c292330"}, "downloads": -1, "filename": "glimpy-0.0.1.tar.gz", "has_sig": false, "md5_digest": "d0db6bbcdf466157ba42c60353725a71", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 4859, "upload_time": "2020-01-13T20:56:01", "upload_time_iso_8601": "2020-01-13T20:56:01.383378Z", "url": "https://files.pythonhosted.org/packages/63/cb/ce9eadee7924a2683d9c8a3165304b51733fdb048f25d7eb97dea374ebac/glimpy-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "af1494e6f40d94f24e8432165f80cfb2", "sha256": "15a4b0581e1a6b2ca1ea9483fc5caeddc7cf10698fd86a65bf4b70d76813da0c"}, "downloads": -1, "filename": "glimpy-0.0.2.tar.gz", "has_sig": false, "md5_digest": "af1494e6f40d94f24e8432165f80cfb2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 4823, "upload_time": "2020-01-13T22:11:55", "upload_time_iso_8601": "2020-01-13T22:11:55.147297Z", "url": "https://files.pythonhosted.org/packages/00/e2/174a766a1e8f74599edd1819e39a5f8b478042e66ed7a23dd87bca1b5e9e/glimpy-0.0.2.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "e194a3c504c4b60d37c66d912e4ee764", "sha256": "7a36284164dab808cce30e9df3b67313a7d1830d0474cc4adedbbc4c0733def2"}, "downloads": -1, "filename": "glimpy-0.1.0.tar.gz", "has_sig": false, "md5_digest": "e194a3c504c4b60d37c66d912e4ee764", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 6054, "upload_time": "2020-01-19T16:48:58", "upload_time_iso_8601": "2020-01-19T16:48:58.205842Z", "url": "https://files.pythonhosted.org/packages/26/a6/5459a13e7baef0ec54a40abefca47f411787eb05ed58bbae09600d33255a/glimpy-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "e194a3c504c4b60d37c66d912e4ee764", "sha256": "7a36284164dab808cce30e9df3b67313a7d1830d0474cc4adedbbc4c0733def2"}, "downloads": -1, "filename": "glimpy-0.1.0.tar.gz", "has_sig": false, "md5_digest": "e194a3c504c4b60d37c66d912e4ee764", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 6054, "upload_time": "2020-01-19T16:48:58", "upload_time_iso_8601": "2020-01-19T16:48:58.205842Z", "url": "https://files.pythonhosted.org/packages/26/a6/5459a13e7baef0ec54a40abefca47f411787eb05ed58bbae09600d33255a/glimpy-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:56:35 2020"}