{"info": {"author": "Steffen Schneider", "author_email": "steffen.schneider@tum.de", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)", "Operating System :: OS Independent", "Programming Language :: Python :: 3", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "\ud83e\udd57 salad \n========\n\n**S**\\ emi-supervised **A**\\ daptive **L**\\ earning **A**\\ cross **D**\\ omains\n\n.. figure:: img/domainshift.png\n   :alt: \n\n\n``salad`` is a library to easily setup experiments using the current\nstate-of-the art techniques in domain adaptation. It features several of\nrecent approaches, with the goal of being able to run fair comparisons\nbetween algorithms and transfer them to real-world use cases. The\ntoolbox is under active development and will extended when new\napproaches are published.\n\nContribute on Github: `https://github.com/domainadaptation/salad`_\n\nCurrently implements the following techniques (in ``salad.solver``)\n\n-  VADA (``VADASolver``),\n   `arxiv:1802.08735 <https://arxiv.org/abs/1802.08735>`__\n-  DIRT-T (``DIRTTSolver``),\n   `arxiv:1802.08735 <https://arxiv.org/abs/1802.08735>`__\n-  Self-Ensembling for Visual Domain Adaptation\n   (``SelfEnsemblingSolver``)\n   `arxiv:1706.05208 <https://arxiv.org/abs/1706.05208>`__\n-  Associative Domain Adaptation (``AssociativeSolver``),\n   `arxiv:1708.00938 <https://arxiv.org/pdf/1708.00938.pdf>`__\n-  Domain Adversarial Training (``DANNSolver``),\n   `jmlr:v17/15-239.html <http://jmlr.org/papers/v17/15-239.html>`__\n-  Generalizing Across Domains via Cross-Gradient Training\n   (``CrossGradSolver``),\n   `arxiv:1708.00938 <http://arxiv.org/abs/1804.10745>`__\n-  Adversarial Dropout Regularization (``AdversarialDropoutSolver``),\n   `arxiv.org:1711.01575 <https://arxiv.org/abs/1711.01575>`__\n\nImplements the following features (in ``salad.layers``):\n\n-  Weights Ensembling using Exponential Moving Averages or Stored\n   Weights\n-  WalkerLoss and Visit Loss\n   (`arxiv:1708.00938 <https://arxiv.org/pdf/1708.00938.pdf>`__)\n-  Virtual Adversarial Training\n   (`arxiv:1704.03976 <https://arxiv.org/abs/1704.03976>`__)\n\nComing soon:\n\n-  Deep Joint Optimal Transport (``DJDOTSolver``),\n   `arxiv:1803.10081 <https://arxiv.org/abs/1803.10081>`__\n-  Translation based approaches\n\n\ud83d\udcca Benchmarking Results\n----------------------\n\nOne of salad's purposes is to constantly track the state of the art of a variety of domain\nadaptation algorithms. The latest results can be reproduced by the files in the ``scripts/``\ndirectory.\n\n.. figure:: img/benchmarks.svg\n    :alt:\n\n\n\ud83d\udcbb Installation\n---------------\n\nRequirements can be found in ``requirement.txt`` and can be installed\nvia\n\n.. code:: bash\n\n    pip install -r requirements.txt\n\nInstall the package via\n\n.. code:: bash\n\n    pip install torch-salad\n\nFor the latest development version, install via\n\n.. code:: bash\n\n    pip install git+https://github.com/bethgelab/domainadaptation\n\n\n\ud83d\udcda Using this library\n---------------------\n\nAlong with the implementation of domain adaptation routines, this\nlibrary comprises code to easily set up deep learning experiments in\ngeneral. \n\nThis section will be extended upon pre-release.\n\nQuick Start\n~~~~~~~~~~~\n\nTo get started, the ``scripts/`` directory contains several python scripts\nfor both running replication studies on digit benchmarks and studies on\na different dataset (toy example: adaptation to noisy images).\n\n.. code:: bash\n\n    $ cd scripts\n    $ python train_digits.py --log ./log --teach --source svhn --target mnist\n\nRefer to the help pages for all options:\n\n.. code::\n\n    usage: train_digits.py [-h] [--gpu GPU] [--cpu] [--njobs NJOBS] [--log LOG]\n                        [--epochs EPOCHS] [--checkpoint CHECKPOINT]\n                        [--learningrate LEARNINGRATE] [--dryrun]\n                        [--source {mnist,svhn,usps,synth,synth-small}]\n                        [--target {mnist,svhn,usps,synth,synth-small}]\n                        [--sourcebatch SOURCEBATCH] [--targetbatch TARGETBATCH]\n                        [--seed SEED] [--print] [--null] [--adv] [--vada]\n                        [--dann] [--assoc] [--coral] [--teach]\n\n    Domain Adaptation Comparision and Reproduction Study\n\n    optional arguments:\n    -h, --help            show this help message and exit\n    --gpu GPU             Specify GPU\n    --cpu                 Use CPU Training\n    --njobs NJOBS         Number of processes per dataloader\n    --log LOG             Log directory. Will be created if non-existing\n    --epochs EPOCHS       Number of Epochs (Full passes through the unsupervised\n                            training set)\n    --checkpoint CHECKPOINT\n                            Checkpoint path\n    --learningrate LEARNINGRATE\n                            Learning rate for Adam. Defaults to Karpathy's\n                            constant ;-)\n    --dryrun              Perform a test run, without actually training a\n                            network.\n    --source {mnist,svhn,usps,synth,synth-small}\n                            Source Dataset. Choose mnist or svhn\n    --target {mnist,svhn,usps,synth,synth-small}\n                            Target Dataset. Choose mnist or svhn\n    --sourcebatch SOURCEBATCH\n                            Batch size of Source\n    --targetbatch TARGETBATCH\n                            Batch size of Target\n    --seed SEED           Random Seed\n    --print\n    --null\n    --adv                 Train a model with Adversarial Domain Regularization\n    --vada                Train a model with Virtual Adversarial Domain\n                            Adaptation\n    --dann                Train a model with Domain Adversarial Training\n    --assoc               Train a model with Associative Domain Adaptation\n    --coral               Train a model with Deep Correlation Alignment\n    --teach               Train a model with Self-Ensembling\n\n\n\nReasons for using solver abstractions\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe chosen abstraction style organizes experiments into a subclass of\n``Solver``.\n\nQuickstart: MNIST Experiment\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nAs a quick MNIST experiment:\n\n.. code:: python\n\n    from salad.solvers import Solver\n\n    class MNISTSolver(Solver):\n\n        def __init__(self, model, dataset, **kwargs):\n\n            self.model = model\n            super().__init__(dataset, **kwargs)\n\n        def _init_optims(self, lr = 1e-4, **kwargs):\n            super()._init_optims(**kwargs)\n\n            opt = torch.optim.Adam(self.model.parameters(), lr = lr)\n            self.register_optimizer(opt)\n\n        def _init_losses(self):\n            pass\n\nFor a simple tasks as MNIST, the code is quite long compared to other\nPyTorch examples `TODO <#>`__.\n\n\ud83d\udca1 Domain Adaptation Problems\n-----------------------------\n\nLegend: Implemented (\u2713), Under Construction (\ud83d\udea7)\n\n\ud83d\udcf7 Vision\n~~~~~~~~~\n\n-  Digits: MNIST \u2194 SVHN \u2194 USPS \u2194 SYNTH (\u2713)\n-  `VisDA 2018 Openset and Detection <http://ai.bu.edu/visda-2018>`__\n   (\u2713)\n-  Synthetic (GAN) \u2194 Real (\ud83d\udea7)\n-  CIFAR \u2194 STL (\ud83d\udea7)\n-  ImageNet to\n   `iCubWorld <https://robotology.github.io/iCubWorld/#datasets>`__ (\ud83d\udea7)\n\n\ud83c\udfa4 Audio\n~~~~~~~~\n\n-  `Mozilla Common Voice Dataset <https://voice.mozilla.org/>`__ (\ud83d\udea7)\n\n\u1368 Neuroscience\n~~~~~~~~~~~~~~\n\n-  White Noise \u2194 Gratings \u2194 Natural Images (\ud83d\udea7)\n-  `Deep Lab Cut Tracking <https://github.com/AlexEMG/DeepLabCut>`__ (\ud83d\udea7)\n\n\ud83d\udd17 References to open source software\n-------------------------------------\n\nPart of the code in this repository is inspired or borrowed from\noriginal implementations, especially:\n\n-  https://github.com/Britefury/self-ensemble-visual-domain-adapt\n-  https://github.com/Britefury/self-ensemble-visual-domain-adapt-photo/\n-  https://github.com/RuiShu/dirt-t\n-  https://github.com/gpascualg/CrossGrad\n-  https://github.com/stes/torch-associative\n-  https://github.com/haeusser/learning\\_by\\_association\n-  https://mil-tokyo.github.io/adr\\_da/\n\nExcellent list of domain adaptation ressources: -\nhttps://github.com/artix41/awesome-transfer-learning\n\n\ud83d\udc64 Contact\n----------\n\nMaintained by `Steffen Schneider <https://code.stes.io>`__. Work is part\nof my thesis project at the `Bethge Lab <http://bethgelab.org>`__. This\nREADME is also available as a webpage at\n`salad.domainadaptation.org <http://salad.domainadaptation.org>`__. We\nwelcome issues and pull requests `to the official github\nrepository <https://github.com/bethgelab/domainadaptation>`__.\n\n\n", "description_content_type": "text/x-rst", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://domainadaptation.org", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "torch-salad", "package_url": "https://pypi.org/project/torch-salad/", "platform": "", "project_url": "https://pypi.org/project/torch-salad/", "project_urls": {"Homepage": "https://domainadaptation.org"}, "release_url": "https://pypi.org/project/torch-salad/0.2.1a0/", "requires_dist": null, "requires_python": "", "summary": "Semi-supervised Adaptive Learning Across Domains", "version": "0.2.1a0", "yanked": false, "html_description": "<div class=\"project-description\">\n            \ud83e\udd57 salad <br>========<br><br>**S**\\ emi-supervised **A**\\ daptive **L**\\ earning **A**\\ cross **D**\\ omains<br><br>.. figure:: img/domainshift.png<br>   :alt: <br><br><br>``salad`` is a library to easily setup experiments using the current<br>state-of-the art techniques in domain adaptation. It features several of<br>recent approaches, with the goal of being able to run fair comparisons<br>between algorithms and transfer them to real-world use cases. The<br>toolbox is under active development and will extended when new<br>approaches are published.<br><br>Contribute on Github: `https://github.com/domainadaptation/salad`_<br><br>Currently implements the following techniques (in ``salad.solver``)<br><br>-  VADA (``VADASolver``),<br>   `arxiv:1802.08735 &lt;https://arxiv.org/abs/1802.08735&gt;`__<br>-  DIRT-T (``DIRTTSolver``),<br>   `arxiv:1802.08735 &lt;https://arxiv.org/abs/1802.08735&gt;`__<br>-  Self-Ensembling for Visual Domain Adaptation<br>   (``SelfEnsemblingSolver``)<br>   `arxiv:1706.05208 &lt;https://arxiv.org/abs/1706.05208&gt;`__<br>-  Associative Domain Adaptation (``AssociativeSolver``),<br>   `arxiv:1708.00938 &lt;https://arxiv.org/pdf/1708.00938.pdf&gt;`__<br>-  Domain Adversarial Training (``DANNSolver``),<br>   `jmlr:v17/15-239.html &lt;http://jmlr.org/papers/v17/15-239.html&gt;`__<br>-  Generalizing Across Domains via Cross-Gradient Training<br>   (``CrossGradSolver``),<br>   `arxiv:1708.00938 &lt;http://arxiv.org/abs/1804.10745&gt;`__<br>-  Adversarial Dropout Regularization (``AdversarialDropoutSolver``),<br>   `arxiv.org:1711.01575 &lt;https://arxiv.org/abs/1711.01575&gt;`__<br><br>Implements the following features (in ``salad.layers``):<br><br>-  Weights Ensembling using Exponential Moving Averages or Stored<br>   Weights<br>-  WalkerLoss and Visit Loss<br>   (`arxiv:1708.00938 &lt;https://arxiv.org/pdf/1708.00938.pdf&gt;`__)<br>-  Virtual Adversarial Training<br>   (`arxiv:1704.03976 &lt;https://arxiv.org/abs/1704.03976&gt;`__)<br><br>Coming soon:<br><br>-  Deep Joint Optimal Transport (``DJDOTSolver``),<br>   `arxiv:1803.10081 &lt;https://arxiv.org/abs/1803.10081&gt;`__<br>-  Translation based approaches<br><br>\ud83d\udcca Benchmarking Results<br>----------------------<br><br>One of salad's purposes is to constantly track the state of the art of a variety of domain<br>adaptation algorithms. The latest results can be reproduced by the files in the ``scripts/``<br>directory.<br><br>.. figure:: img/benchmarks.svg<br>    :alt:<br><br><br>\ud83d\udcbb Installation<br>---------------<br><br>Requirements can be found in ``requirement.txt`` and can be installed<br>via<br><br>.. code:: bash<br><br>    pip install -r requirements.txt<br><br>Install the package via<br><br>.. code:: bash<br><br>    pip install torch-salad<br><br>For the latest development version, install via<br><br>.. code:: bash<br><br>    pip install git+https://github.com/bethgelab/domainadaptation<br><br><br>\ud83d\udcda Using this library<br>---------------------<br><br>Along with the implementation of domain adaptation routines, this<br>library comprises code to easily set up deep learning experiments in<br>general. <br><br>This section will be extended upon pre-release.<br><br>Quick Start<br>~~~~~~~~~~~<br><br>To get started, the ``scripts/`` directory contains several python scripts<br>for both running replication studies on digit benchmarks and studies on<br>a different dataset (toy example: adaptation to noisy images).<br><br>.. code:: bash<br><br>    $ cd scripts<br>    $ python train_digits.py --log ./log --teach --source svhn --target mnist<br><br>Refer to the help pages for all options:<br><br>.. code::<br><br>    usage: train_digits.py [-h] [--gpu GPU] [--cpu] [--njobs NJOBS] [--log LOG]<br>                        [--epochs EPOCHS] [--checkpoint CHECKPOINT]<br>                        [--learningrate LEARNINGRATE] [--dryrun]<br>                        [--source {mnist,svhn,usps,synth,synth-small}]<br>                        [--target {mnist,svhn,usps,synth,synth-small}]<br>                        [--sourcebatch SOURCEBATCH] [--targetbatch TARGETBATCH]<br>                        [--seed SEED] [--print] [--null] [--adv] [--vada]<br>                        [--dann] [--assoc] [--coral] [--teach]<br><br>    Domain Adaptation Comparision and Reproduction Study<br><br>    optional arguments:<br>    -h, --help            show this help message and exit<br>    --gpu GPU             Specify GPU<br>    --cpu                 Use CPU Training<br>    --njobs NJOBS         Number of processes per dataloader<br>    --log LOG             Log directory. Will be created if non-existing<br>    --epochs EPOCHS       Number of Epochs (Full passes through the unsupervised<br>                            training set)<br>    --checkpoint CHECKPOINT<br>                            Checkpoint path<br>    --learningrate LEARNINGRATE<br>                            Learning rate for Adam. Defaults to Karpathy's<br>                            constant ;-)<br>    --dryrun              Perform a test run, without actually training a<br>                            network.<br>    --source {mnist,svhn,usps,synth,synth-small}<br>                            Source Dataset. Choose mnist or svhn<br>    --target {mnist,svhn,usps,synth,synth-small}<br>                            Target Dataset. Choose mnist or svhn<br>    --sourcebatch SOURCEBATCH<br>                            Batch size of Source<br>    --targetbatch TARGETBATCH<br>                            Batch size of Target<br>    --seed SEED           Random Seed<br>    --print<br>    --null<br>    --adv                 Train a model with Adversarial Domain Regularization<br>    --vada                Train a model with Virtual Adversarial Domain<br>                            Adaptation<br>    --dann                Train a model with Domain Adversarial Training<br>    --assoc               Train a model with Associative Domain Adaptation<br>    --coral               Train a model with Deep Correlation Alignment<br>    --teach               Train a model with Self-Ensembling<br><br><br><br>Reasons for using solver abstractions<br>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~<br><br>The chosen abstraction style organizes experiments into a subclass of<br>``Solver``.<br><br>Quickstart: MNIST Experiment<br>~~~~~~~~~~~~~~~~~~~~~~~~~~~~<br><br>As a quick MNIST experiment:<br><br>.. code:: python<br><br>    from salad.solvers import Solver<br><br>    class MNISTSolver(Solver):<br><br>        def __init__(self, model, dataset, **kwargs):<br><br>            self.model = model<br>            super().__init__(dataset, **kwargs)<br><br>        def _init_optims(self, lr = 1e-4, **kwargs):<br>            super()._init_optims(**kwargs)<br><br>            opt = torch.optim.Adam(self.model.parameters(), lr = lr)<br>            self.register_optimizer(opt)<br><br>        def _init_losses(self):<br>            pass<br><br>For a simple tasks as MNIST, the code is quite long compared to other<br>PyTorch examples `TODO &lt;#&gt;`__.<br><br>\ud83d\udca1 Domain Adaptation Problems<br>-----------------------------<br><br>Legend: Implemented (\u2713), Under Construction (\ud83d\udea7)<br><br>\ud83d\udcf7 Vision<br>~~~~~~~~~<br><br>-  Digits: MNIST \u2194 SVHN \u2194 USPS \u2194 SYNTH (\u2713)<br>-  `VisDA 2018 Openset and Detection &lt;http://ai.bu.edu/visda-2018&gt;`__<br>   (\u2713)<br>-  Synthetic (GAN) \u2194 Real (\ud83d\udea7)<br>-  CIFAR \u2194 STL (\ud83d\udea7)<br>-  ImageNet to<br>   `iCubWorld &lt;https://robotology.github.io/iCubWorld/#datasets&gt;`__ (\ud83d\udea7)<br><br>\ud83c\udfa4 Audio<br>~~~~~~~~<br><br>-  `Mozilla Common Voice Dataset &lt;https://voice.mozilla.org/&gt;`__ (\ud83d\udea7)<br><br>\u1368 Neuroscience<br>~~~~~~~~~~~~~~<br><br>-  White Noise \u2194 Gratings \u2194 Natural Images (\ud83d\udea7)<br>-  `Deep Lab Cut Tracking &lt;https://github.com/AlexEMG/DeepLabCut&gt;`__ (\ud83d\udea7)<br><br>\ud83d\udd17 References to open source software<br>-------------------------------------<br><br>Part of the code in this repository is inspired or borrowed from<br>original implementations, especially:<br><br>-  https://github.com/Britefury/self-ensemble-visual-domain-adapt<br>-  https://github.com/Britefury/self-ensemble-visual-domain-adapt-photo/<br>-  https://github.com/RuiShu/dirt-t<br>-  https://github.com/gpascualg/CrossGrad<br>-  https://github.com/stes/torch-associative<br>-  https://github.com/haeusser/learning\\_by\\_association<br>-  https://mil-tokyo.github.io/adr\\_da/<br><br>Excellent list of domain adaptation ressources: -<br>https://github.com/artix41/awesome-transfer-learning<br><br>\ud83d\udc64 Contact<br>----------<br><br>Maintained by `Steffen Schneider &lt;https://code.stes.io&gt;`__. Work is part<br>of my thesis project at the `Bethge Lab &lt;http://bethgelab.org&gt;`__. This<br>README is also available as a webpage at<br>`salad.domainadaptation.org &lt;http://salad.domainadaptation.org&gt;`__. We<br>welcome issues and pull requests `to the official github<br>repository &lt;https://github.com/bethgelab/domainadaptation&gt;`__.<br><br><br>\n          </div>"}, "last_serial": 4327184, "releases": {"0.0.3a0": [{"comment_text": "", "digests": {"md5": "b6c8f2d50c523cca6af472142ec3a862", "sha256": "b05b6ff39d0cd7471d90553f9910b567a6de7da1e0e07ecd96ce4f4652a1e00e"}, "downloads": -1, "filename": "torch_salad-0.0.3a0-py3-none-any.whl", "has_sig": false, "md5_digest": "b6c8f2d50c523cca6af472142ec3a862", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 82703, "upload_time": "2018-10-01T08:21:41", "upload_time_iso_8601": "2018-10-01T08:21:41.995972Z", "url": "https://files.pythonhosted.org/packages/e2/89/6558ec5a834dce50419905188d9edaf304d036367527ad38ff47aa4a887e/torch_salad-0.0.3a0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4b5997ec214f57f307f7ea92af307c32", "sha256": "2923e839db5af4c1a6c51436475136edabf8945f7cc8a7eec2b789cdc451a3e3"}, "downloads": -1, "filename": "torch-salad-0.0.3a0.tar.gz", "has_sig": false, "md5_digest": "4b5997ec214f57f307f7ea92af307c32", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 50266, "upload_time": "2018-10-01T08:21:45", "upload_time_iso_8601": "2018-10-01T08:21:45.074520Z", "url": "https://files.pythonhosted.org/packages/22/dd/18f8210eab0e507672e76e49a116f2e42947c3a0a41c802ffe17857bb633/torch-salad-0.0.3a0.tar.gz", "yanked": false}], "0.1.4a0": [{"comment_text": "", "digests": {"md5": "972f6829bd00a033428bf0252b589619", "sha256": "7b4e9ad7b46ccef5caae36505fde452cdf111d7cdb07b9aac32e7fbad6cfa381"}, "downloads": -1, "filename": "torch_salad-0.1.4a0-py3-none-any.whl", "has_sig": false, "md5_digest": "972f6829bd00a033428bf0252b589619", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 3157, "upload_time": "2018-09-17T23:27:34", "upload_time_iso_8601": "2018-09-17T23:27:34.436033Z", "url": "https://files.pythonhosted.org/packages/cc/ab/317451b95259542e9c162dcca44845e5094810952f7b2a22ed1f5c623d8e/torch_salad-0.1.4a0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "af4f8a5903f84792ebe71776044f45c7", "sha256": "e81e04d7658877ed51a3fae41c8436e3fc8c5f311ec3f081d77270c13193b9d9"}, "downloads": -1, "filename": "torch-salad-0.1.4a0.tar.gz", "has_sig": false, "md5_digest": "af4f8a5903f84792ebe71776044f45c7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2906, "upload_time": "2018-09-17T23:27:35", "upload_time_iso_8601": "2018-09-17T23:27:35.624180Z", "url": "https://files.pythonhosted.org/packages/49/fb/28338530fce35803a6704576a716e45aa42d58dc74dfea2290a73cc2d6c5/torch-salad-0.1.4a0.tar.gz", "yanked": false}], "0.2.0a0": [{"comment_text": "", "digests": {"md5": "c25f3350c079d0ef81ea530f01d6bb4d", "sha256": "c5de4436a6d8e292fa0a9c7df4d5df2ad5d16892a6ae52ef54148869c6edc27f"}, "downloads": -1, "filename": "torch_salad-0.2.0a0-py3-none-any.whl", "has_sig": false, "md5_digest": "c25f3350c079d0ef81ea530f01d6bb4d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 82703, "upload_time": "2018-10-01T08:21:43", "upload_time_iso_8601": "2018-10-01T08:21:43.545970Z", "url": "https://files.pythonhosted.org/packages/3a/87/75789c8cf95948612fa1b6767a2469798da7e1a7d2f0d4428692e3fce193/torch_salad-0.2.0a0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f7dc8a58676c3d11adf4940eceee69d3", "sha256": "aeadc0492cc0876c4495133e7e40e4653110fd7d02a256e30a8830a0c6b0babb"}, "downloads": -1, "filename": "torch-salad-0.2.0a0.tar.gz", "has_sig": false, "md5_digest": "f7dc8a58676c3d11adf4940eceee69d3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 50264, "upload_time": "2018-10-01T08:21:46", "upload_time_iso_8601": "2018-10-01T08:21:46.609018Z", "url": "https://files.pythonhosted.org/packages/25/52/6488a39205ed60a436d008396d611aef129e974c1745fc70c93fd2dd5c15/torch-salad-0.2.0a0.tar.gz", "yanked": false}], "0.2.1a0": [{"comment_text": "", "digests": {"md5": "0fdb0dbb851be484f2c9102210d35b8a", "sha256": "93d7c5071a84a851d8bdbc753cb48ac1bdb1baf03517a7c0aa19e31911b7384a"}, "downloads": -1, "filename": "torch_salad-0.2.1a0-py3-none-any.whl", "has_sig": false, "md5_digest": "0fdb0dbb851be484f2c9102210d35b8a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 82701, "upload_time": "2018-10-01T08:22:39", "upload_time_iso_8601": "2018-10-01T08:22:39.521962Z", "url": "https://files.pythonhosted.org/packages/db/37/a8614582b1b7be0c2b2d145c8af7c92417346b65faf1b6b32ab30355d119/torch_salad-0.2.1a0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7270bea56d0f177a2343d5126ca11377", "sha256": "35222526e6593bfd19c14c5896764e36bd805c9702685e93b081de1f438aacd1"}, "downloads": -1, "filename": "torch-salad-0.2.1a0.tar.gz", "has_sig": false, "md5_digest": "7270bea56d0f177a2343d5126ca11377", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 50257, "upload_time": "2018-10-01T08:22:42", "upload_time_iso_8601": "2018-10-01T08:22:42.269145Z", "url": "https://files.pythonhosted.org/packages/00/99/2278637de69ebb64f5cb23134516ade17b2d16a0fc93e2ff2f0f91454dc5/torch-salad-0.2.1a0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "0fdb0dbb851be484f2c9102210d35b8a", "sha256": "93d7c5071a84a851d8bdbc753cb48ac1bdb1baf03517a7c0aa19e31911b7384a"}, "downloads": -1, "filename": "torch_salad-0.2.1a0-py3-none-any.whl", "has_sig": false, "md5_digest": "0fdb0dbb851be484f2c9102210d35b8a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 82701, "upload_time": "2018-10-01T08:22:39", "upload_time_iso_8601": "2018-10-01T08:22:39.521962Z", "url": "https://files.pythonhosted.org/packages/db/37/a8614582b1b7be0c2b2d145c8af7c92417346b65faf1b6b32ab30355d119/torch_salad-0.2.1a0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7270bea56d0f177a2343d5126ca11377", "sha256": "35222526e6593bfd19c14c5896764e36bd805c9702685e93b081de1f438aacd1"}, "downloads": -1, "filename": "torch-salad-0.2.1a0.tar.gz", "has_sig": false, "md5_digest": "7270bea56d0f177a2343d5126ca11377", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 50257, "upload_time": "2018-10-01T08:22:42", "upload_time_iso_8601": "2018-10-01T08:22:42.269145Z", "url": "https://files.pythonhosted.org/packages/00/99/2278637de69ebb64f5cb23134516ade17b2d16a0fc93e2ff2f0f91454dc5/torch-salad-0.2.1a0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:50:13 2020"}