{"info": {"author": "Andrew Svetlov", "author_email": "andrew.svetlov@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Framework :: AsyncIO", "Intended Audience :: Developers", "License :: OSI Approved :: Apache Software License", "Operating System :: OS Independent", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: System :: Distributed Computing", "Topic :: System :: Networking"], "description": "aiokafka\n========\n.. image:: https://travis-ci.com/aio-libs/aiokafka.svg?branch=master\n    :target: https://travis-ci.com/aio-libs/aiokafka\n    :alt: |Build status|\n.. image:: https://codecov.io/github/aio-libs/aiokafka/coverage.svg?branch=master\n    :target: https://codecov.io/gh/aio-libs/aiokafka/branch/master\n    :alt: |Coverage|\n.. image:: https://badges.gitter.im/Join%20Chat.svg\n    :target: https://gitter.im/aio-libs/Lobby\n    :alt: |Chat on Gitter|\n\nasyncio client for Kafka\n\n\nAIOKafkaProducer\n****************\n\nAIOKafkaProducer is a high-level, asynchronous message producer.\n\nExample of AIOKafkaProducer usage:\n\n.. code-block:: python\n\n    from aiokafka import AIOKafkaProducer\n    import asyncio\n\n    loop = asyncio.get_event_loop()\n\n    async def send_one():\n        producer = AIOKafkaProducer(\n            loop=loop, bootstrap_servers='localhost:9092')\n        # Get cluster layout and initial topic/partition leadership information\n        await producer.start()\n        try:\n            # Produce message\n            await producer.send_and_wait(\"my_topic\", b\"Super message\")\n        finally:\n            # Wait for all pending messages to be delivered or expire.\n            await producer.stop()\n\n    loop.run_until_complete(send_one())\n\n\nAIOKafkaConsumer\n****************\n\nAIOKafkaConsumer is a high-level, asynchronous message consumer.\nIt interacts with the assigned Kafka Group Coordinator node to allow multiple \nconsumers to load balance consumption of topics (requires kafka >= 0.9.0.0).\n\nExample of AIOKafkaConsumer usage:\n\n.. code-block:: python\n\n    from aiokafka import AIOKafkaConsumer\n    import asyncio\n\n    loop = asyncio.get_event_loop()\n\n    async def consume():\n        consumer = AIOKafkaConsumer(\n            'my_topic', 'my_other_topic',\n            loop=loop, bootstrap_servers='localhost:9092',\n            group_id=\"my-group\")\n        # Get cluster layout and join group `my-group`\n        await consumer.start()\n        try:\n            # Consume messages\n            async for msg in consumer:\n                print(\"consumed: \", msg.topic, msg.partition, msg.offset,\n                      msg.key, msg.value, msg.timestamp)\n        finally:\n            # Will leave consumer group; perform autocommit if enabled.\n            await consumer.stop()\n\n    loop.run_until_complete(consume())\n\nRunning tests\n-------------\n\nDocker is required to run tests. See https://docs.docker.com/engine/installation for installation notes. Also note, that `lz4` compression libraries for python will require `python-dev` package,\nor python source header files for compilation on Linux.\nNOTE: You will also need a valid java installation. It's required for the ``keytool`` utility, used to\ngenerate ssh keys for some tests.\n\nSetting up tests requirements (assuming you're within virtualenv on ubuntu 14.04+)::\n\n    sudo apt-get install -y libsnappy-dev\n    make setup\n\nRunning tests with coverage::\n\n    make cov\n\nTo run tests with a specific version of Kafka (default one is 1.0.2) use KAFKA_VERSION variable::\n\n    make cov KAFKA_VERSION=0.10.2.1\n\nTest running cheatsheat:\n\n * ``make test FLAGS=\"-l -x --ff\"`` - run until 1 failure, rerun failed tests fitst. Great for cleaning up a lot of errors, say after a big refactor.\n * ``make test FLAGS=\"-k consumer\"`` - run only the consumer tests.\n * ``make test FLAGS=\"-m 'not ssl'\"`` - run tests excluding ssl.\n * ``make test FLAGS=\"--no-pull\"`` - do not try to pull new docker image before test run.\n\nCHANGES\n-------\n\n0.5.2 (2019-03-10)\n^^^^^^^^^^^^^^^^^^\n\nBugfixes:\n\n* Fix ConnectionError breaking metadata sync background task (issue #517 and #512)\n* Fix event_waiter reference before assignment (pr #504 by @romantolkachyov)\n* Bump version of kafka-python\n\n\n0.5.1 (2019-03-10)\n^^^^^^^^^^^^^^^^^^\n\nNew features:\n\n* Add SASL support with both SASL plain and SASL GGSAPI. Support also includes\n  Broker v0.9.0, but you will need to explicitly pass ``api_version=\"0.9\"``.\n  (Big thanks to @cyrbil and @jsurloppe for working on this)\n* Added support for max_poll_interval_ms and rebalance_timeout_ms settings (\n  issue #67)\n* Added pause/resume API for AIOKafkaConsumer. (issue #304)\n* Added header support to both AIOKafkaConsumer and AIOKafkaProducer for\n  brokers v0.11 and above. (issue #462)\n\nBugfixes:\n\n* Made sure to not request metadata for all topics if broker version is passed\n  explicitly and is 0.10 and above. (issue #440, thanks to @ulrikjohansson)\n* Make sure heartbeat task will close if group is reset. (issue #372)\n\n\n0.5.0 (2018-12-28)\n^^^^^^^^^^^^^^^^^^\n\nNew features:\n\n* Add full support for V2 format messages with a Cython extension. Those are\n  used for Kafka >= 0.11.0.0\n* Added support for transactional producing (issue #182)\n* Added support for indempotent producing with `enable_idempotence` parameter\n* Added support for `fetch_max_bytes` in AIOKafkaConsumer. This can help limit\n  the amount of data transferred in a single roundtrip to broker, which is\n  essential for consumers with large amount of partitions\n\nBugfixes:\n\n* Fix issue with connections not propagating serialization errors\n* Fix issue with `group=None` resetting offsets on every metadata update\n  (issue #441)\n* Fix issue with messages not delivered in order when Leader changes (issue\n  #228)\n* Fixed version parsing of `api_version` parameter. Before it ignored the\n  parameter\n\n\n0.4.3 (2018-11-01)\n^^^^^^^^^^^^^^^^^^\n\nBugfix:\n\n* Fixed memory issue introduced as a result of a bug in `asyncio.shield` and\n  not cancelling coroutine after usage. (see issue #444 and #436)\n\n\n0.4.2 (2018-09-12)\n^^^^^^^^^^^^^^^^^^\n\nBugfix:\n\n* Added error propagation from coordinator to main consumer. Before consumer\n  just stopped with error logged. (issue #294)\n* Fix manual partition assignment, broken in 0.4.0 (issue #394)\n* Fixed RecursionError in MessageAccumulator.add_message (issue #409)\n* Update kafka-python to latest 1.4.3 and added support for Python3.7\n* Dropped support for Python3.3 and Python3.4\n\nInfrastructure:\n\n* Added Kafka 1.0.2 broker for CI test runner\n* Refactored travis CI build pipeline\n\n0.4.1 (2018-05-13)\n^^^^^^^^^^^^^^^^^^\n\n* Fix issue when offset commit error reports wrong partition in log (issue #353)\n* Add ResourceWarning when Producer, Consumer or Connections are not closed\n  properly (issue #295)\n* Fix Subscription None in GroupCoordinator._do_group_rejoin (issue #306)\n\n\n0.4.0 (2018-01-30)\n^^^^^^^^^^^^^^^^^^\n\nMajor changes:\n\n* Full refactor of the internals of AIOKafkaConsumer. Needed to avoid several\n  race conditions in code (PR #286, fixes #258, #264 and #261)\n* Rewrote Records parsing protocol to allow implementation of newer protocol\n  versions later\n* Added C extension for Records parsing protocol, boosting the speed of\n  produce/consume routines significantly\n* Added an experimental batch producer API for unique cases, where user want's\n  to control batching himself (by @shargan)\n\n\nMinor changes:\n\n* Add `timestamp` field to produced message's metadata. This is needed to find\n  LOG_APPEND_TIME configured timestamps.\n* `Consumer.seek()` and similar API's now raise proper ``ValueError``'s on\n  validation failure instead of ``AssertionError``.\n\n\nBug fixes:\n\n* Fix ``connections_max_idle_ms`` option, as earlier it was only applied to\n  bootstrap socket. (PR #299)\n* Fix ``consumer.stop()`` side effect of logging an exception\n  ConsumerStoppedError (issue #263)\n* Problem with Producer not able to recover from broker failure (issue #267)\n* Traceback containing duplicate entries due to exception sharing (PR #247\n  by @Artimi)\n* Concurrent record consumption rasing `InvalidStateError('Exception is not\n  set.')` (PR #249 by @aerkert)\n* Don't fail ``GroupCoordinator._on_join_prepare()`` if ``commit_offset()``\n  throws exception (PR #230 by @shargan)\n* Send session_timeout_ms to GroupCoordinator constructor (PR #229 by @shargan)\n\nBig thanks to:\n\n* @shargan for Producer speed enhancements and the batch produce API\n  proposal/implementation.\n* @vineet-rh and other contributors for constant feedback on Consumer\n  problems, leading to the refactor mentioned above.\n\n\n0.3.1 (2017-09-19)\n^^^^^^^^^^^^^^^^^^\n\n* Added `AIOKafkaProducer.flush()` method. (PR #209 by @vineet-rh)\n* Fixed a bug with uvloop involving `float(\"inf\")` for timeout. (PR #210 by\n   dmitry-moroz)\n* Changed test runner to allow running tests on OSX. (PR #213 by @shargan)\n\n\n0.3.0 (2017-08-17)\n^^^^^^^^^^^^^^^^^^\n\n* Moved all public structures and errors to `aiokafka` namespace. You will no\n  longer need to import from `kafka` namespace.\n* Changed ConsumerRebalanceListener to support either function or coroutine\n  for `on_partitions_assigned` and `on_partitions_revoked` callbacks. (PR #190\n  by @ask)\n* Added support for `offsets_for_times`, `beginning_offsets`, `end_offsets`\n  API's. (issue #164)\n* Coordinator requests are now sent using a separate socket. Fixes slow commit\n  issue. (issuer #137, issue #128)\n* Added `seek_to_end`, `seek_to_beginning` API's. (issue #154)\n* Updated documentation to provide more useful usage guide on both Consumer and\n  Producer interface.\n\n0.2.3 (2017-07-23)\n^^^^^^^^^^^^^^^^^^\n\n* Fixed retry problem in Producer, when buffer is not reset to 0 offset.\n  Thanks to @ngavrysh for the fix in Tubular/aiokafka fork. (issue #184)\n* Fixed how Producer handles retries on Leader node failure. It just did not\n  work before... Thanks to @blugowski for the help in locating the problem.\n  (issue #176, issue #173)\n* Fixed degrade in v0.2.2 on Consumer with no group_id. (issue #166)\n\n\n0.2.2 (2017-04-17)\n^^^^^^^^^^^^^^^^^^\n\n* Reconnect after KafkaTimeoutException. (PR #149 by @Artimi)\n* Fixed compacted topic handling. It could skip messages if those were\n  compacted (issue #71)\n* Fixed old issue with new topics not adding to subscription on pattern\n  (issue #46)\n* Another fix for Consumer race condition on JoinGroup. This forces Leader to\n  wait for new metadata before assigning partitions. (issue #118)\n* Changed metadata listener in Coordinator to avoid 2 rejoins in a rare\n  condition (issue #108)\n* `getmany` will not return 0 results until we hit timeout. (issue #117)\n\nBig thanks to @Artimi for pointing out several of those issues.\n\n\n0.2.1 (2017-02-19)\n^^^^^^^^^^^^^^^^^^\n\n* Add a check to wait topic autocreation in Consumer, instead of raising\n  UnknownTopicOrPartitionError (PR #92 by fabregas)\n* Consumer now stops consumption after `consumer.stop()` call. Any new `get*` calls\n  will result in ConsumerStoppedError (PR #81)\n* Added `exclude_internal_topics` option for Consumer (PR #111)\n* Better support for pattern subscription when used with `group_id` (part of PR #111)\n* Fix for Consumer `subscribe` and JoinGroup race condition (issue #88). Coordinator will now notice subscription changes during rebalance and will join group again. (PR #106)\n* Changed logging messages according to KAFKA-3318. Now INFO level should be less messy and more informative. (PR #110)\n* Add support for connections_max_idle_ms config (PR #113)\n\n\n0.2.0 (2016-12-18)\n^^^^^^^^^^^^^^^^^^\n\n* Added SSL support. (PR #81 by Drizzt1991)\n* Fixed UnknownTopicOrPartitionError error on first message for autocreated topic (PR #96 by fabregas)\n* Fixed `next_record` recursion (PR #94 by fabregas)\n* Fixed Heartbeat fail if no consumers (PR #92 by fabregas)\n* Added docs addressing kafka-python and aiokafka differences (PR #70 by Drizzt1991)\n* Added `max_poll_records` option for Consumer (PR #72 by Drizzt1991)\n* Fix kafka-python typos in docs (PR #69 by jeffwidman)\n* Topics and partitions are now randomized on each Fetch request (PR #66 by Drizzt1991)\n\n\n0.1.4 (2016-11-07)\n^^^^^^^^^^^^^^^^^^\n\n* Bumped kafka-python version to 1.3.1 and Kafka to 0.10.1.0.\n* Fixed auto version detection, to correctly handle 0.10.0.0 version\n* Updated Fetch and Produce requests to use v2 with v0.10.0 message format on brokers.\n  This allows a ``timestamp`` to be associated with messages.\n* Changed lz4 compression framing, as it was changed due to KIP-57 in new message format.\n* Minor refactorings\n\nBig thanks to @fabregas for the hard work on this release (PR #60)\n\n\n0.1.3 (2016-10-18)\n^^^^^^^^^^^^^^^^^^\n\n* Fixed bug with infinite loop on heartbeats with autocommit=True. #44\n* Bumped kafka-python to version 1.1.1\n* Fixed docker test runner with multiple interfaces\n* Minor documentation fixes\n\n\n0.1.2 (2016-04-30)\n^^^^^^^^^^^^^^^^^^\n\n* Added Python3.5 usage example to docs\n* Don't raise retriable exceptions in 3.5's async for iterator\n* Fix Cancellation issue with producer's `send_and_wait` method\n\n\n0.1.1 (2016-04-15)\n^^^^^^^^^^^^^^^^^^\n\n* Fix packaging issues. Removed unneded files from package.\n\n0.1.0 (2016-04-15)\n^^^^^^^^^^^^^^^^^^\n\nInitial release\n\nAdded full support for Kafka 9.0. Older Kafka versions are not tested.", "description_content_type": "", "docs_url": null, "download_url": "https://pypi.python.org/pypi/aiokafka", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://aiokafka.readthedocs.org", "keywords": "", "license": "Apache 2", "maintainer": "", "maintainer_email": "", "name": "aiokafka", "package_url": "https://pypi.org/project/aiokafka/", "platform": "POSIX", "project_url": "https://pypi.org/project/aiokafka/", "project_urls": {"Download": "https://pypi.python.org/pypi/aiokafka", "Homepage": "http://aiokafka.readthedocs.org"}, "release_url": "https://pypi.org/project/aiokafka/0.5.2/", "requires_dist": null, "requires_python": "", "summary": "Kafka integration with asyncio.", "version": "0.5.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://travis-ci.com/aio-libs/aiokafka\" rel=\"nofollow\"><img alt=\"|Build status|\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/edaba46c719d57ae3351705d35d6b336903ec8dc/68747470733a2f2f7472617669732d63692e636f6d2f61696f2d6c6962732f61696f6b61666b612e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://codecov.io/gh/aio-libs/aiokafka/branch/master\" rel=\"nofollow\"><img alt=\"|Coverage|\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/08ef60e8c4cff0becb7255d6a836a87f2e6041cd/68747470733a2f2f636f6465636f762e696f2f6769746875622f61696f2d6c6962732f61696f6b61666b612f636f7665726167652e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://gitter.im/aio-libs/Lobby\" rel=\"nofollow\"><img alt=\"|Chat on Gitter|\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/454be82554a06af0fd3393415ef17b59d8550498/68747470733a2f2f6261646765732e6769747465722e696d2f4a6f696e253230436861742e737667\"></a>\n<p>asyncio client for Kafka</p>\n<div id=\"aiokafkaproducer\">\n<h2>AIOKafkaProducer</h2>\n<p>AIOKafkaProducer is a high-level, asynchronous message producer.</p>\n<p>Example of AIOKafkaProducer usage:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">aiokafka</span> <span class=\"kn\">import</span> <span class=\"n\">AIOKafkaProducer</span>\n<span class=\"kn\">import</span> <span class=\"nn\">asyncio</span>\n\n<span class=\"n\">loop</span> <span class=\"o\">=</span> <span class=\"n\">asyncio</span><span class=\"o\">.</span><span class=\"n\">get_event_loop</span><span class=\"p\">()</span>\n\n<span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">send_one</span><span class=\"p\">():</span>\n    <span class=\"n\">producer</span> <span class=\"o\">=</span> <span class=\"n\">AIOKafkaProducer</span><span class=\"p\">(</span>\n        <span class=\"n\">loop</span><span class=\"o\">=</span><span class=\"n\">loop</span><span class=\"p\">,</span> <span class=\"n\">bootstrap_servers</span><span class=\"o\">=</span><span class=\"s1\">'localhost:9092'</span><span class=\"p\">)</span>\n    <span class=\"c1\"># Get cluster layout and initial topic/partition leadership information</span>\n    <span class=\"k\">await</span> <span class=\"n\">producer</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">()</span>\n    <span class=\"k\">try</span><span class=\"p\">:</span>\n        <span class=\"c1\"># Produce message</span>\n        <span class=\"k\">await</span> <span class=\"n\">producer</span><span class=\"o\">.</span><span class=\"n\">send_and_wait</span><span class=\"p\">(</span><span class=\"s2\">\"my_topic\"</span><span class=\"p\">,</span> <span class=\"sa\">b</span><span class=\"s2\">\"Super message\"</span><span class=\"p\">)</span>\n    <span class=\"k\">finally</span><span class=\"p\">:</span>\n        <span class=\"c1\"># Wait for all pending messages to be delivered or expire.</span>\n        <span class=\"k\">await</span> <span class=\"n\">producer</span><span class=\"o\">.</span><span class=\"n\">stop</span><span class=\"p\">()</span>\n\n<span class=\"n\">loop</span><span class=\"o\">.</span><span class=\"n\">run_until_complete</span><span class=\"p\">(</span><span class=\"n\">send_one</span><span class=\"p\">())</span>\n</pre>\n</div>\n<div id=\"aiokafkaconsumer\">\n<h2>AIOKafkaConsumer</h2>\n<p>AIOKafkaConsumer is a high-level, asynchronous message consumer.\nIt interacts with the assigned Kafka Group Coordinator node to allow multiple\nconsumers to load balance consumption of topics (requires kafka &gt;= 0.9.0.0).</p>\n<p>Example of AIOKafkaConsumer usage:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">aiokafka</span> <span class=\"kn\">import</span> <span class=\"n\">AIOKafkaConsumer</span>\n<span class=\"kn\">import</span> <span class=\"nn\">asyncio</span>\n\n<span class=\"n\">loop</span> <span class=\"o\">=</span> <span class=\"n\">asyncio</span><span class=\"o\">.</span><span class=\"n\">get_event_loop</span><span class=\"p\">()</span>\n\n<span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">consume</span><span class=\"p\">():</span>\n    <span class=\"n\">consumer</span> <span class=\"o\">=</span> <span class=\"n\">AIOKafkaConsumer</span><span class=\"p\">(</span>\n        <span class=\"s1\">'my_topic'</span><span class=\"p\">,</span> <span class=\"s1\">'my_other_topic'</span><span class=\"p\">,</span>\n        <span class=\"n\">loop</span><span class=\"o\">=</span><span class=\"n\">loop</span><span class=\"p\">,</span> <span class=\"n\">bootstrap_servers</span><span class=\"o\">=</span><span class=\"s1\">'localhost:9092'</span><span class=\"p\">,</span>\n        <span class=\"n\">group_id</span><span class=\"o\">=</span><span class=\"s2\">\"my-group\"</span><span class=\"p\">)</span>\n    <span class=\"c1\"># Get cluster layout and join group `my-group`</span>\n    <span class=\"k\">await</span> <span class=\"n\">consumer</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">()</span>\n    <span class=\"k\">try</span><span class=\"p\">:</span>\n        <span class=\"c1\"># Consume messages</span>\n        <span class=\"k\">async</span> <span class=\"k\">for</span> <span class=\"n\">msg</span> <span class=\"ow\">in</span> <span class=\"n\">consumer</span><span class=\"p\">:</span>\n            <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"consumed: \"</span><span class=\"p\">,</span> <span class=\"n\">msg</span><span class=\"o\">.</span><span class=\"n\">topic</span><span class=\"p\">,</span> <span class=\"n\">msg</span><span class=\"o\">.</span><span class=\"n\">partition</span><span class=\"p\">,</span> <span class=\"n\">msg</span><span class=\"o\">.</span><span class=\"n\">offset</span><span class=\"p\">,</span>\n                  <span class=\"n\">msg</span><span class=\"o\">.</span><span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">msg</span><span class=\"o\">.</span><span class=\"n\">value</span><span class=\"p\">,</span> <span class=\"n\">msg</span><span class=\"o\">.</span><span class=\"n\">timestamp</span><span class=\"p\">)</span>\n    <span class=\"k\">finally</span><span class=\"p\">:</span>\n        <span class=\"c1\"># Will leave consumer group; perform autocommit if enabled.</span>\n        <span class=\"k\">await</span> <span class=\"n\">consumer</span><span class=\"o\">.</span><span class=\"n\">stop</span><span class=\"p\">()</span>\n\n<span class=\"n\">loop</span><span class=\"o\">.</span><span class=\"n\">run_until_complete</span><span class=\"p\">(</span><span class=\"n\">consume</span><span class=\"p\">())</span>\n</pre>\n<div id=\"running-tests\">\n<h3>Running tests</h3>\n<p>Docker is required to run tests. See <a href=\"https://docs.docker.com/engine/installation\" rel=\"nofollow\">https://docs.docker.com/engine/installation</a> for installation notes. Also note, that <cite>lz4</cite> compression libraries for python will require <cite>python-dev</cite> package,\nor python source header files for compilation on Linux.\nNOTE: You will also need a valid java installation. It\u2019s required for the <tt>keytool</tt> utility, used to\ngenerate ssh keys for some tests.</p>\n<p>Setting up tests requirements (assuming you\u2019re within virtualenv on ubuntu 14.04+):</p>\n<pre>sudo apt-get install -y libsnappy-dev\nmake setup\n</pre>\n<p>Running tests with coverage:</p>\n<pre>make cov\n</pre>\n<p>To run tests with a specific version of Kafka (default one is 1.0.2) use KAFKA_VERSION variable:</p>\n<pre>make cov KAFKA_VERSION=0.10.2.1\n</pre>\n<p>Test running cheatsheat:</p>\n<blockquote>\n<ul>\n<li><tt>make test <span class=\"pre\">FLAGS=\"-l</span> <span class=\"pre\">-x</span> <span class=\"pre\">--ff\"</span></tt> - run until 1 failure, rerun failed tests fitst. Great for cleaning up a lot of errors, say after a big refactor.</li>\n<li><tt>make test <span class=\"pre\">FLAGS=\"-k</span> consumer\"</tt> - run only the consumer tests.</li>\n<li><tt>make test <span class=\"pre\">FLAGS=\"-m</span> 'not ssl'\"</tt> - run tests excluding ssl.</li>\n<li><tt>make test <span class=\"pre\">FLAGS=\"--no-pull\"</span></tt> - do not try to pull new docker image before test run.</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"changes\">\n<h3>CHANGES</h3>\n<div id=\"id1\">\n<h4>0.5.2 (2019-03-10)</h4>\n<p>Bugfixes:</p>\n<ul>\n<li>Fix ConnectionError breaking metadata sync background task (issue #517 and #512)</li>\n<li>Fix event_waiter reference before assignment (pr #504 by @romantolkachyov)</li>\n<li>Bump version of kafka-python</li>\n</ul>\n</div>\n<div id=\"id2\">\n<h4>0.5.1 (2019-03-10)</h4>\n<p>New features:</p>\n<ul>\n<li>Add SASL support with both SASL plain and SASL GGSAPI. Support also includes\nBroker v0.9.0, but you will need to explicitly pass <tt><span class=\"pre\">api_version=\"0.9\"</span></tt>.\n(Big thanks to @cyrbil and @jsurloppe for working on this)</li>\n<li>Added support for max_poll_interval_ms and rebalance_timeout_ms settings (\nissue #67)</li>\n<li>Added pause/resume API for AIOKafkaConsumer. (issue #304)</li>\n<li>Added header support to both AIOKafkaConsumer and AIOKafkaProducer for\nbrokers v0.11 and above. (issue #462)</li>\n</ul>\n<p>Bugfixes:</p>\n<ul>\n<li>Made sure to not request metadata for all topics if broker version is passed\nexplicitly and is 0.10 and above. (issue #440, thanks to @ulrikjohansson)</li>\n<li>Make sure heartbeat task will close if group is reset. (issue #372)</li>\n</ul>\n</div>\n<div id=\"id3\">\n<h4>0.5.0 (2018-12-28)</h4>\n<p>New features:</p>\n<ul>\n<li>Add full support for V2 format messages with a Cython extension. Those are\nused for Kafka &gt;= 0.11.0.0</li>\n<li>Added support for transactional producing (issue #182)</li>\n<li>Added support for indempotent producing with <cite>enable_idempotence</cite> parameter</li>\n<li>Added support for <cite>fetch_max_bytes</cite> in AIOKafkaConsumer. This can help limit\nthe amount of data transferred in a single roundtrip to broker, which is\nessential for consumers with large amount of partitions</li>\n</ul>\n<p>Bugfixes:</p>\n<ul>\n<li>Fix issue with connections not propagating serialization errors</li>\n<li>Fix issue with <cite>group=None</cite> resetting offsets on every metadata update\n(issue #441)</li>\n<li>Fix issue with messages not delivered in order when Leader changes (issue\n#228)</li>\n<li>Fixed version parsing of <cite>api_version</cite> parameter. Before it ignored the\nparameter</li>\n</ul>\n</div>\n<div id=\"id4\">\n<h4>0.4.3 (2018-11-01)</h4>\n<p>Bugfix:</p>\n<ul>\n<li>Fixed memory issue introduced as a result of a bug in <cite>asyncio.shield</cite> and\nnot cancelling coroutine after usage. (see issue #444 and #436)</li>\n</ul>\n</div>\n<div id=\"id5\">\n<h4>0.4.2 (2018-09-12)</h4>\n<p>Bugfix:</p>\n<ul>\n<li>Added error propagation from coordinator to main consumer. Before consumer\njust stopped with error logged. (issue #294)</li>\n<li>Fix manual partition assignment, broken in 0.4.0 (issue #394)</li>\n<li>Fixed RecursionError in MessageAccumulator.add_message (issue #409)</li>\n<li>Update kafka-python to latest 1.4.3 and added support for Python3.7</li>\n<li>Dropped support for Python3.3 and Python3.4</li>\n</ul>\n<p>Infrastructure:</p>\n<ul>\n<li>Added Kafka 1.0.2 broker for CI test runner</li>\n<li>Refactored travis CI build pipeline</li>\n</ul>\n</div>\n<div id=\"id6\">\n<h4>0.4.1 (2018-05-13)</h4>\n<ul>\n<li>Fix issue when offset commit error reports wrong partition in log (issue #353)</li>\n<li>Add ResourceWarning when Producer, Consumer or Connections are not closed\nproperly (issue #295)</li>\n<li>Fix Subscription None in GroupCoordinator._do_group_rejoin (issue #306)</li>\n</ul>\n</div>\n<div id=\"id7\">\n<h4>0.4.0 (2018-01-30)</h4>\n<p>Major changes:</p>\n<ul>\n<li>Full refactor of the internals of AIOKafkaConsumer. Needed to avoid several\nrace conditions in code (PR #286, fixes #258, #264 and #261)</li>\n<li>Rewrote Records parsing protocol to allow implementation of newer protocol\nversions later</li>\n<li>Added C extension for Records parsing protocol, boosting the speed of\nproduce/consume routines significantly</li>\n<li>Added an experimental batch producer API for unique cases, where user want\u2019s\nto control batching himself (by @shargan)</li>\n</ul>\n<p>Minor changes:</p>\n<ul>\n<li>Add <cite>timestamp</cite> field to produced message\u2019s metadata. This is needed to find\nLOG_APPEND_TIME configured timestamps.</li>\n<li><cite>Consumer.seek()</cite> and similar API\u2019s now raise proper <tt>ValueError</tt>\u2019s on\nvalidation failure instead of <tt>AssertionError</tt>.</li>\n</ul>\n<p>Bug fixes:</p>\n<ul>\n<li>Fix <tt>connections_max_idle_ms</tt> option, as earlier it was only applied to\nbootstrap socket. (PR #299)</li>\n<li>Fix <tt>consumer.stop()</tt> side effect of logging an exception\nConsumerStoppedError (issue #263)</li>\n<li>Problem with Producer not able to recover from broker failure (issue #267)</li>\n<li>Traceback containing duplicate entries due to exception sharing (PR #247\nby @Artimi)</li>\n<li>Concurrent record consumption rasing <cite>InvalidStateError(\u2018Exception is not\nset.\u2019)</cite> (PR #249 by @aerkert)</li>\n<li>Don\u2019t fail <tt>GroupCoordinator._on_join_prepare()</tt> if <tt>commit_offset()</tt>\nthrows exception (PR #230 by @shargan)</li>\n<li>Send session_timeout_ms to GroupCoordinator constructor (PR #229 by @shargan)</li>\n</ul>\n<p>Big thanks to:</p>\n<ul>\n<li>@shargan for Producer speed enhancements and the batch produce API\nproposal/implementation.</li>\n<li>@vineet-rh and other contributors for constant feedback on Consumer\nproblems, leading to the refactor mentioned above.</li>\n</ul>\n</div>\n<div id=\"id8\">\n<h4>0.3.1 (2017-09-19)</h4>\n<ul>\n<li>Added <cite>AIOKafkaProducer.flush()</cite> method. (PR #209 by @vineet-rh)</li>\n<li><dl>\n<dt>Fixed a bug with uvloop involving <cite>float(\u201cinf\u201d)</cite> for timeout. (PR #210 by</dt>\n<dd>dmitry-moroz)</dd>\n</dl>\n</li>\n<li>Changed test runner to allow running tests on OSX. (PR #213 by @shargan)</li>\n</ul>\n</div>\n<div id=\"id9\">\n<h4>0.3.0 (2017-08-17)</h4>\n<ul>\n<li>Moved all public structures and errors to <cite>aiokafka</cite> namespace. You will no\nlonger need to import from <cite>kafka</cite> namespace.</li>\n<li>Changed ConsumerRebalanceListener to support either function or coroutine\nfor <cite>on_partitions_assigned</cite> and <cite>on_partitions_revoked</cite> callbacks. (PR #190\nby @ask)</li>\n<li>Added support for <cite>offsets_for_times</cite>, <cite>beginning_offsets</cite>, <cite>end_offsets</cite>\nAPI\u2019s. (issue #164)</li>\n<li>Coordinator requests are now sent using a separate socket. Fixes slow commit\nissue. (issuer #137, issue #128)</li>\n<li>Added <cite>seek_to_end</cite>, <cite>seek_to_beginning</cite> API\u2019s. (issue #154)</li>\n<li>Updated documentation to provide more useful usage guide on both Consumer and\nProducer interface.</li>\n</ul>\n</div>\n<div id=\"id10\">\n<h4>0.2.3 (2017-07-23)</h4>\n<ul>\n<li>Fixed retry problem in Producer, when buffer is not reset to 0 offset.\nThanks to @ngavrysh for the fix in Tubular/aiokafka fork. (issue #184)</li>\n<li>Fixed how Producer handles retries on Leader node failure. It just did not\nwork before\u2026 Thanks to @blugowski for the help in locating the problem.\n(issue #176, issue #173)</li>\n<li>Fixed degrade in v0.2.2 on Consumer with no group_id. (issue #166)</li>\n</ul>\n</div>\n<div id=\"id11\">\n<h4>0.2.2 (2017-04-17)</h4>\n<ul>\n<li>Reconnect after KafkaTimeoutException. (PR #149 by @Artimi)</li>\n<li>Fixed compacted topic handling. It could skip messages if those were\ncompacted (issue #71)</li>\n<li>Fixed old issue with new topics not adding to subscription on pattern\n(issue #46)</li>\n<li>Another fix for Consumer race condition on JoinGroup. This forces Leader to\nwait for new metadata before assigning partitions. (issue #118)</li>\n<li>Changed metadata listener in Coordinator to avoid 2 rejoins in a rare\ncondition (issue #108)</li>\n<li><cite>getmany</cite> will not return 0 results until we hit timeout. (issue #117)</li>\n</ul>\n<p>Big thanks to @Artimi for pointing out several of those issues.</p>\n</div>\n<div id=\"id12\">\n<h4>0.2.1 (2017-02-19)</h4>\n<ul>\n<li>Add a check to wait topic autocreation in Consumer, instead of raising\nUnknownTopicOrPartitionError (PR #92 by fabregas)</li>\n<li>Consumer now stops consumption after <cite>consumer.stop()</cite> call. Any new <cite>get*</cite> calls\nwill result in ConsumerStoppedError (PR #81)</li>\n<li>Added <cite>exclude_internal_topics</cite> option for Consumer (PR #111)</li>\n<li>Better support for pattern subscription when used with <cite>group_id</cite> (part of PR #111)</li>\n<li>Fix for Consumer <cite>subscribe</cite> and JoinGroup race condition (issue #88). Coordinator will now notice subscription changes during rebalance and will join group again. (PR #106)</li>\n<li>Changed logging messages according to KAFKA-3318. Now INFO level should be less messy and more informative. (PR #110)</li>\n<li>Add support for connections_max_idle_ms config (PR #113)</li>\n</ul>\n</div>\n<div id=\"id13\">\n<h4>0.2.0 (2016-12-18)</h4>\n<ul>\n<li>Added SSL support. (PR #81 by Drizzt1991)</li>\n<li>Fixed UnknownTopicOrPartitionError error on first message for autocreated topic (PR #96 by fabregas)</li>\n<li>Fixed <cite>next_record</cite> recursion (PR #94 by fabregas)</li>\n<li>Fixed Heartbeat fail if no consumers (PR #92 by fabregas)</li>\n<li>Added docs addressing kafka-python and aiokafka differences (PR #70 by Drizzt1991)</li>\n<li>Added <cite>max_poll_records</cite> option for Consumer (PR #72 by Drizzt1991)</li>\n<li>Fix kafka-python typos in docs (PR #69 by jeffwidman)</li>\n<li>Topics and partitions are now randomized on each Fetch request (PR #66 by Drizzt1991)</li>\n</ul>\n</div>\n<div id=\"id14\">\n<h4>0.1.4 (2016-11-07)</h4>\n<ul>\n<li>Bumped kafka-python version to 1.3.1 and Kafka to 0.10.1.0.</li>\n<li>Fixed auto version detection, to correctly handle 0.10.0.0 version</li>\n<li>Updated Fetch and Produce requests to use v2 with v0.10.0 message format on brokers.\nThis allows a <tt>timestamp</tt> to be associated with messages.</li>\n<li>Changed lz4 compression framing, as it was changed due to KIP-57 in new message format.</li>\n<li>Minor refactorings</li>\n</ul>\n<p>Big thanks to @fabregas for the hard work on this release (PR #60)</p>\n</div>\n<div id=\"id15\">\n<h4>0.1.3 (2016-10-18)</h4>\n<ul>\n<li>Fixed bug with infinite loop on heartbeats with autocommit=True. #44</li>\n<li>Bumped kafka-python to version 1.1.1</li>\n<li>Fixed docker test runner with multiple interfaces</li>\n<li>Minor documentation fixes</li>\n</ul>\n</div>\n<div id=\"id16\">\n<h4>0.1.2 (2016-04-30)</h4>\n<ul>\n<li>Added Python3.5 usage example to docs</li>\n<li>Don\u2019t raise retriable exceptions in 3.5\u2019s async for iterator</li>\n<li>Fix Cancellation issue with producer\u2019s <cite>send_and_wait</cite> method</li>\n</ul>\n</div>\n<div id=\"id17\">\n<h4>0.1.1 (2016-04-15)</h4>\n<ul>\n<li>Fix packaging issues. Removed unneded files from package.</li>\n</ul>\n</div>\n<div id=\"id18\">\n<h4>0.1.0 (2016-04-15)</h4>\n<p>Initial release</p>\n<p>Added full support for Kafka 9.0. Older Kafka versions are not tested.</p>\n</div>\n</div>\n</div>\n\n          </div>"}, "last_serial": 5438278, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "80f3d605a0b0617f347426f7032291f7", "sha256": "230bbb0fadddc523541d2963c92a32c832ccd48e3d563592135d1ea2d72444a5"}, "downloads": -1, "filename": "aiokafka-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "80f3d605a0b0617f347426f7032291f7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 57909, "upload_time": "2016-04-11T08:20:49", "upload_time_iso_8601": "2016-04-11T08:20:49.876822Z", "url": "https://files.pythonhosted.org/packages/64/5d/3e041d7b377d6cff0cc04e0cdacadee4a1c9856db0eb6441e627cf46bdbc/aiokafka-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f1d0ab28142fe1feb9aabe72cd6d700b", "sha256": "c5888b00598a496f2e052c21ad299685efbd33e233125ec59e8c053bbc3a6d78"}, "downloads": -1, "filename": "aiokafka-0.0.1.tar.gz", "has_sig": false, "md5_digest": "f1d0ab28142fe1feb9aabe72cd6d700b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 46520, "upload_time": "2016-04-11T08:09:41", "upload_time_iso_8601": "2016-04-11T08:09:41.864643Z", "url": "https://files.pythonhosted.org/packages/8c/06/2d3ca95bd673613dd16299540651609e5dadb30e2d7e55752de60a44daba/aiokafka-0.0.1.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "9c4f9ee607a7421c743fb532cc76835e", "sha256": "3cc67687e7cc5a58db2eecfe5cf198e4546a24008358cd1e914791874c4f26c0"}, "downloads": -1, "filename": "aiokafka-0.1.0.tar.gz", "has_sig": false, "md5_digest": "9c4f9ee607a7421c743fb532cc76835e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 46970, "upload_time": "2016-04-15T10:18:30", "upload_time_iso_8601": "2016-04-15T10:18:30.227047Z", "url": "https://files.pythonhosted.org/packages/0c/de/2055b80402c1c87dc0d3aa015a13047800b9d0a132e32d0e9ed63f251c9e/aiokafka-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "3e54f2e06503d802d9a0ae500c11c433", "sha256": "1b3f758a3dbedcbfa4a3b72e34923367776e3478a2d25f4a8c8465dd69417e14"}, "downloads": -1, "filename": "aiokafka-0.1.1.tar.gz", "has_sig": false, "md5_digest": "3e54f2e06503d802d9a0ae500c11c433", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 39359, "upload_time": "2016-04-15T14:34:07", "upload_time_iso_8601": "2016-04-15T14:34:07.410009Z", "url": "https://files.pythonhosted.org/packages/88/17/c1233e5ae3b62aa33c61e5664e7d3dbd9bfcb94e452fcbff0549f9ace2d6/aiokafka-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "bb61352a635b39ae984857f65e468ad3", "sha256": "8f9c544d85be2a83bb8f2b52b93cf133778eea667e0cf25f6074b0a344e2f7d8"}, "downloads": -1, "filename": "aiokafka-0.1.2.tar.gz", "has_sig": false, "md5_digest": "bb61352a635b39ae984857f65e468ad3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 39648, "upload_time": "2016-04-30T12:31:03", "upload_time_iso_8601": "2016-04-30T12:31:03.360291Z", "url": "https://files.pythonhosted.org/packages/fc/35/bed3eb04190421a9398dc7946a0077b1600e6e569045d96e6ffe39909630/aiokafka-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "024aca96d001c900aff179d663790ef6", "sha256": "a808ddde63006e61434e8efe1c58118d07d09b9e2cdfbc37c33c3ba1da3a3b00"}, "downloads": -1, "filename": "aiokafka-0.1.3.tar.gz", "has_sig": false, "md5_digest": "024aca96d001c900aff179d663790ef6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 38692, "upload_time": "2016-10-18T08:33:17", "upload_time_iso_8601": "2016-10-18T08:33:17.938259Z", "url": "https://files.pythonhosted.org/packages/93/bf/4c506c366a24885ace91408835e879652d6f4a2a73277eb148ef62278e7b/aiokafka-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "f42f48b45c0a49924092dbb37ee6e6e4", "sha256": "4879e08b3e05294b09b9e05028f38d9c7c5c574dd9b6bce0d29060de6c5f306e"}, "downloads": -1, "filename": "aiokafka-0.1.4.tar.gz", "has_sig": false, "md5_digest": "f42f48b45c0a49924092dbb37ee6e6e4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 40514, "upload_time": "2016-11-07T13:12:12", "upload_time_iso_8601": "2016-11-07T13:12:12.991452Z", "url": "https://files.pythonhosted.org/packages/4d/f7/12824981ecb2f301f6a9f24365c249f850d9e9b7e007cab9ce450f637e97/aiokafka-0.1.4.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "9f792e8f2a6cac436346ddfe973dceb8", "sha256": "7e1b8727f398b28a780451c4a9ace4a98c37dd5dc285a6fcdbdfa0bbf13f2501"}, "downloads": -1, "filename": "aiokafka-0.2.0.tar.gz", "has_sig": false, "md5_digest": "9f792e8f2a6cac436346ddfe973dceb8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 45705, "upload_time": "2016-12-18T21:31:55", "upload_time_iso_8601": "2016-12-18T21:31:55.401310Z", "url": "https://files.pythonhosted.org/packages/d4/ff/f440264776a1dc0d869d66197a0b74903206880c1c5d32c99ae5c9f9a337/aiokafka-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "7e15deafe2749db59a9b4759ae13351c", "sha256": "cc08465318b3f763410c0f11635cafc4fcc45466c58a33c04bcc758be0c2be7f"}, "downloads": -1, "filename": "aiokafka-0.2.1.tar.gz", "has_sig": false, "md5_digest": "7e15deafe2749db59a9b4759ae13351c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 48734, "upload_time": "2017-02-19T13:09:22", "upload_time_iso_8601": "2017-02-19T13:09:22.247805Z", "url": "https://files.pythonhosted.org/packages/00/4e/3e8921560e1eb2297f383b0b8a58997f02e9f904e84a8cd0eda58b05068b/aiokafka-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "6d0fc0cc4cfd690c575442ded1746118", "sha256": "56727a44e6fec3eb47ebb6d8b0e6a05bc051ea9d20360e032797b28a2060f864"}, "downloads": -1, "filename": "aiokafka-0.2.2.tar.gz", "has_sig": false, "md5_digest": "6d0fc0cc4cfd690c575442ded1746118", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 50810, "upload_time": "2017-04-17T12:29:50", "upload_time_iso_8601": "2017-04-17T12:29:50.891980Z", "url": "https://files.pythonhosted.org/packages/08/db/d91f707c47ff658a7922f734c8b52b765e01e98bac152051664673243cd8/aiokafka-0.2.2.tar.gz", "yanked": false}], "0.2.3": [{"comment_text": "", "digests": {"md5": "9964f4bab11a467c25fbf49f3e0cbe84", "sha256": "bb524778266e1d22b94ab280bd1d5946daa3e392226198f53a8a1be503279065"}, "downloads": -1, "filename": "aiokafka-0.2.3.tar.gz", "has_sig": false, "md5_digest": "9964f4bab11a467c25fbf49f3e0cbe84", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 49647, "upload_time": "2017-07-23T10:50:06", "upload_time_iso_8601": "2017-07-23T10:50:06.777318Z", "url": "https://files.pythonhosted.org/packages/cc/5a/8acbb0d63d87f9c807052435807bfac5501cb430b06dfa834bc3d0a6dd44/aiokafka-0.2.3.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "bac9bb721b3028f635ffa5c41c8aad8f", "sha256": "23ed2ea180a302012aa26accc7b10ea7d37545a2e84dd6b5da39addba0273f59"}, "downloads": -1, "filename": "aiokafka-0.3.0.tar.gz", "has_sig": false, "md5_digest": "bac9bb721b3028f635ffa5c41c8aad8f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 55675, "upload_time": "2017-08-17T12:14:22", "upload_time_iso_8601": "2017-08-17T12:14:22.962666Z", "url": "https://files.pythonhosted.org/packages/3d/29/8bf00a5dedf52842527cee9b3a0673fc52c76b29aa8010b8cefb3eb635b3/aiokafka-0.3.0.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "1af4c873949bb0a928ff96c5d050dca9", "sha256": "e792e6f32387bc8eb0ee54cbd0b89cb3e2366466c6d81a245b3a52094428b9a8"}, "downloads": -1, "filename": "aiokafka-0.3.1.tar.gz", "has_sig": false, "md5_digest": "1af4c873949bb0a928ff96c5d050dca9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 55855, "upload_time": "2017-09-19T10:06:38", "upload_time_iso_8601": "2017-09-19T10:06:38.459980Z", "url": "https://files.pythonhosted.org/packages/62/f4/06840fbada955e92d38b8627e75a9cf41504e208658be8650ac088491edf/aiokafka-0.3.1.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "a9f0d72327737d494dc3a2e31c4e8b4e", "sha256": "18bd12fe0dfb364508bcc8e9dc60bbf10999e77e824d05189093229c2cb77f8b"}, "downloads": -1, "filename": "aiokafka-0.4.0.tar.gz", "has_sig": false, "md5_digest": "a9f0d72327737d494dc3a2e31c4e8b4e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 184226, "upload_time": "2018-01-30T16:49:52", "upload_time_iso_8601": "2018-01-30T16:49:52.114181Z", "url": "https://files.pythonhosted.org/packages/bc/45/3cb8d3baa158b7db67357ff9b96248c9f85b86db73f5fad382a9f432707f/aiokafka-0.4.0.tar.gz", "yanked": false}], "0.4.1": [{"comment_text": "", "digests": {"md5": "443e0b5023e25669a4b7ff616dc20190", "sha256": "275eecd923bfbd455cc02695693eb43fcda0fed8f2e27d027b67c3d24e4bde17"}, "downloads": -1, "filename": "aiokafka-0.4.1.tar.gz", "has_sig": false, "md5_digest": "443e0b5023e25669a4b7ff616dc20190", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 189080, "upload_time": "2018-09-02T16:02:09", "upload_time_iso_8601": "2018-09-02T16:02:09.562803Z", "url": "https://files.pythonhosted.org/packages/8f/fc/9a7ac686538ca7862fd2317db05d937f2ae3dffd8c3a26aab127cfa54398/aiokafka-0.4.1.tar.gz", "yanked": false}], "0.4.2": [{"comment_text": "", "digests": {"md5": "0abd0d320ba72ee231b01a57cafea4df", "sha256": "6a6838c13f0c64d7d5e18449a2c35f774f3612cb7733429a5e812be3da8ca30e"}, "downloads": -1, "filename": "aiokafka-0.4.2.tar.gz", "has_sig": false, "md5_digest": "0abd0d320ba72ee231b01a57cafea4df", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 194879, "upload_time": "2018-09-12T08:23:31", "upload_time_iso_8601": "2018-09-12T08:23:31.880169Z", "url": "https://files.pythonhosted.org/packages/6a/84/0bc155ac432b2547b2f33e0037c8d8e873c6785a72e9284f4dbff1c2b9d0/aiokafka-0.4.2.tar.gz", "yanked": false}], "0.4.2.dev0": [{"comment_text": "", "digests": {"md5": "8a6c61bfd4c375204d49051419dec7df", "sha256": "568b4d53a2832026666facc0377d1e30dd1c4c48cf0bc025db67dfd9aca6a79d"}, "downloads": -1, "filename": "aiokafka-0.4.2.dev0.tar.gz", "has_sig": false, "md5_digest": "8a6c61bfd4c375204d49051419dec7df", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 188857, "upload_time": "2018-06-09T12:52:28", "upload_time_iso_8601": "2018-06-09T12:52:28.266754Z", "url": "https://files.pythonhosted.org/packages/31/b1/afcc3ae5de8e5e1e6a55680931ec313dd59d899aafb43d8cb29facdc38a3/aiokafka-0.4.2.dev0.tar.gz", "yanked": false}], "0.4.3": [{"comment_text": "", "digests": {"md5": "062df6c48e9fafaa8c38b0c00261b492", "sha256": "b07faae06647d9bc39d8b0510441838d176edf4074e981a15bbd987bb4a8d363"}, "downloads": -1, "filename": "aiokafka-0.4.3.tar.gz", "has_sig": false, "md5_digest": "062df6c48e9fafaa8c38b0c00261b492", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 189523, "upload_time": "2018-11-01T22:17:15", "upload_time_iso_8601": "2018-11-01T22:17:15.647124Z", "url": "https://files.pythonhosted.org/packages/59/80/8a05a305592a35eac9d1a62af002556f0bf18972e60980410ed5c6fe452b/aiokafka-0.4.3.tar.gz", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "833885f2535216cbb8968ea6c27a6c1e", "sha256": "d076650bfe0c8de04bec67514d984450ce9b23ca3d5e9f2954bc98cf8e07fa13"}, "downloads": -1, "filename": "aiokafka-0.5.0.tar.gz", "has_sig": false, "md5_digest": "833885f2535216cbb8968ea6c27a6c1e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 344315, "upload_time": "2018-12-28T07:47:04", "upload_time_iso_8601": "2018-12-28T07:47:04.900646Z", "url": "https://files.pythonhosted.org/packages/79/5b/267bb93a3b5182c62b9dca0cef6c9d696d8c91357b8764e9e2f158436b29/aiokafka-0.5.0.tar.gz", "yanked": false}], "0.5.1": [{"comment_text": "", "digests": {"md5": "6ff08b937c728bd0c324dd0aec4b4a07", "sha256": "25b31f9759427fb9334de5a6224df5ac92247d8af9c13eebf8afddd48a5c05b8"}, "downloads": -1, "filename": "aiokafka-0.5.1.tar.gz", "has_sig": false, "md5_digest": "6ff08b937c728bd0c324dd0aec4b4a07", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 352661, "upload_time": "2019-03-10T12:46:41", "upload_time_iso_8601": "2019-03-10T12:46:41.797187Z", "url": "https://files.pythonhosted.org/packages/0b/26/ecac8e7b05e236c54e91c5fbc6b6af04101cf3cc7135318c85594a1b2fbb/aiokafka-0.5.1.tar.gz", "yanked": false}], "0.5.2": [{"comment_text": "", "digests": {"md5": "ebf4f65a715c7825b969ee216782c562", "sha256": "b11e2284b09cdc59f78b830b5b0344707a673d36a7eb3b7824e537773df30ab4"}, "downloads": -1, "filename": "aiokafka-0.5.2.tar.gz", "has_sig": false, "md5_digest": "ebf4f65a715c7825b969ee216782c562", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 352959, "upload_time": "2019-06-23T21:19:51", "upload_time_iso_8601": "2019-06-23T21:19:51.564021Z", "url": "https://files.pythonhosted.org/packages/f3/0f/1cf852cc1945a919e2dff22aa3c9f4d3be26c216ad0104fb3602e428f099/aiokafka-0.5.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ebf4f65a715c7825b969ee216782c562", "sha256": "b11e2284b09cdc59f78b830b5b0344707a673d36a7eb3b7824e537773df30ab4"}, "downloads": -1, "filename": "aiokafka-0.5.2.tar.gz", "has_sig": false, "md5_digest": "ebf4f65a715c7825b969ee216782c562", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 352959, "upload_time": "2019-06-23T21:19:51", "upload_time_iso_8601": "2019-06-23T21:19:51.564021Z", "url": "https://files.pythonhosted.org/packages/f3/0f/1cf852cc1945a919e2dff22aa3c9f4d3be26c216ad0104fb3602e428f099/aiokafka-0.5.2.tar.gz", "yanked": false}], "timestamp": "Thu May  7 16:21:09 2020"}