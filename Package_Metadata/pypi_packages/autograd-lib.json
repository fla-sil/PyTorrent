{"info": {"author": "Yaroslav Bulatov, Kazuki Osawa", "author_email": "yaroslavvb@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# autograd_lib\n\nBy Yaroslav Bulatov, Kazuki Osawa\n\nLibrary to simplify gradient computations in PyTorch.\n\n# example 1: per-example gradient norms\n\nExample of using it to compute per-example gradient norms for linear layers, using trick from https://arxiv.org/abs/1510.01799\n\nSee `example_norms.py` for a runnable example. The important parts:\n\n\n```\n!pip install autograd-lib\n\nfrom autograd_lib import autograd_lib\n\nloss_fn = ...\ndata = ...\nmodel = ...\nautograd_lib.register(model)\n\n\nactivations = {}\n\ndef save_activations(layer, A, _):\n    activations[layer] = A\n\nwith autograd_lib.module_hook(save_activations):\n    output = model(data)\n    loss = loss_fn(output)\n\nnorms = [torch.zeros(n)]\n\ndef per_example_norms(layer, _, B):\n    A = activations[layer]\n    norms[0]+=(A*A).sum(dim=1)*(B*B).sum(dim=1)\n\nwith autograd_lib.module_hook(per_example_norms):\n    loss.backward()\n\nprint('per-example gradient norms squared:', norms[0])\n\n```\n\n# Example 2: Hessian quantities\n\nTo compute exact Hessian, Hessian diagonal and KFAC approximation for all linear layers of a ReLU network in a single pass.\n\nSee `example_hessian.py` for a self-contained example. The important parts:\n\n\n```\n!pip install autograd-lib\n\nautograd_lib.register(model)\n\nhess = defaultdict(float)\nhess_diag = defaultdict(float)\nhess_kfac = defaultdict(lambda: AttrDefault(float))\n\nactivations = {}\ndef save_activations(layer, A, _):\n    activations[layer] = A\n\n    # KFAC left factor\n    hess_kfac[layer].AA += torch.einsum(\"ni,nj->ij\", A, A)\n\nwith autograd_lib.module_hook(save_activations):\n    output = model(data)\n    loss = loss_fn(output, targets)\n\ndef compute_hess(layer, _, B):\n    A = activations[layer]\n    BA = torch.einsum(\"nl,ni->nli\", B, A)\n\n    # full Hessian\n    hess[layer] += torch.einsum('nli,nkj->likj', BA, BA)\n\n    # Hessian diagonal\n    hess_diag[layer] += torch.einsum(\"ni,nj->ij\", B * B, A * A)\n\n    # KFAC right factor\n    hess_kfac[layer].BB += torch.einsum(\"ni,nj->ij\", B, B)\n\n\nwith autograd_lib.module_hook(compute_hess):\n    autograd_lib.backward_hessian(output, loss='CrossEntropy')\n```\n\nVariations:\n\n- `autograd_lib.backward_hessian` for Hessian\n- `autograd_lib.backward_jacobian` for Jacobian squared\n- `loss.backward()` for empirical Fisher Information Matrix\n\n\nSee autograd_lib_test.py for correctness checks against PyTorch autograd.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/cybertronai/autograd-lib", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "autograd-lib", "package_url": "https://pypi.org/project/autograd-lib/", "platform": "", "project_url": "https://pypi.org/project/autograd-lib/", "project_urls": {"Homepage": "https://github.com/cybertronai/autograd-lib"}, "release_url": "https://pypi.org/project/autograd-lib/0.0.7/", "requires_dist": ["gin-config", "seaborn", "pytorch-lightning"], "requires_python": ">= 3.6", "summary": "Library to simplify autograd computations in PyTorch", "version": "0.0.7", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>autograd_lib</h1>\n<p>By Yaroslav Bulatov, Kazuki Osawa</p>\n<p>Library to simplify gradient computations in PyTorch.</p>\n<h1>example 1: per-example gradient norms</h1>\n<p>Example of using it to compute per-example gradient norms for linear layers, using trick from <a href=\"https://arxiv.org/abs/1510.01799\" rel=\"nofollow\">https://arxiv.org/abs/1510.01799</a></p>\n<p>See <code>example_norms.py</code> for a runnable example. The important parts:</p>\n<pre><code>!pip install autograd-lib\n\nfrom autograd_lib import autograd_lib\n\nloss_fn = ...\ndata = ...\nmodel = ...\nautograd_lib.register(model)\n\n\nactivations = {}\n\ndef save_activations(layer, A, _):\n    activations[layer] = A\n\nwith autograd_lib.module_hook(save_activations):\n    output = model(data)\n    loss = loss_fn(output)\n\nnorms = [torch.zeros(n)]\n\ndef per_example_norms(layer, _, B):\n    A = activations[layer]\n    norms[0]+=(A*A).sum(dim=1)*(B*B).sum(dim=1)\n\nwith autograd_lib.module_hook(per_example_norms):\n    loss.backward()\n\nprint('per-example gradient norms squared:', norms[0])\n\n</code></pre>\n<h1>Example 2: Hessian quantities</h1>\n<p>To compute exact Hessian, Hessian diagonal and KFAC approximation for all linear layers of a ReLU network in a single pass.</p>\n<p>See <code>example_hessian.py</code> for a self-contained example. The important parts:</p>\n<pre><code>!pip install autograd-lib\n\nautograd_lib.register(model)\n\nhess = defaultdict(float)\nhess_diag = defaultdict(float)\nhess_kfac = defaultdict(lambda: AttrDefault(float))\n\nactivations = {}\ndef save_activations(layer, A, _):\n    activations[layer] = A\n\n    # KFAC left factor\n    hess_kfac[layer].AA += torch.einsum(\"ni,nj-&gt;ij\", A, A)\n\nwith autograd_lib.module_hook(save_activations):\n    output = model(data)\n    loss = loss_fn(output, targets)\n\ndef compute_hess(layer, _, B):\n    A = activations[layer]\n    BA = torch.einsum(\"nl,ni-&gt;nli\", B, A)\n\n    # full Hessian\n    hess[layer] += torch.einsum('nli,nkj-&gt;likj', BA, BA)\n\n    # Hessian diagonal\n    hess_diag[layer] += torch.einsum(\"ni,nj-&gt;ij\", B * B, A * A)\n\n    # KFAC right factor\n    hess_kfac[layer].BB += torch.einsum(\"ni,nj-&gt;ij\", B, B)\n\n\nwith autograd_lib.module_hook(compute_hess):\n    autograd_lib.backward_hessian(output, loss='CrossEntropy')\n</code></pre>\n<p>Variations:</p>\n<ul>\n<li><code>autograd_lib.backward_hessian</code> for Hessian</li>\n<li><code>autograd_lib.backward_jacobian</code> for Jacobian squared</li>\n<li><code>loss.backward()</code> for empirical Fisher Information Matrix</li>\n</ul>\n<p>See autograd_lib_test.py for correctness checks against PyTorch autograd.</p>\n\n          </div>"}, "last_serial": 6400247, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "aa6161979f498aec95d77af5ca4409bc", "sha256": "ca157bcdd809ac8051e8b3dba33e6bf534c19f6ec10e5d7e39e06a5fe9769af9"}, "downloads": -1, "filename": "autograd_lib-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "aa6161979f498aec95d77af5ca4409bc", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">= 3.6", "size": 2626, "upload_time": "2019-11-16T19:20:36", "upload_time_iso_8601": "2019-11-16T19:20:36.265666Z", "url": "https://files.pythonhosted.org/packages/5d/bc/7110f0715da880fc573bc0fc31dc0c3b9b37d4bd557e1c6795191ca8e3ac/autograd_lib-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b47bd1450dec1383a53afcef1bf2f063", "sha256": "747d878768eafc41915f6af4df4e0921dbb5f58600ca1d35e8f6c368252998e6"}, "downloads": -1, "filename": "autograd-lib-0.0.1.tar.gz", "has_sig": false, "md5_digest": "b47bd1450dec1383a53afcef1bf2f063", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 2707, "upload_time": "2019-11-16T19:20:38", "upload_time_iso_8601": "2019-11-16T19:20:38.587505Z", "url": "https://files.pythonhosted.org/packages/9f/d6/efc002eef84c0d6ca112fc1d100bc06030611de9575bc1af1ae36dfa8dbf/autograd-lib-0.0.1.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "0bccb3696800402c5bf6d15561a16c4b", "sha256": "81774fd486d99fbd25a987597e16e7b340081b31b842f0f2111eb7686527a839"}, "downloads": -1, "filename": "autograd_lib-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "0bccb3696800402c5bf6d15561a16c4b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">= 3.6", "size": 8550, "upload_time": "2019-12-12T23:07:10", "upload_time_iso_8601": "2019-12-12T23:07:10.444440Z", "url": "https://files.pythonhosted.org/packages/53/82/103c28960cc035ad3a79280f01dac07f09e9878e122489748da76eff9208/autograd_lib-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0340150d6839ed26ebcadb69b22c9b0d", "sha256": "6bbd691d8b55c3b79741e37a523049fd40e5c2cbf4868448c3b3f29c475764af"}, "downloads": -1, "filename": "autograd-lib-0.0.4.tar.gz", "has_sig": false, "md5_digest": "0340150d6839ed26ebcadb69b22c9b0d", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 7866, "upload_time": "2019-12-12T23:07:12", "upload_time_iso_8601": "2019-12-12T23:07:12.815029Z", "url": "https://files.pythonhosted.org/packages/41/6c/0d0014ce79f04a0f170aada597f9e7c91216ca554632b69bca8eb0f84ac6/autograd-lib-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "b429b933e7ef197f0f30f7ea4da22dc8", "sha256": "86375bac2c73876d5e99750e368245977913e4841ed3e8c0501aa03f964056f6"}, "downloads": -1, "filename": "autograd_lib-0.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "b429b933e7ef197f0f30f7ea4da22dc8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">= 3.6", "size": 9094, "upload_time": "2020-01-01T03:19:58", "upload_time_iso_8601": "2020-01-01T03:19:58.239801Z", "url": "https://files.pythonhosted.org/packages/28/82/9efffbbfb015a93a256b6faf970fd13afe6846bbe23445a5489195678386/autograd_lib-0.0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3f3aa859d7a582f23b37604509ad7902", "sha256": "f22dcc62adaee884ec1b1b92c11a19cbb053ee2dd894b4ad3633c3d6bf781000"}, "downloads": -1, "filename": "autograd-lib-0.0.5.tar.gz", "has_sig": false, "md5_digest": "3f3aa859d7a582f23b37604509ad7902", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 8370, "upload_time": "2020-01-01T03:19:59", "upload_time_iso_8601": "2020-01-01T03:19:59.911188Z", "url": "https://files.pythonhosted.org/packages/a1/c2/0cb0bc9e4007c40cb808d4cabcec935c3442d06a83c2d597d2c8e4d80f25/autograd-lib-0.0.5.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "5cf130f7a94898c1063b89c14a5d7024", "sha256": "b5216deaf8ba32bf88d414f00e52b5173d2844a7fc6b1b31fcd2de4b4d6ae157"}, "downloads": -1, "filename": "autograd_lib-0.0.6-py3-none-any.whl", "has_sig": false, "md5_digest": "5cf130f7a94898c1063b89c14a5d7024", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">= 3.6", "size": 9172, "upload_time": "2020-01-01T04:09:43", "upload_time_iso_8601": "2020-01-01T04:09:43.945487Z", "url": "https://files.pythonhosted.org/packages/22/8a/2edf55ed1fd3fccd1bd603eb7c21d77250657a1a000d6af6a76b7f355476/autograd_lib-0.0.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "03fee09bccfd5e2cc8c9bb91597d42c7", "sha256": "70e7d8bd0b7a314f4cd4e0b21ad1bb4971942ec40d220b3e336f1ee09189dd72"}, "downloads": -1, "filename": "autograd-lib-0.0.6.tar.gz", "has_sig": false, "md5_digest": "03fee09bccfd5e2cc8c9bb91597d42c7", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 8442, "upload_time": "2020-01-01T04:09:45", "upload_time_iso_8601": "2020-01-01T04:09:45.613855Z", "url": "https://files.pythonhosted.org/packages/d6/57/72f2e5ea887debc2d3b73a33cb6370699944f1eb820a808d6988ea7a35e0/autograd-lib-0.0.6.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "3eb590938942da88bea444b9e65a72ec", "sha256": "13a72b678fbba22ae47058cc26c8ce170b35e9e5a4690568158aeea68626ec84"}, "downloads": -1, "filename": "autograd_lib-0.0.7-py3-none-any.whl", "has_sig": false, "md5_digest": "3eb590938942da88bea444b9e65a72ec", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">= 3.6", "size": 9202, "upload_time": "2020-01-06T02:24:01", "upload_time_iso_8601": "2020-01-06T02:24:01.884785Z", "url": "https://files.pythonhosted.org/packages/b9/ac/a3927e1e2a886a12b914bce86965bec3b925ad14ffb696b2f84d9f8ee949/autograd_lib-0.0.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6f4c5199eae77b38cf25c7730e1548a6", "sha256": "c0b63666f245f907647380e7de2cc9c4c9c3de2edc30e0d57674c6f350a00d78"}, "downloads": -1, "filename": "autograd-lib-0.0.7.tar.gz", "has_sig": false, "md5_digest": "6f4c5199eae77b38cf25c7730e1548a6", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 8472, "upload_time": "2020-01-06T02:24:03", "upload_time_iso_8601": "2020-01-06T02:24:03.547147Z", "url": "https://files.pythonhosted.org/packages/0a/65/b300be8ecd994f7a4a40c8f9ee0febad5e6239cfedb2e25823446dcf1d98/autograd-lib-0.0.7.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "3eb590938942da88bea444b9e65a72ec", "sha256": "13a72b678fbba22ae47058cc26c8ce170b35e9e5a4690568158aeea68626ec84"}, "downloads": -1, "filename": "autograd_lib-0.0.7-py3-none-any.whl", "has_sig": false, "md5_digest": "3eb590938942da88bea444b9e65a72ec", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">= 3.6", "size": 9202, "upload_time": "2020-01-06T02:24:01", "upload_time_iso_8601": "2020-01-06T02:24:01.884785Z", "url": "https://files.pythonhosted.org/packages/b9/ac/a3927e1e2a886a12b914bce86965bec3b925ad14ffb696b2f84d9f8ee949/autograd_lib-0.0.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6f4c5199eae77b38cf25c7730e1548a6", "sha256": "c0b63666f245f907647380e7de2cc9c4c9c3de2edc30e0d57674c6f350a00d78"}, "downloads": -1, "filename": "autograd-lib-0.0.7.tar.gz", "has_sig": false, "md5_digest": "6f4c5199eae77b38cf25c7730e1548a6", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 8472, "upload_time": "2020-01-06T02:24:03", "upload_time_iso_8601": "2020-01-06T02:24:03.547147Z", "url": "https://files.pythonhosted.org/packages/0a/65/b300be8ecd994f7a4a40c8f9ee0febad5e6239cfedb2e25823446dcf1d98/autograd-lib-0.0.7.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:16:17 2020"}