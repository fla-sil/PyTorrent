{"info": {"author": "Rohit Kapur", "author_email": "rohitkapur@rohitkapur.com", "bugtrack_url": null, "classifiers": [], "description": "LogScraper\n==========\n\nA generic library for gathering stats from log files by running regexes\non them. Things you can do: \\* Create and run any number of regexes on\nany number of files in parallel. \\* Aggregate stats by creating named\nregex groups in your regexes \\* Grab archived logs (so long as you tell\nit where your archives live) \\* Grab files from remote boxes \\* Print\nstats to console \\* Print regex matches to console \\* Search on gzipped\nfiles\n\nInstallation\n------------\n\nThe easiest manner of installation is to grab the package from the PyPI\nrepository.\n\n::\n\n    pip install log_scraper\n\nUsage\n-----\n\nBase Usage\n^^^^^^^^^^\n\nFor off the cuff usage, you can just create a LogScraper object and tell\nit what regexes to run and where to look for files. Eg.\n\n::\n\n    from log_scraper.base import LogScraper\n    import log_scraper.consts as LSC\n\n    filepath = '/path/to/file'\n    filename = 'filename.ext'\n    scraper = LogScraper(default_filepath={LSC.DEFAULT_PATH : filepath, LSC.DEFAULT_FILENAME : filename})\n    scraper.add_regex(name='regex1', pattern=r'your_regex_here')\n\n    # To get aggregated stats\n    data = scraper.get_log_data()\n\n    # To print all the stats\n    scraper.print_total_stats(data)\n\n    # To print each file's individual stats\n    scraper.print_stats_per_file(data)\n\n    # To view log lines matching the regex\n    scraper.view_regex_matches(scraper.get_regex_matches())\n\nThe real power, though, is in creating your own class deriving from\nLogScraper that presets the paths and the regexes to run so that anyone\ncan then use that anywhere to mine data from a process' logs.\n\nDevelopment\n-----------\n\nDependencies\n~~~~~~~~~~~~\n\n-  Python 2.7\n-  `paramiko <http://paramiko-www.readthedocs.org/en/latest/index.html>`_\n\nTesting\n~~~~~~~\n\nTo test successfully, you must set up a virtual environment On Unix, in\nthe root folder for the package, do the following:\n``python -m virtualenv . source ./bin/activate ./bin/python setup.py develop``\n\nNow you can make any changes you want and then run the unit-tests by\ndoing:\n\n::\n\n    ./bin/python setup.py test", "description_content_type": null, "docs_url": null, "download_url": "https://github.com/RohitK89/LogScraper/tarball/0.9.6", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/RohitK89/LogScraper/", "keywords": "log scraper,logs,regex,stats,grep", "license": "Simplified BSD License", "maintainer": null, "maintainer_email": null, "name": "log_scraper", "package_url": "https://pypi.org/project/log_scraper/", "platform": "UNIX,OS X,Windows", "project_url": "https://pypi.org/project/log_scraper/", "project_urls": {"Download": "https://github.com/RohitK89/LogScraper/tarball/0.9.6", "Homepage": "https://github.com/RohitK89/LogScraper/"}, "release_url": "https://pypi.org/project/log_scraper/0.9.9/", "requires_dist": ["paramiko"], "requires_python": null, "summary": "A base library for writing your own log scraper, i.e. something that can run regexes over files and give you meaningful information like stats. Add your own regexes and plug and play. See the readme for more information.", "version": "0.9.9", "yanked": false, "html_description": "<div class=\"project-description\">\n            LogScraper<br>==========<br><br>A generic library for gathering stats from log files by running regexes<br>on them. Things you can do: \\* Create and run any number of regexes on<br>any number of files in parallel. \\* Aggregate stats by creating named<br>regex groups in your regexes \\* Grab archived logs (so long as you tell<br>it where your archives live) \\* Grab files from remote boxes \\* Print<br>stats to console \\* Print regex matches to console \\* Search on gzipped<br>files<br><br>Installation<br>------------<br><br>The easiest manner of installation is to grab the package from the PyPI<br>repository.<br><br>::<br><br>    pip install log_scraper<br><br>Usage<br>-----<br><br>Base Usage<br>^^^^^^^^^^<br><br>For off the cuff usage, you can just create a LogScraper object and tell<br>it what regexes to run and where to look for files. Eg.<br><br>::<br><br>    from log_scraper.base import LogScraper<br>    import log_scraper.consts as LSC<br><br>    filepath = '/path/to/file'<br>    filename = 'filename.ext'<br>    scraper = LogScraper(default_filepath={LSC.DEFAULT_PATH : filepath, LSC.DEFAULT_FILENAME : filename})<br>    scraper.add_regex(name='regex1', pattern=r'your_regex_here')<br><br>    # To get aggregated stats<br>    data = scraper.get_log_data()<br><br>    # To print all the stats<br>    scraper.print_total_stats(data)<br><br>    # To print each file's individual stats<br>    scraper.print_stats_per_file(data)<br><br>    # To view log lines matching the regex<br>    scraper.view_regex_matches(scraper.get_regex_matches())<br><br>The real power, though, is in creating your own class deriving from<br>LogScraper that presets the paths and the regexes to run so that anyone<br>can then use that anywhere to mine data from a process' logs.<br><br>Development<br>-----------<br><br>Dependencies<br>~~~~~~~~~~~~<br><br>-  Python 2.7<br>-  `paramiko &lt;http://paramiko-www.readthedocs.org/en/latest/index.html&gt;`_<br><br>Testing<br>~~~~~~~<br><br>To test successfully, you must set up a virtual environment On Unix, in<br>the root folder for the package, do the following:<br>``python -m virtualenv . source ./bin/activate ./bin/python setup.py develop``<br><br>Now you can make any changes you want and then run the unit-tests by<br>doing:<br><br>::<br><br>    ./bin/python setup.py test\n          </div>"}, "last_serial": 1616588, "releases": {"0.9.4": [{"comment_text": "", "digests": {"md5": "ea950334585b2a54be50310dca3b1a75", "sha256": "d8a065a6612d8d844fdcbc19199687a0d5bd24e5035587e5b002e7736425ecfe"}, "downloads": -1, "filename": "log_scraper-0.9.4.tar.gz", "has_sig": false, "md5_digest": "ea950334585b2a54be50310dca3b1a75", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11911, "upload_time": "2015-05-30T21:04:47", "upload_time_iso_8601": "2015-05-30T21:04:47.737952Z", "url": "https://files.pythonhosted.org/packages/1b/a5/e1ef3a8c043201f00beaa17221bbbb103aa8210208204fa191bbd6b5d1f8/log_scraper-0.9.4.tar.gz", "yanked": false}], "0.9.5": [{"comment_text": "", "digests": {"md5": "7383024c57fbe407293398246a97d7c3", "sha256": "0cf0cffd9aa32dbb69ee6db7eb34c54cbf6578f8476d855921dfab389e9aff0a"}, "downloads": -1, "filename": "log_scraper-0.9.5.tar.gz", "has_sig": false, "md5_digest": "7383024c57fbe407293398246a97d7c3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12213, "upload_time": "2015-06-01T19:16:49", "upload_time_iso_8601": "2015-06-01T19:16:49.179926Z", "url": "https://files.pythonhosted.org/packages/a9/87/21a7cbf8451427e690a8e432ba2a51a23665e3c8f7a9b4064abe9e568c5e/log_scraper-0.9.5.tar.gz", "yanked": false}], "0.9.7": [], "0.9.8": [{"comment_text": "", "digests": {"md5": "6e908f7806dd6cca986cde4764a6cba5", "sha256": "850c57db2133eb948ce36d1ac8124646511d9282df3fb65adc3f2e0dfd7d874a"}, "downloads": -1, "filename": "log_scraper-0.9.8-py2-none-any.whl", "has_sig": false, "md5_digest": "6e908f7806dd6cca986cde4764a6cba5", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 14660, "upload_time": "2015-07-01T21:02:53", "upload_time_iso_8601": "2015-07-01T21:02:53.329898Z", "url": "https://files.pythonhosted.org/packages/93/06/eaece3ea8e075995e41b0b32222d01863bcc717b7d64e13453ff074d1123/log_scraper-0.9.8-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c00d27fd657f4a16746ac624511550bf", "sha256": "55b8b0a16f65d046485ee4918a849309dda389d19aecf6450a76612c33639731"}, "downloads": -1, "filename": "log_scraper-0.9.8.tar.gz", "has_sig": false, "md5_digest": "c00d27fd657f4a16746ac624511550bf", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12435, "upload_time": "2015-07-01T21:02:56", "upload_time_iso_8601": "2015-07-01T21:02:56.316033Z", "url": "https://files.pythonhosted.org/packages/b0/45/a67c30b8815ea6b8246aa8e5f2bfe83d9332212d0a38423912e1202a2707/log_scraper-0.9.8.tar.gz", "yanked": false}], "0.9.9": [{"comment_text": "", "digests": {"md5": "9c7958a56051895c7e486aafdc0bb3f8", "sha256": "af857d6b1aa44d1670b3585c6e5f7d76382a1df9c5325e092cc171ee9bb48b49"}, "downloads": -1, "filename": "log_scraper-0.9.9-py2-none-any.whl", "has_sig": false, "md5_digest": "9c7958a56051895c7e486aafdc0bb3f8", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 14630, "upload_time": "2015-07-02T14:53:13", "upload_time_iso_8601": "2015-07-02T14:53:13.974321Z", "url": "https://files.pythonhosted.org/packages/e0/35/1f5dae4516e20db134a916bffd6270e391326b6a2f012edbdca91e2240e5/log_scraper-0.9.9-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "adb2271ceb69fd7204d8a4485f21c6e4", "sha256": "9e50f5e7864ab2c56bd31644690446a429191f071f559fba954557d017c896b0"}, "downloads": -1, "filename": "log_scraper-0.9.9.tar.gz", "has_sig": false, "md5_digest": "adb2271ceb69fd7204d8a4485f21c6e4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12407, "upload_time": "2015-07-02T14:53:17", "upload_time_iso_8601": "2015-07-02T14:53:17.295271Z", "url": "https://files.pythonhosted.org/packages/98/1a/0dbae964b86eafbff7e4c9d57e82010a84289002bbcfa2394b7edd63c998/log_scraper-0.9.9.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "9c7958a56051895c7e486aafdc0bb3f8", "sha256": "af857d6b1aa44d1670b3585c6e5f7d76382a1df9c5325e092cc171ee9bb48b49"}, "downloads": -1, "filename": "log_scraper-0.9.9-py2-none-any.whl", "has_sig": false, "md5_digest": "9c7958a56051895c7e486aafdc0bb3f8", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 14630, "upload_time": "2015-07-02T14:53:13", "upload_time_iso_8601": "2015-07-02T14:53:13.974321Z", "url": "https://files.pythonhosted.org/packages/e0/35/1f5dae4516e20db134a916bffd6270e391326b6a2f012edbdca91e2240e5/log_scraper-0.9.9-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "adb2271ceb69fd7204d8a4485f21c6e4", "sha256": "9e50f5e7864ab2c56bd31644690446a429191f071f559fba954557d017c896b0"}, "downloads": -1, "filename": "log_scraper-0.9.9.tar.gz", "has_sig": false, "md5_digest": "adb2271ceb69fd7204d8a4485f21c6e4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12407, "upload_time": "2015-07-02T14:53:17", "upload_time_iso_8601": "2015-07-02T14:53:17.295271Z", "url": "https://files.pythonhosted.org/packages/98/1a/0dbae964b86eafbff7e4c9d57e82010a84289002bbcfa2394b7edd63c998/log_scraper-0.9.9.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:44:08 2020"}