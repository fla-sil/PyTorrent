{"info": {"author": "Madison May", "author_email": "madison@indico.io", "bugtrack_url": null, "classifiers": [], "description": "Tomorrow\n========\n\nMagic decorator syntax for asynchronous code in Python\n\nInstallation\n------------\n\nTomorrow is conveniently available via pip:\n\n::\n\n    pip install tomorrow\n\nor installable via ``git clone`` and ``setup.py``\n\n::\n\n    git clone git@github.com:madisonmay/Tomorrow.git\n    sudo python setup.py install\n\nUsage\n-----\n\nThe tomorrow library enables you to utilize the benefits of\nmulti-threading with minimal concern about the implementation details.\n\nBehind the scenes, the library is a thin wrapper around the ``Future``\nobject in ``concurrent.futures`` that resolves the ``Future`` whenever\nyou try to access any of its attributes.\n\nEnough of the implementation details, let's take a look at how simple it\nis to speed up an inefficient chunk of blocking code with minimal\neffort.\n\nNaive Web Scraper\n-----------------\n\nYou've collected a list of urls and are looking to download the HTML of\nthe lot. The following is a perfectly reasonable first stab at solving\nthe task.\n\nFor the following examples, we'll be using the top sites from the Alexa\nrankings.\n\n.. code:: python\n\n    urls = [\n        'http://google.com',\n        'http://facebook.com',\n        'http://youtube.com',\n        'http://baidu.com',\n        'http://yahoo.com',\n    ]\n\nRight then, let's get on to the code.\n\n.. code:: python\n\n    import time\n    import requests\n\n    def download(url):\n        return requests.get(url)\n\n    if __name__ == \"__main__\":\n\n        start = time.time()\n        responses = [download(url) for url in urls]\n        html = [response.text for response in responses]\n        end = time.time()\n        print \"Time: %f seconds\" % (end - start)\n\nMore Efficient Web Scraper\n--------------------------\n\nUsing tomorrow's decorator syntax, we can define a function that\nexecutes in multiple threads. Individual calls to ``download`` are\nnon-blocking, but we can largely ignore this fact and write code\nidentically to how we would in a synchronous paradigm.\n\n.. code:: python\n\n    import time\n    import requests\n\n    from tomorrow import threads\n\n    @threads(5)\n    def download(url):\n        return requests.get(url)\n\n    if __name__ == \"__main__\":\n        import time\n\n        start = time.time()\n        responses = [download(url) for url in urls]\n        html = [response.text for response in responses]\n        end = time.time()\n        print \"Time: %f seconds\" % (end - start)\n\nAwesome! With a single line of additional code (and no explicit\nthreading logic) we can now download websites ~10x as efficiently.\n\nYou can also optionally pass in a timeout argument, to prevent hanging\non a task that is not guaranteed to return.\n\n.. code:: python\n\n    import time\n\n    from tomorrow import threads\n\n    @threads(1, timeout=0.1)\n    def raises_timeout_error():\n        time.sleep(1)\n\n    if __name__ == \"__main__\":\n        print raises_timeout_error()\n\nHow Does it Work?\n-----------------\n\nFeel free to read the source for a peek behind the scenes -- it's less\nthat 50 lines of code.\n\n.. |Codeship Status for madisonmay/Tomorrow| image:: https://codeship.com/projects/9a3b4c60-1b5b-0133-5ec7-7e346f2e432c/status?branch=master\n   :target: https://codeship.com/projects/94472", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/madisonmay/tomorrow", "keywords": null, "license": "MIT License (See LICENSE)", "maintainer": null, "maintainer_email": null, "name": "tomorrow", "package_url": "https://pypi.org/project/tomorrow/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/tomorrow/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/madisonmay/tomorrow"}, "release_url": "https://pypi.org/project/tomorrow/0.2.4/", "requires_dist": null, "requires_python": null, "summary": "Magic decorator syntax for asynchronous code.", "version": "0.2.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>Magic decorator syntax for asynchronous code in Python</p>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>Tomorrow is conveniently available via pip:</p>\n<pre>pip install tomorrow\n</pre>\n<p>or installable via <tt>git clone</tt> and <tt>setup.py</tt></p>\n<pre>git clone git@github.com:madisonmay/Tomorrow.git\nsudo python setup.py install\n</pre>\n</div>\n<div id=\"usage\">\n<h2>Usage</h2>\n<p>The tomorrow library enables you to utilize the benefits of\nmulti-threading with minimal concern about the implementation details.</p>\n<p>Behind the scenes, the library is a thin wrapper around the <tt>Future</tt>\nobject in <tt>concurrent.futures</tt> that resolves the <tt>Future</tt> whenever\nyou try to access any of its attributes.</p>\n<p>Enough of the implementation details, let\u2019s take a look at how simple it\nis to speed up an inefficient chunk of blocking code with minimal\neffort.</p>\n</div>\n<div id=\"naive-web-scraper\">\n<h2>Naive Web Scraper</h2>\n<p>You\u2019ve collected a list of urls and are looking to download the HTML of\nthe lot. The following is a perfectly reasonable first stab at solving\nthe task.</p>\n<p>For the following examples, we\u2019ll be using the top sites from the Alexa\nrankings.</p>\n<pre><span class=\"n\">urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n    <span class=\"s1\">'http://google.com'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'http://facebook.com'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'http://youtube.com'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'http://baidu.com'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'http://yahoo.com'</span><span class=\"p\">,</span>\n<span class=\"p\">]</span>\n</pre>\n<p>Right then, let\u2019s get on to the code.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">time</span>\n<span class=\"kn\">import</span> <span class=\"nn\">requests</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">download</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"n\">requests</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">)</span>\n\n<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s2\">\"__main__\"</span><span class=\"p\">:</span>\n\n    <span class=\"n\">start</span> <span class=\"o\">=</span> <span class=\"n\">time</span><span class=\"o\">.</span><span class=\"n\">time</span><span class=\"p\">()</span>\n    <span class=\"n\">responses</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">download</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">url</span> <span class=\"ow\">in</span> <span class=\"n\">urls</span><span class=\"p\">]</span>\n    <span class=\"n\">html</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">text</span> <span class=\"k\">for</span> <span class=\"n\">response</span> <span class=\"ow\">in</span> <span class=\"n\">responses</span><span class=\"p\">]</span>\n    <span class=\"n\">end</span> <span class=\"o\">=</span> <span class=\"n\">time</span><span class=\"o\">.</span><span class=\"n\">time</span><span class=\"p\">()</span>\n    <span class=\"nb\">print</span> <span class=\"s2\">\"Time: </span><span class=\"si\">%f</span><span class=\"s2\"> seconds\"</span> <span class=\"o\">%</span> <span class=\"p\">(</span><span class=\"n\">end</span> <span class=\"o\">-</span> <span class=\"n\">start</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"more-efficient-web-scraper\">\n<h2>More Efficient Web Scraper</h2>\n<p>Using tomorrow\u2019s decorator syntax, we can define a function that\nexecutes in multiple threads. Individual calls to <tt>download</tt> are\nnon-blocking, but we can largely ignore this fact and write code\nidentically to how we would in a synchronous paradigm.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">time</span>\n<span class=\"kn\">import</span> <span class=\"nn\">requests</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">tomorrow</span> <span class=\"kn\">import</span> <span class=\"n\">threads</span>\n\n<span class=\"nd\">@threads</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n<span class=\"k\">def</span> <span class=\"nf\">download</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"n\">requests</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">)</span>\n\n<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s2\">\"__main__\"</span><span class=\"p\">:</span>\n    <span class=\"kn\">import</span> <span class=\"nn\">time</span>\n\n    <span class=\"n\">start</span> <span class=\"o\">=</span> <span class=\"n\">time</span><span class=\"o\">.</span><span class=\"n\">time</span><span class=\"p\">()</span>\n    <span class=\"n\">responses</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">download</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">url</span> <span class=\"ow\">in</span> <span class=\"n\">urls</span><span class=\"p\">]</span>\n    <span class=\"n\">html</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">text</span> <span class=\"k\">for</span> <span class=\"n\">response</span> <span class=\"ow\">in</span> <span class=\"n\">responses</span><span class=\"p\">]</span>\n    <span class=\"n\">end</span> <span class=\"o\">=</span> <span class=\"n\">time</span><span class=\"o\">.</span><span class=\"n\">time</span><span class=\"p\">()</span>\n    <span class=\"nb\">print</span> <span class=\"s2\">\"Time: </span><span class=\"si\">%f</span><span class=\"s2\"> seconds\"</span> <span class=\"o\">%</span> <span class=\"p\">(</span><span class=\"n\">end</span> <span class=\"o\">-</span> <span class=\"n\">start</span><span class=\"p\">)</span>\n</pre>\n<p>Awesome! With a single line of additional code (and no explicit\nthreading logic) we can now download websites ~10x as efficiently.</p>\n<p>You can also optionally pass in a timeout argument, to prevent hanging\non a task that is not guaranteed to return.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">time</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">tomorrow</span> <span class=\"kn\">import</span> <span class=\"n\">threads</span>\n\n<span class=\"nd\">@threads</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">timeout</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">)</span>\n<span class=\"k\">def</span> <span class=\"nf\">raises_timeout_error</span><span class=\"p\">():</span>\n    <span class=\"n\">time</span><span class=\"o\">.</span><span class=\"n\">sleep</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s2\">\"__main__\"</span><span class=\"p\">:</span>\n    <span class=\"nb\">print</span> <span class=\"n\">raises_timeout_error</span><span class=\"p\">()</span>\n</pre>\n</div>\n<div id=\"how-does-it-work\">\n<h2>How Does it Work?</h2>\n<p>Feel free to read the source for a peek behind the scenes \u2013 it\u2019s less\nthat 50 lines of code.</p>\n</div>\n\n          </div>"}, "last_serial": 1885673, "releases": {"0.2.0": [{"comment_text": "", "digests": {"md5": "4bc21cc9ee6d98f307adbddc5d105fa5", "sha256": "fda91ba329067fe171ae916a50d4b2f8952c82cfe9011bde9a3fa5082314e289"}, "downloads": -1, "filename": "tomorrow-0.2.0.tar.gz", "has_sig": false, "md5_digest": "4bc21cc9ee6d98f307adbddc5d105fa5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2923, "upload_time": "2015-08-02T15:43:04", "upload_time_iso_8601": "2015-08-02T15:43:04.679867Z", "url": "https://files.pythonhosted.org/packages/16/77/761e2e6c14ee4ca1f4c855b60dc46ad6bb128e54091748f0b086117438c3/tomorrow-0.2.0.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "5fbe040094ff38db21a3640ff2a38c25", "sha256": "053f60b3724bd0c123c79d0ee6b686ef8f0d86e196ae45a10191cd2914b9a37c"}, "downloads": -1, "filename": "tomorrow-0.2.2.tar.gz", "has_sig": false, "md5_digest": "5fbe040094ff38db21a3640ff2a38c25", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3177, "upload_time": "2015-08-02T22:56:58", "upload_time_iso_8601": "2015-08-02T22:56:58.340536Z", "url": "https://files.pythonhosted.org/packages/77/3f/01762aa55df6232ce282f20038031360274d2186714fa3c0dd8b44760763/tomorrow-0.2.2.tar.gz", "yanked": false}], "0.2.3": [{"comment_text": "", "digests": {"md5": "9600fbef0f1bdbf78cda7407209b8f58", "sha256": "ae88788be66eaa8c679a663fc3039205e0a6b1b7c87235e1ccebb099c29331a2"}, "downloads": -1, "filename": "tomorrow-0.2.3.tar.gz", "has_sig": false, "md5_digest": "9600fbef0f1bdbf78cda7407209b8f58", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3459, "upload_time": "2015-08-03T15:12:22", "upload_time_iso_8601": "2015-08-03T15:12:22.951649Z", "url": "https://files.pythonhosted.org/packages/ef/e5/3eb3c9d45501fc6020c50aa7a744a7b8dd4ab10d43058af88696005f58c7/tomorrow-0.2.3.tar.gz", "yanked": false}], "0.2.4": [{"comment_text": "", "digests": {"md5": "b4dee06772b9ec2b47374387a5d97a4b", "sha256": "a5ed9656ee62e448f1d3841d1a7c2be338c15f3d9cc9bfbf182790dcff051f20"}, "downloads": -1, "filename": "tomorrow-0.2.4.tar.gz", "has_sig": false, "md5_digest": "b4dee06772b9ec2b47374387a5d97a4b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2989, "upload_time": "2016-01-02T21:36:55", "upload_time_iso_8601": "2016-01-02T21:36:55.640014Z", "url": "https://files.pythonhosted.org/packages/06/29/658616e215bcb0946bca1be430a989816d8a98598cab50133f32e11fa2b1/tomorrow-0.2.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "b4dee06772b9ec2b47374387a5d97a4b", "sha256": "a5ed9656ee62e448f1d3841d1a7c2be338c15f3d9cc9bfbf182790dcff051f20"}, "downloads": -1, "filename": "tomorrow-0.2.4.tar.gz", "has_sig": false, "md5_digest": "b4dee06772b9ec2b47374387a5d97a4b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2989, "upload_time": "2016-01-02T21:36:55", "upload_time_iso_8601": "2016-01-02T21:36:55.640014Z", "url": "https://files.pythonhosted.org/packages/06/29/658616e215bcb0946bca1be430a989816d8a98598cab50133f32e11fa2b1/tomorrow-0.2.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:51:13 2020"}