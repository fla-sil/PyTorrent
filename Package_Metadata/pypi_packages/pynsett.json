{"info": {"author": "Alberto Cetoli", "author_email": "alberto@nlulite.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License"], "description": "Pynsett: A programmable relation extraction tool\n===============================================\n\nInstallation\n------------\n\nBefore installing the package you need to install the tools for compiling python-igraph\n```bash\nsudo apt-get install build-essential python-dev python3-dev\n```\n\nThe basic version can be installed by typing\n```bash\nvirtualenv --python=/usr/bin/python3 .env\npip install pynsett\n```\n\nThe system is now installed, however the parser requires an additional module from Spacy and AllenNLP. You will need to type\n```bash\npython3 -m spacy download en_core_web_lg\npython3 -m pynsett download\n```\n\n\nWhat is Pynsett\n---------------\n\nPynsett is a programmable relation extractor. \nThe user sets up a set of rules which are used to parse any English text. \nAs a result, Pynsett returns a list of triplets as defined in the rules.\n\n\nExample usage\n-------------\n\nLet's assume we want to extract wikidata relations from a file named 'test.txt'.\nAn example code would be\n\n```python\nfrom pynsett.discourse import Discourse\nfrom pynsett.extractor import Extractor\nfrom pynsett.auxiliary.prior_knowedge import get_wikidata_knowledge\n\n\ntext = open('test.txt').read()\ndiscourse = Discourse(text)\n\nextractor = Extractor(discourse, get_wikidata_knowledge())\ntriplets = extractor.extract()\n\nfor triplet in triplets:\n    print(triplet)\n```\n\nThe distribution comes with two sets of rules: The generic knowledge, accessible using\npynsett.auxiliary.prior_knowledge.get_generic_knowledge(), and the wikidata knowledge, which\ncan be loaded using pynsett.auxiliary.prior_knowledge.get_wikidata_knowledge()\n\n\nCreate new rules for extraction\n-------------------------------\n\nLet's assume we are writing a new file called \"my_own_rules.rules\".\nAn example of a new set of rules can be the following:\n\n```bash\nMATCH \"Jane#1 is an engineer#2\"\nCREATE (HAS_ROLE 1 2);\n```\n\nHere the symbol #1 gives a label to 'Jane' and #2 gives a label to 'engineer'. \nThese labels can be used when creating the relation '(IS_A 1 2)'.\n\nA more generic rule uses the entity types (Jane is a PERSON)\n```bash\nMATCH \"{PERSON}#1 is an engineer#2\"\nCREATE (HAS_ROLE 1 2);\n```\n\nThis rule matches all the sentences where the subject is a person (compatibly with the internal\nNER). The name of the person is associated to the node.\n\nThere are 18 entity types that you can type within brackets:\nCARDINAL, DATE, EVENT, FAC, GPE, LANGUAGE, LAW, LOC, MONEY, NORP, ORDINAL,\nORG, PERCENT, PERSON, PRODUCT, QUANTITY, TIME, WORK_OF_ART\n\nThere you go, a person is now connected with a role: Node 1 is whoever matches for node 1 and\nthe profession is \"engineer\". The properties of the words are put into node 1 and 2.\n\nThis seems a little bit limiting, because the previous relations only works for engineers.\nLet us define a `word cloud` and call it \"ROLE\".\n\n```bash\nDEFINE ROLE AS [engineer, architect, physicist, doctor];\n\nMATCH \"{PERSON}#1 is a ROLE#2\"\nCREATE (HAS_ROLE 1 2);\n```\n\nAs a final touch let us make the text a little bit nicer to the eyes: Let's use PERSON instead\nof {PERSON}\n\n```bash\nDEFINE PERSON AS {PERSON};\nDEFINE ROLE AS [engineer, architect, physicist, doctor];\n\nMATCH \"PERSON#1 is a ROLE#2\"\nCREATE (HAS_ROLE 1 2);\n```\n\nA working example of pynsett's rules is in [this file](https://github.com/fractalego/pynsett/blob/master/pynsett/rules/wikidata.rules).\n\n\nUse the extraction rules\n------------------------\n\nIf you have a specific file with the extraction rules, you can load it by creating a new\nKnowledge object:\n\n```python\nfrom pynsett.discourse import Discourse\nfrom pynsett.extractor import Extractor\nfrom pynsett.knowledge import Knowledge\n\n\ntext = open('test.txt').read()\ndiscourse = Discourse(text)\n\nknowledge = Knowledge()\nknowledge.add_rules(open('./my_own_rules.rules').read())\n\nextractor = Extractor(discourse, knowledge)\ntriplets = extractor.extract()\n\nfor triplet in triplets:\n    print(triplet)\n```\n\nImport the triplets into Neo4J\n------------------------------\n\nThe triplets can be imported into a proper graph database. As an example, let us do it for Neo4j.  \nYou would need to install the system onto your machine, as well as installing the python package \n'py2neo'. After everything is set up, you can run the following script.\n\n```python\nfrom py2neo import Graph\nfrom pynsett.discourse import Discourse\nfrom pynsett.extractor import Extractor\nfrom pynsett.auxiliary.prior_knowedge import get_wikidata_knowledge\n\nknowledge = get_wikidata_knowledge()\ntext = open('sample_wikipedia.txt').read()\n\ndiscourse = Discourse(text)\nextractor = Extractor(discourse, knowledge)\ntriplets = extractor.extract()\n\ngraph = Graph('http://localhost:7474/db/data/')\nfor triplet in triplets:\n    graph.run('MERGE (a {text: \"%s\"}) MERGE (b {text: \"%s\"}) CREATE (a)-[:%s]->(b)'\n              % (triplet[0],\n                 triplet[2],\n                 triplet[1]))\n```\n\nThis script works on an example page called 'sample_wikipedia.txt' that you will have to provide.\n\n\nUsing the internal Web Server\n----------------------------\n\nTo start the internal web server you can write the following\n\n```python3\nfrom pynsett.server import pynsett_app\npynsett_app.run(debug=True, port=4001, host='0.0.0.0', use_reloader=False)\n```\n\nwhich will open a flask app at `localhost:4001`.\n\n### Web interface\n\nThe server provides three web interfaces:\n\n#### A Wikidata relation extractor at http://localhost:4001/wikidata\n\n![Image about Asimov's Wikipedia page](images/asimov_wikidata.png)\n\n#### A Programmable relation extractor at http://localhost:4001/relations\n![Image about a programmable rule](images/relations_web.png)\n\n\n#### A Neo-Davidsonian representation of a text at http://localhost:4001\n\n![Image about A Neo-Davidsonian representation](images/asimov_drt.png)\n\n\n## API\n\nThe wikidata relation extractor API can be called with\n\n```python3\nimport json\nimport requests\n\ntext = \"John is a writer.\"\ntriplets = json.loads(requests.post('http://localhost:4001/api/wikidata', json={'text': text}).text)\nprint(triplets)\n```\n\nwith output:\n```python3\n[['John', 'JOB_TITLE', 'writer']]\n```\n\nThe rules can programmed by posting as in the following\n```python3\nimport json\nimport requests\n\nrules = \"\"\"\nDEFINE PERSON AS {PERSON};\nDEFINE ORG AS {ORG};\nDEFINE ROLE AS [engineer, author, doctor, researcher];\n\nMATCH \"PERSON#1 was ROLE at ORG#2\"\nCREATE (WORKED_AT 1 2);\n\"\"\"\n\ntriplets = json.loads(requests.post('http://localhost:4001/api/set_rules', json={'text': rules}).text)\n```\n\nThese rules are then used at the following API endpoint\n```python3\nimport json\nimport requests\n\ntext = \"Isaac Asimov was an American writer and professor of biochemistry at Boston University.\"\ntriplets = json.loads(requests.post('http://localhost:4001/api/relations', json={'text': text}).text)\nprint(triplets)\n```\n\n\nThe Neo-Davidsonian representation API can be called with\n\n```python3\nimport json\nimport requests\ntext = \"John is tall.\"\ngraph = json.loads(requests.post('http://localhost:4001/api/drt', json={'text': text}).text)\nprint(graph)\n```\n\nwith output:\n```python3\n{'edges': [{'arrows': 'to', 'from': 'v1', 'label': 'AGENT', 'to': 'v0'},\n                                       {'arrows': 'to', 'from': 'v1', 'label': 'ADJECTIVE', 'to': 'v2'}],\n                             'nodes': [{'id': 'v1', 'label': 'is'},\n                                       {'id': 'v0', 'label': 'John'},\n                                       {'id': 'v2', 'label': 'tall'}]}\n```\n\n\nPre-Formatting of the Text\n--------------------------\n\nThe text must be submitted respecting the following rules:\n* No parenthesis (...) nor brackets [...]. The parser is confused by those.\n* The paragraphs must be separated by *1 empty line*. Dividing a text into paragraphs helps with anaphora.\n   ```bash\n   This is paragraph 1.\n\n   This is paragraph 2.\n   ```\n\n\n\nKnown issues and shortcomings\n-----------------------------\n\n* Speed! Parsing is done one sentence at a time\n* Anaphora only works inside paragraphs\n* Anaphora is done through AllenNLP, with can be slow-ish without a GPU\n* The text needs to be cleaned and pre-formatted. This is not an issue _per se_ but it must be kept in mind\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://github.com/fractalego/pynsett", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "pynsett", "package_url": "https://pypi.org/project/pynsett/", "platform": "", "project_url": "https://pypi.org/project/pynsett/", "project_urls": {"Homepage": "http://github.com/fractalego/pynsett"}, "release_url": "https://pypi.org/project/pynsett/0.1.8/", "requires_dist": ["spacy (==2.1.3)", "nltk (==3.2.1)", "rdflib (==4.2.2)", "yappi (==1.0)", "gensim (==3.7.2)", "parvusdb (==0.0.26)", "nose (==1.3.7)", "allennlp (==0.8.3)", "flask (==1.0.2)", "flask-cors"], "requires_python": "", "summary": "A programmable relation extractor", "version": "0.1.8", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Pynsett: A programmable relation extraction tool</h1>\n<h2>Installation</h2>\n<p>Before installing the package you need to install the tools for compiling python-igraph</p>\n<pre>sudo apt-get install build-essential python-dev python3-dev\n</pre>\n<p>The basic version can be installed by typing</p>\n<pre>virtualenv --python<span class=\"o\">=</span>/usr/bin/python3 .env\npip install pynsett\n</pre>\n<p>The system is now installed, however the parser requires an additional module from Spacy and AllenNLP. You will need to type</p>\n<pre>python3 -m spacy download en_core_web_lg\npython3 -m pynsett download\n</pre>\n<h2>What is Pynsett</h2>\n<p>Pynsett is a programmable relation extractor.\nThe user sets up a set of rules which are used to parse any English text.\nAs a result, Pynsett returns a list of triplets as defined in the rules.</p>\n<h2>Example usage</h2>\n<p>Let's assume we want to extract wikidata relations from a file named 'test.txt'.\nAn example code would be</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pynsett.discourse</span> <span class=\"kn\">import</span> <span class=\"n\">Discourse</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pynsett.extractor</span> <span class=\"kn\">import</span> <span class=\"n\">Extractor</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pynsett.auxiliary.prior_knowedge</span> <span class=\"kn\">import</span> <span class=\"n\">get_wikidata_knowledge</span>\n\n\n<span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s1\">'test.txt'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">()</span>\n<span class=\"n\">discourse</span> <span class=\"o\">=</span> <span class=\"n\">Discourse</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">)</span>\n\n<span class=\"n\">extractor</span> <span class=\"o\">=</span> <span class=\"n\">Extractor</span><span class=\"p\">(</span><span class=\"n\">discourse</span><span class=\"p\">,</span> <span class=\"n\">get_wikidata_knowledge</span><span class=\"p\">())</span>\n<span class=\"n\">triplets</span> <span class=\"o\">=</span> <span class=\"n\">extractor</span><span class=\"o\">.</span><span class=\"n\">extract</span><span class=\"p\">()</span>\n\n<span class=\"k\">for</span> <span class=\"n\">triplet</span> <span class=\"ow\">in</span> <span class=\"n\">triplets</span><span class=\"p\">:</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">triplet</span><span class=\"p\">)</span>\n</pre>\n<p>The distribution comes with two sets of rules: The generic knowledge, accessible using\npynsett.auxiliary.prior_knowledge.get_generic_knowledge(), and the wikidata knowledge, which\ncan be loaded using pynsett.auxiliary.prior_knowledge.get_wikidata_knowledge()</p>\n<h2>Create new rules for extraction</h2>\n<p>Let's assume we are writing a new file called \"my_own_rules.rules\".\nAn example of a new set of rules can be the following:</p>\n<pre>MATCH <span class=\"s2\">\"Jane#1 is an engineer#2\"</span>\nCREATE <span class=\"o\">(</span>HAS_ROLE <span class=\"m\">1</span> <span class=\"m\">2</span><span class=\"o\">)</span><span class=\"p\">;</span>\n</pre>\n<p>Here the symbol #1 gives a label to 'Jane' and #2 gives a label to 'engineer'.\nThese labels can be used when creating the relation '(IS_A 1 2)'.</p>\n<p>A more generic rule uses the entity types (Jane is a PERSON)</p>\n<pre>MATCH <span class=\"s2\">\"{PERSON}#1 is an engineer#2\"</span>\nCREATE <span class=\"o\">(</span>HAS_ROLE <span class=\"m\">1</span> <span class=\"m\">2</span><span class=\"o\">)</span><span class=\"p\">;</span>\n</pre>\n<p>This rule matches all the sentences where the subject is a person (compatibly with the internal\nNER). The name of the person is associated to the node.</p>\n<p>There are 18 entity types that you can type within brackets:\nCARDINAL, DATE, EVENT, FAC, GPE, LANGUAGE, LAW, LOC, MONEY, NORP, ORDINAL,\nORG, PERCENT, PERSON, PRODUCT, QUANTITY, TIME, WORK_OF_ART</p>\n<p>There you go, a person is now connected with a role: Node 1 is whoever matches for node 1 and\nthe profession is \"engineer\". The properties of the words are put into node 1 and 2.</p>\n<p>This seems a little bit limiting, because the previous relations only works for engineers.\nLet us define a <code>word cloud</code> and call it \"ROLE\".</p>\n<pre>DEFINE ROLE AS <span class=\"o\">[</span>engineer, architect, physicist, doctor<span class=\"o\">]</span><span class=\"p\">;</span>\n\nMATCH <span class=\"s2\">\"{PERSON}#1 is a ROLE#2\"</span>\nCREATE <span class=\"o\">(</span>HAS_ROLE <span class=\"m\">1</span> <span class=\"m\">2</span><span class=\"o\">)</span><span class=\"p\">;</span>\n</pre>\n<p>As a final touch let us make the text a little bit nicer to the eyes: Let's use PERSON instead\nof {PERSON}</p>\n<pre>DEFINE PERSON AS <span class=\"o\">{</span>PERSON<span class=\"o\">}</span><span class=\"p\">;</span>\nDEFINE ROLE AS <span class=\"o\">[</span>engineer, architect, physicist, doctor<span class=\"o\">]</span><span class=\"p\">;</span>\n\nMATCH <span class=\"s2\">\"PERSON#1 is a ROLE#2\"</span>\nCREATE <span class=\"o\">(</span>HAS_ROLE <span class=\"m\">1</span> <span class=\"m\">2</span><span class=\"o\">)</span><span class=\"p\">;</span>\n</pre>\n<p>A working example of pynsett's rules is in <a href=\"https://github.com/fractalego/pynsett/blob/master/pynsett/rules/wikidata.rules\" rel=\"nofollow\">this file</a>.</p>\n<h2>Use the extraction rules</h2>\n<p>If you have a specific file with the extraction rules, you can load it by creating a new\nKnowledge object:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pynsett.discourse</span> <span class=\"kn\">import</span> <span class=\"n\">Discourse</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pynsett.extractor</span> <span class=\"kn\">import</span> <span class=\"n\">Extractor</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pynsett.knowledge</span> <span class=\"kn\">import</span> <span class=\"n\">Knowledge</span>\n\n\n<span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s1\">'test.txt'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">()</span>\n<span class=\"n\">discourse</span> <span class=\"o\">=</span> <span class=\"n\">Discourse</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">)</span>\n\n<span class=\"n\">knowledge</span> <span class=\"o\">=</span> <span class=\"n\">Knowledge</span><span class=\"p\">()</span>\n<span class=\"n\">knowledge</span><span class=\"o\">.</span><span class=\"n\">add_rules</span><span class=\"p\">(</span><span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s1\">'./my_own_rules.rules'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">())</span>\n\n<span class=\"n\">extractor</span> <span class=\"o\">=</span> <span class=\"n\">Extractor</span><span class=\"p\">(</span><span class=\"n\">discourse</span><span class=\"p\">,</span> <span class=\"n\">knowledge</span><span class=\"p\">)</span>\n<span class=\"n\">triplets</span> <span class=\"o\">=</span> <span class=\"n\">extractor</span><span class=\"o\">.</span><span class=\"n\">extract</span><span class=\"p\">()</span>\n\n<span class=\"k\">for</span> <span class=\"n\">triplet</span> <span class=\"ow\">in</span> <span class=\"n\">triplets</span><span class=\"p\">:</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">triplet</span><span class=\"p\">)</span>\n</pre>\n<h2>Import the triplets into Neo4J</h2>\n<p>The triplets can be imported into a proper graph database. As an example, let us do it for Neo4j.<br>\nYou would need to install the system onto your machine, as well as installing the python package\n'py2neo'. After everything is set up, you can run the following script.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">py2neo</span> <span class=\"kn\">import</span> <span class=\"n\">Graph</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pynsett.discourse</span> <span class=\"kn\">import</span> <span class=\"n\">Discourse</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pynsett.extractor</span> <span class=\"kn\">import</span> <span class=\"n\">Extractor</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pynsett.auxiliary.prior_knowedge</span> <span class=\"kn\">import</span> <span class=\"n\">get_wikidata_knowledge</span>\n\n<span class=\"n\">knowledge</span> <span class=\"o\">=</span> <span class=\"n\">get_wikidata_knowledge</span><span class=\"p\">()</span>\n<span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s1\">'sample_wikipedia.txt'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">()</span>\n\n<span class=\"n\">discourse</span> <span class=\"o\">=</span> <span class=\"n\">Discourse</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">)</span>\n<span class=\"n\">extractor</span> <span class=\"o\">=</span> <span class=\"n\">Extractor</span><span class=\"p\">(</span><span class=\"n\">discourse</span><span class=\"p\">,</span> <span class=\"n\">knowledge</span><span class=\"p\">)</span>\n<span class=\"n\">triplets</span> <span class=\"o\">=</span> <span class=\"n\">extractor</span><span class=\"o\">.</span><span class=\"n\">extract</span><span class=\"p\">()</span>\n\n<span class=\"n\">graph</span> <span class=\"o\">=</span> <span class=\"n\">Graph</span><span class=\"p\">(</span><span class=\"s1\">'http://localhost:7474/db/data/'</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">triplet</span> <span class=\"ow\">in</span> <span class=\"n\">triplets</span><span class=\"p\">:</span>\n    <span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"s1\">'MERGE (a {text: \"</span><span class=\"si\">%s</span><span class=\"s1\">\"}) MERGE (b {text: \"</span><span class=\"si\">%s</span><span class=\"s1\">\"}) CREATE (a)-[:</span><span class=\"si\">%s</span><span class=\"s1\">]-&gt;(b)'</span>\n              <span class=\"o\">%</span> <span class=\"p\">(</span><span class=\"n\">triplet</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span>\n                 <span class=\"n\">triplet</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">],</span>\n                 <span class=\"n\">triplet</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]))</span>\n</pre>\n<p>This script works on an example page called 'sample_wikipedia.txt' that you will have to provide.</p>\n<h2>Using the internal Web Server</h2>\n<p>To start the internal web server you can write the following</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pynsett.server</span> <span class=\"kn\">import</span> <span class=\"n\">pynsett_app</span>\n<span class=\"n\">pynsett_app</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">debug</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">port</span><span class=\"o\">=</span><span class=\"mi\">4001</span><span class=\"p\">,</span> <span class=\"n\">host</span><span class=\"o\">=</span><span class=\"s1\">'0.0.0.0'</span><span class=\"p\">,</span> <span class=\"n\">use_reloader</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n</pre>\n<p>which will open a flask app at <code>localhost:4001</code>.</p>\n<h3>Web interface</h3>\n<p>The server provides three web interfaces:</p>\n<h4>A Wikidata relation extractor at <a href=\"http://localhost:4001/wikidata\" rel=\"nofollow\">http://localhost:4001/wikidata</a></h4>\n<p><img alt=\"Image about Asimov's Wikipedia page\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a452390d1a691ebe20cbaa17379f8f6d32132d39/696d616765732f6173696d6f765f77696b69646174612e706e67\"></p>\n<h4>A Programmable relation extractor at <a href=\"http://localhost:4001/relations\" rel=\"nofollow\">http://localhost:4001/relations</a></h4>\n<p><img alt=\"Image about a programmable rule\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e4778b22981323f95ed68d979857b4546d5d3f5e/696d616765732f72656c6174696f6e735f7765622e706e67\"></p>\n<h4>A Neo-Davidsonian representation of a text at <a href=\"http://localhost:4001\" rel=\"nofollow\">http://localhost:4001</a></h4>\n<p><img alt=\"Image about A Neo-Davidsonian representation\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fcd723a9431994fbbcaf67dd422ca7682ca52f0c/696d616765732f6173696d6f765f6472742e706e67\"></p>\n<h2>API</h2>\n<p>The wikidata relation extractor API can be called with</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">json</span>\n<span class=\"kn\">import</span> <span class=\"nn\">requests</span>\n\n<span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"s2\">\"John is a writer.\"</span>\n<span class=\"n\">triplets</span> <span class=\"o\">=</span> <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">loads</span><span class=\"p\">(</span><span class=\"n\">requests</span><span class=\"o\">.</span><span class=\"n\">post</span><span class=\"p\">(</span><span class=\"s1\">'http://localhost:4001/api/wikidata'</span><span class=\"p\">,</span> <span class=\"n\">json</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">text</span><span class=\"p\">})</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">triplets</span><span class=\"p\">)</span>\n</pre>\n<p>with output:</p>\n<pre><span class=\"p\">[[</span><span class=\"s1\">'John'</span><span class=\"p\">,</span> <span class=\"s1\">'JOB_TITLE'</span><span class=\"p\">,</span> <span class=\"s1\">'writer'</span><span class=\"p\">]]</span>\n</pre>\n<p>The rules can programmed by posting as in the following</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">json</span>\n<span class=\"kn\">import</span> <span class=\"nn\">requests</span>\n\n<span class=\"n\">rules</span> <span class=\"o\">=</span> <span class=\"s2\">\"\"\"</span>\n<span class=\"s2\">DEFINE PERSON AS </span><span class=\"si\">{PERSON}</span><span class=\"s2\">;</span>\n<span class=\"s2\">DEFINE ORG AS </span><span class=\"si\">{ORG}</span><span class=\"s2\">;</span>\n<span class=\"s2\">DEFINE ROLE AS [engineer, author, doctor, researcher];</span>\n\n<span class=\"s2\">MATCH \"PERSON#1 was ROLE at ORG#2\"</span>\n<span class=\"s2\">CREATE (WORKED_AT 1 2);</span>\n<span class=\"s2\">\"\"\"</span>\n\n<span class=\"n\">triplets</span> <span class=\"o\">=</span> <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">loads</span><span class=\"p\">(</span><span class=\"n\">requests</span><span class=\"o\">.</span><span class=\"n\">post</span><span class=\"p\">(</span><span class=\"s1\">'http://localhost:4001/api/set_rules'</span><span class=\"p\">,</span> <span class=\"n\">json</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">rules</span><span class=\"p\">})</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">)</span>\n</pre>\n<p>These rules are then used at the following API endpoint</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">json</span>\n<span class=\"kn\">import</span> <span class=\"nn\">requests</span>\n\n<span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"s2\">\"Isaac Asimov was an American writer and professor of biochemistry at Boston University.\"</span>\n<span class=\"n\">triplets</span> <span class=\"o\">=</span> <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">loads</span><span class=\"p\">(</span><span class=\"n\">requests</span><span class=\"o\">.</span><span class=\"n\">post</span><span class=\"p\">(</span><span class=\"s1\">'http://localhost:4001/api/relations'</span><span class=\"p\">,</span> <span class=\"n\">json</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">text</span><span class=\"p\">})</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">triplets</span><span class=\"p\">)</span>\n</pre>\n<p>The Neo-Davidsonian representation API can be called with</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">json</span>\n<span class=\"kn\">import</span> <span class=\"nn\">requests</span>\n<span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"s2\">\"John is tall.\"</span>\n<span class=\"n\">graph</span> <span class=\"o\">=</span> <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">loads</span><span class=\"p\">(</span><span class=\"n\">requests</span><span class=\"o\">.</span><span class=\"n\">post</span><span class=\"p\">(</span><span class=\"s1\">'http://localhost:4001/api/drt'</span><span class=\"p\">,</span> <span class=\"n\">json</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">text</span><span class=\"p\">})</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">graph</span><span class=\"p\">)</span>\n</pre>\n<p>with output:</p>\n<pre><span class=\"p\">{</span><span class=\"s1\">'edges'</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"s1\">'arrows'</span><span class=\"p\">:</span> <span class=\"s1\">'to'</span><span class=\"p\">,</span> <span class=\"s1\">'from'</span><span class=\"p\">:</span> <span class=\"s1\">'v1'</span><span class=\"p\">,</span> <span class=\"s1\">'label'</span><span class=\"p\">:</span> <span class=\"s1\">'AGENT'</span><span class=\"p\">,</span> <span class=\"s1\">'to'</span><span class=\"p\">:</span> <span class=\"s1\">'v0'</span><span class=\"p\">},</span>\n                                       <span class=\"p\">{</span><span class=\"s1\">'arrows'</span><span class=\"p\">:</span> <span class=\"s1\">'to'</span><span class=\"p\">,</span> <span class=\"s1\">'from'</span><span class=\"p\">:</span> <span class=\"s1\">'v1'</span><span class=\"p\">,</span> <span class=\"s1\">'label'</span><span class=\"p\">:</span> <span class=\"s1\">'ADJECTIVE'</span><span class=\"p\">,</span> <span class=\"s1\">'to'</span><span class=\"p\">:</span> <span class=\"s1\">'v2'</span><span class=\"p\">}],</span>\n                             <span class=\"s1\">'nodes'</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"s1\">'id'</span><span class=\"p\">:</span> <span class=\"s1\">'v1'</span><span class=\"p\">,</span> <span class=\"s1\">'label'</span><span class=\"p\">:</span> <span class=\"s1\">'is'</span><span class=\"p\">},</span>\n                                       <span class=\"p\">{</span><span class=\"s1\">'id'</span><span class=\"p\">:</span> <span class=\"s1\">'v0'</span><span class=\"p\">,</span> <span class=\"s1\">'label'</span><span class=\"p\">:</span> <span class=\"s1\">'John'</span><span class=\"p\">},</span>\n                                       <span class=\"p\">{</span><span class=\"s1\">'id'</span><span class=\"p\">:</span> <span class=\"s1\">'v2'</span><span class=\"p\">,</span> <span class=\"s1\">'label'</span><span class=\"p\">:</span> <span class=\"s1\">'tall'</span><span class=\"p\">}]}</span>\n</pre>\n<h2>Pre-Formatting of the Text</h2>\n<p>The text must be submitted respecting the following rules:</p>\n<ul>\n<li>No parenthesis (...) nor brackets [...]. The parser is confused by those.</li>\n<li>The paragraphs must be separated by <em>1 empty line</em>. Dividing a text into paragraphs helps with anaphora.\n<pre>This is paragraph <span class=\"m\">1</span>.\n\nThis is paragraph <span class=\"m\">2</span>.\n</pre>\n</li>\n</ul>\n<h2>Known issues and shortcomings</h2>\n<ul>\n<li>Speed! Parsing is done one sentence at a time</li>\n<li>Anaphora only works inside paragraphs</li>\n<li>Anaphora is done through AllenNLP, with can be slow-ish without a GPU</li>\n<li>The text needs to be cleaned and pre-formatted. This is not an issue <em>per se</em> but it must be kept in mind</li>\n</ul>\n\n          </div>"}, "last_serial": 5494530, "releases": {"0.0.2": [{"comment_text": "", "digests": {"md5": "4b997b8209a0a6fc9220b270f3d7c754", "sha256": "e9ccf6be61116f64373f0225aa5a5f2cef3ff8d8dc88471ea223bcb04c2fa1f0"}, "downloads": -1, "filename": "pynsett-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "4b997b8209a0a6fc9220b270f3d7c754", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 24672, "upload_time": "2017-10-26T15:46:05", "upload_time_iso_8601": "2017-10-26T15:46:05.439099Z", "url": "https://files.pythonhosted.org/packages/50/a4/0be13fa774980d0b9f5411ca274c70e40d00e6aa6d61d87216fdc5dd0d6d/pynsett-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "50520e0dd49ab320d2a03bb7e0ed3c0b", "sha256": "8e185d9f5905b837d3a660a8b3c50311b8f6f94a9df01d307c45765710a49054"}, "downloads": -1, "filename": "pynsett-0.0.2.tar.gz", "has_sig": false, "md5_digest": "50520e0dd49ab320d2a03bb7e0ed3c0b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17093, "upload_time": "2017-10-26T15:46:07", "upload_time_iso_8601": "2017-10-26T15:46:07.634581Z", "url": "https://files.pythonhosted.org/packages/d6/94/a97e4cf7c20d8f3ae46e7df5e7e1d84d20a85ed0c556c311ae3ea08f22a3/pynsett-0.0.2.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "cdf76280af72a110f3ff12ecac20d4ab", "sha256": "914a9ad980ac5c44dd21684882dd854b476081a6066183dc0402b49aa05825f9"}, "downloads": -1, "filename": "pynsett-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "cdf76280af72a110f3ff12ecac20d4ab", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 24671, "upload_time": "2017-10-30T11:43:48", "upload_time_iso_8601": "2017-10-30T11:43:48.255107Z", "url": "https://files.pythonhosted.org/packages/75/ea/2991cdaac4beb5b26aa5d06dc55c1a91e32332c5509048ccebea986a37b6/pynsett-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b5ad436ae2766df35e4f9e540b831280", "sha256": "d2e69f93aeb4e67f892b5bf51345bfaa72633d78bad739d661a45788e9793e61"}, "downloads": -1, "filename": "pynsett-0.0.4.tar.gz", "has_sig": false, "md5_digest": "b5ad436ae2766df35e4f9e540b831280", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17098, "upload_time": "2017-10-30T11:43:51", "upload_time_iso_8601": "2017-10-30T11:43:51.201225Z", "url": "https://files.pythonhosted.org/packages/cd/e5/c988f4d7f3f29b56888bec7c6a6eca7f60f067abe39ab8f121cb3203f33e/pynsett-0.0.4.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "1ecb5ddaa5a6e5b71975de2cea78be35", "sha256": "922a75a35c6188d4c3108b6ad0e64227735c868d2d75dbd5af574b74cf22b4c9"}, "downloads": -1, "filename": "pynsett-0.0.6-py3-none-any.whl", "has_sig": false, "md5_digest": "1ecb5ddaa5a6e5b71975de2cea78be35", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 24708, "upload_time": "2017-10-30T14:12:52", "upload_time_iso_8601": "2017-10-30T14:12:52.079882Z", "url": "https://files.pythonhosted.org/packages/f2/54/9e9c588127f788f2c00ffcd044c40332d319ef5324611f438ad9ca1b5dd5/pynsett-0.0.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1452f2320fb6807b6b90977bb4eb7ca3", "sha256": "a4fce065d259f05359db60632eca572afa313181c14431a5a92628978a7461f8"}, "downloads": -1, "filename": "pynsett-0.0.6.tar.gz", "has_sig": false, "md5_digest": "1452f2320fb6807b6b90977bb4eb7ca3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17174, "upload_time": "2017-10-30T14:12:53", "upload_time_iso_8601": "2017-10-30T14:12:53.242781Z", "url": "https://files.pythonhosted.org/packages/5a/b7/de23601b88ed631f9f9773f6977ae94516f9ad9286824d96b2d1530f1d31/pynsett-0.0.6.tar.gz", "yanked": false}], "0.0.8": [{"comment_text": "", "digests": {"md5": "daa5a2dec71fdea59530c65121e9ee05", "sha256": "c72e6d2931f9beda557b6c853b66969e43b8df2428d698e25858c84ea9c1f1a8"}, "downloads": -1, "filename": "pynsett-0.0.8-py3-none-any.whl", "has_sig": false, "md5_digest": "daa5a2dec71fdea59530c65121e9ee05", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 30937, "upload_time": "2018-02-04T16:41:24", "upload_time_iso_8601": "2018-02-04T16:41:24.770037Z", "url": "https://files.pythonhosted.org/packages/24/dc/e2e87e41f2fdf2a3268812020f04b86655e1d1e0edf785495feff3a984a8/pynsett-0.0.8-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "90b678bf8c1e928ae4ba1a47173ac38c", "sha256": "87926b4e3a71b0fdb8273a156de640a317f8caeef2d5ef3391aeb0a596e0d2ef"}, "downloads": -1, "filename": "pynsett-0.0.8.tar.gz", "has_sig": false, "md5_digest": "90b678bf8c1e928ae4ba1a47173ac38c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20456, "upload_time": "2018-02-04T16:41:26", "upload_time_iso_8601": "2018-02-04T16:41:26.096827Z", "url": "https://files.pythonhosted.org/packages/9c/50/76ec911de6c2da2a1c7ff8a40a334487c57ede0b29395c2181cbf9ab72cd/pynsett-0.0.8.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "12b077ad3051182d8bc8aea95640b4c6", "sha256": "f77bfba5765770b7ab403de7e1b1502e947e29f8f175c36ba1c0fe86faf0421c"}, "downloads": -1, "filename": "pynsett-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "12b077ad3051182d8bc8aea95640b4c6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 42711, "upload_time": "2019-07-01T17:17:28", "upload_time_iso_8601": "2019-07-01T17:17:28.170947Z", "url": "https://files.pythonhosted.org/packages/c9/9e/480754598bc700bbd81ab2cd8464da66707c8a5dc3ed826d5dd6a76c52c0/pynsett-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cbc723202cfc29ebd7168f9b87a9d40e", "sha256": "51c4c4bac5d22aee858290f572232ae9bbe09c7173ecc67fb8d5514851b8e788"}, "downloads": -1, "filename": "pynsett-0.1.0.tar.gz", "has_sig": false, "md5_digest": "cbc723202cfc29ebd7168f9b87a9d40e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 26489, "upload_time": "2019-07-01T17:17:30", "upload_time_iso_8601": "2019-07-01T17:17:30.927177Z", "url": "https://files.pythonhosted.org/packages/e1/cb/9fa20e865ec5f4225cb62c481f7730aba962d8b5aea3f23afc062b5e0c41/pynsett-0.1.0.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "cfba3c29768992a38aff317a95748539", "sha256": "a5d7fa6f989654a58054a0a7ad38f2aae287add812bb409c5182f6796a06df42"}, "downloads": -1, "filename": "pynsett-0.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "cfba3c29768992a38aff317a95748539", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 42743, "upload_time": "2019-07-05T18:55:50", "upload_time_iso_8601": "2019-07-05T18:55:50.903301Z", "url": "https://files.pythonhosted.org/packages/08/9c/2d8628af1da586302c79dd63de0d3829ff3c4390aea965ed68146874ebc7/pynsett-0.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ee8008ccf36d11124525fb753242788b", "sha256": "eb214589f02f0b9eeb5342c7aa9a5bc36fb9456eca0c861567d4b3718730ce4e"}, "downloads": -1, "filename": "pynsett-0.1.2.tar.gz", "has_sig": false, "md5_digest": "ee8008ccf36d11124525fb753242788b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 26503, "upload_time": "2019-07-05T18:55:53", "upload_time_iso_8601": "2019-07-05T18:55:53.738354Z", "url": "https://files.pythonhosted.org/packages/ee/ea/e39d3b17b4f0b152b9810f57eeb9aa56e383cdc917e9e98432423d609b26/pynsett-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "7fcd7e799b990c56f817919f437279d6", "sha256": "a6c6ed2614beeffe6024d00d161fed60d86924cee7a31bdc9802707a64605887"}, "downloads": -1, "filename": "pynsett-0.1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "7fcd7e799b990c56f817919f437279d6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 51278, "upload_time": "2019-07-05T22:32:15", "upload_time_iso_8601": "2019-07-05T22:32:15.558109Z", "url": "https://files.pythonhosted.org/packages/c9/00/c1bdb48a809e2536d0e36ed923d80a5f2828e796b5c67a906a8e6b89cc60/pynsett-0.1.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e2786a2e286359fc8d9fbf8909bd4fcf", "sha256": "fdb5e73d6d6ea1695aa609edaad43a51bf8fea5cd7fb9134497ca7be334583a9"}, "downloads": -1, "filename": "pynsett-0.1.3.tar.gz", "has_sig": false, "md5_digest": "e2786a2e286359fc8d9fbf8909bd4fcf", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 35273, "upload_time": "2019-07-05T22:32:17", "upload_time_iso_8601": "2019-07-05T22:32:17.591088Z", "url": "https://files.pythonhosted.org/packages/cd/56/97e73267c683107a061f2390f23226d0d06b68f03dd87929ac9ffee50bf4/pynsett-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "d9fb36424bb5f35e1fd725d36a3e04fe", "sha256": "4469eca5c0ae1adeabe934f3278adc00c4aa1da74bba267ac659c3610887acfa"}, "downloads": -1, "filename": "pynsett-0.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "d9fb36424bb5f35e1fd725d36a3e04fe", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 51317, "upload_time": "2019-07-05T22:37:13", "upload_time_iso_8601": "2019-07-05T22:37:13.527550Z", "url": "https://files.pythonhosted.org/packages/d9/59/f951078fe951227d2dab7125e86448e0917bef3beffa789020fe628b3877/pynsett-0.1.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "41338d49d2115cc14b3f8c0b26c00339", "sha256": "76887012e8780ca3d5cf0cd4fcd22c4d464733d8de91bf1551497ea9f4e1d678"}, "downloads": -1, "filename": "pynsett-0.1.4.tar.gz", "has_sig": false, "md5_digest": "41338d49d2115cc14b3f8c0b26c00339", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 35230, "upload_time": "2019-07-05T22:37:15", "upload_time_iso_8601": "2019-07-05T22:37:15.094882Z", "url": "https://files.pythonhosted.org/packages/3f/3c/b2e58935e071d581b96351994285961e52dff61556314e20635f64816635/pynsett-0.1.4.tar.gz", "yanked": false}], "0.1.5": [{"comment_text": "", "digests": {"md5": "f73b7b0e406b454250c93acd7d3a6021", "sha256": "b2bd184684a9ca9933a1648590cec46400b179e0535b9014a1afee2ed5af9774"}, "downloads": -1, "filename": "pynsett-0.1.5-py3-none-any.whl", "has_sig": false, "md5_digest": "f73b7b0e406b454250c93acd7d3a6021", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 51305, "upload_time": "2019-07-05T22:43:19", "upload_time_iso_8601": "2019-07-05T22:43:19.688356Z", "url": "https://files.pythonhosted.org/packages/be/67/a98f200e0ddfaf54c6099591d9c2942b34c437b333598f998926fa40730b/pynsett-0.1.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3446f50f1c4ec95547da9ebca8f752c2", "sha256": "e3db5934eeb4060787edd7196c237ccae4cd1cbeecbcf11d5575ec27edf358bf"}, "downloads": -1, "filename": "pynsett-0.1.5.tar.gz", "has_sig": false, "md5_digest": "3446f50f1c4ec95547da9ebca8f752c2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 35240, "upload_time": "2019-07-05T22:43:21", "upload_time_iso_8601": "2019-07-05T22:43:21.604389Z", "url": "https://files.pythonhosted.org/packages/86/47/2e61ad37d43836d4e0bdf9c459c743fc82e2c4fde9f0af3e1c7b6d6bd4f1/pynsett-0.1.5.tar.gz", "yanked": false}], "0.1.6": [{"comment_text": "", "digests": {"md5": "d7ae96722c881e28de9df116debdb43b", "sha256": "05d5925f4c783a772c7b14435c2d4262f48e3a025312a4e6559e1123720e9d65"}, "downloads": -1, "filename": "pynsett-0.1.6-py3-none-any.whl", "has_sig": false, "md5_digest": "d7ae96722c881e28de9df116debdb43b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 57848, "upload_time": "2019-07-05T22:47:07", "upload_time_iso_8601": "2019-07-05T22:47:07.415979Z", "url": "https://files.pythonhosted.org/packages/b3/01/e92e5d11d7b89abc601903bf32c836e14ed3ecc519c4a0630df80a5965f7/pynsett-0.1.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "659ce7be30c9f5d2a1380905a5f77f7c", "sha256": "bd48517cd576ad16b4c0d33160f85682da9bbd11d9573bf6e8feda94bf18a8d6"}, "downloads": -1, "filename": "pynsett-0.1.6.tar.gz", "has_sig": false, "md5_digest": "659ce7be30c9f5d2a1380905a5f77f7c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 38509, "upload_time": "2019-07-05T22:47:09", "upload_time_iso_8601": "2019-07-05T22:47:09.323147Z", "url": "https://files.pythonhosted.org/packages/4c/15/774f69211ed86804d29f24d1fdb6762baa78af6b5441945d384ff41d98ea/pynsett-0.1.6.tar.gz", "yanked": false}], "0.1.7": [{"comment_text": "", "digests": {"md5": "d345bd934f28b09e0d958a891ba5f071", "sha256": "4bcd653b581d45341ac06e1772e5f2e213c84b30429150933ba41acf05c70f11"}, "downloads": -1, "filename": "pynsett-0.1.7-py3-none-any.whl", "has_sig": false, "md5_digest": "d345bd934f28b09e0d958a891ba5f071", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 63478, "upload_time": "2019-07-05T22:52:03", "upload_time_iso_8601": "2019-07-05T22:52:03.239886Z", "url": "https://files.pythonhosted.org/packages/2f/ca/b3f5cab5c67465f1a60aec625bd58cced5a994de043b3027dc82f01929e9/pynsett-0.1.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "79cce56408a334fdcca810396dd2902d", "sha256": "b6f68a54ef51422104b341517acb1dc32eb2ef70400a4aa9b86cd348de3355f4"}, "downloads": -1, "filename": "pynsett-0.1.7.tar.gz", "has_sig": false, "md5_digest": "79cce56408a334fdcca810396dd2902d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 40197, "upload_time": "2019-07-05T22:52:05", "upload_time_iso_8601": "2019-07-05T22:52:05.745158Z", "url": "https://files.pythonhosted.org/packages/df/12/353e611ad2390160f0d7e45325e08b0cb0d144ceedb80bd82a7062b6e3a0/pynsett-0.1.7.tar.gz", "yanked": false}], "0.1.8": [{"comment_text": "", "digests": {"md5": "c0711413682a99041af627c5cd6433d0", "sha256": "03a2347de92a933bd35905423cb0a322919da5e533700824e36d534ed073c519"}, "downloads": -1, "filename": "pynsett-0.1.8-py3-none-any.whl", "has_sig": false, "md5_digest": "c0711413682a99041af627c5cd6433d0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 66343, "upload_time": "2019-07-06T10:29:31", "upload_time_iso_8601": "2019-07-06T10:29:31.704587Z", "url": "https://files.pythonhosted.org/packages/09/ef/edab7ae9e1088e55c962727876ba7001318e83d07a0a42c271d5c483555b/pynsett-0.1.8-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "88dd14349daef9672d9c87f8d1ac5b3c", "sha256": "fef138037b24dd797717e78e9a76484a7f7acea3033c8527009d8665c55f4bdf"}, "downloads": -1, "filename": "pynsett-0.1.8.tar.gz", "has_sig": false, "md5_digest": "88dd14349daef9672d9c87f8d1ac5b3c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 43350, "upload_time": "2019-07-06T10:29:34", "upload_time_iso_8601": "2019-07-06T10:29:34.469562Z", "url": "https://files.pythonhosted.org/packages/26/c6/4f5f39dc8ecdd9109a4fd426d2d77389d58f8967b0e2e75d63ca333ab529/pynsett-0.1.8.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "c0711413682a99041af627c5cd6433d0", "sha256": "03a2347de92a933bd35905423cb0a322919da5e533700824e36d534ed073c519"}, "downloads": -1, "filename": "pynsett-0.1.8-py3-none-any.whl", "has_sig": false, "md5_digest": "c0711413682a99041af627c5cd6433d0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 66343, "upload_time": "2019-07-06T10:29:31", "upload_time_iso_8601": "2019-07-06T10:29:31.704587Z", "url": "https://files.pythonhosted.org/packages/09/ef/edab7ae9e1088e55c962727876ba7001318e83d07a0a42c271d5c483555b/pynsett-0.1.8-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "88dd14349daef9672d9c87f8d1ac5b3c", "sha256": "fef138037b24dd797717e78e9a76484a7f7acea3033c8527009d8665c55f4bdf"}, "downloads": -1, "filename": "pynsett-0.1.8.tar.gz", "has_sig": false, "md5_digest": "88dd14349daef9672d9c87f8d1ac5b3c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 43350, "upload_time": "2019-07-06T10:29:34", "upload_time_iso_8601": "2019-07-06T10:29:34.469562Z", "url": "https://files.pythonhosted.org/packages/26/c6/4f5f39dc8ecdd9109a4fd426d2d77389d58f8967b0e2e75d63ca333ab529/pynsett-0.1.8.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:01:01 2020"}