{"info": {"author": "Lukas \u0160alkauskas", "author_email": "halfas.online@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "# Soon\nWorker decorator for background tasks re-using [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ThreadPoolExecutor).\n\nInstallation\n------------\n\nSoon is conveniently available via pip:\n```\npip install soon\n```\n\nor installable via `git clone` and `setup.py`\n```\ngit clone git@github.com:dotpot/Soon.git\nsudo python setup.py install\n```\n\nTo ensure Soon is properly installed, you can run the unittest suite from the project root:\n```\npipenv run pytest -v \n```\n\nUsage\n-----\nThe Soon library enables you to utilize the benefits of multi-threading with minimal concern about the implementation details.\n\n\nWebsite fetcher example\n-----------------\nYou've collected a list of urls and are looking to download the HTML of the lot.  The following is a perfectly reasonable first stab at solving the task.\n\n```python\nurls = [\n    'https://cnn.com',\n    'https://news.ycombinator.com/',\n    'https://stackoverflow.com/',\n]\n```\n---\n```python\nimport time\nimport requests\n\ndef fetch(url):\n    return requests.get(url)\n\nif __name__ == \"__main__\":\n\n    start = time.time()\n    responses = [fetch(url) for url in urls]\n    html = [response.text for response in responses]\n    end = time.time()\n    print(\"Time: %f seconds\" % (end - start))\n```\n---\n\nMore efficient website fetcher example\n--------------------------\n\nUsing Soon's decorator syntax, we can define a function that executes in multiple threads.  Individual calls to `download` are non-blocking, but we can largely ignore this fact and write code identically to how we would in a synchronous paradigm. \n\n```python\nimport time\nimport requests\n\nfrom soon import workers\n\n@workers(5)\ndef fetch(url):\n    return requests.get(url)\n\nif __name__ == \"__main__\":\n    start = time.time()\n    responses = [fetch(url) for url in urls]\n    html = [response.text for response in responses]\n    end = time.time()\n    print(\"Time: %f seconds\" % (end - start))\n\n```\nWe can now download websites more efficiently.\n\n---\n\nYou can also optionally pass in `timeout` argument, to prevent hanging on a task that is not guaranteed to return.\n\n```python\nimport time\n\nfrom soon import workers\n\n@workers(1, timeout=0.1)\ndef timeout_error():\n    time.sleep(1)\n\nif __name__ == \"__main__\":\n    timeout_error()\n```\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/dotpot/soon", "keywords": "", "license": "MIT License (See LICENSE)", "maintainer": "", "maintainer_email": "", "name": "soon", "package_url": "https://pypi.org/project/soon/", "platform": "", "project_url": "https://pypi.org/project/soon/", "project_urls": {"Homepage": "https://github.com/dotpot/soon"}, "release_url": "https://pypi.org/project/soon/0.2/", "requires_dist": ["futures (>=2.2.0)"], "requires_python": ">=3.7.0", "summary": " Worker decorator for background tasks re-using ThreadPoolExecutor.", "version": "0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            # Soon<br>Worker decorator for background tasks re-using [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ThreadPoolExecutor).<br><br>Installation<br>------------<br><br>Soon is conveniently available via pip:<br>```<br>pip install soon<br>```<br><br>or installable via `git clone` and `setup.py`<br>```<br>git clone git@github.com:dotpot/Soon.git<br>sudo python setup.py install<br>```<br><br>To ensure Soon is properly installed, you can run the unittest suite from the project root:<br>```<br>pipenv run pytest -v <br>```<br><br>Usage<br>-----<br>The Soon library enables you to utilize the benefits of multi-threading with minimal concern about the implementation details.<br><br><br>Website fetcher example<br>-----------------<br>You've collected a list of urls and are looking to download the HTML of the lot.  The following is a perfectly reasonable first stab at solving the task.<br><br>```python<br>urls = [<br>    'https://cnn.com',<br>    'https://news.ycombinator.com/',<br>    'https://stackoverflow.com/',<br>]<br>```<br>---<br>```python<br>import time<br>import requests<br><br>def fetch(url):<br>    return requests.get(url)<br><br>if __name__ == \"__main__\":<br><br>    start = time.time()<br>    responses = [fetch(url) for url in urls]<br>    html = [response.text for response in responses]<br>    end = time.time()<br>    print(\"Time: %f seconds\" % (end - start))<br>```<br>---<br><br>More efficient website fetcher example<br>--------------------------<br><br>Using Soon's decorator syntax, we can define a function that executes in multiple threads.  Individual calls to `download` are non-blocking, but we can largely ignore this fact and write code identically to how we would in a synchronous paradigm. <br><br>```python<br>import time<br>import requests<br><br>from soon import workers<br><br>@workers(5)<br>def fetch(url):<br>    return requests.get(url)<br><br>if __name__ == \"__main__\":<br>    start = time.time()<br>    responses = [fetch(url) for url in urls]<br>    html = [response.text for response in responses]<br>    end = time.time()<br>    print(\"Time: %f seconds\" % (end - start))<br><br>```<br>We can now download websites more efficiently.<br><br>---<br><br>You can also optionally pass in `timeout` argument, to prevent hanging on a task that is not guaranteed to return.<br><br>```python<br>import time<br><br>from soon import workers<br><br>@workers(1, timeout=0.1)<br>def timeout_error():<br>    time.sleep(1)<br><br>if __name__ == \"__main__\":<br>    timeout_error()<br>```<br><br><br>\n          </div>"}, "last_serial": 4873472, "releases": {"0.2": [{"comment_text": "", "digests": {"md5": "d74b659358dd7f9fc709a4594df909e1", "sha256": "d605b605b73785af1a7f139c1e9c2e0b4020d1f4043027dff8e16c793ed89add"}, "downloads": -1, "filename": "soon-0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "d74b659358dd7f9fc709a4594df909e1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7.0", "size": 3566, "upload_time": "2019-02-27T10:05:14", "upload_time_iso_8601": "2019-02-27T10:05:14.220536Z", "url": "https://files.pythonhosted.org/packages/e5/6b/74adc4615cb3132dd78617d5455b9fd38d5a21d42134cf16aa47b1277032/soon-0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "021b90451a3355a56dae953fd3291961", "sha256": "36a465a5097248a485e8d332a3dc26dcf50298362df687dd3b7a7f214cc97727"}, "downloads": -1, "filename": "soon-0.2.tar.gz", "has_sig": false, "md5_digest": "021b90451a3355a56dae953fd3291961", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7.0", "size": 2575, "upload_time": "2019-02-27T10:05:15", "upload_time_iso_8601": "2019-02-27T10:05:15.552033Z", "url": "https://files.pythonhosted.org/packages/8a/2f/3b1cfc1024e72bd04761d3b4100c59776e882b3fedff48a13a869c45947b/soon-0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "d74b659358dd7f9fc709a4594df909e1", "sha256": "d605b605b73785af1a7f139c1e9c2e0b4020d1f4043027dff8e16c793ed89add"}, "downloads": -1, "filename": "soon-0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "d74b659358dd7f9fc709a4594df909e1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7.0", "size": 3566, "upload_time": "2019-02-27T10:05:14", "upload_time_iso_8601": "2019-02-27T10:05:14.220536Z", "url": "https://files.pythonhosted.org/packages/e5/6b/74adc4615cb3132dd78617d5455b9fd38d5a21d42134cf16aa47b1277032/soon-0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "021b90451a3355a56dae953fd3291961", "sha256": "36a465a5097248a485e8d332a3dc26dcf50298362df687dd3b7a7f214cc97727"}, "downloads": -1, "filename": "soon-0.2.tar.gz", "has_sig": false, "md5_digest": "021b90451a3355a56dae953fd3291961", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7.0", "size": 2575, "upload_time": "2019-02-27T10:05:15", "upload_time_iso_8601": "2019-02-27T10:05:15.552033Z", "url": "https://files.pythonhosted.org/packages/8a/2f/3b1cfc1024e72bd04761d3b4100c59776e882b3fedff48a13a869c45947b/soon-0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:06:35 2020"}