{"info": {"author": "haoxintong", "author_email": "haoxintongpku@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "# Gluon FR Toolkit\n[![Documentation Status](https://readthedocs.org/projects/gluon-face/badge/?version=latest)](https://gluon-face.readthedocs.io/en/latest/?badge=latest)\n\nGluonFR is a toolkit based on MXnet-Gluon, provides SOTA deep learning algorithm and models in face recognition.\n\n## Installation\nGluonFR supports Python 3.5 or later. \nTo install this package you need install GluonCV and MXNet first:\n```shell\npip install gluoncv --pre\npip install mxnet-mkl --pre --upgrade\n# if cuda XX is installed\npip install mxnet-cuXXmkl --pre --upgrade\n```\nThen install gluonfr:\n\n- From Source(recommend)\n\n```shell\npip install git+https://github.com/THUFutureLab/gluon-face.git@master\n```\n\n- Pip\n\n```shell\npip install gluonfr\n```\n\n## GluonFR Introduction:\nGluonFR is based on MXnet-Gluon, if you are new to it, please check out [dmlc 60-minute crash course](http://gluon-crash-course.mxnet.io/).\n\n#### Data: \nThis part provides input pipeline for training and validation, \nall datasets is aligned by mtcnn and cropped to (112, 112) by DeepInsight, \nthey converted images to `train.rec`, `train.idx` and `val_data.bin` files,  please check out \n[[insightface/Dataset-Zoo]](https://github.com/deepinsight/insightface/wiki/Dataset-Zoo) for more information. \nIn `data/dali_utils.py`, there is a simple example of Nvidia-DALI. It is worth trying when data augmentation with cpu \ncan not satisfy the speed of gpu training,  \n\nThe files should be prepared like:\n```\nface/\n    emore/\n        train.rec\n        train.idx\n        property\n    ms1m/\n        train.rec\n        train.idx\n        property\n    lfw.bin\n    agedb_30.bin\n    ...\n    vgg2_fp.bin\n```\nWe use `~/.mxnet/datasets` as default dataset root to match mxnet setting.\n\n#### [Model_Zoo](/wiki/Model_Zoo):\nmobile_facenet, res_attention_net, se_resnet... \n\n\n#### Loss:\nGluonFR provides implement of losses in recent, including SoftmaxCrossEntropyLoss, ArcLoss, TripletLoss, \nRingLoss, CosLoss, L2Softmax, ASoftmax, CenterLoss, ContrastiveLoss, ... , and we will keep updating in future.  \nIf there is any method we overlooked, please open an [issue](https://github.com/THUFutureLab/gluon-face/issues).\n\n#### Example:\n\n`examples/` shows how to use gluonfr to train a face recognition model, and how to get Mnist 2-D \nfeature embedding visualization.  \n  \n## Losses in GluonFR:  \n\nThe last column of this chart is the best LFW accuracy reported in paper, they are trained with different data and networks, \nlater we will give our results of these method with same train data and network. \n\n|Method| Paper |Visualization of MNIST|LFW|\n|:---|:---:| :---:|:---:|\n|Contrastive Loss|[ContrastiveLoss](http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf)|-|-|\n|Triplet|[1503.03832](https://arxiv.org/abs/1503.03832)|-|99.63\u00b10.09|\n|Center Loss|[CenterLoss](https://ydwen.github.io/papers/WenECCV16.pdf)|<img src=\"resources/mnist-euclidean/center-train-epoch100.png\"/>|99.28 |\n|L2-Softmax|[1703.09507](https://arxiv.org/abs/1703.09507)|-|99.33|\n|A-Softmax|[1704.08063](https://arxiv.org/abs/1704.08063)|-|99.42|\n|CosLoss/AMSoftmax|[1801.05599](https://arxiv.org/abs/1801.05599)/[1801.05599](https://arxiv.org/abs/1801.05599)|<img src=\"resources/minst-angular/cosloss-train-epoch95.png\"/>|99.17|\n|Arcloss|[1801.07698](https://arxiv.org/abs/1801.07698)|<img src=\"resources/minst-angular/arcloss-train-epoch100.png\"/>|99.82|\n|Ring loss|[1803.00130](https://arxiv.org/abs/1803.00130)|<img src=\"resources/mnist-euclidean/ringloss-train-epoch95-0.1.png\"/>|99.52|\n|LGM Loss|[1803.02988](https://arxiv.org/abs/1803.02988)|<img src=\"resources/mnist-euclidean/LGMloss-train-epoch100.png\"/>|99.20\u00b10.03|\n\n## Pretrained Models\nSee [Model Zoo](https://gluon-face.readthedocs.io/en/latest/model_zoo.html) in doc.\n\n## Todo\n\n- More pretrained models\n- IJB and Megaface Results\n- Other losses\n- Dataloader for loss depend on how to provide batches like Triplet, ContrastiveLoss, RangeLoss...\n- Try GluonCV resnetV1b/c/d/ to improve performance\n- ~~Create hosted docs~~\n- Test module\n- ~~Pypi package~~\n\n\n## Docs\n\nPlease checkout [link](https://gluon-face.readthedocs.io/en/latest/).  \nFor Chinese Version: [link](https://gluon-face.readthedocs.io/zh/latest/index.html) \n\n## Authors\n{ [haoxintong](https://github.com/haoxintong) [Yangxv](https://github.com/PistonY) [Haoyadong](https://github.com/jiqirenno1) [Sunhao](https://github.com/smartadpole) }\n\n## Discussion\n[\u4e2d\u6587\u793e\u533aGluon-Forum](https://discuss.gluon.ai/t/topic/9959) Feel free to use English here :D.\n\n## References\n\n1. MXNet Documentation and Tutorials [https://zh.diveintodeeplearning.org/](https://zh.diveintodeeplearning.org/)\n\n1. NVIDIA DALI documentation[NVIDIA DALI documentation](https://docs.nvidia.com/deeplearning/sdk/dali-developer-guide/docs/index.html)\n\n1. Deepinsight [insightface](https://github.com/deepinsight/insightface)", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/THUFutureLab/gluon-face", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "gluonfr", "package_url": "https://pypi.org/project/gluonfr/", "platform": "", "project_url": "https://pypi.org/project/gluonfr/", "project_urls": {"Homepage": "https://github.com/THUFutureLab/gluon-face"}, "release_url": "https://pypi.org/project/gluonfr/1.0.2/", "requires_dist": null, "requires_python": "", "summary": "Gluon FR Toolkit", "version": "1.0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Gluon FR Toolkit</h1>\n<p><a href=\"https://gluon-face.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fe6f2827f488b8a9cbda4da18fbdd9a1d40b0d11/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f676c756f6e2d666163652f62616467652f3f76657273696f6e3d6c6174657374\"></a></p>\n<p>GluonFR is a toolkit based on MXnet-Gluon, provides SOTA deep learning algorithm and models in face recognition.</p>\n<h2>Installation</h2>\n<p>GluonFR supports Python 3.5 or later.\nTo install this package you need install GluonCV and MXNet first:</p>\n<pre>pip install gluoncv --pre\npip install mxnet-mkl --pre --upgrade\n<span class=\"c1\"># if cuda XX is installed</span>\npip install mxnet-cuXXmkl --pre --upgrade\n</pre>\n<p>Then install gluonfr:</p>\n<ul>\n<li>From Source(recommend)</li>\n</ul>\n<pre>pip install git+https://github.com/THUFutureLab/gluon-face.git@master\n</pre>\n<ul>\n<li>Pip</li>\n</ul>\n<pre>pip install gluonfr\n</pre>\n<h2>GluonFR Introduction:</h2>\n<p>GluonFR is based on MXnet-Gluon, if you are new to it, please check out <a href=\"http://gluon-crash-course.mxnet.io/\" rel=\"nofollow\">dmlc 60-minute crash course</a>.</p>\n<h4>Data:</h4>\n<p>This part provides input pipeline for training and validation,\nall datasets is aligned by mtcnn and cropped to (112, 112) by DeepInsight,\nthey converted images to <code>train.rec</code>, <code>train.idx</code> and <code>val_data.bin</code> files,  please check out\n<a href=\"https://github.com/deepinsight/insightface/wiki/Dataset-Zoo\" rel=\"nofollow\">[insightface/Dataset-Zoo]</a> for more information.\nIn <code>data/dali_utils.py</code>, there is a simple example of Nvidia-DALI. It is worth trying when data augmentation with cpu\ncan not satisfy the speed of gpu training,</p>\n<p>The files should be prepared like:</p>\n<pre><code>face/\n    emore/\n        train.rec\n        train.idx\n        property\n    ms1m/\n        train.rec\n        train.idx\n        property\n    lfw.bin\n    agedb_30.bin\n    ...\n    vgg2_fp.bin\n</code></pre>\n<p>We use <code>~/.mxnet/datasets</code> as default dataset root to match mxnet setting.</p>\n<h4><a href=\"/wiki/Model_Zoo\" rel=\"nofollow\">Model_Zoo</a>:</h4>\n<p>mobile_facenet, res_attention_net, se_resnet...</p>\n<h4>Loss:</h4>\n<p>GluonFR provides implement of losses in recent, including SoftmaxCrossEntropyLoss, ArcLoss, TripletLoss,\nRingLoss, CosLoss, L2Softmax, ASoftmax, CenterLoss, ContrastiveLoss, ... , and we will keep updating in future.<br>\nIf there is any method we overlooked, please open an <a href=\"https://github.com/THUFutureLab/gluon-face/issues\" rel=\"nofollow\">issue</a>.</p>\n<h4>Example:</h4>\n<p><code>examples/</code> shows how to use gluonfr to train a face recognition model, and how to get Mnist 2-D\nfeature embedding visualization.</p>\n<h2>Losses in GluonFR:</h2>\n<p>The last column of this chart is the best LFW accuracy reported in paper, they are trained with different data and networks,\nlater we will give our results of these method with same train data and network.</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Method</th>\n<th align=\"center\">Paper</th>\n<th align=\"center\">Visualization of MNIST</th>\n<th align=\"center\">LFW</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">Contrastive Loss</td>\n<td align=\"center\"><a href=\"http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\" rel=\"nofollow\">ContrastiveLoss</a></td>\n<td align=\"center\">-</td>\n<td align=\"center\">-</td>\n</tr>\n<tr>\n<td align=\"left\">Triplet</td>\n<td align=\"center\"><a href=\"https://arxiv.org/abs/1503.03832\" rel=\"nofollow\">1503.03832</a></td>\n<td align=\"center\">-</td>\n<td align=\"center\">99.63\u00b10.09</td>\n</tr>\n<tr>\n<td align=\"left\">Center Loss</td>\n<td align=\"center\"><a href=\"https://ydwen.github.io/papers/WenECCV16.pdf\" rel=\"nofollow\">CenterLoss</a></td>\n<td align=\"center\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e92641d53b036413c4d3f9f2851e847465a4b95f/7265736f75726365732f6d6e6973742d6575636c696465616e2f63656e7465722d747261696e2d65706f63683130302e706e67\"></td>\n<td align=\"center\">99.28</td>\n</tr>\n<tr>\n<td align=\"left\">L2-Softmax</td>\n<td align=\"center\"><a href=\"https://arxiv.org/abs/1703.09507\" rel=\"nofollow\">1703.09507</a></td>\n<td align=\"center\">-</td>\n<td align=\"center\">99.33</td>\n</tr>\n<tr>\n<td align=\"left\">A-Softmax</td>\n<td align=\"center\"><a href=\"https://arxiv.org/abs/1704.08063\" rel=\"nofollow\">1704.08063</a></td>\n<td align=\"center\">-</td>\n<td align=\"center\">99.42</td>\n</tr>\n<tr>\n<td align=\"left\">CosLoss/AMSoftmax</td>\n<td align=\"center\"><a href=\"https://arxiv.org/abs/1801.05599\" rel=\"nofollow\">1801.05599</a>/<a href=\"https://arxiv.org/abs/1801.05599\" rel=\"nofollow\">1801.05599</a></td>\n<td align=\"center\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/57b8066df4be89e5ce86157b508dda94317707e4/7265736f75726365732f6d696e73742d616e67756c61722f636f736c6f73732d747261696e2d65706f636839352e706e67\"></td>\n<td align=\"center\">99.17</td>\n</tr>\n<tr>\n<td align=\"left\">Arcloss</td>\n<td align=\"center\"><a href=\"https://arxiv.org/abs/1801.07698\" rel=\"nofollow\">1801.07698</a></td>\n<td align=\"center\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d36f108f4e62bbefee7f6cc5e64f8f4ce52f03c1/7265736f75726365732f6d696e73742d616e67756c61722f6172636c6f73732d747261696e2d65706f63683130302e706e67\"></td>\n<td align=\"center\">99.82</td>\n</tr>\n<tr>\n<td align=\"left\">Ring loss</td>\n<td align=\"center\"><a href=\"https://arxiv.org/abs/1803.00130\" rel=\"nofollow\">1803.00130</a></td>\n<td align=\"center\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9611c619c4f8fe11474d11a438113dcc91706a9a/7265736f75726365732f6d6e6973742d6575636c696465616e2f72696e676c6f73732d747261696e2d65706f636839352d302e312e706e67\"></td>\n<td align=\"center\">99.52</td>\n</tr>\n<tr>\n<td align=\"left\">LGM Loss</td>\n<td align=\"center\"><a href=\"https://arxiv.org/abs/1803.02988\" rel=\"nofollow\">1803.02988</a></td>\n<td align=\"center\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6714d2b73ef279319ddf5f69d55e8955271be13d/7265736f75726365732f6d6e6973742d6575636c696465616e2f4c474d6c6f73732d747261696e2d65706f63683130302e706e67\"></td>\n<td align=\"center\">99.20\u00b10.03</td>\n</tr></tbody></table>\n<h2>Pretrained Models</h2>\n<p>See <a href=\"https://gluon-face.readthedocs.io/en/latest/model_zoo.html\" rel=\"nofollow\">Model Zoo</a> in doc.</p>\n<h2>Todo</h2>\n<ul>\n<li>More pretrained models</li>\n<li>IJB and Megaface Results</li>\n<li>Other losses</li>\n<li>Dataloader for loss depend on how to provide batches like Triplet, ContrastiveLoss, RangeLoss...</li>\n<li>Try GluonCV resnetV1b/c/d/ to improve performance</li>\n<li><del>Create hosted docs</del></li>\n<li>Test module</li>\n<li><del>Pypi package</del></li>\n</ul>\n<h2>Docs</h2>\n<p>Please checkout <a href=\"https://gluon-face.readthedocs.io/en/latest/\" rel=\"nofollow\">link</a>.<br>\nFor Chinese Version: <a href=\"https://gluon-face.readthedocs.io/zh/latest/index.html\" rel=\"nofollow\">link</a></p>\n<h2>Authors</h2>\n<p>{ <a href=\"https://github.com/haoxintong\" rel=\"nofollow\">haoxintong</a> <a href=\"https://github.com/PistonY\" rel=\"nofollow\">Yangxv</a> <a href=\"https://github.com/jiqirenno1\" rel=\"nofollow\">Haoyadong</a> <a href=\"https://github.com/smartadpole\" rel=\"nofollow\">Sunhao</a> }</p>\n<h2>Discussion</h2>\n<p><a href=\"https://discuss.gluon.ai/t/topic/9959\" rel=\"nofollow\">\u4e2d\u6587\u793e\u533aGluon-Forum</a> Feel free to use English here :D.</p>\n<h2>References</h2>\n<ol>\n<li>\n<p>MXNet Documentation and Tutorials <a href=\"https://zh.diveintodeeplearning.org/\" rel=\"nofollow\">https://zh.diveintodeeplearning.org/</a></p>\n</li>\n<li>\n<p>NVIDIA DALI documentation<a href=\"https://docs.nvidia.com/deeplearning/sdk/dali-developer-guide/docs/index.html\" rel=\"nofollow\">NVIDIA DALI documentation</a></p>\n</li>\n<li>\n<p>Deepinsight <a href=\"https://github.com/deepinsight/insightface\" rel=\"nofollow\">insightface</a></p>\n</li>\n</ol>\n\n          </div>"}, "last_serial": 5958063, "releases": {"1.0.1": [{"comment_text": "", "digests": {"md5": "2f3a05a87a884689f14658c8a55f6899", "sha256": "41989be55ade40682789281895035bb2e49341371d49a0f09531cc1c249df416"}, "downloads": -1, "filename": "gluonfr-1.0.1.tar.gz", "has_sig": false, "md5_digest": "2f3a05a87a884689f14658c8a55f6899", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 25956, "upload_time": "2019-03-07T08:02:49", "upload_time_iso_8601": "2019-03-07T08:02:49.962656Z", "url": "https://files.pythonhosted.org/packages/b8/3a/77af68708a9853586b8df6513e66d0151277c84596201017cfaf4e42bd33/gluonfr-1.0.1.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "6ec35b4f03151a5ab8fb9cbe55c1bc37", "sha256": "6223c6949964b9025da9d4203b0c71dd3e1c3e7000e244704c201384c7731120"}, "downloads": -1, "filename": "gluonfr-1.0.2.tar.gz", "has_sig": false, "md5_digest": "6ec35b4f03151a5ab8fb9cbe55c1bc37", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24189, "upload_time": "2019-10-11T02:39:47", "upload_time_iso_8601": "2019-10-11T02:39:47.036070Z", "url": "https://files.pythonhosted.org/packages/0b/9d/adb9669f1a97877afbcd766728349498ffe3b4239d1f80bfc6ecde569ee3/gluonfr-1.0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "6ec35b4f03151a5ab8fb9cbe55c1bc37", "sha256": "6223c6949964b9025da9d4203b0c71dd3e1c3e7000e244704c201384c7731120"}, "downloads": -1, "filename": "gluonfr-1.0.2.tar.gz", "has_sig": false, "md5_digest": "6ec35b4f03151a5ab8fb9cbe55c1bc37", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24189, "upload_time": "2019-10-11T02:39:47", "upload_time_iso_8601": "2019-10-11T02:39:47.036070Z", "url": "https://files.pythonhosted.org/packages/0b/9d/adb9669f1a97877afbcd766728349498ffe3b4239d1f80bfc6ecde569ee3/gluonfr-1.0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:56:27 2020"}