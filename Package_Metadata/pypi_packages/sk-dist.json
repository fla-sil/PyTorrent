{"info": {"author": "Ibotta Inc.", "author_email": "machine_learning@ibotta.com", "bugtrack_url": null, "classifiers": ["Intended Audience :: Developers", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Scientific/Engineering"], "description": "sk-dist: Distributed scikit-learn meta-estimators in PySpark\n============================================================\n\n|License| |Build Status| |PyPI Package| |Downloads| |Python Versions|\n\nWhat is it?\n-----------\n\n``sk-dist`` is a Python package for machine learning built on top of\n`scikit-learn <https://scikit-learn.org/stable/index.html>`__ and is\ndistributed under the `Apache 2.0 software\nlicense <https://github.com/Ibotta/sk-dist/blob/master/LICENSE>`__. The\n``sk-dist`` module can be thought of as \"distributed scikit-learn\" as\nits core functionality is to extend the ``scikit-learn`` built-in\n``joblib`` parallelization of meta-estimator training to\n`spark <https://spark.apache.org/>`__. A popular use case is the \nparallelization of grid search as shown here:\n\n\nCheck out the `blog post <https://medium.com/building-ibotta/train-sklearn-100x-faster-bec530fc1f45>`__ \nfor more information on the motivation and use cases of ``sk-dist``.\n\nMain Features\n-------------\n\n-  **Distributed Training** - ``sk-dist`` parallelizes the training of\n   ``scikit-learn`` meta-estimators with PySpark. This allows\n   distributed training of these estimators without any constraint on\n   the physical resources of any one machine. In all cases, spark\n   artifacts are automatically stripped from the fitted estimator. These\n   estimators can then be pickled and un-pickled for prediction tasks,\n   operating identically at predict time to their ``scikit-learn``\n   counterparts. Supported tasks are:\n\n   -  *Grid Search*: `Hyperparameter optimization\n      techniques <https://scikit-learn.org/stable/modules/grid_search.html>`__,\n      particularly\n      `GridSearchCV <https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV>`__\n      and\n      `RandomizedSeachCV <https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV>`__,\n      are distributed such that each parameter set candidate is trained\n      in parallel.\n   -  *Multiclass Strategies*: `Multiclass classification\n      strategies <https://scikit-learn.org/stable/modules/multiclass.html>`__,\n      particularly\n      `OneVsRestClassifier <https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html#sklearn.multiclass.OneVsRestClassifier>`__\n      and\n      `OneVsOneClassifier <https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsOneClassifier.html#sklearn.multiclass.OneVsOneClassifier>`__,\n      are distributed such that each binary probelm is trained in\n      parallel.\n   -  *Tree Ensembles*: `Decision tree\n      ensembles <https://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-trees>`__\n      for classification and regression, particularly\n      `RandomForest <https://scikit-learn.org/stable/modules/ensemble.html#random-forests>`__\n      and\n      `ExtraTrees <https://scikit-learn.org/stable/modules/ensemble.html#extremely-randomized-trees>`__,\n      are distributed such that each tree is trained in parallel.\n\n-  **Distributed Prediction** - ``sk-dist`` provides a prediction module\n   which builds `vectorized\n   UDFs <https://spark.apache.org/docs/latest/sql-pyspark-pandas-with-arrow.html#pandas-udfs-aka-vectorized-udfs>`__\n   for\n   `PySpark <https://spark.apache.org/docs/latest/api/python/index.html>`__\n   `DataFrames <https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame>`__\n   using fitted ``scikit-learn`` estimators. This distributes the\n   ``predict`` and ``predict_proba`` methods of ``scikit-learn``\n   estimators, enabling large scale prediction with ``scikit-learn``.\n-  **Feature Encoding** - ``sk-dist`` provides a flexible feature\n   encoding utility called ``Encoderizer`` which encodes mix-typed\n   feature spaces using either default behavior or user defined\n   customizable settings. It is particularly aimed at text features, but\n   it additionally handles numeric and dictionary type feature spaces.\n\nInstallation\n------------\n\nDependencies\n~~~~~~~~~~~~\n\n``sk-dist`` requires:\n\n-  `Python <https://www.python.org/>`__ (>= 3.5)\n-  `scikit-learn <https://scikit-learn.org/stable/>`__ (>=0.20.0)\n-  `pandas <https://pandas.pydata.org/>`__ (>=0.17.0)\n-  `numpy <https://www.numpy.org/>`__ \n-  `scipy <https://www.scipy.org/>`__ \n-  `joblib <https://joblib.readthedocs.io/en/latest/>`__ \n\nDependency Notes\n~~~~~~~~~~~~~~~~\n\n-  versions of ``numpy``, ``scipy`` and ``joblib`` that are compatible with any supported version of ``scikit-learn`` should be sufficient for ``sk-dist``\n- ``sk-dist`` is not supported with Python 2\n\nSpark Dependencies\n~~~~~~~~~~~~~~~~~~\n\nMost ``sk-dist`` functionality requires a spark installation as well as\nPySpark. Some functionality can run without spark, so spark related\ndependencies are not required. The connection between sk-dist and spark\nrelies solely on a ``sparkContext`` as an argument to various\n``sk-dist`` classes upon instantiation.\n\nA variety of spark configurations and setups will work. It is left up to\nthe user to configure their own spark setup. The testing suite runs\n``spark 2.3`` and ``spark 2.4``, though any ``spark 2.0+`` versions \nare expected to work.\n\nAdditional spark related dependecies are ``pyarrow``, which is used only\nfor ``skdist.predict`` functions. This uses vectorized pandas UDFs which\nrequire ``pyarrow>=0.8.0``. Depending on the spark version, it may be\nnecessary to set\n``spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")`` in the\nspark configuration.\n\nUser Installation\n~~~~~~~~~~~~~~~~~\n\nThe easiest way to install ``sk-dist`` is with ``pip``:\n\n::\n\n    pip install --upgrade sk-dist\n\nYou can also download the source code:\n\n::\n\n    git clone https://github.com/Ibotta/sk-dist.git\n\nTesting\n~~~~~~~\n\nWith ``pytest`` installed, you can run tests locally:\n\n::\n\n    pytest sk-dist\n\nExamples\n--------\n\nThe package contains numerous \n`examples <https://github.com/Ibotta/sk-dist/tree/master/examples>`__ \non how to use ``sk-dist`` in practice. Examples of note are:\n\n-  `Grid Search with XGBoost <https://github.com/Ibotta/sk-dist/blob/master/examples/search/xgb.py>`__\n-  `Spark ML Benchmark Comparison <https://github.com/Ibotta/sk-dist/blob/master/examples/search/spark_ml.py>`__\n-  `Encoderizer with 20 Newsgroups <https://github.com/Ibotta/sk-dist/blob/master/examples/encoder/basic_usage.py>`__\n-  `One-Vs-Rest vs One-Vs-One <https://github.com/Ibotta/sk-dist/blob/master/examples/multiclass/basic_usage.py>`__\n-  `Large Scale Sklearn Prediction with PySpark UDFs <https://github.com/Ibotta/sk-dist/blob/master/examples/predict/basic_usage.py>`_\n\nGradient Boosting\n-----------------\n\n``sk-dist`` has been tested with a number of popular gradient boosting packages that conform to the ``scikit-learn`` API. This \nincludes ``xgboost`` and ``catboost``. These will need to be installed in addition to ``sk-dist`` on all nodes of the spark \ncluster via a node bootstrap script. Version compatibility is left up to the user.\n\nSupport for ``lightgbm`` is not guaranteed, as it requires `additional installations <https://lightgbm.readthedocs.io/en/latest/Installation-Guide.html#linux>`__ on all \nnodes of the spark cluster. This may work given proper installation but has not beed tested with ``sk-dist``.\n\nBackground\n----------\n\nThe project was started at `Ibotta\nInc. <https://medium.com/building-ibotta>`__ on the machine learning\nteam and open sourced in 2019.\n\nIt is currently maintained by the machine learning team at Ibotta. Special\nthanks to those who contributed to ``sk-dist`` while it was initially\nin development at Ibotta:\n\n-  `Evan Harris <https://github.com/denver1117>`__\n-  `Nicole Woytarowicz <https://github.com/nicolele>`__\n-  `Mike Lewis <https://github.com/Mikelew88>`__\n-  `Bobby Crimi <https://github.com/rpcrimi>`__\n\n\n.. |License| image:: https://img.shields.io/badge/License-Apache%202.0-blue.svg\n   :target: https://opensource.org/licenses/Apache-2.0\n.. |Build Status| image:: https://travis-ci.org/Ibotta/sk-dist.png?branch=master\n   :target: https://travis-ci.org/Ibotta/sk-dist\n.. |PyPI Package| image:: https://badge.fury.io/py/sk-dist.svg\n   :target: https://pypi.org/project/sk-dist/\n.. |Downloads| image:: https://img.shields.io/pypi/dm/sk-dist\n   :target: https://pypi.org/project/sk-dist/\n.. |Python Versions| image:: https://img.shields.io/pypi/pyversions/sk-dist\n   :target: https://pypi.org/project/sk-dist/", "description_content_type": "", "docs_url": null, "download_url": "https://pypi.org/project/sk-dist/#files", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "Apache 2.0", "maintainer": "", "maintainer_email": "", "name": "sk-dist", "package_url": "https://pypi.org/project/sk-dist/", "platform": "", "project_url": "https://pypi.org/project/sk-dist/", "project_urls": {"Download": "https://pypi.org/project/sk-dist/#files", "Source Code": "https://github.com/Ibotta/sk-dist"}, "release_url": "https://pypi.org/project/sk-dist/0.1.8/", "requires_dist": null, "requires_python": ">=3.5", "summary": "Distributed scikit-learn meta-estimators with PySpark", "version": "0.1.8", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://opensource.org/licenses/Apache-2.0\" rel=\"nofollow\"><img alt=\"License\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b97ca76cf5d8fd16c7bc4731270e0bbe53df7aa1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d626c75652e737667\"></a> <a href=\"https://travis-ci.org/Ibotta/sk-dist\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0ba4ad9c8daabf860153a9084e49080238ee3edc/68747470733a2f2f7472617669732d63692e6f72672f49626f7474612f736b2d646973742e706e673f6272616e63683d6d6173746572\"></a> <a href=\"https://pypi.org/project/sk-dist/\" rel=\"nofollow\"><img alt=\"PyPI Package\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/16d63f6d202a8e18ef6bdeb0ffbdfd209dbfa5a8/68747470733a2f2f62616467652e667572792e696f2f70792f736b2d646973742e737667\"></a> <a href=\"https://pypi.org/project/sk-dist/\" rel=\"nofollow\"><img alt=\"Downloads\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3fd347bff316bbb3f0e9ea9bf4f699e0f2c85357/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f736b2d64697374\"></a> <a href=\"https://pypi.org/project/sk-dist/\" rel=\"nofollow\"><img alt=\"Python Versions\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/06928db3dd3080c02d88e06c14f6ebcc39469075/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f736b2d64697374\"></a></p>\n<div id=\"what-is-it\">\n<h2>What is it?</h2>\n<p><tt><span class=\"pre\">sk-dist</span></tt> is a Python package for machine learning built on top of\n<a href=\"https://scikit-learn.org/stable/index.html\" rel=\"nofollow\">scikit-learn</a> and is\ndistributed under the <a href=\"https://github.com/Ibotta/sk-dist/blob/master/LICENSE\" rel=\"nofollow\">Apache 2.0 software\nlicense</a>. The\n<tt><span class=\"pre\">sk-dist</span></tt> module can be thought of as \u201cdistributed scikit-learn\u201d as\nits core functionality is to extend the <tt><span class=\"pre\">scikit-learn</span></tt> built-in\n<tt>joblib</tt> parallelization of meta-estimator training to\n<a href=\"https://spark.apache.org/\" rel=\"nofollow\">spark</a>. A popular use case is the\nparallelization of grid search as shown here:</p>\n<p>Check out the <a href=\"https://medium.com/building-ibotta/train-sklearn-100x-faster-bec530fc1f45\" rel=\"nofollow\">blog post</a>\nfor more information on the motivation and use cases of <tt><span class=\"pre\">sk-dist</span></tt>.</p>\n</div>\n<div id=\"main-features\">\n<h2>Main Features</h2>\n<ul>\n<li><strong>Distributed Training</strong> - <tt><span class=\"pre\">sk-dist</span></tt> parallelizes the training of\n<tt><span class=\"pre\">scikit-learn</span></tt> meta-estimators with PySpark. This allows\ndistributed training of these estimators without any constraint on\nthe physical resources of any one machine. In all cases, spark\nartifacts are automatically stripped from the fitted estimator. These\nestimators can then be pickled and un-pickled for prediction tasks,\noperating identically at predict time to their <tt><span class=\"pre\">scikit-learn</span></tt>\ncounterparts. Supported tasks are:<ul>\n<li><em>Grid Search</em>: <a href=\"https://scikit-learn.org/stable/modules/grid_search.html\" rel=\"nofollow\">Hyperparameter optimization\ntechniques</a>,\nparticularly\n<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV\" rel=\"nofollow\">GridSearchCV</a>\nand\n<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV\" rel=\"nofollow\">RandomizedSeachCV</a>,\nare distributed such that each parameter set candidate is trained\nin parallel.</li>\n<li><em>Multiclass Strategies</em>: <a href=\"https://scikit-learn.org/stable/modules/multiclass.html\" rel=\"nofollow\">Multiclass classification\nstrategies</a>,\nparticularly\n<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html#sklearn.multiclass.OneVsRestClassifier\" rel=\"nofollow\">OneVsRestClassifier</a>\nand\n<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsOneClassifier.html#sklearn.multiclass.OneVsOneClassifier\" rel=\"nofollow\">OneVsOneClassifier</a>,\nare distributed such that each binary probelm is trained in\nparallel.</li>\n<li><em>Tree Ensembles</em>: <a href=\"https://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-trees\" rel=\"nofollow\">Decision tree\nensembles</a>\nfor classification and regression, particularly\n<a href=\"https://scikit-learn.org/stable/modules/ensemble.html#random-forests\" rel=\"nofollow\">RandomForest</a>\nand\n<a href=\"https://scikit-learn.org/stable/modules/ensemble.html#extremely-randomized-trees\" rel=\"nofollow\">ExtraTrees</a>,\nare distributed such that each tree is trained in parallel.</li>\n</ul>\n</li>\n<li><strong>Distributed Prediction</strong> - <tt><span class=\"pre\">sk-dist</span></tt> provides a prediction module\nwhich builds <a href=\"https://spark.apache.org/docs/latest/sql-pyspark-pandas-with-arrow.html#pandas-udfs-aka-vectorized-udfs\" rel=\"nofollow\">vectorized\nUDFs</a>\nfor\n<a href=\"https://spark.apache.org/docs/latest/api/python/index.html\" rel=\"nofollow\">PySpark</a>\n<a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame\" rel=\"nofollow\">DataFrames</a>\nusing fitted <tt><span class=\"pre\">scikit-learn</span></tt> estimators. This distributes the\n<tt>predict</tt> and <tt>predict_proba</tt> methods of <tt><span class=\"pre\">scikit-learn</span></tt>\nestimators, enabling large scale prediction with <tt><span class=\"pre\">scikit-learn</span></tt>.</li>\n<li><strong>Feature Encoding</strong> - <tt><span class=\"pre\">sk-dist</span></tt> provides a flexible feature\nencoding utility called <tt>Encoderizer</tt> which encodes mix-typed\nfeature spaces using either default behavior or user defined\ncustomizable settings. It is particularly aimed at text features, but\nit additionally handles numeric and dictionary type feature spaces.</li>\n</ul>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<div id=\"dependencies\">\n<h3>Dependencies</h3>\n<p><tt><span class=\"pre\">sk-dist</span></tt> requires:</p>\n<ul>\n<li><a href=\"https://www.python.org/\" rel=\"nofollow\">Python</a> (&gt;= 3.5)</li>\n<li><a href=\"https://scikit-learn.org/stable/\" rel=\"nofollow\">scikit-learn</a> (&gt;=0.20.0)</li>\n<li><a href=\"https://pandas.pydata.org/\" rel=\"nofollow\">pandas</a> (&gt;=0.17.0)</li>\n<li><a href=\"https://www.numpy.org/\" rel=\"nofollow\">numpy</a></li>\n<li><a href=\"https://www.scipy.org/\" rel=\"nofollow\">scipy</a></li>\n<li><a href=\"https://joblib.readthedocs.io/en/latest/\" rel=\"nofollow\">joblib</a></li>\n</ul>\n</div>\n<div id=\"dependency-notes\">\n<h3>Dependency Notes</h3>\n<ul>\n<li>versions of <tt>numpy</tt>, <tt>scipy</tt> and <tt>joblib</tt> that are compatible with any supported version of <tt><span class=\"pre\">scikit-learn</span></tt> should be sufficient for <tt><span class=\"pre\">sk-dist</span></tt></li>\n<li><tt><span class=\"pre\">sk-dist</span></tt> is not supported with Python 2</li>\n</ul>\n</div>\n<div id=\"spark-dependencies\">\n<h3>Spark Dependencies</h3>\n<p>Most <tt><span class=\"pre\">sk-dist</span></tt> functionality requires a spark installation as well as\nPySpark. Some functionality can run without spark, so spark related\ndependencies are not required. The connection between sk-dist and spark\nrelies solely on a <tt>sparkContext</tt> as an argument to various\n<tt><span class=\"pre\">sk-dist</span></tt> classes upon instantiation.</p>\n<p>A variety of spark configurations and setups will work. It is left up to\nthe user to configure their own spark setup. The testing suite runs\n<tt>spark 2.3</tt> and <tt>spark 2.4</tt>, though any <tt>spark 2.0+</tt> versions\nare expected to work.</p>\n<p>Additional spark related dependecies are <tt>pyarrow</tt>, which is used only\nfor <tt>skdist.predict</tt> functions. This uses vectorized pandas UDFs which\nrequire <tt><span class=\"pre\">pyarrow&gt;=0.8.0</span></tt>. Depending on the spark version, it may be\nnecessary to set\n<tt><span class=\"pre\">spark.conf.set(\"spark.sql.execution.arrow.enabled\",</span> \"true\")</tt> in the\nspark configuration.</p>\n</div>\n<div id=\"user-installation\">\n<h3>User Installation</h3>\n<p>The easiest way to install <tt><span class=\"pre\">sk-dist</span></tt> is with <tt>pip</tt>:</p>\n<pre>pip install --upgrade sk-dist\n</pre>\n<p>You can also download the source code:</p>\n<pre>git clone https://github.com/Ibotta/sk-dist.git\n</pre>\n</div>\n<div id=\"testing\">\n<h3>Testing</h3>\n<p>With <tt>pytest</tt> installed, you can run tests locally:</p>\n<pre>pytest sk-dist\n</pre>\n</div>\n</div>\n<div id=\"examples\">\n<h2>Examples</h2>\n<p>The package contains numerous\n<a href=\"https://github.com/Ibotta/sk-dist/tree/master/examples\" rel=\"nofollow\">examples</a>\non how to use <tt><span class=\"pre\">sk-dist</span></tt> in practice. Examples of note are:</p>\n<ul>\n<li><a href=\"https://github.com/Ibotta/sk-dist/blob/master/examples/search/xgb.py\" rel=\"nofollow\">Grid Search with XGBoost</a></li>\n<li><a href=\"https://github.com/Ibotta/sk-dist/blob/master/examples/search/spark_ml.py\" rel=\"nofollow\">Spark ML Benchmark Comparison</a></li>\n<li><a href=\"https://github.com/Ibotta/sk-dist/blob/master/examples/encoder/basic_usage.py\" rel=\"nofollow\">Encoderizer with 20 Newsgroups</a></li>\n<li><a href=\"https://github.com/Ibotta/sk-dist/blob/master/examples/multiclass/basic_usage.py\" rel=\"nofollow\">One-Vs-Rest vs One-Vs-One</a></li>\n<li><a href=\"https://github.com/Ibotta/sk-dist/blob/master/examples/predict/basic_usage.py\" rel=\"nofollow\">Large Scale Sklearn Prediction with PySpark UDFs</a></li>\n</ul>\n</div>\n<div id=\"gradient-boosting\">\n<h2>Gradient Boosting</h2>\n<p><tt><span class=\"pre\">sk-dist</span></tt> has been tested with a number of popular gradient boosting packages that conform to the <tt><span class=\"pre\">scikit-learn</span></tt> API. This\nincludes <tt>xgboost</tt> and <tt>catboost</tt>. These will need to be installed in addition to <tt><span class=\"pre\">sk-dist</span></tt> on all nodes of the spark\ncluster via a node bootstrap script. Version compatibility is left up to the user.</p>\n<p>Support for <tt>lightgbm</tt> is not guaranteed, as it requires <a href=\"https://lightgbm.readthedocs.io/en/latest/Installation-Guide.html#linux\" rel=\"nofollow\">additional installations</a> on all\nnodes of the spark cluster. This may work given proper installation but has not beed tested with <tt><span class=\"pre\">sk-dist</span></tt>.</p>\n</div>\n<div id=\"background\">\n<h2>Background</h2>\n<p>The project was started at <a href=\"https://medium.com/building-ibotta\" rel=\"nofollow\">Ibotta\nInc.</a> on the machine learning\nteam and open sourced in 2019.</p>\n<p>It is currently maintained by the machine learning team at Ibotta. Special\nthanks to those who contributed to <tt><span class=\"pre\">sk-dist</span></tt> while it was initially\nin development at Ibotta:</p>\n<ul>\n<li><a href=\"https://github.com/denver1117\" rel=\"nofollow\">Evan Harris</a></li>\n<li><a href=\"https://github.com/nicolele\" rel=\"nofollow\">Nicole Woytarowicz</a></li>\n<li><a href=\"https://github.com/Mikelew88\" rel=\"nofollow\">Mike Lewis</a></li>\n<li><a href=\"https://github.com/rpcrimi\" rel=\"nofollow\">Bobby Crimi</a></li>\n</ul>\n</div>\n\n          </div>"}, "last_serial": 6460094, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "d535c9583b4302a413c4c0b1833fa734", "sha256": "57fcc269f71263dca7053232583f802893ef838dc45c5584cefd091ef470ca04"}, "downloads": -1, "filename": "sk-dist-0.1.0.tar.gz", "has_sig": false, "md5_digest": "d535c9583b4302a413c4c0b1833fa734", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 30510, "upload_time": "2019-08-28T15:51:50", "upload_time_iso_8601": "2019-08-28T15:51:50.411673Z", "url": "https://files.pythonhosted.org/packages/de/42/55b1347436452cf2bb68c2fa411aa346f40323de8e4f2b3bdda3b4b614bd/sk-dist-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "d967dcbc6bdca4d561b97cb55b9a2e4f", "sha256": "df75389b9dd06ec2f6384073e27e19b0e372be6f2a1e96d607ba9e73ddedb908"}, "downloads": -1, "filename": "sk-dist-0.1.1.tar.gz", "has_sig": false, "md5_digest": "d967dcbc6bdca4d561b97cb55b9a2e4f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 33186, "upload_time": "2019-09-16T16:05:28", "upload_time_iso_8601": "2019-09-16T16:05:28.869673Z", "url": "https://files.pythonhosted.org/packages/85/29/b4b6e3c4008db35e966b91002686c63022f610aa2078f459dfa02522a132/sk-dist-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "e01317ba15977a3850fec387cb7a266c", "sha256": "6dc9d049c7cc598a89ae505c1aa2ad5e6759fd4fbb3944856188a14d40bed553"}, "downloads": -1, "filename": "sk-dist-0.1.2.tar.gz", "has_sig": false, "md5_digest": "e01317ba15977a3850fec387cb7a266c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 34482, "upload_time": "2019-09-17T22:47:30", "upload_time_iso_8601": "2019-09-17T22:47:30.038104Z", "url": "https://files.pythonhosted.org/packages/aa/aa/c691edb73201430bb1a4f371e0dcbb7492fea788ce5e9a7f62a5a59b24ff/sk-dist-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "93bad74aa9d11bf9919c9a6bda494354", "sha256": "bed78afd84ce81238fb35d28db367c9a0df661e0413cb448cf87550b354517d4"}, "downloads": -1, "filename": "sk-dist-0.1.3.tar.gz", "has_sig": false, "md5_digest": "93bad74aa9d11bf9919c9a6bda494354", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 38544, "upload_time": "2019-10-07T16:57:30", "upload_time_iso_8601": "2019-10-07T16:57:30.827241Z", "url": "https://files.pythonhosted.org/packages/b4/a9/3dd403721701aa37550cf619f4cedfaa3da87bcb8abe00cb40050ecdd24a/sk-dist-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "9e6b986f928b7cca101c33a3a62d3518", "sha256": "2ac7db394e1ff5a405a2933104d2d5376b7990fd937503970074a1596bacca73"}, "downloads": -1, "filename": "sk-dist-0.1.4.tar.gz", "has_sig": false, "md5_digest": "9e6b986f928b7cca101c33a3a62d3518", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 38740, "upload_time": "2019-10-07T21:46:23", "upload_time_iso_8601": "2019-10-07T21:46:23.122835Z", "url": "https://files.pythonhosted.org/packages/dc/e5/73f91dc489b7b1336c00bcca25f8a4b3e8e41457b6ddf61671f734e52875/sk-dist-0.1.4.tar.gz", "yanked": false}], "0.1.5": [{"comment_text": "", "digests": {"md5": "5c5db9ac4d460a2dd6b817c5aaa804b5", "sha256": "c642347a4fb9b941a45aa97b05fafe7fbf2abf79937d2e19564c094923610cdf"}, "downloads": -1, "filename": "sk-dist-0.1.5.tar.gz", "has_sig": false, "md5_digest": "5c5db9ac4d460a2dd6b817c5aaa804b5", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 40849, "upload_time": "2019-10-09T19:21:47", "upload_time_iso_8601": "2019-10-09T19:21:47.065869Z", "url": "https://files.pythonhosted.org/packages/be/4d/0d9ffb4ce3b43de3f0db2fc03c7e8d664285f537d4b657c86805aef8578d/sk-dist-0.1.5.tar.gz", "yanked": false}], "0.1.6": [{"comment_text": "", "digests": {"md5": "241f630f7c9a6d1632cd9ace53eb0bd2", "sha256": "5c62c932c82684a457689a358146024b2738ef53ef794736ca5ce7f42fab4a75"}, "downloads": -1, "filename": "sk-dist-0.1.6.tar.gz", "has_sig": false, "md5_digest": "241f630f7c9a6d1632cd9ace53eb0bd2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 40867, "upload_time": "2019-12-04T20:49:54", "upload_time_iso_8601": "2019-12-04T20:49:54.931932Z", "url": "https://files.pythonhosted.org/packages/f9/d5/33dcec2dd609eb3723ee6026668f4dbae246ae3edf64854f3f4f6a76371d/sk-dist-0.1.6.tar.gz", "yanked": false}], "0.1.7": [{"comment_text": "", "digests": {"md5": "d32d5bf1e5f1e97310f46f09797c8ddb", "sha256": "e6a8d28d72d445e8a804be799c8ea0b650d11e338830f045b6d4381ac4ecbab3"}, "downloads": -1, "filename": "sk-dist-0.1.7.tar.gz", "has_sig": false, "md5_digest": "d32d5bf1e5f1e97310f46f09797c8ddb", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 41058, "upload_time": "2020-01-12T21:21:50", "upload_time_iso_8601": "2020-01-12T21:21:50.455329Z", "url": "https://files.pythonhosted.org/packages/49/93/e2ee4ed9c0315e4c919d5db9bae54526963a43ed8e1eaf7dc71c5fabbc06/sk-dist-0.1.7.tar.gz", "yanked": false}], "0.1.8": [{"comment_text": "", "digests": {"md5": "6a0a5aae03e2cce30f0c9f38455ad936", "sha256": "aaa63febe6979c83114ab7b55708e77d592e1ae68d9ba19ca8080b420e19d559"}, "downloads": -1, "filename": "sk-dist-0.1.8.tar.gz", "has_sig": false, "md5_digest": "6a0a5aae03e2cce30f0c9f38455ad936", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 41232, "upload_time": "2020-01-15T16:29:20", "upload_time_iso_8601": "2020-01-15T16:29:20.865521Z", "url": "https://files.pythonhosted.org/packages/b5/1c/fb4be82866a81e0a04c91ef8db43288db1a38df89cc96425296a98dacb52/sk-dist-0.1.8.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "6a0a5aae03e2cce30f0c9f38455ad936", "sha256": "aaa63febe6979c83114ab7b55708e77d592e1ae68d9ba19ca8080b420e19d559"}, "downloads": -1, "filename": "sk-dist-0.1.8.tar.gz", "has_sig": false, "md5_digest": "6a0a5aae03e2cce30f0c9f38455ad936", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 41232, "upload_time": "2020-01-15T16:29:20", "upload_time_iso_8601": "2020-01-15T16:29:20.865521Z", "url": "https://files.pythonhosted.org/packages/b5/1c/fb4be82866a81e0a04c91ef8db43288db1a38df89cc96425296a98dacb52/sk-dist-0.1.8.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:09:09 2020"}