{"info": {"author": "Quan Wang", "author_email": "quanw@google.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: Apache Software License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# UIS-RNN [![Build Status](https://travis-ci.org/google/uis-rnn.svg?branch=master)](https://travis-ci.org/google/uis-rnn) [![PyPI Version](https://img.shields.io/pypi/v/uisrnn.svg)](https://pypi.python.org/pypi/uisrnn) [![Python Versions](https://img.shields.io/pypi/pyversions/uisrnn.svg)](https://pypi.org/project/uisrnn) [![codecov](https://codecov.io/gh/google/uis-rnn/branch/master/graph/badge.svg)](https://codecov.io/gh/google/uis-rnn) [![Documentation](https://img.shields.io/badge/api-documentation-blue.svg)](https://google.github.io/uis-rnn)\n\n## Overview\n\nThis is the library for the\n*Unbounded Interleaved-State Recurrent Neural Network (UIS-RNN)* algorithm.\nUIS-RNN solves the problem of segmenting and clustering sequential data\nby learning from examples.\n\nThis algorithm was originally proposed in the paper\n[Fully Supervised Speaker Diarization](https://arxiv.org/abs/1810.04719).\n\nThe work has been introduced by\n[Google AI Blog](https://ai.googleblog.com/2018/11/accurate-online-speaker-diarization.html).\n\n![gif](https://raw.githubusercontent.com/google/uis-rnn/master/resources/uisrnn.gif)\n\n## Disclaimer\n\nThis open source implementation is slightly different than the internal one\nwhich we used to produce the results in the\n[paper](https://arxiv.org/abs/1810.04719), due to dependencies on\nsome internal libraries.\n\nWe CANNOT share the data, code, or model for the speaker recognition system\n([d-vector embeddings](https://google.github.io/speaker-id/publications/GE2E/))\nused in the paper, since the speaker recognition system\nheavily depends on Google's internal infrastructure and proprietary data.\n\n**This library is NOT an official Google product.**\n\nWe welcome community contributions ([guidelines](CONTRIBUTING.md))\nto the [`uisrnn/contrib`](uisrnn/contrib) folder.\nBut we won't be responsible for the correctness of any community contributions.\n\n## Dependencies\n\nThis library depends on:\n\n* python 3.5+\n* numpy 1.15.1\n* pytorch 1.3.0\n* scipy 1.1.0 (for evaluation only)\n\n## Getting Started\n\n[![YouTube](resources/YouTube_lecture_screenshot.png)](https://www.youtube.com/watch?v=pGkqwRPzx9U)\n\n### Install the package\n\nWithout downloading the repository, you can install the\n[package](https://pypi.org/project/uisrnn/) by:\n\n```\npip3 install uisrnn\n```\n\nor\n\n```\npython3 -m pip install uisrnn\n```\n\n### Run the demo\n\nTo get started, simply run this command:\n\n```bash\npython3 demo.py --train_iteration=1000 -l=0.001\n```\n\nThis will train a UIS-RNN model using `data/toy_training_data.npz`,\nthen store the model on disk, perform inference on `data/toy_testing_data.npz`,\nprint the inference results, and save the averaged accuracy in a text file.\n\nPS. The files under `data/` are manually generated *toy data*,\nfor demonstration purpose only.\nThese data are very simple, so we are supposed to get 100% accuracy on the\ntesting data.\n\n### Run the tests\n\nYou can also verify the correctness of this library by running:\n\n```bash\nbash run_tests.sh\n```\n\nIf you fork this library and make local changes, be sure to use these tests\nas a sanity check.\n\nBesides, these tests are also great examples for learning\nthe APIs, especially `tests/integration_test.py`.\n\n## Core APIs\n\n### Glossary\n\n| General Machine Learning | Speaker Diarization    |\n|--------------------------|------------------------|\n| Sequence                 | Utterance              |\n| Observation / Feature    | Embedding / d-vector   |\n| Label / Cluster ID       | Speaker                |\n\n### Arguments\n\nIn your main script, call this function to get the arguments:\n\n```python\nmodel_args, training_args, inference_args = uisrnn.parse_arguments()\n```\n\n### Model construction\n\nAll algorithms are implemented as the `UISRNN` class. First, construct a\n`UISRNN` object by:\n\n```python\nmodel = uisrnn.UISRNN(args)\n```\n\nThe definitions of the args are described in `uisrnn/arguments.py`.\nSee `model_parser`.\n\n### Training\n\nNext, train the model by calling the `fit()` function:\n\n```python\nmodel.fit(train_sequences, train_cluster_ids, args)\n```\n\nThe definitions of the args are described in `uisrnn/arguments.py`.\nSee `training_parser`.\n\nThe `fit()` function accepts two types of input, as described below.\n\n#### Input as list of sequences (recommanded)\n\nHere, `train_sequences` is a list of observation sequences.\nEach observation sequence is a 2-dim numpy array of type `float`.\n\n* The first dimension is the length of this sequence. And the length\n  can vary from one sequence to another.\n* The second dimension is the size of each observation. This\n  must be consistent among all sequences. For speaker diarization,\n  the observation could be the\n  [d-vector embeddings](https://google.github.io/speaker-id/publications/GE2E/).\n\n`train_cluster_ids` is also a list, which has the same length as\n`train_sequences`. Each element of `train_cluster_ids` is a 1-dim list or\nnumpy array of strings, containing the ground truth labels for the\ncorresponding sequence in `train_sequences`.\nFor speaker diarization, these labels are the speaker identifiers for each\nobservation.\n\nWhen calling `fit()` in this way, please be very careful with the argument\n`--enforce_cluster_id_uniqueness`.\n\nFor example, assume:\n\n```python\ntrain_cluster_ids = [['a', 'b'], ['a', 'c']]\n```\n\nIf the label `'a'` from the two sequences refers to the same cluster across\nthe entire dataset, then we should have `enforce_cluster_id_uniqueness=False`;\notherwise, if `'a'` is only a local indicator to distinguish from `'b'` in the\n1st sequence, and to distinguish from `'c'` in the 2nd sequence, then we should\nhave `enforce_cluster_id_uniqueness=True`.\n\nAlso, please note that, when calling `fit()` in this way, we are going to\nconcatenate all sequences and all cluster IDs, and delegate to\nthe next section below.\n\n#### Input as single concatenated sequence\n\nHere, `train_sequences` should be a single 2-dim numpy array of type `float`,\nfor the **concatenated** observation sequences.\n\nFor example, if you have *M* training utterances,\nand each utterance is a sequence of *L* embeddings. Each embedding is\na vector of *D* numbers. Then the shape of `train_sequences` is *N * D*,\nwhere *N = M * L*.\n\n`train_cluster_ids` is a 1-dim list or numpy array of strings, of length *N*.\nIt is the **concatenated** ground truth labels of all training data.\n\nSince we are concatenating observation sequences, it is important to note that,\nground truth labels in `train_cluster_id` across different sequences are\nsupposed to be **globally unique**.\n\nFor example, if the set of labels in the first\nsequence is `{'A', 'B', 'C'}`, and the set of labels in the second sequence\nis `{'B', 'C', 'D'}`. Then before concatenation, we should rename them to\nsomething like `{'1_A', '1_B', '1_C'}` and `{'2_B', '2_C', '2_D'}`,\nunless `'B'` and `'C'` in the two sequences are meaningfully identical\n(in speaker diarization, this means they are the same speakers across\nutterances). This part will be automatically taken care of by the argument\n`--enforce_cluster_id_uniqueness` for the previous section.\n\nThe reason we concatenate all training sequences is that, we will be resampling\nand *block-wise* shuffling the training data as a **data augmentation**\nprocess, such that we result in a robust model even when there is insufficient\nnumber of training sequences.\n\n#### Training on large datasets\n\nFor large datasets, the data usually could not be loaded into memory at once.\nIn such cases, the `fit()` function needs to be called multiple times.\n\nHere we provide a few guidelines as our suggestions:\n\n1. Do not feed different datasets into different calls of `fit()`. Instead,\n   for each call of `fit()`, the input should cover sequences from\n   different datasets.\n2. For each call to the `fit()` function, make the size of input roughly the\n   same. And, don't make the input size too small.\n\n### Prediction\n\nOnce we are done with training, we can run the trained model to perform\ninference on new sequences by calling the `predict()` function:\n\n```python\npredicted_cluster_ids = model.predict(test_sequences, args)\n```\n\nHere `test_sequences` should be a list of 2-dim numpy arrays of type `float`,\ncorresponding to the observation sequences for testing.\n\nThe returned `predicted_cluster_ids` is a list of the same size as\n`test_sequences`. Each element of `predicted_cluster_ids` is a list of integers,\nwith the same length as the corresponding test sequence.\n\nYou can also use a single test sequence for `test_sequences`. Then the returned\n`predicted_cluster_ids` will also be a single list of integers.\n\nThe definitions of the args are described in `uisrnn/arguments.py`.\nSee `inference_parser`.\n\n## Citations\n\nOur paper is cited as:\n\n```\n@inproceedings{zhang2019fully,\n  title={Fully supervised speaker diarization},\n  author={Zhang, Aonan and Wang, Quan and Zhu, Zhenyao and Paisley, John and Wang, Chong},\n  booktitle={International Conference on Acoustics, Speech and Signal Processing (ICASSP)},\n  pages={6301--6305},\n  year={2019},\n  organization={IEEE}\n}\n```\n\n## References\n\n### Baseline diarization system\n\nTo learn more about our baseline diarization system based on\n*unsupervised clustering* algorithms, check out\n[this site](https://google.github.io/speaker-id/publications/LstmDiarization/).\n\nA Python re-implementation of the *spectral clustering* algorithm used in this\npaper is available [here](https://github.com/wq2012/SpectralCluster).\n\nThe ground truth labels for the\n[NIST SRE 2000](https://catalog.ldc.upenn.edu/LDC2001S97)\ndataset (Disk6 and Disk8) can be found\n[here](https://github.com/google/speaker-id/tree/master/publications/LstmDiarization/evaluation/NIST_SRE2000).\n\nFor more public resources on speaker diarization, check out [awesome-diarization](https://github.com/wq2012/awesome-diarization).\n\n### Speaker recognizer/encoder\n\nTo learn more about our speaker embedding system, check out\n[this site](https://google.github.io/speaker-id/publications/GE2E/).\n\nWe are aware of several third-party implementations of this work:\n\n* [TensorFlow implementation by Janghyun1230](https://github.com/Janghyun1230/Speaker_Verification)\n* [PyTorch implementaion by HarryVolek](https://github.com/HarryVolek/PyTorch_Speaker_Verification) - with UIS-RNN integration\n* [PyTorch implementation as part of SV2TTS](https://github.com/CorentinJ/Real-Time-Voice-Cloning)\n\nPlease use your own judgement to decide whether you want to use these\nimplementations.\n\n**We are NOT responsible for the correctness of any third-party implementations.**\n\n## Variants\n\nHere we list the repositories that are based on UIS-RNN, but integrated with\nother technologies or added some improvements.\n\n| Link | Description |\n| ---- | ----------- |\n| [taylorlu/Speaker-Diarization](https://github.com/taylorlu/Speaker-Diarization) ![GitHub stars](https://img.shields.io/github/stars/taylorlu/Speaker-Diarization?style=social) | Speaker diarization using UIS-RNN and GhostVLAD. An easier way to support openset speakers. |\n| [DonkeyShot21/uis-rnn-sml](https://github.com/DonkeyShot21/uis-rnn-sml) ![GitHub stars](https://img.shields.io/github/stars/DonkeyShot21/uis-rnn-sml?style=social) | A variant of UIS-RNN, for the paper Supervised Online Diarization with Sample Mean Loss for Multi-Domain Data. |\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/google/uis-rnn", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "uisrnn", "package_url": "https://pypi.org/project/uisrnn/", "platform": "", "project_url": "https://pypi.org/project/uisrnn/", "project_urls": {"Homepage": "https://github.com/google/uis-rnn"}, "release_url": "https://pypi.org/project/uisrnn/0.1.0/", "requires_dist": null, "requires_python": "", "summary": "Unbounded Interleaved-State Recurrent Neural Network", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>UIS-RNN <a href=\"https://travis-ci.org/google/uis-rnn\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/29ebc220a4f8c7b06025afa2e4b10a86aa411a48/68747470733a2f2f7472617669732d63692e6f72672f676f6f676c652f7569732d726e6e2e7376673f6272616e63683d6d6173746572\"></a> <a href=\"https://pypi.python.org/pypi/uisrnn\" rel=\"nofollow\"><img alt=\"PyPI Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/36468559a22d03d32e8a694de907eb27d883b7d3/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f756973726e6e2e737667\"></a> <a href=\"https://pypi.org/project/uisrnn\" rel=\"nofollow\"><img alt=\"Python Versions\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/95098453dd8244a916595893104741268190a236/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f756973726e6e2e737667\"></a> <a href=\"https://codecov.io/gh/google/uis-rnn\" rel=\"nofollow\"><img alt=\"codecov\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b64256b304c57fceca7e82afe5c461ce7255b9c9/68747470733a2f2f636f6465636f762e696f2f67682f676f6f676c652f7569732d726e6e2f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a> <a href=\"https://google.github.io/uis-rnn\" rel=\"nofollow\"><img alt=\"Documentation\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/119734436d72135bd2979d4600257c4d6ccc617a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6170692d646f63756d656e746174696f6e2d626c75652e737667\"></a></h1>\n<h2>Overview</h2>\n<p>This is the library for the\n<em>Unbounded Interleaved-State Recurrent Neural Network (UIS-RNN)</em> algorithm.\nUIS-RNN solves the problem of segmenting and clustering sequential data\nby learning from examples.</p>\n<p>This algorithm was originally proposed in the paper\n<a href=\"https://arxiv.org/abs/1810.04719\" rel=\"nofollow\">Fully Supervised Speaker Diarization</a>.</p>\n<p>The work has been introduced by\n<a href=\"https://ai.googleblog.com/2018/11/accurate-online-speaker-diarization.html\" rel=\"nofollow\">Google AI Blog</a>.</p>\n<p><img alt=\"gif\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/91e3e82885bec1877cbc4b44132c6d3c2b568a9d/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f676f6f676c652f7569732d726e6e2f6d61737465722f7265736f75726365732f756973726e6e2e676966\"></p>\n<h2>Disclaimer</h2>\n<p>This open source implementation is slightly different than the internal one\nwhich we used to produce the results in the\n<a href=\"https://arxiv.org/abs/1810.04719\" rel=\"nofollow\">paper</a>, due to dependencies on\nsome internal libraries.</p>\n<p>We CANNOT share the data, code, or model for the speaker recognition system\n(<a href=\"https://google.github.io/speaker-id/publications/GE2E/\" rel=\"nofollow\">d-vector embeddings</a>)\nused in the paper, since the speaker recognition system\nheavily depends on Google's internal infrastructure and proprietary data.</p>\n<p><strong>This library is NOT an official Google product.</strong></p>\n<p>We welcome community contributions (<a href=\"CONTRIBUTING.md\" rel=\"nofollow\">guidelines</a>)\nto the <a href=\"uisrnn/contrib\" rel=\"nofollow\"><code>uisrnn/contrib</code></a> folder.\nBut we won't be responsible for the correctness of any community contributions.</p>\n<h2>Dependencies</h2>\n<p>This library depends on:</p>\n<ul>\n<li>python 3.5+</li>\n<li>numpy 1.15.1</li>\n<li>pytorch 1.3.0</li>\n<li>scipy 1.1.0 (for evaluation only)</li>\n</ul>\n<h2>Getting Started</h2>\n<p><a href=\"https://www.youtube.com/watch?v=pGkqwRPzx9U\" rel=\"nofollow\"><img alt=\"YouTube\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/273ae8218f1e3fd4b18d2e806f300ba64378111d/7265736f75726365732f596f75547562655f6c6563747572655f73637265656e73686f742e706e67\"></a></p>\n<h3>Install the package</h3>\n<p>Without downloading the repository, you can install the\n<a href=\"https://pypi.org/project/uisrnn/\" rel=\"nofollow\">package</a> by:</p>\n<pre><code>pip3 install uisrnn\n</code></pre>\n<p>or</p>\n<pre><code>python3 -m pip install uisrnn\n</code></pre>\n<h3>Run the demo</h3>\n<p>To get started, simply run this command:</p>\n<pre>python3 demo.py --train_iteration<span class=\"o\">=</span><span class=\"m\">1000</span> -l<span class=\"o\">=</span><span class=\"m\">0</span>.001\n</pre>\n<p>This will train a UIS-RNN model using <code>data/toy_training_data.npz</code>,\nthen store the model on disk, perform inference on <code>data/toy_testing_data.npz</code>,\nprint the inference results, and save the averaged accuracy in a text file.</p>\n<p>PS. The files under <code>data/</code> are manually generated <em>toy data</em>,\nfor demonstration purpose only.\nThese data are very simple, so we are supposed to get 100% accuracy on the\ntesting data.</p>\n<h3>Run the tests</h3>\n<p>You can also verify the correctness of this library by running:</p>\n<pre>bash run_tests.sh\n</pre>\n<p>If you fork this library and make local changes, be sure to use these tests\nas a sanity check.</p>\n<p>Besides, these tests are also great examples for learning\nthe APIs, especially <code>tests/integration_test.py</code>.</p>\n<h2>Core APIs</h2>\n<h3>Glossary</h3>\n<table>\n<thead>\n<tr>\n<th>General Machine Learning</th>\n<th>Speaker Diarization</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Sequence</td>\n<td>Utterance</td>\n</tr>\n<tr>\n<td>Observation / Feature</td>\n<td>Embedding / d-vector</td>\n</tr>\n<tr>\n<td>Label / Cluster ID</td>\n<td>Speaker</td>\n</tr></tbody></table>\n<h3>Arguments</h3>\n<p>In your main script, call this function to get the arguments:</p>\n<pre><span class=\"n\">model_args</span><span class=\"p\">,</span> <span class=\"n\">training_args</span><span class=\"p\">,</span> <span class=\"n\">inference_args</span> <span class=\"o\">=</span> <span class=\"n\">uisrnn</span><span class=\"o\">.</span><span class=\"n\">parse_arguments</span><span class=\"p\">()</span>\n</pre>\n<h3>Model construction</h3>\n<p>All algorithms are implemented as the <code>UISRNN</code> class. First, construct a\n<code>UISRNN</code> object by:</p>\n<pre><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">uisrnn</span><span class=\"o\">.</span><span class=\"n\">UISRNN</span><span class=\"p\">(</span><span class=\"n\">args</span><span class=\"p\">)</span>\n</pre>\n<p>The definitions of the args are described in <code>uisrnn/arguments.py</code>.\nSee <code>model_parser</code>.</p>\n<h3>Training</h3>\n<p>Next, train the model by calling the <code>fit()</code> function:</p>\n<pre><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">train_sequences</span><span class=\"p\">,</span> <span class=\"n\">train_cluster_ids</span><span class=\"p\">,</span> <span class=\"n\">args</span><span class=\"p\">)</span>\n</pre>\n<p>The definitions of the args are described in <code>uisrnn/arguments.py</code>.\nSee <code>training_parser</code>.</p>\n<p>The <code>fit()</code> function accepts two types of input, as described below.</p>\n<h4>Input as list of sequences (recommanded)</h4>\n<p>Here, <code>train_sequences</code> is a list of observation sequences.\nEach observation sequence is a 2-dim numpy array of type <code>float</code>.</p>\n<ul>\n<li>The first dimension is the length of this sequence. And the length\ncan vary from one sequence to another.</li>\n<li>The second dimension is the size of each observation. This\nmust be consistent among all sequences. For speaker diarization,\nthe observation could be the\n<a href=\"https://google.github.io/speaker-id/publications/GE2E/\" rel=\"nofollow\">d-vector embeddings</a>.</li>\n</ul>\n<p><code>train_cluster_ids</code> is also a list, which has the same length as\n<code>train_sequences</code>. Each element of <code>train_cluster_ids</code> is a 1-dim list or\nnumpy array of strings, containing the ground truth labels for the\ncorresponding sequence in <code>train_sequences</code>.\nFor speaker diarization, these labels are the speaker identifiers for each\nobservation.</p>\n<p>When calling <code>fit()</code> in this way, please be very careful with the argument\n<code>--enforce_cluster_id_uniqueness</code>.</p>\n<p>For example, assume:</p>\n<pre><span class=\"n\">train_cluster_ids</span> <span class=\"o\">=</span> <span class=\"p\">[[</span><span class=\"s1\">'a'</span><span class=\"p\">,</span> <span class=\"s1\">'b'</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"s1\">'a'</span><span class=\"p\">,</span> <span class=\"s1\">'c'</span><span class=\"p\">]]</span>\n</pre>\n<p>If the label <code>'a'</code> from the two sequences refers to the same cluster across\nthe entire dataset, then we should have <code>enforce_cluster_id_uniqueness=False</code>;\notherwise, if <code>'a'</code> is only a local indicator to distinguish from <code>'b'</code> in the\n1st sequence, and to distinguish from <code>'c'</code> in the 2nd sequence, then we should\nhave <code>enforce_cluster_id_uniqueness=True</code>.</p>\n<p>Also, please note that, when calling <code>fit()</code> in this way, we are going to\nconcatenate all sequences and all cluster IDs, and delegate to\nthe next section below.</p>\n<h4>Input as single concatenated sequence</h4>\n<p>Here, <code>train_sequences</code> should be a single 2-dim numpy array of type <code>float</code>,\nfor the <strong>concatenated</strong> observation sequences.</p>\n<p>For example, if you have <em>M</em> training utterances,\nand each utterance is a sequence of <em>L</em> embeddings. Each embedding is\na vector of <em>D</em> numbers. Then the shape of <code>train_sequences</code> is <em>N * D</em>,\nwhere <em>N = M * L</em>.</p>\n<p><code>train_cluster_ids</code> is a 1-dim list or numpy array of strings, of length <em>N</em>.\nIt is the <strong>concatenated</strong> ground truth labels of all training data.</p>\n<p>Since we are concatenating observation sequences, it is important to note that,\nground truth labels in <code>train_cluster_id</code> across different sequences are\nsupposed to be <strong>globally unique</strong>.</p>\n<p>For example, if the set of labels in the first\nsequence is <code>{'A', 'B', 'C'}</code>, and the set of labels in the second sequence\nis <code>{'B', 'C', 'D'}</code>. Then before concatenation, we should rename them to\nsomething like <code>{'1_A', '1_B', '1_C'}</code> and <code>{'2_B', '2_C', '2_D'}</code>,\nunless <code>'B'</code> and <code>'C'</code> in the two sequences are meaningfully identical\n(in speaker diarization, this means they are the same speakers across\nutterances). This part will be automatically taken care of by the argument\n<code>--enforce_cluster_id_uniqueness</code> for the previous section.</p>\n<p>The reason we concatenate all training sequences is that, we will be resampling\nand <em>block-wise</em> shuffling the training data as a <strong>data augmentation</strong>\nprocess, such that we result in a robust model even when there is insufficient\nnumber of training sequences.</p>\n<h4>Training on large datasets</h4>\n<p>For large datasets, the data usually could not be loaded into memory at once.\nIn such cases, the <code>fit()</code> function needs to be called multiple times.</p>\n<p>Here we provide a few guidelines as our suggestions:</p>\n<ol>\n<li>Do not feed different datasets into different calls of <code>fit()</code>. Instead,\nfor each call of <code>fit()</code>, the input should cover sequences from\ndifferent datasets.</li>\n<li>For each call to the <code>fit()</code> function, make the size of input roughly the\nsame. And, don't make the input size too small.</li>\n</ol>\n<h3>Prediction</h3>\n<p>Once we are done with training, we can run the trained model to perform\ninference on new sequences by calling the <code>predict()</code> function:</p>\n<pre><span class=\"n\">predicted_cluster_ids</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">test_sequences</span><span class=\"p\">,</span> <span class=\"n\">args</span><span class=\"p\">)</span>\n</pre>\n<p>Here <code>test_sequences</code> should be a list of 2-dim numpy arrays of type <code>float</code>,\ncorresponding to the observation sequences for testing.</p>\n<p>The returned <code>predicted_cluster_ids</code> is a list of the same size as\n<code>test_sequences</code>. Each element of <code>predicted_cluster_ids</code> is a list of integers,\nwith the same length as the corresponding test sequence.</p>\n<p>You can also use a single test sequence for <code>test_sequences</code>. Then the returned\n<code>predicted_cluster_ids</code> will also be a single list of integers.</p>\n<p>The definitions of the args are described in <code>uisrnn/arguments.py</code>.\nSee <code>inference_parser</code>.</p>\n<h2>Citations</h2>\n<p>Our paper is cited as:</p>\n<pre><code>@inproceedings{zhang2019fully,\n  title={Fully supervised speaker diarization},\n  author={Zhang, Aonan and Wang, Quan and Zhu, Zhenyao and Paisley, John and Wang, Chong},\n  booktitle={International Conference on Acoustics, Speech and Signal Processing (ICASSP)},\n  pages={6301--6305},\n  year={2019},\n  organization={IEEE}\n}\n</code></pre>\n<h2>References</h2>\n<h3>Baseline diarization system</h3>\n<p>To learn more about our baseline diarization system based on\n<em>unsupervised clustering</em> algorithms, check out\n<a href=\"https://google.github.io/speaker-id/publications/LstmDiarization/\" rel=\"nofollow\">this site</a>.</p>\n<p>A Python re-implementation of the <em>spectral clustering</em> algorithm used in this\npaper is available <a href=\"https://github.com/wq2012/SpectralCluster\" rel=\"nofollow\">here</a>.</p>\n<p>The ground truth labels for the\n<a href=\"https://catalog.ldc.upenn.edu/LDC2001S97\" rel=\"nofollow\">NIST SRE 2000</a>\ndataset (Disk6 and Disk8) can be found\n<a href=\"https://github.com/google/speaker-id/tree/master/publications/LstmDiarization/evaluation/NIST_SRE2000\" rel=\"nofollow\">here</a>.</p>\n<p>For more public resources on speaker diarization, check out <a href=\"https://github.com/wq2012/awesome-diarization\" rel=\"nofollow\">awesome-diarization</a>.</p>\n<h3>Speaker recognizer/encoder</h3>\n<p>To learn more about our speaker embedding system, check out\n<a href=\"https://google.github.io/speaker-id/publications/GE2E/\" rel=\"nofollow\">this site</a>.</p>\n<p>We are aware of several third-party implementations of this work:</p>\n<ul>\n<li><a href=\"https://github.com/Janghyun1230/Speaker_Verification\" rel=\"nofollow\">TensorFlow implementation by Janghyun1230</a></li>\n<li><a href=\"https://github.com/HarryVolek/PyTorch_Speaker_Verification\" rel=\"nofollow\">PyTorch implementaion by HarryVolek</a> - with UIS-RNN integration</li>\n<li><a href=\"https://github.com/CorentinJ/Real-Time-Voice-Cloning\" rel=\"nofollow\">PyTorch implementation as part of SV2TTS</a></li>\n</ul>\n<p>Please use your own judgement to decide whether you want to use these\nimplementations.</p>\n<p><strong>We are NOT responsible for the correctness of any third-party implementations.</strong></p>\n<h2>Variants</h2>\n<p>Here we list the repositories that are based on UIS-RNN, but integrated with\nother technologies or added some improvements.</p>\n<table>\n<thead>\n<tr>\n<th>Link</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><a href=\"https://github.com/taylorlu/Speaker-Diarization\" rel=\"nofollow\">taylorlu/Speaker-Diarization</a> <img alt=\"GitHub stars\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b0d546c89b6ee44976f50de33ad3f85f7df7a3a4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7461796c6f726c752f537065616b65722d44696172697a6174696f6e3f7374796c653d736f6369616c\"></td>\n<td>Speaker diarization using UIS-RNN and GhostVLAD. An easier way to support openset speakers.</td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/DonkeyShot21/uis-rnn-sml\" rel=\"nofollow\">DonkeyShot21/uis-rnn-sml</a> <img alt=\"GitHub stars\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/15c87eac7ca4fc556f81292353db8b4bbb70e5d7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f446f6e6b657953686f7432312f7569732d726e6e2d736d6c3f7374796c653d736f6369616c\"></td>\n<td>A variant of UIS-RNN, for the paper Supervised Online Diarization with Sample Mean Loss for Multi-Domain Data.</td>\n</tr></tbody></table>\n\n          </div>"}, "last_serial": 6307274, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "5a098d712fdb6249b6c028aa767b2297", "sha256": "e89bfb33c44b347e9401464fde607c2441f8387cade2c520d3633f5c2f584d74"}, "downloads": -1, "filename": "uisrnn-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "5a098d712fdb6249b6c028aa767b2297", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 17179, "upload_time": "2018-12-26T17:05:22", "upload_time_iso_8601": "2018-12-26T17:05:22.573658Z", "url": "https://files.pythonhosted.org/packages/1a/ba/74a0d96e64d779714a53648b6848e271ffa5f1d1fd95c953af47f085b168/uisrnn-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "51c35a042f29005bb4d3240038144d55", "sha256": "8bd6aa2f2a70b6b5a4a87646d4b3ddbdecf0af035001b8b42e085c81bd429361"}, "downloads": -1, "filename": "uisrnn-0.0.1.tar.gz", "has_sig": false, "md5_digest": "51c35a042f29005bb4d3240038144d55", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13488, "upload_time": "2018-12-26T17:05:24", "upload_time_iso_8601": "2018-12-26T17:05:24.460945Z", "url": "https://files.pythonhosted.org/packages/05/dd/c0aeec84436ff8735696d018cd6a42b0e998a0d4d3d1214bfd54f0a229fa/uisrnn-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "d28dfa28e6d68413844d494ee4105027", "sha256": "f912230737731f8fb5c2da7830b40b51e8955718fc3306b212da43bf43bec2e9"}, "downloads": -1, "filename": "uisrnn-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "d28dfa28e6d68413844d494ee4105027", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 17335, "upload_time": "2018-12-26T18:01:33", "upload_time_iso_8601": "2018-12-26T18:01:33.136801Z", "url": "https://files.pythonhosted.org/packages/03/0d/937fa6fe54612b9a10eab6cf9be200fb5f5ed3b9d2132d55051e7125f27b/uisrnn-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a279508ebf6ef3d75a34f75cb4839fa7", "sha256": "a619d14aa0361574c50ee4ab335e3c84d6e023bba2e2b79438731b71f764fa17"}, "downloads": -1, "filename": "uisrnn-0.0.2.tar.gz", "has_sig": false, "md5_digest": "a279508ebf6ef3d75a34f75cb4839fa7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13672, "upload_time": "2018-12-26T18:01:34", "upload_time_iso_8601": "2018-12-26T18:01:34.451574Z", "url": "https://files.pythonhosted.org/packages/57/5f/7b467056dc1940f8b04d4cf9d5a2322a68466d25fa10c61f1c05d20d4234/uisrnn-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "e930d7fe46777e7faf1975bcecafae22", "sha256": "17e86f5f7aecc43ad82b419730cf2d9841259beda0800e935cf62066ee6283f4"}, "downloads": -1, "filename": "uisrnn-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "e930d7fe46777e7faf1975bcecafae22", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 17410, "upload_time": "2018-12-26T18:37:58", "upload_time_iso_8601": "2018-12-26T18:37:58.390364Z", "url": "https://files.pythonhosted.org/packages/f9/6c/48edaeffcac788fe1f608b5d2899d129b11af07c82866e126efc27782f9f/uisrnn-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a5d2dfc98d0fa2f0b2b702f038d3bf7a", "sha256": "19b694c54a4a9b1dbae7f2cf9fedb69f1eedd50f1cde03e640dba0e15ef95879"}, "downloads": -1, "filename": "uisrnn-0.0.3.tar.gz", "has_sig": false, "md5_digest": "a5d2dfc98d0fa2f0b2b702f038d3bf7a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13727, "upload_time": "2018-12-26T18:37:59", "upload_time_iso_8601": "2018-12-26T18:37:59.683890Z", "url": "https://files.pythonhosted.org/packages/ea/8c/deacf2152126a0ac4bc3dbe66f91a8bf97ca477b66b2a5e57f2cbca47471/uisrnn-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "ef1f39305d47eb8623c2efbe167a0a9e", "sha256": "05f2010115822987bdb356ac0bd8736ac55c6fb5d8cef9e26eb6a272f093463f"}, "downloads": -1, "filename": "uisrnn-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "ef1f39305d47eb8623c2efbe167a0a9e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 17883, "upload_time": "2018-12-26T20:24:04", "upload_time_iso_8601": "2018-12-26T20:24:04.069020Z", "url": "https://files.pythonhosted.org/packages/9d/8b/f46e5aa5ae18ab0163bc0c68aa46284c00dfb2b5e7e8b8f38cc381dc8777/uisrnn-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "bda2bd725f00b5f9e304996116f77a4b", "sha256": "b828ad10ec7bb8b293bfdd1dcf62f8cac4da9268cfda8987260fd4d53cd54bd6"}, "downloads": -1, "filename": "uisrnn-0.0.4.tar.gz", "has_sig": false, "md5_digest": "bda2bd725f00b5f9e304996116f77a4b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14312, "upload_time": "2018-12-26T20:24:05", "upload_time_iso_8601": "2018-12-26T20:24:05.399300Z", "url": "https://files.pythonhosted.org/packages/c4/43/eba922bdc96b73d92ffd18b5c99a05e7b4b69c5d05b7eb395c52b251ea14/uisrnn-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "dde2636be92e9d96bab291468116d116", "sha256": "ec49db71ded5ea314758385ba2fc685aa17e098f44d43fc3cd3f8bd41669f638"}, "downloads": -1, "filename": "uisrnn-0.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "dde2636be92e9d96bab291468116d116", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 20002, "upload_time": "2019-01-04T20:40:39", "upload_time_iso_8601": "2019-01-04T20:40:39.926937Z", "url": "https://files.pythonhosted.org/packages/dd/d8/fb6c53dc4bbdbb9ab4ca6aafa6341678cb6927e3ce44c1815566ca2884b6/uisrnn-0.0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8f02ad67a4468d6747b69c3570127f1c", "sha256": "9f251258a93d9d71b45b592aa64be6e1f4ba964d4efd04ee396c7f1282f1256c"}, "downloads": -1, "filename": "uisrnn-0.0.5.tar.gz", "has_sig": false, "md5_digest": "8f02ad67a4468d6747b69c3570127f1c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16417, "upload_time": "2019-01-04T20:40:41", "upload_time_iso_8601": "2019-01-04T20:40:41.649813Z", "url": "https://files.pythonhosted.org/packages/3d/40/bb72a8595a16798dd9a47836d1c284ab8b0afb89cfb83cd8a26676036fe3/uisrnn-0.0.5.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "83bb34f58744ba5c0cb290d4ffab19ec", "sha256": "905209aeff6ee432d76f302f00f2f416b3237946244cf79db0903801b661a8e6"}, "downloads": -1, "filename": "uisrnn-0.0.6-py3-none-any.whl", "has_sig": false, "md5_digest": "83bb34f58744ba5c0cb290d4ffab19ec", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 20546, "upload_time": "2019-02-18T20:47:40", "upload_time_iso_8601": "2019-02-18T20:47:40.210961Z", "url": "https://files.pythonhosted.org/packages/bd/fd/06d0afca8c492ac38c7e9693e446c7e0abd81286fb8a51b9efadb176cd22/uisrnn-0.0.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "dfae1461f7840d1a74f4679aa2f1209c", "sha256": "dbbf0f47255ae1fef1524d209838def46525954afdd76e90f55c38c2c6024972"}, "downloads": -1, "filename": "uisrnn-0.0.6.tar.gz", "has_sig": false, "md5_digest": "dfae1461f7840d1a74f4679aa2f1209c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20677, "upload_time": "2019-02-18T20:47:41", "upload_time_iso_8601": "2019-02-18T20:47:41.644379Z", "url": "https://files.pythonhosted.org/packages/78/d6/27e84cc3949b3f92fdae060c282e1df918070e9e343b1407b5ad827cda84/uisrnn-0.0.6.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "70695d3635f09e28840841dd73c0ad72", "sha256": "82cadc44a377b0a1dc5eb30ee444e7422c813a15126ac4e105e762b62e52904b"}, "downloads": -1, "filename": "uisrnn-0.0.7-py3-none-any.whl", "has_sig": false, "md5_digest": "70695d3635f09e28840841dd73c0ad72", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 24147, "upload_time": "2019-04-25T15:49:12", "upload_time_iso_8601": "2019-04-25T15:49:12.814778Z", "url": "https://files.pythonhosted.org/packages/14/ff/4363c8521f8db60983e1c2d5c057a4fbb1cb6fe6dfbe0ebc7d5ce3cedfa1/uisrnn-0.0.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4bd31b8d9a29f0ce92855cd855cd1353", "sha256": "0635d8bc2718d2bc2adb934da82b3b33a31e4b3dc0fcb923632d15fac7ec4c97"}, "downloads": -1, "filename": "uisrnn-0.0.7.tar.gz", "has_sig": false, "md5_digest": "4bd31b8d9a29f0ce92855cd855cd1353", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16932, "upload_time": "2019-04-25T15:49:15", "upload_time_iso_8601": "2019-04-25T15:49:15.326974Z", "url": "https://files.pythonhosted.org/packages/90/46/f3aff16ac759009b281384cbe180f1ba0a8b0e6b21811f2f0f3a1f4f0027/uisrnn-0.0.7.tar.gz", "yanked": false}], "0.0.8": [{"comment_text": "", "digests": {"md5": "b1927e147396097695294e383ecd977c", "sha256": "fa6104f719cac8dfbfe25156bd3188bc13a197629939261b22d0525678d8eeb5"}, "downloads": -1, "filename": "uisrnn-0.0.8-py3-none-any.whl", "has_sig": false, "md5_digest": "b1927e147396097695294e383ecd977c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 24750, "upload_time": "2019-09-07T18:28:26", "upload_time_iso_8601": "2019-09-07T18:28:26.512856Z", "url": "https://files.pythonhosted.org/packages/6f/53/f3691b43144333b635b5d511e39cc9dffeeedf1faa68689cf4a84df02fbf/uisrnn-0.0.8-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1ca8065a4fb1a2bddce39a4a4a6156ba", "sha256": "3125e66eb5fffa44bd620b0d44977f79de9d99e7df2ba43d06f805f42481d4ad"}, "downloads": -1, "filename": "uisrnn-0.0.8.tar.gz", "has_sig": false, "md5_digest": "1ca8065a4fb1a2bddce39a4a4a6156ba", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21322, "upload_time": "2019-09-07T18:28:28", "upload_time_iso_8601": "2019-09-07T18:28:28.082449Z", "url": "https://files.pythonhosted.org/packages/b1/68/116b7cb947747398152e85fb302836c72b8a91876638e58cb9894a4cc677/uisrnn-0.0.8.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "c72205bb7427116a16365e154ecd462a", "sha256": "70bcba691107fca7f705aafc1eb1cad32ccfac03452adb4e12a1130bf99c5482"}, "downloads": -1, "filename": "uisrnn-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "c72205bb7427116a16365e154ecd462a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 28123, "upload_time": "2019-12-15T17:57:48", "upload_time_iso_8601": "2019-12-15T17:57:48.266548Z", "url": "https://files.pythonhosted.org/packages/49/ac/240e688480bbcb541458642e36b2211ac58fa17e8c9239cc55e22a244822/uisrnn-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "86ab1c9b4e64f7b2f9a1aa0492ec3e17", "sha256": "46c249eaabb476908442ac7d1ba09191a5665a6965e033767f536374e17e5927"}, "downloads": -1, "filename": "uisrnn-0.1.0.tar.gz", "has_sig": false, "md5_digest": "86ab1c9b4e64f7b2f9a1aa0492ec3e17", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24016, "upload_time": "2019-12-15T17:57:50", "upload_time_iso_8601": "2019-12-15T17:57:50.014206Z", "url": "https://files.pythonhosted.org/packages/35/34/c5b7e4c550fc57423a838b830c1425339cb515ed5501600122434ddf8d72/uisrnn-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "c72205bb7427116a16365e154ecd462a", "sha256": "70bcba691107fca7f705aafc1eb1cad32ccfac03452adb4e12a1130bf99c5482"}, "downloads": -1, "filename": "uisrnn-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "c72205bb7427116a16365e154ecd462a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 28123, "upload_time": "2019-12-15T17:57:48", "upload_time_iso_8601": "2019-12-15T17:57:48.266548Z", "url": "https://files.pythonhosted.org/packages/49/ac/240e688480bbcb541458642e36b2211ac58fa17e8c9239cc55e22a244822/uisrnn-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "86ab1c9b4e64f7b2f9a1aa0492ec3e17", "sha256": "46c249eaabb476908442ac7d1ba09191a5665a6965e033767f536374e17e5927"}, "downloads": -1, "filename": "uisrnn-0.1.0.tar.gz", "has_sig": false, "md5_digest": "86ab1c9b4e64f7b2f9a1aa0492ec3e17", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24016, "upload_time": "2019-12-15T17:57:50", "upload_time_iso_8601": "2019-12-15T17:57:50.014206Z", "url": "https://files.pythonhosted.org/packages/35/34/c5b7e4c550fc57423a838b830c1425339cb515ed5501600122434ddf8d72/uisrnn-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:41:24 2020"}