{"info": {"author": "Michael Christoph Nowotny", "author_email": "nowotnym@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: Implementation :: CPython"], "description": "\n# Recombinator - Statistical Resampling in Python\n\n\n## Overview\n\nRecombinator is a Python package for statistical resampling in Python. It provides various algorithms for the iid bootstrap, the block bootstrap, as well as optimal block-length selection. \n\n## Algorithms\n\n*   I.I.D. bootstrap: Standard i.i.d. bootstrap for one-dimensional and multi-dimensional data, balanced bootstrap, anthithetic bootstrap  \n*   Block based bootstrap: Moving Block Bootstrap, Circular Block Bootstrap, Stationary Bootstrap, Tapered Block-Bootstrap \n*   Optimal block-length selection algorithm for Circular Block Bootstrap and Stationary Bootstrap\n\n## Table of Contents\n\n1.  [Installation](#installation)\n2.  [Getting Started](#getting-started)\n\n\n## Installation\n### Latest Release\n<pre>\n    pip install recombinator\n</pre>\nor \n<pre>\n    pip3 install recombinator\n</pre>\nif not using Anaconda.\n\nTo get the latest version, clone the repository from github, \nopen a terminal/command prompt, navigate to the root folder and install via\n<pre>\n    pip install .\n</pre>\nor \n<pre>\n    pip3 install . \n</pre>\nif not using Anaconda.\n\n### Most Recent Version on GitHub\n1. Clone the github repository via\n\n<pre>\n    git clone https://github.com/InvestmentSystems/recombinator.git\n</pre>\n\n2. Navigate to the Recombinator base directory and run\n<pre>\n    pip install .\n</pre> \n\n## Getting Started\nPlease see the Jupyter notebooks 'notebooks/Block Bootstrap.ipynb' and 'notebooks/IID Bootstrap.ipynb' for more examples.\n\n### Basic I.I.D. Bootstrap\nImport modules\n<pre>\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport numpy as np\n\nfrom recombinator.iid_bootstrap import \\\n    iid_balanced_bootstrap, \\\n    iid_bootstrap, \\\n    iid_bootstrap_vectorized, \\\n    iid_bootstrap_via_choice, \\\n    iid_bootstrap_via_loop, \\\n    iid_bootstrap_with_antithetic_resampling\n</pre>\n\nFor illustrative purposes, generate an original dataset of sample size n=100 to resample from.\n<pre>\nn=100\nnp.random.seed(1)\nx = np.abs(np.random.randn(n))\n</pre>\n\nEstimate the 75th percentile from the original sample\n<pre>\npercentile = 75\noriginal_statistic = np.percentile(x, percentile)\nprint(original_statistic)\n</pre>\n\nNow generate 100000 new bootstrap samples by drawing from the original sample with replacement.\n<pre>\nR = 100000\nx_resampled = iid_bootstrap(x, replications=R)\n</pre>\nThis produces a 100000 x 100 dimensional NumPy array. Each row is a new sample.\n\nIf we instead wanted to resample without replacement, we could draw shorter samples. \nThis is known as as subsampling. See these lecture notes by Charles Geyer for statistical background: \nhttp://www.stat.umn.edu/geyer/5601/notes/sub.pdf. \n\nIn recombinator, subsampling is achieved by using the keyword arguments \"sub_sample_length\" and \"replace\". \nTo draw samples of size 50 without replacement we would write\n<pre>\nx_resampled = iid_bootstrap(x, replications=R, sub_sample_length=50, replace=False)\n</pre>\n\nLet us return to the original example of resampling at the full sample size with replacement.\nWe are interested in the sampling distribution of a statistic (in this example the 75th percentile of the distribution).\nHence, we calculate the statistic on each of the new bootstrap samples:\n<pre>\nresampled_statistic = np.percentile(x_resampled, percentile, axis=1)\n</pre>\n\nWe can use Recombinator to estimate the bootstrap standard error and the 95% \nconfidence interval of the statistic as follows.\n<pre>\nfrom recombinator.statistics import \\\n    estimate_confidence_interval_from_bootstrap, \\\n    estimate_standard_error_from_bootstrap\n</pre>\n\nEstimate the standard error of the estimate of the 75th percentile via bootstrap:\n<pre>\nestimate_standard_error_from_bootstrap(bootstrap_estimates=resampled_statistic,\n                                       original_estimate=original_statistic)\n</pre>\n\nEstimate the 95% confidence interval of the 75th percentile via bootstrap:\n<pre>\nestimate_confidence_interval_from_bootstrap(bootstrap_estimates=resampled_statistic, \n                                            confidence_level=95)\n</pre>\n\nRecombinator supports other variations of the standard i.i.d. bootstrap \n(the balanced and the antithetic bootstrap). Please see the Jupyter notebook on the I.I.D. boostrap for examples.\n\n### Block-Based Bootstrap for Time-Series\nRecombinator offers the following block-based approaches to resample temporally dependent data:\n* Moving Block Bootstrap - Kuensch (1989)\n* Circular Block Bootstrap - Politis and Romano (1992)\n* Stationary Bootstrap - Politis and Romano (1994)\n* Tapered Block Bootstrap - Paparoditis and Politis (2001)  \n\nImport statsmodels for the estimation of time-series models.\n<pre>\nfrom statsmodels.tsa.arima_process import ArmaProcess\nfrom statsmodels.tsa.ar_model import AR\nimport statsmodels.api as sm\nfrom statsmodels.graphics.tsaplots import plot_acf\n</pre>\n\n\nGenerate a sample of length n=1000 from an AR(1) process with autoregressive coefficient 0.5:\n<pre>\nnp.random.seed(1)\n\n# number of time periods\nT = 1000\n\n# draw random errors\ne = np.random.randn(T)\ny = np.zeros((T,))\n\n# y is an AR(1) with phi_1 = 0.5\nphi_1 = 0.5\ny[0] = e[0]*np.sqrt(1.0/(1.0-phi_1**2))\nfor t in range(1, T):\n    y[t]=phi_1*y[t-1] + e[t]\n</pre>\n\n\n#### Optimal Block-Length\nIn order to preserve temporal dependence in time-series data, \nbootstrap algorithms sample from the original data in blocks rather than \nsampling single observations. \nA key question is what block length to use. \nWe are using a data based block length selection algorithm due to Politis and White (2004) \nwith corrections by Patton, Politis, and White (2007). \nThis algorithm produces optimal block-lengths for the circular block bootstrap and the stationary bootstrap for the estimation of the variance of the mean.\n\nImport the optimal block-length selection functionality:\n<pre>\nfrom recombinator.optimal_block_length import optimal_block_length\n</pre>\n\nCompute the optimal block length of the sample from the AR(1) process created above:\n<pre>\nb_star = optimal_block_length(y)\nb_star_sb = b_star[0].b_star_sb\nb_star_cb = math.ceil(b_star[0].b_star_cb)\nprint(f'optimal block length for stationary bootstrap = {b_star_sb}')\nprint(f'optimal block length for circular bootstrap = {b_star_cb}')\n</pre>\n\n#### Resampling using a Block-Based Bootstrap\nWe illustrate the procedure using the circular-block bootstrap.\n<pre>\nfrom recombinator.block_bootstrap import circular_block_bootstrap\n</pre>\n\nThe true autoregressive coefficient of the process we simulated is 0.5. \nThe estimated coefficient from the simulated time-series is obtained as follows\n<pre>\nar = AR(y)\nestimate_from_original_data = ar.fit(maxlag=1)\nprint(estimate_from_original_data.params[1])\n</pre>\n\nStatsmodels can produce an estimate of the standard error of the estimate of the autoregressive coefficient resorting to asymptotic theory:\n<pre>\nprint(estimate_from_original_data.bse[1])\n</pre> \n\nGenerate 10000 new time-series by resampling using a circular-block bootstrap\n<pre>\n# number of replications for bootstraps (number of resampled time-series to generate)\nB = 10000\n\ny_star_cb \\\n    = circular_block_bootstrap(y, \n                               block_length=b_star_cb, \n                               replications=B, \n                               replace=True)\n</pre>\n\nNow estimate the AR coefficient on each of the bootstrap samples\n<pre>\nestimates_from_bootstrap = []\nar_estimates_from_bootstrap = np.zeros((B, ))\n\nfor b in range(B):\n    y_bootstrap = y_star_cb[b, :]\n    ar_bootstrap = AR(y_bootstrap)\n    estimate_from_bootstrap = ar_bootstrap.fit(maxlag=1)\n    estimates_from_bootstrap.append(estimate_from_bootstrap)\n    ar_estimates_from_bootstrap[b] = estimate_from_bootstrap.params[1]\n</pre>\n\nPlot the sampling distribution and compute its mean and median\n<pre>\nplt.hist(ar_estimates_from_bootstrap, bins=20)\nprint(f'mean={np.mean(ar_estimates_from_bootstrap)}')\nprint(f'median={np.median(ar_estimates_from_bootstrap)}')\n</pre>\n\nIt turns out that the mean and median are below the AR coefficient estimated on the original sample. \nThis is due to the fact that the block bootstrap approach breaks the temporal \ndependence whenever a new block starts. \nOne can reduce this effect by choosing a higher block-length at the expense of \nreducing the number of possible permutations of the data.\n\nAnother way to reduce this issue is to use a tapered-block bootstrap which is \ndesigned to mitigate artificial structural breaks introduced by the resampling \nprocedure at the block-transition points.\n\nImport the function\n<pre>\nfrom recombinator.tapered_block_bootstrap import tapered_block_bootstrap\n</pre>\n\nRun the tapered-block bootstrap\n<pre>\ny_star_tbb \\\n    = tapered_block_bootstrap(y, \n                              block_length=b_star_cb, \n                              replications=B)\n</pre>\n\nAgain estimate the AR coefficient on each of the new bootstrap samples\n<pre>\nestimates_from_bootstrap = []\nar_estimates_from_bootstrap = np.zeros((B, ))\n\nfor b in range(B):\n    y_bootstrap = y_star_tbb[b, :]\n    ar_bootstrap = AR(y_bootstrap)\n    estimate_from_bootstrap = ar_bootstrap.fit(maxlag=1)\n    estimates_from_bootstrap.append(estimate_from_bootstrap)\n    ar_estimates_from_bootstrap[b] = estimate_from_bootstrap.params[1]\n</pre>\n\n... and plot the sampling distribution\n<pre>\nplt.hist(ar_estimates_from_bootstrap, bins=20)\nprint(f'mean={np.mean(ar_estimates_from_bootstrap)}')\nprint(f'median={np.median(ar_estimates_from_bootstrap)}')\n</pre>\n\nThe mean and median of the distribution are now much closer to the estimate from the original time series.\n\n### Running Recombinator on a GPU\nResampling can be a computationally intensive task, which is highly parallelizable. \nThe implementations of various algorithms fall into two broad categories:\n* Loop-based (via Numba)\n* Vectorized (via NumPy)\n\nVectorized implementations can be run on the GPU depending on the availability a \nGPU package with a NumPy compatible interface. \nTo this end, vectorized implementations in Recombinator lets the user specify \nalternative modules and functions that are to be used internally.\n\nA NumPy compatible package that supports both CUDA and OpenCL is Cocos \navailable at https://github.com/michaelnowotny/cocos.\n\nUsing Cocos, resampling on the GPU using Recombinator can be performed as follows.\n\nImport the NumPy-like Cocos package. This requires an ArrayFire installation, a compatible GPU, and the installation of Cocos.\n<pre>\nimport cocos.numerics as cn\nfrom cocos.device import gpu_sync_wrapper, sync\n</pre>\n\n#### I.I.D. Boostrap\nGenerate an original sample to work with\n<pre>\nn = 100\ncn.random.seed(1)\nx_gpu = cn.absolute(cn.random.randn(n))\nplt.hist(x_gpu);\n</pre>\n\nResample using an i.i.d. boostrap\n<pre>\nx_resampled_vectorized_gpu \\\n    = iid_bootstrap_vectorized(x_gpu, \n                               replications=R, \n                               randint=cn.random.randint)\nsync()\n</pre>\n\nIn this case, GPU support is achieved by simply specifying an alternative \nimplementation of NumPy's randint function.\n\n#### Block-Based Bootstrap\nTransfer the array created in the time-series example above to the GPU\n<pre>\ny_gpu = cn.array(y)\n</pre>\n\nRun a circular-block boostrap on the GPU\n<pre>\ny_star_cb \\\n    = circular_block_bootstrap_vectorized(y_gpu, \n                                          block_length=b_star_cb, \n                                          replications=B, \n                                          replace=True, \n                                          num_pack=cn, \n                                          choice=cn.random.choice)\n</pre>\n\nEstimate the AR coefficient on each of the bootstrap samples\n<pre>\nestimates_from_bootstrap = []\nar_estimates_from_bootstrap = np.zeros((len(y_star_cb), ))\n\nfor b in range(len(y_star_cb)):\n    y_bootstrap = np.array(y_star_mb[b, :].squeeze())\n    ar_bootstrap = AR(y_bootstrap)\n    estimate_from_bootstrap = ar_bootstrap.fit(maxlag=1)\n    estimates_from_bootstrap.append(estimate_from_bootstrap)\n    ar_estimates_from_bootstrap[b] = estimate_from_bootstrap.params[1]\n</pre>\n\nPlot the empirical sampling distribution and the compute its mean and median\n<pre>\nplt.hist(ar_estimates_from_bootstrap, bins=20)\nprint(f'mean={np.mean(ar_estimates_from_bootstrap)}')\nprint(f'median={np.median(ar_estimates_from_bootstrap)}')\n</pre>\n\nFor the block-based bootstrap, GPU support requires the specification of a \nfunction compatible with NumPy's random.choice as well as a package \n(num_pack) that is compatible with NumPy.\n\n#### Cocos-Specific Convenience Functions\nThe module recombinator.bootstrap_cocos provides Cocos specific wrapper-functions \nfor GPU enabled vectorized bootstrap procedures.\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/michaelnowotny/recombinator", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "recombinator", "package_url": "https://pypi.org/project/recombinator/", "platform": "", "project_url": "https://pypi.org/project/recombinator/", "project_urls": {"Homepage": "https://github.com/michaelnowotny/recombinator"}, "release_url": "https://pypi.org/project/recombinator/0.0.4/", "requires_dist": ["cocos", "numba", "numpy", "pandas", "scipy", "pytest"], "requires_python": ">=3.6.0", "summary": "Recombinator - Statistical Resampling in Python", "version": "0.0.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Recombinator - Statistical Resampling in Python</h1>\n<h2>Overview</h2>\n<p>Recombinator is a Python package for statistical resampling in Python. It provides various algorithms for the iid bootstrap, the block bootstrap, as well as optimal block-length selection.</p>\n<h2>Algorithms</h2>\n<ul>\n<li>I.I.D. bootstrap: Standard i.i.d. bootstrap for one-dimensional and multi-dimensional data, balanced bootstrap, anthithetic bootstrap</li>\n<li>Block based bootstrap: Moving Block Bootstrap, Circular Block Bootstrap, Stationary Bootstrap, Tapered Block-Bootstrap</li>\n<li>Optimal block-length selection algorithm for Circular Block Bootstrap and Stationary Bootstrap</li>\n</ul>\n<h2>Table of Contents</h2>\n<ol>\n<li><a href=\"#installation\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#getting-started\" rel=\"nofollow\">Getting Started</a></li>\n</ol>\n<h2>Installation</h2>\n<h3>Latest Release</h3>\n<pre>    pip install recombinator\n</pre>\n<p>or</p>\n<pre>    pip3 install recombinator\n</pre>\n<p>if not using Anaconda.</p>\n<p>To get the latest version, clone the repository from github,\nopen a terminal/command prompt, navigate to the root folder and install via</p>\n<pre>    pip install .\n</pre>\n<p>or</p>\n<pre>    pip3 install . \n</pre>\n<p>if not using Anaconda.</p>\n<h3>Most Recent Version on GitHub</h3>\n<ol>\n<li>Clone the github repository via</li>\n</ol>\n<pre>    git clone https://github.com/InvestmentSystems/recombinator.git\n</pre>\n<ol>\n<li>Navigate to the Recombinator base directory and run</li>\n</ol>\n<pre>    pip install .\n</pre> \n<h2>Getting Started</h2>\n<p>Please see the Jupyter notebooks 'notebooks/Block Bootstrap.ipynb' and 'notebooks/IID Bootstrap.ipynb' for more examples.</p>\n<h3>Basic I.I.D. Bootstrap</h3>\n<p>Import modules</p>\n<pre>import matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport numpy as np\n\nfrom recombinator.iid_bootstrap import \\\n    iid_balanced_bootstrap, \\\n    iid_bootstrap, \\\n    iid_bootstrap_vectorized, \\\n    iid_bootstrap_via_choice, \\\n    iid_bootstrap_via_loop, \\\n    iid_bootstrap_with_antithetic_resampling\n</pre>\n<p>For illustrative purposes, generate an original dataset of sample size n=100 to resample from.</p>\n<pre>n=100\nnp.random.seed(1)\nx = np.abs(np.random.randn(n))\n</pre>\n<p>Estimate the 75th percentile from the original sample</p>\n<pre>percentile = 75\noriginal_statistic = np.percentile(x, percentile)\nprint(original_statistic)\n</pre>\n<p>Now generate 100000 new bootstrap samples by drawing from the original sample with replacement.</p>\n<pre>R = 100000\nx_resampled = iid_bootstrap(x, replications=R)\n</pre>\n<p>This produces a 100000 x 100 dimensional NumPy array. Each row is a new sample.</p>\n<p>If we instead wanted to resample without replacement, we could draw shorter samples.\nThis is known as as subsampling. See these lecture notes by Charles Geyer for statistical background:\n<a href=\"http://www.stat.umn.edu/geyer/5601/notes/sub.pdf\" rel=\"nofollow\">http://www.stat.umn.edu/geyer/5601/notes/sub.pdf</a>.</p>\n<p>In recombinator, subsampling is achieved by using the keyword arguments \"sub_sample_length\" and \"replace\".\nTo draw samples of size 50 without replacement we would write</p>\n<pre>x_resampled = iid_bootstrap(x, replications=R, sub_sample_length=50, replace=False)\n</pre>\n<p>Let us return to the original example of resampling at the full sample size with replacement.\nWe are interested in the sampling distribution of a statistic (in this example the 75th percentile of the distribution).\nHence, we calculate the statistic on each of the new bootstrap samples:</p>\n<pre>resampled_statistic = np.percentile(x_resampled, percentile, axis=1)\n</pre>\n<p>We can use Recombinator to estimate the bootstrap standard error and the 95%\nconfidence interval of the statistic as follows.</p>\n<pre>from recombinator.statistics import \\\n    estimate_confidence_interval_from_bootstrap, \\\n    estimate_standard_error_from_bootstrap\n</pre>\n<p>Estimate the standard error of the estimate of the 75th percentile via bootstrap:</p>\n<pre>estimate_standard_error_from_bootstrap(bootstrap_estimates=resampled_statistic,\n                                       original_estimate=original_statistic)\n</pre>\n<p>Estimate the 95% confidence interval of the 75th percentile via bootstrap:</p>\n<pre>estimate_confidence_interval_from_bootstrap(bootstrap_estimates=resampled_statistic, \n                                            confidence_level=95)\n</pre>\n<p>Recombinator supports other variations of the standard i.i.d. bootstrap\n(the balanced and the antithetic bootstrap). Please see the Jupyter notebook on the I.I.D. boostrap for examples.</p>\n<h3>Block-Based Bootstrap for Time-Series</h3>\n<p>Recombinator offers the following block-based approaches to resample temporally dependent data:</p>\n<ul>\n<li>Moving Block Bootstrap - Kuensch (1989)</li>\n<li>Circular Block Bootstrap - Politis and Romano (1992)</li>\n<li>Stationary Bootstrap - Politis and Romano (1994)</li>\n<li>Tapered Block Bootstrap - Paparoditis and Politis (2001)</li>\n</ul>\n<p>Import statsmodels for the estimation of time-series models.</p>\n<pre>from statsmodels.tsa.arima_process import ArmaProcess\nfrom statsmodels.tsa.ar_model import AR\nimport statsmodels.api as sm\nfrom statsmodels.graphics.tsaplots import plot_acf\n</pre>\n<p>Generate a sample of length n=1000 from an AR(1) process with autoregressive coefficient 0.5:</p>\n<pre>np.random.seed(1)\n\n# number of time periods\nT = 1000\n\n# draw random errors\ne = np.random.randn(T)\ny = np.zeros((T,))\n\n# y is an AR(1) with phi_1 = 0.5\nphi_1 = 0.5\ny[0] = e[0]*np.sqrt(1.0/(1.0-phi_1**2))\nfor t in range(1, T):\n    y[t]=phi_1*y[t-1] + e[t]\n</pre>\n<h4>Optimal Block-Length</h4>\n<p>In order to preserve temporal dependence in time-series data,\nbootstrap algorithms sample from the original data in blocks rather than\nsampling single observations.\nA key question is what block length to use.\nWe are using a data based block length selection algorithm due to Politis and White (2004)\nwith corrections by Patton, Politis, and White (2007).\nThis algorithm produces optimal block-lengths for the circular block bootstrap and the stationary bootstrap for the estimation of the variance of the mean.</p>\n<p>Import the optimal block-length selection functionality:</p>\n<pre>from recombinator.optimal_block_length import optimal_block_length\n</pre>\n<p>Compute the optimal block length of the sample from the AR(1) process created above:</p>\n<pre>b_star = optimal_block_length(y)\nb_star_sb = b_star[0].b_star_sb\nb_star_cb = math.ceil(b_star[0].b_star_cb)\nprint(f'optimal block length for stationary bootstrap = {b_star_sb}')\nprint(f'optimal block length for circular bootstrap = {b_star_cb}')\n</pre>\n<h4>Resampling using a Block-Based Bootstrap</h4>\n<p>We illustrate the procedure using the circular-block bootstrap.</p>\n<pre>from recombinator.block_bootstrap import circular_block_bootstrap\n</pre>\n<p>The true autoregressive coefficient of the process we simulated is 0.5.\nThe estimated coefficient from the simulated time-series is obtained as follows</p>\n<pre>ar = AR(y)\nestimate_from_original_data = ar.fit(maxlag=1)\nprint(estimate_from_original_data.params[1])\n</pre>\n<p>Statsmodels can produce an estimate of the standard error of the estimate of the autoregressive coefficient resorting to asymptotic theory:</p>\n<pre>print(estimate_from_original_data.bse[1])\n</pre> \n<p>Generate 10000 new time-series by resampling using a circular-block bootstrap</p>\n<pre># number of replications for bootstraps (number of resampled time-series to generate)\nB = 10000\n\ny_star_cb \\\n    = circular_block_bootstrap(y, \n                               block_length=b_star_cb, \n                               replications=B, \n                               replace=True)\n</pre>\n<p>Now estimate the AR coefficient on each of the bootstrap samples</p>\n<pre>estimates_from_bootstrap = []\nar_estimates_from_bootstrap = np.zeros((B, ))\n\nfor b in range(B):\n    y_bootstrap = y_star_cb[b, :]\n    ar_bootstrap = AR(y_bootstrap)\n    estimate_from_bootstrap = ar_bootstrap.fit(maxlag=1)\n    estimates_from_bootstrap.append(estimate_from_bootstrap)\n    ar_estimates_from_bootstrap[b] = estimate_from_bootstrap.params[1]\n</pre>\n<p>Plot the sampling distribution and compute its mean and median</p>\n<pre>plt.hist(ar_estimates_from_bootstrap, bins=20)\nprint(f'mean={np.mean(ar_estimates_from_bootstrap)}')\nprint(f'median={np.median(ar_estimates_from_bootstrap)}')\n</pre>\n<p>It turns out that the mean and median are below the AR coefficient estimated on the original sample.\nThis is due to the fact that the block bootstrap approach breaks the temporal\ndependence whenever a new block starts.\nOne can reduce this effect by choosing a higher block-length at the expense of\nreducing the number of possible permutations of the data.</p>\n<p>Another way to reduce this issue is to use a tapered-block bootstrap which is\ndesigned to mitigate artificial structural breaks introduced by the resampling\nprocedure at the block-transition points.</p>\n<p>Import the function</p>\n<pre>from recombinator.tapered_block_bootstrap import tapered_block_bootstrap\n</pre>\n<p>Run the tapered-block bootstrap</p>\n<pre>y_star_tbb \\\n    = tapered_block_bootstrap(y, \n                              block_length=b_star_cb, \n                              replications=B)\n</pre>\n<p>Again estimate the AR coefficient on each of the new bootstrap samples</p>\n<pre>estimates_from_bootstrap = []\nar_estimates_from_bootstrap = np.zeros((B, ))\n\nfor b in range(B):\n    y_bootstrap = y_star_tbb[b, :]\n    ar_bootstrap = AR(y_bootstrap)\n    estimate_from_bootstrap = ar_bootstrap.fit(maxlag=1)\n    estimates_from_bootstrap.append(estimate_from_bootstrap)\n    ar_estimates_from_bootstrap[b] = estimate_from_bootstrap.params[1]\n</pre>\n<p>... and plot the sampling distribution</p>\n<pre>plt.hist(ar_estimates_from_bootstrap, bins=20)\nprint(f'mean={np.mean(ar_estimates_from_bootstrap)}')\nprint(f'median={np.median(ar_estimates_from_bootstrap)}')\n</pre>\n<p>The mean and median of the distribution are now much closer to the estimate from the original time series.</p>\n<h3>Running Recombinator on a GPU</h3>\n<p>Resampling can be a computationally intensive task, which is highly parallelizable.\nThe implementations of various algorithms fall into two broad categories:</p>\n<ul>\n<li>Loop-based (via Numba)</li>\n<li>Vectorized (via NumPy)</li>\n</ul>\n<p>Vectorized implementations can be run on the GPU depending on the availability a\nGPU package with a NumPy compatible interface.\nTo this end, vectorized implementations in Recombinator lets the user specify\nalternative modules and functions that are to be used internally.</p>\n<p>A NumPy compatible package that supports both CUDA and OpenCL is Cocos\navailable at <a href=\"https://github.com/michaelnowotny/cocos\" rel=\"nofollow\">https://github.com/michaelnowotny/cocos</a>.</p>\n<p>Using Cocos, resampling on the GPU using Recombinator can be performed as follows.</p>\n<p>Import the NumPy-like Cocos package. This requires an ArrayFire installation, a compatible GPU, and the installation of Cocos.</p>\n<pre>import cocos.numerics as cn\nfrom cocos.device import gpu_sync_wrapper, sync\n</pre>\n<h4>I.I.D. Boostrap</h4>\n<p>Generate an original sample to work with</p>\n<pre>n = 100\ncn.random.seed(1)\nx_gpu = cn.absolute(cn.random.randn(n))\nplt.hist(x_gpu);\n</pre>\n<p>Resample using an i.i.d. boostrap</p>\n<pre>x_resampled_vectorized_gpu \\\n    = iid_bootstrap_vectorized(x_gpu, \n                               replications=R, \n                               randint=cn.random.randint)\nsync()\n</pre>\n<p>In this case, GPU support is achieved by simply specifying an alternative\nimplementation of NumPy's randint function.</p>\n<h4>Block-Based Bootstrap</h4>\n<p>Transfer the array created in the time-series example above to the GPU</p>\n<pre>y_gpu = cn.array(y)\n</pre>\n<p>Run a circular-block boostrap on the GPU</p>\n<pre>y_star_cb \\\n    = circular_block_bootstrap_vectorized(y_gpu, \n                                          block_length=b_star_cb, \n                                          replications=B, \n                                          replace=True, \n                                          num_pack=cn, \n                                          choice=cn.random.choice)\n</pre>\n<p>Estimate the AR coefficient on each of the bootstrap samples</p>\n<pre>estimates_from_bootstrap = []\nar_estimates_from_bootstrap = np.zeros((len(y_star_cb), ))\n\nfor b in range(len(y_star_cb)):\n    y_bootstrap = np.array(y_star_mb[b, :].squeeze())\n    ar_bootstrap = AR(y_bootstrap)\n    estimate_from_bootstrap = ar_bootstrap.fit(maxlag=1)\n    estimates_from_bootstrap.append(estimate_from_bootstrap)\n    ar_estimates_from_bootstrap[b] = estimate_from_bootstrap.params[1]\n</pre>\n<p>Plot the empirical sampling distribution and the compute its mean and median</p>\n<pre>plt.hist(ar_estimates_from_bootstrap, bins=20)\nprint(f'mean={np.mean(ar_estimates_from_bootstrap)}')\nprint(f'median={np.median(ar_estimates_from_bootstrap)}')\n</pre>\n<p>For the block-based bootstrap, GPU support requires the specification of a\nfunction compatible with NumPy's random.choice as well as a package\n(num_pack) that is compatible with NumPy.</p>\n<h4>Cocos-Specific Convenience Functions</h4>\n<p>The module recombinator.bootstrap_cocos provides Cocos specific wrapper-functions\nfor GPU enabled vectorized bootstrap procedures.</p>\n\n          </div>"}, "last_serial": 6575267, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "9605e3ff60b9ea7f956fb9dca6de6181", "sha256": "8b5b976156a4bc4527af38922a927e85a264a4c8e8183afe0d8a118147acc0a5"}, "downloads": -1, "filename": "recombinator-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "9605e3ff60b9ea7f956fb9dca6de6181", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 20466, "upload_time": "2019-07-03T01:29:16", "upload_time_iso_8601": "2019-07-03T01:29:16.538639Z", "url": "https://files.pythonhosted.org/packages/57/4f/6db305df2347f466f0b17f7579644c1c846ef76a2ef944a80dcf64bcdc25/recombinator-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ea66dcfb552a7686166664464e5c6c70", "sha256": "df6f7c1d75151ec16a127a00ab385fe1fbf2045cc931875a93e997e178443399"}, "downloads": -1, "filename": "recombinator-0.0.1.tar.gz", "has_sig": false, "md5_digest": "ea66dcfb552a7686166664464e5c6c70", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 16471, "upload_time": "2019-07-03T01:29:18", "upload_time_iso_8601": "2019-07-03T01:29:18.897962Z", "url": "https://files.pythonhosted.org/packages/9a/a3/37e4a06dbafa97e64a5231e24244bba927a9f2c6cef6a84ffbd5180531e1/recombinator-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "b841cf4602e9fa9ee10b3acad8c9b770", "sha256": "b9b177b04d46104c5918f4611fb958b5a97482692758dbf4239a6c9d89b120f2"}, "downloads": -1, "filename": "recombinator-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "b841cf4602e9fa9ee10b3acad8c9b770", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 22094, "upload_time": "2019-07-09T09:34:38", "upload_time_iso_8601": "2019-07-09T09:34:38.937931Z", "url": "https://files.pythonhosted.org/packages/3d/83/7a7a224b3e5a9b4270873462104444ad339be47ac4c56225238780bf7da5/recombinator-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "212a41a24d496603db0e01e0bdbff9f6", "sha256": "65e7ceaacee0ea43db168b7e2368f52dd80c64f69ee5d0b10e65da063f847669"}, "downloads": -1, "filename": "recombinator-0.0.2.tar.gz", "has_sig": false, "md5_digest": "212a41a24d496603db0e01e0bdbff9f6", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 17128, "upload_time": "2019-07-09T09:34:40", "upload_time_iso_8601": "2019-07-09T09:34:40.437911Z", "url": "https://files.pythonhosted.org/packages/71/89/ac7fab6f6269848e70305115584258e0fee0425cc770f1d913f3efc32e33/recombinator-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "d013881e9c9083746f6584c5aef72292", "sha256": "8ce343f4fba3bb6e66424e5cbca1c4b2f18d06a87275eae92567ea925b3a873e"}, "downloads": -1, "filename": "recombinator-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "d013881e9c9083746f6584c5aef72292", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 28415, "upload_time": "2019-07-17T04:23:52", "upload_time_iso_8601": "2019-07-17T04:23:52.754108Z", "url": "https://files.pythonhosted.org/packages/e3/79/4da0c103153555dd7fca4cfd9173c2a9eddc118208b14370e177ce8737eb/recombinator-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "15e58b08d76bc496d1d8e5a09c3d3430", "sha256": "3483eb2b0831ccb8f21afdbece6e23dbd44529178e0c3bb96cf3e0f5412fb685"}, "downloads": -1, "filename": "recombinator-0.0.3.tar.gz", "has_sig": false, "md5_digest": "15e58b08d76bc496d1d8e5a09c3d3430", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 23688, "upload_time": "2019-07-17T04:23:54", "upload_time_iso_8601": "2019-07-17T04:23:54.260035Z", "url": "https://files.pythonhosted.org/packages/a2/77/78bc818f5405db0b80d3cb01b28453e1711543aa36ff32fec616ad053a57/recombinator-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "5bbd0b583f0173d1e7076f0518587221", "sha256": "4a7015db0598ce465a4165948425c54e8dbce726473174e0851a12632d1959f3"}, "downloads": -1, "filename": "recombinator-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "5bbd0b583f0173d1e7076f0518587221", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 30671, "upload_time": "2020-02-05T10:38:29", "upload_time_iso_8601": "2020-02-05T10:38:29.330102Z", "url": "https://files.pythonhosted.org/packages/6e/bf/dde19b4cebdcd7d219862eb70b64b631afebbbeaa71e6959728a12793660/recombinator-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0e31824474078200b60f53f97af5716a", "sha256": "cc2889ce56ea5cdf03d66fd82c7f8369f111de38d063a5e1082fd215fa8a5bbc"}, "downloads": -1, "filename": "recombinator-0.0.4.tar.gz", "has_sig": false, "md5_digest": "0e31824474078200b60f53f97af5716a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 28242, "upload_time": "2020-02-05T10:38:31", "upload_time_iso_8601": "2020-02-05T10:38:31.092905Z", "url": "https://files.pythonhosted.org/packages/cd/bd/267e1251694cf1ca6fb5fec1c3c83d75e1f5108711182c455d19e96cbd80/recombinator-0.0.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "5bbd0b583f0173d1e7076f0518587221", "sha256": "4a7015db0598ce465a4165948425c54e8dbce726473174e0851a12632d1959f3"}, "downloads": -1, "filename": "recombinator-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "5bbd0b583f0173d1e7076f0518587221", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 30671, "upload_time": "2020-02-05T10:38:29", "upload_time_iso_8601": "2020-02-05T10:38:29.330102Z", "url": "https://files.pythonhosted.org/packages/6e/bf/dde19b4cebdcd7d219862eb70b64b631afebbbeaa71e6959728a12793660/recombinator-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0e31824474078200b60f53f97af5716a", "sha256": "cc2889ce56ea5cdf03d66fd82c7f8369f111de38d063a5e1082fd215fa8a5bbc"}, "downloads": -1, "filename": "recombinator-0.0.4.tar.gz", "has_sig": false, "md5_digest": "0e31824474078200b60f53f97af5716a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 28242, "upload_time": "2020-02-05T10:38:31", "upload_time_iso_8601": "2020-02-05T10:38:31.092905Z", "url": "https://files.pythonhosted.org/packages/cd/bd/267e1251694cf1ca6fb5fec1c3c83d75e1f5108711182c455d19e96cbd80/recombinator-0.0.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:06:10 2020"}