{"info": {"author": "James Gardner, Stefan Urbanek, Rufus Pollock", "author_email": "ckan@okfn.org", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "License :: OSI Approved :: GNU Affero General Public License v3", "Programming Language :: Python"], "description": "Data Proxy: a google app-engine application for proxying data to json (jsonp) format.\n\nAuthor: James Gardner <http://jimmyg.org>\nAuthor: Stefan Urbanek <stefan.urbanek@gmail.com>\n\nTransformation modules\n======================\n\nFor each resource type there should be a module in transform/<type>_transform.py\n\nEach module should implement:\n* ``transformer(flow, url, query)``, should return a Transformer subclass\n* Transformer subclass with __init__(flow, url, query)\n\nExisting modules:\n* transform/csv_transform - CSV files\n* transform/xls_transform - Excel XLS files\n\n\nRandom notes\n============\n\nMount point\nMaximum file size\n\nhttp://someproxy.example.org/mount_point?url=url_encoded&sheet=1&range=A1:K3&doc=no&indent=4&format=jsonp\n\nResponse format:\n\nheader \n    url = http://...file.xls\n    option = 'row=5&row=7&row_range=10:100000:5000',\nresponse\n    sheet = 'Sheet 1',\n    data = [\n        [...],\n        [...],\n        [...],\n    ]\n\n* Downloading the entire spreadsheet\n* Downloading a single sheet (add ``sheet=1`` to the URL)\n* Downloading a range in a single sheet (add ``range=A1:K3`` to the URL) [a bit nasty for CSV files but will do I think]\n* Choosing a limited set of rows within the sheet (add ``row=5&row=7&row_range=10:100000:5000`` - rowrange format would be give me a row between 10 and 100000 every 5000 rows)\n\n\nHurdles\n-------\n* Some data sets are not in text-based formats => Don't handle them at this stage\n* Excel spreadhseets have formatting and different types => Ignore it, turn everything into a string for now\n* Some data sets are huge => don't proxy more than 100K of data - up to the user to filter it down if needed\n* We don't want to re-download data sets => Need a way to cache data -> storage API\n* Some applications might be wildly popular and put strain on the system -> perhaps API keys and rate limiting are needed so that individual apps/feeds can be disabled. How can we have read API keys on data.gov.uk?", "description_content_type": null, "docs_url": "https://pythonhosted.org/dataproxy/", "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://ckan.org/wiki/Extensions", "keywords": "", "license": "GNU AGPLv3", "maintainer": null, "maintainer_email": null, "name": "dataproxy", "package_url": "https://pypi.org/project/dataproxy/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/dataproxy/", "project_urls": {"Download": "UNKNOWN", "Homepage": "http://ckan.org/wiki/Extensions"}, "release_url": "https://pypi.org/project/dataproxy/0.1.0/", "requires_dist": null, "requires_python": null, "summary": "A (JSONP) dataproxy", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            Data Proxy: a google app-engine application for proxying data to json (jsonp) format.<br><br>Author: James Gardner &lt;http://jimmyg.org&gt;<br>Author: Stefan Urbanek &lt;stefan.urbanek@gmail.com&gt;<br><br>Transformation modules<br>======================<br><br>For each resource type there should be a module in transform/&lt;type&gt;_transform.py<br><br>Each module should implement:<br>* ``transformer(flow, url, query)``, should return a Transformer subclass<br>* Transformer subclass with __init__(flow, url, query)<br><br>Existing modules:<br>* transform/csv_transform - CSV files<br>* transform/xls_transform - Excel XLS files<br><br><br>Random notes<br>============<br><br>Mount point<br>Maximum file size<br><br>http://someproxy.example.org/mount_point?url=url_encoded&amp;sheet=1&amp;range=A1:K3&amp;doc=no&amp;indent=4&amp;format=jsonp<br><br>Response format:<br><br>header <br>    url = http://...file.xls<br>    option = 'row=5&amp;row=7&amp;row_range=10:100000:5000',<br>response<br>    sheet = 'Sheet 1',<br>    data = [<br>        [...],<br>        [...],<br>        [...],<br>    ]<br><br>* Downloading the entire spreadsheet<br>* Downloading a single sheet (add ``sheet=1`` to the URL)<br>* Downloading a range in a single sheet (add ``range=A1:K3`` to the URL) [a bit nasty for CSV files but will do I think]<br>* Choosing a limited set of rows within the sheet (add ``row=5&amp;row=7&amp;row_range=10:100000:5000`` - rowrange format would be give me a row between 10 and 100000 every 5000 rows)<br><br><br>Hurdles<br>-------<br>* Some data sets are not in text-based formats =&gt; Don't handle them at this stage<br>* Excel spreadhseets have formatting and different types =&gt; Ignore it, turn everything into a string for now<br>* Some data sets are huge =&gt; don't proxy more than 100K of data - up to the user to filter it down if needed<br>* We don't want to re-download data sets =&gt; Need a way to cache data -&gt; storage API<br>* Some applications might be wildly popular and put strain on the system -&gt; perhaps API keys and rate limiting are needed so that individual apps/feeds can be disabled. How can we have read API keys on data.gov.uk?\n          </div>"}, "last_serial": 788807, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "5636e1e40bdd84bf8caf387d841e2f8d", "sha256": "0095638765fb7686c619b118acc492970d2aed9f4d1ea686039d12c367772007"}, "downloads": -1, "filename": "dataproxy-0.1.0.tar.gz", "has_sig": false, "md5_digest": "5636e1e40bdd84bf8caf387d841e2f8d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 93098, "upload_time": "2011-01-20T14:14:47", "upload_time_iso_8601": "2011-01-20T14:14:47.053493Z", "url": "https://files.pythonhosted.org/packages/1b/d5/4f3d0e0e171d2bb7d646785dbe568f5b040145eeb6dc3a95b65279be3f4a/dataproxy-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "5636e1e40bdd84bf8caf387d841e2f8d", "sha256": "0095638765fb7686c619b118acc492970d2aed9f4d1ea686039d12c367772007"}, "downloads": -1, "filename": "dataproxy-0.1.0.tar.gz", "has_sig": false, "md5_digest": "5636e1e40bdd84bf8caf387d841e2f8d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 93098, "upload_time": "2011-01-20T14:14:47", "upload_time_iso_8601": "2011-01-20T14:14:47.053493Z", "url": "https://files.pythonhosted.org/packages/1b/d5/4f3d0e0e171d2bb7d646785dbe568f5b040145eeb6dc3a95b65279be3f4a/dataproxy-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:40:15 2020"}