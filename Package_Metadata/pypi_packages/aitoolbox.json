{"info": {"author": "Marko Vidoni", "author_email": "", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "# AI Toolbox\n\n[![Build Status](https://travis-ci.org/mv1388/AIToolbox.svg?branch=master)](https://travis-ci.org/mv1388/AIToolbox)\n[![Documentation Status](https://readthedocs.org/projects/aitoolbox/badge/?version=latest)](https://aitoolbox.readthedocs.io/en/latest/?badge=latest)\n&nbsp; &nbsp;\n[![codebeat badge](https://codebeat.co/badges/04217a3f-a838-418f-8f14-66cf6ae1b03d)](https://codebeat.co/projects/github-com-mv1388-aitoolbox-master)\n[![Codacy Badge](https://api.codacy.com/project/badge/Grade/8349596c31a948d8916814a2037ffdf3)](https://www.codacy.com/manual/mv1388/AIToolbox?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=mv1388/AIToolbox&amp;utm_campaign=Badge_Grade)\n[![CodeFactor](https://www.codefactor.io/repository/github/mv1388/aitoolbox/badge)](https://www.codefactor.io/repository/github/mv1388/aitoolbox)\n\n[**Documentation**](https://aitoolbox.readthedocs.io/en/latest/)\n\n\nA framework which helps you train deep learning models in PyTorch and quickly iterate experiments. \nIt hides the repetitive technicalities of training the neural nets and \nfrees you to focus on interesting part of devising new models. \nIn essence, it offers a keras-style train loop abstraction which can be used for higher \nlevel training process while still allowing the manual control on the lower \nlevel when desired.\n\nIn addition to orchestrating the model training loop the framework also helps you keep track of different \nexperiments by automatically saving models in a structured traceable way and creating performance reports. \nThese can be stored both locally or on AWS S3 (Google Cloud Storage in beta) which makes the library \nvery useful when training on the GPU instance on AWS. Instance can be \nautomatically shut down when training is finished and all the results \nare safely stored on S3.\n\n\n## Installation\n\nTo install the AIToolbox package first clone this repository and then install via the `pip` command:\n```bash\ngit clone https://github.com/mv1388/aitoolbox.git\n\npip install ./aitoolbox\n```\n\nAIToolbox package can be also provided as a dependency in the `requirements.txt` file. To automatically\ndownload the current master branch from github include the following dependency specification in the requirements.txt:\n```bash\ngit+https://github.com/mv1388/aitoolbox#egg=aitoolbox\n```  \n\n\n## TrainLoop\n\n[`TrainLoop`](/aitoolbox/torchtrain/train_loop.py) is the main abstraction for PyTorch neural net training. At its core\nit handles the batch feeding of data into the model, calculating loss and updating parameters for a specified number of epochs.\nTo learn how to define the TrainLoop supported PyTorch model please look at the [Model](#model) section bellow.\n\nAfter the model is created, the simplest way to train it via the TrainLoop abstraction is by doing the following:\n```python\nfrom aitoolbox.torchtrain.train_loop import *\n\ntl = TrainLoop(model,\n               train_loader, val_loader, test_loader,\n               optimizer, criterion)\n\nmodel = tl.fit(num_epochs=10)\n```\n\nAIToolbox includes a few more advanced derivations of the basic TrainLoop\nwhich automatically handle the experiment tracking by creating model\ncheckpoints, performance reports, example predictions, etc. All of this can be saved just on the local drive\nor can also be automatically also stored on AWS S3.  Currently implemented advanced \n[`TrainLoops`](/aitoolbox/torchtrain/train_loop.py) are `TrainLoopCheckpoint`, `TrainLoopEndSave` and `TrainLoopCheckpointEndSave`.\nHere, 'Checkpoint' stands for checkpointing after each epoch, while 'EndSave' will only persist and evaluate at the very end of the training. \n\nFor the most complete experiment tracking it is recommended to use the `TrainLoopCheckpointEndSave` option. \nThe optional use of the *result packages* needed for the neural net performance evaluation is explained in \nthe [experiment section](#experiment) bellow.\n```python\nfrom aitoolbox.torchtrain.train_loop import *\n\nTrainLoopCheckpointEndSave(\n    model,\n    train_loader, validation_loader, test_loader,\n    optimizer, criterion,\n    project_name, experiment_name, local_model_result_folder_path,\n    hyperparams, val_result_package=None, test_result_package=None,\n    cloud_save_mode='s3', bucket_name='models', cloud_dir_prefix=''\n)\n```\n\nCheck out a full [TrainLoop training & experiment tracking example](https://github.com/mv1388/aitoolbox/blob/master/examples/TrainLoop_use/trainloop_fully_tracked_experiment.py).\n\n\n## Multi-GPU training\n\nAll TrainLoop versions in addition to single GPU also support multi-GPU training to achieve even faster training.\nFollowing the core PyTorch setup, two multi-GPU training approaches are available: \n`DataParallel` implemented via `TTDataParallel` and `DistributedDataParallel` implemented via `TTDistributedDataParallel`.\n\n### DataParallel - via TTDataParallel\n\nTo use DataParallel-like multiGPU training with TrainLoop just wrap the model (`TTModel`, [more in Model section](#model))\ninto the `TTDataParallel` object, the same way it would done in core PyTorch:\n```python\nfrom aitoolbox.torchtrain.train_loop import *\nfrom aitoolbox.torchtrain.parallel import TTDataParallel\n\nmodel = ... # TTModel\nmodel = TTDataParallel(model)\n\nTrainLoop(\n    model,\n    train_loader, val_loader, test_loader,\n    optimizer, criterion\n).fit(num_epochs=10)\n```\n\nCheck out a full [DataParallel training example](https://github.com/mv1388/aitoolbox/blob/master/examples/dp_ddp_training/dp_training.py).\n\n### DistributedDataParallel - via TTDistributedDataParallel\n\nDistributed training on multiple GPUs via DistributedDataParallel is enabled by the TrainLoop itself under\nthe hood by wrapping the model (`TTModel`, [more in Model section](#model)) into `TTDistributedDataParallel`.\nTrainLoop also automatically spawns multiple processes and initializes them. Inside each spawned process\nthe model and all other necessary training components are moved to the correct GPU belonging to a specific\nprocess. Lastly, TrainLoop also automatically adds the PyTorch `DistributedSampler` to each of the provided\ndata loaders in order to ensure different data batches go to different GPUs and there is no overlap.\n\nTo enable distributed training via DistributedDataParallel, all the user has to do is to initialize\nTrainLoop where `TTModel` should be provided and then call train loop's dedicated `fit_distributed()` \nfunction (instead of `fit()` used otherwise when not training distributed).\n```python\nfrom aitoolbox.torchtrain.train_loop import *\n\nmodel = ... # TTModel\n\nTrainLoop(\n    model,\n    train_loader, val_loader, test_loader,\n    optimizer, criterion\n).fit_distributed(num_epochs=10, callbacks=None,\n                  train_data_shuffle=True, ddp_model_args=None,\n                  num_nodes=1, node_rank=0, num_gpus=torch.cuda.device_count())\n```\n\nCheck out a full [DistributedDataParallel training example](https://github.com/mv1388/aitoolbox/blob/master/examples/dp_ddp_training/ddp_training.py).\n\n## Automatic Mixed Precision training via Nvidia Apex\n\nAll the TrainLoop versions also support training with Automatic Mixed Precision (*AMP*)\nusing the [Nvidia apex](https://github.com/NVIDIA/apex) extension. To use this feature the user first\nhas to install the Nvidia apex library ([installation instructions](https://github.com/NVIDIA/apex#linux)).\n\nThe user only has to set the TrainLoop parameter `use_amp` to `use_amp=True` in order to use the default \nAMP initialization and start training the model in the mixed precision mode. If the user wants to specify custom \nAMP initialization parameters, these should be provided as a dict parameter `use_amp={'opt_level': 'O1'}` to \nthe TrainLoop. All AMP initializations and training related steps are then handled automatically by the TrainLoop. \n\nYou can read more about different AMP optimization levels in the\n[Nvidia apex documentation](https://nvidia.github.io/apex/amp.html#opt-levels-and-properties).\n\n### Single-GPU mixed precision training\nExample of single-GPU APEX setup:\n```python\nfrom aitoolbox.torchtrain.train_loop import *\n\nmodel = ... # TTModel\n\nTrainLoop(\n    model, ...,\n    optimizer, criterion, use_amp={'opt_level': 'O1'}\n).fit(num_epochs=10)\n``` \n\nCheck out a full [Apex AMP training example](https://github.com/mv1388/aitoolbox/blob/master/examples/apex_amp_training/apex_single_GPU_training.py).\n\n### Multi-GPU DDP mixed precision training\nWhen training in the multi-GPU setting, the setup is mostly the same as in the single-GPU. \nAll the user has to do is set accordingly the `use_amp` parameter of the TrainLoop and to instead call \n`fit_distributed()` in order to start the distributed training. \nUnder the hood, TrainLoop will initialize the model and the optimizer for AMP and start training using \nDistributedDataParallel approach (DDP is currently only multi-GPU training setup supported by Apex AMP).\n```python\nfrom aitoolbox.torchtrain.train_loop import *\n\nmodel = ... # TTModel\n\nTrainLoop(\n    model, ...,\n    optimizer, criterion, use_amp={'opt_level': 'O1'}\n).fit_distributed(num_epochs=10)\n``` \n\nCheck out a full [Apex AMP DistributedDataParallel training example](https://github.com/mv1388/aitoolbox/blob/master/examples/apex_amp_training/apex_mutli_GPU_training.py).\n\n\n## Model\n\nTo take advantage of the TrainLoop abstraction the user has to define their model as a class which is a standard way\nin core PyTorch as well. The only difference is that for TrainLoop supported training the model class has \nto be inherited from the AIToolbox specific [`TTModel`](/aitoolbox/torchtrain/model.py) base class instead of PyTorch `nn.Module`.\n\n`TTModel` itself inherits from the normally used `nn.Module` class thus our models still\nretain all the expected PyTorch enabled functionality. The reason for using the TTModel super class is that\nTrainLoop requires users to implement two additional methods which describe how each batch of data\nis fed into the model when calculating the loss in the training mode and when making the predictions in the \nevaluation mode.\n\nThe code below shows the general skeleton all the TTModels have to follow to enable them to be trained \nwith the TrainLoop:\n```python\nfrom aitoolbox.torchtrain.model import TTModel\n\nclass MyNeuralModel(TTModel):\n    def __init__(self):\n        # model layers, etc.\n\n    def forward(self, x_data_batch):\n        # The same method as required in the base PyTorch nn.Module\n        ...\n        # return prediction\n\n    def get_loss(self, batch_data, criterion, device):\n        # Get loss during training stage, called from fit() in TrainLoop\n        ...\n        # return batch loss\n\n    def get_predictions(self, batch_data, device):\n        # Get predictions during evaluation stage \n        # + return any metadata potentially needed for evaluation\n        ...\n        # return predictions, true_targets, metadata\n```\n\n## Callbacks\n\nFor advanced applications the basic logic offered in different default TrainLoops might not be enough.\nAdditional needed logic can be injected into the training procedure by using [`callbacks`](/aitoolbox/torchtrain/callbacks)\nand providing them as a parameter list to TrainLoop's `fit(callbacks=[callback_1, callback_2, ...])` function. \n\nAIToolbox by default already offers a wide selection of different useful callbacks. However when\nsome completely new functionality is desired the user can also implement their own callbacks by \ninheriting from the base callback object [`AbstractCallback`](/aitoolbox/torchtrain/callbacks/abstract.py). \nAll that the user has to do is to implement corresponding methods to execute the new callback \nat the desired point in the train loop, such as: start/end of batch, epoch, training.\n\n\n## experiment\n\n### Result Package\n\nThis is the definition of the model evaluation procedure on the task we are experimenting with.\nResult packages available out of the box can be found in the [`result_package` module](/aitoolbox/experiment/result_package/)\nwhere we have implemented several [basic, general result packages](/aitoolbox/experiment/result_package/basic_packages.py). \nFurthermore, for those dealing with NLP, result packages for\nseveral widely researched NLP tasks such as translation, QA can be found as part of the \n[`NLP` module](/aitoolbox/nlp/experiment_evaluation/NLP_result_package.py)\nmodule. Last but not least, as the framework was built with extensibility in mind and thus \nif needed the users can easily define their own result packages with custom evaluations by extending the base\n[`AbstractResultPackage`](/aitoolbox/experiment/result_package/abstract_result_packages.py). \n\nUnder the hood the result package executes one or more [`metrics`](/aitoolbox/experiment/core_metrics) objects which actually \ncalculate the performance metric calculation. Result package object is thus used as a wrapper \naround potentially multiple performance calculations which are needed for our task. The metrics\nwhich are part of the specified result package are calculated by calling the `prepare_result_package()` method \nof the result package which we are using to evaluate model's performance.\n\n### Experiment Saver \n\nThe experiment saver saves the model architecture as well as model performance evaluation results and training history. \nThis can be done at the end of each epoch as a model checkpointing or at the end of training.\n\nNormally not really a point of great interest when using the TrainLoop interface as it is hidden under the hood.\nHowever as AIToolbox was designed to be modular one can decide to write their own training loop logic but\njust use the provided experiment saver module to help with the experiment tracking and model saving.\nFor PyTorch users we recommend using the [`FullPyTorchExperimentS3Saver`](/aitoolbox/experiment/experiment_saver.py) \nwhich has also been most thoroughly tested. \nThe experiment is saved by calling the `save_experiment()` function from the selected experiment saver and \nproviding the trained model and the evaluated result package containing the calculated performance results.\n\n\n## cloud\n\nAll of these modules are mainly hidden under the hood when using different experiment tracking\nabstractions. However, if desired and only the cloud saving functionality is needed it is easy to use them\nas standalone modules in some desired downstream application.\n\n### AWS \n\nFunctionality for saving model architecture and training results to S3 either during \ntraining or at the training end. On the other hand, the module also offers the dataset downloading\nfrom the S3 based dataset store. This is useful when we are experimenting with datasets and have only a slow\nlocal connection, thus scp/FTP is out of the picture.\n\n### Google Cloud\n\nSame functionality as for AWS S3 but for Google Cloud Storage. \nImplemented, however, not yet tested in practice. \n\n\n## nlp\n\nCurrently, mainly used for the performance evaluation [`result packages`](/aitoolbox/nlp/experiment_evaluation/NLP_result_package.py) \nneeded for different NLP tasks, such as Q&A, summarization, machine translation. \n\nFor the case of e.g. NMT the module also provides [attention heatmap plotting](/aitoolbox/nlp/experiment_evaluation/attention_heatmap.py)\nwhich is often helpful for gaining addition insights into the seq2seq model. The heatmap plotter\ncreates attention heatmap plots for every validation example and saves them as pictures to disk \n(potentially also to cloud).\n\nLastly, the nlp module also provides several rudimentary NLP data processing functions.\n\n\n## AWS GPU instance prep and management bash scripts\n\nAs some of the tasks when training models on the cloud GPU are quite repetitive, the package\nalso includes several useful bash scripts to automatize tasks such as instance init preparation,\nexperiment file updating, remote AIToolbox installation updating, etc.\n\nFor further information look into the [`/bin/AWS`](/bin/AWS/) folder and read \nthe provided [README](/bin/AWS/README.md).\n\n\n# Examples of package usage\n\nLook into the [`/examples`](/examples) folder for starters. \nWill be adding more examples of different training scenarios.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/mv1388/AIToolbox", "keywords": "PyTorch,deep learning,research,train loop", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "aitoolbox", "package_url": "https://pypi.org/project/aitoolbox/", "platform": "", "project_url": "https://pypi.org/project/aitoolbox/", "project_urls": {"Homepage": "https://github.com/mv1388/AIToolbox"}, "release_url": "https://pypi.org/project/aitoolbox/1.0/", "requires_dist": ["numpy", "pandas", "scikit-learn", "matplotlib", "seaborn", "torch", "torchvision", "torchtext", "pytorch-nlp", "joblib", "tqdm", "awscli", "boto3", "botocore", "google-cloud-storage", "nltk", "allennlp", "pyrouge", "rouge"], "requires_python": ">=3.6.0", "summary": "PyTorch Model Training and Experiment Tracking Framework", "version": "1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>AI Toolbox</h1>\n<p><a href=\"https://travis-ci.org/mv1388/AIToolbox\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/45ff83157c554b11d8ce683109326907225da4d3/68747470733a2f2f7472617669732d63692e6f72672f6d76313338382f4149546f6f6c626f782e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://aitoolbox.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fe13e33af00c8c5a7118f4ee3be9554fa543baea/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6169746f6f6c626f782f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n\u00a0 \u00a0\n<a href=\"https://codebeat.co/projects/github-com-mv1388-aitoolbox-master\" rel=\"nofollow\"><img alt=\"codebeat badge\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/eac759f34e3ef17acc3adfa32749deb038a3f58f/68747470733a2f2f636f6465626561742e636f2f6261646765732f30343231376133662d613833382d343138662d386631342d363663663661653162303364\"></a>\n<a href=\"https://www.codacy.com/manual/mv1388/AIToolbox?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=mv1388/AIToolbox&amp;utm_campaign=Badge_Grade\" rel=\"nofollow\"><img alt=\"Codacy Badge\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ce62244f042e2397a5525eeab73590cd2c49af99/68747470733a2f2f6170692e636f646163792e636f6d2f70726f6a6563742f62616467652f47726164652f3833343935393663333161393438643839313638313461323033376666646633\"></a>\n<a href=\"https://www.codefactor.io/repository/github/mv1388/aitoolbox\" rel=\"nofollow\"><img alt=\"CodeFactor\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a9dfb1cf36a14e413376a1c52b3aa977a2bb6e45/68747470733a2f2f7777772e636f6465666163746f722e696f2f7265706f7369746f72792f6769746875622f6d76313338382f6169746f6f6c626f782f6261646765\"></a></p>\n<p><a href=\"https://aitoolbox.readthedocs.io/en/latest/\" rel=\"nofollow\"><strong>Documentation</strong></a></p>\n<p>A framework which helps you train deep learning models in PyTorch and quickly iterate experiments.\nIt hides the repetitive technicalities of training the neural nets and\nfrees you to focus on interesting part of devising new models.\nIn essence, it offers a keras-style train loop abstraction which can be used for higher\nlevel training process while still allowing the manual control on the lower\nlevel when desired.</p>\n<p>In addition to orchestrating the model training loop the framework also helps you keep track of different\nexperiments by automatically saving models in a structured traceable way and creating performance reports.\nThese can be stored both locally or on AWS S3 (Google Cloud Storage in beta) which makes the library\nvery useful when training on the GPU instance on AWS. Instance can be\nautomatically shut down when training is finished and all the results\nare safely stored on S3.</p>\n<h2>Installation</h2>\n<p>To install the AIToolbox package first clone this repository and then install via the <code>pip</code> command:</p>\n<pre>git clone https://github.com/mv1388/aitoolbox.git\n\npip install ./aitoolbox\n</pre>\n<p>AIToolbox package can be also provided as a dependency in the <code>requirements.txt</code> file. To automatically\ndownload the current master branch from github include the following dependency specification in the requirements.txt:</p>\n<pre>git+https://github.com/mv1388/aitoolbox#egg<span class=\"o\">=</span>aitoolbox\n</pre>\n<h2>TrainLoop</h2>\n<p><a href=\"/aitoolbox/torchtrain/train_loop.py\" rel=\"nofollow\"><code>TrainLoop</code></a> is the main abstraction for PyTorch neural net training. At its core\nit handles the batch feeding of data into the model, calculating loss and updating parameters for a specified number of epochs.\nTo learn how to define the TrainLoop supported PyTorch model please look at the <a href=\"#model\" rel=\"nofollow\">Model</a> section bellow.</p>\n<p>After the model is created, the simplest way to train it via the TrainLoop abstraction is by doing the following:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">aitoolbox.torchtrain.train_loop</span> <span class=\"kn\">import</span> <span class=\"o\">*</span>\n\n<span class=\"n\">tl</span> <span class=\"o\">=</span> <span class=\"n\">TrainLoop</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span>\n               <span class=\"n\">train_loader</span><span class=\"p\">,</span> <span class=\"n\">val_loader</span><span class=\"p\">,</span> <span class=\"n\">test_loader</span><span class=\"p\">,</span>\n               <span class=\"n\">optimizer</span><span class=\"p\">,</span> <span class=\"n\">criterion</span><span class=\"p\">)</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">num_epochs</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n</pre>\n<p>AIToolbox includes a few more advanced derivations of the basic TrainLoop\nwhich automatically handle the experiment tracking by creating model\ncheckpoints, performance reports, example predictions, etc. All of this can be saved just on the local drive\nor can also be automatically also stored on AWS S3.  Currently implemented advanced\n<a href=\"/aitoolbox/torchtrain/train_loop.py\" rel=\"nofollow\"><code>TrainLoops</code></a> are <code>TrainLoopCheckpoint</code>, <code>TrainLoopEndSave</code> and <code>TrainLoopCheckpointEndSave</code>.\nHere, 'Checkpoint' stands for checkpointing after each epoch, while 'EndSave' will only persist and evaluate at the very end of the training.</p>\n<p>For the most complete experiment tracking it is recommended to use the <code>TrainLoopCheckpointEndSave</code> option.\nThe optional use of the <em>result packages</em> needed for the neural net performance evaluation is explained in\nthe <a href=\"#experiment\" rel=\"nofollow\">experiment section</a> bellow.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">aitoolbox.torchtrain.train_loop</span> <span class=\"kn\">import</span> <span class=\"o\">*</span>\n\n<span class=\"n\">TrainLoopCheckpointEndSave</span><span class=\"p\">(</span>\n    <span class=\"n\">model</span><span class=\"p\">,</span>\n    <span class=\"n\">train_loader</span><span class=\"p\">,</span> <span class=\"n\">validation_loader</span><span class=\"p\">,</span> <span class=\"n\">test_loader</span><span class=\"p\">,</span>\n    <span class=\"n\">optimizer</span><span class=\"p\">,</span> <span class=\"n\">criterion</span><span class=\"p\">,</span>\n    <span class=\"n\">project_name</span><span class=\"p\">,</span> <span class=\"n\">experiment_name</span><span class=\"p\">,</span> <span class=\"n\">local_model_result_folder_path</span><span class=\"p\">,</span>\n    <span class=\"n\">hyperparams</span><span class=\"p\">,</span> <span class=\"n\">val_result_package</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">test_result_package</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n    <span class=\"n\">cloud_save_mode</span><span class=\"o\">=</span><span class=\"s1\">'s3'</span><span class=\"p\">,</span> <span class=\"n\">bucket_name</span><span class=\"o\">=</span><span class=\"s1\">'models'</span><span class=\"p\">,</span> <span class=\"n\">cloud_dir_prefix</span><span class=\"o\">=</span><span class=\"s1\">''</span>\n<span class=\"p\">)</span>\n</pre>\n<p>Check out a full <a href=\"https://github.com/mv1388/aitoolbox/blob/master/examples/TrainLoop_use/trainloop_fully_tracked_experiment.py\" rel=\"nofollow\">TrainLoop training &amp; experiment tracking example</a>.</p>\n<h2>Multi-GPU training</h2>\n<p>All TrainLoop versions in addition to single GPU also support multi-GPU training to achieve even faster training.\nFollowing the core PyTorch setup, two multi-GPU training approaches are available:\n<code>DataParallel</code> implemented via <code>TTDataParallel</code> and <code>DistributedDataParallel</code> implemented via <code>TTDistributedDataParallel</code>.</p>\n<h3>DataParallel - via TTDataParallel</h3>\n<p>To use DataParallel-like multiGPU training with TrainLoop just wrap the model (<code>TTModel</code>, <a href=\"#model\" rel=\"nofollow\">more in Model section</a>)\ninto the <code>TTDataParallel</code> object, the same way it would done in core PyTorch:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">aitoolbox.torchtrain.train_loop</span> <span class=\"kn\">import</span> <span class=\"o\">*</span>\n<span class=\"kn\">from</span> <span class=\"nn\">aitoolbox.torchtrain.parallel</span> <span class=\"kn\">import</span> <span class=\"n\">TTDataParallel</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"o\">...</span> <span class=\"c1\"># TTModel</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">TTDataParallel</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">)</span>\n\n<span class=\"n\">TrainLoop</span><span class=\"p\">(</span>\n    <span class=\"n\">model</span><span class=\"p\">,</span>\n    <span class=\"n\">train_loader</span><span class=\"p\">,</span> <span class=\"n\">val_loader</span><span class=\"p\">,</span> <span class=\"n\">test_loader</span><span class=\"p\">,</span>\n    <span class=\"n\">optimizer</span><span class=\"p\">,</span> <span class=\"n\">criterion</span>\n<span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">num_epochs</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n</pre>\n<p>Check out a full <a href=\"https://github.com/mv1388/aitoolbox/blob/master/examples/dp_ddp_training/dp_training.py\" rel=\"nofollow\">DataParallel training example</a>.</p>\n<h3>DistributedDataParallel - via TTDistributedDataParallel</h3>\n<p>Distributed training on multiple GPUs via DistributedDataParallel is enabled by the TrainLoop itself under\nthe hood by wrapping the model (<code>TTModel</code>, <a href=\"#model\" rel=\"nofollow\">more in Model section</a>) into <code>TTDistributedDataParallel</code>.\nTrainLoop also automatically spawns multiple processes and initializes them. Inside each spawned process\nthe model and all other necessary training components are moved to the correct GPU belonging to a specific\nprocess. Lastly, TrainLoop also automatically adds the PyTorch <code>DistributedSampler</code> to each of the provided\ndata loaders in order to ensure different data batches go to different GPUs and there is no overlap.</p>\n<p>To enable distributed training via DistributedDataParallel, all the user has to do is to initialize\nTrainLoop where <code>TTModel</code> should be provided and then call train loop's dedicated <code>fit_distributed()</code>\nfunction (instead of <code>fit()</code> used otherwise when not training distributed).</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">aitoolbox.torchtrain.train_loop</span> <span class=\"kn\">import</span> <span class=\"o\">*</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"o\">...</span> <span class=\"c1\"># TTModel</span>\n\n<span class=\"n\">TrainLoop</span><span class=\"p\">(</span>\n    <span class=\"n\">model</span><span class=\"p\">,</span>\n    <span class=\"n\">train_loader</span><span class=\"p\">,</span> <span class=\"n\">val_loader</span><span class=\"p\">,</span> <span class=\"n\">test_loader</span><span class=\"p\">,</span>\n    <span class=\"n\">optimizer</span><span class=\"p\">,</span> <span class=\"n\">criterion</span>\n<span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">fit_distributed</span><span class=\"p\">(</span><span class=\"n\">num_epochs</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">callbacks</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n                  <span class=\"n\">train_data_shuffle</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">ddp_model_args</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n                  <span class=\"n\">num_nodes</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">node_rank</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">num_gpus</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"o\">.</span><span class=\"n\">device_count</span><span class=\"p\">())</span>\n</pre>\n<p>Check out a full <a href=\"https://github.com/mv1388/aitoolbox/blob/master/examples/dp_ddp_training/ddp_training.py\" rel=\"nofollow\">DistributedDataParallel training example</a>.</p>\n<h2>Automatic Mixed Precision training via Nvidia Apex</h2>\n<p>All the TrainLoop versions also support training with Automatic Mixed Precision (<em>AMP</em>)\nusing the <a href=\"https://github.com/NVIDIA/apex\" rel=\"nofollow\">Nvidia apex</a> extension. To use this feature the user first\nhas to install the Nvidia apex library (<a href=\"https://github.com/NVIDIA/apex#linux\" rel=\"nofollow\">installation instructions</a>).</p>\n<p>The user only has to set the TrainLoop parameter <code>use_amp</code> to <code>use_amp=True</code> in order to use the default\nAMP initialization and start training the model in the mixed precision mode. If the user wants to specify custom\nAMP initialization parameters, these should be provided as a dict parameter <code>use_amp={'opt_level': 'O1'}</code> to\nthe TrainLoop. All AMP initializations and training related steps are then handled automatically by the TrainLoop.</p>\n<p>You can read more about different AMP optimization levels in the\n<a href=\"https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\" rel=\"nofollow\">Nvidia apex documentation</a>.</p>\n<h3>Single-GPU mixed precision training</h3>\n<p>Example of single-GPU APEX setup:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">aitoolbox.torchtrain.train_loop</span> <span class=\"kn\">import</span> <span class=\"o\">*</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"o\">...</span> <span class=\"c1\"># TTModel</span>\n\n<span class=\"n\">TrainLoop</span><span class=\"p\">(</span>\n    <span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">,</span>\n    <span class=\"n\">optimizer</span><span class=\"p\">,</span> <span class=\"n\">criterion</span><span class=\"p\">,</span> <span class=\"n\">use_amp</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'opt_level'</span><span class=\"p\">:</span> <span class=\"s1\">'O1'</span><span class=\"p\">}</span>\n<span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">num_epochs</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n</pre>\n<p>Check out a full <a href=\"https://github.com/mv1388/aitoolbox/blob/master/examples/apex_amp_training/apex_single_GPU_training.py\" rel=\"nofollow\">Apex AMP training example</a>.</p>\n<h3>Multi-GPU DDP mixed precision training</h3>\n<p>When training in the multi-GPU setting, the setup is mostly the same as in the single-GPU.\nAll the user has to do is set accordingly the <code>use_amp</code> parameter of the TrainLoop and to instead call\n<code>fit_distributed()</code> in order to start the distributed training.\nUnder the hood, TrainLoop will initialize the model and the optimizer for AMP and start training using\nDistributedDataParallel approach (DDP is currently only multi-GPU training setup supported by Apex AMP).</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">aitoolbox.torchtrain.train_loop</span> <span class=\"kn\">import</span> <span class=\"o\">*</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"o\">...</span> <span class=\"c1\"># TTModel</span>\n\n<span class=\"n\">TrainLoop</span><span class=\"p\">(</span>\n    <span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">,</span>\n    <span class=\"n\">optimizer</span><span class=\"p\">,</span> <span class=\"n\">criterion</span><span class=\"p\">,</span> <span class=\"n\">use_amp</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'opt_level'</span><span class=\"p\">:</span> <span class=\"s1\">'O1'</span><span class=\"p\">}</span>\n<span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">fit_distributed</span><span class=\"p\">(</span><span class=\"n\">num_epochs</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n</pre>\n<p>Check out a full <a href=\"https://github.com/mv1388/aitoolbox/blob/master/examples/apex_amp_training/apex_mutli_GPU_training.py\" rel=\"nofollow\">Apex AMP DistributedDataParallel training example</a>.</p>\n<h2>Model</h2>\n<p>To take advantage of the TrainLoop abstraction the user has to define their model as a class which is a standard way\nin core PyTorch as well. The only difference is that for TrainLoop supported training the model class has\nto be inherited from the AIToolbox specific <a href=\"/aitoolbox/torchtrain/model.py\" rel=\"nofollow\"><code>TTModel</code></a> base class instead of PyTorch <code>nn.Module</code>.</p>\n<p><code>TTModel</code> itself inherits from the normally used <code>nn.Module</code> class thus our models still\nretain all the expected PyTorch enabled functionality. The reason for using the TTModel super class is that\nTrainLoop requires users to implement two additional methods which describe how each batch of data\nis fed into the model when calculating the loss in the training mode and when making the predictions in the\nevaluation mode.</p>\n<p>The code below shows the general skeleton all the TTModels have to follow to enable them to be trained\nwith the TrainLoop:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">aitoolbox.torchtrain.model</span> <span class=\"kn\">import</span> <span class=\"n\">TTModel</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MyNeuralModel</span><span class=\"p\">(</span><span class=\"n\">TTModel</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"c1\"># model layers, etc.</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x_data_batch</span><span class=\"p\">):</span>\n        <span class=\"c1\"># The same method as required in the base PyTorch nn.Module</span>\n        <span class=\"o\">...</span>\n        <span class=\"c1\"># return prediction</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">get_loss</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">batch_data</span><span class=\"p\">,</span> <span class=\"n\">criterion</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"p\">):</span>\n        <span class=\"c1\"># Get loss during training stage, called from fit() in TrainLoop</span>\n        <span class=\"o\">...</span>\n        <span class=\"c1\"># return batch loss</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">get_predictions</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">batch_data</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"p\">):</span>\n        <span class=\"c1\"># Get predictions during evaluation stage </span>\n        <span class=\"c1\"># + return any metadata potentially needed for evaluation</span>\n        <span class=\"o\">...</span>\n        <span class=\"c1\"># return predictions, true_targets, metadata</span>\n</pre>\n<h2>Callbacks</h2>\n<p>For advanced applications the basic logic offered in different default TrainLoops might not be enough.\nAdditional needed logic can be injected into the training procedure by using <a href=\"/aitoolbox/torchtrain/callbacks\" rel=\"nofollow\"><code>callbacks</code></a>\nand providing them as a parameter list to TrainLoop's <code>fit(callbacks=[callback_1, callback_2, ...])</code> function.</p>\n<p>AIToolbox by default already offers a wide selection of different useful callbacks. However when\nsome completely new functionality is desired the user can also implement their own callbacks by\ninheriting from the base callback object <a href=\"/aitoolbox/torchtrain/callbacks/abstract.py\" rel=\"nofollow\"><code>AbstractCallback</code></a>.\nAll that the user has to do is to implement corresponding methods to execute the new callback\nat the desired point in the train loop, such as: start/end of batch, epoch, training.</p>\n<h2>experiment</h2>\n<h3>Result Package</h3>\n<p>This is the definition of the model evaluation procedure on the task we are experimenting with.\nResult packages available out of the box can be found in the <a href=\"/aitoolbox/experiment/result_package/\" rel=\"nofollow\"><code>result_package</code> module</a>\nwhere we have implemented several <a href=\"/aitoolbox/experiment/result_package/basic_packages.py\" rel=\"nofollow\">basic, general result packages</a>.\nFurthermore, for those dealing with NLP, result packages for\nseveral widely researched NLP tasks such as translation, QA can be found as part of the\n<a href=\"/aitoolbox/nlp/experiment_evaluation/NLP_result_package.py\" rel=\"nofollow\"><code>NLP</code> module</a>\nmodule. Last but not least, as the framework was built with extensibility in mind and thus\nif needed the users can easily define their own result packages with custom evaluations by extending the base\n<a href=\"/aitoolbox/experiment/result_package/abstract_result_packages.py\" rel=\"nofollow\"><code>AbstractResultPackage</code></a>.</p>\n<p>Under the hood the result package executes one or more <a href=\"/aitoolbox/experiment/core_metrics\" rel=\"nofollow\"><code>metrics</code></a> objects which actually\ncalculate the performance metric calculation. Result package object is thus used as a wrapper\naround potentially multiple performance calculations which are needed for our task. The metrics\nwhich are part of the specified result package are calculated by calling the <code>prepare_result_package()</code> method\nof the result package which we are using to evaluate model's performance.</p>\n<h3>Experiment Saver</h3>\n<p>The experiment saver saves the model architecture as well as model performance evaluation results and training history.\nThis can be done at the end of each epoch as a model checkpointing or at the end of training.</p>\n<p>Normally not really a point of great interest when using the TrainLoop interface as it is hidden under the hood.\nHowever as AIToolbox was designed to be modular one can decide to write their own training loop logic but\njust use the provided experiment saver module to help with the experiment tracking and model saving.\nFor PyTorch users we recommend using the <a href=\"/aitoolbox/experiment/experiment_saver.py\" rel=\"nofollow\"><code>FullPyTorchExperimentS3Saver</code></a>\nwhich has also been most thoroughly tested.\nThe experiment is saved by calling the <code>save_experiment()</code> function from the selected experiment saver and\nproviding the trained model and the evaluated result package containing the calculated performance results.</p>\n<h2>cloud</h2>\n<p>All of these modules are mainly hidden under the hood when using different experiment tracking\nabstractions. However, if desired and only the cloud saving functionality is needed it is easy to use them\nas standalone modules in some desired downstream application.</p>\n<h3>AWS</h3>\n<p>Functionality for saving model architecture and training results to S3 either during\ntraining or at the training end. On the other hand, the module also offers the dataset downloading\nfrom the S3 based dataset store. This is useful when we are experimenting with datasets and have only a slow\nlocal connection, thus scp/FTP is out of the picture.</p>\n<h3>Google Cloud</h3>\n<p>Same functionality as for AWS S3 but for Google Cloud Storage.\nImplemented, however, not yet tested in practice.</p>\n<h2>nlp</h2>\n<p>Currently, mainly used for the performance evaluation <a href=\"/aitoolbox/nlp/experiment_evaluation/NLP_result_package.py\" rel=\"nofollow\"><code>result packages</code></a>\nneeded for different NLP tasks, such as Q&amp;A, summarization, machine translation.</p>\n<p>For the case of e.g. NMT the module also provides <a href=\"/aitoolbox/nlp/experiment_evaluation/attention_heatmap.py\" rel=\"nofollow\">attention heatmap plotting</a>\nwhich is often helpful for gaining addition insights into the seq2seq model. The heatmap plotter\ncreates attention heatmap plots for every validation example and saves them as pictures to disk\n(potentially also to cloud).</p>\n<p>Lastly, the nlp module also provides several rudimentary NLP data processing functions.</p>\n<h2>AWS GPU instance prep and management bash scripts</h2>\n<p>As some of the tasks when training models on the cloud GPU are quite repetitive, the package\nalso includes several useful bash scripts to automatize tasks such as instance init preparation,\nexperiment file updating, remote AIToolbox installation updating, etc.</p>\n<p>For further information look into the <a href=\"/bin/AWS/\" rel=\"nofollow\"><code>/bin/AWS</code></a> folder and read\nthe provided <a href=\"/bin/AWS/README.md\" rel=\"nofollow\">README</a>.</p>\n<h1>Examples of package usage</h1>\n<p>Look into the <a href=\"/examples\" rel=\"nofollow\"><code>/examples</code></a> folder for starters.\nWill be adding more examples of different training scenarios.</p>\n\n          </div>"}, "last_serial": 7176125, "releases": {"1.0": [{"comment_text": "", "digests": {"md5": "3e36525dcb121e0bdc849ee987eb5c72", "sha256": "fda8e9142fde9fffa29837dadf0bd448e8244490d13fadad0a118eba50061e27"}, "downloads": -1, "filename": "aitoolbox-1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "3e36525dcb121e0bdc849ee987eb5c72", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 196350, "upload_time": "2020-05-05T21:50:05", "upload_time_iso_8601": "2020-05-05T21:50:05.124125Z", "url": "https://files.pythonhosted.org/packages/f6/b9/60c2ed77f0ffcac2474b20a929cff2cdc4bff19f9495b49c37822b893ee8/aitoolbox-1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "834faca5274f98c1b67016f0e38e9b37", "sha256": "f4b3c07934abb99c99adb3f49fb4346ed64a3dd576c30f07ed8a622a3aa189fd"}, "downloads": -1, "filename": "aitoolbox-1.0.tar.gz", "has_sig": false, "md5_digest": "834faca5274f98c1b67016f0e38e9b37", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 92904, "upload_time": "2020-05-05T21:50:07", "upload_time_iso_8601": "2020-05-05T21:50:07.790309Z", "url": "https://files.pythonhosted.org/packages/a0/dd/26152f4df6510ad7a8e016106f035949cb70a0af5fe6cd272e08f9f1197c/aitoolbox-1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "3e36525dcb121e0bdc849ee987eb5c72", "sha256": "fda8e9142fde9fffa29837dadf0bd448e8244490d13fadad0a118eba50061e27"}, "downloads": -1, "filename": "aitoolbox-1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "3e36525dcb121e0bdc849ee987eb5c72", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 196350, "upload_time": "2020-05-05T21:50:05", "upload_time_iso_8601": "2020-05-05T21:50:05.124125Z", "url": "https://files.pythonhosted.org/packages/f6/b9/60c2ed77f0ffcac2474b20a929cff2cdc4bff19f9495b49c37822b893ee8/aitoolbox-1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "834faca5274f98c1b67016f0e38e9b37", "sha256": "f4b3c07934abb99c99adb3f49fb4346ed64a3dd576c30f07ed8a622a3aa189fd"}, "downloads": -1, "filename": "aitoolbox-1.0.tar.gz", "has_sig": false, "md5_digest": "834faca5274f98c1b67016f0e38e9b37", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 92904, "upload_time": "2020-05-05T21:50:07", "upload_time_iso_8601": "2020-05-05T21:50:07.790309Z", "url": "https://files.pythonhosted.org/packages/a0/dd/26152f4df6510ad7a8e016106f035949cb70a0af5fe6cd272e08f9f1197c/aitoolbox-1.0.tar.gz", "yanked": false}], "timestamp": "Thu May  7 16:20:21 2020"}