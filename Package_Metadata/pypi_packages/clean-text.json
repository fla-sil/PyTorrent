{"info": {"author": "Johannes Filter", "author_email": "hi@jfilter.de", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "# `clean-text` [![Build Status](https://travis-ci.com/jfilter/clean-text.svg?branch=master)](https://travis-ci.com/jfilter/clean-text) [![PyPI](https://img.shields.io/pypi/v/clean-text.svg)](https://pypi.org/project/clean-text/) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/clean-text.svg)](https://pypi.org/project/clean-text/)\n\nClean your text with `clean-text` to create normalized text representations. For instance, turn this corrupted input:\n\n```txt\nA bunch of \\\\u2018new\\\\u2019 references, including [Moana](https://en.wikipedia.org/wiki/Moana_%282016_film%29).\n\n\n\u00bbY\u00f3\u00f9 \u00e0r\u00e9     r\u00efght &lt;3!\u00ab\n```\n\ninto this clean output:\n\n```txt\nA bunch of 'new' references, including [moana](<URL>).\n\n\"you are right <3!\"\n```\n\n`clean-text` uses [ftfy](https://github.com/LuminosoInsight/python-ftfy), [unidecode](https://github.com/takluyver/Unidecode) and numerous hand-crafted rules, i.e., RegEx.\n\n## Installation\n\nTo install the GPL-licensed package [unidecode](https://github.com/takluyver/Unidecode) alongside:\n\n```bash\npip install clean-text[gpl]\n```\n\nYou may want to abstain from GPL:\n\n```bash\npip install clean-text\n```\n\nIf [unidecode](https://github.com/takluyver/Unidecode) is not available, `clean-text` will resort to Python's [unicodedata.normalize](https://docs.python.org/3.7/library/unicodedata.html#unicodedata.normalize) for [transliteration](https://en.wikipedia.org/wiki/Transliteration).\nTransliteration to closest ASCII symbols involes manually mappings, i.e., `\u00ea` to `e`. Unidecode's hand-crafted mapping is superiour but unicodedata's are sufficent.\nHowever, you may want to disable this feature altogether depening on your data and use case.\n\n## Usage\n\n```python\nfrom cleantext import clean\n\nclean(\"some input\",\n    fix_unicode=True,               # fix various unicode errors\n    to_ascii=True,                  # transliterate to closest ASCII representation\n    lower=True,                     # lowercase text\n    no_line_breaks=False,           # fully strip line breaks as opposed to only normalizing them\n    no_urls=False,                  # replace all URLs with a special token\n    no_emails=False,                # replace all email addresses with a special token\n    no_phone_numbers=False,         # replace all phone numbers with a special token\n    no_numbers=False,               # replace all numbers with a special token\n    no_digits=False,                # replace all digits with a special token\n    no_currency_symbols=False,      # replace all currency symbols with a special token\n    no_punct=False,                 # fully remove punctuation\n    replace_with_url=\"<URL>\",\n    replace_with_email=\"<EMAIL>\",\n    replace_with_phone_number=\"<PHONE>\",\n    replace_with_number=\"<NUMBER>\",\n    replace_with_digit=\"0\",\n    replace_with_currency_symbol=\"<CUR>\",\n    lang=\"en\"                       # set to 'de' for German special handling\n)\n```\n\nCarefully choose the arguments that fit your task. The default parameters are listed above. Whitespace is always normalized.\n\nYou may also only use specific functions for cleaning. For this, take a look at the [source code](https://github.com/jfilter/clean-text/blob/master/cleantext/clean.py).\n\nSo far, only English and German are fully supported. It should work for the majority of Western languages. If you need some special handling for you language, feel free to contribute. \ud83d\ude43\n\n## Development\n\n-   install [Pipenv](https://pipenv.readthedocs.io/en/latest/)\n-   get the package: `git clone https://github.com/jfilter/clean-text && cd clean-text && pipenv install`\n-   run tests: `pipenv run pytest`\n\n## Contributing\n\nIf you have a **question**, found a **bug** or want to propose a new **feature**, have a look at the [issues page](https://github.com/jfilter/clean-text/issues).\n\n**Pull requests** are especially welcomed when they fix bugs or improve the code quality.\n\nIf you don't like the output of `clean-text`, consider adding a [test](https://github.com/jfilter/clean-text/tree/master/tests) with your specific input and desired output.\n\n## Related Work\n\n-   https://github.com/pudo/normality\n-   https://github.com/davidmogar/cucco\n\n## Acknowledgements\n\nBuilt upon the work by [Burton DeWilde](https://github.com/bdewilde)'s for [Textacy](https://github.com/chartbeat-labs/textacy).\n\n## License\n\nApache\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/jfilter/clean-text", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "clean-text", "package_url": "https://pypi.org/project/clean-text/", "platform": "", "project_url": "https://pypi.org/project/clean-text/", "project_urls": {"Homepage": "https://github.com/jfilter/clean-text"}, "release_url": "https://pypi.org/project/clean-text/0.1.1/", "requires_dist": ["ftfy", "unidecode ; extra == 'gpl'"], "requires_python": "", "summary": "Clean Your Text to Create Normalized Text Representations", "version": "0.1.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1><code>clean-text</code> <a href=\"https://travis-ci.com/jfilter/clean-text\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0b1402a9af160ca70e16595f3509a24cdb09c55e/68747470733a2f2f7472617669732d63692e636f6d2f6a66696c7465722f636c65616e2d746578742e7376673f6272616e63683d6d6173746572\"></a> <a href=\"https://pypi.org/project/clean-text/\" rel=\"nofollow\"><img alt=\"PyPI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e98fd58c19b27faeea6a6e8f4cb5b501effb32ae/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f636c65616e2d746578742e737667\"></a> <a href=\"https://pypi.org/project/clean-text/\" rel=\"nofollow\"><img alt=\"PyPI - Python Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d421c7c978c934f26b23271f1f3b23f638dc2d49/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f636c65616e2d746578742e737667\"></a></h1>\n<p>Clean your text with <code>clean-text</code> to create normalized text representations. For instance, turn this corrupted input:</p>\n<pre>A bunch of \\\\u2018new\\\\u2019 references, including [Moana](https://en.wikipedia.org/wiki/Moana_%282016_film%29).\n\n\n\u00bbY\u00f3\u00f9 \u00e0r\u00e9     r\u00efght &amp;lt;3!\u00ab\n</pre>\n<p>into this clean output:</p>\n<pre>A bunch of 'new' references, including [moana](&lt;URL&gt;).\n\n\"you are right &lt;3!\"\n</pre>\n<p><code>clean-text</code> uses <a href=\"https://github.com/LuminosoInsight/python-ftfy\" rel=\"nofollow\">ftfy</a>, <a href=\"https://github.com/takluyver/Unidecode\" rel=\"nofollow\">unidecode</a> and numerous hand-crafted rules, i.e., RegEx.</p>\n<h2>Installation</h2>\n<p>To install the GPL-licensed package <a href=\"https://github.com/takluyver/Unidecode\" rel=\"nofollow\">unidecode</a> alongside:</p>\n<pre>pip install clean-text<span class=\"o\">[</span>gpl<span class=\"o\">]</span>\n</pre>\n<p>You may want to abstain from GPL:</p>\n<pre>pip install clean-text\n</pre>\n<p>If <a href=\"https://github.com/takluyver/Unidecode\" rel=\"nofollow\">unidecode</a> is not available, <code>clean-text</code> will resort to Python's <a href=\"https://docs.python.org/3.7/library/unicodedata.html#unicodedata.normalize\" rel=\"nofollow\">unicodedata.normalize</a> for <a href=\"https://en.wikipedia.org/wiki/Transliteration\" rel=\"nofollow\">transliteration</a>.\nTransliteration to closest ASCII symbols involes manually mappings, i.e., <code>\u00ea</code> to <code>e</code>. Unidecode's hand-crafted mapping is superiour but unicodedata's are sufficent.\nHowever, you may want to disable this feature altogether depening on your data and use case.</p>\n<h2>Usage</h2>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">cleantext</span> <span class=\"kn\">import</span> <span class=\"n\">clean</span>\n\n<span class=\"n\">clean</span><span class=\"p\">(</span><span class=\"s2\">\"some input\"</span><span class=\"p\">,</span>\n    <span class=\"n\">fix_unicode</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>               <span class=\"c1\"># fix various unicode errors</span>\n    <span class=\"n\">to_ascii</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>                  <span class=\"c1\"># transliterate to closest ASCII representation</span>\n    <span class=\"n\">lower</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>                     <span class=\"c1\"># lowercase text</span>\n    <span class=\"n\">no_line_breaks</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>           <span class=\"c1\"># fully strip line breaks as opposed to only normalizing them</span>\n    <span class=\"n\">no_urls</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>                  <span class=\"c1\"># replace all URLs with a special token</span>\n    <span class=\"n\">no_emails</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>                <span class=\"c1\"># replace all email addresses with a special token</span>\n    <span class=\"n\">no_phone_numbers</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>         <span class=\"c1\"># replace all phone numbers with a special token</span>\n    <span class=\"n\">no_numbers</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>               <span class=\"c1\"># replace all numbers with a special token</span>\n    <span class=\"n\">no_digits</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>                <span class=\"c1\"># replace all digits with a special token</span>\n    <span class=\"n\">no_currency_symbols</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>      <span class=\"c1\"># replace all currency symbols with a special token</span>\n    <span class=\"n\">no_punct</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>                 <span class=\"c1\"># fully remove punctuation</span>\n    <span class=\"n\">replace_with_url</span><span class=\"o\">=</span><span class=\"s2\">\"&lt;URL&gt;\"</span><span class=\"p\">,</span>\n    <span class=\"n\">replace_with_email</span><span class=\"o\">=</span><span class=\"s2\">\"&lt;EMAIL&gt;\"</span><span class=\"p\">,</span>\n    <span class=\"n\">replace_with_phone_number</span><span class=\"o\">=</span><span class=\"s2\">\"&lt;PHONE&gt;\"</span><span class=\"p\">,</span>\n    <span class=\"n\">replace_with_number</span><span class=\"o\">=</span><span class=\"s2\">\"&lt;NUMBER&gt;\"</span><span class=\"p\">,</span>\n    <span class=\"n\">replace_with_digit</span><span class=\"o\">=</span><span class=\"s2\">\"0\"</span><span class=\"p\">,</span>\n    <span class=\"n\">replace_with_currency_symbol</span><span class=\"o\">=</span><span class=\"s2\">\"&lt;CUR&gt;\"</span><span class=\"p\">,</span>\n    <span class=\"n\">lang</span><span class=\"o\">=</span><span class=\"s2\">\"en\"</span>                       <span class=\"c1\"># set to 'de' for German special handling</span>\n<span class=\"p\">)</span>\n</pre>\n<p>Carefully choose the arguments that fit your task. The default parameters are listed above. Whitespace is always normalized.</p>\n<p>You may also only use specific functions for cleaning. For this, take a look at the <a href=\"https://github.com/jfilter/clean-text/blob/master/cleantext/clean.py\" rel=\"nofollow\">source code</a>.</p>\n<p>So far, only English and German are fully supported. It should work for the majority of Western languages. If you need some special handling for you language, feel free to contribute. \ud83d\ude43</p>\n<h2>Development</h2>\n<ul>\n<li>install <a href=\"https://pipenv.readthedocs.io/en/latest/\" rel=\"nofollow\">Pipenv</a></li>\n<li>get the package: <code>git clone https://github.com/jfilter/clean-text &amp;&amp; cd clean-text &amp;&amp; pipenv install</code></li>\n<li>run tests: <code>pipenv run pytest</code></li>\n</ul>\n<h2>Contributing</h2>\n<p>If you have a <strong>question</strong>, found a <strong>bug</strong> or want to propose a new <strong>feature</strong>, have a look at the <a href=\"https://github.com/jfilter/clean-text/issues\" rel=\"nofollow\">issues page</a>.</p>\n<p><strong>Pull requests</strong> are especially welcomed when they fix bugs or improve the code quality.</p>\n<p>If you don't like the output of <code>clean-text</code>, consider adding a <a href=\"https://github.com/jfilter/clean-text/tree/master/tests\" rel=\"nofollow\">test</a> with your specific input and desired output.</p>\n<h2>Related Work</h2>\n<ul>\n<li><a href=\"https://github.com/pudo/normality\" rel=\"nofollow\">https://github.com/pudo/normality</a></li>\n<li><a href=\"https://github.com/davidmogar/cucco\" rel=\"nofollow\">https://github.com/davidmogar/cucco</a></li>\n</ul>\n<h2>Acknowledgements</h2>\n<p>Built upon the work by <a href=\"https://github.com/bdewilde\" rel=\"nofollow\">Burton DeWilde</a>'s for <a href=\"https://github.com/chartbeat-labs/textacy\" rel=\"nofollow\">Textacy</a>.</p>\n<h2>License</h2>\n<p>Apache</p>\n\n          </div>"}, "last_serial": 5184295, "releases": {"0.1.1": [{"comment_text": "", "digests": {"md5": "d660eb4050eed4fa1d24f2c9edad1403", "sha256": "c90bcd27aefbaf9656c9ebcc18c60deaa01ee1dedea0f6b9474c9de4b19ed83d"}, "downloads": -1, "filename": "clean_text-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "d660eb4050eed4fa1d24f2c9edad1403", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 9033, "upload_time": "2019-04-24T20:19:53", "upload_time_iso_8601": "2019-04-24T20:19:53.650776Z", "url": "https://files.pythonhosted.org/packages/23/98/2650271bc1052002ad7e61595f7a44ff24f6bb4eb24d9c0e42e92c991708/clean_text-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "28ba5fa6a9abb0321df4455c3a816657", "sha256": "dcd547366a35c27b49897793ec6b0ef4f0dcfa772c5b1f2343ee81b7fe2378b3"}, "downloads": -1, "filename": "clean-text-0.1.1.tar.gz", "has_sig": false, "md5_digest": "28ba5fa6a9abb0321df4455c3a816657", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7514, "upload_time": "2019-04-24T20:20:01", "upload_time_iso_8601": "2019-04-24T20:20:01.832942Z", "url": "https://files.pythonhosted.org/packages/be/49/ae6a7ee2e840017653beff7ed0548d44cac799ccf8e970727ab56f6a6095/clean-text-0.1.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "d660eb4050eed4fa1d24f2c9edad1403", "sha256": "c90bcd27aefbaf9656c9ebcc18c60deaa01ee1dedea0f6b9474c9de4b19ed83d"}, "downloads": -1, "filename": "clean_text-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "d660eb4050eed4fa1d24f2c9edad1403", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 9033, "upload_time": "2019-04-24T20:19:53", "upload_time_iso_8601": "2019-04-24T20:19:53.650776Z", "url": "https://files.pythonhosted.org/packages/23/98/2650271bc1052002ad7e61595f7a44ff24f6bb4eb24d9c0e42e92c991708/clean_text-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "28ba5fa6a9abb0321df4455c3a816657", "sha256": "dcd547366a35c27b49897793ec6b0ef4f0dcfa772c5b1f2343ee81b7fe2378b3"}, "downloads": -1, "filename": "clean-text-0.1.1.tar.gz", "has_sig": false, "md5_digest": "28ba5fa6a9abb0321df4455c3a816657", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7514, "upload_time": "2019-04-24T20:20:01", "upload_time_iso_8601": "2019-04-24T20:20:01.832942Z", "url": "https://files.pythonhosted.org/packages/be/49/ae6a7ee2e840017653beff7ed0548d44cac799ccf8e970727ab56f6a6095/clean-text-0.1.1.tar.gz", "yanked": false}], "timestamp": "Thu May  7 22:19:05 2020"}