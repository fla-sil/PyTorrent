{"info": {"author": "Alan Richardson", "author_email": "alan@ausargeo.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# Deepwave\n[![Build Status](https://travis-ci.org/ar4/deepwave.svg?branch=master)](https://travis-ci.org/ar4/deepwave)[![Codacy Badge](https://api.codacy.com/project/badge/Grade/52d27677ef0a439195d574964a6b4be4)](https://www.codacy.com/app/ar4/deepwave?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=ar4/deepwave&amp;utm_campaign=Badge_Grade)\n\nDeepwave provides wave propagation modules for PyTorch (currently only for the constant density acoustic / scalar wave equation). It is primarily aimed at seismic imaging/inversion. One interesting advantage of this is that it allows you to chain operations together. You could, for example, use Deepwave to perform FWI using a custom cost function (as long as PyTorch is able to automatically differentiate it), or add some other operations before and after wave propagation and PyTorch will backpropagate through all of them.\n\nWave propagation and FWI [can be implemented using deep neural networks](https://arxiv.org/abs/1801.07232). Deep learning tools such as TensorFlow and PyTorch are currently too slow and memory inefficient to do this with realistic seismic datasets, however. Deepwave extends PyTorch with higher performance wave propagation modules (written in C and CUDA) so that you can benefit from the conveniences of PyTorch without sacrificing performance.\n\nDeepwave runs on CPUs and NVIDIA GPUs. It should automatically detect compatible GPUs during installation and compile the GPU code if any are found. To run on the GPU you must transfer the model, source amplitude, and source and receiver location Tensors to the GPU in the standard PyTorch way (using `.cuda()` or `.to(device)`).\n\n## Installation\nDeepwave needs NumPy, so [installing Anaconda](https://www.anaconda.com/download) first is highly recommended. It also needs [PyTorch](https://pytorch.org/), so it is also best to install that (using something like `conda install pytorch-cpu -c pytorch`) before installing Deepwave. You can then install the latest release of Deepwave using\n\n`pip install deepwave`\n\nor the latest development version using\n\n`pip install git+https://github.com/ar4/deepwave.git`\n\n\n## Usage\nDeepwave can do two things: forward modeling and backpropagation.\n\n### Forward modeling\nWe first need to create a wave propagation module. If you are familiar with training neural networks, this is the same as defining your network (or a portion of it) and initializing the weights.\n\n```python\nprop = deepwave.scalar.Propagator({'vp': model}, dx)\n```\n\nThe two required arguments are the wave speed model (`model`), and the cell size used in the model (`dx`). The model should be provided as a PyTorch Float Tensor of shape `[nz, (ny, (nx))]`. 1D, 2D, and 3D propagators are available, with the model shape used to choose between them. If you want 1D wave propagation, then the model shape would be `[nz]`, for example. The cell size should also be provided as a single float (if it is the same in every dimension) or a Float Tensor containing the cell size in each spatial dimension; `[dz, dy, dx]` in 3D, `[dz]` in 1D.\n\nNow we can call our propagator.\n\n```python\nreceiver_amplitudes = prop(source_amplitudes, x_s, x_r, dt)\n```\n\nThe required arguments are the source amplitudes, the source coordinates (`x_s`), the receiver coordinates (`x_r`), and the time interval between source samples (`dt`). Receiver amplitudes are returned. The source amplitudes should be a Float Tensor of shape `[nt, num_shots, num_sources_per_shot]`, where `nt` is the number of time samples. Note that you can have more than one source per shot, although in active source seismic experiments there is normally only one. The source coordinates array is a Float Tensor of shape `[num_shots, num_sources_per_shot, num_dimensions]`, where `num_dimensions` corresponds to the number of dimensions in the model. Similarly, the receiver coordinates array is a Float Tensor of shape `[num_shots, num_receivers_per_shot, num_dimensions]`. The coordinates are specified in the same units as `dx` and are with respect to the origin of the model. The time step size `dt` should be a regular float. The returned Float Tensor of shape `[nt, num_shots, num_receivers_per_shot]` contains receiver amplitudes.\n\nYou can run forward propagation multiple times with different inputs, for example to forward model each shot in a dataset. You may have noticed that the propagator is also designed to forward model multiple separate shots simultaneously (the `num_shots` dimension in the inputs). Doing so may give better performance than propagating each shot separately, but you might also run out of memory.\n\nHere is a full example:\n\n```python\nimport math\nimport torch\nimport deepwave\n\ndx = 5.0 # 5m in each dimension\ndt = 0.004 # 4ms\nnz = 20\nny = 40\nnt = int(1 / dt) # 1s\npeak_freq = 4\npeak_source_time = 1/peak_freq\n\n# constant 1500m/s model\nmodel = torch.ones(nz, ny) * 1500\n\n# one source and receiver at the same location\nx_s = torch.Tensor([[[0, 20 * dx]]])\nx_r = x_s.clone()\n\nsource_amplitudes = deepwave.wavelets.ricker(peak_freq, nt, dt,\n                                             peak_source_time).reshape(-1, 1, 1)\n\nprop = deepwave.scalar.Propagator({'vp': model}, dx)\nreceiver_amplitudes = prop(source_amplitudes, x_s, x_r, dt)\n```\n\n### Backpropagation/Inversion (FWI)\nFWI attempts to match the predicted and true receiver amplitudes by modifying the model. This is similar to modifying the weights in a neural network during training. To achieve this with Deepwave, we first specify that we will need to calculate gradients with respect to our model.\n\n```python\nmodel.requires_grad = True\n```\n\nWe also need to specify which optimization algorithm and loss/cost/objective function we wish to use.\n\n```python\noptimizer = torch.optim.Adam([model], lr=10)\ncriterion = torch.nn.MSELoss()\n```\n\nI have chosen to use the Adam optimizer with a learning rate of 10, and mean squared error (MSE) as the cost function. The MSE cost function is provided for us by PyTorch, but I could also have made-up my own cost function and used that instead (as long as PyTorch can automatically differentiate it).\n\nWith our propagator initialized as in the forward modeling section above, we can then iteratively optimize the model.\n\n```python\nfor iter in range(num_iter):\n    optimizer.zero_grad()\n    receiver_amplitudes_pred = prop(source_amplitudes, x_s, x_r, dt)\n    loss = criterion(receiver_amplitudes_pred, receiver_amplitudes_true)\n    loss.backward()\n    optimizer.step()\n```\n\nIn each iteration, we zero the gradients, calculate the predicted receiver amplitudes from the current model, compare these with the true data using our cost function, backpropagate to calculate the gradient of the loss with respect to the model, and then update the model.\n\nThe flexibility of PyTorch means that it is easy to modify this to suit your own needs.\n\nFor a full example of using Deepwave for FWI, see [this notebook](https://colab.research.google.com/drive/1PMO1rFAaibRjwjhBuyH3dLQ1sW5wfec_).\n\nIt is also possible to perform source inversion with Deepwave. Simply set `requires_grad` to `True` on the source amplitude Tensor.\n\n### Born forward modeling (for demigration and LSRTM)\nTo perform Born forward modeling, use `BornPropagator`. In addition to a background wave speed model, you will also need a scattering model (\"image\"). As an example, add the following line to the regular forward modeling example above:\n\n```python\nscatter = torch.zeros_like(model)\nscatter[10, 20] = 100\n```\n\nThis creates a scattering model with a point scatterer of amplitude 100 m/s. Then, replace the line that creates the propagator with one that uses the Born propagator:\n\n```python\nprop = deepwave.scalar.BornPropagator({'vp': model, 'scatter': scatter}, dx)\n```\n\nThe resulting data should only contain recordings from the scattered wavefield, so there will not be any direct arrival.\n\nTo perform LSRTM, optimize the variable `scatter`. Optimizing the source amplitude or the wave speed model is not currently supported with the Born propagator.\n\nFor an example of using Deepwave for LSRTM, see [this notebook](https://colab.research.google.com/drive/1BgQM5VGgyFp7Q--pAJX-vGb2bW9mcbM8).\n\n## Notes\n* Deepwave is only tested with Python 3.6.\n* For a reflective free surface, set the PML width to zero at the surface. For example, in 3D and when the PML width on the other sides is 10 cells, provide the argument `pml_width=[0,10,10,10,10,10]` when creating the propagator if the free surface is at the beginning of the first dimension. The format is [z1, z2, y1, y2, x1, x2], where z1, y1, and x1 are the PML widths at the beginning of the z, y, and x dimensions, and z2, y2, and x2 are the PML widths at the ends of those dimensions.\n* To limit wave simulation to the region covered by the survey (the sources and receivers), provide the `survey_pad` keyword argument when creating the propagator. For example, to use the whole z dimension, but only up to 100m from the first and last source/receiver in the y and x dimensions, use `survey_pad=[None, None, 100, 100, 100, 100]`, where `None` means continue to the edge of the model, and the format is similar to that used for `pml_width`. The default is `None` for every entry.\n* [@LukasMosser](https://github.com/LukasMosser) discovered that GCC 4.9 or above is necessary ([#18](https://github.com/ar4/deepwave/issues/18)).\n* Distributed parallelization over shots is supported, but not within a shot; each shot must run within one node.\n* Currently, the forward source wavefield is saved in memory for use during backpropagation. This means that realistic 3D surveys will probably require more memory than is available. This will be fixed in a future release.\n\n## Contributing\nYour help to improve Deepwave would be greatly appreciated. If you encounter any difficulty using Deepwave, please report it as a Github Issue so that it can be fixed. If you have feature suggestions or other ideas to make Deepwave better, please also report those as Github Issues. If you want to help with the coding, that would be especially wonderful. The Github Issues contain a list of things that need work. If you see one that you would like to attempt, please ask for it to be assigned to you.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/ar4/deepwave", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "deepwave", "package_url": "https://pypi.org/project/deepwave/", "platform": "", "project_url": "https://pypi.org/project/deepwave/", "project_urls": {"Homepage": "https://github.com/ar4/deepwave"}, "release_url": "https://pypi.org/project/deepwave/0.0.7/", "requires_dist": null, "requires_python": "", "summary": "Wave propagation modules for PyTorch.", "version": "0.0.7", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Deepwave</h1>\n<p><a href=\"https://travis-ci.org/ar4/deepwave\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8e69cc341bfe58177b79fe76c91e308b6e747878/68747470733a2f2f7472617669732d63692e6f72672f6172342f64656570776176652e7376673f6272616e63683d6d6173746572\"></a><a href=\"https://www.codacy.com/app/ar4/deepwave?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=ar4/deepwave&amp;utm_campaign=Badge_Grade\" rel=\"nofollow\"><img alt=\"Codacy Badge\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bded71c11e21ef6f70897d20661838c0b4b5a231/68747470733a2f2f6170692e636f646163792e636f6d2f70726f6a6563742f62616467652f47726164652f3532643237363737656630613433393139356435373439363461366234626534\"></a></p>\n<p>Deepwave provides wave propagation modules for PyTorch (currently only for the constant density acoustic / scalar wave equation). It is primarily aimed at seismic imaging/inversion. One interesting advantage of this is that it allows you to chain operations together. You could, for example, use Deepwave to perform FWI using a custom cost function (as long as PyTorch is able to automatically differentiate it), or add some other operations before and after wave propagation and PyTorch will backpropagate through all of them.</p>\n<p>Wave propagation and FWI <a href=\"https://arxiv.org/abs/1801.07232\" rel=\"nofollow\">can be implemented using deep neural networks</a>. Deep learning tools such as TensorFlow and PyTorch are currently too slow and memory inefficient to do this with realistic seismic datasets, however. Deepwave extends PyTorch with higher performance wave propagation modules (written in C and CUDA) so that you can benefit from the conveniences of PyTorch without sacrificing performance.</p>\n<p>Deepwave runs on CPUs and NVIDIA GPUs. It should automatically detect compatible GPUs during installation and compile the GPU code if any are found. To run on the GPU you must transfer the model, source amplitude, and source and receiver location Tensors to the GPU in the standard PyTorch way (using <code>.cuda()</code> or <code>.to(device)</code>).</p>\n<h2>Installation</h2>\n<p>Deepwave needs NumPy, so <a href=\"https://www.anaconda.com/download\" rel=\"nofollow\">installing Anaconda</a> first is highly recommended. It also needs <a href=\"https://pytorch.org/\" rel=\"nofollow\">PyTorch</a>, so it is also best to install that (using something like <code>conda install pytorch-cpu -c pytorch</code>) before installing Deepwave. You can then install the latest release of Deepwave using</p>\n<p><code>pip install deepwave</code></p>\n<p>or the latest development version using</p>\n<p><code>pip install git+https://github.com/ar4/deepwave.git</code></p>\n<h2>Usage</h2>\n<p>Deepwave can do two things: forward modeling and backpropagation.</p>\n<h3>Forward modeling</h3>\n<p>We first need to create a wave propagation module. If you are familiar with training neural networks, this is the same as defining your network (or a portion of it) and initializing the weights.</p>\n<pre><span class=\"n\">prop</span> <span class=\"o\">=</span> <span class=\"n\">deepwave</span><span class=\"o\">.</span><span class=\"n\">scalar</span><span class=\"o\">.</span><span class=\"n\">Propagator</span><span class=\"p\">({</span><span class=\"s1\">'vp'</span><span class=\"p\">:</span> <span class=\"n\">model</span><span class=\"p\">},</span> <span class=\"n\">dx</span><span class=\"p\">)</span>\n</pre>\n<p>The two required arguments are the wave speed model (<code>model</code>), and the cell size used in the model (<code>dx</code>). The model should be provided as a PyTorch Float Tensor of shape <code>[nz, (ny, (nx))]</code>. 1D, 2D, and 3D propagators are available, with the model shape used to choose between them. If you want 1D wave propagation, then the model shape would be <code>[nz]</code>, for example. The cell size should also be provided as a single float (if it is the same in every dimension) or a Float Tensor containing the cell size in each spatial dimension; <code>[dz, dy, dx]</code> in 3D, <code>[dz]</code> in 1D.</p>\n<p>Now we can call our propagator.</p>\n<pre><span class=\"n\">receiver_amplitudes</span> <span class=\"o\">=</span> <span class=\"n\">prop</span><span class=\"p\">(</span><span class=\"n\">source_amplitudes</span><span class=\"p\">,</span> <span class=\"n\">x_s</span><span class=\"p\">,</span> <span class=\"n\">x_r</span><span class=\"p\">,</span> <span class=\"n\">dt</span><span class=\"p\">)</span>\n</pre>\n<p>The required arguments are the source amplitudes, the source coordinates (<code>x_s</code>), the receiver coordinates (<code>x_r</code>), and the time interval between source samples (<code>dt</code>). Receiver amplitudes are returned. The source amplitudes should be a Float Tensor of shape <code>[nt, num_shots, num_sources_per_shot]</code>, where <code>nt</code> is the number of time samples. Note that you can have more than one source per shot, although in active source seismic experiments there is normally only one. The source coordinates array is a Float Tensor of shape <code>[num_shots, num_sources_per_shot, num_dimensions]</code>, where <code>num_dimensions</code> corresponds to the number of dimensions in the model. Similarly, the receiver coordinates array is a Float Tensor of shape <code>[num_shots, num_receivers_per_shot, num_dimensions]</code>. The coordinates are specified in the same units as <code>dx</code> and are with respect to the origin of the model. The time step size <code>dt</code> should be a regular float. The returned Float Tensor of shape <code>[nt, num_shots, num_receivers_per_shot]</code> contains receiver amplitudes.</p>\n<p>You can run forward propagation multiple times with different inputs, for example to forward model each shot in a dataset. You may have noticed that the propagator is also designed to forward model multiple separate shots simultaneously (the <code>num_shots</code> dimension in the inputs). Doing so may give better performance than propagating each shot separately, but you might also run out of memory.</p>\n<p>Here is a full example:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">math</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">deepwave</span>\n\n<span class=\"n\">dx</span> <span class=\"o\">=</span> <span class=\"mf\">5.0</span> <span class=\"c1\"># 5m in each dimension</span>\n<span class=\"n\">dt</span> <span class=\"o\">=</span> <span class=\"mf\">0.004</span> <span class=\"c1\"># 4ms</span>\n<span class=\"n\">nz</span> <span class=\"o\">=</span> <span class=\"mi\">20</span>\n<span class=\"n\">ny</span> <span class=\"o\">=</span> <span class=\"mi\">40</span>\n<span class=\"n\">nt</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"mi\">1</span> <span class=\"o\">/</span> <span class=\"n\">dt</span><span class=\"p\">)</span> <span class=\"c1\"># 1s</span>\n<span class=\"n\">peak_freq</span> <span class=\"o\">=</span> <span class=\"mi\">4</span>\n<span class=\"n\">peak_source_time</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"o\">/</span><span class=\"n\">peak_freq</span>\n\n<span class=\"c1\"># constant 1500m/s model</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">ones</span><span class=\"p\">(</span><span class=\"n\">nz</span><span class=\"p\">,</span> <span class=\"n\">ny</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"mi\">1500</span>\n\n<span class=\"c1\"># one source and receiver at the same location</span>\n<span class=\"n\">x_s</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">([[[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">20</span> <span class=\"o\">*</span> <span class=\"n\">dx</span><span class=\"p\">]]])</span>\n<span class=\"n\">x_r</span> <span class=\"o\">=</span> <span class=\"n\">x_s</span><span class=\"o\">.</span><span class=\"n\">clone</span><span class=\"p\">()</span>\n\n<span class=\"n\">source_amplitudes</span> <span class=\"o\">=</span> <span class=\"n\">deepwave</span><span class=\"o\">.</span><span class=\"n\">wavelets</span><span class=\"o\">.</span><span class=\"n\">ricker</span><span class=\"p\">(</span><span class=\"n\">peak_freq</span><span class=\"p\">,</span> <span class=\"n\">nt</span><span class=\"p\">,</span> <span class=\"n\">dt</span><span class=\"p\">,</span>\n                                             <span class=\"n\">peak_source_time</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">reshape</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"n\">prop</span> <span class=\"o\">=</span> <span class=\"n\">deepwave</span><span class=\"o\">.</span><span class=\"n\">scalar</span><span class=\"o\">.</span><span class=\"n\">Propagator</span><span class=\"p\">({</span><span class=\"s1\">'vp'</span><span class=\"p\">:</span> <span class=\"n\">model</span><span class=\"p\">},</span> <span class=\"n\">dx</span><span class=\"p\">)</span>\n<span class=\"n\">receiver_amplitudes</span> <span class=\"o\">=</span> <span class=\"n\">prop</span><span class=\"p\">(</span><span class=\"n\">source_amplitudes</span><span class=\"p\">,</span> <span class=\"n\">x_s</span><span class=\"p\">,</span> <span class=\"n\">x_r</span><span class=\"p\">,</span> <span class=\"n\">dt</span><span class=\"p\">)</span>\n</pre>\n<h3>Backpropagation/Inversion (FWI)</h3>\n<p>FWI attempts to match the predicted and true receiver amplitudes by modifying the model. This is similar to modifying the weights in a neural network during training. To achieve this with Deepwave, we first specify that we will need to calculate gradients with respect to our model.</p>\n<pre><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">requires_grad</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n</pre>\n<p>We also need to specify which optimization algorithm and loss/cost/objective function we wish to use.</p>\n<pre><span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">Adam</span><span class=\"p\">([</span><span class=\"n\">model</span><span class=\"p\">],</span> <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n<span class=\"n\">criterion</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">MSELoss</span><span class=\"p\">()</span>\n</pre>\n<p>I have chosen to use the Adam optimizer with a learning rate of 10, and mean squared error (MSE) as the cost function. The MSE cost function is provided for us by PyTorch, but I could also have made-up my own cost function and used that instead (as long as PyTorch can automatically differentiate it).</p>\n<p>With our propagator initialized as in the forward modeling section above, we can then iteratively optimize the model.</p>\n<pre><span class=\"k\">for</span> <span class=\"nb\">iter</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">num_iter</span><span class=\"p\">):</span>\n    <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">zero_grad</span><span class=\"p\">()</span>\n    <span class=\"n\">receiver_amplitudes_pred</span> <span class=\"o\">=</span> <span class=\"n\">prop</span><span class=\"p\">(</span><span class=\"n\">source_amplitudes</span><span class=\"p\">,</span> <span class=\"n\">x_s</span><span class=\"p\">,</span> <span class=\"n\">x_r</span><span class=\"p\">,</span> <span class=\"n\">dt</span><span class=\"p\">)</span>\n    <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">criterion</span><span class=\"p\">(</span><span class=\"n\">receiver_amplitudes_pred</span><span class=\"p\">,</span> <span class=\"n\">receiver_amplitudes_true</span><span class=\"p\">)</span>\n    <span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">()</span>\n    <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n</pre>\n<p>In each iteration, we zero the gradients, calculate the predicted receiver amplitudes from the current model, compare these with the true data using our cost function, backpropagate to calculate the gradient of the loss with respect to the model, and then update the model.</p>\n<p>The flexibility of PyTorch means that it is easy to modify this to suit your own needs.</p>\n<p>For a full example of using Deepwave for FWI, see <a href=\"https://colab.research.google.com/drive/1PMO1rFAaibRjwjhBuyH3dLQ1sW5wfec_\" rel=\"nofollow\">this notebook</a>.</p>\n<p>It is also possible to perform source inversion with Deepwave. Simply set <code>requires_grad</code> to <code>True</code> on the source amplitude Tensor.</p>\n<h3>Born forward modeling (for demigration and LSRTM)</h3>\n<p>To perform Born forward modeling, use <code>BornPropagator</code>. In addition to a background wave speed model, you will also need a scattering model (\"image\"). As an example, add the following line to the regular forward modeling example above:</p>\n<pre><span class=\"n\">scatter</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">zeros_like</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">)</span>\n<span class=\"n\">scatter</span><span class=\"p\">[</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">20</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">100</span>\n</pre>\n<p>This creates a scattering model with a point scatterer of amplitude 100 m/s. Then, replace the line that creates the propagator with one that uses the Born propagator:</p>\n<pre><span class=\"n\">prop</span> <span class=\"o\">=</span> <span class=\"n\">deepwave</span><span class=\"o\">.</span><span class=\"n\">scalar</span><span class=\"o\">.</span><span class=\"n\">BornPropagator</span><span class=\"p\">({</span><span class=\"s1\">'vp'</span><span class=\"p\">:</span> <span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"s1\">'scatter'</span><span class=\"p\">:</span> <span class=\"n\">scatter</span><span class=\"p\">},</span> <span class=\"n\">dx</span><span class=\"p\">)</span>\n</pre>\n<p>The resulting data should only contain recordings from the scattered wavefield, so there will not be any direct arrival.</p>\n<p>To perform LSRTM, optimize the variable <code>scatter</code>. Optimizing the source amplitude or the wave speed model is not currently supported with the Born propagator.</p>\n<p>For an example of using Deepwave for LSRTM, see <a href=\"https://colab.research.google.com/drive/1BgQM5VGgyFp7Q--pAJX-vGb2bW9mcbM8\" rel=\"nofollow\">this notebook</a>.</p>\n<h2>Notes</h2>\n<ul>\n<li>Deepwave is only tested with Python 3.6.</li>\n<li>For a reflective free surface, set the PML width to zero at the surface. For example, in 3D and when the PML width on the other sides is 10 cells, provide the argument <code>pml_width=[0,10,10,10,10,10]</code> when creating the propagator if the free surface is at the beginning of the first dimension. The format is [z1, z2, y1, y2, x1, x2], where z1, y1, and x1 are the PML widths at the beginning of the z, y, and x dimensions, and z2, y2, and x2 are the PML widths at the ends of those dimensions.</li>\n<li>To limit wave simulation to the region covered by the survey (the sources and receivers), provide the <code>survey_pad</code> keyword argument when creating the propagator. For example, to use the whole z dimension, but only up to 100m from the first and last source/receiver in the y and x dimensions, use <code>survey_pad=[None, None, 100, 100, 100, 100]</code>, where <code>None</code> means continue to the edge of the model, and the format is similar to that used for <code>pml_width</code>. The default is <code>None</code> for every entry.</li>\n<li><a href=\"https://github.com/LukasMosser\" rel=\"nofollow\">@LukasMosser</a> discovered that GCC 4.9 or above is necessary (<a href=\"https://github.com/ar4/deepwave/issues/18\" rel=\"nofollow\">#18</a>).</li>\n<li>Distributed parallelization over shots is supported, but not within a shot; each shot must run within one node.</li>\n<li>Currently, the forward source wavefield is saved in memory for use during backpropagation. This means that realistic 3D surveys will probably require more memory than is available. This will be fixed in a future release.</li>\n</ul>\n<h2>Contributing</h2>\n<p>Your help to improve Deepwave would be greatly appreciated. If you encounter any difficulty using Deepwave, please report it as a Github Issue so that it can be fixed. If you have feature suggestions or other ideas to make Deepwave better, please also report those as Github Issues. If you want to help with the coding, that would be especially wonderful. The Github Issues contain a list of things that need work. If you see one that you would like to attempt, please ask for it to be assigned to you.</p>\n\n          </div>"}, "last_serial": 6458186, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "e58f0248fe3cf6bce1f753445f7d1ba0", "sha256": "94c32fb90e1f900f7df840ce37a411321bbc352e77c4b9ddd99b2018cacc671f"}, "downloads": -1, "filename": "deepwave-0.0.1.tar.gz", "has_sig": false, "md5_digest": "e58f0248fe3cf6bce1f753445f7d1ba0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18045, "upload_time": "2018-07-14T19:22:02", "upload_time_iso_8601": "2018-07-14T19:22:02.082196Z", "url": "https://files.pythonhosted.org/packages/36/ab/3bd0abeb831e17ea856f5ef3f762cbdd098a2111effefc2a8c262ddfc3fd/deepwave-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "e511c41b77943ccd97bfae6b3838b3a4", "sha256": "ffa01424b2b39a761d255633a7fd3328a69b1c11784f653b632dd0e466004bb3"}, "downloads": -1, "filename": "deepwave-0.0.2.tar.gz", "has_sig": false, "md5_digest": "e511c41b77943ccd97bfae6b3838b3a4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22901, "upload_time": "2018-09-26T14:49:03", "upload_time_iso_8601": "2018-09-26T14:49:03.736888Z", "url": "https://files.pythonhosted.org/packages/09/fa/7d04cfa069b5fbd12ceac11293448c4589a13945c8525502de2e9720b40d/deepwave-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "91a7287871a986248e81051b70602b53", "sha256": "cfcfa6a55386b5956badba7d999887f784d30a4d8d811c523463b2164585746b"}, "downloads": -1, "filename": "deepwave-0.0.3.tar.gz", "has_sig": false, "md5_digest": "91a7287871a986248e81051b70602b53", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22976, "upload_time": "2018-09-30T13:27:20", "upload_time_iso_8601": "2018-09-30T13:27:20.594392Z", "url": "https://files.pythonhosted.org/packages/a4/15/30ddb96a892c8675fe933f0fb656e53c05592ba7ce25b461b93fdca75386/deepwave-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "59067bbc55644de5f3cd4b0fd1336a35", "sha256": "3c6530b569b815a8e03c7abde6d1827ef2540be34371ec2cfcccd773f7d21ef6"}, "downloads": -1, "filename": "deepwave-0.0.4.tar.gz", "has_sig": false, "md5_digest": "59067bbc55644de5f3cd4b0fd1336a35", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 26180, "upload_time": "2018-10-03T13:54:16", "upload_time_iso_8601": "2018-10-03T13:54:16.931910Z", "url": "https://files.pythonhosted.org/packages/7f/22/6659543d0a76ec264be7e7a4a69600d4e327df80c89c8a35a4ed9cdc5aaa/deepwave-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "c3f613845a16344e3471944dcdccecb2", "sha256": "e353af47c5e80709c350db8620ac737dc8f595990d76e82ade50455d9a563ffc"}, "downloads": -1, "filename": "deepwave-0.0.5.tar.gz", "has_sig": false, "md5_digest": "c3f613845a16344e3471944dcdccecb2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 32118, "upload_time": "2018-12-05T13:26:59", "upload_time_iso_8601": "2018-12-05T13:26:59.444206Z", "url": "https://files.pythonhosted.org/packages/e2/da/65059d443c90389a71effc03938c94cc7ceb2c36b79cdc7e3a7db142171e/deepwave-0.0.5.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "43db8dcb26859ebd83cd5258ff43fea5", "sha256": "d4b3d09e7342977061cadc1ed876af1889011c409f8c51882e5747f1da26eb70"}, "downloads": -1, "filename": "deepwave-0.0.6.tar.gz", "has_sig": false, "md5_digest": "43db8dcb26859ebd83cd5258ff43fea5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 36166, "upload_time": "2018-12-09T13:11:47", "upload_time_iso_8601": "2018-12-09T13:11:47.987856Z", "url": "https://files.pythonhosted.org/packages/b9/f3/85d374f4cbe3b91757cfcda41b616f57e7e7751b338f5d893307e4ef1eff/deepwave-0.0.6.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "e4732aa7c132d7abcebe2aed1f9918f7", "sha256": "2821839a52f6f5b25fad90393ac6ab148166602c9b621df3b1ad5fa6d3040374"}, "downloads": -1, "filename": "deepwave-0.0.7.tar.gz", "has_sig": false, "md5_digest": "e4732aa7c132d7abcebe2aed1f9918f7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 32978, "upload_time": "2020-01-15T12:08:18", "upload_time_iso_8601": "2020-01-15T12:08:18.655468Z", "url": "https://files.pythonhosted.org/packages/ce/68/6e1946fb28c6e10bce268c48d0b560e4f3c0c95df27a64c5b2ef369f1983/deepwave-0.0.7.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "e4732aa7c132d7abcebe2aed1f9918f7", "sha256": "2821839a52f6f5b25fad90393ac6ab148166602c9b621df3b1ad5fa6d3040374"}, "downloads": -1, "filename": "deepwave-0.0.7.tar.gz", "has_sig": false, "md5_digest": "e4732aa7c132d7abcebe2aed1f9918f7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 32978, "upload_time": "2020-01-15T12:08:18", "upload_time_iso_8601": "2020-01-15T12:08:18.655468Z", "url": "https://files.pythonhosted.org/packages/ce/68/6e1946fb28c6e10bce268c48d0b560e4f3c0c95df27a64c5b2ef369f1983/deepwave-0.0.7.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:39:18 2020"}