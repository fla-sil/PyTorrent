{"info": {"author": "Roger Ineichen, Projekt01 GmbH", "author_email": "dev@projekt01.ch", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Web Environment", "Framework :: Zope3", "Intended Audience :: Developers", "License :: OSI Approved :: Zope Public License", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python", "Topic :: Internet :: WWW/HTTP"], "description": "This package provides a remote processing queue for Zope3 using the mongodb\ninstead of ZODB.\n\n\n======\nREADME\n======\n\nThis package offers a remote processor. This remote processor is implemented as\na simple object using the mongodb as storage. The processor can execute pre\ndefined jobs in another thread. It is also possible to run jobs at specific\ntime using the different scheduler items.\n\nThe RemoteProcessor uses two different processor. One processes jobs and the\nother pickes items from the scheduler and is adding jobs. This separation\nis usefull if you implement a distributed concept. This means one or more\napplication can schedule job items based on the given scheduler items. And\nanother application is processing jobs and doesn't know about how to scheduling\nnext items.\n\nSince we use this remote scheduler for low CPU intensive jobs, we offer multi\nprocessing. This is done by running more then one worker in the main worker\nthread. If you use subprocess for your job processing, you will get a real\nmultiprocessing processor which isn't limited to the current python process.\n\nYou can configure the amount of threads which a job worker can start in the\nremote processor. See jobWorkerArguments/maxThreads. By default this number\nuses the amount of CPU installed on your machine.\n\nThe implementation uses a mongodb as a storage for it's component. This means\njobs, job factories and scheduler items get stored in the mongodb using the\nORM concept given from m01.mongo.\n\nSee p01.remote for a ZODB based remote processor implementation but take care\nthe p01.remote implementation doesn't provide the worker and scheduler\nprocessor separation. At least not yet.\n\n\nSetup\n-----\n\n  >>> import transaction\n  >>> from pprint import pprint\n  >>> import zope.component\n  >>> import m01.mongo\n  >>> from m01.mongo import UTC\n  >>> import m01.remote.job\n  >>> from m01.remote import testing\n\nLet's now start by create two a remote processor. We can use our remote queue\nsite implementation:\n\n  >>> from zope.security.proxy import removeSecurityProxy\n  >>> from m01.remote import interfaces\n\nOur test remote processor should be available as application root:\n\n  >>> rp = root\n  >>> rp\n  <TestProcessor None>\n\nLet's discover the available jobs:\n\n  >>> dict(root._jobs)\n  {}\n\nThe job container is initially empty, because we have not added any job\nfactory. Let's now define a job factory that simply echos an input string:\n\n  >>> echoJob = testing.EchoJob({})\n\nNow we can set the job input:\n\n  >>> echoJob.input = {'foo': u'blah'}\n\nThe only API requirement on the job is to be callable. Now we make sure that\nthe job works. Note we call our job with the remote processor instance which\nis our initialized application root:\n\n  >>> echoJob(root)\n  {'foo': u'blah'}\n\nLet's add the job to the available job list:\n\n  >>> rp.addJobFactory(u'echo', echoJob)\n\nThe echo job is now available in the remote processor:\n\n  >>> dict(rp._jobFactories)\n  {u'echo': <EchoJob u'echo'>}\n\nSince the remote processor cannot instantaneously complete a job, incoming jobs\nare managed by a queue. First we request the echo job to be executed:\n\n  >>> jobid1 = rp.addJob(u'echo', {'foo': 'bar'})\n  >>> jobid1\n  u'...'\n\n  >>> sorted([job.status for job in rp._jobs.values()])\n  [u'queued']\n\nThe ``addJob()`` function schedules the job called \"echo\" to be executed\nwith the specified arguments. The method returns a job id with which we can\ninquire about the job. The ``addJob()`` function marks a job as queued.\n\n  >>> rp.getJobStatus(jobid1)\n  u'queued'\n\nSince the job has not been processed, the status is set to \"queued\". Further,\nthere is no result available yet:\n\n  >>> rp.getJobResult(jobid1) is None\n  True\n\nAs long as the job is not being processed, it can be cancelled:\n\n  >>> rp.cancelJob(jobid1)\n  >>> rp.getJobStatus(jobid1)\n  u'cancelled'\n\n  >>> sorted([job.status for job in rp._jobs.values()])\n  [u'cancelled']\n\nThe worker processor isn't being started by default:\n\n  >>> rp.isProcessing\n  False\n\nTo get a clean logging environment let's clear the logging stack::\n\n  >>> logger.clear()\n\nNow we can start the remote processor by calling ``startProcessor``:\n\n  >>> rp.startProcessor()\n\nand voila - the remote processor is processing:\n\n  >>> rp.isProcessing\n  True\n\nChecking out the logging will prove the started remote processor:\n\n  >>> print logger\n  m01.remote INFO\n    Processor 'root-worker' started\n\nLet's stop the processor again:\n\n  >>> rp.stopProcessor()\n  >>> rp.isProcessing\n  False\n\nNow let's get a result from a processed job but first commit the new added job:\n\n  >>> jobid2 = rp.addJob(u'echo', {'foo': u'bar'})\n  >>> transaction.commit()\n\n  >>> sorted([job.status for job in rp._jobs.values()])\n  [u'cancelled', u'queued']\n\nNow create a worker and process the new jobs by calling our simple worker:\n\n  >>> class FakeWorker(object):\n  ...\n  ...     def __init__(self, rp):\n  ...         self.rp = rp\n  ...\n  ...     def __call__(self):\n  ...         try:\n  ...             result = self.rp.processNextJob()\n  ...             transaction.commit()\n  ...         except Exception, error:\n  ...             transaction.commit()\n\n  >>> worker = FakeWorker(rp)\n  >>> worker()\n\n  >>> sorted([job.status for job in rp._jobs.values()])\n  [u'cancelled', u'completed']\n\nFirst check if the job get processed:\n\n  >>> rp.getJobStatus(jobid2)\n  u'completed'\n\n  >>> rp.getJobResult(jobid2)\n  {u'foo': u'bar'}\n\n\nError handling\n--------------\n\nNow, let's define a new job that causes an error:\n\n  >>> errorJob = testing.RemoteExceptionJob()\n  >>> rp.addJobFactory(u'error', errorJob)\n\nNow add and execute it:\n\n  >>> jobid3 = rp.addJob(u'error')\n  >>> transaction.commit()\n  >>> worker()\n\n  >>> sorted([job.status for job in rp._jobs.values()])\n  [u'cancelled', u'completed', u'error']\n\nLet's now see what happened:\n\n  >>> rp.getJobStatus(jobid3)\n  u'error'\n  >>> errors = rp.getJobErrors(jobid3)\n  >>> errors\n  [<JobError u'...'>]\n\nSuch a JobError item provides the following data:\n\n  >>> error = tuple(errors)[0]\n  >>> data = error.dump()\n  >>> data = m01.mongo.dictify(data)\n  >>> pprint(data)\n  {'_id': ObjectId('...'),\n   '_type': u'JobError',\n   'created': datetime.datetime(..., ..., ..., ..., ..., ..., ..., tzinfo=<bson.tz_util.FixedOffset object at ...>),\n   'tb': u\"<p>Traceback (most recent call last):...\"}\n\nAs you can see the traceback stored as tb is the most important information:\n\n  >>> print data['tb']\n  <p>Traceback (most recent call last):</p>\n  <ul>\n  <li>  Module m01.remote.processor, line 297, in _processJob<br />\n      job.output = job(self)</li>\n  <li>  Module m01.remote.testing, line 86, in __call__<br />\n      raise exceptions.RemoteException('An error occurred.')</li>\n  </ul><p>RemoteException: An error occurred.<br />\n  </p>\n\nTry at also with a not so nice error:\n\n  >>> fatalJob = testing.FatalExceptionJob()\n  >>> rp.addJobFactory(u'fatal', fatalJob)\n\nNow add and execute it:\n\n  >>> jobid4 = rp.addJob(u'fatal')\n  >>> transaction.commit()\n  >>> worker()\n\n  >>> sorted([job.status for job in rp._jobs.values()])\n  [u'cancelled', u'completed', u'error', u'queued']\n\n  >>> job4 = rp._jobs[jobid4]\n  >>> job4.retryCounter\n  1\n  >>> job4.status == u'queued'\n  True\n\n  >>> job4.errors\n  [<JobError u'...'>]\n\nAnd process the job again but first set our retryTime to an outdated value which\nwill simulate that time passes since our last call:\n\n  >>> import datetime\n  >>> job4.retryTime = datetime.datetime(2000, 1, 1, tzinfo=UTC)\n  >>> transaction.commit()\n  >>> worker()\n\n  >>> sorted([job.status for job in rp._jobs.values()])\n  [u'cancelled', u'completed', u'error', u'queued']\n\n  >>> job4 = rp._jobs[jobid4]\n  >>> job4.retryCounter\n  2\n\n  >>> job4.errors\n  [<JobError u'...'>,\n   <JobError u'...'>]\n\nAnd process the job again the 3rd time. Now it does not re-raise the exception\nbut the error message get appended to the error list.\n\n  >>> job4.retryTime = datetime.datetime(2000, 1, 1, tzinfo=UTC)\n  >>> transaction.commit()\n  >>> worker()\n\n  >>> sorted([job.status for job in rp._jobs.values()])\n  [u'cancelled', u'completed', u'error', u'error']\n\nLet's now see what happened:\n\n  >>> job4 = rp._jobs[jobid4]\n  >>> job4.retryCounter\n  3\n\n  >>> job4.status\n  u'error'\n\n  >>> rp.getJobStatus(jobid4)\n  u'error'\n\n  >>> job4.errors\n  [<JobError u'...'>,\n   <JobError u'...'>,\n   <JobError u'...'>]\n\n  >>> rp.getJobErrors(jobid4)\n  [<JobError u'...'>,\n   <JobError u'...'>,\n   <JobError u'...'>]\n\n\nFor management purposes, the remote processor also allows you to inspect all\njobs:\n\n  >>> pprint(dict(rp._jobs))\n  {u'...': <EchoJob u'...' ...>,\n   u'...': <EchoJob u'...' ...>,\n   u'...': <RemoteExceptionJob u'...' ...>,\n   u'...': <FatalExceptionJob u'...' ...>}\n\n\nTo get rid of jobs not needed anymore we can use the reomveJobs method.\n\n  >>> jobid8 = rp.addJob(u'echo', {'blah': 'blah'})\n  >>> transaction.commit()\n\n  >>> sorted([job.status for job in rp._jobs.values()])\n  [u'cancelled', u'completed', u'error', u'error', u'queued']\n\n  >>> rp.removeJobs()\n  {u'cancelled': 1, u'completed': 1, u'error': 2}\n\n  >>> sorted([job.status for job in rp._jobs.values()])\n  [u'queued']\n\nNow process the last pending job and make sure we do not get more jobs:\n\n  >>> rp.pullNextJob()\n  <EchoJob u'...' ...>\n\n\nThreading behavior\n------------------\n\nEach remote processor runs in a separate thread, allowing them to operate\nindependently. Jobs should be designed to avoid conflict errors.\n\nLet's start the remote processor we have defined at this point, and see what\nthreads are running as a result::\n\n  >>> rp.startProcessor()\n\n  >>> import pprint\n  >>> import threading\n\n  >>> def show_threads():\n  ...     threads = [t for t in threading.enumerate()\n  ...                if t.getName().startswith('root')]\n  ...     threads.sort(key=lambda t: t.getName())\n  ...     pprint.pprint(threads)\n\n  >>> show_threads()\n  [<Thread(root-worker, started daemon ...)>]\n\nLet's stop the remote processor, and give the background threads a chance to get\nthe message::\n\n  >>> rp.stopProcessor()\n\n  >>> import time\n  >>> time.sleep(2)\n\nThe threads have exited now::\n\n  >>> print [t for t in threading.enumerate()\n  ...        if t.getName().startswith('root')]\n  []\n\n\n===========\nJob Workers\n===========\n\nThe actual processing of the jobs in a queue is handled by a spearate\ncomponent, known as a job worker. This component usually runs in its own\nthread and provides its own main loop.\n\n  >>> import time\n  >>> import transaction\n\nThe ``worker`` module provides a job worker which executes one job at a\ntime. Another worker is scheduling new jobs items beased on scheduler item\nsettings. Let's create the necessary components to test the job worker:\n\n1. Create the remote processor:\n\n  >>> from m01.remote import testing\n  >>> rp = root\n  >>> rp.isProcessing\n  False\n\n  >>> rp.isScheduling\n  False\n\n2. Register a job that simply sleeps and writes a message:\n\n  >>> data = {'retryDelay': 1}\n  >>> sleepJob = testing.SleepJob(data)\n  >>> rp.addJobFactory(u'sleep', sleepJob)\n\n\nSimpleJobWorker\n---------------\n\nThis worker executes one job at a time. It was designed for jobs that would\ntake a long time and use up most of the processing power of a computer.\n\nLet's first register a few jobs:\n\n  >>> jobid1 = rp.addJob(u'sleep', (0.04, 1))\n  >>> time.sleep(0.2)\n  >>> jobid2 = rp.addJob(u'sleep', (0.1,  2))\n  >>> time.sleep(0.2)\n  >>> jobid3 = rp.addJob(u'sleep', (0,    3))\n  >>> time.sleep(0.2)\n  >>> jobid4 = rp.addJob(u'sleep', (0.08, 4))\n  >>> time.sleep(0.2)\n  >>> transaction.commit()\n\nNow let's first check if we can aceess the jobs:\n\n  >>> job = rp._jobs.get(jobid1)\n  >>> job\n  <SleepJob u'...' ...>\n\nAnd let's try if the job is ready for processing:\n\n  >>> rp.getJobStatus(jobid1)\n  u'queued'\n\n  >>> rp.getJobStatus(jobid2)\n  u'queued'\n\n  >>> rp.getJobStatus(jobid3)\n  u'queued'\n\n  >>> rp.getJobStatus(jobid4)\n  u'queued'\n\nLet's start by executing a job directly. The first argument to the simple\nworker constructor is the remote processor instance. All other arguments are\noptional and can be defined as worker rguments in the RemoteProcessor class,\nsee jobWorkerArguments and schedulerWorkerArguments:\n\n  >>> from m01.remote.worker import SimpleJobWorker\n  >>> worker = SimpleJobWorker(rp, waitTime=0.0)\n\nLet's now process the first job. We clear the log and we also have to end any\nexisting interactions in order to process the job in this thread:\n\n  >>> logger.clear()\n\n  >>> from zope.security import management\n  >>> management.endInteraction()\n\n  >>> worker.doProcessNextJob()\n  True\n\n  >>> print logger\n  m01.remote INFO\n    Job: 1\n\nLet's now use the worker from within the remote processor. Since the worker\nconstructors also accept additional arguments, they are specified as well:\n\n  >>> rp.jobWorkerFactory = SimpleJobWorker\n  >>> rp.jobWorkerFactory\n  <class 'm01.remote.worker.SimpleJobWorker'>\n\n  >>> rp.jobWorkerArguments\n  {'waitTime': 0.0}\n\nThe wait time has been set to zero for testing purposes only. It is really set\nto 1 second by default. Let's now start processing jobs, wait a little bit\nfor all the jobs to complete and then stop processing again:\n\n  >>> rp.startProcessor()\n  >>> transaction.commit()\n\n  >>> time.sleep(0.5)\n\n  >>> rp.stopProcessor()\n  >>> transaction.commit()\n\n  >>> time.sleep(0.5)\n\nThe log shows that all jobs have been processed. But more importantly, they\nwere all completed in the order they were defined. Note the first job get\nprocessed before we started the remote processor. And yes this means a remote\nprocessor can process jobs if the queue is not started. Starting a remote\nprocessor only means that the job get processed as jobs without to do it\nmanualy.\n\n  >>> print logger\n  m01.remote INFO\n    Job: 1\n  m01.remote INFO\n    Processor 'root-worker' started\n  m01.remote INFO\n    Job: 2\n  m01.remote INFO\n    Job: 3\n  m01.remote INFO\n    Job: 4\n  m01.remote INFO\n    Processor 'root-worker' stopped\n\n  >>> logger.clear()\n\n\nTransactions in jobs\n--------------------\n\nWith the SimpleJobWorker, jobs _should_ not change the transaction status, since\nboth the administration of the jobs by the RemoteProcessor and the job itself\nrun in the same transaction, so aborting it from inside the job could mess up\nthe administrative part.\n\nThis is a regression test that aborting the transaction inside the job does not\nlead to an infinite loop (because SimpleJobWorker pulls the job inside the\ntransaction, so if it is aborted, the job remains on the queue):\n\n  >>> testing.testCounter\n  0\n\n  >>> counter = 0\n  >>> data = {'counter': counter}\n  >>> abortJob = testing.TransactionAbortJob(data)\n  >>> rp.addJobFactory(u'abortJob', abortJob)\n  >>> jobid = rp.addJob(u'abortJob', (1))\n  >>> time.sleep(0.5)\n  >>> jobid = rp.addJob(u'abortJob', (2))\n  >>> transaction.commit()\n\n  >>> rp.startProcessor()\n  >>> transaction.commit()\n  >>> time.sleep(0.5)\n\n  >>> rp.stopProcessor()\n  >>> transaction.commit()\n  >>> time.sleep(0.5)\n\n  >>> transaction.abort() # prevent spurious conflict errors\n  >>> testing.testCounter\n  2\n\n  >>> print logger\n  m01.remote INFO\n    Processor 'root-worker' started\n  m01.remote INFO\n    Job: 1\n  m01.remote INFO\n    Job: 2\n  m01.remote INFO\n    Processor 'root-worker' stopped\n\nReset test counter\n\n  >>> testing.testCounter = 0\n\n\nMultiJobProcessor\n-----------------\n\nThe multi-threaded job worker executes several jobs at once. It was designed\nfor jobs that would take a long time but use very little processing power.\n\nLet's add a few new jobs to execute:\n\n  >>> jobid1 = rp.addJob(u'sleep', (0.04, 1))\n  >>> time.sleep(0.2)\n  >>> jobid2 = rp.addJob(u'sleep', (1.0,  2))\n  >>> time.sleep(0.2)\n  >>> jobid3 = rp.addJob(u'sleep', (0,    3))\n  >>> time.sleep(0.2)\n  >>> jobid4 = rp.addJob(u'sleep', (0.2,  4))\n  >>> time.sleep(0.2)\n  >>> transaction.commit()\n\nBefore testing the worker in the remote processor, let's have a look at every\nmethod by itself. So we instantiate the worker:\n\n  >>> from m01.remote.worker import MultiJobWorker\n  >>> worker = MultiJobWorker(rp, waitTime=0, maxThreads=2)\n\nThe maximum amount of threads can be set as well:\n\n  >>> worker.maxThreads\n  2\n\nAll working threads can be reviewed at any time:\n\n  >>> worker.threads\n  []\n\n  >>> from zope.security import management\n  >>> management.endInteraction()\n\nLet's pull a new job:\n\n  >>> job = worker.doPullNextJob()\n  >>> job\n  <SleepJob u'...' ...>\n\nWe need to pull a job before executing it, so that the database marks the job\nas processing and no new thread picks up the same job. As you can see the job\nget marked with the processing status:\n\n  >>> job.status\n  u'processing'\n\nOnce we pulled a particular job, we can process it:\n\n  >>> logger.clear()\n  >>> print logger\n\n  >>> worker.doProcessJob(job.__name__)\n\n  >>> print logger\n  m01.remote INFO\n    Job: 1\n\nLet's now have a look at using the processor in the task service. This\nprimarily means setting the processor factory:\n\n  >>> management.newInteraction()\n\n  >>> rp.jobWorkerFactory = MultiJobWorker\n  >>> rp.jobWorkerArguments = {'waitTime': 1.0, 'maxThreads': 2}\n  >>> transaction.commit()\n\n  >>> logger.clear()\n\nLet's now process the remaining jobs:\n\n  >>> rp.startProcessor()\n  >>> transaction.commit()\n  >>> time.sleep(1.5)\n\n  >>> rp.stopProcessor()\n  >>> transaction.commit()\n  >>> time.sleep(0.5)\n\nAs you can see, this time the jobs are not completed in order anymore, because\nthey all need different time to execute:\n\n  >>> print logger\n  m01.remote INFO\n    Processor 'root-worker' started\n  m01.remote INFO\n    MultiJobWorker: processing job ...\n  m01.remote INFO\n    MultiJobWorker: processing job ...\n  m01.remote INFO\n    Job: 3\n  m01.remote INFO\n    MultiJobWorker: processing job ...\n  m01.remote INFO\n    Job: 4\n  m01.remote INFO\n    Job: 2\n  m01.remote INFO\n    Processor 'root-worker' stopped\n\nLet's now set the thread limit to four and construct a new set of jobs that\ndemonstrate that all jobs will run at the same time:\n\n  >>> rp.jobWorkerArguments = {'waitTime': 0.0, 'maxThreads': 4}\n\n  >>> jobid1 = rp.addJob(u'sleep', (0.3, 1))\n  >>> time.sleep(0.2)\n  >>> jobid2 = rp.addJob(u'sleep', (0.4, 2))\n  >>> time.sleep(0.2)\n  >>> jobid3 = rp.addJob(u'sleep', (0.1, 3))\n  >>> time.sleep(0.2)\n  >>> jobid4 = rp.addJob(u'sleep', (0.5, 4))\n  >>> time.sleep(0.2)\n  >>> transaction.commit()\n\nIf all tasks are processed at once, job 3 should be done first. You can also\nsee that the job 4 get processed ASAP even before the worker logs processing:\n\n  >>> logger.clear()\n\n  >>> rp.startProcessor()\n  >>> transaction.commit()\n\n  >>> time.sleep(1.0)\n\n  >>> rp.stopProcessor()\n  >>> transaction.commit()\n  >>> time.sleep(0.5)\n\n  >>> print logger\n  m01.remote INFO\n    Processor 'root-worker' started\n  m01.remote INFO\n    MultiJobWorker: processing job ...\n  m01.remote INFO\n    MultiJobWorker: processing job ...\n  m01.remote INFO\n    MultiJobWorker: processing job ...\n  m01.remote INFO\n    MultiJobWorker: processing job ...\n  m01.remote INFO\n    Job: 3\n  m01.remote INFO\n    Job: 1\n  m01.remote INFO\n    Job: 2\n  m01.remote INFO\n    Job: 4\n  m01.remote INFO\n    Processor 'root-worker' stopped\n\nLet's now set the thread limit to two and construct a new set of jobs that\ndemonstrate that not more than two threads run at the same time:\n\n  >>> rp.jobWorkerArguments = {'waitTime': 0.0, 'maxThreads': 2}\n  >>> transaction.commit()\n\n  >>> jobid1 = rp.addJob(u'sleep', (0.3, 1))\n  >>> time.sleep(0.2)\n  >>> jobid2 = rp.addJob(u'sleep', (0.4, 2))\n  >>> time.sleep(0.2)\n  >>> jobid3 = rp.addJob(u'sleep', (0.2, 3))\n  >>> time.sleep(0.2)\n  >>> jobid4 = rp.addJob(u'sleep', (0.5, 4))\n  >>> time.sleep(0.2)\n  >>> transaction.commit()\n\nIf all tasks are processed at once, job 3 should be done first, but since the\njob has to wait for an available thread, it will come in third. We can now run\nthe jobs and see the result:\n\n  >>> logger.clear()\n\n  >>> rp.startProcessor()\n  >>> transaction.commit()\n\n  >>> time.sleep(1.5)\n\n  >>> rp.stopProcessor()\n  >>> transaction.commit()\n  >>> time.sleep(0.5)\n\n  >>> print logger\n  m01.remote INFO\n    Processor 'root-worker' started\n  m01.remote INFO\n    MultiJobWorker: processing job ...\n  m01.remote INFO\n    MultiJobWorker: processing job ...\n  m01.remote INFO\n    Job: 1\n  m01.remote INFO\n    MultiJobWorker: processing job ...\n  m01.remote INFO\n    Job: 2\n  m01.remote INFO\n    MultiJobWorker: processing job ...\n  m01.remote INFO\n    Job: 3\n  m01.remote INFO\n    Job: 4\n  m01.remote INFO\n    Processor 'root-worker' stopped\n\n=========\nScheduler\n=========\n\nThe scheduler concept is implemented as an additional scheduler container which\ncontains scheduler items.\n\n  >>> from m01.mongo import UTC\n  >>> import m01.remote.scheduler\n  >>> from m01.remote import interfaces\n  >>> from m01.remote import testing\n\nLet's now start by get our test remote procesor which contains our scheduler\ncontainer:\n\n  >>> remoteProcessor = root\n  >>> remoteProcessor\n  <TestProcessor None>\n\n  >>> scheduler = remoteProcessor._scheduler\n\n  >>> tuple(scheduler.values())\n  ()\n\n\nDelay\n-----\n\nWe can add a scheduler item for delay a job processing. Let's add such an item:\n\n  >>> import datetime\n  >>> def getNextTime(dt, seconds):\n  ...     return dt + datetime.timedelta(seconds=seconds)\n\n  >>> now = datetime.datetime(2010, 10, 1, 0, 0, 0, tzinfo=UTC)\n  >>> now10 = getNextTime(now, 10)\n  >>> delay = 10\n  >>> data = {'jobName': u'echo 1', 'active': True, 'delay': delay,\n  ...         'retryDelay': 5, 'nextCallTime': now10}\n  >>> firstEcho = m01.remote.scheduler.Delay(data)\n  >>> interfaces.IDelay.providedBy(firstEcho)\n  True\n\nThe delay is set to 10:\n\n  >>> firstEcho.delay\n  10\n\nand the retryDelay to 5\n\n  >>> firstEcho.retryDelay\n  5\n\nand we set an explicit nextCallTime of now + 10:\n\n  >>> firstEcho.nextCallTime == getNextTime(now, 10)\n  True\n\nand our retryTime is None:\n\n  >>> firstEcho.retryTime is None\n  True\n\nNow we can add the delay item to the scheduler:\n\n  >>> scheduler.add(firstEcho)\n  u'...'\n\nAs you can see the scheduler contains on item:\n\n  >>> sorted(scheduler.values())\n  [<Delay ... for: u'echo 1'>]\n\nAs next we'll test some scheduler AP methods. First check if we can update\nthe retryTime for an item in our adding cache with ``updateRetryTime``::\n\n  >>> scheduler.updateRetryTime(firstEcho.dump(), now)\n  False\n\nAs you can see we did not get a new retryTime. This happens because we didn't\nuse the correct callTime. Let's try with the correct nextCallTime:\n\n  >>> now10 = getNextTime(now, 10)\n  >>> now15 = getNextTime(now, 15)\n  >>> retryTime = scheduler.updateRetryTime(firstEcho.dump(), now10)\n  >>> retryTime == now15\n  True\n\nAs you can see the new retryTime is using the retryDelay of 5 second. This\nretryTime is used for lock an item. This means an item get not picked as long\nas this time get passed.\n\n\nNow let' try another internal API method hihc is able to get the next item\nfrom our adding cache:\n\n  >>> scheduler.getNextCachedItem(now)\n\nAs you can see the method didn't return an item, let's try with the next\nscheduled call time:\n\n  >>> nextCallTime = firstEcho.nextCallTime\n  >>> scheduler.getNextCachedItem(now10)\n  <Delay ... for: u'echo 1'>\n\nAs you can see the retryTime get set based on the nextCallTime and the\nretryDelay:\n\n  >>> firstEcho.retryTime == getNextTime(nextCallTime, 5)\n  True\n\nNow the important part. Let's test our method which is responsible for get\na next item including items from mongo. This method uses the two methods above.\nOf corse with the current time we will not get any item:\n\n  >>> scheduler.pullNextSchedulerItem(now) is None\n  True\n\nBut now we need another nextCallTime because the previous call update the \nitems nextCallTime. Let's first check the nextCallTime:\n\n  >>> firstEcho.nextCallTime == now10\n  True\n\nBut as you can see, the retryTime is already set during our previous test. this\nmeans we only will get an item if we at least use a larger time if the\nretryTime:\n\n  >>> firstEcho.retryTime == now15\n  True\n\n  >>> scheduler.pullNextSchedulerItem(now10)\n\n  >>> scheduler.pullNextSchedulerItem(now15)\n  <Delay ... for: u'echo 1'>\n\nNow, let's check our scheduled item times:\n\n  >>> now20 = getNextTime(now15, 5)\n  >>> firstEcho.nextCallTime == now10\n  True\n\nNote, our retryTime get calculated with the current call time and retryDelay.\nIt whould not make sense if we whould use the callTime as retryTime calculation\nbase:\n\n  >>> firstEcho.retryTime == now20\n  True\n\n\nThe method pullNextSchedulerItem returns a pending item or None since we don't\nhave one pending:\n\n  >>> scheduler.pullNextSchedulerItem(now) is None\n  True\n\nNow let's add a second scheduler item within some scheduler time:\n\n  >>> import datetime\n  >>> delay = 10\n  >>> data = {'jobName': u'echo 2', 'active': True, 'delay': delay,\n  ...         'retryDelay': 5}\n  >>> secondEcho = m01.remote.scheduler.Delay(data)\n\n  >>> scheduler.add(secondEcho)\n  u'...'\n\n  >>> sorted(scheduler.values(), key=lambda x:(x.__name__, x.__name__))\n  [<Delay ... for: u'echo 1'>, <Delay ... for: u'echo 2'>]\n\n  >>> scheduler.remove(firstEcho)\n  >>> scheduler.remove(secondEcho)\n  >>> tuple(scheduler.values())\n  ()\n\n\n\nadjustCallTime\n--------------\n\nBefore we test our cron item, let's test test our method which can reset a\ngiven datetime to the smalles starting point e.g. if hours are given as a\ncalculation base, we need to start counting within the first minute:\n\n  >>> from m01.remote.scheduler import adjustCallTime\n\n  >>> now = datetime.datetime(2010, 10, 25, 16, 6, 5, 123, tzinfo=UTC)\n  >>> now\n  datetime.datetime(2010, 10, 25, 16, 6, 5, 123, tzinfo=UTC)\n\n  >>> item = m01.remote.scheduler.Cron({'jobName': u'bar', 'minute': [5]})\n  >>> adjustCallTime(item, now)\n  datetime.datetime(2010, 10, 25, 16, 6, 0, 123, tzinfo=UTC)\n\nCron\n----\n\nA probably more interesting implementation is the cron scheduler item. This\ncron item can schedule jobs at a specific given time. Let's setup such a cron\nitem:\n\n  >>> data = {'jobName': u'bar', 'active': True, 'retryDelay': 5}\n  >>> cronItem = m01.remote.scheduler.Cron(data)\n\nThe cronItem provides the ISchedulerItem and ICron interface:\n\n  >>> interfaces.ISchedulerItem.providedBy(cronItem)\n  True\n\n  >>> interfaces.ICron.providedBy(cronItem)\n  True\n\nAs you can see the cron item also provides a retryDelay:\n\n  >>> cronItem.retryDelay\n  5\n\nLet's first explain how this works. The cron scheduler provides a next call\ntime stamp. If the calculated next call time is smaller then the last call time,\nthe cron scheduler item will calculate the new next call time and store them\nas nextCallTime and at the same time the previous nextCallTime get returnd.\nThis will makes sure that we have a minimum of time calculation calls because\neach time a cron scheduler item get asked about the next call time the stored\nnextCallTime is used. The cron schdeuler item only calculates the next call\ntime if the existing next call time is smaller then the given call time.\n\nNow let's test a cron as a scheduler item. Setup a simple corn item with a\n5 minute period.\n\n\n  >>> now = datetime.datetime(2010, 10, 1, 0, 0, 0, tzinfo=UTC)\n  >>> now\n  datetime.datetime(2010, 10, 1, 0, 0, tzinfo=UTC)\n\n  >>> data = {'jobName': u'echo cron', 'active': True, 'retryDelay': 5,\n  ...         'minute': [5], 'nextCallTime': now}\n  >>> cronEcho = m01.remote.scheduler.Cron(data)\n\nNow add the item to the schdeuler:\n\n  >>> scheduler.add(cronEcho)\n  u'...'\n\nAs you can see, our cron item get scheduled based on the given nextCallTime:\n\n  >>> cronEcho.nextCallTime\n  datetime.datetime(2010, 10, 1, 0, 0, tzinfo=UTC)\n\nthe retrytime is empty\n\n  >>> cronEcho.retryTime is None\n  True\n\n\nand the minute list contains our 5 minute:\n\n  >>> cronEcho.minute\n  [5]\n\n  >>> cronEcho.hour\n  []\n\n  >>> cronEcho.dayOfMonth\n  []\n\n  >>> cronEcho.month\n  []\n\n  >>> cronEcho.dayOfWeek\n  []\n\nAnd the scheduler contains one cron item:\n\n  >>> tuple(scheduler.values())\n  (<Cron ... for: u'echo cron'>,)\n\nNow we can get the job based on the jobName ``echo`` defined by our cron\nscheduler item if we call pullNextSchedulerItem.\n\n  >>> scheduler.pullNextSchedulerItem(now)\n  <Cron ... for: u'echo cron'>\n\nDuring this call the retryTime get set based on the retryDelay:\n\n  >>> cronEcho.retryTime\n  datetime.datetime(2010, 10, 1, 0, 0, 5, tzinfo=UTC)\n\nNow let's test the the different cron settings. Note that we provide a list of\nvalues for minutes, hours, month, dayOfWeek and dayOfMonth. This means you can\nschedule a job for every 15 minutes if you will set the minutes to\n(0, 15, 30, 45) or if you like to set a job only each 15 minutes after an hour\nyou can set minutes to (15,). If you will set more then one argument e.g.\nminute, hours or days etc. all arguments must fit the given time.\n\nLet's start with a cron scheduler for every first and second minute per hour.\nNormaly the corn scheduler item will set now ``int(time.time())`` as\nnextCallTime value. For test our cron scheduler items, we use a explicit\nstartTime value of 0 (zero):\n\n  >>> data = {'jobName': u'bar', 'active': True, 'retryDelay': 5,\n  ...         'minute': [0, 1]}\n  >>> cronItem = m01.remote.scheduler.Cron(data)\n\nThe next call time is set based on the given startTime value. This means the\nfirst call will be at 0 (zero) minute:\n\n  >>> cronItem.nextCallTime is None\n  True\n\nNow let's call getNextCallTime, as you can see we will get None as nextCallTime\nbecause we ddn't set a nextCallTime during cron initialization and the\nnextCallTime is set to the next minute:\n\n  >>> cronItem.getNextCallTime(now) is None\n  True\n\n  >>> cronItem.nextCallTime\n  datetime.datetime(2010, 10, 1, 0, 1, tzinfo=UTC)\n\nNow let's call getNextCallTime again, as you can see we will get the\nnextCallTime we calculated during object initialization which is the given\ncall time and the nextCallTime is set to the next minute:\n\nIf we use a call time + 5 seconds, we still will get the cached next call\ntime of 1 minute and we will not generate a new next call time since this\ntime is already in the future:\n\n  >>> cronItem.getNextCallTime(getNextTime(now, 5))\n  datetime.datetime(2010, 10, 1, 0, 1, tzinfo=UTC)\n\n  >>> cronItem.nextCallTime\n  datetime.datetime(2010, 10, 1, 0, 1, tzinfo=UTC)\n\nIf we call the cron scheduler item with a call time equal or larger then our\n1 minute delay from the cached next call time, we will get the cached call time\nas value as we whould get similar to a smaller call time (see sample above).\n\n  >>> cronItem.getNextCallTime(getNextTime(now, 65))\n  datetime.datetime(2010, 10, 1, 0, 1, tzinfo=UTC)\n\n  >>> cronItem.nextCallTime\n  datetime.datetime(2010, 10, 1, 1, 0, tzinfo=UTC)\n\nAll future calls with a smaller time then the nextCallTime will return the \ncurrent nextCallTime and not calculate any new time.\n\n  >>> cronItem.getNextCallTime(getNextTime(now, 125))\n  datetime.datetime(2010, 10, 1, 1, 0, tzinfo=UTC)\n\n  >>> cronItem.getNextCallTime(getNextTime(now, 1*60*60))\n  datetime.datetime(2010, 10, 1, 1, 0, tzinfo=UTC)\n\n\nRemember, getNextCallTime returns the previous calculated nextCallTime and the\nnew calculated nextCallTime get stored as nextCallTime. For a simpler test\noutput we define a test method which shows the time calculation:\n\n\nMinutes\n~~~~~~~\n\nLet's start testing the time tables.\n\n  >>> def getNextCallTime(cron, dt, seconds=None):\n  ...     \"\"\"Return stored and new calculated nextCallTime\"\"\"\n  ...     if seconds is None:\n  ...         callTime = dt\n  ...     else:\n  ...         callTime = getNextTime(dt, seconds)\n  ...     nextCallTime = cron.getNextCallTime(callTime)\n  ...     return '%s --> %s' % (nextCallTime, cron.nextCallTime)\n\n  >>> now = datetime.datetime(1970, 1, 1, 0, 3, 0, tzinfo=UTC)\n  >>> data = {'jobName': u'bar', 'active': True, 'retryDelay': 5,\n  ...         'minute': [0, 10], 'nextCallTime':now}\n  >>> item = m01.remote.scheduler.Cron(data)\n\n  >>> str(now)\n  '1970-01-01 00:03:00+00:00'\n\n  >>> getNextCallTime(item, now)\n  '1970-01-01 00:03:00+00:00 --> 1970-01-01 00:10:00+00:00'\n\n  >>> getNextCallTime(item, now, 1)\n  '1970-01-01 00:10:00+00:00 --> 1970-01-01 00:10:00+00:00'\n\n  >>> getNextCallTime(item, now, 2*60)\n  '1970-01-01 00:10:00+00:00 --> 1970-01-01 00:10:00+00:00'\n\n  >>> getNextCallTime(item, now, 51*60)\n  '1970-01-01 00:10:00+00:00 --> 1970-01-01 01:00:00+00:00'\n\n  >>> getNextCallTime(item, now, 55*60)\n  '1970-01-01 01:00:00+00:00 --> 1970-01-01 01:00:00+00:00'\n\n\nHour\n~~~~\n\n  >>> data = {'jobName': u'bar', 'active': True, 'retryDelay': 5,\n  ...         'hour': [2, 13], 'nextCallTime':now}\n  >>> item = m01.remote.scheduler.Cron(data)\n\n  >>> getNextCallTime(item, now)\n  '1970-01-01 00:03:00+00:00 --> 1970-01-01 02:00:00+00:00'\n\n  >>> getNextCallTime(item, now, 2*60*60)\n  '1970-01-01 02:00:00+00:00 --> 1970-01-01 13:00:00+00:00'\n\n  >>> getNextCallTime(item, now, 4*60*60)\n  '1970-01-01 13:00:00+00:00 --> 1970-01-01 13:00:00+00:00'\n\n  >>> getNextCallTime(item, now, 13*60*60)\n  '1970-01-01 13:00:00+00:00 --> 1970-01-02 02:00:00+00:00'\n\n  >>> getNextCallTime(item, now, 15*60*60)\n  '1970-01-02 02:00:00+00:00 --> 1970-01-02 02:00:00+00:00'\n\n\nMonth\n~~~~~\n\n  >>> data = {'jobName': u'bar', 'active': True, 'retryDelay': 5,\n  ...         'month': [1, 2, 5, 12], 'nextCallTime':now}\n  >>> item = m01.remote.scheduler.Cron(data)\n\n  >>> getNextCallTime(item, now)\n  '1970-01-01 00:03:00+00:00 --> 1970-02-01 00:03:00+00:00'\n\n  >>> getNextCallTime(item, now, 90*24*60*60)\n  '1970-02-01 00:03:00+00:00 --> 1970-05-01 00:03:00+00:00'\n\n  >>> getNextCallTime(item, now, 120*24*60*60)\n  '1970-05-01 00:03:00+00:00 --> 1970-12-01 00:03:00+00:00'\n\n  >>> getNextCallTime(item, now, 130*24*60*60)\n  '1970-12-01 00:03:00+00:00 --> 1970-12-01 00:03:00+00:00'\n\n  >>> getNextCallTime(item, now, 360*24*60*60)\n  '1970-12-01 00:03:00+00:00 --> 1971-01-01 00:03:00+00:00'\n\n\ndayOfWeek [0..6]\n~~~~~~~~~~~~~~~~\n\n  >>> data = {'jobName': u'bar', 'active': True, 'retryDelay': 5,\n  ...         'dayOfWeek': [0, 2, 4, 5], 'nextCallTime':now}\n  >>> item = m01.remote.scheduler.Cron(data)\n\nThe current weekday of now is:\n\n  >>> now.weekday()\n  3\n\nthis means our nextCallTime should get changed using day 4 as our \nnextCallTime if we call them with ``now``:\n\n  >>> getNextCallTime(item, now)\n  '1970-01-01 00:03:00+00:00 --> 1970-01-02 00:03:00+00:00'\n\nwith a day more, we will get the weekday 4 (skip):\n\n  >>> getNextCallTime(item, now, 24*60*60)\n  '1970-01-02 00:03:00+00:00 --> 1970-01-03 00:03:00+00:00'\n\nwith another day more, we will get the weekday 5 (incr):\n\n  >>> getNextCallTime(item, now, 2*24*60*60)\n  '1970-01-03 00:03:00+00:00 --> 1970-01-05 00:03:00+00:00'\n\nwith another day more, we will get the weekday 6 (skip):\n\n  >>> getNextCallTime(item, now, 3*24*60*60)\n  '1970-01-05 00:03:00+00:00 --> 1970-01-05 00:03:00+00:00'\n\nwith another day more, we will get the weekday 0 (inc):\n\n  >>> getNextCallTime(item, now, 4*24*60*60)\n  '1970-01-05 00:03:00+00:00 --> 1970-01-07 00:03:00+00:00'\n\n\ndayOfMonth [1..31]\n~~~~~~~~~~~~~~~~~~\n\n  >>> data = {'jobName': u'bar', 'active': True, 'retryDelay': 5,\n  ...         'dayOfMonth': [2, 12, 21, 30], 'nextCallTime': now}\n  >>> item = m01.remote.scheduler.Cron(data)\n\n  >>> getNextCallTime(item, now)\n  '1970-01-01 00:03:00+00:00 --> 1970-01-02 00:00:00+00:00'\n\n  >>> getNextCallTime(item, now, 12*24*60*60)\n  '1970-01-02 00:00:00+00:00 --> 1970-01-21 00:00:00+00:00'\n\n  >>> getNextCallTime(item, now, 31*24*60*60)\n  '1970-01-21 00:00:00+00:00 --> 1970-02-02 00:00:00+00:00'\n\n\nCombined\n~~~~~~~~\n\ncombine some attributes:\n\n  >>> data = {'jobName': u'bar', 'active': True, 'retryDelay': 5,\n  ...         'minute': [10], 'dayOfMonth': [1, 10, 20, 30],\n  ...         'nextCallTime': now}\n  >>> item = m01.remote.scheduler.Cron(data)\n\n  >>> getNextCallTime(item, now)\n  '1970-01-01 00:03:00+00:00 --> 1970-01-01 00:10:00+00:00'\n\n  >>> getNextCallTime(item, now, 10*60)\n  '1970-01-01 00:10:00+00:00 --> 1970-01-01 01:10:00+00:00'\n\n  >>> getNextCallTime(item, now, 10*24*60*60)\n  '1970-01-01 01:10:00+00:00 --> 1970-01-20 00:10:00+00:00'\n\n  >>> getNextCallTime(item, now, 20*24*60*60)\n  '1970-01-20 00:10:00+00:00 --> 1970-01-30 00:10:00+00:00'\n\nanother sample:\n\n  >>> data = {'jobName': u'bar', 'active': True, 'retryDelay': 5,\n  ...         'minute': [10], 'hour': [4], 'dayOfMonth': [1, 12, 21, 30],\n  ...         'nextCallTime': now}\n  >>> item = m01.remote.scheduler.Cron(data)\n\n  >>> getNextCallTime(item, now)\n  '1970-01-01 00:03:00+00:00 --> 1970-01-01 04:10:00+00:00'\n\n  >>> getNextCallTime(item, now, 10*60)\n  '1970-01-01 04:10:00+00:00 --> 1970-01-01 04:10:00+00:00'\n\n  >>> getNextCallTime(item, now, 4*60*60)\n  '1970-01-01 04:10:00+00:00 --> 1970-01-01 04:10:00+00:00'\n\n  >>> getNextCallTime(item, now, 5*60*60)\n  '1970-01-01 04:10:00+00:00 --> 1970-01-12 04:10:00+00:00'\n\n\n=======\nCHANGES\n=======\n\n3.0.0 (2015-11-10)\n------------------\n\n- support pymongo >= 3.0.0 and use 3.0.0 as package version and reflect\n  pymongo >= 3.0.0 compatibility\n\n\n0.6.0 (2013-06-28)\n------------------\n\n- feature: implemented JobError as Job sub item. And rename previous JobError\n  to RemoteException. This changes requires that you delete all previous\n  JobError jobs in the job list before update. Also raise RemoteException\n  instead of JobError in your code. The new JobError sub item provides a\n  better error traceback message and a created date.\n\n- feature: implement better error handling, save formatted traceback string\n\n\n0.5.1 (2012-11-18)\n------------------\n\n- added MANIFEST.in files\n\n- remove p01.i18n package dependency\n\n- allow to remove jobs with all stati\n\n- split scheduler and container and move scheduler part into mixin class\n\n- switch to bson import\n\n- reflect changes in getBatchData signature\n\n- fix dateime compare, round milliseconds\n\n- adjust different schema description, user the same message id as used in title\n\n- removed unused id\n\n\n0.5.0 (2011-08-19)\n------------------\n\n- initial release", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://pypi.python.org/pypi/m01.remote", "keywords": "Zope3 z3c p01 m01 remote processor queue mongodb", "license": "ZPL 2.1", "maintainer": null, "maintainer_email": null, "name": "m01.remote", "package_url": "https://pypi.org/project/m01.remote/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/m01.remote/", "project_urls": {"Download": "UNKNOWN", "Homepage": "http://pypi.python.org/pypi/m01.remote"}, "release_url": "https://pypi.org/project/m01.remote/3.0.0/", "requires_dist": null, "requires_python": null, "summary": "Remote processing queue for Zope3", "version": "3.0.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>This package provides a remote processing queue for Zope3 using the mongodb\ninstead of ZODB.</p>\n<div id=\"readme\">\n<h2>README</h2>\n<p>This package offers a remote processor. This remote processor is implemented as\na simple object using the mongodb as storage. The processor can execute pre\ndefined jobs in another thread. It is also possible to run jobs at specific\ntime using the different scheduler items.</p>\n<p>The RemoteProcessor uses two different processor. One processes jobs and the\nother pickes items from the scheduler and is adding jobs. This separation\nis usefull if you implement a distributed concept. This means one or more\napplication can schedule job items based on the given scheduler items. And\nanother application is processing jobs and doesn\u2019t know about how to scheduling\nnext items.</p>\n<p>Since we use this remote scheduler for low CPU intensive jobs, we offer multi\nprocessing. This is done by running more then one worker in the main worker\nthread. If you use subprocess for your job processing, you will get a real\nmultiprocessing processor which isn\u2019t limited to the current python process.</p>\n<p>You can configure the amount of threads which a job worker can start in the\nremote processor. See jobWorkerArguments/maxThreads. By default this number\nuses the amount of CPU installed on your machine.</p>\n<p>The implementation uses a mongodb as a storage for it\u2019s component. This means\njobs, job factories and scheduler items get stored in the mongodb using the\nORM concept given from m01.mongo.</p>\n<p>See p01.remote for a ZODB based remote processor implementation but take care\nthe p01.remote implementation doesn\u2019t provide the worker and scheduler\nprocessor separation. At least not yet.</p>\n<div id=\"setup\">\n<h3>Setup</h3>\n<blockquote>\n<pre>&gt;&gt;&gt; import transaction\n&gt;&gt;&gt; from pprint import pprint\n&gt;&gt;&gt; import zope.component\n&gt;&gt;&gt; import m01.mongo\n&gt;&gt;&gt; from m01.mongo import UTC\n&gt;&gt;&gt; import m01.remote.job\n&gt;&gt;&gt; from m01.remote import testing\n</pre>\n</blockquote>\n<p>Let\u2019s now start by create two a remote processor. We can use our remote queue\nsite implementation:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; from zope.security.proxy import removeSecurityProxy\n&gt;&gt;&gt; from m01.remote import interfaces\n</pre>\n</blockquote>\n<p>Our test remote processor should be available as application root:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; rp = root\n&gt;&gt;&gt; rp\n&lt;TestProcessor None&gt;\n</pre>\n</blockquote>\n<p>Let\u2019s discover the available jobs:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; dict(root._jobs)\n{}\n</pre>\n</blockquote>\n<p>The job container is initially empty, because we have not added any job\nfactory. Let\u2019s now define a job factory that simply echos an input string:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; echoJob = testing.EchoJob({})\n</pre>\n</blockquote>\n<p>Now we can set the job input:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; echoJob.input = {'foo': u'blah'}\n</pre>\n</blockquote>\n<p>The only API requirement on the job is to be callable. Now we make sure that\nthe job works. Note we call our job with the remote processor instance which\nis our initialized application root:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; echoJob(root)\n{'foo': u'blah'}\n</pre>\n</blockquote>\n<p>Let\u2019s add the job to the available job list:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; rp.addJobFactory(u'echo', echoJob)\n</pre>\n</blockquote>\n<p>The echo job is now available in the remote processor:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; dict(rp._jobFactories)\n{u'echo': &lt;EchoJob u'echo'&gt;}\n</pre>\n</blockquote>\n<p>Since the remote processor cannot instantaneously complete a job, incoming jobs\nare managed by a queue. First we request the echo job to be executed:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; jobid1 = rp.addJob(u'echo', {'foo': 'bar'})\n&gt;&gt;&gt; jobid1\nu'...'\n</pre>\n<pre>&gt;&gt;&gt; sorted([job.status for job in rp._jobs.values()])\n[u'queued']\n</pre>\n</blockquote>\n<p>The <tt>addJob()</tt> function schedules the job called \u201cecho\u201d to be executed\nwith the specified arguments. The method returns a job id with which we can\ninquire about the job. The <tt>addJob()</tt> function marks a job as queued.</p>\n<blockquote>\n<pre>&gt;&gt;&gt; rp.getJobStatus(jobid1)\nu'queued'\n</pre>\n</blockquote>\n<p>Since the job has not been processed, the status is set to \u201cqueued\u201d. Further,\nthere is no result available yet:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; rp.getJobResult(jobid1) is None\nTrue\n</pre>\n</blockquote>\n<p>As long as the job is not being processed, it can be cancelled:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; rp.cancelJob(jobid1)\n&gt;&gt;&gt; rp.getJobStatus(jobid1)\nu'cancelled'\n</pre>\n<pre>&gt;&gt;&gt; sorted([job.status for job in rp._jobs.values()])\n[u'cancelled']\n</pre>\n</blockquote>\n<p>The worker processor isn\u2019t being started by default:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; rp.isProcessing\nFalse\n</pre>\n</blockquote>\n<p>To get a clean logging environment let\u2019s clear the logging stack:</p>\n<pre>&gt;&gt;&gt; logger.clear()\n</pre>\n<p>Now we can start the remote processor by calling <tt>startProcessor</tt>:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; rp.startProcessor()\n</pre>\n</blockquote>\n<p>and voila - the remote processor is processing:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; rp.isProcessing\nTrue\n</pre>\n</blockquote>\n<p>Checking out the logging will prove the started remote processor:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; print logger\nm01.remote INFO\n  Processor 'root-worker' started\n</pre>\n</blockquote>\n<p>Let\u2019s stop the processor again:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; rp.stopProcessor()\n&gt;&gt;&gt; rp.isProcessing\nFalse\n</pre>\n</blockquote>\n<p>Now let\u2019s get a result from a processed job but first commit the new added job:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; jobid2 = rp.addJob(u'echo', {'foo': u'bar'})\n&gt;&gt;&gt; transaction.commit()\n</pre>\n<pre>&gt;&gt;&gt; sorted([job.status for job in rp._jobs.values()])\n[u'cancelled', u'queued']\n</pre>\n</blockquote>\n<p>Now create a worker and process the new jobs by calling our simple worker:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; class FakeWorker(object):\n...\n...     def __init__(self, rp):\n...         self.rp = rp\n...\n...     def __call__(self):\n...         try:\n...             result = self.rp.processNextJob()\n...             transaction.commit()\n...         except Exception, error:\n...             transaction.commit()\n</pre>\n<pre>&gt;&gt;&gt; worker = FakeWorker(rp)\n&gt;&gt;&gt; worker()\n</pre>\n<pre>&gt;&gt;&gt; sorted([job.status for job in rp._jobs.values()])\n[u'cancelled', u'completed']\n</pre>\n</blockquote>\n<p>First check if the job get processed:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; rp.getJobStatus(jobid2)\nu'completed'\n</pre>\n<pre>&gt;&gt;&gt; rp.getJobResult(jobid2)\n{u'foo': u'bar'}\n</pre>\n</blockquote>\n</div>\n<div id=\"error-handling\">\n<h3>Error handling</h3>\n<p>Now, let\u2019s define a new job that causes an error:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; errorJob = testing.RemoteExceptionJob()\n&gt;&gt;&gt; rp.addJobFactory(u'error', errorJob)\n</pre>\n</blockquote>\n<p>Now add and execute it:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; jobid3 = rp.addJob(u'error')\n&gt;&gt;&gt; transaction.commit()\n&gt;&gt;&gt; worker()\n</pre>\n<pre>&gt;&gt;&gt; sorted([job.status for job in rp._jobs.values()])\n[u'cancelled', u'completed', u'error']\n</pre>\n</blockquote>\n<p>Let\u2019s now see what happened:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; rp.getJobStatus(jobid3)\nu'error'\n&gt;&gt;&gt; errors = rp.getJobErrors(jobid3)\n&gt;&gt;&gt; errors\n[&lt;JobError u'...'&gt;]\n</pre>\n</blockquote>\n<p>Such a JobError item provides the following data:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; error = tuple(errors)[0]\n&gt;&gt;&gt; data = error.dump()\n&gt;&gt;&gt; data = m01.mongo.dictify(data)\n&gt;&gt;&gt; pprint(data)\n{'_id': ObjectId('...'),\n '_type': u'JobError',\n 'created': datetime.datetime(..., ..., ..., ..., ..., ..., ..., tzinfo=&lt;bson.tz_util.FixedOffset object at ...&gt;),\n 'tb': u\"&lt;p&gt;Traceback (most recent call last):...\"}\n</pre>\n</blockquote>\n<p>As you can see the traceback stored as tb is the most important information:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; print data['tb']\n&lt;p&gt;Traceback (most recent call last):&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;  Module m01.remote.processor, line 297, in _processJob&lt;br /&gt;\n    job.output = job(self)&lt;/li&gt;\n&lt;li&gt;  Module m01.remote.testing, line 86, in __call__&lt;br /&gt;\n    raise exceptions.RemoteException('An error occurred.')&lt;/li&gt;\n&lt;/ul&gt;&lt;p&gt;RemoteException: An error occurred.&lt;br /&gt;\n&lt;/p&gt;\n</pre>\n</blockquote>\n<p>Try at also with a not so nice error:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; fatalJob = testing.FatalExceptionJob()\n&gt;&gt;&gt; rp.addJobFactory(u'fatal', fatalJob)\n</pre>\n</blockquote>\n<p>Now add and execute it:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; jobid4 = rp.addJob(u'fatal')\n&gt;&gt;&gt; transaction.commit()\n&gt;&gt;&gt; worker()\n</pre>\n<pre>&gt;&gt;&gt; sorted([job.status for job in rp._jobs.values()])\n[u'cancelled', u'completed', u'error', u'queued']\n</pre>\n<pre>&gt;&gt;&gt; job4 = rp._jobs[jobid4]\n&gt;&gt;&gt; job4.retryCounter\n1\n&gt;&gt;&gt; job4.status == u'queued'\nTrue\n</pre>\n<pre>&gt;&gt;&gt; job4.errors\n[&lt;JobError u'...'&gt;]\n</pre>\n</blockquote>\n<p>And process the job again but first set our retryTime to an outdated value which\nwill simulate that time passes since our last call:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; import datetime\n&gt;&gt;&gt; job4.retryTime = datetime.datetime(2000, 1, 1, tzinfo=UTC)\n&gt;&gt;&gt; transaction.commit()\n&gt;&gt;&gt; worker()\n</pre>\n<pre>&gt;&gt;&gt; sorted([job.status for job in rp._jobs.values()])\n[u'cancelled', u'completed', u'error', u'queued']\n</pre>\n<pre>&gt;&gt;&gt; job4 = rp._jobs[jobid4]\n&gt;&gt;&gt; job4.retryCounter\n2\n</pre>\n<pre>&gt;&gt;&gt; job4.errors\n[&lt;JobError u'...'&gt;,\n &lt;JobError u'...'&gt;]\n</pre>\n</blockquote>\n<p>And process the job again the 3rd time. Now it does not re-raise the exception\nbut the error message get appended to the error list.</p>\n<blockquote>\n<pre>&gt;&gt;&gt; job4.retryTime = datetime.datetime(2000, 1, 1, tzinfo=UTC)\n&gt;&gt;&gt; transaction.commit()\n&gt;&gt;&gt; worker()\n</pre>\n<pre>&gt;&gt;&gt; sorted([job.status for job in rp._jobs.values()])\n[u'cancelled', u'completed', u'error', u'error']\n</pre>\n</blockquote>\n<p>Let\u2019s now see what happened:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; job4 = rp._jobs[jobid4]\n&gt;&gt;&gt; job4.retryCounter\n3\n</pre>\n<pre>&gt;&gt;&gt; job4.status\nu'error'\n</pre>\n<pre>&gt;&gt;&gt; rp.getJobStatus(jobid4)\nu'error'\n</pre>\n<pre>&gt;&gt;&gt; job4.errors\n[&lt;JobError u'...'&gt;,\n &lt;JobError u'...'&gt;,\n &lt;JobError u'...'&gt;]\n</pre>\n<pre>&gt;&gt;&gt; rp.getJobErrors(jobid4)\n[&lt;JobError u'...'&gt;,\n &lt;JobError u'...'&gt;,\n &lt;JobError u'...'&gt;]\n</pre>\n</blockquote>\n<p>For management purposes, the remote processor also allows you to inspect all\njobs:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; pprint(dict(rp._jobs))\n{u'...': &lt;EchoJob u'...' ...&gt;,\n u'...': &lt;EchoJob u'...' ...&gt;,\n u'...': &lt;RemoteExceptionJob u'...' ...&gt;,\n u'...': &lt;FatalExceptionJob u'...' ...&gt;}\n</pre>\n</blockquote>\n<p>To get rid of jobs not needed anymore we can use the reomveJobs method.</p>\n<blockquote>\n<pre>&gt;&gt;&gt; jobid8 = rp.addJob(u'echo', {'blah': 'blah'})\n&gt;&gt;&gt; transaction.commit()\n</pre>\n<pre>&gt;&gt;&gt; sorted([job.status for job in rp._jobs.values()])\n[u'cancelled', u'completed', u'error', u'error', u'queued']\n</pre>\n<pre>&gt;&gt;&gt; rp.removeJobs()\n{u'cancelled': 1, u'completed': 1, u'error': 2}\n</pre>\n<pre>&gt;&gt;&gt; sorted([job.status for job in rp._jobs.values()])\n[u'queued']\n</pre>\n</blockquote>\n<p>Now process the last pending job and make sure we do not get more jobs:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; rp.pullNextJob()\n&lt;EchoJob u'...' ...&gt;\n</pre>\n</blockquote>\n</div>\n<div id=\"threading-behavior\">\n<h3>Threading behavior</h3>\n<p>Each remote processor runs in a separate thread, allowing them to operate\nindependently. Jobs should be designed to avoid conflict errors.</p>\n<p>Let\u2019s start the remote processor we have defined at this point, and see what\nthreads are running as a result:</p>\n<pre>&gt;&gt;&gt; rp.startProcessor()\n\n&gt;&gt;&gt; import pprint\n&gt;&gt;&gt; import threading\n\n&gt;&gt;&gt; def show_threads():\n...     threads = [t for t in threading.enumerate()\n...                if t.getName().startswith('root')]\n...     threads.sort(key=lambda t: t.getName())\n...     pprint.pprint(threads)\n\n&gt;&gt;&gt; show_threads()\n[&lt;Thread(root-worker, started daemon ...)&gt;]\n</pre>\n<p>Let\u2019s stop the remote processor, and give the background threads a chance to get\nthe message:</p>\n<pre>&gt;&gt;&gt; rp.stopProcessor()\n\n&gt;&gt;&gt; import time\n&gt;&gt;&gt; time.sleep(2)\n</pre>\n<p>The threads have exited now:</p>\n<pre>&gt;&gt;&gt; print [t for t in threading.enumerate()\n...        if t.getName().startswith('root')]\n[]\n</pre>\n</div>\n</div>\n<div id=\"job-workers\">\n<h2>Job Workers</h2>\n<p>The actual processing of the jobs in a queue is handled by a spearate\ncomponent, known as a job worker. This component usually runs in its own\nthread and provides its own main loop.</p>\n<blockquote>\n<pre>&gt;&gt;&gt; import time\n&gt;&gt;&gt; import transaction\n</pre>\n</blockquote>\n<p>The <tt>worker</tt> module provides a job worker which executes one job at a\ntime. Another worker is scheduling new jobs items beased on scheduler item\nsettings. Let\u2019s create the necessary components to test the job worker:</p>\n<ol>\n<li>Create the remote processor:</li>\n</ol>\n<blockquote>\n<pre>&gt;&gt;&gt; from m01.remote import testing\n&gt;&gt;&gt; rp = root\n&gt;&gt;&gt; rp.isProcessing\nFalse\n</pre>\n<pre>&gt;&gt;&gt; rp.isScheduling\nFalse\n</pre>\n</blockquote>\n<ol>\n<li>Register a job that simply sleeps and writes a message:</li>\n</ol>\n<blockquote>\n<pre>&gt;&gt;&gt; data = {'retryDelay': 1}\n&gt;&gt;&gt; sleepJob = testing.SleepJob(data)\n&gt;&gt;&gt; rp.addJobFactory(u'sleep', sleepJob)\n</pre>\n</blockquote>\n<div id=\"simplejobworker\">\n<h3>SimpleJobWorker</h3>\n<p>This worker executes one job at a time. It was designed for jobs that would\ntake a long time and use up most of the processing power of a computer.</p>\n<p>Let\u2019s first register a few jobs:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; jobid1 = rp.addJob(u'sleep', (0.04, 1))\n&gt;&gt;&gt; time.sleep(0.2)\n&gt;&gt;&gt; jobid2 = rp.addJob(u'sleep', (0.1,  2))\n&gt;&gt;&gt; time.sleep(0.2)\n&gt;&gt;&gt; jobid3 = rp.addJob(u'sleep', (0,    3))\n&gt;&gt;&gt; time.sleep(0.2)\n&gt;&gt;&gt; jobid4 = rp.addJob(u'sleep', (0.08, 4))\n&gt;&gt;&gt; time.sleep(0.2)\n&gt;&gt;&gt; transaction.commit()\n</pre>\n</blockquote>\n<p>Now let\u2019s first check if we can aceess the jobs:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; job = rp._jobs.get(jobid1)\n&gt;&gt;&gt; job\n&lt;SleepJob u'...' ...&gt;\n</pre>\n</blockquote>\n<p>And let\u2019s try if the job is ready for processing:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; rp.getJobStatus(jobid1)\nu'queued'\n</pre>\n<pre>&gt;&gt;&gt; rp.getJobStatus(jobid2)\nu'queued'\n</pre>\n<pre>&gt;&gt;&gt; rp.getJobStatus(jobid3)\nu'queued'\n</pre>\n<pre>&gt;&gt;&gt; rp.getJobStatus(jobid4)\nu'queued'\n</pre>\n</blockquote>\n<p>Let\u2019s start by executing a job directly. The first argument to the simple\nworker constructor is the remote processor instance. All other arguments are\noptional and can be defined as worker rguments in the RemoteProcessor class,\nsee jobWorkerArguments and schedulerWorkerArguments:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; from m01.remote.worker import SimpleJobWorker\n&gt;&gt;&gt; worker = SimpleJobWorker(rp, waitTime=0.0)\n</pre>\n</blockquote>\n<p>Let\u2019s now process the first job. We clear the log and we also have to end any\nexisting interactions in order to process the job in this thread:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; logger.clear()\n</pre>\n<pre>&gt;&gt;&gt; from zope.security import management\n&gt;&gt;&gt; management.endInteraction()\n</pre>\n<pre>&gt;&gt;&gt; worker.doProcessNextJob()\nTrue\n</pre>\n<pre>&gt;&gt;&gt; print logger\nm01.remote INFO\n  Job: 1\n</pre>\n</blockquote>\n<p>Let\u2019s now use the worker from within the remote processor. Since the worker\nconstructors also accept additional arguments, they are specified as well:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; rp.jobWorkerFactory = SimpleJobWorker\n&gt;&gt;&gt; rp.jobWorkerFactory\n&lt;class 'm01.remote.worker.SimpleJobWorker'&gt;\n</pre>\n<pre>&gt;&gt;&gt; rp.jobWorkerArguments\n{'waitTime': 0.0}\n</pre>\n</blockquote>\n<p>The wait time has been set to zero for testing purposes only. It is really set\nto 1 second by default. Let\u2019s now start processing jobs, wait a little bit\nfor all the jobs to complete and then stop processing again:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; rp.startProcessor()\n&gt;&gt;&gt; transaction.commit()\n</pre>\n<pre>&gt;&gt;&gt; time.sleep(0.5)\n</pre>\n<pre>&gt;&gt;&gt; rp.stopProcessor()\n&gt;&gt;&gt; transaction.commit()\n</pre>\n<pre>&gt;&gt;&gt; time.sleep(0.5)\n</pre>\n</blockquote>\n<p>The log shows that all jobs have been processed. But more importantly, they\nwere all completed in the order they were defined. Note the first job get\nprocessed before we started the remote processor. And yes this means a remote\nprocessor can process jobs if the queue is not started. Starting a remote\nprocessor only means that the job get processed as jobs without to do it\nmanualy.</p>\n<blockquote>\n<pre>&gt;&gt;&gt; print logger\nm01.remote INFO\n  Job: 1\nm01.remote INFO\n  Processor 'root-worker' started\nm01.remote INFO\n  Job: 2\nm01.remote INFO\n  Job: 3\nm01.remote INFO\n  Job: 4\nm01.remote INFO\n  Processor 'root-worker' stopped\n</pre>\n<pre>&gt;&gt;&gt; logger.clear()\n</pre>\n</blockquote>\n</div>\n<div id=\"transactions-in-jobs\">\n<h3>Transactions in jobs</h3>\n<p>With the SimpleJobWorker, jobs _should_ not change the transaction status, since\nboth the administration of the jobs by the RemoteProcessor and the job itself\nrun in the same transaction, so aborting it from inside the job could mess up\nthe administrative part.</p>\n<p>This is a regression test that aborting the transaction inside the job does not\nlead to an infinite loop (because SimpleJobWorker pulls the job inside the\ntransaction, so if it is aborted, the job remains on the queue):</p>\n<blockquote>\n<pre>&gt;&gt;&gt; testing.testCounter\n0\n</pre>\n<pre>&gt;&gt;&gt; counter = 0\n&gt;&gt;&gt; data = {'counter': counter}\n&gt;&gt;&gt; abortJob = testing.TransactionAbortJob(data)\n&gt;&gt;&gt; rp.addJobFactory(u'abortJob', abortJob)\n&gt;&gt;&gt; jobid = rp.addJob(u'abortJob', (1))\n&gt;&gt;&gt; time.sleep(0.5)\n&gt;&gt;&gt; jobid = rp.addJob(u'abortJob', (2))\n&gt;&gt;&gt; transaction.commit()\n</pre>\n<pre>&gt;&gt;&gt; rp.startProcessor()\n&gt;&gt;&gt; transaction.commit()\n&gt;&gt;&gt; time.sleep(0.5)\n</pre>\n<pre>&gt;&gt;&gt; rp.stopProcessor()\n&gt;&gt;&gt; transaction.commit()\n&gt;&gt;&gt; time.sleep(0.5)\n</pre>\n<pre>&gt;&gt;&gt; transaction.abort() # prevent spurious conflict errors\n&gt;&gt;&gt; testing.testCounter\n2\n</pre>\n<pre>&gt;&gt;&gt; print logger\nm01.remote INFO\n  Processor 'root-worker' started\nm01.remote INFO\n  Job: 1\nm01.remote INFO\n  Job: 2\nm01.remote INFO\n  Processor 'root-worker' stopped\n</pre>\n</blockquote>\n<p>Reset test counter</p>\n<blockquote>\n<pre>&gt;&gt;&gt; testing.testCounter = 0\n</pre>\n</blockquote>\n</div>\n<div id=\"multijobprocessor\">\n<h3>MultiJobProcessor</h3>\n<p>The multi-threaded job worker executes several jobs at once. It was designed\nfor jobs that would take a long time but use very little processing power.</p>\n<p>Let\u2019s add a few new jobs to execute:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; jobid1 = rp.addJob(u'sleep', (0.04, 1))\n&gt;&gt;&gt; time.sleep(0.2)\n&gt;&gt;&gt; jobid2 = rp.addJob(u'sleep', (1.0,  2))\n&gt;&gt;&gt; time.sleep(0.2)\n&gt;&gt;&gt; jobid3 = rp.addJob(u'sleep', (0,    3))\n&gt;&gt;&gt; time.sleep(0.2)\n&gt;&gt;&gt; jobid4 = rp.addJob(u'sleep', (0.2,  4))\n&gt;&gt;&gt; time.sleep(0.2)\n&gt;&gt;&gt; transaction.commit()\n</pre>\n</blockquote>\n<p>Before testing the worker in the remote processor, let\u2019s have a look at every\nmethod by itself. So we instantiate the worker:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; from m01.remote.worker import MultiJobWorker\n&gt;&gt;&gt; worker = MultiJobWorker(rp, waitTime=0, maxThreads=2)\n</pre>\n</blockquote>\n<p>The maximum amount of threads can be set as well:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; worker.maxThreads\n2\n</pre>\n</blockquote>\n<p>All working threads can be reviewed at any time:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; worker.threads\n[]\n</pre>\n<pre>&gt;&gt;&gt; from zope.security import management\n&gt;&gt;&gt; management.endInteraction()\n</pre>\n</blockquote>\n<p>Let\u2019s pull a new job:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; job = worker.doPullNextJob()\n&gt;&gt;&gt; job\n&lt;SleepJob u'...' ...&gt;\n</pre>\n</blockquote>\n<p>We need to pull a job before executing it, so that the database marks the job\nas processing and no new thread picks up the same job. As you can see the job\nget marked with the processing status:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; job.status\nu'processing'\n</pre>\n</blockquote>\n<p>Once we pulled a particular job, we can process it:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; logger.clear()\n&gt;&gt;&gt; print logger\n</pre>\n<pre>&gt;&gt;&gt; worker.doProcessJob(job.__name__)\n</pre>\n<pre>&gt;&gt;&gt; print logger\nm01.remote INFO\n  Job: 1\n</pre>\n</blockquote>\n<p>Let\u2019s now have a look at using the processor in the task service. This\nprimarily means setting the processor factory:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; management.newInteraction()\n</pre>\n<pre>&gt;&gt;&gt; rp.jobWorkerFactory = MultiJobWorker\n&gt;&gt;&gt; rp.jobWorkerArguments = {'waitTime': 1.0, 'maxThreads': 2}\n&gt;&gt;&gt; transaction.commit()\n</pre>\n<pre>&gt;&gt;&gt; logger.clear()\n</pre>\n</blockquote>\n<p>Let\u2019s now process the remaining jobs:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; rp.startProcessor()\n&gt;&gt;&gt; transaction.commit()\n&gt;&gt;&gt; time.sleep(1.5)\n</pre>\n<pre>&gt;&gt;&gt; rp.stopProcessor()\n&gt;&gt;&gt; transaction.commit()\n&gt;&gt;&gt; time.sleep(0.5)\n</pre>\n</blockquote>\n<p>As you can see, this time the jobs are not completed in order anymore, because\nthey all need different time to execute:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; print logger\nm01.remote INFO\n  Processor 'root-worker' started\nm01.remote INFO\n  MultiJobWorker: processing job ...\nm01.remote INFO\n  MultiJobWorker: processing job ...\nm01.remote INFO\n  Job: 3\nm01.remote INFO\n  MultiJobWorker: processing job ...\nm01.remote INFO\n  Job: 4\nm01.remote INFO\n  Job: 2\nm01.remote INFO\n  Processor 'root-worker' stopped\n</pre>\n</blockquote>\n<p>Let\u2019s now set the thread limit to four and construct a new set of jobs that\ndemonstrate that all jobs will run at the same time:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; rp.jobWorkerArguments = {'waitTime': 0.0, 'maxThreads': 4}\n</pre>\n<pre>&gt;&gt;&gt; jobid1 = rp.addJob(u'sleep', (0.3, 1))\n&gt;&gt;&gt; time.sleep(0.2)\n&gt;&gt;&gt; jobid2 = rp.addJob(u'sleep', (0.4, 2))\n&gt;&gt;&gt; time.sleep(0.2)\n&gt;&gt;&gt; jobid3 = rp.addJob(u'sleep', (0.1, 3))\n&gt;&gt;&gt; time.sleep(0.2)\n&gt;&gt;&gt; jobid4 = rp.addJob(u'sleep', (0.5, 4))\n&gt;&gt;&gt; time.sleep(0.2)\n&gt;&gt;&gt; transaction.commit()\n</pre>\n</blockquote>\n<p>If all tasks are processed at once, job 3 should be done first. You can also\nsee that the job 4 get processed ASAP even before the worker logs processing:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; logger.clear()\n</pre>\n<pre>&gt;&gt;&gt; rp.startProcessor()\n&gt;&gt;&gt; transaction.commit()\n</pre>\n<pre>&gt;&gt;&gt; time.sleep(1.0)\n</pre>\n<pre>&gt;&gt;&gt; rp.stopProcessor()\n&gt;&gt;&gt; transaction.commit()\n&gt;&gt;&gt; time.sleep(0.5)\n</pre>\n<pre>&gt;&gt;&gt; print logger\nm01.remote INFO\n  Processor 'root-worker' started\nm01.remote INFO\n  MultiJobWorker: processing job ...\nm01.remote INFO\n  MultiJobWorker: processing job ...\nm01.remote INFO\n  MultiJobWorker: processing job ...\nm01.remote INFO\n  MultiJobWorker: processing job ...\nm01.remote INFO\n  Job: 3\nm01.remote INFO\n  Job: 1\nm01.remote INFO\n  Job: 2\nm01.remote INFO\n  Job: 4\nm01.remote INFO\n  Processor 'root-worker' stopped\n</pre>\n</blockquote>\n<p>Let\u2019s now set the thread limit to two and construct a new set of jobs that\ndemonstrate that not more than two threads run at the same time:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; rp.jobWorkerArguments = {'waitTime': 0.0, 'maxThreads': 2}\n&gt;&gt;&gt; transaction.commit()\n</pre>\n<pre>&gt;&gt;&gt; jobid1 = rp.addJob(u'sleep', (0.3, 1))\n&gt;&gt;&gt; time.sleep(0.2)\n&gt;&gt;&gt; jobid2 = rp.addJob(u'sleep', (0.4, 2))\n&gt;&gt;&gt; time.sleep(0.2)\n&gt;&gt;&gt; jobid3 = rp.addJob(u'sleep', (0.2, 3))\n&gt;&gt;&gt; time.sleep(0.2)\n&gt;&gt;&gt; jobid4 = rp.addJob(u'sleep', (0.5, 4))\n&gt;&gt;&gt; time.sleep(0.2)\n&gt;&gt;&gt; transaction.commit()\n</pre>\n</blockquote>\n<p>If all tasks are processed at once, job 3 should be done first, but since the\njob has to wait for an available thread, it will come in third. We can now run\nthe jobs and see the result:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; logger.clear()\n</pre>\n<pre>&gt;&gt;&gt; rp.startProcessor()\n&gt;&gt;&gt; transaction.commit()\n</pre>\n<pre>&gt;&gt;&gt; time.sleep(1.5)\n</pre>\n<pre>&gt;&gt;&gt; rp.stopProcessor()\n&gt;&gt;&gt; transaction.commit()\n&gt;&gt;&gt; time.sleep(0.5)\n</pre>\n<pre>&gt;&gt;&gt; print logger\nm01.remote INFO\n  Processor 'root-worker' started\nm01.remote INFO\n  MultiJobWorker: processing job ...\nm01.remote INFO\n  MultiJobWorker: processing job ...\nm01.remote INFO\n  Job: 1\nm01.remote INFO\n  MultiJobWorker: processing job ...\nm01.remote INFO\n  Job: 2\nm01.remote INFO\n  MultiJobWorker: processing job ...\nm01.remote INFO\n  Job: 3\nm01.remote INFO\n  Job: 4\nm01.remote INFO\n  Processor 'root-worker' stopped\n</pre>\n</blockquote>\n</div>\n</div>\n<div id=\"scheduler\">\n<h2>Scheduler</h2>\n<p>The scheduler concept is implemented as an additional scheduler container which\ncontains scheduler items.</p>\n<blockquote>\n<pre>&gt;&gt;&gt; from m01.mongo import UTC\n&gt;&gt;&gt; import m01.remote.scheduler\n&gt;&gt;&gt; from m01.remote import interfaces\n&gt;&gt;&gt; from m01.remote import testing\n</pre>\n</blockquote>\n<p>Let\u2019s now start by get our test remote procesor which contains our scheduler\ncontainer:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; remoteProcessor = root\n&gt;&gt;&gt; remoteProcessor\n&lt;TestProcessor None&gt;\n</pre>\n<pre>&gt;&gt;&gt; scheduler = remoteProcessor._scheduler\n</pre>\n<pre>&gt;&gt;&gt; tuple(scheduler.values())\n()\n</pre>\n</blockquote>\n<div id=\"delay\">\n<h3>Delay</h3>\n<p>We can add a scheduler item for delay a job processing. Let\u2019s add such an item:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; import datetime\n&gt;&gt;&gt; def getNextTime(dt, seconds):\n...     return dt + datetime.timedelta(seconds=seconds)\n</pre>\n<pre>&gt;&gt;&gt; now = datetime.datetime(2010, 10, 1, 0, 0, 0, tzinfo=UTC)\n&gt;&gt;&gt; now10 = getNextTime(now, 10)\n&gt;&gt;&gt; delay = 10\n&gt;&gt;&gt; data = {'jobName': u'echo 1', 'active': True, 'delay': delay,\n...         'retryDelay': 5, 'nextCallTime': now10}\n&gt;&gt;&gt; firstEcho = m01.remote.scheduler.Delay(data)\n&gt;&gt;&gt; interfaces.IDelay.providedBy(firstEcho)\nTrue\n</pre>\n</blockquote>\n<p>The delay is set to 10:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; firstEcho.delay\n10\n</pre>\n</blockquote>\n<p>and the retryDelay to 5</p>\n<blockquote>\n<pre>&gt;&gt;&gt; firstEcho.retryDelay\n5\n</pre>\n</blockquote>\n<p>and we set an explicit nextCallTime of now + 10:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; firstEcho.nextCallTime == getNextTime(now, 10)\nTrue\n</pre>\n</blockquote>\n<p>and our retryTime is None:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; firstEcho.retryTime is None\nTrue\n</pre>\n</blockquote>\n<p>Now we can add the delay item to the scheduler:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; scheduler.add(firstEcho)\nu'...'\n</pre>\n</blockquote>\n<p>As you can see the scheduler contains on item:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; sorted(scheduler.values())\n[&lt;Delay ... for: u'echo 1'&gt;]\n</pre>\n</blockquote>\n<p>As next we\u2019ll test some scheduler AP methods. First check if we can update\nthe retryTime for an item in our adding cache with <tt>updateRetryTime</tt>:</p>\n<pre>&gt;&gt;&gt; scheduler.updateRetryTime(firstEcho.dump(), now)\nFalse\n</pre>\n<p>As you can see we did not get a new retryTime. This happens because we didn\u2019t\nuse the correct callTime. Let\u2019s try with the correct nextCallTime:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; now10 = getNextTime(now, 10)\n&gt;&gt;&gt; now15 = getNextTime(now, 15)\n&gt;&gt;&gt; retryTime = scheduler.updateRetryTime(firstEcho.dump(), now10)\n&gt;&gt;&gt; retryTime == now15\nTrue\n</pre>\n</blockquote>\n<p>As you can see the new retryTime is using the retryDelay of 5 second. This\nretryTime is used for lock an item. This means an item get not picked as long\nas this time get passed.</p>\n<p>Now let\u2019 try another internal API method hihc is able to get the next item\nfrom our adding cache:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; scheduler.getNextCachedItem(now)\n</pre>\n</blockquote>\n<p>As you can see the method didn\u2019t return an item, let\u2019s try with the next\nscheduled call time:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; nextCallTime = firstEcho.nextCallTime\n&gt;&gt;&gt; scheduler.getNextCachedItem(now10)\n&lt;Delay ... for: u'echo 1'&gt;\n</pre>\n</blockquote>\n<p>As you can see the retryTime get set based on the nextCallTime and the\nretryDelay:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; firstEcho.retryTime == getNextTime(nextCallTime, 5)\nTrue\n</pre>\n</blockquote>\n<p>Now the important part. Let\u2019s test our method which is responsible for get\na next item including items from mongo. This method uses the two methods above.\nOf corse with the current time we will not get any item:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; scheduler.pullNextSchedulerItem(now) is None\nTrue\n</pre>\n</blockquote>\n<p>But now we need another nextCallTime because the previous call update the\nitems nextCallTime. Let\u2019s first check the nextCallTime:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; firstEcho.nextCallTime == now10\nTrue\n</pre>\n</blockquote>\n<p>But as you can see, the retryTime is already set during our previous test. this\nmeans we only will get an item if we at least use a larger time if the\nretryTime:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; firstEcho.retryTime == now15\nTrue\n</pre>\n<pre>&gt;&gt;&gt; scheduler.pullNextSchedulerItem(now10)\n</pre>\n<pre>&gt;&gt;&gt; scheduler.pullNextSchedulerItem(now15)\n&lt;Delay ... for: u'echo 1'&gt;\n</pre>\n</blockquote>\n<p>Now, let\u2019s check our scheduled item times:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; now20 = getNextTime(now15, 5)\n&gt;&gt;&gt; firstEcho.nextCallTime == now10\nTrue\n</pre>\n</blockquote>\n<p>Note, our retryTime get calculated with the current call time and retryDelay.\nIt whould not make sense if we whould use the callTime as retryTime calculation\nbase:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; firstEcho.retryTime == now20\nTrue\n</pre>\n</blockquote>\n<p>The method pullNextSchedulerItem returns a pending item or None since we don\u2019t\nhave one pending:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; scheduler.pullNextSchedulerItem(now) is None\nTrue\n</pre>\n</blockquote>\n<p>Now let\u2019s add a second scheduler item within some scheduler time:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; import datetime\n&gt;&gt;&gt; delay = 10\n&gt;&gt;&gt; data = {'jobName': u'echo 2', 'active': True, 'delay': delay,\n...         'retryDelay': 5}\n&gt;&gt;&gt; secondEcho = m01.remote.scheduler.Delay(data)\n</pre>\n<pre>&gt;&gt;&gt; scheduler.add(secondEcho)\nu'...'\n</pre>\n<pre>&gt;&gt;&gt; sorted(scheduler.values(), key=lambda x:(x.__name__, x.__name__))\n[&lt;Delay ... for: u'echo 1'&gt;, &lt;Delay ... for: u'echo 2'&gt;]\n</pre>\n<pre>&gt;&gt;&gt; scheduler.remove(firstEcho)\n&gt;&gt;&gt; scheduler.remove(secondEcho)\n&gt;&gt;&gt; tuple(scheduler.values())\n()\n</pre>\n</blockquote>\n</div>\n<div id=\"adjustcalltime\">\n<h3>adjustCallTime</h3>\n<p>Before we test our cron item, let\u2019s test test our method which can reset a\ngiven datetime to the smalles starting point e.g. if hours are given as a\ncalculation base, we need to start counting within the first minute:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; from m01.remote.scheduler import adjustCallTime\n</pre>\n<pre>&gt;&gt;&gt; now = datetime.datetime(2010, 10, 25, 16, 6, 5, 123, tzinfo=UTC)\n&gt;&gt;&gt; now\ndatetime.datetime(2010, 10, 25, 16, 6, 5, 123, tzinfo=UTC)\n</pre>\n<pre>&gt;&gt;&gt; item = m01.remote.scheduler.Cron({'jobName': u'bar', 'minute': [5]})\n&gt;&gt;&gt; adjustCallTime(item, now)\ndatetime.datetime(2010, 10, 25, 16, 6, 0, 123, tzinfo=UTC)\n</pre>\n</blockquote>\n</div>\n<div id=\"cron\">\n<h3>Cron</h3>\n<p>A probably more interesting implementation is the cron scheduler item. This\ncron item can schedule jobs at a specific given time. Let\u2019s setup such a cron\nitem:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; data = {'jobName': u'bar', 'active': True, 'retryDelay': 5}\n&gt;&gt;&gt; cronItem = m01.remote.scheduler.Cron(data)\n</pre>\n</blockquote>\n<p>The cronItem provides the ISchedulerItem and ICron interface:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; interfaces.ISchedulerItem.providedBy(cronItem)\nTrue\n</pre>\n<pre>&gt;&gt;&gt; interfaces.ICron.providedBy(cronItem)\nTrue\n</pre>\n</blockquote>\n<p>As you can see the cron item also provides a retryDelay:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; cronItem.retryDelay\n5\n</pre>\n</blockquote>\n<p>Let\u2019s first explain how this works. The cron scheduler provides a next call\ntime stamp. If the calculated next call time is smaller then the last call time,\nthe cron scheduler item will calculate the new next call time and store them\nas nextCallTime and at the same time the previous nextCallTime get returnd.\nThis will makes sure that we have a minimum of time calculation calls because\neach time a cron scheduler item get asked about the next call time the stored\nnextCallTime is used. The cron schdeuler item only calculates the next call\ntime if the existing next call time is smaller then the given call time.</p>\n<p>Now let\u2019s test a cron as a scheduler item. Setup a simple corn item with a\n5 minute period.</p>\n<blockquote>\n<pre>&gt;&gt;&gt; now = datetime.datetime(2010, 10, 1, 0, 0, 0, tzinfo=UTC)\n&gt;&gt;&gt; now\ndatetime.datetime(2010, 10, 1, 0, 0, tzinfo=UTC)\n</pre>\n<pre>&gt;&gt;&gt; data = {'jobName': u'echo cron', 'active': True, 'retryDelay': 5,\n...         'minute': [5], 'nextCallTime': now}\n&gt;&gt;&gt; cronEcho = m01.remote.scheduler.Cron(data)\n</pre>\n</blockquote>\n<p>Now add the item to the schdeuler:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; scheduler.add(cronEcho)\nu'...'\n</pre>\n</blockquote>\n<p>As you can see, our cron item get scheduled based on the given nextCallTime:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; cronEcho.nextCallTime\ndatetime.datetime(2010, 10, 1, 0, 0, tzinfo=UTC)\n</pre>\n</blockquote>\n<p>the retrytime is empty</p>\n<blockquote>\n<pre>&gt;&gt;&gt; cronEcho.retryTime is None\nTrue\n</pre>\n</blockquote>\n<p>and the minute list contains our 5 minute:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; cronEcho.minute\n[5]\n</pre>\n<pre>&gt;&gt;&gt; cronEcho.hour\n[]\n</pre>\n<pre>&gt;&gt;&gt; cronEcho.dayOfMonth\n[]\n</pre>\n<pre>&gt;&gt;&gt; cronEcho.month\n[]\n</pre>\n<pre>&gt;&gt;&gt; cronEcho.dayOfWeek\n[]\n</pre>\n</blockquote>\n<p>And the scheduler contains one cron item:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; tuple(scheduler.values())\n(&lt;Cron ... for: u'echo cron'&gt;,)\n</pre>\n</blockquote>\n<p>Now we can get the job based on the jobName <tt>echo</tt> defined by our cron\nscheduler item if we call pullNextSchedulerItem.</p>\n<blockquote>\n<pre>&gt;&gt;&gt; scheduler.pullNextSchedulerItem(now)\n&lt;Cron ... for: u'echo cron'&gt;\n</pre>\n</blockquote>\n<p>During this call the retryTime get set based on the retryDelay:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; cronEcho.retryTime\ndatetime.datetime(2010, 10, 1, 0, 0, 5, tzinfo=UTC)\n</pre>\n</blockquote>\n<p>Now let\u2019s test the the different cron settings. Note that we provide a list of\nvalues for minutes, hours, month, dayOfWeek and dayOfMonth. This means you can\nschedule a job for every 15 minutes if you will set the minutes to\n(0, 15, 30, 45) or if you like to set a job only each 15 minutes after an hour\nyou can set minutes to (15,). If you will set more then one argument e.g.\nminute, hours or days etc. all arguments must fit the given time.</p>\n<p>Let\u2019s start with a cron scheduler for every first and second minute per hour.\nNormaly the corn scheduler item will set now <tt><span class=\"pre\">int(time.time())</span></tt> as\nnextCallTime value. For test our cron scheduler items, we use a explicit\nstartTime value of 0 (zero):</p>\n<blockquote>\n<pre>&gt;&gt;&gt; data = {'jobName': u'bar', 'active': True, 'retryDelay': 5,\n...         'minute': [0, 1]}\n&gt;&gt;&gt; cronItem = m01.remote.scheduler.Cron(data)\n</pre>\n</blockquote>\n<p>The next call time is set based on the given startTime value. This means the\nfirst call will be at 0 (zero) minute:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; cronItem.nextCallTime is None\nTrue\n</pre>\n</blockquote>\n<p>Now let\u2019s call getNextCallTime, as you can see we will get None as nextCallTime\nbecause we ddn\u2019t set a nextCallTime during cron initialization and the\nnextCallTime is set to the next minute:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; cronItem.getNextCallTime(now) is None\nTrue\n</pre>\n<pre>&gt;&gt;&gt; cronItem.nextCallTime\ndatetime.datetime(2010, 10, 1, 0, 1, tzinfo=UTC)\n</pre>\n</blockquote>\n<p>Now let\u2019s call getNextCallTime again, as you can see we will get the\nnextCallTime we calculated during object initialization which is the given\ncall time and the nextCallTime is set to the next minute:</p>\n<p>If we use a call time + 5 seconds, we still will get the cached next call\ntime of 1 minute and we will not generate a new next call time since this\ntime is already in the future:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; cronItem.getNextCallTime(getNextTime(now, 5))\ndatetime.datetime(2010, 10, 1, 0, 1, tzinfo=UTC)\n</pre>\n<pre>&gt;&gt;&gt; cronItem.nextCallTime\ndatetime.datetime(2010, 10, 1, 0, 1, tzinfo=UTC)\n</pre>\n</blockquote>\n<p>If we call the cron scheduler item with a call time equal or larger then our\n1 minute delay from the cached next call time, we will get the cached call time\nas value as we whould get similar to a smaller call time (see sample above).</p>\n<blockquote>\n<pre>&gt;&gt;&gt; cronItem.getNextCallTime(getNextTime(now, 65))\ndatetime.datetime(2010, 10, 1, 0, 1, tzinfo=UTC)\n</pre>\n<pre>&gt;&gt;&gt; cronItem.nextCallTime\ndatetime.datetime(2010, 10, 1, 1, 0, tzinfo=UTC)\n</pre>\n</blockquote>\n<p>All future calls with a smaller time then the nextCallTime will return the\ncurrent nextCallTime and not calculate any new time.</p>\n<blockquote>\n<pre>&gt;&gt;&gt; cronItem.getNextCallTime(getNextTime(now, 125))\ndatetime.datetime(2010, 10, 1, 1, 0, tzinfo=UTC)\n</pre>\n<pre>&gt;&gt;&gt; cronItem.getNextCallTime(getNextTime(now, 1*60*60))\ndatetime.datetime(2010, 10, 1, 1, 0, tzinfo=UTC)\n</pre>\n</blockquote>\n<p>Remember, getNextCallTime returns the previous calculated nextCallTime and the\nnew calculated nextCallTime get stored as nextCallTime. For a simpler test\noutput we define a test method which shows the time calculation:</p>\n<div id=\"minutes\">\n<h4>Minutes</h4>\n<p>Let\u2019s start testing the time tables.</p>\n<blockquote>\n<pre>&gt;&gt;&gt; def getNextCallTime(cron, dt, seconds=None):\n...     \"\"\"Return stored and new calculated nextCallTime\"\"\"\n...     if seconds is None:\n...         callTime = dt\n...     else:\n...         callTime = getNextTime(dt, seconds)\n...     nextCallTime = cron.getNextCallTime(callTime)\n...     return '%s --&gt; %s' % (nextCallTime, cron.nextCallTime)\n</pre>\n<pre>&gt;&gt;&gt; now = datetime.datetime(1970, 1, 1, 0, 3, 0, tzinfo=UTC)\n&gt;&gt;&gt; data = {'jobName': u'bar', 'active': True, 'retryDelay': 5,\n...         'minute': [0, 10], 'nextCallTime':now}\n&gt;&gt;&gt; item = m01.remote.scheduler.Cron(data)\n</pre>\n<pre>&gt;&gt;&gt; str(now)\n'1970-01-01 00:03:00+00:00'\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now)\n'1970-01-01 00:03:00+00:00 --&gt; 1970-01-01 00:10:00+00:00'\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 1)\n'1970-01-01 00:10:00+00:00 --&gt; 1970-01-01 00:10:00+00:00'\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 2*60)\n'1970-01-01 00:10:00+00:00 --&gt; 1970-01-01 00:10:00+00:00'\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 51*60)\n'1970-01-01 00:10:00+00:00 --&gt; 1970-01-01 01:00:00+00:00'\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 55*60)\n'1970-01-01 01:00:00+00:00 --&gt; 1970-01-01 01:00:00+00:00'\n</pre>\n</blockquote>\n</div>\n<div id=\"hour\">\n<h4>Hour</h4>\n<blockquote>\n<pre>&gt;&gt;&gt; data = {'jobName': u'bar', 'active': True, 'retryDelay': 5,\n...         'hour': [2, 13], 'nextCallTime':now}\n&gt;&gt;&gt; item = m01.remote.scheduler.Cron(data)\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now)\n'1970-01-01 00:03:00+00:00 --&gt; 1970-01-01 02:00:00+00:00'\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 2*60*60)\n'1970-01-01 02:00:00+00:00 --&gt; 1970-01-01 13:00:00+00:00'\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 4*60*60)\n'1970-01-01 13:00:00+00:00 --&gt; 1970-01-01 13:00:00+00:00'\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 13*60*60)\n'1970-01-01 13:00:00+00:00 --&gt; 1970-01-02 02:00:00+00:00'\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 15*60*60)\n'1970-01-02 02:00:00+00:00 --&gt; 1970-01-02 02:00:00+00:00'\n</pre>\n</blockquote>\n</div>\n<div id=\"month\">\n<h4>Month</h4>\n<blockquote>\n<pre>&gt;&gt;&gt; data = {'jobName': u'bar', 'active': True, 'retryDelay': 5,\n...         'month': [1, 2, 5, 12], 'nextCallTime':now}\n&gt;&gt;&gt; item = m01.remote.scheduler.Cron(data)\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now)\n'1970-01-01 00:03:00+00:00 --&gt; 1970-02-01 00:03:00+00:00'\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 90*24*60*60)\n'1970-02-01 00:03:00+00:00 --&gt; 1970-05-01 00:03:00+00:00'\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 120*24*60*60)\n'1970-05-01 00:03:00+00:00 --&gt; 1970-12-01 00:03:00+00:00'\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 130*24*60*60)\n'1970-12-01 00:03:00+00:00 --&gt; 1970-12-01 00:03:00+00:00'\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 360*24*60*60)\n'1970-12-01 00:03:00+00:00 --&gt; 1971-01-01 00:03:00+00:00'\n</pre>\n</blockquote>\n</div>\n<div id=\"dayofweek-0-6\">\n<h4>dayOfWeek [0..6]</h4>\n<blockquote>\n<pre>&gt;&gt;&gt; data = {'jobName': u'bar', 'active': True, 'retryDelay': 5,\n...         'dayOfWeek': [0, 2, 4, 5], 'nextCallTime':now}\n&gt;&gt;&gt; item = m01.remote.scheduler.Cron(data)\n</pre>\n</blockquote>\n<p>The current weekday of now is:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; now.weekday()\n3\n</pre>\n</blockquote>\n<p>this means our nextCallTime should get changed using day 4 as our\nnextCallTime if we call them with <tt>now</tt>:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now)\n'1970-01-01 00:03:00+00:00 --&gt; 1970-01-02 00:03:00+00:00'\n</pre>\n</blockquote>\n<p>with a day more, we will get the weekday 4 (skip):</p>\n<blockquote>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 24*60*60)\n'1970-01-02 00:03:00+00:00 --&gt; 1970-01-03 00:03:00+00:00'\n</pre>\n</blockquote>\n<p>with another day more, we will get the weekday 5 (incr):</p>\n<blockquote>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 2*24*60*60)\n'1970-01-03 00:03:00+00:00 --&gt; 1970-01-05 00:03:00+00:00'\n</pre>\n</blockquote>\n<p>with another day more, we will get the weekday 6 (skip):</p>\n<blockquote>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 3*24*60*60)\n'1970-01-05 00:03:00+00:00 --&gt; 1970-01-05 00:03:00+00:00'\n</pre>\n</blockquote>\n<p>with another day more, we will get the weekday 0 (inc):</p>\n<blockquote>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 4*24*60*60)\n'1970-01-05 00:03:00+00:00 --&gt; 1970-01-07 00:03:00+00:00'\n</pre>\n</blockquote>\n</div>\n<div id=\"dayofmonth-1-31\">\n<h4>dayOfMonth [1..31]</h4>\n<blockquote>\n<pre>&gt;&gt;&gt; data = {'jobName': u'bar', 'active': True, 'retryDelay': 5,\n...         'dayOfMonth': [2, 12, 21, 30], 'nextCallTime': now}\n&gt;&gt;&gt; item = m01.remote.scheduler.Cron(data)\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now)\n'1970-01-01 00:03:00+00:00 --&gt; 1970-01-02 00:00:00+00:00'\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 12*24*60*60)\n'1970-01-02 00:00:00+00:00 --&gt; 1970-01-21 00:00:00+00:00'\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 31*24*60*60)\n'1970-01-21 00:00:00+00:00 --&gt; 1970-02-02 00:00:00+00:00'\n</pre>\n</blockquote>\n</div>\n<div id=\"combined\">\n<h4>Combined</h4>\n<p>combine some attributes:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; data = {'jobName': u'bar', 'active': True, 'retryDelay': 5,\n...         'minute': [10], 'dayOfMonth': [1, 10, 20, 30],\n...         'nextCallTime': now}\n&gt;&gt;&gt; item = m01.remote.scheduler.Cron(data)\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now)\n'1970-01-01 00:03:00+00:00 --&gt; 1970-01-01 00:10:00+00:00'\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 10*60)\n'1970-01-01 00:10:00+00:00 --&gt; 1970-01-01 01:10:00+00:00'\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 10*24*60*60)\n'1970-01-01 01:10:00+00:00 --&gt; 1970-01-20 00:10:00+00:00'\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 20*24*60*60)\n'1970-01-20 00:10:00+00:00 --&gt; 1970-01-30 00:10:00+00:00'\n</pre>\n</blockquote>\n<p>another sample:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; data = {'jobName': u'bar', 'active': True, 'retryDelay': 5,\n...         'minute': [10], 'hour': [4], 'dayOfMonth': [1, 12, 21, 30],\n...         'nextCallTime': now}\n&gt;&gt;&gt; item = m01.remote.scheduler.Cron(data)\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now)\n'1970-01-01 00:03:00+00:00 --&gt; 1970-01-01 04:10:00+00:00'\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 10*60)\n'1970-01-01 04:10:00+00:00 --&gt; 1970-01-01 04:10:00+00:00'\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 4*60*60)\n'1970-01-01 04:10:00+00:00 --&gt; 1970-01-01 04:10:00+00:00'\n</pre>\n<pre>&gt;&gt;&gt; getNextCallTime(item, now, 5*60*60)\n'1970-01-01 04:10:00+00:00 --&gt; 1970-01-12 04:10:00+00:00'\n</pre>\n</blockquote>\n</div>\n</div>\n</div>\n<div id=\"changes\">\n<h2>CHANGES</h2>\n<div id=\"id1\">\n<h3>3.0.0 (2015-11-10)</h3>\n<ul>\n<li>support pymongo &gt;= 3.0.0 and use 3.0.0 as package version and reflect\npymongo &gt;= 3.0.0 compatibility</li>\n</ul>\n</div>\n<div id=\"id2\">\n<h3>0.6.0 (2013-06-28)</h3>\n<ul>\n<li>feature: implemented JobError as Job sub item. And rename previous JobError\nto RemoteException. This changes requires that you delete all previous\nJobError jobs in the job list before update. Also raise RemoteException\ninstead of JobError in your code. The new JobError sub item provides a\nbetter error traceback message and a created date.</li>\n<li>feature: implement better error handling, save formatted traceback string</li>\n</ul>\n</div>\n<div id=\"id3\">\n<h3>0.5.1 (2012-11-18)</h3>\n<ul>\n<li>added MANIFEST.in files</li>\n<li>remove p01.i18n package dependency</li>\n<li>allow to remove jobs with all stati</li>\n<li>split scheduler and container and move scheduler part into mixin class</li>\n<li>switch to bson import</li>\n<li>reflect changes in getBatchData signature</li>\n<li>fix dateime compare, round milliseconds</li>\n<li>adjust different schema description, user the same message id as used in title</li>\n<li>removed unused id</li>\n</ul>\n</div>\n<div id=\"id4\">\n<h3>0.5.0 (2011-08-19)</h3>\n<ul>\n<li>initial release</li>\n</ul>\n</div>\n</div>\n\n          </div>"}, "last_serial": 1811433, "releases": {"0.5.0": [{"comment_text": "", "digests": {"md5": "0589dfc9ad9d16b10700b694ce0a2e8f", "sha256": "37a38d542e504e8cd25ff3eede85562e8dc6079c1e170a4e9e9de5f5b4cfae7c"}, "downloads": -1, "filename": "m01.remote-0.5.0.zip", "has_sig": false, "md5_digest": "0589dfc9ad9d16b10700b694ce0a2e8f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 64184, "upload_time": "2011-08-19T04:05:59", "upload_time_iso_8601": "2011-08-19T04:05:59.091352Z", "url": "https://files.pythonhosted.org/packages/e1/18/9a1fe023974f0fafaaec9f0f79605c0dbab564573f8e1c503addbc2c581a/m01.remote-0.5.0.zip", "yanked": false}], "0.5.1": [{"comment_text": "", "digests": {"md5": "54693cb1f592a7b99a51ff7e29b50f79", "sha256": "f3224e6a3eb1caf7ce24bb908bef73099569b2f2214c027cfd53a839f231a7f4"}, "downloads": -1, "filename": "m01.remote-0.5.1.zip", "has_sig": false, "md5_digest": "54693cb1f592a7b99a51ff7e29b50f79", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 65388, "upload_time": "2012-11-18T17:18:35", "upload_time_iso_8601": "2012-11-18T17:18:35.918579Z", "url": "https://files.pythonhosted.org/packages/cf/3b/b200c20c9fe3571aa35eaf7283fc837f2d4b57a8d6e11d8f6e5a61dafe6b/m01.remote-0.5.1.zip", "yanked": false}], "0.6.0": [{"comment_text": "", "digests": {"md5": "df3872822756b3778402605dbc2e745d", "sha256": "c70cfdaad040d319fe558ce44c040f0bd284f50a7da492c64f00891485b5e23b"}, "downloads": -1, "filename": "m01.remote-0.6.0.zip", "has_sig": false, "md5_digest": "df3872822756b3778402605dbc2e745d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 66453, "upload_time": "2013-06-28T15:38:52", "upload_time_iso_8601": "2013-06-28T15:38:52.749312Z", "url": "https://files.pythonhosted.org/packages/f6/3f/3ada97a3327ff4dedfe524ec1bbedb158c3aa922e6ae99adeeaa168fe46a/m01.remote-0.6.0.zip", "yanked": false}], "3.0.0": [{"comment_text": "", "digests": {"md5": "86d4c3febb7762b467a6c0561fa52538", "sha256": "d7fa107b72a17164ed53d6ea7558718ff40ec44d8e4f0d29bffae7eb8af64267"}, "downloads": -1, "filename": "m01.remote-3.0.0.zip", "has_sig": false, "md5_digest": "86d4c3febb7762b467a6c0561fa52538", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 68523, "upload_time": "2015-11-11T12:57:49", "upload_time_iso_8601": "2015-11-11T12:57:49.895387Z", "url": "https://files.pythonhosted.org/packages/b8/7e/79d9c86a988017d46e1bfd5bd615bad6e9e1dd00eb2b084406cf8fd5819e/m01.remote-3.0.0.zip", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "86d4c3febb7762b467a6c0561fa52538", "sha256": "d7fa107b72a17164ed53d6ea7558718ff40ec44d8e4f0d29bffae7eb8af64267"}, "downloads": -1, "filename": "m01.remote-3.0.0.zip", "has_sig": false, "md5_digest": "86d4c3febb7762b467a6c0561fa52538", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 68523, "upload_time": "2015-11-11T12:57:49", "upload_time_iso_8601": "2015-11-11T12:57:49.895387Z", "url": "https://files.pythonhosted.org/packages/b8/7e/79d9c86a988017d46e1bfd5bd615bad6e9e1dd00eb2b084406cf8fd5819e/m01.remote-3.0.0.zip", "yanked": false}], "timestamp": "Fri May  8 00:42:35 2020"}