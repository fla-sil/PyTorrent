{"info": {"author": "Jon Pipitone, Gabriel A. Devenyi", "author_email": "jon@pipitone.ca, gdevenyi@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Environment :: Console", "Intended Audience :: Science/Research", "License :: Public Domain", "Natural Language :: English", "Operating System :: POSIX :: Linux", "Programming Language :: Python :: 2", "Programming Language :: Python :: 3", "Topic :: System :: Clustering", "Topic :: System :: Distributed Computing", "Topic :: Utilities"], "description": "# qbatch\nExecute shell command lines in parallel on Slurm, S(on) of Grid Engine (SGE),\nPBS/Torque clusters\n\n[![Travis CI build status](https://travis-ci.org/pipitone/qbatch.svg?branch=master)](https://travis-ci.org/pipitone/qbatch)\n\nqbatch is a tool for executing commands in parallel across a compute cluster.\nIt takes as input a list of **commands** (shell command lines or executable\nscripts) in a file or piped to ``qbatch``. The list of commands are divided into\narbitrarily sized **chunks** which are submitted as jobs to the cluster either as\nindividual submissions or an array. Each job runs the commands in its chunk in\nparallel according to **cores**. Commands can also be run locally on systems\nwith no cluster capability via gnu-paralel.\n\n``qbatch`` can also be used within python using the ``qbatch.qbatchParser`` and\n``qbatch.qbatchDriver`` functions. ``qbatchParser`` will accept a list of\ncommand line options identical to the shell interface, parse, and submit jobs.\nThe ``qbatchDriver`` interface will accept key-value pairs\ncorresponding to the outputs of the argument parser, and additionally, the\n``task_list`` option, providing a list of strings of commands to run.\n\n## Installation\n\n```sh\n$ pip install qbatch\n```\n\n## Dependencies\n``qbatch`` requires python (>2.7) and [GNU Parallel](https://gnu.org/s/parallel).\nFor Torque/PBS and gridengine clusters, ``qbatch`` requires the ``qsub`` and\n``qstat`` commands. For Slurm workload manager, ``qbatch`` requires the\n``sbatch`` and ``squeue`` commands.\n\n## Environment variable defaults\nqbatch supports several environment variables to customize defaults for your\nlocal system.\n\n```sh\n$ export QBATCH_PPJ=12                   # requested processors per job\n$ export QBATCH_CHUNKSIZE=$QBATCH_PPJ    # commands to run per job\n$ export QBATCH_CORES=$QBATCH_PPJ        # commonds to run in parallel per job\n$ export QBATCH_NODES=1                  # number of compute nodes to request for the job, typically for MPI jobs\n$ export QBATCH_MEM=\"0\"                  # requested memory per job\n$ export QBATCH_MEMVARS=\"mem\"            # memory request variable to set\n$ export QBATCH_SYSTEM=\"pbs\"             # queuing system to use (\"pbs\", \"sge\",\"slurm\", or \"local\")\n$ export QBATCH_NODES=1                  # (PBS-only) nodes to request per job\n$ export QBATCH_SGE_PE=\"smp\"             # (SGE-only) parallel environment name\n$ export QBATCH_QUEUE=\"1day\"             # Name of submission queue\n$ export QBATCH_OPTIONS=\"\"               # Arbitrary cluster options to embed in all jobs\n$ export QBATCH_SCRIPT_FOLDER=\".qbatch/\" # Location to generate jobfiles for submission\n$ export QBATCH_SHELL=\"/bin/sh\"          # Shell to use to evaluate jobfile\n```\n\n## Command line help\n\n```\nusage: qbatch [-h] [-w WALLTIME] [-c CHUNKSIZE] [-j CORES] [--ppj PPJ]\n              [-N JOBNAME] [--mem MEM] [-q QUEUE] [-n] [-v] [--version]\n              [--depend DEPEND] [-d WORKDIR] [--logdir LOGDIR] [-o OPTIONS]\n              [--header HEADER] [--footer FOOTER] [--nodes NODES]\n              [--sge-pe SGE_PE] [--memvars MEMVARS]\n              [--pbs-nodes-spec PBS_NODES_SPEC] [-i]\n              [-b {pbs,sge,slurm,local,container}] [--env {copied,batch,none}]\n              [--shell SHELL]\n              ...\n\nSubmits a list of commands to a queueing system. The list of commands can be\nbroken up into 'chunks' when submitted, so that the commands in each chunk run\nin parallel (using GNU parallel). The job script(s) generated by qbatch are\nstored in the folder .qbatch/\n\npositional arguments:\n  command_file          An input file containing a list of shell commands to\n                        be submitted, - to read the command list from stdin or\n                        -- followed by a single command\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -w WALLTIME, --walltime WALLTIME\n                        Maximum walltime for an array job element or\n                        individual job (default: None)\n  -c CHUNKSIZE, --chunksize CHUNKSIZE\n                        Number of commands from the command list that are\n                        wrapped into each job (default: 1)\n  -j CORES, --cores CORES\n                        Number of commands each job runs in parallel. If the\n                        chunk size (-c) is smaller than -j then only chunk\n                        size commands will run in parallel. This option can\n                        also be expressed as a percentage (e.g. 100%) of the\n                        total available cores (default: 1)\n  --ppj PPJ             Requested number of processors per job (aka ppn on\n                        PBS, slots on SGE, cpus per task on SLURM). Cores can\n                        be over subscribed if -j is larger than --ppj (useful\n                        to make use of hyper-threading on some systems)\n                        (default: 1)\n  -N JOBNAME, --jobname JOBNAME\n                        Set job name (defaults to name of command file, or\n                        STDIN) (default: None)\n  --mem MEM             Memory required for each job (e.g. --mem 1G). This\n                        value will be set on each variable specified in\n                        --memvars. To not set any memory requirement, set this\n                        to 0 (default: 0)\n  -q QUEUE, --queue QUEUE\n                        Name of queue to submit jobs to (defaults to no queue)\n                        (default: None)\n  -n, --dryrun          Dry run; Create jobfiles but do not submit or run any\n                        commands (default: False)\n  -v, --verbose         Verbose output (default: False)\n  --version             show program's version number and exit\n\nadvanced options:\n  --depend DEPEND       Wait for successful completion of job(s) with name\n                        matching given glob pattern or job id matching given\n                        job id(s) before starting (default: None)\n  -d WORKDIR, --workdir WORKDIR\n                        Job working directory (default:\n                        current working directory)\n  --logdir LOGDIR       Directory to save store log files (default:\n                        {workdir}/logs)\n  -o OPTIONS, --options OPTIONS\n                        Custom options passed directly to the queuing system\n                        (e.g --options \"-l vf=8G\". This option can be given\n                        multiple times (default: [])\n  --header HEADER       A line to insert verbatim at the start of the script,\n                        and will be run once per job. This option can be given\n                        multiple times (default: None)\n  --footer FOOTER       A line to insert verbatim at the end of the script,\n                        and will be run once per job. This option can be given\n                        multiple times (default: None)\n  --nodes NODES         (PBS and SLURM only) Nodes to request per job\n                        (default: 1)\n  --sge-pe SGE_PE       (SGE-only) The parallel environment to use if more\n                        than one processor per job is requested (default: smp)\n  --memvars MEMVARS     A comma-separated list of variables to set with the\n                        memory limit given by the --mem option (e.g.\n                        --memvars=h_vmem,vf) (default: mem)\n  --pbs-nodes-spec PBS_NODES_SPEC\n                        (PBS-only) String to be inserted into nodes= line of\n                        job (default: None)\n  -i, --individual      Submit individual jobs instead of an array job\n                        (default: False)\n  -b {pbs,sge,slurm,local,container}, --system {pbs,sge,slurm,local,container}\n                        The type of queueing system to use. 'pbs' and 'sge'\n                        both make calls to qsub to submit jobs. 'slurm' calls\n                        sbatch. 'local' runs the entire command list (without\n                        chunking) locally. 'container' creates a joblist and\n                        metadata file, to pass commands out of a container to\n                        a monitoring process for submission to a batch system.\n                        (default: local)\n  --env {copied,batch,none}\n                        Determines how your environment is propagated when\n                        your job runs. \"copied\" records your environment\n                        settings in the job submission script, \"batch\" uses\n                        the cluster's mechanism for propagating your\n                        environment, and \"none\" does not propagate any\n                        environment variables. (default: copied)\n  --shell SHELL         Shell to use for spawning jobs and launching single\n                        commands (default: /bin/sh)\n```\n\n## Some examples:\n```sh\n# Submit an array job from a list of commands (one per line)\n# Generates a job script in ./.qbatch/ and job logs appear in ./logs/\\\n# All defaults are inherited from QBATCH_* environment variables\n$ qbatch commands.txt\n\n# Submit a single command to the cluster\n$ qbatch -- echo hello\n\n# Set the walltime for each job\n$ qbatch -w 3:00:00 commands.txt\n\n# Run 24 commands per job\n$ qbatch -c24 commands.txt\n\n# Pack 24 commands per job, run 12 in parallel at a time\n$ qbatch -c24 -j12 commands.txt\n\n# Start jobs after successful completion of existing jobs with names starting with \"stage1_\"\n$ qbatch --afterok 'stage1_*' commands.txt\n\n# Pipe a list of commands to qbatch\n$ parallel echo process.sh {} ::: *.dat | qbatch -\n\n# Run jobs locally with GNU Parallel, 12 commands in parallel\n$ qbatch -b local -j12 commands.txt\n\n# Many options don't make sense locally: chunking, individual vs array, nodes,\n# ppj, highmem, and afterok are ignored\n```\n\nA python script example:\n```python\n# Submit jobs to a cluster using the QBATCH_* environment defaults\nimport qbatch\ntask_list = ['echo hello', 'echo hello2']\nqbatch.qbatchDriver(task_list = task_list)\n\n```", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/pipitone/qbatch", "keywords": "", "license": "Unlicense", "maintainer": "", "maintainer_email": "", "name": "qbatch", "package_url": "https://pypi.org/project/qbatch/", "platform": "", "project_url": "https://pypi.org/project/qbatch/", "project_urls": {"Homepage": "https://github.com/pipitone/qbatch"}, "release_url": "https://pypi.org/project/qbatch/2.2/", "requires_dist": null, "requires_python": "", "summary": "Execute shell command lines in parallel on Slurm, S(un|on of) Grid Engine (SGE) and PBS/Torque clusters", "version": "2.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>qbatch</h1>\n<p>Execute shell command lines in parallel on Slurm, S(on) of Grid Engine (SGE),\nPBS/Torque clusters</p>\n<p><a href=\"https://travis-ci.org/pipitone/qbatch\" rel=\"nofollow\"><img alt=\"Travis CI build status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/76f58c0f98ae39b31cbb347a20b7741445cb5b3d/68747470733a2f2f7472617669732d63692e6f72672f70697069746f6e652f7162617463682e7376673f6272616e63683d6d6173746572\"></a></p>\n<p>qbatch is a tool for executing commands in parallel across a compute cluster.\nIt takes as input a list of <strong>commands</strong> (shell command lines or executable\nscripts) in a file or piped to <code>qbatch</code>. The list of commands are divided into\narbitrarily sized <strong>chunks</strong> which are submitted as jobs to the cluster either as\nindividual submissions or an array. Each job runs the commands in its chunk in\nparallel according to <strong>cores</strong>. Commands can also be run locally on systems\nwith no cluster capability via gnu-paralel.</p>\n<p><code>qbatch</code> can also be used within python using the <code>qbatch.qbatchParser</code> and\n<code>qbatch.qbatchDriver</code> functions. <code>qbatchParser</code> will accept a list of\ncommand line options identical to the shell interface, parse, and submit jobs.\nThe <code>qbatchDriver</code> interface will accept key-value pairs\ncorresponding to the outputs of the argument parser, and additionally, the\n<code>task_list</code> option, providing a list of strings of commands to run.</p>\n<h2>Installation</h2>\n<pre>$ pip install qbatch\n</pre>\n<h2>Dependencies</h2>\n<p><code>qbatch</code> requires python (&gt;2.7) and <a href=\"https://gnu.org/s/parallel\" rel=\"nofollow\">GNU Parallel</a>.\nFor Torque/PBS and gridengine clusters, <code>qbatch</code> requires the <code>qsub</code> and\n<code>qstat</code> commands. For Slurm workload manager, <code>qbatch</code> requires the\n<code>sbatch</code> and <code>squeue</code> commands.</p>\n<h2>Environment variable defaults</h2>\n<p>qbatch supports several environment variables to customize defaults for your\nlocal system.</p>\n<pre>$ <span class=\"nb\">export</span> <span class=\"nv\">QBATCH_PPJ</span><span class=\"o\">=</span><span class=\"m\">12</span>                   <span class=\"c1\"># requested processors per job</span>\n$ <span class=\"nb\">export</span> <span class=\"nv\">QBATCH_CHUNKSIZE</span><span class=\"o\">=</span><span class=\"nv\">$QBATCH_PPJ</span>    <span class=\"c1\"># commands to run per job</span>\n$ <span class=\"nb\">export</span> <span class=\"nv\">QBATCH_CORES</span><span class=\"o\">=</span><span class=\"nv\">$QBATCH_PPJ</span>        <span class=\"c1\"># commonds to run in parallel per job</span>\n$ <span class=\"nb\">export</span> <span class=\"nv\">QBATCH_NODES</span><span class=\"o\">=</span><span class=\"m\">1</span>                  <span class=\"c1\"># number of compute nodes to request for the job, typically for MPI jobs</span>\n$ <span class=\"nb\">export</span> <span class=\"nv\">QBATCH_MEM</span><span class=\"o\">=</span><span class=\"s2\">\"0\"</span>                  <span class=\"c1\"># requested memory per job</span>\n$ <span class=\"nb\">export</span> <span class=\"nv\">QBATCH_MEMVARS</span><span class=\"o\">=</span><span class=\"s2\">\"mem\"</span>            <span class=\"c1\"># memory request variable to set</span>\n$ <span class=\"nb\">export</span> <span class=\"nv\">QBATCH_SYSTEM</span><span class=\"o\">=</span><span class=\"s2\">\"pbs\"</span>             <span class=\"c1\"># queuing system to use (\"pbs\", \"sge\",\"slurm\", or \"local\")</span>\n$ <span class=\"nb\">export</span> <span class=\"nv\">QBATCH_NODES</span><span class=\"o\">=</span><span class=\"m\">1</span>                  <span class=\"c1\"># (PBS-only) nodes to request per job</span>\n$ <span class=\"nb\">export</span> <span class=\"nv\">QBATCH_SGE_PE</span><span class=\"o\">=</span><span class=\"s2\">\"smp\"</span>             <span class=\"c1\"># (SGE-only) parallel environment name</span>\n$ <span class=\"nb\">export</span> <span class=\"nv\">QBATCH_QUEUE</span><span class=\"o\">=</span><span class=\"s2\">\"1day\"</span>             <span class=\"c1\"># Name of submission queue</span>\n$ <span class=\"nb\">export</span> <span class=\"nv\">QBATCH_OPTIONS</span><span class=\"o\">=</span><span class=\"s2\">\"\"</span>               <span class=\"c1\"># Arbitrary cluster options to embed in all jobs</span>\n$ <span class=\"nb\">export</span> <span class=\"nv\">QBATCH_SCRIPT_FOLDER</span><span class=\"o\">=</span><span class=\"s2\">\".qbatch/\"</span> <span class=\"c1\"># Location to generate jobfiles for submission</span>\n$ <span class=\"nb\">export</span> <span class=\"nv\">QBATCH_SHELL</span><span class=\"o\">=</span><span class=\"s2\">\"/bin/sh\"</span>          <span class=\"c1\"># Shell to use to evaluate jobfile</span>\n</pre>\n<h2>Command line help</h2>\n<pre><code>usage: qbatch [-h] [-w WALLTIME] [-c CHUNKSIZE] [-j CORES] [--ppj PPJ]\n              [-N JOBNAME] [--mem MEM] [-q QUEUE] [-n] [-v] [--version]\n              [--depend DEPEND] [-d WORKDIR] [--logdir LOGDIR] [-o OPTIONS]\n              [--header HEADER] [--footer FOOTER] [--nodes NODES]\n              [--sge-pe SGE_PE] [--memvars MEMVARS]\n              [--pbs-nodes-spec PBS_NODES_SPEC] [-i]\n              [-b {pbs,sge,slurm,local,container}] [--env {copied,batch,none}]\n              [--shell SHELL]\n              ...\n\nSubmits a list of commands to a queueing system. The list of commands can be\nbroken up into 'chunks' when submitted, so that the commands in each chunk run\nin parallel (using GNU parallel). The job script(s) generated by qbatch are\nstored in the folder .qbatch/\n\npositional arguments:\n  command_file          An input file containing a list of shell commands to\n                        be submitted, - to read the command list from stdin or\n                        -- followed by a single command\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -w WALLTIME, --walltime WALLTIME\n                        Maximum walltime for an array job element or\n                        individual job (default: None)\n  -c CHUNKSIZE, --chunksize CHUNKSIZE\n                        Number of commands from the command list that are\n                        wrapped into each job (default: 1)\n  -j CORES, --cores CORES\n                        Number of commands each job runs in parallel. If the\n                        chunk size (-c) is smaller than -j then only chunk\n                        size commands will run in parallel. This option can\n                        also be expressed as a percentage (e.g. 100%) of the\n                        total available cores (default: 1)\n  --ppj PPJ             Requested number of processors per job (aka ppn on\n                        PBS, slots on SGE, cpus per task on SLURM). Cores can\n                        be over subscribed if -j is larger than --ppj (useful\n                        to make use of hyper-threading on some systems)\n                        (default: 1)\n  -N JOBNAME, --jobname JOBNAME\n                        Set job name (defaults to name of command file, or\n                        STDIN) (default: None)\n  --mem MEM             Memory required for each job (e.g. --mem 1G). This\n                        value will be set on each variable specified in\n                        --memvars. To not set any memory requirement, set this\n                        to 0 (default: 0)\n  -q QUEUE, --queue QUEUE\n                        Name of queue to submit jobs to (defaults to no queue)\n                        (default: None)\n  -n, --dryrun          Dry run; Create jobfiles but do not submit or run any\n                        commands (default: False)\n  -v, --verbose         Verbose output (default: False)\n  --version             show program's version number and exit\n\nadvanced options:\n  --depend DEPEND       Wait for successful completion of job(s) with name\n                        matching given glob pattern or job id matching given\n                        job id(s) before starting (default: None)\n  -d WORKDIR, --workdir WORKDIR\n                        Job working directory (default:\n                        current working directory)\n  --logdir LOGDIR       Directory to save store log files (default:\n                        {workdir}/logs)\n  -o OPTIONS, --options OPTIONS\n                        Custom options passed directly to the queuing system\n                        (e.g --options \"-l vf=8G\". This option can be given\n                        multiple times (default: [])\n  --header HEADER       A line to insert verbatim at the start of the script,\n                        and will be run once per job. This option can be given\n                        multiple times (default: None)\n  --footer FOOTER       A line to insert verbatim at the end of the script,\n                        and will be run once per job. This option can be given\n                        multiple times (default: None)\n  --nodes NODES         (PBS and SLURM only) Nodes to request per job\n                        (default: 1)\n  --sge-pe SGE_PE       (SGE-only) The parallel environment to use if more\n                        than one processor per job is requested (default: smp)\n  --memvars MEMVARS     A comma-separated list of variables to set with the\n                        memory limit given by the --mem option (e.g.\n                        --memvars=h_vmem,vf) (default: mem)\n  --pbs-nodes-spec PBS_NODES_SPEC\n                        (PBS-only) String to be inserted into nodes= line of\n                        job (default: None)\n  -i, --individual      Submit individual jobs instead of an array job\n                        (default: False)\n  -b {pbs,sge,slurm,local,container}, --system {pbs,sge,slurm,local,container}\n                        The type of queueing system to use. 'pbs' and 'sge'\n                        both make calls to qsub to submit jobs. 'slurm' calls\n                        sbatch. 'local' runs the entire command list (without\n                        chunking) locally. 'container' creates a joblist and\n                        metadata file, to pass commands out of a container to\n                        a monitoring process for submission to a batch system.\n                        (default: local)\n  --env {copied,batch,none}\n                        Determines how your environment is propagated when\n                        your job runs. \"copied\" records your environment\n                        settings in the job submission script, \"batch\" uses\n                        the cluster's mechanism for propagating your\n                        environment, and \"none\" does not propagate any\n                        environment variables. (default: copied)\n  --shell SHELL         Shell to use for spawning jobs and launching single\n                        commands (default: /bin/sh)\n</code></pre>\n<h2>Some examples:</h2>\n<pre><span class=\"c1\"># Submit an array job from a list of commands (one per line)</span>\n<span class=\"c1\"># Generates a job script in ./.qbatch/ and job logs appear in ./logs/\\</span>\n<span class=\"c1\"># All defaults are inherited from QBATCH_* environment variables</span>\n$ qbatch commands.txt\n\n<span class=\"c1\"># Submit a single command to the cluster</span>\n$ qbatch -- <span class=\"nb\">echo</span> hello\n\n<span class=\"c1\"># Set the walltime for each job</span>\n$ qbatch -w <span class=\"m\">3</span>:00:00 commands.txt\n\n<span class=\"c1\"># Run 24 commands per job</span>\n$ qbatch -c24 commands.txt\n\n<span class=\"c1\"># Pack 24 commands per job, run 12 in parallel at a time</span>\n$ qbatch -c24 -j12 commands.txt\n\n<span class=\"c1\"># Start jobs after successful completion of existing jobs with names starting with \"stage1_\"</span>\n$ qbatch --afterok <span class=\"s1\">'stage1_*'</span> commands.txt\n\n<span class=\"c1\"># Pipe a list of commands to qbatch</span>\n$ parallel <span class=\"nb\">echo</span> process.sh <span class=\"o\">{}</span> ::: *.dat <span class=\"p\">|</span> qbatch -\n\n<span class=\"c1\"># Run jobs locally with GNU Parallel, 12 commands in parallel</span>\n$ qbatch -b <span class=\"nb\">local</span> -j12 commands.txt\n\n<span class=\"c1\"># Many options don't make sense locally: chunking, individual vs array, nodes,</span>\n<span class=\"c1\"># ppj, highmem, and afterok are ignored</span>\n</pre>\n<p>A python script example:</p>\n<pre><span class=\"c1\"># Submit jobs to a cluster using the QBATCH_* environment defaults</span>\n<span class=\"kn\">import</span> <span class=\"nn\">qbatch</span>\n<span class=\"n\">task_list</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'echo hello'</span><span class=\"p\">,</span> <span class=\"s1\">'echo hello2'</span><span class=\"p\">]</span>\n<span class=\"n\">qbatch</span><span class=\"o\">.</span><span class=\"n\">qbatchDriver</span><span class=\"p\">(</span><span class=\"n\">task_list</span> <span class=\"o\">=</span> <span class=\"n\">task_list</span><span class=\"p\">)</span>\n</pre>\n\n          </div>"}, "last_serial": 6799547, "releases": {"1.0": [{"comment_text": "", "digests": {"md5": "4b3ee03de55f31cf3a7e669cff6a027f", "sha256": "e2659de226a0a009d52bd121177c6c8244633ede669ee4048bfd1f1c8debb2b4"}, "downloads": -1, "filename": "qbatch-1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "4b3ee03de55f31cf3a7e669cff6a027f", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 9506, "upload_time": "2016-05-06T12:28:26", "upload_time_iso_8601": "2016-05-06T12:28:26.993940Z", "url": "https://files.pythonhosted.org/packages/cd/f0/6b68c5c8d32653a2317ef6bbeb5a30a616225db32bd3cea9261ffd0d5665/qbatch-1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b310ca24e546520b6b55f21fb5ee25c8", "sha256": "00824ee3424140bc32096e9c875239e7ccc2c8ba24b1e3369c29de805023f916"}, "downloads": -1, "filename": "qbatch-1.0.tar.gz", "has_sig": false, "md5_digest": "b310ca24e546520b6b55f21fb5ee25c8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7877, "upload_time": "2016-05-06T12:28:33", "upload_time_iso_8601": "2016-05-06T12:28:33.187475Z", "url": "https://files.pythonhosted.org/packages/52/8e/b93bf9d038ecf89a76b101304019ef01559445365f6ec668569b41e14024/qbatch-1.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "252d5e932bd1133f4e8600965df0860e", "sha256": "a51a0e793d023f9b9f81227d53bca132a529f5033051cade3f7a2da9c15086ad"}, "downloads": -1, "filename": "qbatch-1.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "252d5e932bd1133f4e8600965df0860e", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 7274, "upload_time": "2016-05-06T15:21:10", "upload_time_iso_8601": "2016-05-06T15:21:10.937328Z", "url": "https://files.pythonhosted.org/packages/25/d8/3182316b4ad3ba8e8027f4f398afba130cd9b9e1e1b23a57752758f3f468/qbatch-1.0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "27aae0512c78a92f98f1205a7c4f62a8", "sha256": "1fd39a70813c5f002ed648f98840e1341114567068d27bf01c733fd8b3a511f1"}, "downloads": -1, "filename": "qbatch-1.0.1.tar.gz", "has_sig": false, "md5_digest": "27aae0512c78a92f98f1205a7c4f62a8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6943, "upload_time": "2016-05-06T15:21:17", "upload_time_iso_8601": "2016-05-06T15:21:17.535478Z", "url": "https://files.pythonhosted.org/packages/a6/e5/ff6a284b699593c9e2c16693547a72fb60dd2df40cf4e3bc877b09ae6972/qbatch-1.0.1.tar.gz", "yanked": false}], "1.0rc1": [], "1.0rc2": [{"comment_text": "", "digests": {"md5": "72567e1809f398906a02297ced0517b0", "sha256": "abd30f8c59ace3b16b1ed5e0a80f77ee7c95eef3215ce3baf51f4686aaf4244d"}, "downloads": -1, "filename": "qbatch-1.0rc2.tar.gz", "has_sig": false, "md5_digest": "72567e1809f398906a02297ced0517b0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7369, "upload_time": "2016-03-23T02:53:05", "upload_time_iso_8601": "2016-03-23T02:53:05.946876Z", "url": "https://files.pythonhosted.org/packages/16/53/c56a94b6b4040f9c453d22ef5a562a407fc15617e3ceca63dfbd20a31e0b/qbatch-1.0rc2.tar.gz", "yanked": false}], "2.0": [{"comment_text": "", "digests": {"md5": "bd803f05bdf9f1141deee37041ebd42c", "sha256": "edcdd2afbc1946970a99e11dcd4c20030ffb8a8dcdae16e160ba0ffdbea55c3b"}, "downloads": -1, "filename": "qbatch-2.0.tar.gz", "has_sig": false, "md5_digest": "bd803f05bdf9f1141deee37041ebd42c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11375, "upload_time": "2018-04-27T18:45:24", "upload_time_iso_8601": "2018-04-27T18:45:24.239493Z", "url": "https://files.pythonhosted.org/packages/94/59/6dc6fcb446c9f82625c80ba45678766cd3d489b744fb013ddb05dafda611/qbatch-2.0.tar.gz", "yanked": false}], "2.0.1": [{"comment_text": "", "digests": {"md5": "dab362f3d386593c51cccc9eb828fe0b", "sha256": "0f1791fd01d4afa5b5ec7ab5200752b761caf08275119ee3b796f32c44e91daa"}, "downloads": -1, "filename": "qbatch-2.0.1.tar.gz", "has_sig": false, "md5_digest": "dab362f3d386593c51cccc9eb828fe0b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12416, "upload_time": "2018-04-28T02:57:28", "upload_time_iso_8601": "2018-04-28T02:57:28.840592Z", "url": "https://files.pythonhosted.org/packages/cb/f3/e45b58820393b2c0f76f208666c9e3f2996b7f7450cc5393d3f0c5015efd/qbatch-2.0.1.tar.gz", "yanked": false}], "2.0.2": [{"comment_text": "", "digests": {"md5": "ed4f8ea3276686e80f763a4b20cc15ab", "sha256": "108f22b6d84f9b833b9f6d5231b252c04701ffc86b19dfb12278bf543f251171"}, "downloads": -1, "filename": "qbatch-2.0.2.tar.gz", "has_sig": false, "md5_digest": "ed4f8ea3276686e80f763a4b20cc15ab", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12414, "upload_time": "2018-04-28T13:19:22", "upload_time_iso_8601": "2018-04-28T13:19:22.150933Z", "url": "https://files.pythonhosted.org/packages/99/9f/28a97787ba6c26e23c77f9349e67a6a10a5b85b4489e0732647f2d393769/qbatch-2.0.2.tar.gz", "yanked": false}], "2.1": [{"comment_text": "", "digests": {"md5": "95ae1c6bb932a8b9da499b2c6948af64", "sha256": "919830e2fb5b0524babac74ae656bc65d779606ea2b0821bd645808c13abedbe"}, "downloads": -1, "filename": "qbatch-2.1.tar.gz", "has_sig": false, "md5_digest": "95ae1c6bb932a8b9da499b2c6948af64", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12477, "upload_time": "2019-02-25T22:00:09", "upload_time_iso_8601": "2019-02-25T22:00:09.907588Z", "url": "https://files.pythonhosted.org/packages/97/56/c349a9e8ddb21c8f66f3298cc3dcacecdeecddec9274883937e800b5f49e/qbatch-2.1.tar.gz", "yanked": false}], "2.1.1": [{"comment_text": "", "digests": {"md5": "52d2bb5abe0e77137d358415a8039c4f", "sha256": "358c4e859f282c249ae11b61f6ad61601e0922f87d160be500d6410359dc997f"}, "downloads": -1, "filename": "qbatch-2.1.1.tar.gz", "has_sig": false, "md5_digest": "52d2bb5abe0e77137d358415a8039c4f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12168, "upload_time": "2019-05-23T15:57:32", "upload_time_iso_8601": "2019-05-23T15:57:32.727472Z", "url": "https://files.pythonhosted.org/packages/13/78/4ab56a8baeae1db30639a0345da3f17499f48bf8192bab949331fe790433/qbatch-2.1.1.tar.gz", "yanked": false}], "2.1.2": [{"comment_text": "", "digests": {"md5": "ded0837e5111cdbc9c8d8467459e8b44", "sha256": "ee7fd5a10d426a383b28301277b1e9dbefd62a6f6e13652c1d5b31f3c002c7e1"}, "downloads": -1, "filename": "qbatch-2.1.2.tar.gz", "has_sig": false, "md5_digest": "ded0837e5111cdbc9c8d8467459e8b44", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12172, "upload_time": "2019-06-07T02:40:48", "upload_time_iso_8601": "2019-06-07T02:40:48.907227Z", "url": "https://files.pythonhosted.org/packages/f5/e6/4cb57fd4d873f9a911c5e9a74a1e445a2921e434c479d64570cfbf03cede/qbatch-2.1.2.tar.gz", "yanked": false}], "2.1.3": [{"comment_text": "", "digests": {"md5": "800a3831ac639bc578b26efc45fc2162", "sha256": "b823ae30b1de7bcf7ac5ce73084f120c4b886378cb12ff46eb269f2fd7cdd7bc"}, "downloads": -1, "filename": "qbatch-2.1.3.tar.gz", "has_sig": false, "md5_digest": "800a3831ac639bc578b26efc45fc2162", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12185, "upload_time": "2019-06-07T17:45:44", "upload_time_iso_8601": "2019-06-07T17:45:44.129017Z", "url": "https://files.pythonhosted.org/packages/9e/38/84b86d597463c7f46558f502bf75b78488a37a7d1e13cc2ad6a6cddeb3c2/qbatch-2.1.3.tar.gz", "yanked": false}], "2.1.4": [{"comment_text": "", "digests": {"md5": "56e386318657c571513d75a7afb4a179", "sha256": "35039d5ad9520af32f6247bc140c2c1a2586a37891259afa4df29f3ed1f660c2"}, "downloads": -1, "filename": "qbatch-2.1.4.tar.gz", "has_sig": false, "md5_digest": "56e386318657c571513d75a7afb4a179", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12173, "upload_time": "2019-06-20T14:47:40", "upload_time_iso_8601": "2019-06-20T14:47:40.130787Z", "url": "https://files.pythonhosted.org/packages/f2/b1/e04bec924babd14f6a2e16ebf8d22ac9824d824d2f5db9f419f0f31e02c4/qbatch-2.1.4.tar.gz", "yanked": false}], "2.1.5": [{"comment_text": "", "digests": {"md5": "6c2c8a37b9a7e49b138ecf2c284ec1d2", "sha256": "f564f4d2808503e2ae585b890babc24db77022caeb515ab89f76a0d0f6355582"}, "downloads": -1, "filename": "qbatch-2.1.5.tar.gz", "has_sig": false, "md5_digest": "6c2c8a37b9a7e49b138ecf2c284ec1d2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12638, "upload_time": "2019-07-05T19:59:53", "upload_time_iso_8601": "2019-07-05T19:59:53.977096Z", "url": "https://files.pythonhosted.org/packages/b1/0c/5ac9928d5ef4391b83139b62fdf70ddd69f0715ba94eb2adc2339a9b3d1e/qbatch-2.1.5.tar.gz", "yanked": false}], "2.2": [{"comment_text": "", "digests": {"md5": "13073e3253856a4bf01fc8289c33c6dd", "sha256": "777f1b0b3bb5c8b7a3d81dadf2c2f0101ad3475349667a0378d312ad0e7f0681"}, "downloads": -1, "filename": "qbatch-2.2.tar.gz", "has_sig": false, "md5_digest": "13073e3253856a4bf01fc8289c33c6dd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15971, "upload_time": "2020-03-12T14:00:48", "upload_time_iso_8601": "2020-03-12T14:00:48.790127Z", "url": "https://files.pythonhosted.org/packages/38/7f/84daf55bff13ba2a7275304949bcb070479b25da48ce2729ca6fe5b293a5/qbatch-2.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "13073e3253856a4bf01fc8289c33c6dd", "sha256": "777f1b0b3bb5c8b7a3d81dadf2c2f0101ad3475349667a0378d312ad0e7f0681"}, "downloads": -1, "filename": "qbatch-2.2.tar.gz", "has_sig": false, "md5_digest": "13073e3253856a4bf01fc8289c33c6dd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15971, "upload_time": "2020-03-12T14:00:48", "upload_time_iso_8601": "2020-03-12T14:00:48.790127Z", "url": "https://files.pythonhosted.org/packages/38/7f/84daf55bff13ba2a7275304949bcb070479b25da48ce2729ca6fe5b293a5/qbatch-2.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:10:06 2020"}