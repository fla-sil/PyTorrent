{"info": {"author": "Christopher Choy", "author_email": "chrischoy@ai.stanford.edu", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Environment :: Console", "Intended Audience :: Developers", "Intended Audience :: Other Audience", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Programming Language :: C++", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8", "Topic :: Multimedia :: Graphics", "Topic :: Scientific/Engineering", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Scientific/Engineering :: Mathematics", "Topic :: Scientific/Engineering :: Physics", "Topic :: Scientific/Engineering :: Visualization"], "description": "[pypi-image]: https://badge.fury.io/py/MinkowskiEngine.svg\n[pypi-url]: https://pypi.org/project/MinkowskiEngine/\n\n# Minkowski Engine\n\n[![PyPI Version][pypi-image]][pypi-url] [![Join the chat at https://gitter.im/MinkowskiEngineGitter/general](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/MinkowskiEngineGitter/general)\n\nThe Minkowski Engine is an auto-differentiation library for sparse tensors. It supports all standard neural network layers such as convolution, pooling, unpooling, and broadcasting operations for sparse tensors. For more information, please visit [the documentation page](http://stanfordvl.github.io/MinkowskiEngine/overview.html).\n\n## Example Networks\n\nThe Minkowski Engine supports various functions that can be built on a sparse tensor. We list a few popular network architectures and applications here. To run the examples, please install the package and run the command in the package root directory.\n\n| Examples              | Networks and Commands                                                                                                                                                           |\n|:---------------------:|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|\n| Semantic Segmentation | <img src=\"https://stanfordvl.github.io/MinkowskiEngine/_images/segmentation_3d_net.png\"> <br /> <img src=\"https://stanfordvl.github.io/MinkowskiEngine/_images/segmentation.png\" width=\"256\"> <br /> `python -m examples.indoor` |\n| Classification        | ![](https://stanfordvl.github.io/MinkowskiEngine/_images/classification_3d_net.png) <br /> `python -m examples.modelnet40`                                                      |\n| Reconstruction        | <img src=\"https://stanfordvl.github.io/MinkowskiEngine/_images/generative_3d_net.png\"> <br /> <img src=\"https://stanfordvl.github.io/MinkowskiEngine/_images/generative_3d_results.gif\" width=\"256\"> <br /> `python -m examples.reconstruction` |\n| Completion            | <img src=\"https://stanfordvl.github.io/MinkowskiEngine/_images/completion_3d_net.png\"> <br /> `python -m examples.completion`                                                   |\n\n\n## Sparse Tensor Networks: Neural Networks for Spatially Sparse Tensors\n\nCompressing a neural network to speedup inference and minimize memory footprint has been studied widely. One of the popular techniques for model compression is pruning the weights in convnets, is also known as [*sparse convolutional networks*](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Liu_Sparse_Convolutional_Neural_2015_CVPR_paper.pdf). Such parameter-space sparsity used for model compression compresses networks that operate on dense tensors and all intermediate activations of these networks are also dense tensors.\n\nHowever, in this work, we focus on [*spatially* sparse data](https://arxiv.org/abs/1409.6070), in particular, spatially sparse high-dimensional inputs. We can also represent these data as sparse tensors, and these sparse tensors are commonplace in high-dimensional problems such as 3D perception, registration, and statistical data. We define neural networks specialized for these inputs as *sparse tensor networks*  and these sparse tensor networks process and generate sparse tensors as outputs. To construct a sparse tensor network, we build all standard neural network layers such as MLPs, non-linearities, convolution, normalizations, pooling operations as the same way we define them on a dense tensor and implemented in the Minkowski Engine.\n\nWe visualized a sparse tensor network operation on a sparse tensor, convolution, below. The convolution layer on a sparse tensor works similarly to that on a dense tensor. However, on a sparse tensor, we compute convolution outputs on a few specified points which we can control in the [generalized convolution](https://stanfordvl.github.io/MinkowskiEngine/sparse_tensor_network.html). For more information, please visit [the documentation page on sparse tensor networks](https://stanfordvl.github.io/MinkowskiEngine/sparse_tensor_network.html) and [the terminology page](https://stanfordvl.github.io/MinkowskiEngine/terminology.html).\n\n| Dense Tensor                                                                    | Sparse Tensor                                                                     |\n|:-------------------------------------------------------------------------------:|:---------------------------------------------------------------------------------:|\n| <img src=\"https://stanfordvl.github.io/MinkowskiEngine/_images/conv_dense.gif\"> | <img src=\"https://stanfordvl.github.io/MinkowskiEngine/_images/conv_sparse.gif\" > |\n\n--------------------------------------------------------------------------------\n\n## Features\n\n- Unlimited high-dimensional sparse tensor support\n- All standard neural network layers (Convolution, Pooling, Broadcast, etc.)\n- Dynamic computation graph\n- Custom kernel shapes\n- Multi-GPU training\n- Multi-threaded kernel map\n- Multi-threaded compilation\n- Highly-optimized GPU kernels\n\n\n## Requirements\n\n- Ubuntu 14.04 or higher\n- CUDA 10.1 or higher\n- pytorch 1.3 or higher\n- python 3.6 or higher\n- GCC 6 or higher\n\n\n## Installation\n\nYou can install the Minkowski Engine with `pip`, with anaconda, or on the system directly. If you experience issues installing the package, please checkout the [common compilation issues page](https://stanfordvl.github.io/MinkowskiEngine/issues.html) or [the installation wiki page](https://github.com/StanfordVL/MinkowskiEngine/wiki/Installation).\nIf you cannot find a relevant problem, please report the issue on [the github issue page](https://github.com/StanfordVL/MinkowskiEngine/issues).\n\n### Pip\n\nThe MinkowskiEngine is distributed via [PyPI MinkowskiEngine][pypi-url] which can be installed simply with `pip`.\nFirst, install pytorch following the [instruction](https://pytorch.org). Next, install `openblas`.\n\n```\nsudo apt install libopenblas-dev\npip3 install torch\npip3 install -U MinkowskiEngine\n```\n\n### Pip from the latest source\n\n```\nsudo apt install libopenblas-dev\npip3 install torch\npip3 install -U -I git+https://github.com/StanfordVL/MinkowskiEngine\n```\n\n### Anaconda\n\nWe recommend `python>=3.6` for installation.\n\n\n#### 1. Create a conda virtual environment and install requirements.\n\nFirst, follow [the anaconda documentation](https://docs.anaconda.com/anaconda/install/) to install anaconda on your computer.\n\n```\nconda create -n py3-mink python=3.7\nconda activate py3-mink\nconda install numpy mkl-include\nconda install pytorch -c pytorch\n```\n\n#### 2. Compilation and installation\n\n```\nconda activate py3-mink\ngit clone https://github.com/StanfordVL/MinkowskiEngine.git\ncd MinkowskiEngine\npython setup.py install\n```\n\n\n### System Python\n\nLike the anaconda installation, make sure that you install pytorch with the same CUDA version that `nvcc` uses.\n\n```\n# install system requirements\nsudo apt install python3-dev libopenblas-dev\n\n# Skip if you already have pip installed on your python3\ncurl https://bootstrap.pypa.io/get-pip.py | python3\n\n# Get pip and install python requirements\npython3 -m pip install torch numpy\n\ngit clone https://github.com/StanfordVL/MinkowskiEngine.git\n\ncd MinkowskiEngine\n\npython setup.py install\n```\n\n\n## CPU only build and BLAS configuration (MKL)\n\nThe Minkowski Engine supports CPU only build on other platforms that do not have NVidia GPUs. Please refer to [quick start](https://stanfordvl.github.io/MinkowskiEngine/quick_start.html) for more details.\n\n\n## Quick Start\n\nTo use the Minkowski Engine, you first would need to import the engine.\nThen, you would need to define the network. If the data you have is not\nquantized, you would need to voxelize or quantize the (spatial) data into a\nsparse tensor.  Fortunately, the Minkowski Engine provides the quantization\nfunction (`MinkowskiEngine.utils.sparse_quantize`).\n\n\n### Creating a Network\n\n```python\nimport torch.nn as nn\nimport MinkowskiEngine as ME\n\nclass ExampleNetwork(ME.MinkowskiNetwork):\n\n    def __init__(self, in_feat, out_feat, D):\n        super(ExampleNetwork, self).__init__(D)\n        self.conv1 = nn.Sequential(\n            ME.MinkowskiConvolution(\n                in_channels=in_feat,\n                out_channels=64,\n                kernel_size=3,\n                stride=2,\n                dilation=1,\n                has_bias=False,\n                dimension=D),\n            ME.MinkowskiBatchNorm(64),\n            ME.MinkowskiReLU())\n        self.conv2 = nn.Sequential(\n            ME.MinkowskiConvolution(\n                in_channels=64,\n                out_channels=128,\n                kernel_size=3,\n                stride=2,\n                dimension=D),\n            ME.MinkowskiBatchNorm(128),\n            ME.MinkowskiReLU())\n        self.pooling = ME.MinkowskiGlobalPooling()\n        self.linear = ME.MinkowskiLinear(128, out_feat)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.conv2(out)\n        out = self.pooling(out)\n        return self.linear(out)\n```\n\n### Forward and backward using the custom network\n\n```python\n    # loss and network\n    criterion = nn.CrossEntropyLoss()\n    net = ExampleNetwork(in_feat=3, out_feat=5, D=2)\n    print(net)\n\n    # a data loader must return a tuple of coords, features, and labels.\n    coords, feat, label = data_loader()\n    input = ME.SparseTensor(feat, coords=coords)\n    # Forward\n    output = net(input)\n\n    # Loss\n    loss = criterion(output.F, label)\n```\n\n## Discussion and Documentation\n\nFor discussion and questions, please use `minkowskiengine@googlegroups.com`.\nFor API and general usage, please refer to the [MinkowskiEngine documentation\npage](http://stanfordvl.github.io/MinkowskiEngine/) for more detail.\n\nFor issues not listed on the API and feature requests, feel free to submit\nan issue on the [github issue\npage](https://github.com/StanfordVL/MinkowskiEngine/issues).\n\n\n## Citing Minkowski Engine\n\nIf you use the Minkowski Engine, please cite:\n\n- [4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks, CVPR'19](https://arxiv.org/abs/1904.08755), [[pdf]](https://arxiv.org/pdf/1904.08755.pdf)\n\n```\n@inproceedings{choy20194d,\n  title={4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks},\n  author={Choy, Christopher and Gwak, JunYoung and Savarese, Silvio},\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n  pages={3075--3084},\n  year={2019}\n}\n```\n\n## Projects using Minkowski Engine\n\n- [3D and 4D Spatio-Temporal Semantic Segmentation, CVPR'19](https://github.com/chrischoy/SpatioTemporalSegmentation)\n- [Fully Convolutional Geometric Features, ICCV'19](https://github.com/chrischoy/FCGF)\n- [Learning multiview 3D point cloud registration](https://arxiv.org/abs/2001.05119)", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/StanfordVL/MinkowskiEngine", "keywords": "pytorch,Minkowski Engine,Sparse Tensor,Convolutional Neural Networks,3D Vision,Deep Learning", "license": "", "maintainer": "", "maintainer_email": "", "name": "MinkowskiEngine", "package_url": "https://pypi.org/project/MinkowskiEngine/", "platform": "", "project_url": "https://pypi.org/project/MinkowskiEngine/", "project_urls": {"Homepage": "https://github.com/StanfordVL/MinkowskiEngine"}, "release_url": "https://pypi.org/project/MinkowskiEngine/0.4.2/", "requires_dist": null, "requires_python": ">=3.6", "summary": "a convolutional neural network library for sparse tensors", "version": "0.4.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Minkowski Engine</h1>\n<p><a href=\"https://pypi.org/project/MinkowskiEngine/\" rel=\"nofollow\"><img alt=\"PyPI Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b1398f21d84e76e5c0d16a48f43940d70350abeb/68747470733a2f2f62616467652e667572792e696f2f70792f4d696e6b6f77736b69456e67696e652e737667\"></a> <a href=\"https://gitter.im/MinkowskiEngineGitter/general\" rel=\"nofollow\"><img alt=\"Join the chat at https://gitter.im/MinkowskiEngineGitter/general\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/454be82554a06af0fd3393415ef17b59d8550498/68747470733a2f2f6261646765732e6769747465722e696d2f4a6f696e253230436861742e737667\"></a></p>\n<p>The Minkowski Engine is an auto-differentiation library for sparse tensors. It supports all standard neural network layers such as convolution, pooling, unpooling, and broadcasting operations for sparse tensors. For more information, please visit <a href=\"http://stanfordvl.github.io/MinkowskiEngine/overview.html\" rel=\"nofollow\">the documentation page</a>.</p>\n<h2>Example Networks</h2>\n<p>The Minkowski Engine supports various functions that can be built on a sparse tensor. We list a few popular network architectures and applications here. To run the examples, please install the package and run the command in the package root directory.</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">Examples</th>\n<th align=\"center\">Networks and Commands</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">Semantic Segmentation</td>\n<td align=\"center\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/39e949d4a80f86856e01508a94a19a0f38646644/68747470733a2f2f7374616e666f7264766c2e6769746875622e696f2f4d696e6b6f77736b69456e67696e652f5f696d616765732f7365676d656e746174696f6e5f33645f6e65742e706e67\"> <br> <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/7f82d9424c93600b2b3b3aed3bbf4dd30e507d25/68747470733a2f2f7374616e666f7264766c2e6769746875622e696f2f4d696e6b6f77736b69456e67696e652f5f696d616765732f7365676d656e746174696f6e2e706e67\" width=\"256\"> <br> <code>python -m examples.indoor</code></td>\n</tr>\n<tr>\n<td align=\"center\">Classification</td>\n<td align=\"center\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1eeb673144cbcd5cd7878b00fdb94e5498111c5f/68747470733a2f2f7374616e666f7264766c2e6769746875622e696f2f4d696e6b6f77736b69456e67696e652f5f696d616765732f636c617373696669636174696f6e5f33645f6e65742e706e67\"> <br> <code>python -m examples.modelnet40</code></td>\n</tr>\n<tr>\n<td align=\"center\">Reconstruction</td>\n<td align=\"center\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/26b70b193fadc6dd2ebbaa2ae8387b879522937d/68747470733a2f2f7374616e666f7264766c2e6769746875622e696f2f4d696e6b6f77736b69456e67696e652f5f696d616765732f67656e657261746976655f33645f6e65742e706e67\"> <br> <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e00d228d5f7373daecc79c48a172c69f5e5aff39/68747470733a2f2f7374616e666f7264766c2e6769746875622e696f2f4d696e6b6f77736b69456e67696e652f5f696d616765732f67656e657261746976655f33645f726573756c74732e676966\" width=\"256\"> <br> <code>python -m examples.reconstruction</code></td>\n</tr>\n<tr>\n<td align=\"center\">Completion</td>\n<td align=\"center\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1b7377de0eac712ec3f246c8d7b61d32e429106e/68747470733a2f2f7374616e666f7264766c2e6769746875622e696f2f4d696e6b6f77736b69456e67696e652f5f696d616765732f636f6d706c6574696f6e5f33645f6e65742e706e67\"> <br> <code>python -m examples.completion</code></td>\n</tr></tbody></table>\n<h2>Sparse Tensor Networks: Neural Networks for Spatially Sparse Tensors</h2>\n<p>Compressing a neural network to speedup inference and minimize memory footprint has been studied widely. One of the popular techniques for model compression is pruning the weights in convnets, is also known as <a href=\"https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Liu_Sparse_Convolutional_Neural_2015_CVPR_paper.pdf\" rel=\"nofollow\"><em>sparse convolutional networks</em></a>. Such parameter-space sparsity used for model compression compresses networks that operate on dense tensors and all intermediate activations of these networks are also dense tensors.</p>\n<p>However, in this work, we focus on <a href=\"https://arxiv.org/abs/1409.6070\" rel=\"nofollow\"><em>spatially</em> sparse data</a>, in particular, spatially sparse high-dimensional inputs. We can also represent these data as sparse tensors, and these sparse tensors are commonplace in high-dimensional problems such as 3D perception, registration, and statistical data. We define neural networks specialized for these inputs as <em>sparse tensor networks</em>  and these sparse tensor networks process and generate sparse tensors as outputs. To construct a sparse tensor network, we build all standard neural network layers such as MLPs, non-linearities, convolution, normalizations, pooling operations as the same way we define them on a dense tensor and implemented in the Minkowski Engine.</p>\n<p>We visualized a sparse tensor network operation on a sparse tensor, convolution, below. The convolution layer on a sparse tensor works similarly to that on a dense tensor. However, on a sparse tensor, we compute convolution outputs on a few specified points which we can control in the <a href=\"https://stanfordvl.github.io/MinkowskiEngine/sparse_tensor_network.html\" rel=\"nofollow\">generalized convolution</a>. For more information, please visit <a href=\"https://stanfordvl.github.io/MinkowskiEngine/sparse_tensor_network.html\" rel=\"nofollow\">the documentation page on sparse tensor networks</a> and <a href=\"https://stanfordvl.github.io/MinkowskiEngine/terminology.html\" rel=\"nofollow\">the terminology page</a>.</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">Dense Tensor</th>\n<th align=\"center\">Sparse Tensor</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2572bc9ea33affe02e2bf71f793886f8bbcd2e6b/68747470733a2f2f7374616e666f7264766c2e6769746875622e696f2f4d696e6b6f77736b69456e67696e652f5f696d616765732f636f6e765f64656e73652e676966\"></td>\n<td align=\"center\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5b0a0ec9edd217eed4a57d22ea3d1f906f95d63d/68747470733a2f2f7374616e666f7264766c2e6769746875622e696f2f4d696e6b6f77736b69456e67696e652f5f696d616765732f636f6e765f7370617273652e676966\"></td>\n</tr></tbody></table>\n<hr>\n<h2>Features</h2>\n<ul>\n<li>Unlimited high-dimensional sparse tensor support</li>\n<li>All standard neural network layers (Convolution, Pooling, Broadcast, etc.)</li>\n<li>Dynamic computation graph</li>\n<li>Custom kernel shapes</li>\n<li>Multi-GPU training</li>\n<li>Multi-threaded kernel map</li>\n<li>Multi-threaded compilation</li>\n<li>Highly-optimized GPU kernels</li>\n</ul>\n<h2>Requirements</h2>\n<ul>\n<li>Ubuntu 14.04 or higher</li>\n<li>CUDA 10.1 or higher</li>\n<li>pytorch 1.3 or higher</li>\n<li>python 3.6 or higher</li>\n<li>GCC 6 or higher</li>\n</ul>\n<h2>Installation</h2>\n<p>You can install the Minkowski Engine with <code>pip</code>, with anaconda, or on the system directly. If you experience issues installing the package, please checkout the <a href=\"https://stanfordvl.github.io/MinkowskiEngine/issues.html\" rel=\"nofollow\">common compilation issues page</a> or <a href=\"https://github.com/StanfordVL/MinkowskiEngine/wiki/Installation\" rel=\"nofollow\">the installation wiki page</a>.\nIf you cannot find a relevant problem, please report the issue on <a href=\"https://github.com/StanfordVL/MinkowskiEngine/issues\" rel=\"nofollow\">the github issue page</a>.</p>\n<h3>Pip</h3>\n<p>The MinkowskiEngine is distributed via <a href=\"https://pypi.org/project/MinkowskiEngine/\" rel=\"nofollow\">PyPI MinkowskiEngine</a> which can be installed simply with <code>pip</code>.\nFirst, install pytorch following the <a href=\"https://pytorch.org\" rel=\"nofollow\">instruction</a>. Next, install <code>openblas</code>.</p>\n<pre><code>sudo apt install libopenblas-dev\npip3 install torch\npip3 install -U MinkowskiEngine\n</code></pre>\n<h3>Pip from the latest source</h3>\n<pre><code>sudo apt install libopenblas-dev\npip3 install torch\npip3 install -U -I git+https://github.com/StanfordVL/MinkowskiEngine\n</code></pre>\n<h3>Anaconda</h3>\n<p>We recommend <code>python&gt;=3.6</code> for installation.</p>\n<h4>1. Create a conda virtual environment and install requirements.</h4>\n<p>First, follow <a href=\"https://docs.anaconda.com/anaconda/install/\" rel=\"nofollow\">the anaconda documentation</a> to install anaconda on your computer.</p>\n<pre><code>conda create -n py3-mink python=3.7\nconda activate py3-mink\nconda install numpy mkl-include\nconda install pytorch -c pytorch\n</code></pre>\n<h4>2. Compilation and installation</h4>\n<pre><code>conda activate py3-mink\ngit clone https://github.com/StanfordVL/MinkowskiEngine.git\ncd MinkowskiEngine\npython setup.py install\n</code></pre>\n<h3>System Python</h3>\n<p>Like the anaconda installation, make sure that you install pytorch with the same CUDA version that <code>nvcc</code> uses.</p>\n<pre><code># install system requirements\nsudo apt install python3-dev libopenblas-dev\n\n# Skip if you already have pip installed on your python3\ncurl https://bootstrap.pypa.io/get-pip.py | python3\n\n# Get pip and install python requirements\npython3 -m pip install torch numpy\n\ngit clone https://github.com/StanfordVL/MinkowskiEngine.git\n\ncd MinkowskiEngine\n\npython setup.py install\n</code></pre>\n<h2>CPU only build and BLAS configuration (MKL)</h2>\n<p>The Minkowski Engine supports CPU only build on other platforms that do not have NVidia GPUs. Please refer to <a href=\"https://stanfordvl.github.io/MinkowskiEngine/quick_start.html\" rel=\"nofollow\">quick start</a> for more details.</p>\n<h2>Quick Start</h2>\n<p>To use the Minkowski Engine, you first would need to import the engine.\nThen, you would need to define the network. If the data you have is not\nquantized, you would need to voxelize or quantize the (spatial) data into a\nsparse tensor.  Fortunately, the Minkowski Engine provides the quantization\nfunction (<code>MinkowskiEngine.utils.sparse_quantize</code>).</p>\n<h3>Creating a Network</h3>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch.nn</span> <span class=\"k\">as</span> <span class=\"nn\">nn</span>\n<span class=\"kn\">import</span> <span class=\"nn\">MinkowskiEngine</span> <span class=\"k\">as</span> <span class=\"nn\">ME</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">ExampleNetwork</span><span class=\"p\">(</span><span class=\"n\">ME</span><span class=\"o\">.</span><span class=\"n\">MinkowskiNetwork</span><span class=\"p\">):</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">in_feat</span><span class=\"p\">,</span> <span class=\"n\">out_feat</span><span class=\"p\">,</span> <span class=\"n\">D</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">ExampleNetwork</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"n\">D</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv1</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n            <span class=\"n\">ME</span><span class=\"o\">.</span><span class=\"n\">MinkowskiConvolution</span><span class=\"p\">(</span>\n                <span class=\"n\">in_channels</span><span class=\"o\">=</span><span class=\"n\">in_feat</span><span class=\"p\">,</span>\n                <span class=\"n\">out_channels</span><span class=\"o\">=</span><span class=\"mi\">64</span><span class=\"p\">,</span>\n                <span class=\"n\">kernel_size</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span>\n                <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span>\n                <span class=\"n\">dilation</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span>\n                <span class=\"n\">has_bias</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n                <span class=\"n\">dimension</span><span class=\"o\">=</span><span class=\"n\">D</span><span class=\"p\">),</span>\n            <span class=\"n\">ME</span><span class=\"o\">.</span><span class=\"n\">MinkowskiBatchNorm</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">),</span>\n            <span class=\"n\">ME</span><span class=\"o\">.</span><span class=\"n\">MinkowskiReLU</span><span class=\"p\">())</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv2</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n            <span class=\"n\">ME</span><span class=\"o\">.</span><span class=\"n\">MinkowskiConvolution</span><span class=\"p\">(</span>\n                <span class=\"n\">in_channels</span><span class=\"o\">=</span><span class=\"mi\">64</span><span class=\"p\">,</span>\n                <span class=\"n\">out_channels</span><span class=\"o\">=</span><span class=\"mi\">128</span><span class=\"p\">,</span>\n                <span class=\"n\">kernel_size</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span>\n                <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span>\n                <span class=\"n\">dimension</span><span class=\"o\">=</span><span class=\"n\">D</span><span class=\"p\">),</span>\n            <span class=\"n\">ME</span><span class=\"o\">.</span><span class=\"n\">MinkowskiBatchNorm</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">),</span>\n            <span class=\"n\">ME</span><span class=\"o\">.</span><span class=\"n\">MinkowskiReLU</span><span class=\"p\">())</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">pooling</span> <span class=\"o\">=</span> <span class=\"n\">ME</span><span class=\"o\">.</span><span class=\"n\">MinkowskiGlobalPooling</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">linear</span> <span class=\"o\">=</span> <span class=\"n\">ME</span><span class=\"o\">.</span><span class=\"n\">MinkowskiLinear</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">out_feat</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n        <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv1</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv2</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">)</span>\n        <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">pooling</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">linear</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">)</span>\n</pre>\n<h3>Forward and backward using the custom network</h3>\n<pre>    <span class=\"c1\"># loss and network</span>\n    <span class=\"n\">criterion</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">CrossEntropyLoss</span><span class=\"p\">()</span>\n    <span class=\"n\">net</span> <span class=\"o\">=</span> <span class=\"n\">ExampleNetwork</span><span class=\"p\">(</span><span class=\"n\">in_feat</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">out_feat</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">D</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">net</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># a data loader must return a tuple of coords, features, and labels.</span>\n    <span class=\"n\">coords</span><span class=\"p\">,</span> <span class=\"n\">feat</span><span class=\"p\">,</span> <span class=\"n\">label</span> <span class=\"o\">=</span> <span class=\"n\">data_loader</span><span class=\"p\">()</span>\n    <span class=\"nb\">input</span> <span class=\"o\">=</span> <span class=\"n\">ME</span><span class=\"o\">.</span><span class=\"n\">SparseTensor</span><span class=\"p\">(</span><span class=\"n\">feat</span><span class=\"p\">,</span> <span class=\"n\">coords</span><span class=\"o\">=</span><span class=\"n\">coords</span><span class=\"p\">)</span>\n    <span class=\"c1\"># Forward</span>\n    <span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">net</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># Loss</span>\n    <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">criterion</span><span class=\"p\">(</span><span class=\"n\">output</span><span class=\"o\">.</span><span class=\"n\">F</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"p\">)</span>\n</pre>\n<h2>Discussion and Documentation</h2>\n<p>For discussion and questions, please use <code>minkowskiengine@googlegroups.com</code>.\nFor API and general usage, please refer to the <a href=\"http://stanfordvl.github.io/MinkowskiEngine/\" rel=\"nofollow\">MinkowskiEngine documentation\npage</a> for more detail.</p>\n<p>For issues not listed on the API and feature requests, feel free to submit\nan issue on the <a href=\"https://github.com/StanfordVL/MinkowskiEngine/issues\" rel=\"nofollow\">github issue\npage</a>.</p>\n<h2>Citing Minkowski Engine</h2>\n<p>If you use the Minkowski Engine, please cite:</p>\n<ul>\n<li><a href=\"https://arxiv.org/abs/1904.08755\" rel=\"nofollow\">4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks, CVPR'19</a>, <a href=\"https://arxiv.org/pdf/1904.08755.pdf\" rel=\"nofollow\">[pdf]</a></li>\n</ul>\n<pre><code>@inproceedings{choy20194d,\n  title={4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks},\n  author={Choy, Christopher and Gwak, JunYoung and Savarese, Silvio},\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n  pages={3075--3084},\n  year={2019}\n}\n</code></pre>\n<h2>Projects using Minkowski Engine</h2>\n<ul>\n<li><a href=\"https://github.com/chrischoy/SpatioTemporalSegmentation\" rel=\"nofollow\">3D and 4D Spatio-Temporal Semantic Segmentation, CVPR'19</a></li>\n<li><a href=\"https://github.com/chrischoy/FCGF\" rel=\"nofollow\">Fully Convolutional Geometric Features, ICCV'19</a></li>\n<li><a href=\"https://arxiv.org/abs/2001.05119\" rel=\"nofollow\">Learning multiview 3D point cloud registration</a></li>\n</ul>\n\n          </div>"}, "last_serial": 6810237, "releases": {"0.3.2": [{"comment_text": "", "digests": {"md5": "7eb33760e9a1593e8a7afed75103a591", "sha256": "0a63bb358df3f31151a1a286014e34e95d1287c008bb644db50c0bfad2ac06c7"}, "downloads": -1, "filename": "MinkowskiEngine-0.3.2.tar.gz", "has_sig": false, "md5_digest": "7eb33760e9a1593e8a7afed75103a591", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 97118, "upload_time": "2019-12-25T10:26:39", "upload_time_iso_8601": "2019-12-25T10:26:39.098704Z", "url": "https://files.pythonhosted.org/packages/77/7f/f1a468f7ff10f2b47441c3732604032df7c66dcb0e983d408747dff4569e/MinkowskiEngine-0.3.2.tar.gz", "yanked": false}], "0.3.3": [{"comment_text": "", "digests": {"md5": "f318a7569004a83427bbe2d8985afc59", "sha256": "ce06744206fa625815caed81793669bdbb46bd8753a9bdb213de8a278434de51"}, "downloads": -1, "filename": "MinkowskiEngine-0.3.3.tar.gz", "has_sig": false, "md5_digest": "f318a7569004a83427bbe2d8985afc59", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 103111, "upload_time": "2020-01-08T02:13:39", "upload_time_iso_8601": "2020-01-08T02:13:39.473345Z", "url": "https://files.pythonhosted.org/packages/d0/9b/951919938e9767baa15962a2662a087e8f0adf7716509ea3b4ced1c162bf/MinkowskiEngine-0.3.3.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "48a036a0150ef23961093016e0a88c0e", "sha256": "cc8e6c3ce7d8e2ae79fd492d6fbd96b61919c415933c9f93422af434b2e164e3"}, "downloads": -1, "filename": "MinkowskiEngine-0.4.0.tar.gz", "has_sig": false, "md5_digest": "48a036a0150ef23961093016e0a88c0e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 106026, "upload_time": "2020-01-27T07:12:32", "upload_time_iso_8601": "2020-01-27T07:12:32.683662Z", "url": "https://files.pythonhosted.org/packages/a3/b1/6d81bdea2e652cd4fd3ff280449b9b5b24055ca43e003e2d6fddbf9834c8/MinkowskiEngine-0.4.0.tar.gz", "yanked": false}], "0.4.1": [{"comment_text": "", "digests": {"md5": "dc3f14106365c78e29f7f0e2f5fcb734", "sha256": "c3018aafdeea590fc408f031447d6cd9cc9c22ded241c275944fd16b56df1b58"}, "downloads": -1, "filename": "MinkowskiEngine-0.4.1.tar.gz", "has_sig": false, "md5_digest": "dc3f14106365c78e29f7f0e2f5fcb734", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 106434, "upload_time": "2020-01-28T16:20:51", "upload_time_iso_8601": "2020-01-28T16:20:51.968894Z", "url": "https://files.pythonhosted.org/packages/dd/cd/0c763e1be0bebe50552bccb8196052c4d9ec4e028304857bcbed76f1efc0/MinkowskiEngine-0.4.1.tar.gz", "yanked": false}], "0.4.2": [{"comment_text": "", "digests": {"md5": "5b21e5f71b756bf4884a6dbdb1c59efd", "sha256": "911433888976f69db3a5e58308408e7f3263e4646d8ef79cbce6218c2cae0bae"}, "downloads": -1, "filename": "MinkowskiEngine-0.4.2.tar.gz", "has_sig": false, "md5_digest": "5b21e5f71b756bf4884a6dbdb1c59efd", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 108776, "upload_time": "2020-03-14T05:17:46", "upload_time_iso_8601": "2020-03-14T05:17:46.500313Z", "url": "https://files.pythonhosted.org/packages/d7/7c/3892a4d9ee70869b900ba06c750943e31c85fc2a165dc483e3b79cd61b39/MinkowskiEngine-0.4.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "5b21e5f71b756bf4884a6dbdb1c59efd", "sha256": "911433888976f69db3a5e58308408e7f3263e4646d8ef79cbce6218c2cae0bae"}, "downloads": -1, "filename": "MinkowskiEngine-0.4.2.tar.gz", "has_sig": false, "md5_digest": "5b21e5f71b756bf4884a6dbdb1c59efd", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 108776, "upload_time": "2020-03-14T05:17:46", "upload_time_iso_8601": "2020-03-14T05:17:46.500313Z", "url": "https://files.pythonhosted.org/packages/d7/7c/3892a4d9ee70869b900ba06c750943e31c85fc2a165dc483e3b79cd61b39/MinkowskiEngine-0.4.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:54:15 2020"}