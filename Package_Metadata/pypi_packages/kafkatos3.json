{"info": {"author": "Ben Corlett", "author_email": "ben.corlett@bgch.co.uk", "bugtrack_url": null, "classifiers": ["Development Status :: 1 - Planning", "Environment :: Console", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.6", "Topic :: Documentation", "Topic :: Software Development :: Libraries :: Python Modules", "Topic :: System :: Installation/Setup", "Topic :: System :: Software Distribution"], "description": "=========================\n KafkatoS3\n=========================\n\nArchive kafka message data to Amazon's s3.\n\nKafkatos3 is a daemon that connects to Kafka and consumes messages. These messages are written to the disk in a MAK format. At a set interval they are compressed and uploaded to S3.\n\nThe purpose of saving the messages is for long term storage for analysis of messages at a later date.\n\nInitially we started looking at programs like secor and bifrost to do this but found they didn't quite meet our requirements so we wrote our own.\n\n\nInstallation Instructions\n=========================\n\n- pip install kafkatos3\n- copy config/kafkatos3.cfg.example to kafkatos3.cfg\n- edit kafkatos3.cfg and put in your settings\n- Start kafkatos3 with:\n    kafkatos3 kafkatos3.cfg\n\n\nDevelopment Installation Instructions\n=====================================\n\n- python setup.py install\n\n\nConfiguration\n=============\n\nKafkatos3 uses the python multiprocess module rather than threading due to GIL limitations. It has three main settings to configure these:\n\nconsumer_processes = 1\ns3uploader_workers = 1\ncompressor_workers = 1\n\nTo utilise more than one core for consuming messages these should be increased.\n\nCompression\n-----------\n\nCurrently kafkatos3 calls gzip as an external call to compress the MAK files. This is not configurable yet.\n\n\nKafka Consumers\n---------------\n\nBy default kafatos3 will use the python kafka consumer (https://github.com/dpkp/kafka-python). This can be changed to the C++ kafka consumer (https://github.com/confluentinc/confluent-kafka-python).\n\nThis may be more performant than the python consumer although we have not tested this.\n\nIn order to install this you will need to pip install confluent-kafka. This requires that the c library from here: https://github.com/edenhill/librdkafka\n\nTo switch over the consumer, making the following change in the config file:\n\nconsumer_class = KafkaPythonConsumer\n\nto\n\nconsumer_class = KafkaConfluentConsumer\n\n\nRunning Over Multiple Instances\n===============================\n\nCurrently there is no supported way to kafkatos3 to run this on more than one machine. Although the shared storage option would work with limitations (see below).\n\nPossible options for the future:\n\n- With shared storage: This would work fine as long as all instances of kafkatos are using the same consumer group. However currently there is no locking for the compression and s3upload. To get this work currently you'd need to allocate one machine for the compression and one machine for the s3 uploading. The other machines should have their worker count set to 0 to avoid conflicts.\n\n- Without shared storage: The problem with not having shared storage is that kafka can reassign partitions to different consumers at the drop of a hat. This means you might get topicname-0_0-500_160811.mak file on one machine, but a couple of reassignments mid way through could mean you get another file like downstream-0_234-237_160811.mak on another machine. This may not be a problem for you. However, currently with the functionlity the way it is you may end up with orphaned inprogress files that need to be rotated. Only files the daemon is actively locking will get rotated.\n\n- Without shared storage and locked partitions: This solution avoids the problem of kafka assigning different partitions to different boxes randomly by fixing certain partitions to certain machines. However offers no resilience option. This would require some config changes and some tweaks to the consumers.\n\n\n\nMAK Format\n==========\n\nThe MAK (Message Archive Kafka) is a custom format created for the purpose of storing and archiving kafka messages.\n\nThis install comes with the following command line util which will parse and print the messages for you:\n\nkafkatos3_parse <filename>.mak\n\nCode examples to parse the mak files yourself can be found in the mak-example directory.\n\nThe message form has a header section to describe info about the file and then <key> <message> <offset> repeated over and over again.\n\n\nFuture Plans\n============\n\n- Add config options to lock files during compress and upload.\n- Add support of kafka 0.8 zookeeper offsets. Old consumer support.\n- Add support for kafka 0.10 timestamps in the messages and add to MAK format.\n- Add thread to check for unused inprogress files and rotate them out.\n- Add support for different compression and compression passwords.\n\nLicense\n=======\n\nCopyright 2016 Ben Corlett, Paul Makkar\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n\n\n", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/ConnectedHomes/kafkatos3", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "kafkatos3", "package_url": "https://pypi.org/project/kafkatos3/", "platform": "", "project_url": "https://pypi.org/project/kafkatos3/", "project_urls": {"Homepage": "https://github.com/ConnectedHomes/kafkatos3"}, "release_url": "https://pypi.org/project/kafkatos3/0.2.0/", "requires_dist": ["boto3", "kafka", "portalocker", "psutil", "setproctitle"], "requires_python": "", "summary": "Archive kafka messages to S3", "version": "0.2.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>Archive kafka message data to Amazon\u2019s s3.</p>\n<p>Kafkatos3 is a daemon that connects to Kafka and consumes messages. These messages are written to the disk in a MAK format. At a set interval they are compressed and uploaded to S3.</p>\n<p>The purpose of saving the messages is for long term storage for analysis of messages at a later date.</p>\n<p>Initially we started looking at programs like secor and bifrost to do this but found they didn\u2019t quite meet our requirements so we wrote our own.</p>\n<div id=\"installation-instructions\">\n<h2>Installation Instructions</h2>\n<ul>\n<li>pip install kafkatos3</li>\n<li>copy config/kafkatos3.cfg.example to kafkatos3.cfg</li>\n<li>edit kafkatos3.cfg and put in your settings</li>\n<li><dl>\n<dt>Start kafkatos3 with:</dt>\n<dd>kafkatos3 kafkatos3.cfg</dd>\n</dl>\n</li>\n</ul>\n</div>\n<div id=\"development-installation-instructions\">\n<h2>Development Installation Instructions</h2>\n<ul>\n<li>python setup.py install</li>\n</ul>\n</div>\n<div id=\"configuration\">\n<h2>Configuration</h2>\n<p>Kafkatos3 uses the python multiprocess module rather than threading due to GIL limitations. It has three main settings to configure these:</p>\n<p>consumer_processes = 1\ns3uploader_workers = 1\ncompressor_workers = 1</p>\n<p>To utilise more than one core for consuming messages these should be increased.</p>\n<div id=\"compression\">\n<h3>Compression</h3>\n<p>Currently kafkatos3 calls gzip as an external call to compress the MAK files. This is not configurable yet.</p>\n</div>\n<div id=\"kafka-consumers\">\n<h3>Kafka Consumers</h3>\n<p>By default kafatos3 will use the python kafka consumer (<a href=\"https://github.com/dpkp/kafka-python\" rel=\"nofollow\">https://github.com/dpkp/kafka-python</a>). This can be changed to the C++ kafka consumer (<a href=\"https://github.com/confluentinc/confluent-kafka-python\" rel=\"nofollow\">https://github.com/confluentinc/confluent-kafka-python</a>).</p>\n<p>This may be more performant than the python consumer although we have not tested this.</p>\n<p>In order to install this you will need to pip install confluent-kafka. This requires that the c library from here: <a href=\"https://github.com/edenhill/librdkafka\" rel=\"nofollow\">https://github.com/edenhill/librdkafka</a></p>\n<p>To switch over the consumer, making the following change in the config file:</p>\n<p>consumer_class = KafkaPythonConsumer</p>\n<p>to</p>\n<p>consumer_class = KafkaConfluentConsumer</p>\n</div>\n</div>\n<div id=\"running-over-multiple-instances\">\n<h2>Running Over Multiple Instances</h2>\n<p>Currently there is no supported way to kafkatos3 to run this on more than one machine. Although the shared storage option would work with limitations (see below).</p>\n<p>Possible options for the future:</p>\n<ul>\n<li>With shared storage: This would work fine as long as all instances of kafkatos are using the same consumer group. However currently there is no locking for the compression and s3upload. To get this work currently you\u2019d need to allocate one machine for the compression and one machine for the s3 uploading. The other machines should have their worker count set to 0 to avoid conflicts.</li>\n<li>Without shared storage: The problem with not having shared storage is that kafka can reassign partitions to different consumers at the drop of a hat. This means you might get topicname-0_0-500_160811.mak file on one machine, but a couple of reassignments mid way through could mean you get another file like downstream-0_234-237_160811.mak on another machine. This may not be a problem for you. However, currently with the functionlity the way it is you may end up with orphaned inprogress files that need to be rotated. Only files the daemon is actively locking will get rotated.</li>\n<li>Without shared storage and locked partitions: This solution avoids the problem of kafka assigning different partitions to different boxes randomly by fixing certain partitions to certain machines. However offers no resilience option. This would require some config changes and some tweaks to the consumers.</li>\n</ul>\n</div>\n<div id=\"mak-format\">\n<h2>MAK Format</h2>\n<p>The MAK (Message Archive Kafka) is a custom format created for the purpose of storing and archiving kafka messages.</p>\n<p>This install comes with the following command line util which will parse and print the messages for you:</p>\n<p>kafkatos3_parse &lt;filename&gt;.mak</p>\n<p>Code examples to parse the mak files yourself can be found in the mak-example directory.</p>\n<p>The message form has a header section to describe info about the file and then &lt;key&gt; &lt;message&gt; &lt;offset&gt; repeated over and over again.</p>\n</div>\n<div id=\"future-plans\">\n<h2>Future Plans</h2>\n<ul>\n<li>Add config options to lock files during compress and upload.</li>\n<li>Add support of kafka 0.8 zookeeper offsets. Old consumer support.</li>\n<li>Add support for kafka 0.10 timestamps in the messages and add to MAK format.</li>\n<li>Add thread to check for unused inprogress files and rotate them out.</li>\n<li>Add support for different compression and compression passwords.</li>\n</ul>\n</div>\n<div id=\"license\">\n<h2>License</h2>\n<p>Copyright 2016 Ben Corlett, Paul Makkar</p>\n<p>Licensed under the Apache License, Version 2.0 (the \u201cLicense\u201d);\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at</p>\n<blockquote>\n<a href=\"http://www.apache.org/licenses/LICENSE-2.0\" rel=\"nofollow\">http://www.apache.org/licenses/LICENSE-2.0</a></blockquote>\n<p>Unless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \u201cAS IS\u201d BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.</p>\n</div>\n\n          </div>"}, "last_serial": 3668639, "releases": {"0.1.2": [{"comment_text": "", "digests": {"md5": "a2ff339cc738a97077f9dcae97d59bd1", "sha256": "295770d0c987b9a572dcca11dd3c13626641efd0cfe3ff959bfd7c3ae4c3d471"}, "downloads": -1, "filename": "kafkatos3-0.1.2.tar.gz", "has_sig": false, "md5_digest": "a2ff339cc738a97077f9dcae97d59bd1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24473, "upload_time": "2016-10-12T15:10:37", "upload_time_iso_8601": "2016-10-12T15:10:37.872625Z", "url": "https://files.pythonhosted.org/packages/c8/2f/19e0a9e2f8665b78b989a55067aa7a1415c84b24bb5436c4f5d27a889986/kafkatos3-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "553c15c003ff8be87a619df8343f4d6a", "sha256": "509170b28b256be6740bc935b9a1c786e718be492e8f62204a5a6ff6dfb1bd87"}, "downloads": -1, "filename": "kafkatos3-0.1.3.tar.gz", "has_sig": false, "md5_digest": "553c15c003ff8be87a619df8343f4d6a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24457, "upload_time": "2016-10-18T10:01:58", "upload_time_iso_8601": "2016-10-18T10:01:58.367663Z", "url": "https://files.pythonhosted.org/packages/da/bc/42597f4d49073aba348b6badaa85d97666750372780c16adff49d4218e1e/kafkatos3-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "a94bd50f825ee5a66ba3626edd51effd", "sha256": "f10eceabd89b53c0101de4698baa6bb39dcd52816eadfd6ec46e1a22b18f39ea"}, "downloads": -1, "filename": "kafkatos3-0.1.4.tar.gz", "has_sig": false, "md5_digest": "a94bd50f825ee5a66ba3626edd51effd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 26284, "upload_time": "2016-11-17T11:13:46", "upload_time_iso_8601": "2016-11-17T11:13:46.848867Z", "url": "https://files.pythonhosted.org/packages/99/67/4bca72db3c7e99cd8e711ae004d6cb9fa6136b5dc119863d357cf4b98f5e/kafkatos3-0.1.4.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "a23458cc81421e93357ce6cd1a396718", "sha256": "5995763afdb89cab3a4399507cab3dbf907b894698ee500042a4bcb5fac44c29"}, "downloads": -1, "filename": "kafkatos3-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "a23458cc81421e93357ce6cd1a396718", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 22693, "upload_time": "2018-03-14T12:11:41", "upload_time_iso_8601": "2018-03-14T12:11:41.529749Z", "url": "https://files.pythonhosted.org/packages/89/80/ac061054b57668e9150bf7266953cc1d0457d8db0ed9f8a41f9588a757f8/kafkatos3-0.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f09712102ba56076751576237f2a3e28", "sha256": "34d429f1c42831019b23409ebc45163ef3003e6b92005577da98e834706ab3d1"}, "downloads": -1, "filename": "kafkatos3-0.2.0.tar.gz", "has_sig": false, "md5_digest": "f09712102ba56076751576237f2a3e28", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28985, "upload_time": "2018-03-14T12:11:44", "upload_time_iso_8601": "2018-03-14T12:11:44.866297Z", "url": "https://files.pythonhosted.org/packages/ea/ce/118f15d72f6761586fc4dbfc25852251aa4c6dda3740df0bf36d74e238da/kafkatos3-0.2.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "a23458cc81421e93357ce6cd1a396718", "sha256": "5995763afdb89cab3a4399507cab3dbf907b894698ee500042a4bcb5fac44c29"}, "downloads": -1, "filename": "kafkatos3-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "a23458cc81421e93357ce6cd1a396718", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 22693, "upload_time": "2018-03-14T12:11:41", "upload_time_iso_8601": "2018-03-14T12:11:41.529749Z", "url": "https://files.pythonhosted.org/packages/89/80/ac061054b57668e9150bf7266953cc1d0457d8db0ed9f8a41f9588a757f8/kafkatos3-0.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f09712102ba56076751576237f2a3e28", "sha256": "34d429f1c42831019b23409ebc45163ef3003e6b92005577da98e834706ab3d1"}, "downloads": -1, "filename": "kafkatos3-0.2.0.tar.gz", "has_sig": false, "md5_digest": "f09712102ba56076751576237f2a3e28", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28985, "upload_time": "2018-03-14T12:11:44", "upload_time_iso_8601": "2018-03-14T12:11:44.866297Z", "url": "https://files.pythonhosted.org/packages/ea/ce/118f15d72f6761586fc4dbfc25852251aa4c6dda3740df0bf36d74e238da/kafkatos3-0.2.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:50:50 2020"}