{"info": {"author": "Ingo Kleiber", "author_email": "ingo@kleiber.me", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Programming Language :: Python :: 3.6"], "description": "=============\nTextDirectory\n=============\n\n.. image:: https://img.shields.io/pypi/v/textdirectory.svg\n        :target: https://pypi.python.org/pypi/textdirectory\n\n.. image:: https://img.shields.io/travis/IngoKl/textdirectory.svg\n        :target: https://travis-ci.org/IngoKl/textdirectory\n\n.. image:: https://readthedocs.org/projects/textdirectory/badge/?version=latest\n        :target: https://textdirectory.readthedocs.io/en/latest/?badge=latest\n        :alt: Documentation Status\n\n|\n|\n\n.. image:: https://user-images.githubusercontent.com/16179317/39367680-cd409a00-4a37-11e8-8d42-0bed5a4e814b.png\n        :alt: TextDirectory\n\n*TextDirectory* allows you to combine multiple text files into one aggregated file. TextDirectory also supports matching\nfiles for certain criteria and applying transformations to the aggregated text.\n\n*TextDirectory* can be used as a mere tool (via the CLI) and as a Python library.\n\nOf course, everything *TextDirectory* does could be achieved in bash or PowerShell. However, there are certain\nuse-cases (e.g. when used as a library) in which it might be useful.\n\n\n* Free software: MIT license\n* Documentation: https://textdirectory.readthedocs.io.\n\nFeatures\n========\n* Aggregating multiple text files\n* Filtering documents/texts based on various parameters such as length, content, and random sampling\n* Transforming the aggregated text (e.g. transforming the text to lowercase)\n\n.. csv-table::\n   :header: \"Version\", \"Filters\", \"Transformations\"\n   :widths: 10, 30, 30\n\n   0.1.0, filter_by_max_chars(n int); filter_by_min_chars(n int); filter_by_max_tokens(n int); filter_by_min_tokens(n int); filter_by_contains(str); filter_by_not_contains(str); filter_by_random_sampling(n int; replace=False), transformation_lowercase\n   0.1.1, filter_by_chars_outliers(n sigmas int), transformation_remove_nl\n   0.1.2, filter_by_filename_contains(str), transformation_usas_en_semtag; transformation_uppercase; transformation_postag(spacy_model str)\n   0.1.3, filter_by_similar_documents(reference_file str; threshold float), transformation_remove_non_ascii; transformation_remove_non_alphanumerical\n   0.2.0, filter_by_max_filesize(max_kb int); filter_by_min_filesize(min_kb int), transformation_to_leetspeak; transformation_crude_spellchecker(language model str)\n   0.2.1, None, transformation_remove_stopwords(stopwords_source str; stopwords str [en]; spacy_model str; custom_stopwords str); transformation_remove_htmltags\n   0.3.0, None, transformation_remove_weird_tokens(spaCy model; remove_double_space=False); transformation_lemmatizer(spaCy model)\n\nQuickstart\n==========\nInstall *TextDirectory* via pip: ``pip install textdirectory``\n\n*TextDirectory*, as exemplified below, works with a two-stage model. After loading in your data (directory) you can iteratively select the files you want to process. In a second step you can perform transformations on the text before finally aggregating it.\n\n.. image:: https://user-images.githubusercontent.com/16179317/39367589-7f774116-4a37-11e8-9a09-5cbdf5f3311b.png\n        :alt: TextDirectory\n\nAs a Command-Line Tool\n~~~~~~~~~~~~~~~~~~~~~~\n*TextDirectory* comes equipped with a CLI.\n\nThe syntax for both the *filters* and *tranformations* works similarly. They are chained by adding slashes (/) and\nparameters are passed via commas (,): ``filter_by_min_tokens,5/filter_by_random_sampling,2``.\n\n**Example 1: A Very Simple Aggregation**\n\n``textdirectory --directory testdata --output_file aggregated.txt``\n\nThis will take all files (.txt) in *testdata* and then aggregates the files into a file called *aggregated.txt*.\n\n**Example 2: Applying Filters and Transformations**\n\nIn this example we want to filter the files based on their token count, perform a random sampling and finally transform all text to lowercase.\n\n``textdirectory --directory testdata --output_file aggregated.txt --filters filter_by_min_tokens,5/filter_by_random_sampling,2 --transformations transformation_lowercase``\n\nAfter passing two filters (*filter_by_min_tokens* and *filter_by_random_sampling*) we've applied the *transform_lowercase* transformation.\n\nThe resulting file will contain the content of two files that each have at least five tokens.\n\nAs a Python Library\n~~~~~~~~~~~~~~~~~~~\nIn order to demonstrate *TextDirectory* as a Python library, we'll recreate the second example from above:\n\n.. code:: python\n\n    import textdirectory\n    td = textdirectory.TextDirectory(directory='testdata')\n    td.load_files(recursive=False, filetype='txt', sort=True)\n    td.filter_by_min_tokens(5)\n    td.filter_by_random_sampling(2)\n    td.stage_transformation(['transformation_lowercase'])\n    td.aggregate_to_file('aggregated.txt')\n\nIf we wanted to keep working with the actual aggregated text, we could have called ``text = td.aggregate_to_memory()``.\n\nEvery applied filter will create a *state* (i.e. a checkpoint). If we want to go back to a previous state, we can print\nall states by calling ``td.print_saved_states()``. Previous states can then be loaded by\ncalling ``td.load_aggregation_state(state=0)``.\n\n\nIt's also possible to pass arguments to the individual transformations. In order to do this (at the moment) you have to adhere to the correct order of arguments.\n\n.. code:: python\n\n    # def transformation_remove_stopwords(text, stopwords_source='internal', stopwords='en', spacy_model='en_core_web_sm', custom_stopwords=None, *args)\n    td.stage_transformation(['transformation_remove_stopwords', 'internal', 'en', 'en_core_web_sm', 'dolor'])\n\nIn the above example, we are adding additional custom stopwords to the transformer.\n\nNotes for Developers\n====================\nIf you want to run tests, please use `python setup.py test`.\n\nTo-Do\n=======\n* Increasing test coverage\n* Writing better documentation\n* Adding better error handling (raw exception are, well ...)\n* Adding logging\n* Better handling of non-unicode files (e.g. by detecting and reporting the encoding)\n* Contemplating whether it makes sense to stage filters similarly to transformations\n* Allowing users to pass keyword arguments to transformers\n* Implementing autodoc (via Sphinx)\n\nBehavior\n=========\nWe are not holding the actual texts in memory. This leads to much more disk read activity (and time inefficiency), but\nsaves memory.\n\n``transformation_usas_en_semtag`` relies on the web version of `Paul Rayson's USAS Tagger\n<http://ucrel.lancs.ac.uk/usas/>`_. Don't use this transformation for large amounts of text, give credit, and\nconsider using their commercial product `Wmatrix <http://ucrel.lancs.ac.uk/wmatrix/>`_.\n\nCredits\n=======\nThis package is based on the `audreyr/cookiecutter-pypackage`_ coockiecutter template. The *crude spellchecker*\n(transformation) is implemented following Peter Norvig's excellent `tutorial`_.\n\n.. _Cookiecutter: https://github.com/audreyr/cookiecutter\n.. _`audreyr/cookiecutter-pypackage`: https://github.com/audreyr/cookiecutter-pypackage\n.. _`tutorial`: http://norvig.com/spell-correct.html\n\n\n=======\nHistory\n=======\n\n\n0.1.0 (2018-04-26)\n==================\n\n* Initial release\n* First release on PyPI.\n\n0.1.1 (2018-04-27)\n==================\n\n* added filter_by_chars_outliers\n* added transformation_remove_nl\n\n0.1.2 (2018-04-29)\n==================\n* added transformation_postag\n* added transformation_usas_en_semtag\n* added transformation_uppercase\n* added filter_by_filename_contains\n* added parameter support for transformations\n\n0.1.3 (2018-04-30)\n==================\n* filter_by_random_sampling now has a \"replacement\" option\n* changed from tabulate to an embedded function\n* added transformation_remove_non_ascii\n* added transformation_remove_non_alphanumerical\n* added filter_by_similar_documents\n\n0.1.4 (2018-04-02)\n==================\n* fixed an object mutation problem in the tabulate function\n\n0.2.0 (2018-05-13)\n==================\n* added transform_to_memory() function\n* added transformation_to_leetspeak() function\n* added transformation_crude_spellchecker\n* added filter_by_max_filesize\n* added filter_by_min_filesize\n* fixed a bug where load_files() would fail if there were no files\n\n0.2.1 (2019-06-13)\n==================\nadded transformation_remove_stopwords\nadded transformation_remove_htmltags\nfixed some minor bugs\n\n0.2.2 (2019-06-13)\n==================\nchanged the data packaging\n\n0.3.0 (2020-01-19)\n==================\n* added transformation_remove_weird_tokens\n* added transformation_lemmatizer\n* fixed some minor bugs\n* added a function to revert applied filters\n* added a function that prints the current pipeline\n* added a function that clears all transformations\n* added helper functions to list available filters and transformations\n* fixed a bug in which ``tabulate_flat_list_of_dicts`` would fail if the dictionary was empty\n* ``self.aggregation`` does not hold a copy of the files anymore but references to ``self.files``\n* transformations relying on spaCy are now estimating a max_length based on available memory\n* TextDirectory objects are now iterable\n\n0.3.1 (2020-01-20)\n==================\n* added long_description_content_type to setup.py\n\n", "description_content_type": "text/x-rst", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/IngoKl/textdirectory", "keywords": "textdirectory", "license": "MIT license", "maintainer": "", "maintainer_email": "", "name": "textdirectory", "package_url": "https://pypi.org/project/textdirectory/", "platform": "", "project_url": "https://pypi.org/project/textdirectory/", "project_urls": {"Homepage": "https://github.com/IngoKl/textdirectory"}, "release_url": "https://pypi.org/project/textdirectory/0.3.1.1/", "requires_dist": ["Click (>=6.0)", "numpy", "requests", "beautifulsoup4", "spacy", "psutil", "en-core-web-sm", "twine"], "requires_python": "", "summary": "TextDirectory allows you to combine multiple text files into one.", "version": "0.3.1.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"textdirectory\">\n<h2>TextDirectory</h2>\n<a href=\"https://pypi.python.org/pypi/textdirectory\" rel=\"nofollow\"><img alt=\"https://img.shields.io/pypi/v/textdirectory.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e1dc58a8b7e70424850ce4ab40bcba5e824563fc/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f746578746469726563746f72792e737667\"></a>\n<a href=\"https://travis-ci.org/IngoKl/textdirectory\" rel=\"nofollow\"><img alt=\"https://img.shields.io/travis/IngoKl/textdirectory.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1fa93ee69482faa142502d52832c2058827a2d29/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f496e676f4b6c2f746578746469726563746f72792e737667\"></a>\n<a href=\"https://textdirectory.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/17b8ec9e75c57b6e010000e81fc83a68fc3b18d9/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f746578746469726563746f72792f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<div>\n<div><br></div>\n<div><br></div>\n</div>\n<img alt=\"TextDirectory\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/93aaf6a9f181d489308ada00cbf931dab14c8269/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31363137393331372f33393336373638302d63643430396130302d346133372d313165382d386434322d3062656435613465383134622e706e67\">\n<p><em>TextDirectory</em> allows you to combine multiple text files into one aggregated file. TextDirectory also supports matching\nfiles for certain criteria and applying transformations to the aggregated text.</p>\n<p><em>TextDirectory</em> can be used as a mere tool (via the CLI) and as a Python library.</p>\n<p>Of course, everything <em>TextDirectory</em> does could be achieved in bash or PowerShell. However, there are certain\nuse-cases (e.g. when used as a library) in which it might be useful.</p>\n<ul>\n<li>Free software: MIT license</li>\n<li>Documentation: <a href=\"https://textdirectory.readthedocs.io\" rel=\"nofollow\">https://textdirectory.readthedocs.io</a>.</li>\n</ul>\n<div id=\"features\">\n<h3>Features</h3>\n<ul>\n<li>Aggregating multiple text files</li>\n<li>Filtering documents/texts based on various parameters such as length, content, and random sampling</li>\n<li>Transforming the aggregated text (e.g. transforming the text to lowercase)</li>\n</ul>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Version</th>\n<th>Filters</th>\n<th>Transformations</th>\n</tr>\n</thead>\n<tbody>\n<tr><td>0.1.0</td>\n<td>filter_by_max_chars(n int); filter_by_min_chars(n int); filter_by_max_tokens(n int); filter_by_min_tokens(n int); filter_by_contains(str); filter_by_not_contains(str); filter_by_random_sampling(n int; replace=False)</td>\n<td>transformation_lowercase</td>\n</tr>\n<tr><td>0.1.1</td>\n<td>filter_by_chars_outliers(n sigmas int)</td>\n<td>transformation_remove_nl</td>\n</tr>\n<tr><td>0.1.2</td>\n<td>filter_by_filename_contains(str)</td>\n<td>transformation_usas_en_semtag; transformation_uppercase; transformation_postag(spacy_model str)</td>\n</tr>\n<tr><td>0.1.3</td>\n<td>filter_by_similar_documents(reference_file str; threshold float)</td>\n<td>transformation_remove_non_ascii; transformation_remove_non_alphanumerical</td>\n</tr>\n<tr><td>0.2.0</td>\n<td>filter_by_max_filesize(max_kb int); filter_by_min_filesize(min_kb int)</td>\n<td>transformation_to_leetspeak; transformation_crude_spellchecker(language model str)</td>\n</tr>\n<tr><td>0.2.1</td>\n<td>None</td>\n<td>transformation_remove_stopwords(stopwords_source str; stopwords str [en]; spacy_model str; custom_stopwords str); transformation_remove_htmltags</td>\n</tr>\n<tr><td>0.3.0</td>\n<td>None</td>\n<td>transformation_remove_weird_tokens(spaCy model; remove_double_space=False); transformation_lemmatizer(spaCy model)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<div id=\"quickstart\">\n<h3>Quickstart</h3>\n<p>Install <em>TextDirectory</em> via pip: <tt>pip install textdirectory</tt></p>\n<p><em>TextDirectory</em>, as exemplified below, works with a two-stage model. After loading in your data (directory) you can iteratively select the files you want to process. In a second step you can perform transformations on the text before finally aggregating it.</p>\n<img alt=\"TextDirectory\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/872433205e40e94ebedf14cc2ea5efcd6aca8507/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31363137393331372f33393336373538392d37663737343131362d346133372d313165382d396130392d3563626466356633333131622e706e67\">\n<div id=\"as-a-command-line-tool\">\n<h4>As a Command-Line Tool</h4>\n<p><em>TextDirectory</em> comes equipped with a CLI.</p>\n<p>The syntax for both the <em>filters</em> and <em>tranformations</em> works similarly. They are chained by adding slashes (/) and\nparameters are passed via commas (,): <tt>filter_by_min_tokens,5/filter_by_random_sampling,2</tt>.</p>\n<p><strong>Example 1: A Very Simple Aggregation</strong></p>\n<p><tt>textdirectory <span class=\"pre\">--directory</span> testdata <span class=\"pre\">--output_file</span> aggregated.txt</tt></p>\n<p>This will take all files (.txt) in <em>testdata</em> and then aggregates the files into a file called <em>aggregated.txt</em>.</p>\n<p><strong>Example 2: Applying Filters and Transformations</strong></p>\n<p>In this example we want to filter the files based on their token count, perform a random sampling and finally transform all text to lowercase.</p>\n<p><tt>textdirectory <span class=\"pre\">--directory</span> testdata <span class=\"pre\">--output_file</span> aggregated.txt <span class=\"pre\">--filters</span> filter_by_min_tokens,5/filter_by_random_sampling,2 <span class=\"pre\">--transformations</span> transformation_lowercase</tt></p>\n<p>After passing two filters (<em>filter_by_min_tokens</em> and <em>filter_by_random_sampling</em>) we\u2019ve applied the <em>transform_lowercase</em> transformation.</p>\n<p>The resulting file will contain the content of two files that each have at least five tokens.</p>\n</div>\n<div id=\"as-a-python-library\">\n<h4>As a Python Library</h4>\n<p>In order to demonstrate <em>TextDirectory</em> as a Python library, we\u2019ll recreate the second example from above:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">textdirectory</span>\n<span class=\"n\">td</span> <span class=\"o\">=</span> <span class=\"n\">textdirectory</span><span class=\"o\">.</span><span class=\"n\">TextDirectory</span><span class=\"p\">(</span><span class=\"n\">directory</span><span class=\"o\">=</span><span class=\"s1\">'testdata'</span><span class=\"p\">)</span>\n<span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">load_files</span><span class=\"p\">(</span><span class=\"n\">recursive</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">filetype</span><span class=\"o\">=</span><span class=\"s1\">'txt'</span><span class=\"p\">,</span> <span class=\"n\">sort</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">filter_by_min_tokens</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n<span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">filter_by_random_sampling</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n<span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">stage_transformation</span><span class=\"p\">([</span><span class=\"s1\">'transformation_lowercase'</span><span class=\"p\">])</span>\n<span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">aggregate_to_file</span><span class=\"p\">(</span><span class=\"s1\">'aggregated.txt'</span><span class=\"p\">)</span>\n</pre>\n<p>If we wanted to keep working with the actual aggregated text, we could have called <tt>text = td.aggregate_to_memory()</tt>.</p>\n<p>Every applied filter will create a <em>state</em> (i.e. a checkpoint). If we want to go back to a previous state, we can print\nall states by calling <tt>td.print_saved_states()</tt>. Previous states can then be loaded by\ncalling <tt>td.load_aggregation_state(state=0)</tt>.</p>\n<p>It\u2019s also possible to pass arguments to the individual transformations. In order to do this (at the moment) you have to adhere to the correct order of arguments.</p>\n<pre><span class=\"c1\"># def transformation_remove_stopwords(text, stopwords_source='internal', stopwords='en', spacy_model='en_core_web_sm', custom_stopwords=None, *args)</span>\n<span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">stage_transformation</span><span class=\"p\">([</span><span class=\"s1\">'transformation_remove_stopwords'</span><span class=\"p\">,</span> <span class=\"s1\">'internal'</span><span class=\"p\">,</span> <span class=\"s1\">'en'</span><span class=\"p\">,</span> <span class=\"s1\">'en_core_web_sm'</span><span class=\"p\">,</span> <span class=\"s1\">'dolor'</span><span class=\"p\">])</span>\n</pre>\n<p>In the above example, we are adding additional custom stopwords to the transformer.</p>\n</div>\n</div>\n<div id=\"notes-for-developers\">\n<h3>Notes for Developers</h3>\n<p>If you want to run tests, please use <cite>python setup.py test</cite>.</p>\n</div>\n<div id=\"to-do\">\n<h3>To-Do</h3>\n<ul>\n<li>Increasing test coverage</li>\n<li>Writing better documentation</li>\n<li>Adding better error handling (raw exception are, well \u2026)</li>\n<li>Adding logging</li>\n<li>Better handling of non-unicode files (e.g. by detecting and reporting the encoding)</li>\n<li>Contemplating whether it makes sense to stage filters similarly to transformations</li>\n<li>Allowing users to pass keyword arguments to transformers</li>\n<li>Implementing autodoc (via Sphinx)</li>\n</ul>\n</div>\n<div id=\"behavior\">\n<h3>Behavior</h3>\n<p>We are not holding the actual texts in memory. This leads to much more disk read activity (and time inefficiency), but\nsaves memory.</p>\n<p><tt>transformation_usas_en_semtag</tt> relies on the web version of <a href=\"http://ucrel.lancs.ac.uk/usas/\" rel=\"nofollow\">Paul Rayson\u2019s USAS Tagger</a>. Don\u2019t use this transformation for large amounts of text, give credit, and\nconsider using their commercial product <a href=\"http://ucrel.lancs.ac.uk/wmatrix/\" rel=\"nofollow\">Wmatrix</a>.</p>\n</div>\n<div id=\"credits\">\n<h3>Credits</h3>\n<p>This package is based on the <a href=\"https://github.com/audreyr/cookiecutter-pypackage\" rel=\"nofollow\">audreyr/cookiecutter-pypackage</a> coockiecutter template. The <em>crude spellchecker</em>\n(transformation) is implemented following Peter Norvig\u2019s excellent <a href=\"http://norvig.com/spell-correct.html\" rel=\"nofollow\">tutorial</a>.</p>\n</div>\n</div>\n<div id=\"history\">\n<h2>History</h2>\n<div id=\"id1\">\n<h3>0.1.0 (2018-04-26)</h3>\n<ul>\n<li>Initial release</li>\n<li>First release on PyPI.</li>\n</ul>\n</div>\n<div id=\"id2\">\n<h3>0.1.1 (2018-04-27)</h3>\n<ul>\n<li>added filter_by_chars_outliers</li>\n<li>added transformation_remove_nl</li>\n</ul>\n</div>\n<div id=\"id3\">\n<h3>0.1.2 (2018-04-29)</h3>\n<ul>\n<li>added transformation_postag</li>\n<li>added transformation_usas_en_semtag</li>\n<li>added transformation_uppercase</li>\n<li>added filter_by_filename_contains</li>\n<li>added parameter support for transformations</li>\n</ul>\n</div>\n<div id=\"id4\">\n<h3>0.1.3 (2018-04-30)</h3>\n<ul>\n<li>filter_by_random_sampling now has a \u201creplacement\u201d option</li>\n<li>changed from tabulate to an embedded function</li>\n<li>added transformation_remove_non_ascii</li>\n<li>added transformation_remove_non_alphanumerical</li>\n<li>added filter_by_similar_documents</li>\n</ul>\n</div>\n<div id=\"id5\">\n<h3>0.1.4 (2018-04-02)</h3>\n<ul>\n<li>fixed an object mutation problem in the tabulate function</li>\n</ul>\n</div>\n<div id=\"id6\">\n<h3>0.2.0 (2018-05-13)</h3>\n<ul>\n<li>added transform_to_memory() function</li>\n<li>added transformation_to_leetspeak() function</li>\n<li>added transformation_crude_spellchecker</li>\n<li>added filter_by_max_filesize</li>\n<li>added filter_by_min_filesize</li>\n<li>fixed a bug where load_files() would fail if there were no files</li>\n</ul>\n</div>\n<div id=\"id7\">\n<h3>0.2.1 (2019-06-13)</h3>\n<p>added transformation_remove_stopwords\nadded transformation_remove_htmltags\nfixed some minor bugs</p>\n</div>\n<div id=\"id8\">\n<h3>0.2.2 (2019-06-13)</h3>\n<p>changed the data packaging</p>\n</div>\n<div id=\"id9\">\n<h3>0.3.0 (2020-01-19)</h3>\n<ul>\n<li>added transformation_remove_weird_tokens</li>\n<li>added transformation_lemmatizer</li>\n<li>fixed some minor bugs</li>\n<li>added a function to revert applied filters</li>\n<li>added a function that prints the current pipeline</li>\n<li>added a function that clears all transformations</li>\n<li>added helper functions to list available filters and transformations</li>\n<li>fixed a bug in which <tt>tabulate_flat_list_of_dicts</tt> would fail if the dictionary was empty</li>\n<li><tt>self.aggregation</tt> does not hold a copy of the files anymore but references to <tt>self.files</tt></li>\n<li>transformations relying on spaCy are now estimating a max_length based on available memory</li>\n<li>TextDirectory objects are now iterable</li>\n</ul>\n</div>\n<div id=\"id10\">\n<h3>0.3.1 (2020-01-20)</h3>\n<ul>\n<li>added long_description_content_type to setup.py</li>\n</ul>\n</div>\n</div>\n\n          </div>"}, "last_serial": 6484309, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "9dfa59c304fb89d17e00daf90e314e07", "sha256": "fa01cd7a4267ba538d25625f43b0444ba7964ec56925b7241de1a7ae11600032"}, "downloads": -1, "filename": "textdirectory-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "9dfa59c304fb89d17e00daf90e314e07", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 7294, "upload_time": "2018-04-27T13:24:30", "upload_time_iso_8601": "2018-04-27T13:24:30.246777Z", "url": "https://files.pythonhosted.org/packages/a1/3d/c99a1735b5e500e7ad8f40e58d39997d038403a82c4434e02677ebc98072/textdirectory-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "900f0c3460822ad87b675ebc185f2e4a", "sha256": "e5e2634f1d80ef6b633e18795f1126c5b349e12fea7eee840368466fec2c2938"}, "downloads": -1, "filename": "textdirectory-0.1.0.tar.gz", "has_sig": false, "md5_digest": "900f0c3460822ad87b675ebc185f2e4a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11030, "upload_time": "2018-04-27T13:24:31", "upload_time_iso_8601": "2018-04-27T13:24:31.395977Z", "url": "https://files.pythonhosted.org/packages/ac/0d/c695dd4aaf04126e9c98fa73357fdb5cddc74e016c2422ab5e40df16c54f/textdirectory-0.1.0.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "31c5d0d2bc75bde1745dcc711fbf9d05", "sha256": "fd0eea9a172cbb953b1211a169c501d1b527eebd47281d61ceb61705867318ec"}, "downloads": -1, "filename": "textdirectory-0.1.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "31c5d0d2bc75bde1745dcc711fbf9d05", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 10842, "upload_time": "2018-04-29T16:47:46", "upload_time_iso_8601": "2018-04-29T16:47:46.665349Z", "url": "https://files.pythonhosted.org/packages/7e/b6/034c56cd6c5fa37444b926e3c4764200711b82368c1c0edabc46767c6c00/textdirectory-0.1.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "eb1c138e3ceba7ad89c695d119c6b73d", "sha256": "7112d64abb93d23f68fe84cbb837f3b4e946b119bf88d5064604790186836408"}, "downloads": -1, "filename": "textdirectory-0.1.2.tar.gz", "has_sig": false, "md5_digest": "eb1c138e3ceba7ad89c695d119c6b73d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15119, "upload_time": "2018-04-29T16:47:48", "upload_time_iso_8601": "2018-04-29T16:47:48.221809Z", "url": "https://files.pythonhosted.org/packages/cc/ac/b262c793628858a67a2b256803528de57848d919899afd3efda7e35d7d1e/textdirectory-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "1b9a8b4a612f2755279a7180a93dc211", "sha256": "c3ac9d91f5d9a9daab5b64a06d7ed6588ebd1a66afb70034b90ce7f5b749da1d"}, "downloads": -1, "filename": "textdirectory-0.1.3-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "1b9a8b4a612f2755279a7180a93dc211", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 12255, "upload_time": "2018-04-30T21:28:39", "upload_time_iso_8601": "2018-04-30T21:28:39.594984Z", "url": "https://files.pythonhosted.org/packages/88/4c/a48b4dc25c13e4f3aea6c497e30595240aae9b72f60645f843ba34e8d521/textdirectory-0.1.3-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "51f23add19b369faec806699ab8ec592", "sha256": "5563836b58b380996eb489c68557c0fcc1d55beecc3af32c3b88a74011f24916"}, "downloads": -1, "filename": "textdirectory-0.1.3.tar.gz", "has_sig": false, "md5_digest": "51f23add19b369faec806699ab8ec592", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22945, "upload_time": "2018-04-30T21:28:42", "upload_time_iso_8601": "2018-04-30T21:28:42.033766Z", "url": "https://files.pythonhosted.org/packages/a0/6b/82ffab0692ac9f9fed201c406a30f0c66a9c1e5b7e03e2ad434aa966e60f/textdirectory-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "3f2c6b8e69090834b20985c855f830b4", "sha256": "bd674a12328042cc8f55b65ca270805564a06aab1b9b32b9b84bd866cc805692"}, "downloads": -1, "filename": "textdirectory-0.1.4-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "3f2c6b8e69090834b20985c855f830b4", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 12412, "upload_time": "2018-05-02T12:18:57", "upload_time_iso_8601": "2018-05-02T12:18:57.123679Z", "url": "https://files.pythonhosted.org/packages/22/9f/938d8b38eaa2e04849e2ccf829951a9da2813a8b8db109f8b6264d5e6b45/textdirectory-0.1.4-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cd13396ecef704d39a731df01aa8ccf8", "sha256": "8ae1d01633e160590a344954c32f5ce386ddd2ce0176bc74321f6456806ae0ad"}, "downloads": -1, "filename": "textdirectory-0.1.4.tar.gz", "has_sig": false, "md5_digest": "cd13396ecef704d39a731df01aa8ccf8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17817, "upload_time": "2018-05-02T12:18:58", "upload_time_iso_8601": "2018-05-02T12:18:58.082801Z", "url": "https://files.pythonhosted.org/packages/90/28/f2cbc73d1dcbf4eee2ab49877726c66848f9c1db2fc1ac8943a94ae73685/textdirectory-0.1.4.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "19871d49fde4451372431fe67a68d4a4", "sha256": "5d1070f016a8e5c80882a02991c3993c10f6fbbf711af30f8402e89b5a03ce65"}, "downloads": -1, "filename": "textdirectory-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "19871d49fde4451372431fe67a68d4a4", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 15235, "upload_time": "2018-05-13T14:40:23", "upload_time_iso_8601": "2018-05-13T14:40:23.837368Z", "url": "https://files.pythonhosted.org/packages/bd/00/ae8f1c153f758fca8ae3ef794435a6da876f93130f03d5d8aa38ac58999a/textdirectory-0.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f93ff3c5779e3ef8abd983364925e71c", "sha256": "5c3b42c1aabc6cb07668413da052802ef9af943c1c60ce1842316af5575809cf"}, "downloads": -1, "filename": "textdirectory-0.2.0.tar.gz", "has_sig": false, "md5_digest": "f93ff3c5779e3ef8abd983364925e71c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20589, "upload_time": "2018-05-13T14:40:25", "upload_time_iso_8601": "2018-05-13T14:40:25.226011Z", "url": "https://files.pythonhosted.org/packages/20/42/b953c62a08b9881858f1ebb116d1ba2d9dd224118ebca9f54d7ac768553a/textdirectory-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "cc818dea2ffdce59c03fdd6ae5a48b47", "sha256": "3cb99a771ca7c47f919197af453feb34201d551f4e8391a5c2f1a29010dfd989"}, "downloads": -1, "filename": "textdirectory-0.2.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "cc818dea2ffdce59c03fdd6ae5a48b47", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 13269, "upload_time": "2019-06-13T12:28:52", "upload_time_iso_8601": "2019-06-13T12:28:52.107702Z", "url": "https://files.pythonhosted.org/packages/3c/74/097ebbf63c234ecf39b8fa16bf011585214f4fb58c953de69912438e6720/textdirectory-0.2.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "783cf331bf9d798f0b3256dbda16b8ec", "sha256": "100f712062508b3b267bde9bf84731d39bbf442767fcfe4ba880deb02b3ae09c"}, "downloads": -1, "filename": "textdirectory-0.2.1.tar.gz", "has_sig": false, "md5_digest": "783cf331bf9d798f0b3256dbda16b8ec", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21467, "upload_time": "2019-06-13T12:28:53", "upload_time_iso_8601": "2019-06-13T12:28:53.815956Z", "url": "https://files.pythonhosted.org/packages/08/45/f4d73d4ee9cf73405be138acf3b254d2472e7acb6bab87199e18b70457b3/textdirectory-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "2ddb4bf0eb146b9d68c772f902562b9c", "sha256": "d8f8f5a632b5bcd7d52a4a64d765004310046c636070ad5657fa620eb20011a9"}, "downloads": -1, "filename": "textdirectory-0.2.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "2ddb4bf0eb146b9d68c772f902562b9c", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 12288038, "upload_time": "2019-06-13T13:59:52", "upload_time_iso_8601": "2019-06-13T13:59:52.030196Z", "url": "https://files.pythonhosted.org/packages/7d/77/73fc13c178a976a4b991de92873341b6cae7f74e9a8aadfe39805dc458e5/textdirectory-0.2.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ff756268f2c104be75002204657965f4", "sha256": "419f7e4c272d2439a2f0bdd8f99254b9259c1c0279aff8bde3d90b343c4e9193"}, "downloads": -1, "filename": "textdirectory-0.2.2.tar.gz", "has_sig": false, "md5_digest": "ff756268f2c104be75002204657965f4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6159019, "upload_time": "2019-06-13T13:59:55", "upload_time_iso_8601": "2019-06-13T13:59:55.851123Z", "url": "https://files.pythonhosted.org/packages/60/35/59a8fe5368dc0cf5ed084f050cd7b68e6847b79bae66dd7546b8ead65d28/textdirectory-0.2.2.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "3d78df9bbe796a91c7874aa376b50a5e", "sha256": "0c910709bed9a101c2a3171f037ff8eba56b74c7badabea1fad0175b47d016a9"}, "downloads": -1, "filename": "textdirectory-0.3.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "3d78df9bbe796a91c7874aa376b50a5e", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 6154485, "upload_time": "2020-01-20T00:31:42", "upload_time_iso_8601": "2020-01-20T00:31:42.808906Z", "url": "https://files.pythonhosted.org/packages/ea/3b/7c325d02dbb92d2feaea5335d94cf846742b91e73b8052ffcef611ba4237/textdirectory-0.3.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "13d07752e256382f60d5af41cba20c8f", "sha256": "3e86318a3787a94475ce529b2bea6767a958c861cf242d1a25502d6dd0b5fb61"}, "downloads": -1, "filename": "textdirectory-0.3.0.tar.gz", "has_sig": false, "md5_digest": "13d07752e256382f60d5af41cba20c8f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6163409, "upload_time": "2020-01-20T00:31:49", "upload_time_iso_8601": "2020-01-20T00:31:49.457728Z", "url": "https://files.pythonhosted.org/packages/e2/24/4c731e0cceb4f3d328438cfd5a861a38974aa0ddb5fa38e15852dbf691ff/textdirectory-0.3.0.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "ec99ef45915114ce91d3352e8b2e2a9f", "sha256": "22c7b4eee366d80be4a2e7f8f27215a831019a72007f1cfc7cc6af678746a76f"}, "downloads": -1, "filename": "textdirectory-0.3.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "ec99ef45915114ce91d3352e8b2e2a9f", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 6154538, "upload_time": "2020-01-20T00:36:25", "upload_time_iso_8601": "2020-01-20T00:36:25.664244Z", "url": "https://files.pythonhosted.org/packages/c7/b7/53bbe517af9b4cd805eb1479dc83010a2f25d7431fc8458dbcf03c6b45a6/textdirectory-0.3.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "09c4e45dd1ed0326e55010e45afe78e1", "sha256": "eb99563656111193fef78225f099dbbcc924979214a3eb147bdaf444d1a6429b"}, "downloads": -1, "filename": "textdirectory-0.3.1.tar.gz", "has_sig": false, "md5_digest": "09c4e45dd1ed0326e55010e45afe78e1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6163539, "upload_time": "2020-01-20T00:36:32", "upload_time_iso_8601": "2020-01-20T00:36:32.438261Z", "url": "https://files.pythonhosted.org/packages/71/b6/492d5a992e56beb186e16399fed811df38b51275bc635a71c90e3b22d431/textdirectory-0.3.1.tar.gz", "yanked": false}], "0.3.1.1": [{"comment_text": "", "digests": {"md5": "123ab3c4be32f800ce155fd513fc532f", "sha256": "530093ef7902aa507ef99c6e239deb85b45514814bc4576936f432f73bedd1e5"}, "downloads": -1, "filename": "textdirectory-0.3.1.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "123ab3c4be32f800ce155fd513fc532f", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 6154547, "upload_time": "2020-01-20T00:54:54", "upload_time_iso_8601": "2020-01-20T00:54:54.796575Z", "url": "https://files.pythonhosted.org/packages/58/db/ec0b8d9a607de6a3959c215052ad88a135f305e66dd695163731f537ecd1/textdirectory-0.3.1.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "240d2899c9d74cffce40bda83b8d17ab", "sha256": "bd5470e64e62b47c4cec2c5226ef4ce7b8c832304648e2772aae0fbdfc87d7c1"}, "downloads": -1, "filename": "textdirectory-0.3.1.1.tar.gz", "has_sig": false, "md5_digest": "240d2899c9d74cffce40bda83b8d17ab", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6163473, "upload_time": "2020-01-20T00:55:01", "upload_time_iso_8601": "2020-01-20T00:55:01.856590Z", "url": "https://files.pythonhosted.org/packages/b1/f2/9fefbf89e9247dfdd2ce935f3e61c54c4c2cee13e56bd8c6be3d2ba94a1f/textdirectory-0.3.1.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "123ab3c4be32f800ce155fd513fc532f", "sha256": "530093ef7902aa507ef99c6e239deb85b45514814bc4576936f432f73bedd1e5"}, "downloads": -1, "filename": "textdirectory-0.3.1.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "123ab3c4be32f800ce155fd513fc532f", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 6154547, "upload_time": "2020-01-20T00:54:54", "upload_time_iso_8601": "2020-01-20T00:54:54.796575Z", "url": "https://files.pythonhosted.org/packages/58/db/ec0b8d9a607de6a3959c215052ad88a135f305e66dd695163731f537ecd1/textdirectory-0.3.1.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "240d2899c9d74cffce40bda83b8d17ab", "sha256": "bd5470e64e62b47c4cec2c5226ef4ce7b8c832304648e2772aae0fbdfc87d7c1"}, "downloads": -1, "filename": "textdirectory-0.3.1.1.tar.gz", "has_sig": false, "md5_digest": "240d2899c9d74cffce40bda83b8d17ab", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6163473, "upload_time": "2020-01-20T00:55:01", "upload_time_iso_8601": "2020-01-20T00:55:01.856590Z", "url": "https://files.pythonhosted.org/packages/b1/f2/9fefbf89e9247dfdd2ce935f3e61c54c4c2cee13e56bd8c6be3d2ba94a1f/textdirectory-0.3.1.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:55:04 2020"}