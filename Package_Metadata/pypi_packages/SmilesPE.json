{"info": {"author": "Xinhao Li", "author_email": "xli74@ncsu.edu", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: Apache Software License", "Natural Language :: English", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8"], "description": "# SMILES Pair Encoding (SmilesPE).\n> SMILES Pair Encoding (SmilesPE) trains a substructure tokenizer from a large set of SMILES strings (e.g., ChEMBL) based on [byte-pair-encoding (BPE)](https://www.aclweb.org/anthology/P16-1162/).\n\n\n## Overview\n\n## Installation\n\n```\npip install SmilesPE\n```\n\n## Usage Instructions\n\n### Basic Tokenizers\n\n1. Atom-level Tokenizer\n\n```python\nfrom SmilesPE.pretokenizer import atomwise_tokenizer\n\nsmi = 'CC[N+](C)(C)Cc1ccccc1Br'\ntoks = atomwise_tokenizer(smi)\nprint(toks)\n```\n\n    ['C', 'C', '[N+]', '(', 'C', ')', '(', 'C', ')', 'C', 'c', '1', 'c', 'c', 'c', 'c', 'c', '1', 'Br']\n\n\n2. K-mer Tokenzier\n\n```python\nfrom SmilesPE.pretokenizer import kmer_tokenizer\n\nsmi = 'CC[N+](C)(C)Cc1ccccc1Br'\ntoks = kmer_tokenizer(smi, ngram=4)\nprint(toks)\n```\n\n    ['CC[N+](', 'C[N+](C', '[N+](C)', '(C)(', 'C)(C', ')(C)', '(C)C', 'C)Cc', ')Cc1', 'Cc1c', 'c1cc', '1ccc', 'cccc', 'cccc', 'ccc1', 'cc1Br']\n\n\nThe basic tokenizers are also compatible with [SELFIES](https://github.com/aspuru-guzik-group/selfies) and [DeepSMILES](https://github.com/baoilleach/deepsmiles). Package installations are required.\n\nExample of SELFIES\n\n```python\nimport selfies\nsmi = 'CC[N+](C)(C)Cc1ccccc1Br'\nsel = selfies.encoder(smi)\nprint(f'SELFIES string: {sel}')\n> >> SELFIES string: [C][C][N+][Branch1_2][epsilon][C][Branch1_3][epsilon][C][C][c][c][c][c][c][c][Ring1][Branch1_1][Br]    \ntoks = atomwise_tokenizer(sel)\nprint(toks)\n> >> ['[C]', '[C]', '[N+]', '[Branch1_2]', '[epsilon]', '[C]', '[Branch1_3]', '[epsilon]', '[C]', '[C]', '[c]', '[c]', '[c]', '[c]', '[c]', '[c]', '[Ring1]', '[Branch1_1]', '[Br]']\n\ntoks = kmer_tokenizer(sel, ngram=4)\nprint(toks)\n\n>>> ['[C][C][N+][Branch1_2]', '[C][N+][Branch1_2][epsilon]', '[N+][Branch1_2][epsilon][C]', '[Branch1_2][epsilon][C][Branch1_3]', '[epsilon][C][Branch1_3][epsilon]', '[C][Branch1_3][epsilon][C]', '[Branch1_3][epsilon][C][C]', '[epsilon][C][C][c]', '[C][C][c][c]', '[C][c][c][c]', '[c][c][c][c]', '[c][c][c][c]', '[c][c][c][c]', '[c][c][c][Ring1]', '[c][c][Ring1][Branch1_1]', '[c][Ring1][Branch1_1][Br]']\n```\n\nExample of DeepSMILES\n\n```python\nimport deepsmiles\nconverter = deepsmiles.Converter(rings=True, branches=True)\nsmi = 'CC[N+](C)(C)Cc1ccccc1Br'\ndeepsmi = converter.encode(smi)\nprint(f'DeepSMILES string: {deepsmi}')> >> DeepSMILES string: CC[N+]C)C)Ccccccc6Br\ntoks = atomwise_tokenizer(deepsmi)\nprint(toks)\n\n>>> ['C', 'C', '[N+]', 'C', ')', 'C', ')', 'C', 'c', 'c', 'c', 'c', 'c', 'c', '6', 'Br']\n\ntoks = kmer_tokenizer(deepsmi, ngram=4)\nprint(toks)\n\n>>> ['CC[N+]C', 'C[N+]C)', '[N+]C)C', 'C)C)', ')C)C', 'C)Cc', ')Ccc', 'Cccc', 'cccc', 'cccc', 'cccc', 'ccc6', 'cc6Br']\n```\n\n### Use the Pre-trained SmilesPE Tokenizer\n\nDowbload ['SPE_ChEMBL.txt'](https://github.com/XinhaoLi74/SmilesPE/blob/master/SPE_ChEMBL.txt).\n\n```python\n\nimport codecs\nfrom SmilesPE.tokenizer import *\n\nspe_vob= codecs.open('../SPE_ChEMBL.txt')\nspe = SPE_Tokenizer(spe_vob)\n\nsmi = 'CC[N+](C)(C)Cc1ccccc1Br'\nspe.tokenize(smi)\n\n>>> 'CC [N+](C) (C)C c1ccccc1 Br'\n```\n\n### Train a SmilesPE Tokenizer with a Custom Dataset\n\nSee [train_SPE.ipynb](https://github.com/XinhaoLi74/SmilesPE/blob/master/Examples/train_SPE.ipynb) for an example of training A SPE tokenizer on ChEMBL data.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/XinhaoLi74/SmilesPE", "keywords": "Cheminformatics SMILES", "license": "Apache Software License 2.0", "maintainer": "", "maintainer_email": "", "name": "SmilesPE", "package_url": "https://pypi.org/project/SmilesPE/", "platform": "", "project_url": "https://pypi.org/project/SmilesPE/", "project_urls": {"Homepage": "https://github.com/XinhaoLi74/SmilesPE"}, "release_url": "https://pypi.org/project/SmilesPE/0.0.3/", "requires_dist": ["fastprogress", "gensim"], "requires_python": ">=3.6", "summary": "Tokenize SMILES with substructure units", "version": "0.0.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>SMILES Pair Encoding (SmilesPE).</h1>\n<blockquote>\n<p>SMILES Pair Encoding (SmilesPE) trains a substructure tokenizer from a large set of SMILES strings (e.g., ChEMBL) based on <a href=\"https://www.aclweb.org/anthology/P16-1162/\" rel=\"nofollow\">byte-pair-encoding (BPE)</a>.</p>\n</blockquote>\n<h2>Overview</h2>\n<h2>Installation</h2>\n<pre><code>pip install SmilesPE\n</code></pre>\n<h2>Usage Instructions</h2>\n<h3>Basic Tokenizers</h3>\n<ol>\n<li>Atom-level Tokenizer</li>\n</ol>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">SmilesPE.pretokenizer</span> <span class=\"kn\">import</span> <span class=\"n\">atomwise_tokenizer</span>\n\n<span class=\"n\">smi</span> <span class=\"o\">=</span> <span class=\"s1\">'CC[N+](C)(C)Cc1ccccc1Br'</span>\n<span class=\"n\">toks</span> <span class=\"o\">=</span> <span class=\"n\">atomwise_tokenizer</span><span class=\"p\">(</span><span class=\"n\">smi</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">toks</span><span class=\"p\">)</span>\n</pre>\n<pre><code>['C', 'C', '[N+]', '(', 'C', ')', '(', 'C', ')', 'C', 'c', '1', 'c', 'c', 'c', 'c', 'c', '1', 'Br']\n</code></pre>\n<ol>\n<li>K-mer Tokenzier</li>\n</ol>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">SmilesPE.pretokenizer</span> <span class=\"kn\">import</span> <span class=\"n\">kmer_tokenizer</span>\n\n<span class=\"n\">smi</span> <span class=\"o\">=</span> <span class=\"s1\">'CC[N+](C)(C)Cc1ccccc1Br'</span>\n<span class=\"n\">toks</span> <span class=\"o\">=</span> <span class=\"n\">kmer_tokenizer</span><span class=\"p\">(</span><span class=\"n\">smi</span><span class=\"p\">,</span> <span class=\"n\">ngram</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">toks</span><span class=\"p\">)</span>\n</pre>\n<pre><code>['CC[N+](', 'C[N+](C', '[N+](C)', '(C)(', 'C)(C', ')(C)', '(C)C', 'C)Cc', ')Cc1', 'Cc1c', 'c1cc', '1ccc', 'cccc', 'cccc', 'ccc1', 'cc1Br']\n</code></pre>\n<p>The basic tokenizers are also compatible with <a href=\"https://github.com/aspuru-guzik-group/selfies\" rel=\"nofollow\">SELFIES</a> and <a href=\"https://github.com/baoilleach/deepsmiles\" rel=\"nofollow\">DeepSMILES</a>. Package installations are required.</p>\n<p>Example of SELFIES</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">selfies</span>\n<span class=\"n\">smi</span> <span class=\"o\">=</span> <span class=\"s1\">'CC[N+](C)(C)Cc1ccccc1Br'</span>\n<span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">selfies</span><span class=\"o\">.</span><span class=\"n\">encoder</span><span class=\"p\">(</span><span class=\"n\">smi</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">'SELFIES string: </span><span class=\"si\">{</span><span class=\"n\">sel</span><span class=\"si\">}</span><span class=\"s1\">'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;</span> <span class=\"o\">&gt;&gt;</span> <span class=\"n\">SELFIES</span> <span class=\"n\">string</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"n\">C</span><span class=\"p\">][</span><span class=\"n\">C</span><span class=\"p\">][</span><span class=\"n\">N</span><span class=\"o\">+</span><span class=\"p\">][</span><span class=\"n\">Branch1_2</span><span class=\"p\">][</span><span class=\"n\">epsilon</span><span class=\"p\">][</span><span class=\"n\">C</span><span class=\"p\">][</span><span class=\"n\">Branch1_3</span><span class=\"p\">][</span><span class=\"n\">epsilon</span><span class=\"p\">][</span><span class=\"n\">C</span><span class=\"p\">][</span><span class=\"n\">C</span><span class=\"p\">][</span><span class=\"n\">c</span><span class=\"p\">][</span><span class=\"n\">c</span><span class=\"p\">][</span><span class=\"n\">c</span><span class=\"p\">][</span><span class=\"n\">c</span><span class=\"p\">][</span><span class=\"n\">c</span><span class=\"p\">][</span><span class=\"n\">c</span><span class=\"p\">][</span><span class=\"n\">Ring1</span><span class=\"p\">][</span><span class=\"n\">Branch1_1</span><span class=\"p\">][</span><span class=\"n\">Br</span><span class=\"p\">]</span>    \n<span class=\"n\">toks</span> <span class=\"o\">=</span> <span class=\"n\">atomwise_tokenizer</span><span class=\"p\">(</span><span class=\"n\">sel</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">toks</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;</span> <span class=\"o\">&gt;&gt;</span> <span class=\"p\">[</span><span class=\"s1\">'[C]'</span><span class=\"p\">,</span> <span class=\"s1\">'[C]'</span><span class=\"p\">,</span> <span class=\"s1\">'[N+]'</span><span class=\"p\">,</span> <span class=\"s1\">'[Branch1_2]'</span><span class=\"p\">,</span> <span class=\"s1\">'[epsilon]'</span><span class=\"p\">,</span> <span class=\"s1\">'[C]'</span><span class=\"p\">,</span> <span class=\"s1\">'[Branch1_3]'</span><span class=\"p\">,</span> <span class=\"s1\">'[epsilon]'</span><span class=\"p\">,</span> <span class=\"s1\">'[C]'</span><span class=\"p\">,</span> <span class=\"s1\">'[C]'</span><span class=\"p\">,</span> <span class=\"s1\">'[c]'</span><span class=\"p\">,</span> <span class=\"s1\">'[c]'</span><span class=\"p\">,</span> <span class=\"s1\">'[c]'</span><span class=\"p\">,</span> <span class=\"s1\">'[c]'</span><span class=\"p\">,</span> <span class=\"s1\">'[c]'</span><span class=\"p\">,</span> <span class=\"s1\">'[c]'</span><span class=\"p\">,</span> <span class=\"s1\">'[Ring1]'</span><span class=\"p\">,</span> <span class=\"s1\">'[Branch1_1]'</span><span class=\"p\">,</span> <span class=\"s1\">'[Br]'</span><span class=\"p\">]</span>\n\n<span class=\"n\">toks</span> <span class=\"o\">=</span> <span class=\"n\">kmer_tokenizer</span><span class=\"p\">(</span><span class=\"n\">sel</span><span class=\"p\">,</span> <span class=\"n\">ngram</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">toks</span><span class=\"p\">)</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"p\">[</span><span class=\"s1\">'[C][C][N+][Branch1_2]'</span><span class=\"p\">,</span> <span class=\"s1\">'[C][N+][Branch1_2][epsilon]'</span><span class=\"p\">,</span> <span class=\"s1\">'[N+][Branch1_2][epsilon][C]'</span><span class=\"p\">,</span> <span class=\"s1\">'[Branch1_2][epsilon][C][Branch1_3]'</span><span class=\"p\">,</span> <span class=\"s1\">'[epsilon][C][Branch1_3][epsilon]'</span><span class=\"p\">,</span> <span class=\"s1\">'[C][Branch1_3][epsilon][C]'</span><span class=\"p\">,</span> <span class=\"s1\">'[Branch1_3][epsilon][C][C]'</span><span class=\"p\">,</span> <span class=\"s1\">'[epsilon][C][C][c]'</span><span class=\"p\">,</span> <span class=\"s1\">'[C][C][c][c]'</span><span class=\"p\">,</span> <span class=\"s1\">'[C][c][c][c]'</span><span class=\"p\">,</span> <span class=\"s1\">'[c][c][c][c]'</span><span class=\"p\">,</span> <span class=\"s1\">'[c][c][c][c]'</span><span class=\"p\">,</span> <span class=\"s1\">'[c][c][c][c]'</span><span class=\"p\">,</span> <span class=\"s1\">'[c][c][c][Ring1]'</span><span class=\"p\">,</span> <span class=\"s1\">'[c][c][Ring1][Branch1_1]'</span><span class=\"p\">,</span> <span class=\"s1\">'[c][Ring1][Branch1_1][Br]'</span><span class=\"p\">]</span>\n</pre>\n<p>Example of DeepSMILES</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">deepsmiles</span>\n<span class=\"n\">converter</span> <span class=\"o\">=</span> <span class=\"n\">deepsmiles</span><span class=\"o\">.</span><span class=\"n\">Converter</span><span class=\"p\">(</span><span class=\"n\">rings</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">branches</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"n\">smi</span> <span class=\"o\">=</span> <span class=\"s1\">'CC[N+](C)(C)Cc1ccccc1Br'</span>\n<span class=\"n\">deepsmi</span> <span class=\"o\">=</span> <span class=\"n\">converter</span><span class=\"o\">.</span><span class=\"n\">encode</span><span class=\"p\">(</span><span class=\"n\">smi</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">'DeepSMILES string: </span><span class=\"si\">{</span><span class=\"n\">deepsmi</span><span class=\"si\">}</span><span class=\"s1\">'</span><span class=\"p\">)</span><span class=\"o\">&gt;</span> <span class=\"o\">&gt;&gt;</span> <span class=\"n\">DeepSMILES</span> <span class=\"n\">string</span><span class=\"p\">:</span> <span class=\"n\">CC</span><span class=\"p\">[</span><span class=\"n\">N</span><span class=\"o\">+</span><span class=\"p\">]</span><span class=\"n\">C</span><span class=\"p\">)</span><span class=\"n\">C</span><span class=\"p\">)</span><span class=\"n\">Ccccccc6Br</span>\n<span class=\"n\">toks</span> <span class=\"o\">=</span> <span class=\"n\">atomwise_tokenizer</span><span class=\"p\">(</span><span class=\"n\">deepsmi</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">toks</span><span class=\"p\">)</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"p\">[</span><span class=\"s1\">'C'</span><span class=\"p\">,</span> <span class=\"s1\">'C'</span><span class=\"p\">,</span> <span class=\"s1\">'[N+]'</span><span class=\"p\">,</span> <span class=\"s1\">'C'</span><span class=\"p\">,</span> <span class=\"s1\">')'</span><span class=\"p\">,</span> <span class=\"s1\">'C'</span><span class=\"p\">,</span> <span class=\"s1\">')'</span><span class=\"p\">,</span> <span class=\"s1\">'C'</span><span class=\"p\">,</span> <span class=\"s1\">'c'</span><span class=\"p\">,</span> <span class=\"s1\">'c'</span><span class=\"p\">,</span> <span class=\"s1\">'c'</span><span class=\"p\">,</span> <span class=\"s1\">'c'</span><span class=\"p\">,</span> <span class=\"s1\">'c'</span><span class=\"p\">,</span> <span class=\"s1\">'c'</span><span class=\"p\">,</span> <span class=\"s1\">'6'</span><span class=\"p\">,</span> <span class=\"s1\">'Br'</span><span class=\"p\">]</span>\n\n<span class=\"n\">toks</span> <span class=\"o\">=</span> <span class=\"n\">kmer_tokenizer</span><span class=\"p\">(</span><span class=\"n\">deepsmi</span><span class=\"p\">,</span> <span class=\"n\">ngram</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">toks</span><span class=\"p\">)</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"p\">[</span><span class=\"s1\">'CC[N+]C'</span><span class=\"p\">,</span> <span class=\"s1\">'C[N+]C)'</span><span class=\"p\">,</span> <span class=\"s1\">'[N+]C)C'</span><span class=\"p\">,</span> <span class=\"s1\">'C)C)'</span><span class=\"p\">,</span> <span class=\"s1\">')C)C'</span><span class=\"p\">,</span> <span class=\"s1\">'C)Cc'</span><span class=\"p\">,</span> <span class=\"s1\">')Ccc'</span><span class=\"p\">,</span> <span class=\"s1\">'Cccc'</span><span class=\"p\">,</span> <span class=\"s1\">'cccc'</span><span class=\"p\">,</span> <span class=\"s1\">'cccc'</span><span class=\"p\">,</span> <span class=\"s1\">'cccc'</span><span class=\"p\">,</span> <span class=\"s1\">'ccc6'</span><span class=\"p\">,</span> <span class=\"s1\">'cc6Br'</span><span class=\"p\">]</span>\n</pre>\n<h3>Use the Pre-trained SmilesPE Tokenizer</h3>\n<p>Dowbload <a href=\"https://github.com/XinhaoLi74/SmilesPE/blob/master/SPE_ChEMBL.txt\" rel=\"nofollow\">'SPE_ChEMBL.txt'</a>.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">codecs</span>\n<span class=\"kn\">from</span> <span class=\"nn\">SmilesPE.tokenizer</span> <span class=\"kn\">import</span> <span class=\"o\">*</span>\n\n<span class=\"n\">spe_vob</span><span class=\"o\">=</span> <span class=\"n\">codecs</span><span class=\"o\">.</span><span class=\"n\">open</span><span class=\"p\">(</span><span class=\"s1\">'../SPE_ChEMBL.txt'</span><span class=\"p\">)</span>\n<span class=\"n\">spe</span> <span class=\"o\">=</span> <span class=\"n\">SPE_Tokenizer</span><span class=\"p\">(</span><span class=\"n\">spe_vob</span><span class=\"p\">)</span>\n\n<span class=\"n\">smi</span> <span class=\"o\">=</span> <span class=\"s1\">'CC[N+](C)(C)Cc1ccccc1Br'</span>\n<span class=\"n\">spe</span><span class=\"o\">.</span><span class=\"n\">tokenize</span><span class=\"p\">(</span><span class=\"n\">smi</span><span class=\"p\">)</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"s1\">'CC [N+](C) (C)C c1ccccc1 Br'</span>\n</pre>\n<h3>Train a SmilesPE Tokenizer with a Custom Dataset</h3>\n<p>See <a href=\"https://github.com/XinhaoLi74/SmilesPE/blob/master/Examples/train_SPE.ipynb\" rel=\"nofollow\">train_SPE.ipynb</a> for an example of training A SPE tokenizer on ChEMBL data.</p>\n\n          </div>"}, "last_serial": 6973592, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "bfa0a753b5f529b686e5a39557af12c0", "sha256": "4ef0522dd1b353258e90046ec0905ff56086282dc8f0d9318c007da7c34fbdd7"}, "downloads": -1, "filename": "SmilesPE-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "bfa0a753b5f529b686e5a39557af12c0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 13331, "upload_time": "2020-03-18T19:40:33", "upload_time_iso_8601": "2020-03-18T19:40:33.048679Z", "url": "https://files.pythonhosted.org/packages/83/29/32a3a7afc1b1768010fde2dab2ab4f0585fe8262948c388ea254b8b4ba09/SmilesPE-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2497fcd17b1619b2b3ca5dd9983d74b4", "sha256": "d4077b30fa965b0fca0a77c56075399b906d1b3fbacfb55b823b27fda18b3b5b"}, "downloads": -1, "filename": "SmilesPE-0.0.1.tar.gz", "has_sig": false, "md5_digest": "2497fcd17b1619b2b3ca5dd9983d74b4", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 13533, "upload_time": "2020-03-18T19:40:35", "upload_time_iso_8601": "2020-03-18T19:40:35.286470Z", "url": "https://files.pythonhosted.org/packages/9e/c6/e25afa1caef0892d57281bf97f7ca858a9c13688f05d4f8450a6fb918eba/SmilesPE-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "45343714cdb75646e978b7f0ad423d7e", "sha256": "5763f7c30df1558a80911f9e349045159d76b3be6e01f881d53d99b5b879341c"}, "downloads": -1, "filename": "SmilesPE-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "45343714cdb75646e978b7f0ad423d7e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 13828, "upload_time": "2020-03-18T20:57:59", "upload_time_iso_8601": "2020-03-18T20:57:59.486786Z", "url": "https://files.pythonhosted.org/packages/66/2e/e10ccf110fdbde53b66527c44014fb9a69bcb7f7460fbc06dbd9cb7c58ba/SmilesPE-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e69e8d8df9ae98cbf0db536c838eac32", "sha256": "248a7208715966834f94c4ff6201069898582c17b9fbdbffd5d0e7e9f4fffa82"}, "downloads": -1, "filename": "SmilesPE-0.0.2.tar.gz", "has_sig": false, "md5_digest": "e69e8d8df9ae98cbf0db536c838eac32", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 13715, "upload_time": "2020-03-18T20:58:00", "upload_time_iso_8601": "2020-03-18T20:58:00.615527Z", "url": "https://files.pythonhosted.org/packages/88/b9/51394197d3ed54f69701689f182c3a1e843c508eab481e516508ca2c9e5e/SmilesPE-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "d9faf4f4f324a7018a099d8f9a933d6c", "sha256": "9f74279daa14945859546fb2de11c208b5116927ce5fe03b3cf46bcba96f5e58"}, "downloads": -1, "filename": "SmilesPE-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "d9faf4f4f324a7018a099d8f9a933d6c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 15723, "upload_time": "2020-04-07T22:12:02", "upload_time_iso_8601": "2020-04-07T22:12:02.522544Z", "url": "https://files.pythonhosted.org/packages/6d/f9/273f54d9d4b42779926291c82a5b3ffea30cff2492ebbe4ce08dccdcc949/SmilesPE-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ac151f898f038aab0f6becc2f620e78d", "sha256": "7ceebc7d314e456a08f77d45f08fe4b638886901c0eac50f0cdb005b9f0912bc"}, "downloads": -1, "filename": "SmilesPE-0.0.3.tar.gz", "has_sig": false, "md5_digest": "ac151f898f038aab0f6becc2f620e78d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 15625, "upload_time": "2020-04-07T22:12:03", "upload_time_iso_8601": "2020-04-07T22:12:03.569070Z", "url": "https://files.pythonhosted.org/packages/5e/5c/a638fd96cdf4499eaed76d5dbcec734d98c4ddaf2a8f9e13e44e5151fa29/SmilesPE-0.0.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "d9faf4f4f324a7018a099d8f9a933d6c", "sha256": "9f74279daa14945859546fb2de11c208b5116927ce5fe03b3cf46bcba96f5e58"}, "downloads": -1, "filename": "SmilesPE-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "d9faf4f4f324a7018a099d8f9a933d6c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 15723, "upload_time": "2020-04-07T22:12:02", "upload_time_iso_8601": "2020-04-07T22:12:02.522544Z", "url": "https://files.pythonhosted.org/packages/6d/f9/273f54d9d4b42779926291c82a5b3ffea30cff2492ebbe4ce08dccdcc949/SmilesPE-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ac151f898f038aab0f6becc2f620e78d", "sha256": "7ceebc7d314e456a08f77d45f08fe4b638886901c0eac50f0cdb005b9f0912bc"}, "downloads": -1, "filename": "SmilesPE-0.0.3.tar.gz", "has_sig": false, "md5_digest": "ac151f898f038aab0f6becc2f620e78d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 15625, "upload_time": "2020-04-07T22:12:03", "upload_time_iso_8601": "2020-04-07T22:12:03.569070Z", "url": "https://files.pythonhosted.org/packages/5e/5c/a638fd96cdf4499eaed76d5dbcec734d98c4ddaf2a8f9e13e44e5151fa29/SmilesPE-0.0.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:07:54 2020"}