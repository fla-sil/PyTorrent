{"info": {"author": "Aaron Westendorf", "author_email": "aaron@agoragames.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: BSD License", "Operating System :: POSIX", "Programming Language :: Python", "Programming Language :: Python :: 2.7", "Topic :: Communications", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules", "Topic :: System :: Distributed Computing"], "description": "=================================\nKairos - Time series data storage\n=================================\n\n:Version: 0.10.1\n:Download: http://pypi.python.org/pypi/kairos\n:Source: https://github.com/agoragames/kairos\n:Keywords: python, redis, mongo, sql, mysql, sqlite, postgresql, cassandra, timeseries, rrd, gevent, statistics\n\n.. contents::\n    :local:\n\n.. _kairos-overview:\n\nOverview\n========\n\nKairos provides time series storage using Redis, Mongo, SQL or Cassandra \nbackends. Kairos is intended to replace RRD and Whisper in situations where \nthe scale and flexibility of other data stores is required. It works with\n`gevent <http://www.gevent.org/>`_ and is the library on which\n`torus <https://github.com/agoragames/torus>`_ is built.\n\nRecommended for python 2.7 and later, it can work with previous versions if you\ninstall `OrderedDict <https://pypi.python.org/pypi/ordereddict>`_.\n\nKairos provides a consistent API for a variety of timeseries types and the\nstorage engines they're implemented in. Each timestamp is resolved to a \nconsistent bucket identifier (\"interval\") based on the number of whole seconds\nsince epoch, or a number corresponding to the Gregorian date associated with\nthe relative intervals  ``[daily, weekly, monthly, yearly]`` (e.g ``19991231``).\nWithin that, data can optionally be stored at resolutions (e.g. \"daily, \nin 1 hour increments\"). Multiple intervals can be tracked within a timeseries,\neach with its own resolution and optional TTL (e.g. 60 days of daily data,\nlifetime monthly data).\n\nIn data stores that support it, TTLs can be set for automatically deleting \ndata after a set number of intervals; other data stores expose an ``expire()``\nmethod for deleting data programmatically.\n\nWithin each interval (or resolution), data is stored according to the type of\nthe timeseries and what each backend supports. The values tracked in each\ntimeseries can be loosely typed for backends that support it, else the type\nwill be whatever is set in the timeseries constructor. Even when loosely typed,\nit should be assumed that the value should be a string or number.\n\nseries\n  All data will be stored in the order in which it arrives. Uses data store\n  list types where supported, else it will be timestamped records that \n  come as close as possible to the order in which they were written. Queries\n  will return list objects.\n\nhistogram\n  A hash of unique values to the number of its occurrences within an interval.\n  Uses data store dictionaries where supported, else it will be separate \n  records for each unique value and timestamp. Queries will return dictionary\n  objects. Built-in transforms assume that keys are real numbers.\n\ncount\n  A simple counter will be maintained for each interval, starting at 0 for\n  an interval. Queries will return an integer.\n\ngauge\n  Stores the last-written value for each interval. Queries will return whatever\n  the value type was.\n\nset\n  Stores all the unique values within an interval. Uses data store sets where\n  supported, else it will be separate records for each unique value. Queries\n  will return set objects.\n    \nUsage\n=====\n\nKairos supports all storage engines using the same API. The constructor will \nreturn a Timeseries instance tailored for the type of data and the storage \nengine, and the API for updating and querying the timeseries is consistent \nfor all combinations of data type and storage engine.\n\nConstructor\n-----------\n\nThe first argument is a handle to a supported storage engine or a URL (see \nbelow), and the rest of the keyword arguments configure the timeseries. The \nkeyword arguments supported by all storage engines are:\n\ntype\n  Required, defines the type of the timeseries. Raises a ``NotImplementedError``\n  if the backend does not support the type.\n\nread_func\n  Optional, is a function applied to all values read back from the\n  database. Without it, values will be strings for Redis, whatever \n  `write_func` defined for Mongo. Must accept a string value for Redis\n  (empty string for no data) and can return anything.\n\nwrite_func\n  Optional, is a function applied to all values when writing. Can be\n  used for histogram resolution, converting an object into an id, etc.\n  Must accept whatever can be inserted into a timeseries and return an\n  object which can be saved according to the rules of the storage engine.\n\nintervals\n  Required, a dictionary of interval configurations in the form of: ::\n\n    {\n      # interval name, used in keys and should conform to best \n      # practices according to the storage engine.\n      minute: {\n        \n        # Required. The number of seconds that the interval will cover,\n        # or a supported Gregorian interval.\n        step: 60,\n        \n        # Optional. The maximum number of intervals to maintain. If supplied,\n        # will use Redis and Mongo expiration to delete old intervals, else \n        # intervals exist in perpetuity. If the storage engine doesn't support\n        # expiry, will be used to implement the expire() call.\n        steps: 240,\n        \n        # Optional. Defines the resolution of the data, i.e. the number of \n        # seconds in which data is assumed to have occurred \"at the same time\".\n        # So if you're tracking a month-long time series, you may only need \n        # resolution down to the day, or resolution=86400. Defaults to same\n        # value as \"step\". Can also be a Gregorian interval.\n        resolution: 60,\n      }\n    }\n\n  In addition to specifying ``step`` and ``resolution`` in terms of seconds, \n  kairos also supports a simplified format for larger time intervals. For\n  hours (h), days (d), weeks (w), months (m) and years (y), you can use \n  the format ``30d`` to represent 30 days, for example.\n\n  As of ``0.3.0``, kairos also supports the Gregorian calendar for ``step``\n  and ``resolution``. Either or both parameters can use the terms ``[daily,\n  weekly, monthly, yearly]`` to describe an interval. You can also mix these\n  terms between ``step`` and ``resolution`` (e.g. ``daily`` in \n  ``1h`` resolutions). The expiration time for Gregorian dates is still defined\n  in terms of seconds and may not match the varying month lengths, leap years, \n  etc. Gregorian dates are translated into ``strptime``- and ``strftime``-compatible\n  keys (as integers) and so may be easier to use in raw form or with any \n  external tools. The ``duration`` parameter to transforms run on gregorian\n  series will be seconds in whole number of days (where a day is 86400 seconds).\n\nStorage Engines\n---------------\n\nEach of the supported storage engines also supports a set of keyword arguments\nto configure their behavior. When intializing with a URL, the keyword argument\n``client_config`` can optionally be a dictionary which will be passed as \nkeyword arguments to the constructor for the client associated with the URL.\nIf kairos implements any custom keyword arguments from ``client_config`` those\nare documented below.\n\nRedis (redis://)\n****************\n\nAn example timeseries stored in Redis: ::\n\n  from kairos import Timeseries\n  import redis\n\n  client = redis.Redis('localhost', 6379)\n  t = Timeseries(client, type='histogram', read_func=int, intervals={\n    'minute':{\n      'step':60,            # 60 seconds\n      'steps':120,          # last 2 hours\n    }\n  })\n\n  t.insert('example', 3.14159)\n  t.insert('example', 2.71828)\n  print t.get('example', 'minute')\n\nAdditional keyword arguments are: ::\n\n  prefix\n    Optional, is a prefix for all keys in this timeseries. If \n    supplied and it doesn't end with \":\", it will be automatically appended.\n\nSupported URL `formats`__: ::\n\n  redis://localhost\n  redis://localhost/3\n\n__ https://github.com/andymccurdy/redis-py/blob/master/redis/client.py#L332\n\nAll `supported <https://github.com/andymccurdy/redis-py/blob/master/redis/client.py#L361>`_ configuration options can be passed in ``client_config``.\n\nMongo (mongodb://)\n******************\n\nAn example timeseries stored in Mongo: ::\n\n  from kairos import Timeseries\n  import pymongo\n\n  client = pymongo.MongoClient('localhost')\n  t = Timeseries(client, type='histogram', read_func=float, intervals={\n    'minute':{\n      'step':60,            # 60 seconds\n      'steps':120,          # last 2 hours\n    }\n  })\n\n  t.insert('example', 3.14159)\n  t.insert('example', 2.71828)\n  print t.get('example', 'minute')\n\nAdditional keyword arguments are: ::\n\n  escape_character\n    Optional, defines the character used to escape periods. Defaults to the\n    unicode character \"U+FFFF\". \n\nSupported URL `formats`__: ::\n\n  mongodb://localhost\n  mongodb://localhost:27018/timeseries\n  mongodb://guest:host@localhost/authed_db\n\n__ http://docs.mongodb.org/manual/reference/connection-string/\n\nAll `supported`__ configuration arguments can be passed in ``client_config``, in addition to: ::\n\n  database\n    The name of the database to use. Defaults to 'kairos'. Required if using\n    an auth database. Overrides any database provided in the URL.\n\n__ http://api.mongodb.org/python/current/api/pymongo/mongo_client.html\n\nSQL (\\*sql\\*://)\n****************\n\nAn example timeseries stored in a SQLite memory store: ::\n\n  from kairos import Timeseries\n  from sqlalchemy import create_engine\n\n  client = create_engine('sqlite:///:memory:')\n  t = Timeseries(client, type='histogram', read_func=int, intervals={\n    'minute':{\n      'step':60,            # 60 seconds\n      'steps':120,          # last 2 hours\n    }\n  })\n\n  t.insert('example', 3.14159)\n  t.insert('example', 2.71828)\n  print t.get('example', 'minute')\n\nAdditional keyword arguments are: ::\n\n  string_length\n    Optional, configures the length of strings (VARCHARs). Defaults to 255.\n    All tables have at least 2 string columns, and the size of these columns\n    may impact usability of the SQL storage engine.\n\n  text_length\n    Optional, configures the length of TEXT and BLOB columns. Defaults to \n    32Kbytes. Only matters if value_type is a text or blob.\n\n  table_name\n    Optional, overrides the default table name for a timeseries type.\n\n  value_type\n    Optional, defines the type of value to be stored in the timeseries. \n    Defaults to float. Can be a string, a Python type or a SQLAlchemy type\n    or instance.\n    \n    'blob'\n    'bool'\n    <type 'bool'>\n    'boolean'\n    'clob'\n    'date'\n    <type 'datetime.date'>\n    'datetime'\n    <type 'datetime.datetime'>\n    'decimal'\n    <class 'decimal.Decimal'>\n    'float'\n    <type 'float'>\n    'int'\n    'int64'\n    'integer'\n    <type 'int'>\n    'long'\n    <type 'long'>\n    'str'\n    'string'\n    <type 'str'>\n    'text'\n    'time'\n    <type 'datetime.time'>\n    'unicode'\n    <type 'unicode'>\n\nSupported URL `formats <http://docs.sqlalchemy.org/en/rel_0_9/core/engines.html#database-urls>`_ are many and varied. A few examples: ::\n\n  sqlite:///:memory:\n  postgresql://scott:tiger@localhost/mydatabase\n  mysql+mysqldb://scott:tiger@localhost/foo\n  oracle://scott:tiger@127.0.0.1:1521/sidname\n\nAll `supported`__ constructor arguments can be used in ``client_config``.\n\n__  http://docs.sqlalchemy.org/en/rel_0_9/core/engines.html#sqlalchemy.create_engine\n\nCassandra (cassandra://, cql://)\n********************************\n\nAn example timeseries stored in Cassandra: ::\n\n  from kairos import Timeseries\n  import cql\n\n  client = cql.connect('localhost', 9160, 'keyspace', cql_version='3.0.0')\n  t = Timeseries(client, type='histogram', read_func=int, intervals={\n    'minute':{\n      'step':60,            # 60 seconds\n      'steps':120,          # last 2 hours\n    }\n  })\n\n  t.insert('example', 3.14159)\n  t.insert('example', 2.71828)\n  print t.get('example', 'minute')\n\nAdditional keyword arguments are: ::\n\n  table_name\n    Optional, overrides the default table name for a timeseries type.\n\n  pool_size\n    Optional, set a cap on the pool size. Defines the maximum number of\n    connections to maintain in the pool. Defaults to 0 for no maximum.\n\n  value_type\n    Optional, defines the type of value to be stored in the timeseries. \n    Defaults to float. Can be a string or a Python type.\n\n    <type 'unicode'>\n    string\n    decimal\n    <type 'long'>\n    int\n    double\n    unicode\n    float\n    long\n    <type 'bool'>\n    <type 'float'>\n    boolean\n    int64\n    str\n    text\n    blob\n    clob\n    integer\n    bool\n    <type 'str'>\n    <type 'int'>\n    inet\n\nSupported URL formats are: ::\n  \n  cql://\n  cassandra://localhost:9160\n  cassandra://localhost/database\n\nAll `supported`__ constructor arguments can be used in ``client_config``.\n\n__  https://code.google.com/a/apache-extras.org/p/cassandra-dbapi2/source/browse/cql/connection.py\n\nkairos requires `cql <https://pypi.python.org/pypi/cql>`_ as it supports\n`CQL3 <https://cassandra.apache.org/doc/cql3/CQL.html>`_ and gevent. This \nrequires that the keyspace be created before the connection, and the keyword \nargument ``cql_version='3.0.0'`` must be used.\n\nA notable downside of this library is that it does not support a list of\nendpoints to connect to, so is missing key High Availability features.\n\nIt is likely that future versions of kairos will require \n`cassandra-driver <https://github.com/datastax/python-driver>`_ when it \nis ready.\n\nCassandra counters can only store integers, and cannot be used for a \nrunning total of floating point numbers.\n\nKairos implements a connection pooling mechanism on top of `cql`. The pool\nis a simple soft-cap on the number of connections maintained in the pool,\nbut not necessarily the total number of connections at a time. An optional\nhard cap may be implemented in a future release.\n\nInserting Data\n--------------\n\nThere are two methods to insert data, ``Timeseries.insert`` and ``Timeseries.bulk_insert``.\n\ninsert\n******\n\n* **name** The name of the statistic\n* **value** The value of the statistic (optional for count timeseries), or a list of values\n* **timestamp** `(optional)` The timestamp of the statistic, defaults to ``time.time()`` if not supplied\n* **intervals** `(optional)` The number of time intervals before (<0) or after (>0) ``timestamp`` to copy the data\n* **\\*\\*kwargs** `(optional)` Any additional keyword arguments supported by a backend, see below\n\nFor ``series`` and ``histogram`` timeseries types, ``value`` can be whatever \nyou'd like, optionally processed through the ``write_func`` method before being \nwritten to storage. Depending on your needs, ``value`` (or the output of \n``write_func``) does not have to be a number, and can be used to track such \nthings as unique occurances of a string or references to other objects, such \nas MongoDB ObjectIds. Note that many of the aggregate functions in ``histogram``\nexpect the data to be real numbers.\n\nFor the ``count`` type, ``value`` is optional and should be a float or integer \nrepresenting the amount by which to increment or decrement ``name``; it defaults\nto ``1``.\n\nFor the ``gauge`` type, ``value`` can be anything and it will be stored as-is.\n\nFor all timeseries types, if ``value`` is one of ``(list,tuple,set)``, will \ncall ``bulk_insert``.\n\nThe ``intervals`` option allows the caller to simulate the value appearing in\ntime periods before or after the ``timestamp``. This is useful for creating \nfast trending (e.g. \"count over last seven days\"). It is important to note \nthat, because the time periods are simulated, resolution is lost for the\nthe simulated timestamps.\n\nRedis\n#####\n\nRedis supports an additional keyword argument, ``pipeline``, to give the caller\ncontrol over batches of commands. If ``pipeline`` is supplied, the ``execute``\nmethod will not be called and it is up to the caller to do so.\n\nbulk_insert\n***********\n\n* **inserts** The structure of inserts (see below)\n* **intervals** `(optional)` The number of time intervals before (<0) or after (>0) ``timestamp`` to copy the data\n* **\\*\\*kwargs** `(optional)` Any additional keyword arguments supported by a backend, see below\n\nThe ``inserts`` field must take the following form: ::\n\n    {\n      timestamp : {\n        name: [ value, ... ],\n        ...\n      },\n      ...\n    }\n\nThe meaning of ``timestamp``, ``name`` and ``value`` are identical to those \nparameters in ``insert``. The caller can insert any number of timestamps,\nstatistic names and values, and the backend will optimize the insert where\npossible. See details on the different backends below. Where a backend does\nnot support an optimized bulk insert, the data structure will be processed\nsuch that each value will be passed to ``insert``.\n\nThe ``inserts`` structure can be a ``dict`` or ``OrderedDict``. If you need\nthe insert order preserved, such as when inserting into a ``series`` or \n``gauge``, you should use ``OrderedDict``.\n\nIf ``timestamp`` is unknown, use ``None`` for the key and it will be set to\nthe current value of ``time.time()``. Note that this may alter ordering if\n``inserts`` is an ``OrderedDict``.\n\n**NOTE** bulk inserts will increase memory usage of the client process.\n\nRedis\n#####\n\nRedis bulk inserts are implemented by using a single pipeline (without\ntransactions) and committing the pipeline after all bulk inserts have been\nexecuted. The bulk insert also supports the ``pipeline`` argument, with the\nsame rules as ``insert``.\n\nMongo\n#####\n\nMongo bulk inserts are implemented by joining all of the data together into\na condensed set of queries and updates. As the configuration of a timeseries\nmay result in multiple timestamps resolving to the same record (e.g. per-day\ndata), this could result in significant performance gains when the timeseries\nis a ``count``, ``histogram`` or ``gauge``.\n\nSQL\n###\n\nThere is no optimization for bulk inserts in SQL due to the lack of \nnative update-or-insert support. The generic SQL implementation requires an\nattempted update to be committed before kairos can determine if an insert is\nrequired. Future versions may have optimized implementations for specific\nSQL servers which support such a feature, at which time bulk inserts may be\noptimized for those specific backends.\n\nCassandra\n#########\n\nThe ``cql`` library has no support for transactions, grouping, etc.\n\nMeta Data\n---------\n\nThere are two methods to query meta data about a Timeseries.\n\nlist\n****\n\nThere are no arguments. Returns a list of all of the stat names stored \nin the Timeseries.\n\nproperties\n**********\n\nTakes a single argument, the name of the timeseries. Returns a dictionary\nwith the following fields: ::\n\n  { interval : { 'first' : timestamp, 'last' : timestamp } }\n\n``interval`` will be the named interval, such as \"minute\". For each interval,\nthere is a dictionary of properties. ``first`` is the timestamp of the first\ndata point in the timeseries, and ``last`` is the last data point in the \ntimeseries.\n\n\nReading Data\n------------\n\nThere are three methods to read data, ``Timeseries.get``, ``Timeseries.series``\nand ``Timeseries.iterate``. ``get`` will return data from a single bucket, \nand ``series`` will return data from several buckets. ``iterate`` will use\nthe ``Timeseries.properties`` method to determine the date range of the data,\nand return a generator that calls ``get`` for every possible interval in\nthe date range.\n\nget\n***\n\nSupports the following parameters. All optional parameters are keyword arguments.\n\n* **name** The name of the statistic, or a list of names whose data will be joined together.\n* **interval** The named interval to read from\n* **timestamp** `(optional)` The timestamp to read, defaults to ``time.time()``\n* **condensed** `(optional)` **DEPRECATED** Use ``condense`` instead. Support for this will be removed entirely in a future release.\n* **transform** `(optional)` Optionally process each row of data. Supports ``[mean, count, min, max, sum]``, or any callable that accepts datapoints according to the type of series (e.g histograms are dictionaries, counts are integers, etc). Transforms are called after ``read_func`` has cast the data type and after resolution data is optionally condensed. If ``transform`` is one of ``(list,tuple,set)``, will load the data once and run all the transforms on that data set. If ``transform`` is a ``dict`` of the form ``{ transform_name : transform_func }``, will run all of the transform functions on the data set. See `Customized Reads`_ for more on custom transforms.\n* **fetch** `(optional)` Function to use instead of the built-in implementations for fetching data. See `Customized Reads`_.\n* **process_row** `(optional)` Can be a callable to implement `Customized Reads`_.\n* **condense** `(optional)` If using resolutions, ``True`` will collapse the resolution data into a single row. Can be a callable to implement `Customized Reads`_.\n* **join_rows** `(optional)` Can be a callable to implement `Customized Reads`_.\n\nReturns a dictionary of ``{ timestamp : data }``, where ``timestamp`` is a Unix timestamp\nand ``data`` is a data structure corresponding to the type of series, or whatever \n``transform`` returns.  If not using resolutions or ``condense=True``, the length \nof the dictionary is 1, else it will be the number of resolution buckets within\nthe interval that contained data. If ``transform`` is a list, ``data`` will be a \ndictionary of ``{ transform_func : transformed_data }``. If ``transform`` is a ``dict``,\n``data`` will be a dictionary of ``{ transform_name : transformed_data }``.\n\nseries\n******\n\nAlmost identical to ``get``, supports the following parameters. All optional parameters are keyword arguments.\n\n* **name** The name of the statistic, or a list of names whose data will be joined together.\n* **interval** The named interval to read from\n* **start** `(optional)` The timestamp which should be in the first interval of the returned data.\n* **end** `(optional)` The timestamp which should be in the last interval of the returned data. \n* **steps** `(optional)` The number of steps in the interval to read, defaults to either ``steps`` in the configuration or 1. Ignored if both ``start`` and ``end`` are defined. If either ``start`` or ``end`` are defined, ``steps`` is inclusive of whatever interval that timestamp falls into.\n* **condensed** `(optional)` **DEPRECATED** Use ``condense`` instead. Support for this will be removed entirely in a future release.\n* **transform** `(optional)` Optionally process each row of data. Supports ``[mean, count, min, max, sum]``, or any callable that accepts a list of datapoints according to the type of series (e.g histograms are dictionaries, counts are integers, etc). Transforms are called after ``read_func`` has cast the data type and after resolution data is optionally condensed. If ``transform`` is one of ``(list,tuple,set)``, will load the data once and run all the transforms on that data set. If ``transform`` is a ``dict`` of the form ``{ transform_name : transform_func }``, will run all of the transform functions on the data set. See `Customized Reads`_ for more on custom transforms.\n* **fetch** `(optional)` Function to use instead of the built-in implementations for fetching data. See `Customized Reads`_.\n* **process_row** `(optional)` Can be a callable to implement `Customized Reads`_.\n* **condense** `(optional)` If using resolutions, ``True`` will collapse the resolution data into a single row. Can be a callable to implement `Customized Reads`_.\n* **join_rows** `(optional)` Can be a callable to implement `Customized Reads`_.\n* **collapse** `(optional)` ``True`` will collapse all of the data in the date range into a single result. Can be a callable to implement `Customized Reads`_.\n\nReturns an ordered dictionary of ``{ interval_timestamp : { resolution_timestamp: data } }``,\nwhere ``interval_timestamp`` and ``resolution_timestamp`` are Unix timestamps\nand ``data`` is a data structure corresponding to the type of series, or whatever \n``transform`` returns.  If not using resolutions or ``condense=True``, the dictionary\nwill be of the form ``{ interval_timestamp : data }``.\n\nAll variations of ``transform`` and the resulting format of ``data`` are the same\nas in ``get``.\n\nIf both ``start`` and ``end`` are defined, the returned data will start and end\non intervals including those timestamps. If only ``start`` is defined, then the\nreturn data will start with an interval that includes that timestamp, with the\ntotal number of intervals returned defined by ``steps``. If only ``end`` is \ndefined, then the return data will end with an interval that includes that \ntimestamp, with the total number of intervals preceeding it defined by ``steps``.\n\nIt is important to note that the interval timestamps in the returned data will\nnot necessarily match ``start`` or ``end``. This is because of the consistent\nhashing scheme that kairos uses, such that ``start`` and ``end`` will be \ntranslated into the bucket in which it can be found.\n\niterate\n*******\n\nAlmost identical to ``get`` except it does not accept a ``timestamp`` argument.\n\n* **name** The name of the statistic, or a list of names whose data will be joined together.\n* **interval** The named interval to read from\n* **transform** `(optional)` Optionally process each row of data. Supports ``[mean, count, min, max, sum]``, or any callable that accepts datapoints according to the type of series (e.g histograms are dictionaries, counts are integers, etc). Transforms are called after ``read_func`` has cast the data type and after resolution data is optionally condensed. If ``transform`` is one of ``(list,tuple,set)``, will load the data once and run all the transforms on that data set. If ``transform`` is a ``dict`` of the form ``{ transform_name : transform_func }``, will run all of the transform functions on the data set. See `Customized Reads`_ for more on custom transforms.\n* **fetch** `(optional)` Function to use instead of the built-in implementations for fetching data. See `Customized Reads`_.\n* **process_row** `(optional)` Can be a callable to implement `Customized Reads`_.\n* **condense** `(optional)` If using resolutions, ``True`` will collapse the resolution data into a single row. Can be a callable to implement `Customized Reads`_.\n* **join_rows** `(optional)` Can be a callable to implement `Customized Reads`_.\n\nReturns a generator which iterates over ``( timestamp, data )`` tuples, where\n``timestamp`` is a Unix timestamp and ``data`` corresponds to the rules\ndocumented in ``get``. Yields a tuple for each potential timestamp in the\nentire date range of the timeseries, even if there is no data. \n\n\nCustomized Reads\n----------------\n\n**ALPHA** This feature is still being explored and the API may change significantly.\n\nThere are times when the data in a timeseries requires processing to\nbe pushed onto the datastore. \n\nThere are times when one needs custom control over the reading and processing\nof data in a timeseries. As there is no good way to do this generically,\nthe ``get`` and ``series`` API supports several keyword arguments to customize\naccess to the data. Common use cases are to handle large sets of data that\ncan be processed in the datastore, and situations where one wants to implement\ncutom analysis of the dataset such as calculating variance. \n\nGeneral\n*******\n\nThe following functions can be overloaded with keyword parameters to ``get`` and\n``series`` (``collapse`` being only used for a series).\n\nfetch\n#####\n\nA customized database read function. The usage varies depending on the backends\nwhich are described in detail below.\n**IMPORTANT** You are welcome to change the type of the return value, but be\nwary that transforms, condense and collapse functionality may not work\nproperly with the changed data types.\n\nprocess_row\n###########\n\nThe function which handles the type casting of the data read from the backend\nand also calling the ``read_func`` if it has been defined for the time series.\nIt is required that you define this function if you overload ``fetch`` such\nthat the returned data type is not the same as the time series' native format\n(``dict`` for histogram, ``list`` for series, etc).\n\nThe function must be in the form of ``process_row(data)``, where:\n\n* **data** The row data generated by the native or ``fetch`` implementation, not\n  including any time stamps.\n\nThe function may return any data type, but if it's not the native format of the\ntime series, additional downstream functions may have to be overloaded.\n\ncondense\n########\n\nIf the ``condense`` argument is a callable, the caller can override how resolution\ndata is collapsed (reduced) into a single interval. The argument will always be \nin the form of: ::\n\n  {\n    'resolution_t0' : <data_t0>,\n    'resolution_t1' : <data_t1>,\n    ...\n    'resolution_tN' : <data_tN>,\n  }\n\nWhere ``<data_tN>`` is the data returned from the native or ``fetch`` \nimplementation and passed through the native or custom ``process_row``\nimplementation.\n\nThe function should return a single value, optionally in the same format as \n``<data_tN>``, but this method could also be used for calculating such\nthings as rate of change or variance within a time interval.\n\njoin_rows\n#########\n\nIf the ``join_rows`` argument is a callable and the ``name`` parameter to ``get``\nor ``series`` is one of ``(list,tuple,set)``, this method will be called to join\nthe data from several named timeseries into a single result. The argument will\nalways be in the form of: ::\n\n  [\n    <data_series0>,\n    <data_series1>,\n    ...\n    <data_seriesN>\n  ]\n\nWhere ``<data_series0>`` will be the data within a single timestamp window in\nthe series' native format or whatever was generated by custom implementations\nof ``fetch``, ``process_row`` and/or ``condense``. It is important to note\nthat not every series will contain data points within a given time interval.\n\nIn addition to reducing multiple time series' worth of data within an interval\ninto a single result, this method could be used to implement cross-series\nanalytics such as unions, intersections and differentials.\n\ncollapse\n########\n\nIf the ``collapse`` argument is a callable, the caller can override how interval\ndata is collapsed (reduced) into a single result. The native implementation is to\ncall the ``condense`` function implemented by a time series. The arguments are\nthe same as a custom ``condense`` function, as-is the expected return value.\n\nIt's important to note that if ``collapse`` is defined, the series will \nautomatically be condensed as well, so if ``fetch`` is overloaded to return a \ncustom data type, then ``condense`` must also be defined. If ``collapse`` is\n``True``, the custom ``condense`` function will be used if defined.\n\nIn addition to collapsing the result of a time series into a single data set,\nthis method could also be used to calculate data across a time series, such as\nvariance.\n\ntransform\n#########\n\nAs noted previously, ``transform`` can be any callable, list of names or callables,\nor a named map of transform names or callables. The transforms will be processed \nafter all previous native or custom read functions, including ``collapse``.\n\nTransforms must accept 2 parameters, the data and the time interval in seconds\nover which that data was captured. The ``data`` parameter will be of a type\ncorresponding to the timeseries type, or whatever was generated by a custom\n``fetch``. For example: ::\n\n    def custom_rate_for_counts(data, duration):\n      return float(data) / float(duration)\n\nFor gregorian timeseries, ``duration`` will seconds in terms of the whole\nnumber of days over which the data was captured, where a day is 86400 seconds.\n\nRedis\n*****\n\nThe function must be in the form of ``fetch(handle, key)``, where:\n\n* **handle** Either a Redis client or pipeline instance\n* **key** The key for the timeseries data\n\nThe return value should correspond to the data type of timeseries, e.g. ``dict``\nfor a histogram. One should always assume that ``handle`` is both a pipeline\n`and` a client, and ``fetch`` should return the result of, e.g. \n``handle.hlen(...)``, but that it cannot be used to return a literal, such\nas ``lambda: h,k: { 'foo' : h.hlen(k) }``\n\nMongo\n*****\n\nThe function must be in the form of ``fetch(handle, **kwargs)``, where:\n\n* **handle** A PyMongo ``Collection``\n* **spec** The (suggested) query specification\n* **sort** The (suggested) sort definition for the query\n* **method** The suggested method to use on the ``handle``\n\nThe required return value depends on the value of ``method``.\n\n* **find_one** Should return a hash in the form ``{ value : <data> }``, where\n  ``<data>`` should correspond to the data type of the timeseries, e.g. ``list``\n  for a series. May directly return a result from ``pymongo.collection.find_one``.\n* **find** Should return an iterable in the form ``[ { value: <data> }, ... ]``,\n  where ``<data>`` follows the same rules as ``find_one``.\n\nRe-implementing the default functionality would look like: ::\n\n  def mongo_fetch(handle, spec, sort, method):\n    if method=='find':\n      return handle.find( spec=spec, sort=sort )\n    elif method=='find_one':\n      return handle.find_one( spec )\n\nSQL\n***\n\nThe function must be in the form \n``fetch(connection, table, name, interval, i_start, i_end)``, where:\n\n* **connection** A SQLAlchemy ``Connection``\n* **table** A SQLAlchemy ``Table``\n* **name** The name of the stat to fetch\n* **interval** The interval of the stat to fetch\n* **i_start** The interval timestamp (starting) key\n* **i_end** (optional) For a series, the ending timestamp key\n\nThe return value should be in the form of ::\n\n  { \n    'interval_t0' : {\n      'resolution_t0t0' : <data_t0t0>,\n      'resolution_t0t1' : <data_t0t1>,\n      ...\n      'resolution_t0tN' : <data_t0tN>\n    },\n    'interval_t1' : { ... },\n    ...\n    'interval_tN' : { ... },\n  }\n\nIf the series doesn't use resolutions, then ``resolution_tNtN`` should be \n``None``, and so each interval will be in the form \n``{ 'interval_tN: { None : <data_tN> } }``. This is inherent in the way that\ndata is stored within the tables.\n\nIf ``i_end`` is supplied, the query should be over the range \n``i_time >= i_start AND i_time <= i_end``, else the query should be for\nthe interval ``i_time = i_start``.\n\nCassandra\n*********\n\nThe function must be in the form \n``fetch(connection, table, name, interval, i_start, i_end)``, where:\n\n* **cursor** A ``cql`` ``Connection``\n* **table** The name of the table\n* **name** The name of the stat to fetch\n* **interval** The interval of the stat to fetch\n* **intervals** The list of interval timestamps\n\nThe return value should be in the form of ::\n\n  { \n    'interval_t0' : {\n      'resolution_t0t0' : <data_t0t0>,\n      'resolution_t0t1' : <data_t0t1>,\n      ...\n      'resolution_t0tN' : <data_t0tN>\n    },\n    'interval_t1' : { ... },\n    ...\n    'interval_tN' : { ... },\n  }\n\nIf the series doesn't use resolutions, then ``resolution_tNtN`` should be \n``None``, and so each interval will be in the form \n``{ 'interval_tN: { None : <data_tN> } }`` and can be determined when a row\nhas an ``r_time`` of ``-1``.\n\nIf ``intervals`` is a list of 1, it's effectively a ``get`` query where\n``i_time = intervals[0]``, else it's ``i_time >= intervals[0] AND\ni_time <= intervals[-1]``. The full list of intervals is supplied to workaround\nCassandra's lack of grouping support in situations where an aggregate per\n``i_time`` is desired.\n\n\nDeleting Data\n-------------\n\ndelete\n******\n\nTakes a single argument, the name of the timeseries. Will delete all data for \nthat timeseries in all intervals.\n\ndelete_all\n**********\n\nDeletes every timeseries for all intervals. This method may be fast in data\nstores that support optimized deletes, else it will have to delete for each\ntimeseries returned in ``list``.\n\nexpire\n******\n\nTakes a single argument, the name of the timeseries. For storage engines that \ndo not support expiry, such as SQL, will delete expired data from intervals\nfor which ``steps`` is defined. All other storage engines will raise the\n``NotImplementedError`` exception.\n\nDragons!\n--------\n\nKairos achieves its efficiency by using TTLs and data structures\nin combination with a key naming scheme that generates consistent keys based on\nany timestamp relative to epoch. However, just like \n`RRDtool <http://oss.oetiker.ch/rrdtool/>`_, changing any attribute of the\ntimeseries means that new data will be stored differently than old data. For\nthis reason it's best to completely delete all data in an old time series\nbefore creating or querying using a new configuration.\n\nIf you want to migrate data, there are tools in \n`torus <https://github.com/agoragames/torus>`_ that can help.\n\n\nInstallation\n============\n\nKairos is available on `pypi <http://pypi.python.org/pypi/kairos>`_ and can be\ninstalled using ``pip`` ::\n\n  pip install kairos\n\n\nIf installing from source:\n\n* with development requirements (e.g. testing frameworks) ::\n\n    pip install -r development.pip\n\n* without development requirements ::\n\n    pip install -r requirements.pip\n\nNote that kairos does not install packages for any of the supported backends,\nand that you must do this yourself.\n\nTests\n=====\n\nUse `nose <https://github.com/nose-devs/nose/>`_ to run the test suite. ::\n\n  $ nosetests\n\nThe test suite can be controlled through several environment variables, all\ndefaulting to ``true``. \n\n* **TEST_REDIS** *true*\n* **TEST_MONGO** *true*\n* **TEST_SQL** *true*\n* **TEST_CASSANDRA** *true*\n* **TEST_SERIES** *true*\n* **TEST_HISTOGRAM** *true*\n* **TEST_COUNT** *true*\n* **TEST_GAUGE** *true*\n* **TEST_SET** *true*\n* **SQL_HOST** *sqlite:///:memory:*\n* **CASSANDRA_KEYSPACE** *kairos*\n\nRoadmap\n=======\n\n* Round-robbin intervals for datastores without TTLs\n* Round-robbin databases: memcache (and compatible, e.g. ElastiCache), Riak,\n  DynamoDB, SimpleDB, GDBM, Berkeley DB, and more\n* Redis optimizations\n* Capped collection support for mongo\n* Python 3 support\n* InfluxDB support\n* Bloom filters\n* Joined series populate a data structure at query time\n* Joined series support concurrency \"runner\"\n\nLicense\n=======\n\nThis software is licensed under the `New BSD License`. See the ``LICENSE.txt``\nfile in the top distribution directory for the full license text.\n\n.. # vim: syntax=rst expandtab tabstop=4 shiftwidth=4 shiftround", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/agoragames/kairos", "keywords": "python,redis,mongo,sql,mysql,sqlite,postgresql,cassandra,time,timeseries,rrd,gevent,statistics", "license": "LICENSE.txt", "maintainer": null, "maintainer_email": null, "name": "kairos", "package_url": "https://pypi.org/project/kairos/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/kairos/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/agoragames/kairos"}, "release_url": "https://pypi.org/project/kairos/0.10.1/", "requires_dist": null, "requires_python": null, "summary": "Time series data storage in Redis, Mongo, SQL and Cassandra", "version": "0.10.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <table>\n<col>\n<col>\n<tbody>\n<tr><th>Version:</th>\n<td>0.10.1</td></tr>\n<tr><th>Download:</th><td><a href=\"http://pypi.python.org/pypi/kairos\" rel=\"nofollow\">http://pypi.python.org/pypi/kairos</a></td>\n</tr>\n<tr><th>Source:</th><td><a href=\"https://github.com/agoragames/kairos\" rel=\"nofollow\">https://github.com/agoragames/kairos</a></td>\n</tr>\n<tr><th>Keywords:</th><td>python, redis, mongo, sql, mysql, sqlite, postgresql, cassandra, timeseries, rrd, gevent, statistics</td>\n</tr>\n</tbody>\n</table>\n<div id=\"contents\">\n<ul>\n<li><a href=\"#overview\" id=\"id12\" rel=\"nofollow\">Overview</a></li>\n<li><a href=\"#usage\" id=\"id13\" rel=\"nofollow\">Usage</a><ul>\n<li><a href=\"#constructor\" id=\"id14\" rel=\"nofollow\">Constructor</a></li>\n<li><a href=\"#storage-engines\" id=\"id15\" rel=\"nofollow\">Storage Engines</a><ul>\n<li><a href=\"#redis-redis\" id=\"id16\" rel=\"nofollow\">Redis (redis://)</a></li>\n<li><a href=\"#mongo-mongodb\" id=\"id17\" rel=\"nofollow\">Mongo (mongodb://)</a></li>\n<li><a href=\"#sql-sql\" id=\"id18\" rel=\"nofollow\">SQL (*sql*://)</a></li>\n<li><a href=\"#cassandra-cassandra-cql\" id=\"id19\" rel=\"nofollow\">Cassandra (cassandra://, cql://)</a></li>\n</ul>\n</li>\n<li><a href=\"#inserting-data\" id=\"id20\" rel=\"nofollow\">Inserting Data</a><ul>\n<li><a href=\"#insert\" id=\"id21\" rel=\"nofollow\">insert</a><ul>\n<li><a href=\"#redis\" id=\"id22\" rel=\"nofollow\">Redis</a></li>\n</ul>\n</li>\n<li><a href=\"#bulk-insert\" id=\"id23\" rel=\"nofollow\">bulk_insert</a><ul>\n<li><a href=\"#id6\" id=\"id24\" rel=\"nofollow\">Redis</a></li>\n<li><a href=\"#mongo\" id=\"id25\" rel=\"nofollow\">Mongo</a></li>\n<li><a href=\"#sql\" id=\"id26\" rel=\"nofollow\">SQL</a></li>\n<li><a href=\"#cassandra\" id=\"id27\" rel=\"nofollow\">Cassandra</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"#meta-data\" id=\"id28\" rel=\"nofollow\">Meta Data</a><ul>\n<li><a href=\"#list\" id=\"id29\" rel=\"nofollow\">list</a></li>\n<li><a href=\"#properties\" id=\"id30\" rel=\"nofollow\">properties</a></li>\n</ul>\n</li>\n<li><a href=\"#reading-data\" id=\"id31\" rel=\"nofollow\">Reading Data</a><ul>\n<li><a href=\"#get\" id=\"id32\" rel=\"nofollow\">get</a></li>\n<li><a href=\"#series\" id=\"id33\" rel=\"nofollow\">series</a></li>\n<li><a href=\"#iterate\" id=\"id34\" rel=\"nofollow\">iterate</a></li>\n</ul>\n</li>\n<li><a href=\"#customized-reads\" id=\"id35\" rel=\"nofollow\">Customized Reads</a><ul>\n<li><a href=\"#general\" id=\"id36\" rel=\"nofollow\">General</a><ul>\n<li><a href=\"#fetch\" id=\"id37\" rel=\"nofollow\">fetch</a></li>\n<li><a href=\"#process-row\" id=\"id38\" rel=\"nofollow\">process_row</a></li>\n<li><a href=\"#condense\" id=\"id39\" rel=\"nofollow\">condense</a></li>\n<li><a href=\"#join-rows\" id=\"id40\" rel=\"nofollow\">join_rows</a></li>\n<li><a href=\"#collapse\" id=\"id41\" rel=\"nofollow\">collapse</a></li>\n<li><a href=\"#transform\" id=\"id42\" rel=\"nofollow\">transform</a></li>\n</ul>\n</li>\n<li><a href=\"#id7\" id=\"id43\" rel=\"nofollow\">Redis</a></li>\n<li><a href=\"#id8\" id=\"id44\" rel=\"nofollow\">Mongo</a></li>\n<li><a href=\"#id9\" id=\"id45\" rel=\"nofollow\">SQL</a></li>\n<li><a href=\"#id10\" id=\"id46\" rel=\"nofollow\">Cassandra</a></li>\n</ul>\n</li>\n<li><a href=\"#deleting-data\" id=\"id47\" rel=\"nofollow\">Deleting Data</a><ul>\n<li><a href=\"#delete\" id=\"id48\" rel=\"nofollow\">delete</a></li>\n<li><a href=\"#delete-all\" id=\"id49\" rel=\"nofollow\">delete_all</a></li>\n<li><a href=\"#expire\" id=\"id50\" rel=\"nofollow\">expire</a></li>\n</ul>\n</li>\n<li><a href=\"#dragons\" id=\"id51\" rel=\"nofollow\">Dragons!</a></li>\n</ul>\n</li>\n<li><a href=\"#installation\" id=\"id52\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#tests\" id=\"id53\" rel=\"nofollow\">Tests</a></li>\n<li><a href=\"#roadmap\" id=\"id54\" rel=\"nofollow\">Roadmap</a></li>\n<li><a href=\"#license\" id=\"id55\" rel=\"nofollow\">License</a></li>\n</ul>\n</div>\n<div id=\"overview\">\n<span id=\"kairos-overview\"></span><h2><a href=\"#id12\" rel=\"nofollow\">Overview</a></h2>\n<p>Kairos provides time series storage using Redis, Mongo, SQL or Cassandra\nbackends. Kairos is intended to replace RRD and Whisper in situations where\nthe scale and flexibility of other data stores is required. It works with\n<a href=\"http://www.gevent.org/\" rel=\"nofollow\">gevent</a> and is the library on which\n<a href=\"https://github.com/agoragames/torus\" rel=\"nofollow\">torus</a> is built.</p>\n<p>Recommended for python 2.7 and later, it can work with previous versions if you\ninstall <a href=\"https://pypi.python.org/pypi/ordereddict\" rel=\"nofollow\">OrderedDict</a>.</p>\n<p>Kairos provides a consistent API for a variety of timeseries types and the\nstorage engines they\u2019re implemented in. Each timestamp is resolved to a\nconsistent bucket identifier (\u201cinterval\u201d) based on the number of whole seconds\nsince epoch, or a number corresponding to the Gregorian date associated with\nthe relative intervals  <tt>[daily, weekly, monthly, yearly]</tt> (e.g <tt>19991231</tt>).\nWithin that, data can optionally be stored at resolutions (e.g. \u201cdaily,\nin 1 hour increments\u201d). Multiple intervals can be tracked within a timeseries,\neach with its own resolution and optional TTL (e.g. 60 days of daily data,\nlifetime monthly data).</p>\n<p>In data stores that support it, TTLs can be set for automatically deleting\ndata after a set number of intervals; other data stores expose an <tt>expire()</tt>\nmethod for deleting data programmatically.</p>\n<p>Within each interval (or resolution), data is stored according to the type of\nthe timeseries and what each backend supports. The values tracked in each\ntimeseries can be loosely typed for backends that support it, else the type\nwill be whatever is set in the timeseries constructor. Even when loosely typed,\nit should be assumed that the value should be a string or number.</p>\n<dl>\n<dt>series</dt>\n<dd>All data will be stored in the order in which it arrives. Uses data store\nlist types where supported, else it will be timestamped records that\ncome as close as possible to the order in which they were written. Queries\nwill return list objects.</dd>\n<dt>histogram</dt>\n<dd>A hash of unique values to the number of its occurrences within an interval.\nUses data store dictionaries where supported, else it will be separate\nrecords for each unique value and timestamp. Queries will return dictionary\nobjects. Built-in transforms assume that keys are real numbers.</dd>\n<dt>count</dt>\n<dd>A simple counter will be maintained for each interval, starting at 0 for\nan interval. Queries will return an integer.</dd>\n<dt>gauge</dt>\n<dd>Stores the last-written value for each interval. Queries will return whatever\nthe value type was.</dd>\n<dt>set</dt>\n<dd>Stores all the unique values within an interval. Uses data store sets where\nsupported, else it will be separate records for each unique value. Queries\nwill return set objects.</dd>\n</dl>\n</div>\n<div id=\"usage\">\n<h2><a href=\"#id13\" rel=\"nofollow\">Usage</a></h2>\n<p>Kairos supports all storage engines using the same API. The constructor will\nreturn a Timeseries instance tailored for the type of data and the storage\nengine, and the API for updating and querying the timeseries is consistent\nfor all combinations of data type and storage engine.</p>\n<div id=\"constructor\">\n<h3><a href=\"#id14\" rel=\"nofollow\">Constructor</a></h3>\n<p>The first argument is a handle to a supported storage engine or a URL (see\nbelow), and the rest of the keyword arguments configure the timeseries. The\nkeyword arguments supported by all storage engines are:</p>\n<dl>\n<dt>type</dt>\n<dd>Required, defines the type of the timeseries. Raises a <tt>NotImplementedError</tt>\nif the backend does not support the type.</dd>\n<dt>read_func</dt>\n<dd>Optional, is a function applied to all values read back from the\ndatabase. Without it, values will be strings for Redis, whatever\n<cite>write_func</cite> defined for Mongo. Must accept a string value for Redis\n(empty string for no data) and can return anything.</dd>\n<dt>write_func</dt>\n<dd>Optional, is a function applied to all values when writing. Can be\nused for histogram resolution, converting an object into an id, etc.\nMust accept whatever can be inserted into a timeseries and return an\nobject which can be saved according to the rules of the storage engine.</dd>\n<dt>intervals</dt>\n<dd><p>Required, a dictionary of interval configurations in the form of:</p>\n<pre>{\n  # interval name, used in keys and should conform to best\n  # practices according to the storage engine.\n  minute: {\n\n    # Required. The number of seconds that the interval will cover,\n    # or a supported Gregorian interval.\n    step: 60,\n\n    # Optional. The maximum number of intervals to maintain. If supplied,\n    # will use Redis and Mongo expiration to delete old intervals, else\n    # intervals exist in perpetuity. If the storage engine doesn't support\n    # expiry, will be used to implement the expire() call.\n    steps: 240,\n\n    # Optional. Defines the resolution of the data, i.e. the number of\n    # seconds in which data is assumed to have occurred \"at the same time\".\n    # So if you're tracking a month-long time series, you may only need\n    # resolution down to the day, or resolution=86400. Defaults to same\n    # value as \"step\". Can also be a Gregorian interval.\n    resolution: 60,\n  }\n}\n</pre>\n<p>In addition to specifying <tt>step</tt> and <tt>resolution</tt> in terms of seconds,\nkairos also supports a simplified format for larger time intervals. For\nhours (h), days (d), weeks (w), months (m) and years (y), you can use\nthe format <tt>30d</tt> to represent 30 days, for example.</p>\n<p>As of <tt>0.3.0</tt>, kairos also supports the Gregorian calendar for <tt>step</tt>\nand <tt>resolution</tt>. Either or both parameters can use the terms <tt>[daily,\nweekly, monthly, yearly]</tt> to describe an interval. You can also mix these\nterms between <tt>step</tt> and <tt>resolution</tt> (e.g. <tt>daily</tt> in\n<tt>1h</tt> resolutions). The expiration time for Gregorian dates is still defined\nin terms of seconds and may not match the varying month lengths, leap years,\netc. Gregorian dates are translated into <tt>strptime</tt>- and <tt>strftime</tt>-compatible\nkeys (as integers) and so may be easier to use in raw form or with any\nexternal tools. The <tt>duration</tt> parameter to transforms run on gregorian\nseries will be seconds in whole number of days (where a day is 86400 seconds).</p>\n</dd>\n</dl>\n</div>\n<div id=\"storage-engines\">\n<h3><a href=\"#id15\" rel=\"nofollow\">Storage Engines</a></h3>\n<p>Each of the supported storage engines also supports a set of keyword arguments\nto configure their behavior. When intializing with a URL, the keyword argument\n<tt>client_config</tt> can optionally be a dictionary which will be passed as\nkeyword arguments to the constructor for the client associated with the URL.\nIf kairos implements any custom keyword arguments from <tt>client_config</tt> those\nare documented below.</p>\n<div id=\"redis-redis\">\n<h4><a href=\"#id16\" rel=\"nofollow\">Redis (redis://)</a></h4>\n<p>An example timeseries stored in Redis:</p>\n<pre>from kairos import Timeseries\nimport redis\n\nclient = redis.Redis('localhost', 6379)\nt = Timeseries(client, type='histogram', read_func=int, intervals={\n  'minute':{\n    'step':60,            # 60 seconds\n    'steps':120,          # last 2 hours\n  }\n})\n\nt.insert('example', 3.14159)\nt.insert('example', 2.71828)\nprint t.get('example', 'minute')\n</pre>\n<p>Additional keyword arguments are:</p>\n<pre>prefix\n  Optional, is a prefix for all keys in this timeseries. If\n  supplied and it doesn't end with \":\", it will be automatically appended.\n</pre>\n<p>Supported URL <a href=\"https://github.com/andymccurdy/redis-py/blob/master/redis/client.py#L332\" rel=\"nofollow\">formats</a>:</p>\n<pre>redis://localhost\nredis://localhost/3\n</pre>\n<p>All <a href=\"https://github.com/andymccurdy/redis-py/blob/master/redis/client.py#L361\" rel=\"nofollow\">supported</a> configuration options can be passed in <tt>client_config</tt>.</p>\n</div>\n<div id=\"mongo-mongodb\">\n<h4><a href=\"#id17\" rel=\"nofollow\">Mongo (mongodb://)</a></h4>\n<p>An example timeseries stored in Mongo:</p>\n<pre>from kairos import Timeseries\nimport pymongo\n\nclient = pymongo.MongoClient('localhost')\nt = Timeseries(client, type='histogram', read_func=float, intervals={\n  'minute':{\n    'step':60,            # 60 seconds\n    'steps':120,          # last 2 hours\n  }\n})\n\nt.insert('example', 3.14159)\nt.insert('example', 2.71828)\nprint t.get('example', 'minute')\n</pre>\n<p>Additional keyword arguments are:</p>\n<pre>escape_character\n  Optional, defines the character used to escape periods. Defaults to the\n  unicode character \"U+FFFF\".\n</pre>\n<p>Supported URL <a href=\"http://docs.mongodb.org/manual/reference/connection-string/\" rel=\"nofollow\">formats</a>:</p>\n<pre>mongodb://localhost\nmongodb://localhost:27018/timeseries\nmongodb://guest:host@localhost/authed_db\n</pre>\n<p>All <a href=\"http://api.mongodb.org/python/current/api/pymongo/mongo_client.html\" rel=\"nofollow\">supported</a> configuration arguments can be passed in <tt>client_config</tt>, in addition to:</p>\n<pre>database\n  The name of the database to use. Defaults to 'kairos'. Required if using\n  an auth database. Overrides any database provided in the URL.\n</pre>\n</div>\n<div id=\"sql-sql\">\n<h4><a href=\"#id18\" rel=\"nofollow\">SQL (*sql*://)</a></h4>\n<p>An example timeseries stored in a SQLite memory store:</p>\n<pre>from kairos import Timeseries\nfrom sqlalchemy import create_engine\n\nclient = create_engine('sqlite:///:memory:')\nt = Timeseries(client, type='histogram', read_func=int, intervals={\n  'minute':{\n    'step':60,            # 60 seconds\n    'steps':120,          # last 2 hours\n  }\n})\n\nt.insert('example', 3.14159)\nt.insert('example', 2.71828)\nprint t.get('example', 'minute')\n</pre>\n<p>Additional keyword arguments are:</p>\n<pre>string_length\n  Optional, configures the length of strings (VARCHARs). Defaults to 255.\n  All tables have at least 2 string columns, and the size of these columns\n  may impact usability of the SQL storage engine.\n\ntext_length\n  Optional, configures the length of TEXT and BLOB columns. Defaults to\n  32Kbytes. Only matters if value_type is a text or blob.\n\ntable_name\n  Optional, overrides the default table name for a timeseries type.\n\nvalue_type\n  Optional, defines the type of value to be stored in the timeseries.\n  Defaults to float. Can be a string, a Python type or a SQLAlchemy type\n  or instance.\n\n  'blob'\n  'bool'\n  &lt;type 'bool'&gt;\n  'boolean'\n  'clob'\n  'date'\n  &lt;type 'datetime.date'&gt;\n  'datetime'\n  &lt;type 'datetime.datetime'&gt;\n  'decimal'\n  &lt;class 'decimal.Decimal'&gt;\n  'float'\n  &lt;type 'float'&gt;\n  'int'\n  'int64'\n  'integer'\n  &lt;type 'int'&gt;\n  'long'\n  &lt;type 'long'&gt;\n  'str'\n  'string'\n  &lt;type 'str'&gt;\n  'text'\n  'time'\n  &lt;type 'datetime.time'&gt;\n  'unicode'\n  &lt;type 'unicode'&gt;\n</pre>\n<p>Supported URL <a href=\"http://docs.sqlalchemy.org/en/rel_0_9/core/engines.html#database-urls\" rel=\"nofollow\">formats</a> are many and varied. A few examples:</p>\n<pre>sqlite:///:memory:\npostgresql://scott:tiger@localhost/mydatabase\nmysql+mysqldb://scott:tiger@localhost/foo\noracle://scott:tiger@127.0.0.1:1521/sidname\n</pre>\n<p>All <a href=\"http://docs.sqlalchemy.org/en/rel_0_9/core/engines.html#sqlalchemy.create_engine\" rel=\"nofollow\">supported</a> constructor arguments can be used in <tt>client_config</tt>.</p>\n</div>\n<div id=\"cassandra-cassandra-cql\">\n<h4><a href=\"#id19\" rel=\"nofollow\">Cassandra (cassandra://, cql://)</a></h4>\n<p>An example timeseries stored in Cassandra:</p>\n<pre>from kairos import Timeseries\nimport cql\n\nclient = cql.connect('localhost', 9160, 'keyspace', cql_version='3.0.0')\nt = Timeseries(client, type='histogram', read_func=int, intervals={\n  'minute':{\n    'step':60,            # 60 seconds\n    'steps':120,          # last 2 hours\n  }\n})\n\nt.insert('example', 3.14159)\nt.insert('example', 2.71828)\nprint t.get('example', 'minute')\n</pre>\n<p>Additional keyword arguments are:</p>\n<pre>table_name\n  Optional, overrides the default table name for a timeseries type.\n\npool_size\n  Optional, set a cap on the pool size. Defines the maximum number of\n  connections to maintain in the pool. Defaults to 0 for no maximum.\n\nvalue_type\n  Optional, defines the type of value to be stored in the timeseries.\n  Defaults to float. Can be a string or a Python type.\n\n  &lt;type 'unicode'&gt;\n  string\n  decimal\n  &lt;type 'long'&gt;\n  int\n  double\n  unicode\n  float\n  long\n  &lt;type 'bool'&gt;\n  &lt;type 'float'&gt;\n  boolean\n  int64\n  str\n  text\n  blob\n  clob\n  integer\n  bool\n  &lt;type 'str'&gt;\n  &lt;type 'int'&gt;\n  inet\n</pre>\n<p>Supported URL formats are:</p>\n<pre>cql://\ncassandra://localhost:9160\ncassandra://localhost/database\n</pre>\n<p>All <a href=\"https://code.google.com/a/apache-extras.org/p/cassandra-dbapi2/source/browse/cql/connection.py\" rel=\"nofollow\">supported</a> constructor arguments can be used in <tt>client_config</tt>.</p>\n<p>kairos requires <a href=\"https://pypi.python.org/pypi/cql\" rel=\"nofollow\">cql</a> as it supports\n<a href=\"https://cassandra.apache.org/doc/cql3/CQL.html\" rel=\"nofollow\">CQL3</a> and gevent. This\nrequires that the keyspace be created before the connection, and the keyword\nargument <tt><span class=\"pre\">cql_version='3.0.0'</span></tt> must be used.</p>\n<p>A notable downside of this library is that it does not support a list of\nendpoints to connect to, so is missing key High Availability features.</p>\n<p>It is likely that future versions of kairos will require\n<a href=\"https://github.com/datastax/python-driver\" rel=\"nofollow\">cassandra-driver</a> when it\nis ready.</p>\n<p>Cassandra counters can only store integers, and cannot be used for a\nrunning total of floating point numbers.</p>\n<p>Kairos implements a connection pooling mechanism on top of <cite>cql</cite>. The pool\nis a simple soft-cap on the number of connections maintained in the pool,\nbut not necessarily the total number of connections at a time. An optional\nhard cap may be implemented in a future release.</p>\n</div>\n</div>\n<div id=\"inserting-data\">\n<h3><a href=\"#id20\" rel=\"nofollow\">Inserting Data</a></h3>\n<p>There are two methods to insert data, <tt>Timeseries.insert</tt> and <tt>Timeseries.bulk_insert</tt>.</p>\n<div id=\"insert\">\n<h4><a href=\"#id21\" rel=\"nofollow\">insert</a></h4>\n<ul>\n<li><strong>name</strong> The name of the statistic</li>\n<li><strong>value</strong> The value of the statistic (optional for count timeseries), or a list of values</li>\n<li><strong>timestamp</strong> <cite>(optional)</cite> The timestamp of the statistic, defaults to <tt>time.time()</tt> if not supplied</li>\n<li><strong>intervals</strong> <cite>(optional)</cite> The number of time intervals before (&lt;0) or after (&gt;0) <tt>timestamp</tt> to copy the data</li>\n<li><strong>**kwargs</strong> <cite>(optional)</cite> Any additional keyword arguments supported by a backend, see below</li>\n</ul>\n<p>For <tt>series</tt> and <tt>histogram</tt> timeseries types, <tt>value</tt> can be whatever\nyou\u2019d like, optionally processed through the <tt>write_func</tt> method before being\nwritten to storage. Depending on your needs, <tt>value</tt> (or the output of\n<tt>write_func</tt>) does not have to be a number, and can be used to track such\nthings as unique occurances of a string or references to other objects, such\nas MongoDB ObjectIds. Note that many of the aggregate functions in <tt>histogram</tt>\nexpect the data to be real numbers.</p>\n<p>For the <tt>count</tt> type, <tt>value</tt> is optional and should be a float or integer\nrepresenting the amount by which to increment or decrement <tt>name</tt>; it defaults\nto <tt>1</tt>.</p>\n<p>For the <tt>gauge</tt> type, <tt>value</tt> can be anything and it will be stored as-is.</p>\n<p>For all timeseries types, if <tt>value</tt> is one of <tt>(list,tuple,set)</tt>, will\ncall <tt>bulk_insert</tt>.</p>\n<p>The <tt>intervals</tt> option allows the caller to simulate the value appearing in\ntime periods before or after the <tt>timestamp</tt>. This is useful for creating\nfast trending (e.g. \u201ccount over last seven days\u201d). It is important to note\nthat, because the time periods are simulated, resolution is lost for the\nthe simulated timestamps.</p>\n<div id=\"redis\">\n<h5><a href=\"#id22\" rel=\"nofollow\">Redis</a></h5>\n<p>Redis supports an additional keyword argument, <tt>pipeline</tt>, to give the caller\ncontrol over batches of commands. If <tt>pipeline</tt> is supplied, the <tt>execute</tt>\nmethod will not be called and it is up to the caller to do so.</p>\n</div>\n</div>\n<div id=\"bulk-insert\">\n<h4><a href=\"#id23\" rel=\"nofollow\">bulk_insert</a></h4>\n<ul>\n<li><strong>inserts</strong> The structure of inserts (see below)</li>\n<li><strong>intervals</strong> <cite>(optional)</cite> The number of time intervals before (&lt;0) or after (&gt;0) <tt>timestamp</tt> to copy the data</li>\n<li><strong>**kwargs</strong> <cite>(optional)</cite> Any additional keyword arguments supported by a backend, see below</li>\n</ul>\n<p>The <tt>inserts</tt> field must take the following form:</p>\n<pre>{\n  timestamp : {\n    name: [ value, ... ],\n    ...\n  },\n  ...\n}\n</pre>\n<p>The meaning of <tt>timestamp</tt>, <tt>name</tt> and <tt>value</tt> are identical to those\nparameters in <tt>insert</tt>. The caller can insert any number of timestamps,\nstatistic names and values, and the backend will optimize the insert where\npossible. See details on the different backends below. Where a backend does\nnot support an optimized bulk insert, the data structure will be processed\nsuch that each value will be passed to <tt>insert</tt>.</p>\n<p>The <tt>inserts</tt> structure can be a <tt>dict</tt> or <tt>OrderedDict</tt>. If you need\nthe insert order preserved, such as when inserting into a <tt>series</tt> or\n<tt>gauge</tt>, you should use <tt>OrderedDict</tt>.</p>\n<p>If <tt>timestamp</tt> is unknown, use <tt>None</tt> for the key and it will be set to\nthe current value of <tt>time.time()</tt>. Note that this may alter ordering if\n<tt>inserts</tt> is an <tt>OrderedDict</tt>.</p>\n<p><strong>NOTE</strong> bulk inserts will increase memory usage of the client process.</p>\n<div id=\"id6\">\n<h5><a href=\"#id24\" rel=\"nofollow\">Redis</a></h5>\n<p>Redis bulk inserts are implemented by using a single pipeline (without\ntransactions) and committing the pipeline after all bulk inserts have been\nexecuted. The bulk insert also supports the <tt>pipeline</tt> argument, with the\nsame rules as <tt>insert</tt>.</p>\n</div>\n<div id=\"mongo\">\n<h5><a href=\"#id25\" rel=\"nofollow\">Mongo</a></h5>\n<p>Mongo bulk inserts are implemented by joining all of the data together into\na condensed set of queries and updates. As the configuration of a timeseries\nmay result in multiple timestamps resolving to the same record (e.g. per-day\ndata), this could result in significant performance gains when the timeseries\nis a <tt>count</tt>, <tt>histogram</tt> or <tt>gauge</tt>.</p>\n</div>\n<div id=\"sql\">\n<h5><a href=\"#id26\" rel=\"nofollow\">SQL</a></h5>\n<p>There is no optimization for bulk inserts in SQL due to the lack of\nnative update-or-insert support. The generic SQL implementation requires an\nattempted update to be committed before kairos can determine if an insert is\nrequired. Future versions may have optimized implementations for specific\nSQL servers which support such a feature, at which time bulk inserts may be\noptimized for those specific backends.</p>\n</div>\n<div id=\"cassandra\">\n<h5><a href=\"#id27\" rel=\"nofollow\">Cassandra</a></h5>\n<p>The <tt>cql</tt> library has no support for transactions, grouping, etc.</p>\n</div>\n</div>\n</div>\n<div id=\"meta-data\">\n<h3><a href=\"#id28\" rel=\"nofollow\">Meta Data</a></h3>\n<p>There are two methods to query meta data about a Timeseries.</p>\n<div id=\"list\">\n<h4><a href=\"#id29\" rel=\"nofollow\">list</a></h4>\n<p>There are no arguments. Returns a list of all of the stat names stored\nin the Timeseries.</p>\n</div>\n<div id=\"properties\">\n<h4><a href=\"#id30\" rel=\"nofollow\">properties</a></h4>\n<p>Takes a single argument, the name of the timeseries. Returns a dictionary\nwith the following fields:</p>\n<pre>{ interval : { 'first' : timestamp, 'last' : timestamp } }\n</pre>\n<p><tt>interval</tt> will be the named interval, such as \u201cminute\u201d. For each interval,\nthere is a dictionary of properties. <tt>first</tt> is the timestamp of the first\ndata point in the timeseries, and <tt>last</tt> is the last data point in the\ntimeseries.</p>\n</div>\n</div>\n<div id=\"reading-data\">\n<h3><a href=\"#id31\" rel=\"nofollow\">Reading Data</a></h3>\n<p>There are three methods to read data, <tt>Timeseries.get</tt>, <tt>Timeseries.series</tt>\nand <tt>Timeseries.iterate</tt>. <tt>get</tt> will return data from a single bucket,\nand <tt>series</tt> will return data from several buckets. <tt>iterate</tt> will use\nthe <tt>Timeseries.properties</tt> method to determine the date range of the data,\nand return a generator that calls <tt>get</tt> for every possible interval in\nthe date range.</p>\n<div id=\"get\">\n<h4><a href=\"#id32\" rel=\"nofollow\">get</a></h4>\n<p>Supports the following parameters. All optional parameters are keyword arguments.</p>\n<ul>\n<li><strong>name</strong> The name of the statistic, or a list of names whose data will be joined together.</li>\n<li><strong>interval</strong> The named interval to read from</li>\n<li><strong>timestamp</strong> <cite>(optional)</cite> The timestamp to read, defaults to <tt>time.time()</tt></li>\n<li><strong>condensed</strong> <cite>(optional)</cite> <strong>DEPRECATED</strong> Use <tt>condense</tt> instead. Support for this will be removed entirely in a future release.</li>\n<li><strong>transform</strong> <cite>(optional)</cite> Optionally process each row of data. Supports <tt>[mean, count, min, max, sum]</tt>, or any callable that accepts datapoints according to the type of series (e.g histograms are dictionaries, counts are integers, etc). Transforms are called after <tt>read_func</tt> has cast the data type and after resolution data is optionally condensed. If <tt>transform</tt> is one of <tt>(list,tuple,set)</tt>, will load the data once and run all the transforms on that data set. If <tt>transform</tt> is a <tt>dict</tt> of the form <tt>{ transform_name : transform_func }</tt>, will run all of the transform functions on the data set. See <a href=\"#customized-reads\" rel=\"nofollow\">Customized Reads</a> for more on custom transforms.</li>\n<li><strong>fetch</strong> <cite>(optional)</cite> Function to use instead of the built-in implementations for fetching data. See <a href=\"#customized-reads\" rel=\"nofollow\">Customized Reads</a>.</li>\n<li><strong>process_row</strong> <cite>(optional)</cite> Can be a callable to implement <a href=\"#customized-reads\" rel=\"nofollow\">Customized Reads</a>.</li>\n<li><strong>condense</strong> <cite>(optional)</cite> If using resolutions, <tt>True</tt> will collapse the resolution data into a single row. Can be a callable to implement <a href=\"#customized-reads\" rel=\"nofollow\">Customized Reads</a>.</li>\n<li><strong>join_rows</strong> <cite>(optional)</cite> Can be a callable to implement <a href=\"#customized-reads\" rel=\"nofollow\">Customized Reads</a>.</li>\n</ul>\n<p>Returns a dictionary of <tt>{ timestamp : data }</tt>, where <tt>timestamp</tt> is a Unix timestamp\nand <tt>data</tt> is a data structure corresponding to the type of series, or whatever\n<tt>transform</tt> returns.  If not using resolutions or <tt>condense=True</tt>, the length\nof the dictionary is 1, else it will be the number of resolution buckets within\nthe interval that contained data. If <tt>transform</tt> is a list, <tt>data</tt> will be a\ndictionary of <tt>{ transform_func : transformed_data }</tt>. If <tt>transform</tt> is a <tt>dict</tt>,\n<tt>data</tt> will be a dictionary of <tt>{ transform_name : transformed_data }</tt>.</p>\n</div>\n<div id=\"series\">\n<h4><a href=\"#id33\" rel=\"nofollow\">series</a></h4>\n<p>Almost identical to <tt>get</tt>, supports the following parameters. All optional parameters are keyword arguments.</p>\n<ul>\n<li><strong>name</strong> The name of the statistic, or a list of names whose data will be joined together.</li>\n<li><strong>interval</strong> The named interval to read from</li>\n<li><strong>start</strong> <cite>(optional)</cite> The timestamp which should be in the first interval of the returned data.</li>\n<li><strong>end</strong> <cite>(optional)</cite> The timestamp which should be in the last interval of the returned data.</li>\n<li><strong>steps</strong> <cite>(optional)</cite> The number of steps in the interval to read, defaults to either <tt>steps</tt> in the configuration or 1. Ignored if both <tt>start</tt> and <tt>end</tt> are defined. If either <tt>start</tt> or <tt>end</tt> are defined, <tt>steps</tt> is inclusive of whatever interval that timestamp falls into.</li>\n<li><strong>condensed</strong> <cite>(optional)</cite> <strong>DEPRECATED</strong> Use <tt>condense</tt> instead. Support for this will be removed entirely in a future release.</li>\n<li><strong>transform</strong> <cite>(optional)</cite> Optionally process each row of data. Supports <tt>[mean, count, min, max, sum]</tt>, or any callable that accepts a list of datapoints according to the type of series (e.g histograms are dictionaries, counts are integers, etc). Transforms are called after <tt>read_func</tt> has cast the data type and after resolution data is optionally condensed. If <tt>transform</tt> is one of <tt>(list,tuple,set)</tt>, will load the data once and run all the transforms on that data set. If <tt>transform</tt> is a <tt>dict</tt> of the form <tt>{ transform_name : transform_func }</tt>, will run all of the transform functions on the data set. See <a href=\"#customized-reads\" rel=\"nofollow\">Customized Reads</a> for more on custom transforms.</li>\n<li><strong>fetch</strong> <cite>(optional)</cite> Function to use instead of the built-in implementations for fetching data. See <a href=\"#customized-reads\" rel=\"nofollow\">Customized Reads</a>.</li>\n<li><strong>process_row</strong> <cite>(optional)</cite> Can be a callable to implement <a href=\"#customized-reads\" rel=\"nofollow\">Customized Reads</a>.</li>\n<li><strong>condense</strong> <cite>(optional)</cite> If using resolutions, <tt>True</tt> will collapse the resolution data into a single row. Can be a callable to implement <a href=\"#customized-reads\" rel=\"nofollow\">Customized Reads</a>.</li>\n<li><strong>join_rows</strong> <cite>(optional)</cite> Can be a callable to implement <a href=\"#customized-reads\" rel=\"nofollow\">Customized Reads</a>.</li>\n<li><strong>collapse</strong> <cite>(optional)</cite> <tt>True</tt> will collapse all of the data in the date range into a single result. Can be a callable to implement <a href=\"#customized-reads\" rel=\"nofollow\">Customized Reads</a>.</li>\n</ul>\n<p>Returns an ordered dictionary of <tt>{ interval_timestamp : { resolution_timestamp: data } }</tt>,\nwhere <tt>interval_timestamp</tt> and <tt>resolution_timestamp</tt> are Unix timestamps\nand <tt>data</tt> is a data structure corresponding to the type of series, or whatever\n<tt>transform</tt> returns.  If not using resolutions or <tt>condense=True</tt>, the dictionary\nwill be of the form <tt>{ interval_timestamp : data }</tt>.</p>\n<p>All variations of <tt>transform</tt> and the resulting format of <tt>data</tt> are the same\nas in <tt>get</tt>.</p>\n<p>If both <tt>start</tt> and <tt>end</tt> are defined, the returned data will start and end\non intervals including those timestamps. If only <tt>start</tt> is defined, then the\nreturn data will start with an interval that includes that timestamp, with the\ntotal number of intervals returned defined by <tt>steps</tt>. If only <tt>end</tt> is\ndefined, then the return data will end with an interval that includes that\ntimestamp, with the total number of intervals preceeding it defined by <tt>steps</tt>.</p>\n<p>It is important to note that the interval timestamps in the returned data will\nnot necessarily match <tt>start</tt> or <tt>end</tt>. This is because of the consistent\nhashing scheme that kairos uses, such that <tt>start</tt> and <tt>end</tt> will be\ntranslated into the bucket in which it can be found.</p>\n</div>\n<div id=\"iterate\">\n<h4><a href=\"#id34\" rel=\"nofollow\">iterate</a></h4>\n<p>Almost identical to <tt>get</tt> except it does not accept a <tt>timestamp</tt> argument.</p>\n<ul>\n<li><strong>name</strong> The name of the statistic, or a list of names whose data will be joined together.</li>\n<li><strong>interval</strong> The named interval to read from</li>\n<li><strong>transform</strong> <cite>(optional)</cite> Optionally process each row of data. Supports <tt>[mean, count, min, max, sum]</tt>, or any callable that accepts datapoints according to the type of series (e.g histograms are dictionaries, counts are integers, etc). Transforms are called after <tt>read_func</tt> has cast the data type and after resolution data is optionally condensed. If <tt>transform</tt> is one of <tt>(list,tuple,set)</tt>, will load the data once and run all the transforms on that data set. If <tt>transform</tt> is a <tt>dict</tt> of the form <tt>{ transform_name : transform_func }</tt>, will run all of the transform functions on the data set. See <a href=\"#customized-reads\" rel=\"nofollow\">Customized Reads</a> for more on custom transforms.</li>\n<li><strong>fetch</strong> <cite>(optional)</cite> Function to use instead of the built-in implementations for fetching data. See <a href=\"#customized-reads\" rel=\"nofollow\">Customized Reads</a>.</li>\n<li><strong>process_row</strong> <cite>(optional)</cite> Can be a callable to implement <a href=\"#customized-reads\" rel=\"nofollow\">Customized Reads</a>.</li>\n<li><strong>condense</strong> <cite>(optional)</cite> If using resolutions, <tt>True</tt> will collapse the resolution data into a single row. Can be a callable to implement <a href=\"#customized-reads\" rel=\"nofollow\">Customized Reads</a>.</li>\n<li><strong>join_rows</strong> <cite>(optional)</cite> Can be a callable to implement <a href=\"#customized-reads\" rel=\"nofollow\">Customized Reads</a>.</li>\n</ul>\n<p>Returns a generator which iterates over <tt>( timestamp, data )</tt> tuples, where\n<tt>timestamp</tt> is a Unix timestamp and <tt>data</tt> corresponds to the rules\ndocumented in <tt>get</tt>. Yields a tuple for each potential timestamp in the\nentire date range of the timeseries, even if there is no data.</p>\n</div>\n</div>\n<div id=\"customized-reads\">\n<h3><a href=\"#id35\" rel=\"nofollow\">Customized Reads</a></h3>\n<p><strong>ALPHA</strong> This feature is still being explored and the API may change significantly.</p>\n<p>There are times when the data in a timeseries requires processing to\nbe pushed onto the datastore.</p>\n<p>There are times when one needs custom control over the reading and processing\nof data in a timeseries. As there is no good way to do this generically,\nthe <tt>get</tt> and <tt>series</tt> API supports several keyword arguments to customize\naccess to the data. Common use cases are to handle large sets of data that\ncan be processed in the datastore, and situations where one wants to implement\ncutom analysis of the dataset such as calculating variance.</p>\n<div id=\"general\">\n<h4><a href=\"#id36\" rel=\"nofollow\">General</a></h4>\n<p>The following functions can be overloaded with keyword parameters to <tt>get</tt> and\n<tt>series</tt> (<tt>collapse</tt> being only used for a series).</p>\n<div id=\"fetch\">\n<h5><a href=\"#id37\" rel=\"nofollow\">fetch</a></h5>\n<p>A customized database read function. The usage varies depending on the backends\nwhich are described in detail below.\n<strong>IMPORTANT</strong> You are welcome to change the type of the return value, but be\nwary that transforms, condense and collapse functionality may not work\nproperly with the changed data types.</p>\n</div>\n<div id=\"process-row\">\n<h5><a href=\"#id38\" rel=\"nofollow\">process_row</a></h5>\n<p>The function which handles the type casting of the data read from the backend\nand also calling the <tt>read_func</tt> if it has been defined for the time series.\nIt is required that you define this function if you overload <tt>fetch</tt> such\nthat the returned data type is not the same as the time series\u2019 native format\n(<tt>dict</tt> for histogram, <tt>list</tt> for series, etc).</p>\n<p>The function must be in the form of <tt>process_row(data)</tt>, where:</p>\n<ul>\n<li><strong>data</strong> The row data generated by the native or <tt>fetch</tt> implementation, not\nincluding any time stamps.</li>\n</ul>\n<p>The function may return any data type, but if it\u2019s not the native format of the\ntime series, additional downstream functions may have to be overloaded.</p>\n</div>\n<div id=\"condense\">\n<h5><a href=\"#id39\" rel=\"nofollow\">condense</a></h5>\n<p>If the <tt>condense</tt> argument is a callable, the caller can override how resolution\ndata is collapsed (reduced) into a single interval. The argument will always be\nin the form of:</p>\n<pre>{\n  'resolution_t0' : &lt;data_t0&gt;,\n  'resolution_t1' : &lt;data_t1&gt;,\n  ...\n  'resolution_tN' : &lt;data_tN&gt;,\n}\n</pre>\n<p>Where <tt>&lt;data_tN&gt;</tt> is the data returned from the native or <tt>fetch</tt>\nimplementation and passed through the native or custom <tt>process_row</tt>\nimplementation.</p>\n<p>The function should return a single value, optionally in the same format as\n<tt>&lt;data_tN&gt;</tt>, but this method could also be used for calculating such\nthings as rate of change or variance within a time interval.</p>\n</div>\n<div id=\"join-rows\">\n<h5><a href=\"#id40\" rel=\"nofollow\">join_rows</a></h5>\n<p>If the <tt>join_rows</tt> argument is a callable and the <tt>name</tt> parameter to <tt>get</tt>\nor <tt>series</tt> is one of <tt>(list,tuple,set)</tt>, this method will be called to join\nthe data from several named timeseries into a single result. The argument will\nalways be in the form of:</p>\n<pre>[\n  &lt;data_series0&gt;,\n  &lt;data_series1&gt;,\n  ...\n  &lt;data_seriesN&gt;\n]\n</pre>\n<p>Where <tt>&lt;data_series0&gt;</tt> will be the data within a single timestamp window in\nthe series\u2019 native format or whatever was generated by custom implementations\nof <tt>fetch</tt>, <tt>process_row</tt> and/or <tt>condense</tt>. It is important to note\nthat not every series will contain data points within a given time interval.</p>\n<p>In addition to reducing multiple time series\u2019 worth of data within an interval\ninto a single result, this method could be used to implement cross-series\nanalytics such as unions, intersections and differentials.</p>\n</div>\n<div id=\"collapse\">\n<h5><a href=\"#id41\" rel=\"nofollow\">collapse</a></h5>\n<p>If the <tt>collapse</tt> argument is a callable, the caller can override how interval\ndata is collapsed (reduced) into a single result. The native implementation is to\ncall the <tt>condense</tt> function implemented by a time series. The arguments are\nthe same as a custom <tt>condense</tt> function, as-is the expected return value.</p>\n<p>It\u2019s important to note that if <tt>collapse</tt> is defined, the series will\nautomatically be condensed as well, so if <tt>fetch</tt> is overloaded to return a\ncustom data type, then <tt>condense</tt> must also be defined. If <tt>collapse</tt> is\n<tt>True</tt>, the custom <tt>condense</tt> function will be used if defined.</p>\n<p>In addition to collapsing the result of a time series into a single data set,\nthis method could also be used to calculate data across a time series, such as\nvariance.</p>\n</div>\n<div id=\"transform\">\n<h5><a href=\"#id42\" rel=\"nofollow\">transform</a></h5>\n<p>As noted previously, <tt>transform</tt> can be any callable, list of names or callables,\nor a named map of transform names or callables. The transforms will be processed\nafter all previous native or custom read functions, including <tt>collapse</tt>.</p>\n<p>Transforms must accept 2 parameters, the data and the time interval in seconds\nover which that data was captured. The <tt>data</tt> parameter will be of a type\ncorresponding to the timeseries type, or whatever was generated by a custom\n<tt>fetch</tt>. For example:</p>\n<pre>def custom_rate_for_counts(data, duration):\n  return float(data) / float(duration)\n</pre>\n<p>For gregorian timeseries, <tt>duration</tt> will seconds in terms of the whole\nnumber of days over which the data was captured, where a day is 86400 seconds.</p>\n</div>\n</div>\n<div id=\"id7\">\n<h4><a href=\"#id43\" rel=\"nofollow\">Redis</a></h4>\n<p>The function must be in the form of <tt>fetch(handle, key)</tt>, where:</p>\n<ul>\n<li><strong>handle</strong> Either a Redis client or pipeline instance</li>\n<li><strong>key</strong> The key for the timeseries data</li>\n</ul>\n<p>The return value should correspond to the data type of timeseries, e.g. <tt>dict</tt>\nfor a histogram. One should always assume that <tt>handle</tt> is both a pipeline\n<cite>and</cite> a client, and <tt>fetch</tt> should return the result of, e.g.\n<tt><span class=\"pre\">handle.hlen(...)</span></tt>, but that it cannot be used to return a literal, such\nas <tt>lambda: h,k: { 'foo' : h.hlen(k) }</tt></p>\n</div>\n<div id=\"id8\">\n<h4><a href=\"#id44\" rel=\"nofollow\">Mongo</a></h4>\n<p>The function must be in the form of <tt>fetch(handle, **kwargs)</tt>, where:</p>\n<ul>\n<li><strong>handle</strong> A PyMongo <tt>Collection</tt></li>\n<li><strong>spec</strong> The (suggested) query specification</li>\n<li><strong>sort</strong> The (suggested) sort definition for the query</li>\n<li><strong>method</strong> The suggested method to use on the <tt>handle</tt></li>\n</ul>\n<p>The required return value depends on the value of <tt>method</tt>.</p>\n<ul>\n<li><strong>find_one</strong> Should return a hash in the form <tt>{ value : &lt;data&gt; }</tt>, where\n<tt>&lt;data&gt;</tt> should correspond to the data type of the timeseries, e.g. <tt>list</tt>\nfor a series. May directly return a result from <tt>pymongo.collection.find_one</tt>.</li>\n<li><strong>find</strong> Should return an iterable in the form <tt>[ { value: &lt;data&gt; }, ... ]</tt>,\nwhere <tt>&lt;data&gt;</tt> follows the same rules as <tt>find_one</tt>.</li>\n</ul>\n<p>Re-implementing the default functionality would look like:</p>\n<pre>def mongo_fetch(handle, spec, sort, method):\n  if method=='find':\n    return handle.find( spec=spec, sort=sort )\n  elif method=='find_one':\n    return handle.find_one( spec )\n</pre>\n</div>\n<div id=\"id9\">\n<h4><a href=\"#id45\" rel=\"nofollow\">SQL</a></h4>\n<p>The function must be in the form\n<tt>fetch(connection, table, name, interval, i_start, i_end)</tt>, where:</p>\n<ul>\n<li><strong>connection</strong> A SQLAlchemy <tt>Connection</tt></li>\n<li><strong>table</strong> A SQLAlchemy <tt>Table</tt></li>\n<li><strong>name</strong> The name of the stat to fetch</li>\n<li><strong>interval</strong> The interval of the stat to fetch</li>\n<li><strong>i_start</strong> The interval timestamp (starting) key</li>\n<li><strong>i_end</strong> (optional) For a series, the ending timestamp key</li>\n</ul>\n<p>The return value should be in the form of</p>\n<pre>{\n  'interval_t0' : {\n    'resolution_t0t0' : &lt;data_t0t0&gt;,\n    'resolution_t0t1' : &lt;data_t0t1&gt;,\n    ...\n    'resolution_t0tN' : &lt;data_t0tN&gt;\n  },\n  'interval_t1' : { ... },\n  ...\n  'interval_tN' : { ... },\n}\n</pre>\n<p>If the series doesn\u2019t use resolutions, then <tt>resolution_tNtN</tt> should be\n<tt>None</tt>, and so each interval will be in the form\n<tt>{ 'interval_tN: { None : &lt;data_tN&gt; } }</tt>. This is inherent in the way that\ndata is stored within the tables.</p>\n<p>If <tt>i_end</tt> is supplied, the query should be over the range\n<tt>i_time &gt;= i_start AND i_time &lt;= i_end</tt>, else the query should be for\nthe interval <tt>i_time = i_start</tt>.</p>\n</div>\n<div id=\"id10\">\n<h4><a href=\"#id46\" rel=\"nofollow\">Cassandra</a></h4>\n<p>The function must be in the form\n<tt>fetch(connection, table, name, interval, i_start, i_end)</tt>, where:</p>\n<ul>\n<li><strong>cursor</strong> A <tt>cql</tt> <tt>Connection</tt></li>\n<li><strong>table</strong> The name of the table</li>\n<li><strong>name</strong> The name of the stat to fetch</li>\n<li><strong>interval</strong> The interval of the stat to fetch</li>\n<li><strong>intervals</strong> The list of interval timestamps</li>\n</ul>\n<p>The return value should be in the form of</p>\n<pre>{\n  'interval_t0' : {\n    'resolution_t0t0' : &lt;data_t0t0&gt;,\n    'resolution_t0t1' : &lt;data_t0t1&gt;,\n    ...\n    'resolution_t0tN' : &lt;data_t0tN&gt;\n  },\n  'interval_t1' : { ... },\n  ...\n  'interval_tN' : { ... },\n}\n</pre>\n<p>If the series doesn\u2019t use resolutions, then <tt>resolution_tNtN</tt> should be\n<tt>None</tt>, and so each interval will be in the form\n<tt>{ 'interval_tN: { None : &lt;data_tN&gt; } }</tt> and can be determined when a row\nhas an <tt>r_time</tt> of <tt><span class=\"pre\">-1</span></tt>.</p>\n<p>If <tt>intervals</tt> is a list of 1, it\u2019s effectively a <tt>get</tt> query where\n<tt>i_time = intervals[0]</tt>, else it\u2019s <tt>i_time &gt;= intervals[0] AND\ni_time &lt;= <span class=\"pre\">intervals[-1]</span></tt>. The full list of intervals is supplied to workaround\nCassandra\u2019s lack of grouping support in situations where an aggregate per\n<tt>i_time</tt> is desired.</p>\n</div>\n</div>\n<div id=\"deleting-data\">\n<h3><a href=\"#id47\" rel=\"nofollow\">Deleting Data</a></h3>\n<div id=\"delete\">\n<h4><a href=\"#id48\" rel=\"nofollow\">delete</a></h4>\n<p>Takes a single argument, the name of the timeseries. Will delete all data for\nthat timeseries in all intervals.</p>\n</div>\n<div id=\"delete-all\">\n<h4><a href=\"#id49\" rel=\"nofollow\">delete_all</a></h4>\n<p>Deletes every timeseries for all intervals. This method may be fast in data\nstores that support optimized deletes, else it will have to delete for each\ntimeseries returned in <tt>list</tt>.</p>\n</div>\n<div id=\"expire\">\n<h4><a href=\"#id50\" rel=\"nofollow\">expire</a></h4>\n<p>Takes a single argument, the name of the timeseries. For storage engines that\ndo not support expiry, such as SQL, will delete expired data from intervals\nfor which <tt>steps</tt> is defined. All other storage engines will raise the\n<tt>NotImplementedError</tt> exception.</p>\n</div>\n</div>\n<div id=\"dragons\">\n<h3><a href=\"#id51\" rel=\"nofollow\">Dragons!</a></h3>\n<p>Kairos achieves its efficiency by using TTLs and data structures\nin combination with a key naming scheme that generates consistent keys based on\nany timestamp relative to epoch. However, just like\n<a href=\"http://oss.oetiker.ch/rrdtool/\" rel=\"nofollow\">RRDtool</a>, changing any attribute of the\ntimeseries means that new data will be stored differently than old data. For\nthis reason it\u2019s best to completely delete all data in an old time series\nbefore creating or querying using a new configuration.</p>\n<p>If you want to migrate data, there are tools in\n<a href=\"https://github.com/agoragames/torus\" rel=\"nofollow\">torus</a> that can help.</p>\n</div>\n</div>\n<div id=\"installation\">\n<h2><a href=\"#id52\" rel=\"nofollow\">Installation</a></h2>\n<p>Kairos is available on <a href=\"http://pypi.python.org/pypi/kairos\" rel=\"nofollow\">pypi</a> and can be\ninstalled using <tt>pip</tt></p>\n<pre>pip install kairos\n</pre>\n<p>If installing from source:</p>\n<ul>\n<li><p>with development requirements (e.g. testing frameworks)</p>\n<pre>pip install -r development.pip\n</pre>\n</li>\n<li><p>without development requirements</p>\n<pre>pip install -r requirements.pip\n</pre>\n</li>\n</ul>\n<p>Note that kairos does not install packages for any of the supported backends,\nand that you must do this yourself.</p>\n</div>\n<div id=\"tests\">\n<h2><a href=\"#id53\" rel=\"nofollow\">Tests</a></h2>\n<p>Use <a href=\"https://github.com/nose-devs/nose/\" rel=\"nofollow\">nose</a> to run the test suite.</p>\n<pre>$ nosetests\n</pre>\n<p>The test suite can be controlled through several environment variables, all\ndefaulting to <tt>true</tt>.</p>\n<ul>\n<li><strong>TEST_REDIS</strong> <em>true</em></li>\n<li><strong>TEST_MONGO</strong> <em>true</em></li>\n<li><strong>TEST_SQL</strong> <em>true</em></li>\n<li><strong>TEST_CASSANDRA</strong> <em>true</em></li>\n<li><strong>TEST_SERIES</strong> <em>true</em></li>\n<li><strong>TEST_HISTOGRAM</strong> <em>true</em></li>\n<li><strong>TEST_COUNT</strong> <em>true</em></li>\n<li><strong>TEST_GAUGE</strong> <em>true</em></li>\n<li><strong>TEST_SET</strong> <em>true</em></li>\n<li><strong>SQL_HOST</strong> <em>sqlite:///:memory:</em></li>\n<li><strong>CASSANDRA_KEYSPACE</strong> <em>kairos</em></li>\n</ul>\n</div>\n<div id=\"roadmap\">\n<h2><a href=\"#id54\" rel=\"nofollow\">Roadmap</a></h2>\n<ul>\n<li>Round-robbin intervals for datastores without TTLs</li>\n<li>Round-robbin databases: memcache (and compatible, e.g. ElastiCache), Riak,\nDynamoDB, SimpleDB, GDBM, Berkeley DB, and more</li>\n<li>Redis optimizations</li>\n<li>Capped collection support for mongo</li>\n<li>Python 3 support</li>\n<li>InfluxDB support</li>\n<li>Bloom filters</li>\n<li>Joined series populate a data structure at query time</li>\n<li>Joined series support concurrency \u201crunner\u201d</li>\n</ul>\n</div>\n<div id=\"license\">\n<h2><a href=\"#id55\" rel=\"nofollow\">License</a></h2>\n<p>This software is licensed under the <cite>New BSD License</cite>. See the <tt>LICENSE.txt</tt>\nfile in the top distribution directory for the full license text.</p>\n</div>\n\n          </div>"}, "last_serial": 1236523, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "7d3d834ceb8ddb27126b2da703faa340", "sha256": "193af50471285fec28da644893242895b6165a41a858627f7dcb6111921ff57e"}, "downloads": -1, "filename": "kairos-0.0.1.tar.gz", "has_sig": false, "md5_digest": "7d3d834ceb8ddb27126b2da703faa340", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3211, "upload_time": "2012-04-11T21:34:57", "upload_time_iso_8601": "2012-04-11T21:34:57.924321Z", "url": "https://files.pythonhosted.org/packages/04/1b/6e41e0a4c4762b9ce73b8beb159af8d4ebf84765bf559db09b498ec158d8/kairos-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "b35ec9134ef9455a48d0bab2c9ef4070", "sha256": "b7de2a17ef983a03d3d3d6ab9c73d040071801185b4fe32dfc238cf689414eec"}, "downloads": -1, "filename": "kairos-0.0.2.tar.gz", "has_sig": false, "md5_digest": "b35ec9134ef9455a48d0bab2c9ef4070", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4686, "upload_time": "2012-04-12T22:32:09", "upload_time_iso_8601": "2012-04-12T22:32:09.406046Z", "url": "https://files.pythonhosted.org/packages/6a/31/d9f305b1dda9a76aa1023fbb0617f3f9f90ea1be2632f6bfd85dd4c934e4/kairos-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "745e786385b0e5e44e21a32398e4c387", "sha256": "b925d95fbd6de0ac16fb20a798bd8349eaea8a24cb8e6784b288e4669b59459a"}, "downloads": -1, "filename": "kairos-0.0.3.tar.gz", "has_sig": false, "md5_digest": "745e786385b0e5e44e21a32398e4c387", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5930, "upload_time": "2012-04-13T21:54:26", "upload_time_iso_8601": "2012-04-13T21:54:26.477546Z", "url": "https://files.pythonhosted.org/packages/a9/13/46596101780e240f3422fe3d8ac768a3ec89261882eb888bda38b686f86a/kairos-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "373345d9981ccc4556f394de182e78c4", "sha256": "176046c11ee28534782cf039d9237ac8388dc585fdff022131c4978940378ce1"}, "downloads": -1, "filename": "kairos-0.0.4.tar.gz", "has_sig": false, "md5_digest": "373345d9981ccc4556f394de182e78c4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5998, "upload_time": "2012-04-13T22:18:36", "upload_time_iso_8601": "2012-04-13T22:18:36.049314Z", "url": "https://files.pythonhosted.org/packages/db/19/8385ea4139245bbe79abda9bb9805976de22b537b443dd8e2c6017056420/kairos-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "cb0d2971db2b825955d74f19a01554da", "sha256": "0d87a7310ee7af4307994c158ab36bbc71e0055a4cd85c2a32c5b55356c01b74"}, "downloads": -1, "filename": "kairos-0.0.5.tar.gz", "has_sig": false, "md5_digest": "cb0d2971db2b825955d74f19a01554da", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6113, "upload_time": "2012-04-16T17:50:50", "upload_time_iso_8601": "2012-04-16T17:50:50.100797Z", "url": "https://files.pythonhosted.org/packages/8a/f3/4c744e1db06a62a2e6c62688022055b8cebf2d4475af0afe06058c20af52/kairos-0.0.5.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "20874d5e47ee9d297761e5ca77878845", "sha256": "56fc27a0403db9730478c011234456802893d20f84889be01194956b028b7e4e"}, "downloads": -1, "filename": "kairos-0.0.6.tar.gz", "has_sig": false, "md5_digest": "20874d5e47ee9d297761e5ca77878845", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6381, "upload_time": "2012-04-26T21:46:55", "upload_time_iso_8601": "2012-04-26T21:46:55.539189Z", "url": "https://files.pythonhosted.org/packages/6f/0b/b80793451154379a7e236230a2880090ee110a9e314a5eb762a8ff63cfd1/kairos-0.0.6.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "f06c4a6ec9410503126e34009bf7fdc1", "sha256": "b3a83ac0c543ac46a9ab9e46482b4a31f1a79d10513ebe74497be980a44d91d3"}, "downloads": -1, "filename": "kairos-0.0.7.tar.gz", "has_sig": false, "md5_digest": "f06c4a6ec9410503126e34009bf7fdc1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6578, "upload_time": "2012-05-18T15:59:28", "upload_time_iso_8601": "2012-05-18T15:59:28.608152Z", "url": "https://files.pythonhosted.org/packages/9a/50/5b165cae3f06a1e1e053c3be51187f403a9ba1d4c9b7c51cb674cad348ca/kairos-0.0.7.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "cbe046bb244dd2de5cc69791b95a4a69", "sha256": "cf8214ff3d8edb997400247003881d579a87a28c1c7100822b3c97bbf874cc2c"}, "downloads": -1, "filename": "kairos-0.1.0.tar.gz", "has_sig": false, "md5_digest": "cbe046bb244dd2de5cc69791b95a4a69", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8463, "upload_time": "2012-11-05T16:31:26", "upload_time_iso_8601": "2012-11-05T16:31:26.837183Z", "url": "https://files.pythonhosted.org/packages/2b/32/5f66d3c274b203fdb8ee3212c9573acc4607a8bb9292d77895bce8cd9daf/kairos-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "52d30befeb2bf2a2d9cbd19fefb56bde", "sha256": "a9cb5fdf128be5724cb6e5ec638011bee0a71c7726a2265e797a643e1bb41f19"}, "downloads": -1, "filename": "kairos-0.1.1.tar.gz", "has_sig": false, "md5_digest": "52d30befeb2bf2a2d9cbd19fefb56bde", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9640, "upload_time": "2013-03-04T15:31:27", "upload_time_iso_8601": "2013-03-04T15:31:27.822418Z", "url": "https://files.pythonhosted.org/packages/11/5b/bccefed0c863927af87bb3abbee70a9e419613dd8e9a76bd629b5977831f/kairos-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "10ffe997ce19394955e78d4080a3e773", "sha256": "1fdaf1285cfc63ca553f9a2e1aa28bef45c29ab227e15150219d8452ecd898f6"}, "downloads": -1, "filename": "kairos-0.1.2.tar.gz", "has_sig": false, "md5_digest": "10ffe997ce19394955e78d4080a3e773", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13249, "upload_time": "2013-03-04T20:48:04", "upload_time_iso_8601": "2013-03-04T20:48:04.163131Z", "url": "https://files.pythonhosted.org/packages/8e/10/69c7ffef6879dd90033e0c33aec6dc8a436f1eaf72be9572a849fa5580f6/kairos-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "aa042bc6d9fbe6b8df9f50411f4ddaf1", "sha256": "2883ad451a4c38fa47166b2d64222e6d13ca3337924a961f4e3215ce3b112227"}, "downloads": -1, "filename": "kairos-0.1.3.tar.gz", "has_sig": false, "md5_digest": "aa042bc6d9fbe6b8df9f50411f4ddaf1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13251, "upload_time": "2013-03-08T16:51:01", "upload_time_iso_8601": "2013-03-08T16:51:01.246552Z", "url": "https://files.pythonhosted.org/packages/eb/03/05836462a4397674fb2c3b4aae03a1e5588527f5b0ac37ec49af928d6846/kairos-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "a36a29bb543090a82aebed38411cd906", "sha256": "fbfeade08a6d290d73e62a32a5912bc9d4bf4d96a2c2ea26c40c375e5714737c"}, "downloads": -1, "filename": "kairos-0.1.4.tar.gz", "has_sig": false, "md5_digest": "a36a29bb543090a82aebed38411cd906", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13372, "upload_time": "2013-03-11T14:14:09", "upload_time_iso_8601": "2013-03-11T14:14:09.487389Z", "url": "https://files.pythonhosted.org/packages/4c/cc/26bc97db7d235898fcf2eed962b608a9367466fd82eddea42851c1c65447/kairos-0.1.4.tar.gz", "yanked": false}], "0.1.5": [{"comment_text": "", "digests": {"md5": "bbd661f76a16ab7ab35bcbd02a85cf6f", "sha256": "603b628a55fd02f92a998cd26d7bb627dbd07eadd14cd3f97fe5775aa4f17b63"}, "downloads": -1, "filename": "kairos-0.1.5.tar.gz", "has_sig": false, "md5_digest": "bbd661f76a16ab7ab35bcbd02a85cf6f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13405, "upload_time": "2013-03-12T17:20:33", "upload_time_iso_8601": "2013-03-12T17:20:33.906316Z", "url": "https://files.pythonhosted.org/packages/29/59/5691d0bc0ab747896a97350ee132ba48e0c71b0c45470bae91cfba740916/kairos-0.1.5.tar.gz", "yanked": false}], "0.10.0": [{"comment_text": "", "digests": {"md5": "756b0fbaf8d96d16d7172681633b2078", "sha256": "2f208a28d2353a843030bcb62dfa0d9362e8cddaf5f2a01cf7eb5b7e04b24f16"}, "downloads": -1, "filename": "kairos-0.10.0.tar.gz", "has_sig": false, "md5_digest": "756b0fbaf8d96d16d7172681633b2078", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 54571, "upload_time": "2014-02-27T22:20:54", "upload_time_iso_8601": "2014-02-27T22:20:54.675910Z", "url": "https://files.pythonhosted.org/packages/d6/9f/66384c6b1dd4906f5ce57342a1e5a841e2ada4a4e9fab053a9a58090bac8/kairos-0.10.0.tar.gz", "yanked": false}], "0.10.1": [{"comment_text": "", "digests": {"md5": "306df2e61e599c6a9332d6dae131046d", "sha256": "3603815a9f37b38d3a0d4ffb8a9b3a017afd9cc118e801cb088c4d88f730221c"}, "downloads": -1, "filename": "kairos-0.10.1.tar.gz", "has_sig": false, "md5_digest": "306df2e61e599c6a9332d6dae131046d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 54897, "upload_time": "2014-09-24T15:04:36", "upload_time_iso_8601": "2014-09-24T15:04:36.069592Z", "url": "https://files.pythonhosted.org/packages/6d/33/0fd8cfc68bf04c2cbbbef8745fbaba494cf50c53f63526b8e92c3043250d/kairos-0.10.1.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "b2437b840a194f6f80fcf6a4bef4520b", "sha256": "61362e7ed985f2d2737ea3d5247832948830e62d698ccf9a258ecbf7536f4a5b"}, "downloads": -1, "filename": "kairos-0.2.0.tar.gz", "has_sig": false, "md5_digest": "b2437b840a194f6f80fcf6a4bef4520b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16816, "upload_time": "2013-04-30T16:30:12", "upload_time_iso_8601": "2013-04-30T16:30:12.335631Z", "url": "https://files.pythonhosted.org/packages/9b/83/526b46398cdf8fd8cea844a8a0223b0c77c13ae0e76308336f4faa97fabf/kairos-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "1d0e8c1b672e43578a982224315a4105", "sha256": "1b05211c1f13fde9b68609da8718d2214f43bd3e998c81420232d3fefe48c243"}, "downloads": -1, "filename": "kairos-0.2.1.tar.gz", "has_sig": false, "md5_digest": "1d0e8c1b672e43578a982224315a4105", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17074, "upload_time": "2013-04-30T18:17:42", "upload_time_iso_8601": "2013-04-30T18:17:42.776159Z", "url": "https://files.pythonhosted.org/packages/08/55/e7f586495af4addf06b6b3406049721079f9572ea16ec0bbfea79a80e302/kairos-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "e08a9fc2943a0a6867f490cbed6404cd", "sha256": "b19db0e0d27263977bf7c0b4de0d4d383f9fc688323d3b8bd80a0af684d28c66"}, "downloads": -1, "filename": "kairos-0.2.2.tar.gz", "has_sig": false, "md5_digest": "e08a9fc2943a0a6867f490cbed6404cd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17150, "upload_time": "2013-05-10T10:59:13", "upload_time_iso_8601": "2013-05-10T10:59:13.434616Z", "url": "https://files.pythonhosted.org/packages/8a/af/9f4771282235be2d565fea783e6a08b3618f7864a9840fbedcaf5d727224/kairos-0.2.2.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "929afee5050e20d5e698f9208beeb04f", "sha256": "f6b82ed5d68866f4f627f93200dc6c83eac02e14721556ff8a3787de0f6c465e"}, "downloads": -1, "filename": "kairos-0.3.0.tar.gz", "has_sig": false, "md5_digest": "929afee5050e20d5e698f9208beeb04f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 19652, "upload_time": "2013-05-15T15:15:59", "upload_time_iso_8601": "2013-05-15T15:15:59.165700Z", "url": "https://files.pythonhosted.org/packages/dd/d6/4bc09cfe5215165972c877e2997d28894da15856cd0bccd5d02efaad41f1/kairos-0.3.0.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "b3ab3d8b8a330b6f57968e2d692bb60a", "sha256": "59484198b69492d1cd682944aea2378426d8f2f691fc3649550e3a3dd9673f77"}, "downloads": -1, "filename": "kairos-0.4.0.tar.gz", "has_sig": false, "md5_digest": "b3ab3d8b8a330b6f57968e2d692bb60a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20671, "upload_time": "2013-06-27T21:48:28", "upload_time_iso_8601": "2013-06-27T21:48:28.380144Z", "url": "https://files.pythonhosted.org/packages/be/35/fc9103e7825b922d8371f174236c1ee4a856e8839775d6c0737324dd75c4/kairos-0.4.0.tar.gz", "yanked": false}], "0.4.2": [{"comment_text": "", "digests": {"md5": "61f299c5ce6454303d2f13d07ac524bf", "sha256": "2107e67cbebfdf7ad141e454e6342211d3734c1d88af2ccd84b5b16aefb920d7"}, "downloads": -1, "filename": "kairos-0.4.2.tar.gz", "has_sig": false, "md5_digest": "61f299c5ce6454303d2f13d07ac524bf", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21412, "upload_time": "2013-07-29T19:45:59", "upload_time_iso_8601": "2013-07-29T19:45:59.271291Z", "url": "https://files.pythonhosted.org/packages/12/68/fb94b6dca7b3a04e5703449610bc8af6d6e201ce0040a0181cee0dcd27bb/kairos-0.4.2.tar.gz", "yanked": false}], "0.4.3": [{"comment_text": "", "digests": {"md5": "1cc8be92577f5592df466caca9886df6", "sha256": "d37a7994f9e96f051bc49bf008b49ca119430e0642a02cf4571a36199c91da32"}, "downloads": -1, "filename": "kairos-0.4.3.tar.gz", "has_sig": false, "md5_digest": "1cc8be92577f5592df466caca9886df6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21955, "upload_time": "2013-08-30T12:51:04", "upload_time_iso_8601": "2013-08-30T12:51:04.376770Z", "url": "https://files.pythonhosted.org/packages/c3/fc/9ee976b3f6d4bbbf72d8298c221713f7bb556f8ca424441a14873c4edcc6/kairos-0.4.3.tar.gz", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "061fc841868b049c07c0f08cb41f3f32", "sha256": "30cd1e3971154ede6485477814c0e0d9c83dd1ac06301ba7d7f6f07b3b1b251a"}, "downloads": -1, "filename": "kairos-0.5.0.tar.gz", "has_sig": false, "md5_digest": "061fc841868b049c07c0f08cb41f3f32", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23821, "upload_time": "2013-09-12T01:01:19", "upload_time_iso_8601": "2013-09-12T01:01:19.560337Z", "url": "https://files.pythonhosted.org/packages/b9/3d/b57844eb336d617270175e228caa57027992c88947e72e6dd0f19d0be735/kairos-0.5.0.tar.gz", "yanked": false}], "0.6.0": [{"comment_text": "", "digests": {"md5": "124298c7867d5e8a9b1c8c87437a00af", "sha256": "35724ff4beee6629e62469d7c4345557bc7337842733c845ea1ca43b25280c5b"}, "downloads": -1, "filename": "kairos-0.6.0.tar.gz", "has_sig": false, "md5_digest": "124298c7867d5e8a9b1c8c87437a00af", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 26743, "upload_time": "2013-10-10T16:49:41", "upload_time_iso_8601": "2013-10-10T16:49:41.140777Z", "url": "https://files.pythonhosted.org/packages/46/49/2f7bf0cad730b64e169ad2362eeafbeb7b4a1bec9f72839f63ed85d36798/kairos-0.6.0.tar.gz", "yanked": false}], "0.6.1": [{"comment_text": "", "digests": {"md5": "fbfcc0677cf00943b1104128664bc536", "sha256": "cba7ba275c9d8128cb7d7d2cc48e9edc9a5dfd52c38075f69db3d6839e110fc7"}, "downloads": -1, "filename": "kairos-0.6.1.tar.gz", "has_sig": false, "md5_digest": "fbfcc0677cf00943b1104128664bc536", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 26769, "upload_time": "2013-10-10T19:03:15", "upload_time_iso_8601": "2013-10-10T19:03:15.236245Z", "url": "https://files.pythonhosted.org/packages/ac/f7/a7e9cec3d9402e8535504e3025bbe433940f65e681fcdc0815cd5e73f19e/kairos-0.6.1.tar.gz", "yanked": false}], "0.6.2": [{"comment_text": "", "digests": {"md5": "c77a7e124597f5847c215ed318d60af4", "sha256": "6b223a661c05899af70c783849e3f0f6f29fe9444755fcf7b1a256202edde679"}, "downloads": -1, "filename": "kairos-0.6.2.tar.gz", "has_sig": false, "md5_digest": "c77a7e124597f5847c215ed318d60af4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 26747, "upload_time": "2013-10-10T20:27:57", "upload_time_iso_8601": "2013-10-10T20:27:57.436792Z", "url": "https://files.pythonhosted.org/packages/0d/54/0ceef617197f9bb14bcb8f85b4278292b22c920f3373372dc2d85abbe8ea/kairos-0.6.2.tar.gz", "yanked": false}], "0.6.3": [{"comment_text": "", "digests": {"md5": "08e5a112ae05c0ac5019b9ef31f2cae6", "sha256": "21448920cd460fa3b18465d4c96e12f2e9a8fa4ad7379ee0635fe221de3cb163"}, "downloads": -1, "filename": "kairos-0.6.3.tar.gz", "has_sig": false, "md5_digest": "08e5a112ae05c0ac5019b9ef31f2cae6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 29199, "upload_time": "2013-10-18T19:45:24", "upload_time_iso_8601": "2013-10-18T19:45:24.017946Z", "url": "https://files.pythonhosted.org/packages/d9/8a/af9586e570e1e6c69122e79bcc2318c4a451a2d86b5dc0e29f91b8f3b8e4/kairos-0.6.3.tar.gz", "yanked": false}], "0.7.0": [{"comment_text": "", "digests": {"md5": "c1937ef665f68afd803723ac9c63317d", "sha256": "8df0c0bd2e7c30435e5d37c66dd2de3b92b8db9413892241efbcad47bfc5672e"}, "downloads": -1, "filename": "kairos-0.7.0.tar.gz", "has_sig": false, "md5_digest": "c1937ef665f68afd803723ac9c63317d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 33798, "upload_time": "2013-10-23T18:22:13", "upload_time_iso_8601": "2013-10-23T18:22:13.555521Z", "url": "https://files.pythonhosted.org/packages/91/49/200b07437ea1d80b2aec414b8be60cc5e7649f8163504599460e5fd5c1a1/kairos-0.7.0.tar.gz", "yanked": false}], "0.8.0": [{"comment_text": "", "digests": {"md5": "8bbbbba4621c6a6c2b4809b692762a18", "sha256": "b39772c872d9d7fd9d16cea193b45b1cb7d544713a001e1ecd416fc0a07519c5"}, "downloads": -1, "filename": "kairos-0.8.0.tar.gz", "has_sig": false, "md5_digest": "8bbbbba4621c6a6c2b4809b692762a18", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 42963, "upload_time": "2013-11-07T22:05:37", "upload_time_iso_8601": "2013-11-07T22:05:37.269754Z", "url": "https://files.pythonhosted.org/packages/ff/9c/501be7091ca0c6fa9fd94af8350d44f06dee36aece59dc1f585fe3db09e1/kairos-0.8.0.tar.gz", "yanked": false}], "0.8.1": [{"comment_text": "", "digests": {"md5": "bdb220962966a95a3e3e11d9fe6165bc", "sha256": "cb531c9743154f4b3fe189d64fccee67fac41ba7015bd5c85d1cbc26e4168e6d"}, "downloads": -1, "filename": "kairos-0.8.1.tar.gz", "has_sig": false, "md5_digest": "bdb220962966a95a3e3e11d9fe6165bc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 46211, "upload_time": "2013-11-19T03:34:32", "upload_time_iso_8601": "2013-11-19T03:34:32.580454Z", "url": "https://files.pythonhosted.org/packages/6d/0b/cefa6e927268a0de92d0cd4d422c7d2b98485f619b7e3b8299dc16979098/kairos-0.8.1.tar.gz", "yanked": false}], "0.9.0": [{"comment_text": "", "digests": {"md5": "793186b0e1be95037d82053771a25154", "sha256": "921de560e85936c2c3cc888bcc57f7ec7977a88d8a22fb4733d42ebaf8125fad"}, "downloads": -1, "filename": "kairos-0.9.0.tar.gz", "has_sig": false, "md5_digest": "793186b0e1be95037d82053771a25154", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 50799, "upload_time": "2014-02-07T21:27:42", "upload_time_iso_8601": "2014-02-07T21:27:42.511248Z", "url": "https://files.pythonhosted.org/packages/30/d0/bbaeeff58479525aa3f46c415ceadcbbbcdb2313088912d68eab8c20e04a/kairos-0.9.0.tar.gz", "yanked": false}], "0.9.1": [{"comment_text": "", "digests": {"md5": "842c3e2a8c3c7768d5fe859a75c86c85", "sha256": "edc308dea18b24140ffa344b7fa2cc4cb41989f890fad213d4a72babccdb7b62"}, "downloads": -1, "filename": "kairos-0.9.1.tar.gz", "has_sig": false, "md5_digest": "842c3e2a8c3c7768d5fe859a75c86c85", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 50819, "upload_time": "2014-02-11T19:13:01", "upload_time_iso_8601": "2014-02-11T19:13:01.349449Z", "url": "https://files.pythonhosted.org/packages/b0/e4/8bbf23ddbae9bb67344230dbfe83d55c9ff8ea3a6da2bb4744c1e35c4549/kairos-0.9.1.tar.gz", "yanked": false}], "0.9.2": [{"comment_text": "", "digests": {"md5": "b0909117e8c0f5ffe6a83130e9e7029e", "sha256": "eaf939f5c117093478d263bb60a7d229649e8facf1404c73f03ab9b9f2c6744e"}, "downloads": -1, "filename": "kairos-0.9.2.tar.gz", "has_sig": false, "md5_digest": "b0909117e8c0f5ffe6a83130e9e7029e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 53230, "upload_time": "2014-02-12T21:13:26", "upload_time_iso_8601": "2014-02-12T21:13:26.861092Z", "url": "https://files.pythonhosted.org/packages/ee/49/73929437133c374b8b80035192fbe853f6795369d0224f556afe58ebb6b3/kairos-0.9.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "306df2e61e599c6a9332d6dae131046d", "sha256": "3603815a9f37b38d3a0d4ffb8a9b3a017afd9cc118e801cb088c4d88f730221c"}, "downloads": -1, "filename": "kairos-0.10.1.tar.gz", "has_sig": false, "md5_digest": "306df2e61e599c6a9332d6dae131046d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 54897, "upload_time": "2014-09-24T15:04:36", "upload_time_iso_8601": "2014-09-24T15:04:36.069592Z", "url": "https://files.pythonhosted.org/packages/6d/33/0fd8cfc68bf04c2cbbbef8745fbaba494cf50c53f63526b8e92c3043250d/kairos-0.10.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:50:47 2020"}