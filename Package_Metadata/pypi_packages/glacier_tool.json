{"info": {"author": "Dustin Oprea", "author_email": "myselfasunder@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "Introduction\n============\n\nThis is a tool to allow you to quickly push massive archives into Glacier, an ultra low-cost storage solution. It's fast to upload and cheap to maintain (currently $10 per terabyte/month), but there's a four-hour delay in all retrieval requests and a finite window to download.\n\n\nNotes\n=====\n\n- This project is meant for large uploads. It doesn't do small-uploads (the mechanism Currently, this project only provides the mechanism to upload quickly. I couldn't find another reliable, current tool to do large uploads, so I wrote one. I'll write a download-tool in the near future. Until then, use what's already out there or request one via an issue.\n\n- The Amazon library (`boto <https://github.com/boto/boto>`_) that many/most people use to access AWS services (including Glacier) is currently broken for multipart uploads and the version that seems to work fine for multipart uploads is broken for Python 3. So, this library uses *boto* version 2.29.1 under Python 2.7 .\n\n\nUsage\n=====\n\nThe command is fully-documented at the command-line. Just provide the \"-h\" parameter to print the usage::\n\n    $ gt_upload_large -h\n    usage: gt_upload_large [-h] [-em ESTIMATED_MBPS] [-pt PART_SIZE]\n                           vault_name filepath description\n\n    Push a large archive into long-term storage.\n\n    positional arguments:\n      vault_name            Vault name\n      filepath              File-path to upload\n      description           Description of uploaded file\n\n    optional arguments:\n      -h, --help            show this help message and exit\n      -em ESTIMATED_MBPS, --estimated-mbps ESTIMATED_MBPS\n                            Mbps to estimate a duration against\n      -pt PART_SIZE, --part-size PART_SIZE\n                            Part-size in bytes. Defaults to 4M. Must be between 1M\n                            and 4G.\n\n\nTo perform the upload, you'll have to define the AWS access- and secret-key in the environment::\n\n    $ export AWS_ACCESS_KEY=XXX\n    $ export AWS_SECRET_KEY=YYY\n\n    $ gt_upload_large image-backups /mnt/tower/backups/images-main-2010-20150617-2211.tar.xz images-main-2010-20150617-2211.tar.xz -em 11.33\n    Uploading: [/mnt/array/backups/images-main-2010-20150617-2211.tar.xz]\n    Size: (15.78) G\n    Start time: [2015-07-05 01:22:01]\n    Estimated duration: (3.17) hours => [2015-07-05 04:32:11] @ (11.33) Mbps\n    Archive ID: [IEGZ8uXToCDIgO3pMrrIHBIcJs...YyNlPigEwIR2NA]\n    Duration: (3.16) hours @ (11.37) Mbps\n\n    $ gt_upload_large image-backups /mnt/tower/backups/images-main-2011-20150617-2211.tar.xz images-main-2011-20150617-2211.tar.xz -em 11.37\n    Uploading: [/mnt/array/backups/images-main-2011-20150617-2211.tar.xz]\n    Size: (26.66) G\n    Start time: [2015-07-05 10:07:58]\n    Estimated duration: (5.33) hours => [2015-07-05 15:28:03] @ (11.37) Mbps\n\nNotice that the output tells you the actual rate of the upload (the *boto* call that I use doesn't provide a progress callback with which to provide realtime feedback). You can pass this value into the command for the next upload with the \"-em\" parameter to estimate the time-until-completion.\n\nIt's probably best to record the archive-IDs somewhere. It'll take you four-hours for an inventory request to be fulfilled (to get a list of your archives) and Amazon only uploads its inventory of your archives every twenty-four hours (so you won't even be able to get a list the first day).", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/dsoprea/GlacierTool", "keywords": "glacier concurrent", "license": "GPL 2", "maintainer": null, "maintainer_email": null, "name": "glacier_tool", "package_url": "https://pypi.org/project/glacier_tool/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/glacier_tool/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/dsoprea/GlacierTool"}, "release_url": "https://pypi.org/project/glacier_tool/0.2.3/", "requires_dist": null, "requires_python": null, "summary": "Do concurrent, multipart uploads of massive archives to Amazon Glacier.", "version": "0.2.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"introduction\">\n<h2>Introduction</h2>\n<p>This is a tool to allow you to quickly push massive archives into Glacier, an ultra low-cost storage solution. It\u2019s fast to upload and cheap to maintain (currently $10 per terabyte/month), but there\u2019s a four-hour delay in all retrieval requests and a finite window to download.</p>\n</div>\n<div id=\"notes\">\n<h2>Notes</h2>\n<ul>\n<li>This project is meant for large uploads. It doesn\u2019t do small-uploads (the mechanism Currently, this project only provides the mechanism to upload quickly. I couldn\u2019t find another reliable, current tool to do large uploads, so I wrote one. I\u2019ll write a download-tool in the near future. Until then, use what\u2019s already out there or request one via an issue.</li>\n<li>The Amazon library (<a href=\"https://github.com/boto/boto\" rel=\"nofollow\">boto</a>) that many/most people use to access AWS services (including Glacier) is currently broken for multipart uploads and the version that seems to work fine for multipart uploads is broken for Python 3. So, this library uses <em>boto</em> version 2.29.1 under Python 2.7 .</li>\n</ul>\n</div>\n<div id=\"usage\">\n<h2>Usage</h2>\n<p>The command is fully-documented at the command-line. Just provide the \u201c-h\u201d parameter to print the usage:</p>\n<pre>$ gt_upload_large -h\nusage: gt_upload_large [-h] [-em ESTIMATED_MBPS] [-pt PART_SIZE]\n                       vault_name filepath description\n\nPush a large archive into long-term storage.\n\npositional arguments:\n  vault_name            Vault name\n  filepath              File-path to upload\n  description           Description of uploaded file\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -em ESTIMATED_MBPS, --estimated-mbps ESTIMATED_MBPS\n                        Mbps to estimate a duration against\n  -pt PART_SIZE, --part-size PART_SIZE\n                        Part-size in bytes. Defaults to 4M. Must be between 1M\n                        and 4G.\n</pre>\n<p>To perform the upload, you\u2019ll have to define the AWS access- and secret-key in the environment:</p>\n<pre>$ export AWS_ACCESS_KEY=XXX\n$ export AWS_SECRET_KEY=YYY\n\n$ gt_upload_large image-backups /mnt/tower/backups/images-main-2010-20150617-2211.tar.xz images-main-2010-20150617-2211.tar.xz -em 11.33\nUploading: [/mnt/array/backups/images-main-2010-20150617-2211.tar.xz]\nSize: (15.78) G\nStart time: [2015-07-05 01:22:01]\nEstimated duration: (3.17) hours =&gt; [2015-07-05 04:32:11] @ (11.33) Mbps\nArchive ID: [IEGZ8uXToCDIgO3pMrrIHBIcJs...YyNlPigEwIR2NA]\nDuration: (3.16) hours @ (11.37) Mbps\n\n$ gt_upload_large image-backups /mnt/tower/backups/images-main-2011-20150617-2211.tar.xz images-main-2011-20150617-2211.tar.xz -em 11.37\nUploading: [/mnt/array/backups/images-main-2011-20150617-2211.tar.xz]\nSize: (26.66) G\nStart time: [2015-07-05 10:07:58]\nEstimated duration: (5.33) hours =&gt; [2015-07-05 15:28:03] @ (11.37) Mbps\n</pre>\n<p>Notice that the output tells you the actual rate of the upload (the <em>boto</em> call that I use doesn\u2019t provide a progress callback with which to provide realtime feedback). You can pass this value into the command for the next upload with the \u201c-em\u201d parameter to estimate the time-until-completion.</p>\n<p>It\u2019s probably best to record the archive-IDs somewhere. It\u2019ll take you four-hours for an inventory request to be fulfilled (to get a list of your archives) and Amazon only uploads its inventory of your archives every twenty-four hours (so you won\u2019t even be able to get a list the first day).</p>\n</div>\n\n          </div>"}, "last_serial": 1620069, "releases": {"0.2.0": [{"comment_text": "", "digests": {"md5": "cafac825ac2450b1270b7cfd8ff55625", "sha256": "e55b7c5537433735aaaa18e287fa38d835a82711221c981de2f39cae28f5ddd5"}, "downloads": -1, "filename": "glacier_tool-0.2.0.tar.gz", "has_sig": false, "md5_digest": "cafac825ac2450b1270b7cfd8ff55625", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3698, "upload_time": "2015-07-05T15:09:16", "upload_time_iso_8601": "2015-07-05T15:09:16.290531Z", "url": "https://files.pythonhosted.org/packages/96/b4/0b8e917474104d5ab67d0e53894ba5b3522a5bc6fe59f2c670479a7647f6/glacier_tool-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "4e19c7a32e1188234c9c74959fb08a1b", "sha256": "9a4ca69df8b31b5666261b0e8d6a0e8e368d239ad60a2383f1e608454dd0e3d5"}, "downloads": -1, "filename": "glacier_tool-0.2.1.tar.gz", "has_sig": false, "md5_digest": "4e19c7a32e1188234c9c74959fb08a1b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3753, "upload_time": "2015-07-05T15:12:53", "upload_time_iso_8601": "2015-07-05T15:12:53.826501Z", "url": "https://files.pythonhosted.org/packages/bf/7a/19a30e56c1547fd5e34cd1eac5fc36b899d6d8d2b416af1714421d641ca7/glacier_tool-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "6da74d6d2b0b72e7a89c88abe9c29751", "sha256": "66ac6359cf6905ae10399153c9c16d3ddf4c53429d2e598199df848386ddf7f0"}, "downloads": -1, "filename": "glacier_tool-0.2.2.tar.gz", "has_sig": false, "md5_digest": "6da74d6d2b0b72e7a89c88abe9c29751", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3993, "upload_time": "2015-07-05T15:15:40", "upload_time_iso_8601": "2015-07-05T15:15:40.321374Z", "url": "https://files.pythonhosted.org/packages/c0/c0/c75c09b505db9e7eba45a4084f43669d9c7e57ec807e225221c4d4c97d45/glacier_tool-0.2.2.tar.gz", "yanked": false}], "0.2.3": [{"comment_text": "", "digests": {"md5": "dc2621e23c6458c3f8c0b66e5c7d8244", "sha256": "fda073c6e6eab5c6a2ef00db8965969133216e18cb5b93b1ec7e06a6a86ca46f"}, "downloads": -1, "filename": "glacier_tool-0.2.3.tar.gz", "has_sig": false, "md5_digest": "dc2621e23c6458c3f8c0b66e5c7d8244", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4202, "upload_time": "2015-07-05T15:33:15", "upload_time_iso_8601": "2015-07-05T15:33:15.061106Z", "url": "https://files.pythonhosted.org/packages/8d/a8/047512c428b71280243f2b8bf08143f33b7f1852e735866a23d765707ae8/glacier_tool-0.2.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "dc2621e23c6458c3f8c0b66e5c7d8244", "sha256": "fda073c6e6eab5c6a2ef00db8965969133216e18cb5b93b1ec7e06a6a86ca46f"}, "downloads": -1, "filename": "glacier_tool-0.2.3.tar.gz", "has_sig": false, "md5_digest": "dc2621e23c6458c3f8c0b66e5c7d8244", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4202, "upload_time": "2015-07-05T15:33:15", "upload_time_iso_8601": "2015-07-05T15:33:15.061106Z", "url": "https://files.pythonhosted.org/packages/8d/a8/047512c428b71280243f2b8bf08143f33b7f1852e735866a23d765707ae8/glacier_tool-0.2.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:56:41 2020"}