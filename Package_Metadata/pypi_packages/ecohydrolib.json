{"info": {"author": "Brian Miles", "author_email": "brian_miles@unc.edu", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Environment :: Console", "Intended Audience :: Science/Research", "License :: OSI Approved :: BSD License", "Natural Language :: English", "Operating System :: Unix", "Topic :: Scientific/Engineering :: GIS"], "description": "EcohydroLib\t\t\t{#index}\n=============================\n\nThis software is provided free of charge under the New BSD License. Please see\nthe following license information:\n\nCopyright (c) 2013-2015 University of North Carolina at Chapel Hill\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n    - Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n    - Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in the\n      documentation and/or other materials provided with the distribution.\n    - Neither the name of the University of North Carolina at Chapel Hill nor \n      the names of its contributors may be used to endorse or promote products\n      derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL\nBE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR \nCONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE\nGOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\nHOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT \nLIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT\nOF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nAuthors\n-------\nBrian Miles <brian_miles@unc.edu>\n\nLawrence E. Band <lband@email.unc.edu>\n\nFor questions or support contact [Brian Miles](brian_miles@unc.edu)\n\n\nFunding\n-------\nThis work was supported by the following NSF grants\n\n- Award no. 1239678 EAGER: Collaborative Research: Interoperability\n   Testbed-Assessing a Layered Architecture for Integration of\n   Existing Capabilities\n\n- Award no. 0940841 DataNet Federation Consortium.\n\n- Award no. 1148090 Collaborative Research: SI2-SSI: An Interactive Software\n   Infrastructure for Sustaining Collaborative Innovation in the\n   Hydrologic Sciences\n\n\nIntroduction \n------------ \nEcohydroLib provides a series of Python scripts for performing\necohydrology data preparation workflows.  Workflow sub-components are\norchestrated via a metadata persistence store provided by the\necohydrolib.metadata package.  These scripts are built on top of a\nseries of task-oriented APIs defined in the Python package\nEcohydroLib.  The workflow scripts provide tools for downloading and\nmanipulating geospatial data needed to run a ecohydrology models,\ninformation such as: digital elevation model (DEM), soils, land cover,\nand vegetation leaf area index.  These data can be drawn both from\nnational spatial data infrastructure (NLCD, SSURGO) as well as custom\nlocal datasets.\n\nA metadata store is used to orchestrate a series of workflow scripts\nused to prepare data for an ecohydrology model.  The current\nimplementation uses the Python ConfigParser key-value storage\nmechanism to persist metadata to disk, however conceivably any\nkey-value store could be used.  The metadata contains information\nrelated to the study area (e.g. bounding box, spatial reference, DEM\nresolution), as well as provenance information for each spatial data\nlayer imported, and a processing history that records the parameters\nused to invoke each workflow script; provenance information is\nrepresented as a subset of Dublin Core attributes\n(http://dublincore.org).  When using the workflow scripts in a\nstand-alone environment, the metadata store provides information\nnecessary to understand where ecohydrology input data came from, and\nwhat transformations have been made to the data.  When the workflow\nscripts are integrated into a data grid or workflow environment\n(e.g. iRODS), the metadata store can serve as a staging area for\nmetadata and provenance information that will be registered into the\nformal workflow environment.\n\nThe fundamental operation for any ecohydrology modeling workflow is to\ndefine the study region of interest (ROI).  In EcohydroLib the ROI is\nsimply defined as a bounding box of WGS84 latitude and longitude\ncoordinates (e.g. coordinates for the upper- left and lower-right\ncorners).  For workflows using the National Hydrography Dataset (NHD),\nthe ROI bounding box can be derived using catchment polygons\nassociated with the stream reaches upstream of a particular gage.  The\nuser begins by picking a streamflow discharge gage listed in the NHD\ndataset.  EcohydroLib can then determine the stream reaches upstream\nof the data, and then select the catchment polygons associated with\neach upstream reach.  From these polygons, the bounding box of the\nland area draining through the streamflow gage can easily be\ncalculated.\n\nOnce the ROI is known, EcohydroLib can extract datasets (DEM, soils,\netc.)  specific to the study area.  Some of these datasets are\nextracted from static local copies of national spatial data\n(e.g. NLCD), while other are retrieved via web services interfaces\nfrom federal agency data centers (e.g. SSURGO soils data from USDA) or\nfrom third-party data centers (GeoBrain's DEM Explorer).  However it\nis also possible for the user to register their own custom data for a\ngiven datatype (e.g. local LIDAR-based DEM).\n\n![Fig. 1 Ecohydrology model data preparation workflow software stack depicting EcohydroLib's role as an intermediary between raw data, derived data subsets, and specific ecohydrology models](EcohydroLib-Architecture.png)\n\n\nSource code\n-----------\nSource code can be found at: https://github.com/selimnairb/EcohydroLib.\n\nDocumentation can be found at: http://pythonhosted.org/ecohydrolib\n\n\nInstallation\n------------\nDetailed installation and usage instructions can be found in the RHESSysWorkflows \n[readme](https://github.com/selimnairb/RHESSysWorkflows).\n\nThe following instructions should only be used by advanced users. \n\nUsing easy_install:\n\neasy_install --script-dir /path/to/install/scripts EcohydroLib\n\nUsing pip:\n\npip install EcohydroLib\n\n\nIt is recommended that you install the workflow scripts in a location\ndistinct from where the Python package will be installed.  This is\naccomplished by specifying the --script-dir option to easy install\n(see above).\n\nNote, pyspatialite 3.0.1, needed for GHCNDSetup.py and \nGetGHCNDailyClimateData*.py, currently fails to build under easy_install/pip.\nUntil this is fixed by the pyspatialite developer, I have removed\npyspatialite from the dependency list.  If you need to use GNCHD data, you\ncan install pyspatialite manually using the following steps (this can be\ndone before or after installing EcohydroLib):\n- Manually download pyspatialite here:\n  https://pypi.python.org/pypi/pyspatialite/3.0.1 \n- Apply the following patch to pyspatialite's setup.py:\n  https://code.google.com/p/pyspatialite/issues/detail?id=9 \n- Install pyspatialite \n- Install EcohydroLib as described above\n\n\nRequired runtime software\n-------------------------\nPython 2.7\n\nLibraries (with headers):\n- libxml2\n- libxslt\n- libproj\n- libgeos\n\nBinaries:\n- GDAL/OGR 1.9 or later (throughout)\n- SQLite3 (throughout)\n- Seven Zip (if using NHDPlusV2Setup/NHDPlusV2Setup.py)\n- Spatialite (if using GHCNDSetup.py/GetGHCNDailyClimateData*.py)\n- Unix find (if using NHDPlusV2Setup/NHDPlusV2Setup.py)\n\n\nData stored locally\n-------------------\n- NLCD 2006 raster (http://www.mrlc.gov/nlcd06_data.php)\n- HYDRO1k North America dataset (http://eros.usgs.gov/#/Find_Data/Products_and_Data_Available/gtopo30/hydro/namerica)\n- NHDPlus V2 dataset (http://www.horizon-systems.com/NHDPlus/NHDPlusV2_home.php)\n\n\nNHDPlus V2 database setup\n-------------------------\nBefore EcohydroLib is able to extract study area ROI using the NHDPlus\ndataset, it is necessary to have a local copy of the NHDPlus dataset.\nOwing to the large size of the NHDPlus dataset, these data are\ndistributed as as series of compressed archives broken into several\nregions for the continental U.S.  There are two choices for obtaining\nNHDPlus in a format usable by EcohydroLib (as several SQLite3\ndatabases).  A national-scale dataset (i.e. covering the entire\ncontinental U.S.) is available for download here:\n\nhttp://...\n\nOnce downloaded, extract the archive and record its location in your\nEcohydroLib configuation file; see the 'Configuration files' section\nfor more information.\n\nIf you wish to build you own copy of the database (i.e. for a subset\nof U.S. country) a script for building the dataset from downloaded\nNHDPlus V2 7z archives is provided in\nbin/NHDPlusV2Setup/NHDPlusV2Setup.py.  The following NHDPlus V2\ndatasets are required:\n\n- NHDPlusV21_NationalData_GageInfo_02.7z\n- NHDPlusV21_NationalData_GageLoc_01.7z\n- NHDPlusV21_NationalData_Gage_Smooth_01.7z\n- NHDPlusV21_??_??_NHDPlusAttributes_??.7z\n- NHDPlusV21_??_??_NHDPlusCatchment_??.7z\n- NHDPlusV21_??_??_NHDSnapshot_??.7z\n\nNote that the NHDPlusAttributes, NHDPlusCatchment, and NHDPlusSnapshot\ndata are released as regional subsets (due to the large size and\ncomplexity of the data).  NHDPlusV2Setup.py can build its NHDPlus\nSQLite3 databases for any number of regions; all data for the desired\nnumber of regions will be combined into a single database.\n\nOnce you've decided which NHDPlusV2 regions you wish to build a\ndatabase for, simply download the relevant 7z archives from the\nNHDPlusV2 web site (see above), and store the archives in a single\ndirectory.  NHDPlusV2Setup.py will unpack these archives into a\nspecified output location and then will process the unarchived files\ninto the following databases: - Catchment.sqlite (a spatial dataset\ncontaining all catchment polygons in the selected NHD region(s); -\nGageLoc.sqlite (a spatial dataset containing streamflow gage points\nfor the national NHD dataset; - NHDPlusDB.sqlite (a tabular dataset\ncontaining other NHD data needed by EcohydroLib).\n\nMake sure to edit your configuration file to include the absolute\npaths of these files (see below).\n\nFor national NHD coverage, Catchment.sqlite is over 8 GB, and\nNHDPlusDB.sqlite is over 2 GB, so you will need a kernel and\nfilesystem that has large file support to build and use these\ndatasets.  Also, it may take over an hour to create these datasets; 8\nGB of memory or more is recommended to build the datasets efficiently.\nHowever, database setup is a one-time process, and you can use\ndatabases created on one machine on other machines, provided SQLite3\nis installed.  NHDPlusV2Setup.py creates each database with the\nindices needed by EcohydroLib, so lookups are very fast.\n\n\nHYDRO1k North America\n---------------------\nTo use HYDRO1k basin shapefile, you must first uncompress\nna_bas.e00.gz to na_bas.e00.  Then you must convert the e00 (Arc\ninterchange file) to a shapefile using a tool such as ArcGIS.\n\n\nGHCN Climate Data\n-----------------\nTo download NCDC Global Historical Climatology Network (GHCN) dataset\nfor daily climate data, you must first create the spatialite database\nthat EcohydroLib uses to find climate stations using\nspatial queries.  This database is created using\nbin/GHCNDSetup/GHCNDSetup.py.  The output from the script will be a\nspatialite database.  Make sure to edit your configuration file and\nset PATH_OF_STATION_DB to the absolute path of this spatialite\ndatabase (see below).\n\n\nConfiguration files\n-------------------\nMany of the command line scripts (including NHDPlusV2Setup.py) require\na configuration file to specify locations to executables and datasets\nrequired by the ecohydrology workflow libraries.  The configuration\nfile can be specified via the environmental variable\nECOHYDROLIB_CFG or via command line option. Here is an example\nconfiguration file:\n\n\t\t[GDAL/OGR]\n\t\tPATH_OF_OGR2OGR = /Library/Frameworks/GDAL.framework/Versions/Current/Programs/ogr2ogr\n\t\tPATH_OF_GDAL_RASTERIZE = /Library/Frameworks/GDAL.framework/Versions/Current/Programs/gdal_rasterize\n\t\tPATH_OF_GDAL_WARP = /Library/Frameworks/GDAL.framework/Versions/Current/Programs/gdalwarp\n\t\tPATH_OF_GDAL_TRANSLATE = /Library/Frameworks/GDAL.framework/Versions/Current/Programs/gdal_translate\n\t\t\n\t\t[NHDPLUS2]\n\t\tPATH_OF_NHDPLUS2_DB = /Users/<username>/Research/data/GIS/NHDPlusV21/national/NHDPlusDB.sqlite\n\t\tPATH_OF_NHDPLUS2_CATCHMENT = /Users/<username>/Research/data/GIS/NHDPlusV21/national/Catchment.sqlite\n\t\tPATH_OF_NHDPLUS2_GAGELOC = /Users/<username>/Research/data/GIS/NHDPlusV21/national/GageLoc.sqlite\n\t\t\n\t\t[SOLIM]\n\t\tPATH_OF_SOLIM = /Users/<username>/Research/bin/solim/solim.out\n\t\t\n\t\t[NLCD]\n\t\tPATH_OF_NLCD2006 = /Users/<username>/Research/data/GIS/NLCD2006/nlcd2006/nlcd2006_landcover_4-20-11_se5.img\n\t\t\n\t\t[HYDRO1k]\n\t\tPATH_OF_HYDRO1K_DEM = /Users/<username>/Research/data/GIS/HYDRO1k/na/na_dem.bil\n\t\tPATH_OF_HYDRO1K_BAS = /Users/<username>/Research/data/GIS/HYDRO1k/na/na_bas_polygon.shp\n\t\tHYDRO1k_BAS_LAYER_NAME = na_bas_polygon\n\t\t\n\t\t[GHCND]\n\t\tPATH_OF_STATION_DB = /Users/<username>/Research/data/obs/NCDC/GHCND/GHCND.spatialite\n\t\t\n\t\t[UTIL]\n\t\tPATH_OF_FIND = /usr/bin/find\n\t\tPATH_OF_SEVEN_ZIP = /opt/local/bin/7z\n\t\tPATH_OF_SQLITE = /opt/local/bin/sqlite3 \n\t\t\nIf you create your initial configuration file by copying and pasting\nfrom this documentation, make sure to remove any leading spaces from\neach line of the file.\n\n\nHow to use - Typical workflows \n------------------------------\nA workflow using data from large-scale spatial data infrastructure\nwill consist of running the follow scripts in the following order:\n1. GetNHDStreamflowGageIdentifiersAndLocation.py\n2. GetCatchmentShapefileForNHDStreamflowGage.py\n3. GetBoundingboxFromStudyAreaShapefile.py\n4. GetUSGSDEMForBoundingbox.py\n5. GetNLCDForDEMExtent.py\n6. GetSSURGOFeaturesForBoundingbox.py\n7. GenerateSoilPropertyRastersFromSSURGO.py or GenerateSoilPropertyRastersFromSOLIM.py\n\nThe first 4 steps must be run in this order, the remaining workflow\ncomponents can be run in any order.  Other workflow components,\ne.g. to register a custom dataset, can be substituted for the latter 4\nworkflow components as well (as indicated above).  See the\ndocumentation for each script to see invocations details.\n\n\nA workflow collecting data appropriate for large-scale land surface\nprocess models may consist of running the following scripts in the\nfollowing order:\n1. GetCatchmentShapefileForHYDRO1kBasins.py\n2. GetBoundingboxFromStudyAreaShapefile.py\n3. GetHYDRO1kDEMForBoundingbox.py\n6. GetGHCNDailyClimateDataForBoundingboxCentroid.py OR GetGHCNDailyClimateDataForStationsInBoundingbox.py\n\n\nA workflow using custom local data sources will consist of running the\nfollow scripts in the following order:\n1. RegisterDEM.py\n2. RegisterGage.py\n3. RegisterRaster.py\n4. GetSSURGOFeaturesForBoundingbox.py\n\nA workflow using custom streamflow gage, but with standard spatial data (NED, NLCD, SSURGO)\ncould consist of running the follow scripts in the following order:\n1. RegisterStudyAreaShapefile.py\n2. GetBoundingboxFromStudyAreaShapefile.py\n3. GetUSGSDEMForBoundingbox.py\n4. GetNLCDForDEMExtent.py\n5. GetSSURGOFeaturesForBoundingbox.py\n6. GenerateSoilPropertyRastersFromSSURGO.py", "description_content_type": null, "docs_url": "https://pythonhosted.org/ecohydrolib/", "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/selimnairb/EcohydroLib", "keywords": null, "license": "BSD", "maintainer": null, "maintainer_email": null, "name": "ecohydrolib", "package_url": "https://pypi.org/project/ecohydrolib/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/ecohydrolib/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/selimnairb/EcohydroLib"}, "release_url": "https://pypi.org/project/ecohydrolib/1.29/", "requires_dist": null, "requires_python": null, "summary": "Libraries and command-line scripts for performing ecohydrology data preparation workflows.", "version": "1.29", "yanked": false, "html_description": "<div class=\"project-description\">\n            EcohydroLib\t\t\t{#index}<br>=============================<br><br>This software is provided free of charge under the New BSD License. Please see<br>the following license information:<br><br>Copyright (c) 2013-2015 University of North Carolina at Chapel Hill<br>All rights reserved.<br><br>Redistribution and use in source and binary forms, with or without<br>modification, are permitted provided that the following conditions are met:<br>    - Redistributions of source code must retain the above copyright<br>      notice, this list of conditions and the following disclaimer.<br>    - Redistributions in binary form must reproduce the above copyright<br>      notice, this list of conditions and the following disclaimer in the<br>      documentation and/or other materials provided with the distribution.<br>    - Neither the name of the University of North Carolina at Chapel Hill nor <br>      the names of its contributors may be used to endorse or promote products<br>      derived from this software without specific prior written permission.<br><br>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND<br>ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED<br>WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE<br>DISCLAIMED. IN NO EVENT SHALL THE UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL<br>BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR <br>CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE<br>GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)<br>HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT <br>LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT<br>OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.<br><br><br>Authors<br>-------<br>Brian Miles &lt;brian_miles@unc.edu&gt;<br><br>Lawrence E. Band &lt;lband@email.unc.edu&gt;<br><br>For questions or support contact [Brian Miles](brian_miles@unc.edu)<br><br><br>Funding<br>-------<br>This work was supported by the following NSF grants<br><br>- Award no. 1239678 EAGER: Collaborative Research: Interoperability<br>   Testbed-Assessing a Layered Architecture for Integration of<br>   Existing Capabilities<br><br>- Award no. 0940841 DataNet Federation Consortium.<br><br>- Award no. 1148090 Collaborative Research: SI2-SSI: An Interactive Software<br>   Infrastructure for Sustaining Collaborative Innovation in the<br>   Hydrologic Sciences<br><br><br>Introduction <br>------------ <br>EcohydroLib provides a series of Python scripts for performing<br>ecohydrology data preparation workflows.  Workflow sub-components are<br>orchestrated via a metadata persistence store provided by the<br>ecohydrolib.metadata package.  These scripts are built on top of a<br>series of task-oriented APIs defined in the Python package<br>EcohydroLib.  The workflow scripts provide tools for downloading and<br>manipulating geospatial data needed to run a ecohydrology models,<br>information such as: digital elevation model (DEM), soils, land cover,<br>and vegetation leaf area index.  These data can be drawn both from<br>national spatial data infrastructure (NLCD, SSURGO) as well as custom<br>local datasets.<br><br>A metadata store is used to orchestrate a series of workflow scripts<br>used to prepare data for an ecohydrology model.  The current<br>implementation uses the Python ConfigParser key-value storage<br>mechanism to persist metadata to disk, however conceivably any<br>key-value store could be used.  The metadata contains information<br>related to the study area (e.g. bounding box, spatial reference, DEM<br>resolution), as well as provenance information for each spatial data<br>layer imported, and a processing history that records the parameters<br>used to invoke each workflow script; provenance information is<br>represented as a subset of Dublin Core attributes<br>(http://dublincore.org).  When using the workflow scripts in a<br>stand-alone environment, the metadata store provides information<br>necessary to understand where ecohydrology input data came from, and<br>what transformations have been made to the data.  When the workflow<br>scripts are integrated into a data grid or workflow environment<br>(e.g. iRODS), the metadata store can serve as a staging area for<br>metadata and provenance information that will be registered into the<br>formal workflow environment.<br><br>The fundamental operation for any ecohydrology modeling workflow is to<br>define the study region of interest (ROI).  In EcohydroLib the ROI is<br>simply defined as a bounding box of WGS84 latitude and longitude<br>coordinates (e.g. coordinates for the upper- left and lower-right<br>corners).  For workflows using the National Hydrography Dataset (NHD),<br>the ROI bounding box can be derived using catchment polygons<br>associated with the stream reaches upstream of a particular gage.  The<br>user begins by picking a streamflow discharge gage listed in the NHD<br>dataset.  EcohydroLib can then determine the stream reaches upstream<br>of the data, and then select the catchment polygons associated with<br>each upstream reach.  From these polygons, the bounding box of the<br>land area draining through the streamflow gage can easily be<br>calculated.<br><br>Once the ROI is known, EcohydroLib can extract datasets (DEM, soils,<br>etc.)  specific to the study area.  Some of these datasets are<br>extracted from static local copies of national spatial data<br>(e.g. NLCD), while other are retrieved via web services interfaces<br>from federal agency data centers (e.g. SSURGO soils data from USDA) or<br>from third-party data centers (GeoBrain's DEM Explorer).  However it<br>is also possible for the user to register their own custom data for a<br>given datatype (e.g. local LIDAR-based DEM).<br><br>![Fig. 1 Ecohydrology model data preparation workflow software stack depicting EcohydroLib's role as an intermediary between raw data, derived data subsets, and specific ecohydrology models](EcohydroLib-Architecture.png)<br><br><br>Source code<br>-----------<br>Source code can be found at: https://github.com/selimnairb/EcohydroLib.<br><br>Documentation can be found at: http://pythonhosted.org/ecohydrolib<br><br><br>Installation<br>------------<br>Detailed installation and usage instructions can be found in the RHESSysWorkflows <br>[readme](https://github.com/selimnairb/RHESSysWorkflows).<br><br>The following instructions should only be used by advanced users. <br><br>Using easy_install:<br><br>easy_install --script-dir /path/to/install/scripts EcohydroLib<br><br>Using pip:<br><br>pip install EcohydroLib<br><br><br>It is recommended that you install the workflow scripts in a location<br>distinct from where the Python package will be installed.  This is<br>accomplished by specifying the --script-dir option to easy install<br>(see above).<br><br>Note, pyspatialite 3.0.1, needed for GHCNDSetup.py and <br>GetGHCNDailyClimateData*.py, currently fails to build under easy_install/pip.<br>Until this is fixed by the pyspatialite developer, I have removed<br>pyspatialite from the dependency list.  If you need to use GNCHD data, you<br>can install pyspatialite manually using the following steps (this can be<br>done before or after installing EcohydroLib):<br>- Manually download pyspatialite here:<br>  https://pypi.python.org/pypi/pyspatialite/3.0.1 <br>- Apply the following patch to pyspatialite's setup.py:<br>  https://code.google.com/p/pyspatialite/issues/detail?id=9 <br>- Install pyspatialite <br>- Install EcohydroLib as described above<br><br><br>Required runtime software<br>-------------------------<br>Python 2.7<br><br>Libraries (with headers):<br>- libxml2<br>- libxslt<br>- libproj<br>- libgeos<br><br>Binaries:<br>- GDAL/OGR 1.9 or later (throughout)<br>- SQLite3 (throughout)<br>- Seven Zip (if using NHDPlusV2Setup/NHDPlusV2Setup.py)<br>- Spatialite (if using GHCNDSetup.py/GetGHCNDailyClimateData*.py)<br>- Unix find (if using NHDPlusV2Setup/NHDPlusV2Setup.py)<br><br><br>Data stored locally<br>-------------------<br>- NLCD 2006 raster (http://www.mrlc.gov/nlcd06_data.php)<br>- HYDRO1k North America dataset (http://eros.usgs.gov/#/Find_Data/Products_and_Data_Available/gtopo30/hydro/namerica)<br>- NHDPlus V2 dataset (http://www.horizon-systems.com/NHDPlus/NHDPlusV2_home.php)<br><br><br>NHDPlus V2 database setup<br>-------------------------<br>Before EcohydroLib is able to extract study area ROI using the NHDPlus<br>dataset, it is necessary to have a local copy of the NHDPlus dataset.<br>Owing to the large size of the NHDPlus dataset, these data are<br>distributed as as series of compressed archives broken into several<br>regions for the continental U.S.  There are two choices for obtaining<br>NHDPlus in a format usable by EcohydroLib (as several SQLite3<br>databases).  A national-scale dataset (i.e. covering the entire<br>continental U.S.) is available for download here:<br><br>http://...<br><br>Once downloaded, extract the archive and record its location in your<br>EcohydroLib configuation file; see the 'Configuration files' section<br>for more information.<br><br>If you wish to build you own copy of the database (i.e. for a subset<br>of U.S. country) a script for building the dataset from downloaded<br>NHDPlus V2 7z archives is provided in<br>bin/NHDPlusV2Setup/NHDPlusV2Setup.py.  The following NHDPlus V2<br>datasets are required:<br><br>- NHDPlusV21_NationalData_GageInfo_02.7z<br>- NHDPlusV21_NationalData_GageLoc_01.7z<br>- NHDPlusV21_NationalData_Gage_Smooth_01.7z<br>- NHDPlusV21_??_??_NHDPlusAttributes_??.7z<br>- NHDPlusV21_??_??_NHDPlusCatchment_??.7z<br>- NHDPlusV21_??_??_NHDSnapshot_??.7z<br><br>Note that the NHDPlusAttributes, NHDPlusCatchment, and NHDPlusSnapshot<br>data are released as regional subsets (due to the large size and<br>complexity of the data).  NHDPlusV2Setup.py can build its NHDPlus<br>SQLite3 databases for any number of regions; all data for the desired<br>number of regions will be combined into a single database.<br><br>Once you've decided which NHDPlusV2 regions you wish to build a<br>database for, simply download the relevant 7z archives from the<br>NHDPlusV2 web site (see above), and store the archives in a single<br>directory.  NHDPlusV2Setup.py will unpack these archives into a<br>specified output location and then will process the unarchived files<br>into the following databases: - Catchment.sqlite (a spatial dataset<br>containing all catchment polygons in the selected NHD region(s); -<br>GageLoc.sqlite (a spatial dataset containing streamflow gage points<br>for the national NHD dataset; - NHDPlusDB.sqlite (a tabular dataset<br>containing other NHD data needed by EcohydroLib).<br><br>Make sure to edit your configuration file to include the absolute<br>paths of these files (see below).<br><br>For national NHD coverage, Catchment.sqlite is over 8 GB, and<br>NHDPlusDB.sqlite is over 2 GB, so you will need a kernel and<br>filesystem that has large file support to build and use these<br>datasets.  Also, it may take over an hour to create these datasets; 8<br>GB of memory or more is recommended to build the datasets efficiently.<br>However, database setup is a one-time process, and you can use<br>databases created on one machine on other machines, provided SQLite3<br>is installed.  NHDPlusV2Setup.py creates each database with the<br>indices needed by EcohydroLib, so lookups are very fast.<br><br><br>HYDRO1k North America<br>---------------------<br>To use HYDRO1k basin shapefile, you must first uncompress<br>na_bas.e00.gz to na_bas.e00.  Then you must convert the e00 (Arc<br>interchange file) to a shapefile using a tool such as ArcGIS.<br><br><br>GHCN Climate Data<br>-----------------<br>To download NCDC Global Historical Climatology Network (GHCN) dataset<br>for daily climate data, you must first create the spatialite database<br>that EcohydroLib uses to find climate stations using<br>spatial queries.  This database is created using<br>bin/GHCNDSetup/GHCNDSetup.py.  The output from the script will be a<br>spatialite database.  Make sure to edit your configuration file and<br>set PATH_OF_STATION_DB to the absolute path of this spatialite<br>database (see below).<br><br><br>Configuration files<br>-------------------<br>Many of the command line scripts (including NHDPlusV2Setup.py) require<br>a configuration file to specify locations to executables and datasets<br>required by the ecohydrology workflow libraries.  The configuration<br>file can be specified via the environmental variable<br>ECOHYDROLIB_CFG or via command line option. Here is an example<br>configuration file:<br><br>\t\t[GDAL/OGR]<br>\t\tPATH_OF_OGR2OGR = /Library/Frameworks/GDAL.framework/Versions/Current/Programs/ogr2ogr<br>\t\tPATH_OF_GDAL_RASTERIZE = /Library/Frameworks/GDAL.framework/Versions/Current/Programs/gdal_rasterize<br>\t\tPATH_OF_GDAL_WARP = /Library/Frameworks/GDAL.framework/Versions/Current/Programs/gdalwarp<br>\t\tPATH_OF_GDAL_TRANSLATE = /Library/Frameworks/GDAL.framework/Versions/Current/Programs/gdal_translate<br>\t\t<br>\t\t[NHDPLUS2]<br>\t\tPATH_OF_NHDPLUS2_DB = /Users/&lt;username&gt;/Research/data/GIS/NHDPlusV21/national/NHDPlusDB.sqlite<br>\t\tPATH_OF_NHDPLUS2_CATCHMENT = /Users/&lt;username&gt;/Research/data/GIS/NHDPlusV21/national/Catchment.sqlite<br>\t\tPATH_OF_NHDPLUS2_GAGELOC = /Users/&lt;username&gt;/Research/data/GIS/NHDPlusV21/national/GageLoc.sqlite<br>\t\t<br>\t\t[SOLIM]<br>\t\tPATH_OF_SOLIM = /Users/&lt;username&gt;/Research/bin/solim/solim.out<br>\t\t<br>\t\t[NLCD]<br>\t\tPATH_OF_NLCD2006 = /Users/&lt;username&gt;/Research/data/GIS/NLCD2006/nlcd2006/nlcd2006_landcover_4-20-11_se5.img<br>\t\t<br>\t\t[HYDRO1k]<br>\t\tPATH_OF_HYDRO1K_DEM = /Users/&lt;username&gt;/Research/data/GIS/HYDRO1k/na/na_dem.bil<br>\t\tPATH_OF_HYDRO1K_BAS = /Users/&lt;username&gt;/Research/data/GIS/HYDRO1k/na/na_bas_polygon.shp<br>\t\tHYDRO1k_BAS_LAYER_NAME = na_bas_polygon<br>\t\t<br>\t\t[GHCND]<br>\t\tPATH_OF_STATION_DB = /Users/&lt;username&gt;/Research/data/obs/NCDC/GHCND/GHCND.spatialite<br>\t\t<br>\t\t[UTIL]<br>\t\tPATH_OF_FIND = /usr/bin/find<br>\t\tPATH_OF_SEVEN_ZIP = /opt/local/bin/7z<br>\t\tPATH_OF_SQLITE = /opt/local/bin/sqlite3 <br>\t\t<br>If you create your initial configuration file by copying and pasting<br>from this documentation, make sure to remove any leading spaces from<br>each line of the file.<br><br><br>How to use - Typical workflows <br>------------------------------<br>A workflow using data from large-scale spatial data infrastructure<br>will consist of running the follow scripts in the following order:<br>1. GetNHDStreamflowGageIdentifiersAndLocation.py<br>2. GetCatchmentShapefileForNHDStreamflowGage.py<br>3. GetBoundingboxFromStudyAreaShapefile.py<br>4. GetUSGSDEMForBoundingbox.py<br>5. GetNLCDForDEMExtent.py<br>6. GetSSURGOFeaturesForBoundingbox.py<br>7. GenerateSoilPropertyRastersFromSSURGO.py or GenerateSoilPropertyRastersFromSOLIM.py<br><br>The first 4 steps must be run in this order, the remaining workflow<br>components can be run in any order.  Other workflow components,<br>e.g. to register a custom dataset, can be substituted for the latter 4<br>workflow components as well (as indicated above).  See the<br>documentation for each script to see invocations details.<br><br><br>A workflow collecting data appropriate for large-scale land surface<br>process models may consist of running the following scripts in the<br>following order:<br>1. GetCatchmentShapefileForHYDRO1kBasins.py<br>2. GetBoundingboxFromStudyAreaShapefile.py<br>3. GetHYDRO1kDEMForBoundingbox.py<br>6. GetGHCNDailyClimateDataForBoundingboxCentroid.py OR GetGHCNDailyClimateDataForStationsInBoundingbox.py<br><br><br>A workflow using custom local data sources will consist of running the<br>follow scripts in the following order:<br>1. RegisterDEM.py<br>2. RegisterGage.py<br>3. RegisterRaster.py<br>4. GetSSURGOFeaturesForBoundingbox.py<br><br>A workflow using custom streamflow gage, but with standard spatial data (NED, NLCD, SSURGO)<br>could consist of running the follow scripts in the following order:<br>1. RegisterStudyAreaShapefile.py<br>2. GetBoundingboxFromStudyAreaShapefile.py<br>3. GetUSGSDEMForBoundingbox.py<br>4. GetNLCDForDEMExtent.py<br>5. GetSSURGOFeaturesForBoundingbox.py<br>6. GenerateSoilPropertyRastersFromSSURGO.py\n          </div>"}, "last_serial": 1617210, "releases": {"1.0": [{"comment_text": "", "digests": {"md5": "7d8250c92c6ff232a148ed2826c6207a", "sha256": "280264630ec9b39e2825074155096c6efc1e4bdca3b216d5821c42bc23dcd536"}, "downloads": -1, "filename": "ecohydrolib-1.0.tar.gz", "has_sig": false, "md5_digest": "7d8250c92c6ff232a148ed2826c6207a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 67150, "upload_time": "2013-07-12T15:04:29", "upload_time_iso_8601": "2013-07-12T15:04:29.332308Z", "url": "https://files.pythonhosted.org/packages/af/87/9b38e25d4482293f8b46d9a97dbd819b6f1aab3530ff654bc8459e0bdc83/ecohydrolib-1.0.tar.gz", "yanked": false}], "1.1": [{"comment_text": "", "digests": {"md5": "639e81937110b5fe20c990b79762cfbb", "sha256": "ae94017f7014c52ab8ee7aab009c637cbd098dc99dce18ec0d55af2dd7e4f436"}, "downloads": -1, "filename": "ecohydrolib-1.1.tar.gz", "has_sig": false, "md5_digest": "639e81937110b5fe20c990b79762cfbb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 75143, "upload_time": "2013-07-30T18:42:09", "upload_time_iso_8601": "2013-07-30T18:42:09.050387Z", "url": "https://files.pythonhosted.org/packages/d6/44/ae57ef02adaef692ba7a81ef3d8bd1eba2654a59bed6b605cd1b9352b25f/ecohydrolib-1.1.tar.gz", "yanked": false}], "1.11": [{"comment_text": "", "digests": {"md5": "59707a46d466669cae639b4803feba84", "sha256": "4d7244a3adf35cc94cdb3db442549fccbd2d73abdefc7722ff8bbbff98e77d79"}, "downloads": -1, "filename": "ecohydrolib-1.11.tar.gz", "has_sig": false, "md5_digest": "59707a46d466669cae639b4803feba84", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 77643, "upload_time": "2013-08-24T02:06:52", "upload_time_iso_8601": "2013-08-24T02:06:52.565054Z", "url": "https://files.pythonhosted.org/packages/be/2f/22e7a7fe30f67bef9bfd52ce2c63d61ebe4da7a86be5be2645443bfdc83d/ecohydrolib-1.11.tar.gz", "yanked": false}], "1.12": [{"comment_text": "", "digests": {"md5": "c75ce43bd11fbeca3621523585d1eea2", "sha256": "f9f48c83d27866612c3586cdc67e499fde8e1d00198aa4e2bf285f133ff6a282"}, "downloads": -1, "filename": "ecohydrolib-1.12.tar.gz", "has_sig": false, "md5_digest": "c75ce43bd11fbeca3621523585d1eea2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 79473, "upload_time": "2013-09-26T16:10:04", "upload_time_iso_8601": "2013-09-26T16:10:04.514315Z", "url": "https://files.pythonhosted.org/packages/6e/0a/fc9122d3f97fe2876f4a79e20d24901c2eaab77b713d421fae6fcf3c2b11/ecohydrolib-1.12.tar.gz", "yanked": false}], "1.13": [{"comment_text": "", "digests": {"md5": "80fbe2e2ace7a06f9d140d783230744c", "sha256": "b38f0608579fbce112ac33b1000fd5c0e0a013d2581254bef3d5aeef0b57c154"}, "downloads": -1, "filename": "ecohydrolib-1.13.tar.gz", "has_sig": false, "md5_digest": "80fbe2e2ace7a06f9d140d783230744c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 79620, "upload_time": "2013-09-27T22:29:10", "upload_time_iso_8601": "2013-09-27T22:29:10.869232Z", "url": "https://files.pythonhosted.org/packages/41/41/ca99941c04f81ffbc1123fb08204150b6a5ee7f26d25e9799decb2de3754/ecohydrolib-1.13.tar.gz", "yanked": false}], "1.14": [{"comment_text": "", "digests": {"md5": "039a20049ca37a08df466284af902640", "sha256": "72bd00ac6486f957f2833c3652f08f18091e7c8f1a7a933d15cd597f9024b822"}, "downloads": -1, "filename": "ecohydrolib-1.14.tar.gz", "has_sig": false, "md5_digest": "039a20049ca37a08df466284af902640", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 80127, "upload_time": "2013-10-19T03:58:54", "upload_time_iso_8601": "2013-10-19T03:58:54.786167Z", "url": "https://files.pythonhosted.org/packages/71/c1/9932061f823d00a6a8e2b45479fc9d177e123e3af0350d9cd69a3b250493/ecohydrolib-1.14.tar.gz", "yanked": false}], "1.15": [{"comment_text": "", "digests": {"md5": "e9fed461c0e38ba4fccf74b0c6f7ae05", "sha256": "26b6e116ac2761fb5fff1ebe54c30d79cbb585966ce3baa2c44a4e65939b1c59"}, "downloads": -1, "filename": "ecohydrolib-1.15.tar.gz", "has_sig": false, "md5_digest": "e9fed461c0e38ba4fccf74b0c6f7ae05", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 80870, "upload_time": "2013-11-06T18:13:00", "upload_time_iso_8601": "2013-11-06T18:13:00.212457Z", "url": "https://files.pythonhosted.org/packages/83/40/418f36bbea1cac3b47d31d12f933ab1df01989e56746baf04697599be133/ecohydrolib-1.15.tar.gz", "yanked": false}], "1.16": [{"comment_text": "", "digests": {"md5": "ac37fa4473ccd291328be9aea0c2a0f5", "sha256": "21ff9602e1f7938119e6de6272a0469d381745dd412ddb0b895ba71b1922a4b0"}, "downloads": -1, "filename": "ecohydrolib-1.16.tar.gz", "has_sig": false, "md5_digest": "ac37fa4473ccd291328be9aea0c2a0f5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 81656, "upload_time": "2013-11-07T20:58:13", "upload_time_iso_8601": "2013-11-07T20:58:13.679267Z", "url": "https://files.pythonhosted.org/packages/52/53/fae74b42b695a44f4b88d02f02a747889f4798fcd2eb0c6a001ab4b8dd49/ecohydrolib-1.16.tar.gz", "yanked": false}], "1.17": [{"comment_text": "", "digests": {"md5": "d6045daf8f779484603e0ca380bc8936", "sha256": "b5681104cfac6364215f6f2ea76953e09ff1f0c556f1e21e01b4bdf5cdfad68c"}, "downloads": -1, "filename": "ecohydrolib-1.17.tar.gz", "has_sig": false, "md5_digest": "d6045daf8f779484603e0ca380bc8936", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 82205, "upload_time": "2014-01-18T14:44:33", "upload_time_iso_8601": "2014-01-18T14:44:33.526204Z", "url": "https://files.pythonhosted.org/packages/c4/f9/c5655e78e9c3320cdc18a2795767e37355f13bf190e73d80100e6e5ea65e/ecohydrolib-1.17.tar.gz", "yanked": false}], "1.18": [{"comment_text": "", "digests": {"md5": "02c33686a2ae00954436df5bb61e2844", "sha256": "6139fcb57194edb38bc8f773a3db9eb741f37928f477e241e50ae3df3402e672"}, "downloads": -1, "filename": "ecohydrolib-1.18.tar.gz", "has_sig": false, "md5_digest": "02c33686a2ae00954436df5bb61e2844", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 82177, "upload_time": "2014-02-05T23:21:19", "upload_time_iso_8601": "2014-02-05T23:21:19.061803Z", "url": "https://files.pythonhosted.org/packages/ff/24/cac2170312ccf09b1bf233b52f46c16370f9f53f6dabb75218341ba51e45/ecohydrolib-1.18.tar.gz", "yanked": false}], "1.19": [{"comment_text": "", "digests": {"md5": "c9f4fad7c0549c38e825849cd4235904", "sha256": "a9de60bdc1259cb2541ca0167304e1540ff9e7344bc491434766fadd2f001bd5"}, "downloads": -1, "filename": "ecohydrolib-1.19.tar.gz", "has_sig": false, "md5_digest": "c9f4fad7c0549c38e825849cd4235904", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 82289, "upload_time": "2014-02-13T20:16:56", "upload_time_iso_8601": "2014-02-13T20:16:56.220747Z", "url": "https://files.pythonhosted.org/packages/9c/2d/503102fb6d8c4ee2eee8c97f16cced74a599ff5575e57b7576dc307762cb/ecohydrolib-1.19.tar.gz", "yanked": false}], "1.20": [{"comment_text": "", "digests": {"md5": "4456149504032b7aedc9a3fc7d96ab76", "sha256": "86927c514b504903a8b92e14a738121318789f476a967587ce3f5420645c19bf"}, "downloads": -1, "filename": "ecohydrolib-1.20.tar.gz", "has_sig": false, "md5_digest": "4456149504032b7aedc9a3fc7d96ab76", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 82044, "upload_time": "2014-11-04T23:53:37", "upload_time_iso_8601": "2014-11-04T23:53:37.257016Z", "url": "https://files.pythonhosted.org/packages/81/ff/9ede7322372351d47ef41007ed2d789e6533dab92fe38118912512d43f25/ecohydrolib-1.20.tar.gz", "yanked": false}], "1.21": [{"comment_text": "", "digests": {"md5": "11ef7a13e9d45b8180e28ab9a90860ad", "sha256": "13889e9f9ab1d5fe7514ea77fa82f820e795899cd1a6c4d5f45d3e7bcb62cd2e"}, "downloads": -1, "filename": "ecohydrolib-1.21.tar.gz", "has_sig": false, "md5_digest": "11ef7a13e9d45b8180e28ab9a90860ad", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 82062, "upload_time": "2014-12-03T01:26:33", "upload_time_iso_8601": "2014-12-03T01:26:33.080777Z", "url": "https://files.pythonhosted.org/packages/73/35/495488d0ba4876d869ca136801f2166a4a42f701ce112c00043bb4538e30/ecohydrolib-1.21.tar.gz", "yanked": false}], "1.22": [{"comment_text": "", "digests": {"md5": "65bb5657860a507db4b5e1f9ea0e2036", "sha256": "bb28b115c66d97f0111095411ad1f0d02a698f904a7deb13c40ed66c0123751f"}, "downloads": -1, "filename": "ecohydrolib-1.22.tar.gz", "has_sig": false, "md5_digest": "65bb5657860a507db4b5e1f9ea0e2036", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 84421, "upload_time": "2015-01-01T21:39:49", "upload_time_iso_8601": "2015-01-01T21:39:49.872026Z", "url": "https://files.pythonhosted.org/packages/5c/dd/5c8cad818b97a96af0f183a222d37c9f63ebc607922881ff5d1635b647a9/ecohydrolib-1.22.tar.gz", "yanked": false}], "1.23": [{"comment_text": "", "digests": {"md5": "b1a9e55d3b08704cac796b60b0e0e802", "sha256": "50089b7f7a0266333f271778f719c4be39d4b0f4e90861d0ecf3f0275a594eb7"}, "downloads": -1, "filename": "ecohydrolib-1.23.tar.gz", "has_sig": false, "md5_digest": "b1a9e55d3b08704cac796b60b0e0e802", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 90592, "upload_time": "2015-03-19T00:25:37", "upload_time_iso_8601": "2015-03-19T00:25:37.700108Z", "url": "https://files.pythonhosted.org/packages/6b/d4/7f2fd1559d39d2dc82a13aad37a2c401bb01f8a001cad02f5e9fd79c5f47/ecohydrolib-1.23.tar.gz", "yanked": false}], "1.24": [{"comment_text": "", "digests": {"md5": "31acb60d5d1ee7b87cf90157d60e5157", "sha256": "7e45ddef2754efc42f1add32569f5dd794cbccb7c7a1b41969146bcdd4ac16f9"}, "downloads": -1, "filename": "ecohydrolib-1.24.tar.gz", "has_sig": false, "md5_digest": "31acb60d5d1ee7b87cf90157d60e5157", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 90779, "upload_time": "2015-03-24T23:44:26", "upload_time_iso_8601": "2015-03-24T23:44:26.342666Z", "url": "https://files.pythonhosted.org/packages/3a/88/a6ac710f8b854f5a79fdc96fc738edb787f41a6f81571e39c5b49f06c79d/ecohydrolib-1.24.tar.gz", "yanked": false}], "1.25": [{"comment_text": "", "digests": {"md5": "6d4a1710441217e377fa07386601c36d", "sha256": "e4de071c5a1703b4761a29f6cbdc7b9f21995c0b00ed6c52ae2c80c3f6a214cb"}, "downloads": -1, "filename": "ecohydrolib-1.25.tar.gz", "has_sig": false, "md5_digest": "6d4a1710441217e377fa07386601c36d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 95221, "upload_time": "2015-05-26T01:05:53", "upload_time_iso_8601": "2015-05-26T01:05:53.283150Z", "url": "https://files.pythonhosted.org/packages/a3/8f/77e91afa39e1fc6748be1446d1b61c63b9c5d90ad71b6d58b3b33ea68790/ecohydrolib-1.25.tar.gz", "yanked": false}], "1.26": [{"comment_text": "", "digests": {"md5": "29b380b7098b336041a6b17bc21840c7", "sha256": "e8e71d2741f37a5a81c3dcd21530d13733ffd527b986d2f71e11c9603d1729a1"}, "downloads": -1, "filename": "ecohydrolib-1.26.tar.gz", "has_sig": false, "md5_digest": "29b380b7098b336041a6b17bc21840c7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 98707, "upload_time": "2015-06-12T13:11:31", "upload_time_iso_8601": "2015-06-12T13:11:31.059963Z", "url": "https://files.pythonhosted.org/packages/d2/43/b4628229caab978ade17ff875857c26fa7b0419180715397b0c321c26811/ecohydrolib-1.26.tar.gz", "yanked": false}], "1.27": [{"comment_text": "", "digests": {"md5": "bd4e00cbcb2a61494fa36e6f706b6be1", "sha256": "1610b2789f7480f704dc0c04c4e933e8b1c312e8a5891ca0e359eef21fa8efbd"}, "downloads": -1, "filename": "ecohydrolib-1.27.tar.gz", "has_sig": false, "md5_digest": "bd4e00cbcb2a61494fa36e6f706b6be1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 101001, "upload_time": "2015-06-22T21:27:09", "upload_time_iso_8601": "2015-06-22T21:27:09.850448Z", "url": "https://files.pythonhosted.org/packages/89/70/bdab064b9da76c8ee099a726ab9a7f099a45a10e7494a4d7070b6e518c03/ecohydrolib-1.27.tar.gz", "yanked": false}], "1.28": [{"comment_text": "", "digests": {"md5": "8f8d95141ab0074408390685c6d21aef", "sha256": "5c2b9b42d7d39a1ea77fcc53ac5150d59ccc6154a8423c9525f604a64ba0c5c4"}, "downloads": -1, "filename": "ecohydrolib-1.28.tar.gz", "has_sig": false, "md5_digest": "8f8d95141ab0074408390685c6d21aef", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 101247, "upload_time": "2015-07-01T22:16:39", "upload_time_iso_8601": "2015-07-01T22:16:39.072601Z", "url": "https://files.pythonhosted.org/packages/90/59/59fc33f57f340361d731c8dfdaf36b7f4aa522f461414ab488b8c3e6ff52/ecohydrolib-1.28.tar.gz", "yanked": false}], "1.29": [{"comment_text": "", "digests": {"md5": "51a2ac9751d5c71696368dce4f781497", "sha256": "9442cc4befce73daff248bca890f3cf3ba467d9a23aec5682338bb85d2ee3760"}, "downloads": -1, "filename": "ecohydrolib-1.29.tar.gz", "has_sig": false, "md5_digest": "51a2ac9751d5c71696368dce4f781497", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 101289, "upload_time": "2015-07-02T21:34:30", "upload_time_iso_8601": "2015-07-02T21:34:30.754792Z", "url": "https://files.pythonhosted.org/packages/85/ca/b38fa45ca8755857b408b422c34236d6ae350e86f3da2230bda5561b8e42/ecohydrolib-1.29.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "51a2ac9751d5c71696368dce4f781497", "sha256": "9442cc4befce73daff248bca890f3cf3ba467d9a23aec5682338bb85d2ee3760"}, "downloads": -1, "filename": "ecohydrolib-1.29.tar.gz", "has_sig": false, "md5_digest": "51a2ac9751d5c71696368dce4f781497", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 101289, "upload_time": "2015-07-02T21:34:30", "upload_time_iso_8601": "2015-07-02T21:34:30.754792Z", "url": "https://files.pythonhosted.org/packages/85/ca/b38fa45ca8755857b408b422c34236d6ae350e86f3da2230bda5561b8e42/ecohydrolib-1.29.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:47:59 2020"}