{"info": {"author": "Arun S. Maiya", "author_email": "arun@maiya.net", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "# TorchFit\n\n`TorchFit` is a bare-bones, minimalistic *training-helper* for **PyTorch** that exposes an easy-to-use `fit` method in the style of **fastai** and **Keras**.  \n\n`TorchFit` is intended to be minimally-invasive with a tiny footprint and as little bloat as possible. It is well-suited to those that are new to training models in PyTorch. \n\n## Usage\n\n```python\n\n\n# normal PyTorch stuff\ntrain_loader = create_your_training_data_loader()\nval_loader = create_your_validation_data_loader()\ntest_loader = create_your_test_data_loader()\nmodel = create_your_pytorch_model()\n\n# wrap model and data in Learner\nimport torchfit\nlearner = torchfit.Learner(model, train_loader, val_loader=val_loader)\n\n# estimate LR using Learning Rate Finder\nlearner.find_lr()\n\n# train using 1cycle learning rate policy\nlearner.fit_onecycle(1e-4, 3)\n\n# plot training vs. validation loss\nlearner.plot('loss')\n\n# make predictions as easy as in Keras\ny_pred = learner.predict(test_loader)\n\n# save model and reload later\nlearner.save('/tmp/mymodel')\nlearer.load('/tmp/mymodel')\n```\n\n\n#### `TorchFit` Training Loop\n<img src=\"https://github.com/amaiya/torchfit/raw/develop/images/torchfit_progress.gif\" width=\"800\">\n\n\n## Tutorials and Examples\n- **[Quickstart with MNIST](https://github.com/amaiya/torchfit/blob/master/examples/quickstart-mnist.ipynb):**  quickstart notebook to get you up and running\n- **[Tutorial Notebook](https://github.com/amaiya/torchfit/blob/master/examples/tutorial.ipynb):**  tutorial notebook using the same model and data employed in the [PyTorch text classification tutorial](https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html)\n\n\n##  Features\n\n#### Learning Rate Finder\n```learner.find_lr()```\n\n\n#### A `fit` method for Training\n```\n# Examples\nlearner.fit(lr, epochs)\nlearner.fit_onecycle(lr, epochs)\nlearner.fit(lr, epochs, schedulers=[scheduler])\n```\n\n#### Easy-to-Execute Testing and Predictions\n```\n# Examples\noutputs = learner.predict(test_loader)\noutputs, targets = learner.predict(test_loader, return_targets=True)\n\ntext = 'Shares of IBM rose today.'\npredicted_label = learner.predict_example(text, preproc_fn=preprocess, labels=labels)\n```\n\n\n#### Gradient Accumulation\n```learner.fit_onecycle(lr, 1, accumulation_steps=8)```\n\n\n#### Gradient Clipping\n```learner.fit_onecycle(lr, 1, gradient_clip_val=1)```\n\n\n#### Mixed Precision Training\n```torchfit.Learner(model, train_loader, val_loader=val_loader, use_amp=True, amp_level='O2')```\n\n#### Multi-GPU Training and GPU Selection\n\nTo train on first two GPUs (0 and 1):\n\n```learner = torchfit.Learner(model, train_loader, val_loader=test_loader, gpus=[0,1])```\n\nTo train only on the second GPU, one can do either this:\n\n```learner = torchfit.Learner(model, train_loader, val_loader=test_loader, gpus=[1])```\n\nor this...\n\n```learner = torchfit.Learner(model, train_loader, val_loader=test_loader, device='cuda:1')```\n\n\n#### Resetting Weights of Model\n```learner.reset_weights()``` \n\n\n#### Saving/Loading Model\n```\nlearner.save('/tmp/mymodel')\nlearner.load('/tmp/mymodel')\n```\n\n\n\n\n\n\n## Installation\n\nAfter ensuring [PyTorch is installed](https://pytorch.org/get-started/locally/), install `TorchFit` with:\n\n```\npip3 install torchfit\n\n```\n\n<!-- pip3 install pillow==6.2.2 torch==1.3.1+cu100 torchvision==0.4.2+cu100 -f https://download.pytorch.org/whl/torch_stable.html -->", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/amaiya/torchfit", "keywords": "pytorch,deep learning,machine learning", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "torchfit", "package_url": "https://pypi.org/project/torchfit/", "platform": "", "project_url": "https://pypi.org/project/torchfit/", "project_urls": {"Homepage": "https://github.com/amaiya/torchfit"}, "release_url": "https://pypi.org/project/torchfit/0.2.5/", "requires_dist": null, "requires_python": "", "summary": "TorchFit is a simple, easy-to-use, and minimalistic training-helper for PyTorch", "version": "0.2.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>TorchFit</h1>\n<p><code>TorchFit</code> is a bare-bones, minimalistic <em>training-helper</em> for <strong>PyTorch</strong> that exposes an easy-to-use <code>fit</code> method in the style of <strong>fastai</strong> and <strong>Keras</strong>.</p>\n<p><code>TorchFit</code> is intended to be minimally-invasive with a tiny footprint and as little bloat as possible. It is well-suited to those that are new to training models in PyTorch.</p>\n<h2>Usage</h2>\n<pre><span class=\"c1\"># normal PyTorch stuff</span>\n<span class=\"n\">train_loader</span> <span class=\"o\">=</span> <span class=\"n\">create_your_training_data_loader</span><span class=\"p\">()</span>\n<span class=\"n\">val_loader</span> <span class=\"o\">=</span> <span class=\"n\">create_your_validation_data_loader</span><span class=\"p\">()</span>\n<span class=\"n\">test_loader</span> <span class=\"o\">=</span> <span class=\"n\">create_your_test_data_loader</span><span class=\"p\">()</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">create_your_pytorch_model</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># wrap model and data in Learner</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torchfit</span>\n<span class=\"n\">learner</span> <span class=\"o\">=</span> <span class=\"n\">torchfit</span><span class=\"o\">.</span><span class=\"n\">Learner</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">train_loader</span><span class=\"p\">,</span> <span class=\"n\">val_loader</span><span class=\"o\">=</span><span class=\"n\">val_loader</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># estimate LR using Learning Rate Finder</span>\n<span class=\"n\">learner</span><span class=\"o\">.</span><span class=\"n\">find_lr</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># train using 1cycle learning rate policy</span>\n<span class=\"n\">learner</span><span class=\"o\">.</span><span class=\"n\">fit_onecycle</span><span class=\"p\">(</span><span class=\"mf\">1e-4</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># plot training vs. validation loss</span>\n<span class=\"n\">learner</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"s1\">'loss'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># make predictions as easy as in Keras</span>\n<span class=\"n\">y_pred</span> <span class=\"o\">=</span> <span class=\"n\">learner</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">test_loader</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># save model and reload later</span>\n<span class=\"n\">learner</span><span class=\"o\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"s1\">'/tmp/mymodel'</span><span class=\"p\">)</span>\n<span class=\"n\">learer</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s1\">'/tmp/mymodel'</span><span class=\"p\">)</span>\n</pre>\n<h4><code>TorchFit</code> Training Loop</h4>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a10dbbc18a2828033cdcc773224326e37df4024b/68747470733a2f2f6769746875622e636f6d2f616d616979612f746f7263686669742f7261772f646576656c6f702f696d616765732f746f7263686669745f70726f67726573732e676966\" width=\"800\">\n<h2>Tutorials and Examples</h2>\n<ul>\n<li><strong><a href=\"https://github.com/amaiya/torchfit/blob/master/examples/quickstart-mnist.ipynb\" rel=\"nofollow\">Quickstart with MNIST</a>:</strong>  quickstart notebook to get you up and running</li>\n<li><strong><a href=\"https://github.com/amaiya/torchfit/blob/master/examples/tutorial.ipynb\" rel=\"nofollow\">Tutorial Notebook</a>:</strong>  tutorial notebook using the same model and data employed in the <a href=\"https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html\" rel=\"nofollow\">PyTorch text classification tutorial</a></li>\n</ul>\n<h2>Features</h2>\n<h4>Learning Rate Finder</h4>\n<p><code>learner.find_lr()</code></p>\n<h4>A <code>fit</code> method for Training</h4>\n<pre><code># Examples\nlearner.fit(lr, epochs)\nlearner.fit_onecycle(lr, epochs)\nlearner.fit(lr, epochs, schedulers=[scheduler])\n</code></pre>\n<h4>Easy-to-Execute Testing and Predictions</h4>\n<pre><code># Examples\noutputs = learner.predict(test_loader)\noutputs, targets = learner.predict(test_loader, return_targets=True)\n\ntext = 'Shares of IBM rose today.'\npredicted_label = learner.predict_example(text, preproc_fn=preprocess, labels=labels)\n</code></pre>\n<h4>Gradient Accumulation</h4>\n<p><code>learner.fit_onecycle(lr, 1, accumulation_steps=8)</code></p>\n<h4>Gradient Clipping</h4>\n<p><code>learner.fit_onecycle(lr, 1, gradient_clip_val=1)</code></p>\n<h4>Mixed Precision Training</h4>\n<p><code>torchfit.Learner(model, train_loader, val_loader=val_loader, use_amp=True, amp_level='O2')</code></p>\n<h4>Multi-GPU Training and GPU Selection</h4>\n<p>To train on first two GPUs (0 and 1):</p>\n<p><code>learner = torchfit.Learner(model, train_loader, val_loader=test_loader, gpus=[0,1])</code></p>\n<p>To train only on the second GPU, one can do either this:</p>\n<p><code>learner = torchfit.Learner(model, train_loader, val_loader=test_loader, gpus=[1])</code></p>\n<p>or this...</p>\n<p><code>learner = torchfit.Learner(model, train_loader, val_loader=test_loader, device='cuda:1')</code></p>\n<h4>Resetting Weights of Model</h4>\n<p><code>learner.reset_weights()</code></p>\n<h4>Saving/Loading Model</h4>\n<pre><code>learner.save('/tmp/mymodel')\nlearner.load('/tmp/mymodel')\n</code></pre>\n<h2>Installation</h2>\n<p>After ensuring <a href=\"https://pytorch.org/get-started/locally/\" rel=\"nofollow\">PyTorch is installed</a>, install <code>TorchFit</code> with:</p>\n<pre><code>pip3 install torchfit\n\n</code></pre>\n\n\n          </div>"}, "last_serial": 6619816, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "96f0be1a8076a95027c4431b51d9888f", "sha256": "8117bf628861bbf537d3644ecbfa79c84789c046553cab1fea163ce8de3dc5ba"}, "downloads": -1, "filename": "torchfit-0.1.0.tar.gz", "has_sig": false, "md5_digest": "96f0be1a8076a95027c4431b51d9888f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8566, "upload_time": "2020-02-06T21:26:21", "upload_time_iso_8601": "2020-02-06T21:26:21.323411Z", "url": "https://files.pythonhosted.org/packages/30/87/85939a3f8cbd27e2a23e66e144d8b28c1fefb90565890a0c52db83fa1805/torchfit-0.1.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "eeb42a9c438b7c2adc97f69132c0ef27", "sha256": "6a79dbe7fff672eab203e6f93790c91a8ca23db2afc0ab38a28976c8305e9860"}, "downloads": -1, "filename": "torchfit-0.2.0.tar.gz", "has_sig": false, "md5_digest": "eeb42a9c438b7c2adc97f69132c0ef27", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8569, "upload_time": "2020-02-07T18:23:55", "upload_time_iso_8601": "2020-02-07T18:23:55.580256Z", "url": "https://files.pythonhosted.org/packages/73/d8/b9722785bcd4584ebb18c98cc36c9188d426a536b46be91d734f82eecb9e/torchfit-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "e66d4670ca75e9b41e85d220b0c4f2b6", "sha256": "b93a53f90a07df4d6748e14d30dd50f45cec12267ce18a84403b0b837aea1e98"}, "downloads": -1, "filename": "torchfit-0.2.1.tar.gz", "has_sig": false, "md5_digest": "e66d4670ca75e9b41e85d220b0c4f2b6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8683, "upload_time": "2020-02-07T23:22:59", "upload_time_iso_8601": "2020-02-07T23:22:59.043287Z", "url": "https://files.pythonhosted.org/packages/ed/f4/da2cbf47af2c0053d64d1f17becadb6c1df185944115e278f5f9fb7b7eb6/torchfit-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "69e6f3fc16a105a79a4893ac6426dff1", "sha256": "14ac9aebce47f758bf68ce290620edc2a88e77a5e0c36fba8d4c35b163757c4e"}, "downloads": -1, "filename": "torchfit-0.2.2.tar.gz", "has_sig": false, "md5_digest": "69e6f3fc16a105a79a4893ac6426dff1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15075, "upload_time": "2020-02-11T21:49:13", "upload_time_iso_8601": "2020-02-11T21:49:13.700028Z", "url": "https://files.pythonhosted.org/packages/86/82/912d1af9ad7dcc6353014f6e0776fd345470a5ed0317dc736419e63bbc73/torchfit-0.2.2.tar.gz", "yanked": false}], "0.2.3": [{"comment_text": "", "digests": {"md5": "ebe883bdf9d920afe9322d432192c3bd", "sha256": "96875d41e245f7cd0de1c6c614d293f6be7cd3a51769dbf53295801422e4ebb8"}, "downloads": -1, "filename": "torchfit-0.2.3.tar.gz", "has_sig": false, "md5_digest": "ebe883bdf9d920afe9322d432192c3bd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15101, "upload_time": "2020-02-11T23:00:13", "upload_time_iso_8601": "2020-02-11T23:00:13.464749Z", "url": "https://files.pythonhosted.org/packages/ba/44/c85111c86b6de27bd5d2e4c15f6f2a5386e5efa542b721dced130e7ed6e4/torchfit-0.2.3.tar.gz", "yanked": false}], "0.2.4": [{"comment_text": "", "digests": {"md5": "75f65affb3f400f86dc2da67f9479428", "sha256": "01c817602155e4c525948f683ca3b99d0ab3b3a9c485259fb5e695772bd39062"}, "downloads": -1, "filename": "torchfit-0.2.4.tar.gz", "has_sig": false, "md5_digest": "75f65affb3f400f86dc2da67f9479428", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15122, "upload_time": "2020-02-11T23:10:31", "upload_time_iso_8601": "2020-02-11T23:10:31.961649Z", "url": "https://files.pythonhosted.org/packages/c0/07/52139be78945e462db1d7dfcb851335c5345b873cdc9403e7aee6b9215cf/torchfit-0.2.4.tar.gz", "yanked": false}], "0.2.5": [{"comment_text": "", "digests": {"md5": "144f382ae6f9445cd080012e300eb8ac", "sha256": "44a08e3c2e978a62a629b75e533617d3ef5c6a7b20fc31533787c290472864d9"}, "downloads": -1, "filename": "torchfit-0.2.5.tar.gz", "has_sig": false, "md5_digest": "144f382ae6f9445cd080012e300eb8ac", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16026, "upload_time": "2020-02-12T23:21:45", "upload_time_iso_8601": "2020-02-12T23:21:45.849817Z", "url": "https://files.pythonhosted.org/packages/23/53/adc1e69f9d3d07d16bebf8a6ecfc1b7c8d54947a7ac71b02e5a66acde934/torchfit-0.2.5.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "144f382ae6f9445cd080012e300eb8ac", "sha256": "44a08e3c2e978a62a629b75e533617d3ef5c6a7b20fc31533787c290472864d9"}, "downloads": -1, "filename": "torchfit-0.2.5.tar.gz", "has_sig": false, "md5_digest": "144f382ae6f9445cd080012e300eb8ac", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16026, "upload_time": "2020-02-12T23:21:45", "upload_time_iso_8601": "2020-02-12T23:21:45.849817Z", "url": "https://files.pythonhosted.org/packages/23/53/adc1e69f9d3d07d16bebf8a6ecfc1b7c8d54947a7ac71b02e5a66acde934/torchfit-0.2.5.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:50:30 2020"}