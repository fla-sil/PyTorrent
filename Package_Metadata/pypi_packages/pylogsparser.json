{"info": {"author": "Wallix", "author_email": "opensource@wallix.org", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "License :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)", "Topic :: Software Development :: Libraries", "Topic :: System :: Logging"], "description": "LogsParser\n==========\n\nDescription\n:::::::::::\n\nLogsParser is an opensource python library created by Wallix ( http://www.wallix.org ).\nIt is used as the core mechanism for logs tagging and normalization by Wallix's LogBox\n( http://www.wallix.com/index.php/products/wallix-logbox ).\n\nLogs come in a variety of formats. In order to parse many different types of\nlogs, a developer used to need to write an engine based on a large list of complex\nregular expressions. It can become rapidly unreadable and unmaintainable.\n\nBy using LogsParser, a developer can free herself from the burden of writing a\nlog parsing engine, since the module comes in with \"batteries included\".\nFurthermore, this engine relies upon XML definition files that can be loaded at\nruntime. The definition files were designed to be easily readable and need very\nlittle skill in programming or regular expressions, without sacrificing\npowerfulness or expressiveness.\n\nPurpose\n:::::::\n\nThe LogsParser module uses normalization definition files in order to tag\nlog entries. The definition files are written in XML.\n\nThe definition files allow anyone with a basic understanding of regular\nexpressions and knowledge of a specific log format to create and maintain\na customized pool of parsers.\n\nBasically a definition file will consist of a list of log patterns, each\ncomposed of many keywords. A keyword is a placeholder for a notable and/or \nvariable part in the described log line, and therefore associated to a tag\nname. It is paired to a tag type, e.g. a regular expression matching the\nexpected value to assign to this tag. If the raw value extracted this way needs\nfurther processing, callback functions can be applied to this value.\n\nThis format also allows to add useful meta-data about parsed logs, such as\nextensive documentation about expected log patterns and log samples.\n\nFormat Description\n------------------\n\nA normalization definition file must strictly follow the specifications as\nthey are detailed in the file normalizer.dtd .\n\nA simple template is provided to help parser writers get started with their\ntask, called normalizer.template.\n\nMost definition files will include the following sections :\n\n* Some generic documentation about the parsed logs : emitting application,\n  application version, etc ... (non-mandatory)\n* the definition file's author(s) (non-mandatory)\n* custom tag types (non-mandatory)\n* callback functions (non-mandatory)\n* Prerequisites on tag values prior to parsing (non-mandatory)\n* Log pattern(s) and how they are to be parsed\n* Extra tags with a fixed value that should be added once the parsing is done\n  (non-mandatory)\n\nRoot\n....\n\nThe definition file's root must hold the following elements :\n\n* the normalizer's name.\n* the normalizer's version.\n* the flags to apply to the compilation of regular expressions associated with\n  this parser : unicode support, multiple lines support, and ignore case.\n* how to match the regular expression : from the beginning of the log line (match)\n  or from anywhere in the targeted tag (search)\n* the tag value to parse (raw, body...)\n* the service taxonomy, if relevant, of the normalizer. See the end of this\n  document for more details.\n* the optional expandWhitespaces value. If set to \"yes\", spaces or carriage returns\n   in a pattern will be converted to match any whitespace character (line feed, tab, etc). \n   This is to maintain the readability of multiline patterns.\n\nDefault tag types\n.................\n\nA few basic tag types are defined in the file common_tagTypes.xml . In order\nto use it, it has to be loaded when instantiating the Normalizer class; see the\nclass documentation for further information.\n\nHere is a list of default tag types shipped with this library.\n\n* Anything : any character chain of any length.\n* Integer\n* EpochTime : an EPOCH timestamp of arbitrary precision (to the second and below).\n* syslogDate : a date as seen in syslog formatted logs (example : Mar 12 20:13:23)\n* URL\n* MACAddress\n* Email\n* IP\n* ZuluTime : a \"Zulu Time\"-type timestamp (example : 2012-12-21T13:45:05)\n\n\nCustom Tag Types\n................\n\nIt is always possible to define new tag types in a parser definition file, and\nto overwrite default ones. To define a new tag type, the following elements are\nneeded :\n\n* a type name. This will be used as the type reference in log patterns.\n* the python type of the expected result : this element is not used yet and can\n  be safely set to anything.\n* a non-mandatory description.\n* the regular expression defining this type.\n\nCallback Functions\n..................\n\nOne might want to transform a raw value after it has been extracted from a pattern:\nthe syslog normalizer converts the raw log timestamp into a python datetime object,\nfor example.\n\nIn order to do this, the <callback> tag must be used to define a callback function.\n\n<callback> requires a function name as a mandatory attribute. Its text defines the\nfunction body as in python, meaning the PEP8 indentation rules are to be followed. \n\nWhen writing a callback function, the following rules must be respected :\n\n* Your callback function will take ONLY two arguments: **value** and **log**.\n  \"value\" is the raw value extracted from applying the log pattern to the log,\n  and \"log\" is the dictionary of the normalized log in its current state (prior\n  to normalization induced by this parser definition file).\n* Your callback function can modify the \"log\" argument (especially assign\n  the transformed value to the concerned tag name) and must not return anything.\n* Your callback function has a restricted access to the following facilities: ::\n\n   \"list\", \"dict\", \"tuple\", \"set\", \"long\", \"float\", \"object\",\n   \"bool\", \"callable\", \"True\", \"False\", \"dir\",\n   \"frozenset\", \"getattr\", \"hasattr\", \"abs\", \"cmp\", \"complex\",\n   \"divmod\", \"id\", \"pow\", \"round\", \"slice\", \"vars\",\n   \"hash\", \"hex\", \"int\", \"isinstance\", \"issubclass\", \"len\",\n   \"map\", \"filter\", \"max\", \"min\", \"oct\", \"chr\", \"ord\", \"range\",\n   \"reduce\", \"repr\", \"str\", \"unicode\", \"basestring\", \"type\", \"zip\", \"xrange\", \"None\",\n   \"Exception\"  \n\n* Importing modules is therefore forbidden and impossible. The *re* and *datetime*\n  modules are available for use as if the following lines were present: ::\n\n   import re\n   from datetime import datetime\n   \n* In version 0.4, the \"extras\" package is introduced. It allows more freedom in \n  what can be used in callbacks. It also increases execution speed in some \n  cases; typically when you need to use complex objects in your callback like \n  a big set or a big regular expression. In the old approach, this object \n  would be created each time the function is called; by deporting the object's\n  creation in the extras package it is created once and for all. See the modules\n  in logsparser.extras for use cases.\n\nDefault callbacks\n.................\n\nAs with default tag types, a few generic callbacks are defined in the file \ncommon_callBacks.xml . Currently they are meant to deal with common date \nformattings. Therefore they will automatically set the \"date\" tag. In order to \nuse it, the callbacks file has to be loaded when instantiating the Normalizer \nclass; see the class documentation for further information.\n\nIn case of name collisions, callbacks defined in a normalizer description file \ntake precedence over common callbacks.\n\nHere is a list of default callbacks shipped with this library. \n\n* MM/dd/YYYY hh:mm:ss : parses dates such as 04/13/2010 14:23:56\n* dd/MMM/YYYY:hh:mm:ss : parses dates such as 19/Jul/2009 12:02:43\n* MMM dd hh:mm:ss : parses dates such as Oct 23 10:23:12 . The year is guessed \n  so that the resulting date is the closest in the past.\n* DDD MMM dd hh:mm:ss YYYY : parses dates such as Mon Sep 11 09:13:54 2011\n* YYYY-MM-DD hh:mm:ss : parses dates such as 2012-12-21 00:00:00\n* MM/DD/YY, hh:mm:ss : parses dates such as 10/23/11, 07:24:04 . The year is \n  assumed to be in the XXIst century.\n* YYMMDD hh:mm:ss:  parses dates such as 070811 17:23:12 . The year is assumed \n  to be in the XXIst century.\n* ISO8601 : converts a combined date and time in UTC expressed according to the \n  ISO 8601 standard. Also commonly referred to as \"Zulu Time\".\n* EPOCH : parses EPOCH timestamps\n* dd-MMM-YYYY hh:mm:ss : parses dates such as 28-Feb-2010 23:15:54\n\nFinal callbacks\n...............\n\nOne might want to wait until a pattern has been fully applied before processing\ndata : if for example you'd like to tag a log with a value made of a concatenation of\nother values, and so on. It is possible to specify a list of callbacks to apply\nat the end of the parsing with the XML tag \"finalCallbacks\".\n\nSuch callbacks will follow the mechanics described above, with one notable change:\nthey will be called with the argument \"value\" set to None. Therefore, you have\nto make sure your callback will work correctly that way.\n\nThere are a few examples of use available : in the test_normalizer.py test code,\nand in the deny_all normalizer.\n\nPattern definition\n..................\n\nA definition file can contain as many log patterns as one sees fit. These patterns\nare simplified regular expressions and applied in alphabetical order of their names,\nso it is important to name them so that the more precise patterns are tried\nbefore the more generic ones.\n\nA pattern is a \"meta regular expression\", which means that every syntactic rule from\npython's regular expressions are to be followed when writing a pattern, especially\nescaping special characters. To make the patterns easier to read than an obtuse\nregular expression, keywords act as \"macros\" and correspond to a part of the log\nto assign to a tag.\n\nA log pattern has the following components:\n\n* A name.\n* A non-mandatory description of the pattern's context.\n* The pattern itself, under the tag \"text\".\n* The tags as they appear in the pattern, the associated name once the normalization\n  is over, and the callback functions to eventually call on their raw values\n* Non-mandatory log samples. These can be used for self-validation.\n\nIf a tag name starts with __ (double underscore), this tag won't be added to the\nfinal normalized dictionary. This allows to create temporary tags that will\ntypically be used in conjunction to a series of callback functions, when the\noriginal raw value has no actual interest.\n\nTo define log patterns describing a CSV-formatted message, one must add the\nfollowing attributes in the tag \"text\":\n\n* type=\"csv\"\n* separator=\",\" or the relevant separator character\n* quotechar='\"' or the relevant quotation character\n\nTags are then defined normally. Pylogsparser will deal automatically with missing\nfields.\n\n\nBest practices\n..............\n\n* Order your patterns in decreasing order of specificity. Not doing so might\n  trigger errors, as more generic patterns will match earlier.\n* The more precise your tagTypes' regular expressions, the more accurate your\n  parser will be.\n* Use description tags liberally. The more documented a log format, the better.\n  Examples are also invaluable.\n\nTag naming convention\n.....................\n\nThe tag naming convention is lowercase, underscore separated words. It is strongly\nrecommended to stick to that naming convention when writing new normalizers\nfor consistency's sake. In case of dynamic fields, it is advised to make sure\ndynamic naming follows the convention. There's an example of this in \nMSExchange2007MessageTracking.xml; see the callback named \"decode_MTLSourceContext\".\n\nLog contains common informations such as username, IP address, informations about\ntransport protocol... In order to ease log post-processing we must define a common\nmethod to name those tags and not deal for example with a series of \"login, user,\nusername, userid\" all describing a user id.\nThe alphabetical list below is a series of tag names that must be used when relevant.\n\n- action : action taken by a component such as DELETED, migrated, DROP, open.\n- bind_int : binding interface for a network service.\n- dest_host : hostname or FQDN of a destination host.\n- dest_ip : IP address of a destination host.\n- dest_mac : MAC address of a destination host.\n- dest_port : destination port of a network connection.\n- event_id : id describing an event.\n- inbound_int : network interface for incoming data.\n- len : a data size.\n- local_host : hostname or FQDN of the local host.\n- local_ip : IP adress of the local host.\n- local_mac : MAC address of the local host.\n- local_port : listening port of a local service.\n- message_id : message or transaction id.\n- message_recipient : message recipient id.\n- message_sender : message sender id.\n- method : component access method such as GET, key_auth.\n- outbound_int : network interface for outgoing data.\n- protocol : network or software protocol name or numeric id such as TCP, NTP, SMTP.\n- source_host : hostname or FQDN of a source host.\n- source_ip : IP address of a source host.\n- source_mac : MAC address of a source host.\n- source_port : source port of a network connection.\n- status : component status such as FAIL, success, 404.\n  see below for a complete list.\n- url : an URL as defined in rfc1738. (scheme://netloc/path;parameters?query#fragment)\n- user : a user id.\n\nService taxonomy\n................\n\nAs of pylogsparser 0.4 a taxonomy tag is added to relevant normalizers. It helps\nclassifying logs by service type, which can be useful for reporting among other\nthings. Here is a list of identified services; suggestions and improvements are\nwelcome !\n\n+-----------+----------------------------------------+------------------------+\n| Service   | Description                            | Normalizers            |\n+===========+========================================+========================+\n| access    | A service dealing with authentication  | Fail2ban               |\n| control   | and/or authorization                   | pam                    |\n|           |                                        | sshd                   |\n|           |                                        | wabauth                |\n+-----------+----------------------------------------+------------------------+\n| antivirus | A service dealing with malware         | bitdefender            |\n|           | detection and prevention               | symantec               |\n+-----------+----------------------------------------+------------------------+\n| database  | A database service such as mySQLd,     | mysql                  |\n|           | postmaster (postGRESQL), ...           |                        |\n+-----------+----------------------------------------+------------------------+\n| address   | A service in charge of network address | dhcpd                  |\n|assignation| assignations                           |                        |\n+-----------+----------------------------------------+------------------------+\n| name      | A service in charge of network names   | named                  |\n| resolution| resolutions                            | named-2                |\n+-----------+----------------------------------------+------------------------+\n| firewall  | A service in charge of monitoring      | LEA                    |\n|           | and filtering network traffic          | arkoonFAST360          |\n|           |                                        | deny_event             |\n|           |                                        | netfilter              |\n+-----------+----------------------------------------+------------------------+\n| file      | A file transfer service                | xferlog                |\n| transfer  |                                        |                        |\n+-----------+----------------------------------------+------------------------+\n| hypervisor| A virtualization platform service      | VMWare_ESX4-ESXi4      |\n|           |                                        |                        |\n+-----------+----------------------------------------+------------------------+\n| mail      | A mail server                          | MSExchange2007-        |\n|           |                                        | MessageTracking        |\n|           |                                        | postfix                |\n+-----------+----------------------------------------+------------------------+\n| web proxy | A service acting as an intermediary    | dansguardian           |\n|           | between clients and web resources;     | deny_traffic           |\n|           | access control and content filtering   | squid                  |\n|           | can also occur                         |                        |\n+-----------+----------------------------------------+------------------------+\n| web server| A service exposing web resources       | IIS                    |\n|           |                                        | apache                 |\n+-----------+----------------------------------------+------------------------+", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://www.wallix.org/pylogsparser-project/", "keywords": "log parser xml library python", "license": "LGPL", "maintainer": null, "maintainer_email": null, "name": "pylogsparser", "package_url": "https://pypi.org/project/pylogsparser/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/pylogsparser/", "project_urls": {"Download": "UNKNOWN", "Homepage": "http://www.wallix.org/pylogsparser-project/"}, "release_url": "https://pypi.org/project/pylogsparser/0.8/", "requires_dist": null, "requires_python": null, "summary": "A log parser library packaged with a set of ready to use parsers (DHCPd, Squid, Apache, ...)", "version": "0.8", "yanked": false, "html_description": "<div class=\"project-description\">\n            LogsParser<br>==========<br><br>Description<br>:::::::::::<br><br>LogsParser is an opensource python library created by Wallix ( http://www.wallix.org ).<br>It is used as the core mechanism for logs tagging and normalization by Wallix's LogBox<br>( http://www.wallix.com/index.php/products/wallix-logbox ).<br><br>Logs come in a variety of formats. In order to parse many different types of<br>logs, a developer used to need to write an engine based on a large list of complex<br>regular expressions. It can become rapidly unreadable and unmaintainable.<br><br>By using LogsParser, a developer can free herself from the burden of writing a<br>log parsing engine, since the module comes in with \"batteries included\".<br>Furthermore, this engine relies upon XML definition files that can be loaded at<br>runtime. The definition files were designed to be easily readable and need very<br>little skill in programming or regular expressions, without sacrificing<br>powerfulness or expressiveness.<br><br>Purpose<br>:::::::<br><br>The LogsParser module uses normalization definition files in order to tag<br>log entries. The definition files are written in XML.<br><br>The definition files allow anyone with a basic understanding of regular<br>expressions and knowledge of a specific log format to create and maintain<br>a customized pool of parsers.<br><br>Basically a definition file will consist of a list of log patterns, each<br>composed of many keywords. A keyword is a placeholder for a notable and/or <br>variable part in the described log line, and therefore associated to a tag<br>name. It is paired to a tag type, e.g. a regular expression matching the<br>expected value to assign to this tag. If the raw value extracted this way needs<br>further processing, callback functions can be applied to this value.<br><br>This format also allows to add useful meta-data about parsed logs, such as<br>extensive documentation about expected log patterns and log samples.<br><br>Format Description<br>------------------<br><br>A normalization definition file must strictly follow the specifications as<br>they are detailed in the file normalizer.dtd .<br><br>A simple template is provided to help parser writers get started with their<br>task, called normalizer.template.<br><br>Most definition files will include the following sections :<br><br>* Some generic documentation about the parsed logs : emitting application,<br>  application version, etc ... (non-mandatory)<br>* the definition file's author(s) (non-mandatory)<br>* custom tag types (non-mandatory)<br>* callback functions (non-mandatory)<br>* Prerequisites on tag values prior to parsing (non-mandatory)<br>* Log pattern(s) and how they are to be parsed<br>* Extra tags with a fixed value that should be added once the parsing is done<br>  (non-mandatory)<br><br>Root<br>....<br><br>The definition file's root must hold the following elements :<br><br>* the normalizer's name.<br>* the normalizer's version.<br>* the flags to apply to the compilation of regular expressions associated with<br>  this parser : unicode support, multiple lines support, and ignore case.<br>* how to match the regular expression : from the beginning of the log line (match)<br>  or from anywhere in the targeted tag (search)<br>* the tag value to parse (raw, body...)<br>* the service taxonomy, if relevant, of the normalizer. See the end of this<br>  document for more details.<br>* the optional expandWhitespaces value. If set to \"yes\", spaces or carriage returns<br>   in a pattern will be converted to match any whitespace character (line feed, tab, etc). <br>   This is to maintain the readability of multiline patterns.<br><br>Default tag types<br>.................<br><br>A few basic tag types are defined in the file common_tagTypes.xml . In order<br>to use it, it has to be loaded when instantiating the Normalizer class; see the<br>class documentation for further information.<br><br>Here is a list of default tag types shipped with this library.<br><br>* Anything : any character chain of any length.<br>* Integer<br>* EpochTime : an EPOCH timestamp of arbitrary precision (to the second and below).<br>* syslogDate : a date as seen in syslog formatted logs (example : Mar 12 20:13:23)<br>* URL<br>* MACAddress<br>* Email<br>* IP<br>* ZuluTime : a \"Zulu Time\"-type timestamp (example : 2012-12-21T13:45:05)<br><br><br>Custom Tag Types<br>................<br><br>It is always possible to define new tag types in a parser definition file, and<br>to overwrite default ones. To define a new tag type, the following elements are<br>needed :<br><br>* a type name. This will be used as the type reference in log patterns.<br>* the python type of the expected result : this element is not used yet and can<br>  be safely set to anything.<br>* a non-mandatory description.<br>* the regular expression defining this type.<br><br>Callback Functions<br>..................<br><br>One might want to transform a raw value after it has been extracted from a pattern:<br>the syslog normalizer converts the raw log timestamp into a python datetime object,<br>for example.<br><br>In order to do this, the &lt;callback&gt; tag must be used to define a callback function.<br><br>&lt;callback&gt; requires a function name as a mandatory attribute. Its text defines the<br>function body as in python, meaning the PEP8 indentation rules are to be followed. <br><br>When writing a callback function, the following rules must be respected :<br><br>* Your callback function will take ONLY two arguments: **value** and **log**.<br>  \"value\" is the raw value extracted from applying the log pattern to the log,<br>  and \"log\" is the dictionary of the normalized log in its current state (prior<br>  to normalization induced by this parser definition file).<br>* Your callback function can modify the \"log\" argument (especially assign<br>  the transformed value to the concerned tag name) and must not return anything.<br>* Your callback function has a restricted access to the following facilities: ::<br><br>   \"list\", \"dict\", \"tuple\", \"set\", \"long\", \"float\", \"object\",<br>   \"bool\", \"callable\", \"True\", \"False\", \"dir\",<br>   \"frozenset\", \"getattr\", \"hasattr\", \"abs\", \"cmp\", \"complex\",<br>   \"divmod\", \"id\", \"pow\", \"round\", \"slice\", \"vars\",<br>   \"hash\", \"hex\", \"int\", \"isinstance\", \"issubclass\", \"len\",<br>   \"map\", \"filter\", \"max\", \"min\", \"oct\", \"chr\", \"ord\", \"range\",<br>   \"reduce\", \"repr\", \"str\", \"unicode\", \"basestring\", \"type\", \"zip\", \"xrange\", \"None\",<br>   \"Exception\"  <br><br>* Importing modules is therefore forbidden and impossible. The *re* and *datetime*<br>  modules are available for use as if the following lines were present: ::<br><br>   import re<br>   from datetime import datetime<br>   <br>* In version 0.4, the \"extras\" package is introduced. It allows more freedom in <br>  what can be used in callbacks. It also increases execution speed in some <br>  cases; typically when you need to use complex objects in your callback like <br>  a big set or a big regular expression. In the old approach, this object <br>  would be created each time the function is called; by deporting the object's<br>  creation in the extras package it is created once and for all. See the modules<br>  in logsparser.extras for use cases.<br><br>Default callbacks<br>.................<br><br>As with default tag types, a few generic callbacks are defined in the file <br>common_callBacks.xml . Currently they are meant to deal with common date <br>formattings. Therefore they will automatically set the \"date\" tag. In order to <br>use it, the callbacks file has to be loaded when instantiating the Normalizer <br>class; see the class documentation for further information.<br><br>In case of name collisions, callbacks defined in a normalizer description file <br>take precedence over common callbacks.<br><br>Here is a list of default callbacks shipped with this library. <br><br>* MM/dd/YYYY hh:mm:ss : parses dates such as 04/13/2010 14:23:56<br>* dd/MMM/YYYY:hh:mm:ss : parses dates such as 19/Jul/2009 12:02:43<br>* MMM dd hh:mm:ss : parses dates such as Oct 23 10:23:12 . The year is guessed <br>  so that the resulting date is the closest in the past.<br>* DDD MMM dd hh:mm:ss YYYY : parses dates such as Mon Sep 11 09:13:54 2011<br>* YYYY-MM-DD hh:mm:ss : parses dates such as 2012-12-21 00:00:00<br>* MM/DD/YY, hh:mm:ss : parses dates such as 10/23/11, 07:24:04 . The year is <br>  assumed to be in the XXIst century.<br>* YYMMDD hh:mm:ss:  parses dates such as 070811 17:23:12 . The year is assumed <br>  to be in the XXIst century.<br>* ISO8601 : converts a combined date and time in UTC expressed according to the <br>  ISO 8601 standard. Also commonly referred to as \"Zulu Time\".<br>* EPOCH : parses EPOCH timestamps<br>* dd-MMM-YYYY hh:mm:ss : parses dates such as 28-Feb-2010 23:15:54<br><br>Final callbacks<br>...............<br><br>One might want to wait until a pattern has been fully applied before processing<br>data : if for example you'd like to tag a log with a value made of a concatenation of<br>other values, and so on. It is possible to specify a list of callbacks to apply<br>at the end of the parsing with the XML tag \"finalCallbacks\".<br><br>Such callbacks will follow the mechanics described above, with one notable change:<br>they will be called with the argument \"value\" set to None. Therefore, you have<br>to make sure your callback will work correctly that way.<br><br>There are a few examples of use available : in the test_normalizer.py test code,<br>and in the deny_all normalizer.<br><br>Pattern definition<br>..................<br><br>A definition file can contain as many log patterns as one sees fit. These patterns<br>are simplified regular expressions and applied in alphabetical order of their names,<br>so it is important to name them so that the more precise patterns are tried<br>before the more generic ones.<br><br>A pattern is a \"meta regular expression\", which means that every syntactic rule from<br>python's regular expressions are to be followed when writing a pattern, especially<br>escaping special characters. To make the patterns easier to read than an obtuse<br>regular expression, keywords act as \"macros\" and correspond to a part of the log<br>to assign to a tag.<br><br>A log pattern has the following components:<br><br>* A name.<br>* A non-mandatory description of the pattern's context.<br>* The pattern itself, under the tag \"text\".<br>* The tags as they appear in the pattern, the associated name once the normalization<br>  is over, and the callback functions to eventually call on their raw values<br>* Non-mandatory log samples. These can be used for self-validation.<br><br>If a tag name starts with __ (double underscore), this tag won't be added to the<br>final normalized dictionary. This allows to create temporary tags that will<br>typically be used in conjunction to a series of callback functions, when the<br>original raw value has no actual interest.<br><br>To define log patterns describing a CSV-formatted message, one must add the<br>following attributes in the tag \"text\":<br><br>* type=\"csv\"<br>* separator=\",\" or the relevant separator character<br>* quotechar='\"' or the relevant quotation character<br><br>Tags are then defined normally. Pylogsparser will deal automatically with missing<br>fields.<br><br><br>Best practices<br>..............<br><br>* Order your patterns in decreasing order of specificity. Not doing so might<br>  trigger errors, as more generic patterns will match earlier.<br>* The more precise your tagTypes' regular expressions, the more accurate your<br>  parser will be.<br>* Use description tags liberally. The more documented a log format, the better.<br>  Examples are also invaluable.<br><br>Tag naming convention<br>.....................<br><br>The tag naming convention is lowercase, underscore separated words. It is strongly<br>recommended to stick to that naming convention when writing new normalizers<br>for consistency's sake. In case of dynamic fields, it is advised to make sure<br>dynamic naming follows the convention. There's an example of this in <br>MSExchange2007MessageTracking.xml; see the callback named \"decode_MTLSourceContext\".<br><br>Log contains common informations such as username, IP address, informations about<br>transport protocol... In order to ease log post-processing we must define a common<br>method to name those tags and not deal for example with a series of \"login, user,<br>username, userid\" all describing a user id.<br>The alphabetical list below is a series of tag names that must be used when relevant.<br><br>- action : action taken by a component such as DELETED, migrated, DROP, open.<br>- bind_int : binding interface for a network service.<br>- dest_host : hostname or FQDN of a destination host.<br>- dest_ip : IP address of a destination host.<br>- dest_mac : MAC address of a destination host.<br>- dest_port : destination port of a network connection.<br>- event_id : id describing an event.<br>- inbound_int : network interface for incoming data.<br>- len : a data size.<br>- local_host : hostname or FQDN of the local host.<br>- local_ip : IP adress of the local host.<br>- local_mac : MAC address of the local host.<br>- local_port : listening port of a local service.<br>- message_id : message or transaction id.<br>- message_recipient : message recipient id.<br>- message_sender : message sender id.<br>- method : component access method such as GET, key_auth.<br>- outbound_int : network interface for outgoing data.<br>- protocol : network or software protocol name or numeric id such as TCP, NTP, SMTP.<br>- source_host : hostname or FQDN of a source host.<br>- source_ip : IP address of a source host.<br>- source_mac : MAC address of a source host.<br>- source_port : source port of a network connection.<br>- status : component status such as FAIL, success, 404.<br>  see below for a complete list.<br>- url : an URL as defined in rfc1738. (scheme://netloc/path;parameters?query#fragment)<br>- user : a user id.<br><br>Service taxonomy<br>................<br><br>As of pylogsparser 0.4 a taxonomy tag is added to relevant normalizers. It helps<br>classifying logs by service type, which can be useful for reporting among other<br>things. Here is a list of identified services; suggestions and improvements are<br>welcome !<br><br>+-----------+----------------------------------------+------------------------+<br>| Service   | Description                            | Normalizers            |<br>+===========+========================================+========================+<br>| access    | A service dealing with authentication  | Fail2ban               |<br>| control   | and/or authorization                   | pam                    |<br>|           |                                        | sshd                   |<br>|           |                                        | wabauth                |<br>+-----------+----------------------------------------+------------------------+<br>| antivirus | A service dealing with malware         | bitdefender            |<br>|           | detection and prevention               | symantec               |<br>+-----------+----------------------------------------+------------------------+<br>| database  | A database service such as mySQLd,     | mysql                  |<br>|           | postmaster (postGRESQL), ...           |                        |<br>+-----------+----------------------------------------+------------------------+<br>| address   | A service in charge of network address | dhcpd                  |<br>|assignation| assignations                           |                        |<br>+-----------+----------------------------------------+------------------------+<br>| name      | A service in charge of network names   | named                  |<br>| resolution| resolutions                            | named-2                |<br>+-----------+----------------------------------------+------------------------+<br>| firewall  | A service in charge of monitoring      | LEA                    |<br>|           | and filtering network traffic          | arkoonFAST360          |<br>|           |                                        | deny_event             |<br>|           |                                        | netfilter              |<br>+-----------+----------------------------------------+------------------------+<br>| file      | A file transfer service                | xferlog                |<br>| transfer  |                                        |                        |<br>+-----------+----------------------------------------+------------------------+<br>| hypervisor| A virtualization platform service      | VMWare_ESX4-ESXi4      |<br>|           |                                        |                        |<br>+-----------+----------------------------------------+------------------------+<br>| mail      | A mail server                          | MSExchange2007-        |<br>|           |                                        | MessageTracking        |<br>|           |                                        | postfix                |<br>+-----------+----------------------------------------+------------------------+<br>| web proxy | A service acting as an intermediary    | dansguardian           |<br>|           | between clients and web resources;     | deny_traffic           |<br>|           | access control and content filtering   | squid                  |<br>|           | can also occur                         |                        |<br>+-----------+----------------------------------------+------------------------+<br>| web server| A service exposing web resources       | IIS                    |<br>|           |                                        | apache                 |<br>+-----------+----------------------------------------+------------------------+\n          </div>"}, "last_serial": 797377, "releases": {"0.1": [], "0.2": [], "0.4": [{"comment_text": "", "digests": {"md5": "ae0868c4190205085aea878e7f088e96", "sha256": "b29a0673a61dfc819eeee264b104ce5b82f3065b7bfd4424e9ffc88f4c864ae6"}, "downloads": -1, "filename": "pylogsparser-0.4.tar.gz", "has_sig": false, "md5_digest": "ae0868c4190205085aea878e7f088e96", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 135104, "upload_time": "2012-03-01T10:55:07", "upload_time_iso_8601": "2012-03-01T10:55:07.676161Z", "url": "https://files.pythonhosted.org/packages/db/bc/cd7a626deba816d1ef5020c203a49b4a8cc2eefc3d8b166bbb445a12ac60/pylogsparser-0.4.tar.gz", "yanked": false}], "0.6": [{"comment_text": "", "digests": {"md5": "ad9980098f3cbab10537ab088111bb99", "sha256": "df2053b92cd088c3cb33ff2d6023fd71d78abc316cb25fd20ba33488f4af7f1e"}, "downloads": -1, "filename": "pylogsparser-0.6.tar.gz", "has_sig": false, "md5_digest": "ad9980098f3cbab10537ab088111bb99", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 146408, "upload_time": "2012-10-26T10:13:30", "upload_time_iso_8601": "2012-10-26T10:13:30.779266Z", "url": "https://files.pythonhosted.org/packages/cd/ab/460003af0302fcab8162ff3f9143512c39c5a3839a2901edeee9c9859ccb/pylogsparser-0.6.tar.gz", "yanked": false}], "0.8": [{"comment_text": "", "digests": {"md5": "b4e44b99a4e87c1baa1a52122f1b4a5b", "sha256": "cd7be5fcc704214511b22b088ab11b8a5589b6843c19362856195374d31517cd"}, "downloads": -1, "filename": "pylogsparser-0.8.tar.gz", "has_sig": false, "md5_digest": "b4e44b99a4e87c1baa1a52122f1b4a5b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 173974, "upload_time": "2012-11-28T18:13:04", "upload_time_iso_8601": "2012-11-28T18:13:04.156801Z", "url": "https://files.pythonhosted.org/packages/83/09/90872203a17ed769d80d9f5e6487d8a320a962ebca2851940a2d148f04c8/pylogsparser-0.8.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "b4e44b99a4e87c1baa1a52122f1b4a5b", "sha256": "cd7be5fcc704214511b22b088ab11b8a5589b6843c19362856195374d31517cd"}, "downloads": -1, "filename": "pylogsparser-0.8.tar.gz", "has_sig": false, "md5_digest": "b4e44b99a4e87c1baa1a52122f1b4a5b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 173974, "upload_time": "2012-11-28T18:13:04", "upload_time_iso_8601": "2012-11-28T18:13:04.156801Z", "url": "https://files.pythonhosted.org/packages/83/09/90872203a17ed769d80d9f5e6487d8a320a962ebca2851940a2d148f04c8/pylogsparser-0.8.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:02:50 2020"}