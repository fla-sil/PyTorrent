{"info": {"author": "thruflo", "author_email": "thruflo@googlemail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Environment :: Web Environment", "Intended Audience :: Developers", "License :: Public Domain", "Programming Language :: Python"], "description": "Overview\n--------\n\n\nThis is a mashup that uses three APIs:\n\n- `Delicious feeds <http://delicious.com/help/feeds>`_\n\n- `Backtweets API <http://backtweets.com/api>`_\n\n- (optionally) `Twitter API <http://apiwiki.twitter.com/REST+API+Documentation>`_\n\n\nIt works as follows:\n\n#. fetch a list of urls tagged on delicious (which whatever tag(s) you specify)\n\n#. query backtweets to find users who've posted links to those urls\n\n#. return a list of those users' twitter usernames\n\n\nIf you want, you can:\n\n#. either just find the usernames; or\n\n#. automatically start following the users you find on twitter\n\n\nIf you really like the idea, you can automate the script to check for new users\nto follow every few hours (the delay is configurable).\n\nThe idea is that you can find people who are interested in sites you're interested\nin. If you find that by automatically following them they happen to follow you\nback, well, who knows, maybe this little package will make you famous ;)\n\nHow useful it is will depend on the sites you tag.  Having ``http://www.yahoo.com``\nin there is not likely to be much of a useful filter.  Wheras having something\nspecialist like, say, http://tav.espians.com, probably will be.\n\n\n\nPrerequisites\n-------------\n\n\n- you'll need a unix based computer atm; this is due to the ``python-crontab``\n  dependency which we're using to schedule tasks.  There are many others ways of\n  scheduling tasks, if you'd like to improve the package and make it windows\n  compatible, please `go ahead <http://github.com/thruflo/tasty-tweets>`_ ;)\n\n- you need `Python <http://www.python.org>`_\n\n- you'll need a `Delicious <http://www.delicious.com>`_ account\n\n- you'll need a `Backtweets <http://www.backtweet.com/api>`_ API key\n\n- if you want to automatically follow the users you'll need a\n  `Twitter <http://www.twitter.com>`_ account\n\n\n\nUsage\n-----\n\n\nInstall it::\n\n    $ easy_install tastytweets\n\nThis installs a number of console scripts (it'll put them where your python puts\nscripts). To find all twitter users who've posted on the URLs you're\ninterested in::\n\n    $ ./path/to/bin/tastytweets-find [... options ...]\n\n``tastytweets-find`` is the simplest way of using this package, especially if\nyou don't like the way the automation that follows has been implemented.\n\nFind and automatically follow those users (in real life on your twitter account, for real,\ndon't do this unless you actually mean to!!)::\n\n    $ ./path/to/bin/tastytweets-follow [... options ...]\n\nAutomate the script (to run forever) to check for new users to follow every\n6 hours::\n\n    $ ./path/to/bin/tastytweets-automate [... options ...] --follow-delay 6\n\nThe command line options required vary according to what you're trying to do.\nTo see all the options, run one of the scripts with the ``-h`` option::\n\n    $ ./path/to/bin/tastytweets-find -h\n\nThe default tag the script looks for in your delicious account is 'follow' but\nyou can pass any tags using the ``-t`` option, e.g.: ``-t foo bar dolores``\nwill only pick up urls tagged with ``foo`` and ``bar`` and ``dolores`` (n.b.: it's\ncumulative, like ``'foo' AND 'bar' AND 'dolores'``).\n\nFor example, a fully optioned-up call might be [line wraps are marked ``\\``]::\n\n    $ ./path/to/bin/tastytweets-automate -u TWITTER_USERNAME -p TWITTER_PASSWORD \\\n    -k BACKTWEETS_KEY -d DELICIOUS_USER -t follow socialgraphing \\\n    --follow-delay 6 --push-delay 5\n\nThere are two implementation details you should be aware of.  Firstly, Twitter\nhas a limit of 100 requests per hour, so the script also uses a directory queue\nto store requests to make on the filesystem and adds a cronjob (for the duration\nof the queue being full) to process one request every ``--push-delay`` minutes.  \nThis defaults to every 5 minutes.\n\nSecondly, the package is designed primarily to be automated, so it maintains an\ninternal record of the last time it checked for posts.  If you want to use the\n``./tastytweets-find`` or ``./tastytweets-follow`` scripts manually, you may want\nto reset the internal record so that you get all of the posts.\n\nTo reset the last time checked::\n\n    $ ./path/to/bin/tastytweets-reset-status-id\n\nTo reset the last time-checked, reset the queue, destroying any pending requests\nand delete any crontab jobs scheduled::\n\n    $ ./path/to/bin/tastytweets-reset-everything\n\nTo manually push queued follow requests use::\n\n    $ ./path/to/bin/tastytweets-push\n\nYou shouldn't need to though, as ``tastytweets-follow`` takes care of pushing\nautomatically.\n\nFinally, you can also, of course, use the package directly from python.  See\n``tastytweets.client.TastyTweeter.__doc__`` for details.", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://github.com/thruflo/tasty-tweets", "keywords": null, "license": "Public Domain", "maintainer": null, "maintainer_email": null, "name": "tastytweets", "package_url": "https://pypi.org/project/tastytweets/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/tastytweets/", "project_urls": {"Download": "UNKNOWN", "Homepage": "http://github.com/thruflo/tasty-tweets"}, "release_url": "https://pypi.org/project/tastytweets/0.2.2/", "requires_dist": null, "requires_python": null, "summary": "delicious twitter mashup; finds twitter users posting links to urls you've tagged so you can start following them", "version": "0.2.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"overview\">\n<h2>Overview</h2>\n<p>This is a mashup that uses three APIs:</p>\n<ul>\n<li><a href=\"http://delicious.com/help/feeds\" rel=\"nofollow\">Delicious feeds</a></li>\n<li><a href=\"http://backtweets.com/api\" rel=\"nofollow\">Backtweets API</a></li>\n<li>(optionally) <a href=\"http://apiwiki.twitter.com/REST+API+Documentation\" rel=\"nofollow\">Twitter API</a></li>\n</ul>\n<p>It works as follows:</p>\n<ol>\n<li>fetch a list of urls tagged on delicious (which whatever tag(s) you specify)</li>\n<li>query backtweets to find users who\u2019ve posted links to those urls</li>\n<li>return a list of those users\u2019 twitter usernames</li>\n</ol>\n<p>If you want, you can:</p>\n<ol>\n<li>either just find the usernames; or</li>\n<li>automatically start following the users you find on twitter</li>\n</ol>\n<p>If you really like the idea, you can automate the script to check for new users\nto follow every few hours (the delay is configurable).</p>\n<p>The idea is that you can find people who are interested in sites you\u2019re interested\nin. If you find that by automatically following them they happen to follow you\nback, well, who knows, maybe this little package will make you famous ;)</p>\n<p>How useful it is will depend on the sites you tag.  Having <tt><span class=\"pre\">http://www.yahoo.com</span></tt>\nin there is not likely to be much of a useful filter.  Wheras having something\nspecialist like, say, <a href=\"http://tav.espians.com\" rel=\"nofollow\">http://tav.espians.com</a>, probably will be.</p>\n</div>\n<div id=\"prerequisites\">\n<h2>Prerequisites</h2>\n<ul>\n<li>you\u2019ll need a unix based computer atm; this is due to the <tt><span class=\"pre\">python-crontab</span></tt>\ndependency which we\u2019re using to schedule tasks.  There are many others ways of\nscheduling tasks, if you\u2019d like to improve the package and make it windows\ncompatible, please <a href=\"http://github.com/thruflo/tasty-tweets\" rel=\"nofollow\">go ahead</a> ;)</li>\n<li>you need <a href=\"http://www.python.org\" rel=\"nofollow\">Python</a></li>\n<li>you\u2019ll need a <a href=\"http://www.delicious.com\" rel=\"nofollow\">Delicious</a> account</li>\n<li>you\u2019ll need a <a href=\"http://www.backtweet.com/api\" rel=\"nofollow\">Backtweets</a> API key</li>\n<li>if you want to automatically follow the users you\u2019ll need a\n<a href=\"http://www.twitter.com\" rel=\"nofollow\">Twitter</a> account</li>\n</ul>\n</div>\n<div id=\"usage\">\n<h2>Usage</h2>\n<p>Install it:</p>\n<pre>$ easy_install tastytweets\n</pre>\n<p>This installs a number of console scripts (it\u2019ll put them where your python puts\nscripts). To find all twitter users who\u2019ve posted on the URLs you\u2019re\ninterested in:</p>\n<pre>$ ./path/to/bin/tastytweets-find [... options ...]\n</pre>\n<p><tt><span class=\"pre\">tastytweets-find</span></tt> is the simplest way of using this package, especially if\nyou don\u2019t like the way the automation that follows has been implemented.</p>\n<p>Find and automatically follow those users (in real life on your twitter account, for real,\ndon\u2019t do this unless you actually mean to!!):</p>\n<pre>$ ./path/to/bin/tastytweets-follow [... options ...]\n</pre>\n<p>Automate the script (to run forever) to check for new users to follow every\n6 hours:</p>\n<pre>$ ./path/to/bin/tastytweets-automate [... options ...] --follow-delay 6\n</pre>\n<p>The command line options required vary according to what you\u2019re trying to do.\nTo see all the options, run one of the scripts with the <tt><span class=\"pre\">-h</span></tt> option:</p>\n<pre>$ ./path/to/bin/tastytweets-find -h\n</pre>\n<p>The default tag the script looks for in your delicious account is \u2018follow\u2019 but\nyou can pass any tags using the <tt><span class=\"pre\">-t</span></tt> option, e.g.: <tt><span class=\"pre\">-t</span> foo bar dolores</tt>\nwill only pick up urls tagged with <tt>foo</tt> and <tt>bar</tt> and <tt>dolores</tt> (n.b.: it\u2019s\ncumulative, like <tt>'foo' AND 'bar' AND 'dolores'</tt>).</p>\n<p>For example, a fully optioned-up call might be [line wraps are marked <tt>\\</tt>]:</p>\n<pre>$ ./path/to/bin/tastytweets-automate -u TWITTER_USERNAME -p TWITTER_PASSWORD \\\n-k BACKTWEETS_KEY -d DELICIOUS_USER -t follow socialgraphing \\\n--follow-delay 6 --push-delay 5\n</pre>\n<p>There are two implementation details you should be aware of.  Firstly, Twitter\nhas a limit of 100 requests per hour, so the script also uses a directory queue\nto store requests to make on the filesystem and adds a cronjob (for the duration\nof the queue being full) to process one request every <tt><span class=\"pre\">--push-delay</span></tt> minutes.\nThis defaults to every 5 minutes.</p>\n<p>Secondly, the package is designed primarily to be automated, so it maintains an\ninternal record of the last time it checked for posts.  If you want to use the\n<tt><span class=\"pre\">./tastytweets-find</span></tt> or <tt><span class=\"pre\">./tastytweets-follow</span></tt> scripts manually, you may want\nto reset the internal record so that you get all of the posts.</p>\n<p>To reset the last time checked:</p>\n<pre>$ ./path/to/bin/tastytweets-reset-status-id\n</pre>\n<p>To reset the last time-checked, reset the queue, destroying any pending requests\nand delete any crontab jobs scheduled:</p>\n<pre>$ ./path/to/bin/tastytweets-reset-everything\n</pre>\n<p>To manually push queued follow requests use:</p>\n<pre>$ ./path/to/bin/tastytweets-push\n</pre>\n<p>You shouldn\u2019t need to though, as <tt><span class=\"pre\">tastytweets-follow</span></tt> takes care of pushing\nautomatically.</p>\n<p>Finally, you can also, of course, use the package directly from python.  See\n<tt>tastytweets.client.TastyTweeter.__doc__</tt> for details.</p>\n</div>\n\n          </div>"}, "last_serial": 800381, "releases": {"0.2": [{"comment_text": "", "digests": {"md5": "07e0025fa3f6567006385cf62f4fb983", "sha256": "f9a43c2dfe9d75dd5a6e7e6b62a5644a198f35d96fd72f06dbd90dbe8aee7423"}, "downloads": -1, "filename": "tastytweets-0.2.tar.gz", "has_sig": false, "md5_digest": "07e0025fa3f6567006385cf62f4fb983", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10858, "upload_time": "2009-03-17T12:02:07", "upload_time_iso_8601": "2009-03-17T12:02:07.081714Z", "url": "https://files.pythonhosted.org/packages/bc/95/607ced8c393923f97afd15e92b4994536144ba896dd3e6d2489207c156f8/tastytweets-0.2.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "24a8ad0e1ac7ebc091b1e1a93121bf38", "sha256": "3ed13a227d85336f1dcc86fbd0df58bbc954346ef55741ed3f4bfb44f08088af"}, "downloads": -1, "filename": "tastytweets-0.2.1.tar.gz", "has_sig": false, "md5_digest": "24a8ad0e1ac7ebc091b1e1a93121bf38", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11506, "upload_time": "2009-03-17T12:21:15", "upload_time_iso_8601": "2009-03-17T12:21:15.582259Z", "url": "https://files.pythonhosted.org/packages/06/a7/541a12b8093e25eddaeeaa704c2de95e6e71481b3e001131854eeeb662fb/tastytweets-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "11b614da48ec02198a698eb9a9debb8e", "sha256": "bd5e271408f4f18e3b8d52734bf8173c2ffccd1fc891b6fc6af32a3ec9d29390"}, "downloads": -1, "filename": "tastytweets-0.2.2.tar.gz", "has_sig": false, "md5_digest": "11b614da48ec02198a698eb9a9debb8e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11498, "upload_time": "2009-03-17T13:08:27", "upload_time_iso_8601": "2009-03-17T13:08:27.380672Z", "url": "https://files.pythonhosted.org/packages/4c/9a/a5eea3adb403a9b457c773058de0eda47aea90cc6fa44f4b335a33f49c63/tastytweets-0.2.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "11b614da48ec02198a698eb9a9debb8e", "sha256": "bd5e271408f4f18e3b8d52734bf8173c2ffccd1fc891b6fc6af32a3ec9d29390"}, "downloads": -1, "filename": "tastytweets-0.2.2.tar.gz", "has_sig": false, "md5_digest": "11b614da48ec02198a698eb9a9debb8e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11498, "upload_time": "2009-03-17T13:08:27", "upload_time_iso_8601": "2009-03-17T13:08:27.380672Z", "url": "https://files.pythonhosted.org/packages/4c/9a/a5eea3adb403a9b457c773058de0eda47aea90cc6fa44f4b335a33f49c63/tastytweets-0.2.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:57:40 2020"}