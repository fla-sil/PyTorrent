{"info": {"author": "Nitesh Kumar", "author_email": "nit567esh@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.2", "Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "dsconnect - Power your data connections with python\n===================================================\n\n| 1.Overview_\n| 2.Installation_\n| 3.Usages-Guidelines_\n| 4.Examples_\n| 5.Support_\n| 6.Upcoming-Integrations_\n| 7.References_ \n\n1.Overview\n==========\n**dsconnect** is prepared for connecting multiple data source by using a single configuration file where a user can maintain a huge list of reusable connection list and can use it by calling single **conid** parameter.\nIts main features are the variety of popular data source connection capabilities. It is a single wrapper of all most popular data connection python libraries into a single library.\n\ndsconnect is purley implemented in Python.\n\n2.Installation\n==============\n| **To install the library, use below command**\n|    $ pip install dsconnect\n\n.. note::\n\n    During the installation of package please verify that all the required dependencies installed successfully, if not try to install them one by one.\n\n3.Usages-Guidelines\n===================\n| This python library need a configured input file which will include list of all datasource details.File should be in below format:-\n\n +---------+-------------+------------+--------+------------+------------+------------------+-------------+-----------------+\n |**conid**|**host**     |**dbname**  |**port**|**username**|**password**|**datasourcetype**|**conString**|**PythonLibrary**|\n +---------+-------------+------------+--------+------------+------------+------------------+-------------+-----------------+\n |1        |127.0.0.1    |employee    |5433    |livexyz     |live@123    |Redshift          |NA           |psycopg2         |\n +---------+-------------+------------+--------+------------+------------+------------------+-------------+-----------------+\n\n| Once file is prepared with all available datasource connection details, follow the below steps to get data/connect to respective datasource\n\n| **Step 1:** Load  connection details *.csv* file into pandas dataframe             \n|             >> import dsconnect as p\n|             >> <pandas dataframe name> = pandas.read_csv(<filepath>)\n|             >> con = p.config_df(df = <pandas dataframe name>)\n\n| **Step 2:** Pass query with respective conid and get result into pandas\n|             >> df = con.mysql(conid=1,sql=\"select top 10 * from employeesalary\")\n|             >> df = con.redshift(conid=2,sql=\"select top 10 * from students\")\n\n.. note::\n\n    01. Use the same header name which is provided in sample file format for more help a user can use **p.config_df_sample()** command to see structure of sample configuration file format.\n\n    02. Before using conid, verify the datatype of your conid column and pass the same in query for eg. if 1 is string then pass '1', if 1 is int then pass 1.\n\n4.Examples\n==========\nMySQL\n~~~~~~~\n| *Package Used:* mysql-connector-python\n| Eg. df = con.mysql(conid=<uniqueid>,sql=\"select top 10 * from <table>\")\n\nMS SQL Server\n~~~~~~~~~~~~~\n| *Package Used:* pyodbc\n| Eg. df = con.mssql(conid=<uniqueid>,sql=\"select top 10 * from <table>\")\n\nMS Azure SQL Database\n~~~~~~~~~~~~~~~~~~~~~\n| *Package Used:* pyodbc\n| Eg. df = con.msazuresql(conid=<uniqueid>,sql=\"select top 10 * from <table>\")\n\nOracle\n~~~~~~\n| *Package Used:* cx_Oracle\n| Eg. df = con.oracle(conid=<uniqueid>,sql=\"select top 10 * from <table>\")\n\nDB2\n~~~~~~~\n| *Package Used:* ibm_db\n| Eg. df = con.ibmdb(conid=<uniqueid>,sql=\"select top 10 * from <table>\")\n\nPostgreSQL\n~~~~~~~~~~\n| *Package Used:* psycopg2\n| Eg. df = con.postgresql(conid=<uniqueid>,sql=\"select top 10 * from <table>\")\n\nRedshift\n~~~~~~~~\n| *Package Used:* psycopg2\n| Eg. df = con.mysql(conid=<uniqueid>,sql=\"select top 10 * from <table>\")\n\nGsheet\n~~~~~~\n| *Package Used:* pygsheets\n| Eg. con = con.gsheet(conid=<uniqueid>) then proceed with pygsheets documentation with *con* as connection object.\n| **conString** column should be use to store client_secret.json path(Obtained from Google Gsheet API OAuth).\n\n +-----+----+------+----+--------+--------+--------------+---------+------------------+-------------+\n |conid|host|dbname|port|username|password|datasourcetype|conString                   |PythonLibrary|\n +-----+----+------+----+--------+--------+--------------+---------+------------------+-------------+\n |1    |NA  |NA    |NA  |NA      |NA      |Gsheet        |<D:/Test/client_secret.json>|pygsheets    |\n +-----+----+------+----+--------+--------+--------------+---------+------------------+-------------+\n\nURL Download\n~~~~~~~~~~~~\n| *Package Used:* requests\n| A user can directly pass download url.\n| Eg. p.byurl(url<download url>,targetpath=<path to store downloaded file>)\n\nSFTP\n~~~~\n| *Package Used:* pysftp\n| Eg. con = con.sftp(conid=1) then proceed with pysftp documentation with *con* as connection object.\n\n +-----+---------+------+--------+--------+--------+--------------+---------+-------------+\n |conid|host     |dbname|port    |username|password|datasourcetype|conString|PythonLibrary|\n +-----+---------+------+--------+--------+--------+--------------+---------+-------------+\n |1    |127.0.0.1|NA    |NA      |xxxxxx  |xxxxxx  |SFTP          |NA       |pysftp       |\n +-----+---------+------+--------+--------+--------+--------------+---------+-------------+\n\nAWS S3\n~~~~~~\n| *Package Used:* boto3\n| Eg. con = con.s3connect(conid=1) then proceed with boto3 documentation with *con* as connection object for S3 bucket.\n\n +-----+----+------+----+--------+--------+--------------+-------------------------------------+-------------+\n |conid|host|dbname|port|username|password|datasourcetype|conString                            |PythonLibrary|\n +-----+----+------+----+--------+--------+--------------+-------------------------------------+-------------+\n |1    |NA  |NA    |NA  |NA      |NA      |AWS S3        |{'accesskey':'XXX','secretkey':'XXX'}|boto3        |\n +-----+----+------+----+--------+--------+--------------+-------------------------------------+-------------+\n\nS3 SELECT\n~~~~~~~~~\n| *Package Used:* boto3\n| Eg. df = con.s3select(conid=1,bucket=<bucket name>,select_stmnt=<SQL expr>,output_format=<CSV/JSON>,fielddelimiter=<',','|' etc. Only applicable for csv/txt files>)\n\n\n\n5.Support\n==========\n +--------------------+------------------------------------+\n |**Operating System**|Linux/OSX/Windows                   |\n +--------------------+------------------------------------+\n |**Python Version**  |2/2.7/3/3.2/3.3/3.4/3.5/3.7 etc.    |\n +--------------------+------------------------------------+ \n\n6.Upcoming-Integrations\n=======================\n\n| Below are the list of datasources planned to add in next version of **dsconnect**\n\n| 01. Mixpanel\n| 02. ElasticSearch\n| 03. HDFS\n| 04. Hive\n| 05. Google Analytics\n| 06. Google Adwords\n| 07. Sisense BI - REST API Connect and many more.\n| 08. Dropbox\n\n7.References\n============\n| Many thanks to the developers of dependent packages. Please use the below links to get deeper knowledge about required packages:-\n\n| **PYSFTP:** https://pypi.org/project/pysftp/\n| **ORACLE:** https://pypi.org/project/cx_Oracle/\n| **MYSQL:** https://pypi.org/project/mysql-connector-python/\n| **PSYCOPG2:** https://pypi.org/project/psycopg2/\n| **PYODBC:** https://pypi.org/project/pyodbc/\n| **PYGSHEETS:** https://pypi.org/project/pygsheets/\n| **BOTO3:** https://pypi.org/project/boto3/\n| **IBM DB2:** https://pypi.org/project/ibm_db/\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://github.com/nit567esh/dsconnect", "keywords": "MySQL,MS SQL Server,MS Azure SQL Database,Oracle,IBM-DB,PostgreSQL,Redshift,GSheets,download-url,SFTP,Pandas,CSV,JSON", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "dsconnect", "package_url": "https://pypi.org/project/dsconnect/", "platform": "", "project_url": "https://pypi.org/project/dsconnect/", "project_urls": {"Homepage": "http://github.com/nit567esh/dsconnect"}, "release_url": "https://pypi.org/project/dsconnect/0.0.1/", "requires_dist": ["pandas", "psycopg2", "pyodbc", "pygsheets", "pysftp", "boto3", "mysql-connector-python", "cx-Oracle", "ibm-db"], "requires_python": "", "summary": "Power your data connections with python", "version": "0.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"dsconnect-power-your-data-connections-with-python\">\n<h2>dsconnect - Power your data connections with python</h2>\n<div>\n<div><a href=\"#overview\" rel=\"nofollow\">1.Overview</a></div>\n<div><a href=\"#installation\" rel=\"nofollow\">2.Installation</a></div>\n<div><a href=\"#usages-guidelines\" rel=\"nofollow\">3.Usages-Guidelines</a></div>\n<div><a href=\"#examples\" rel=\"nofollow\">4.Examples</a></div>\n<div><a href=\"#support\" rel=\"nofollow\">5.Support</a></div>\n<div><a href=\"#upcoming-integrations\" rel=\"nofollow\">6.Upcoming-Integrations</a></div>\n<div><a href=\"#references\" rel=\"nofollow\">7.References</a></div>\n</div>\n</div>\n<div id=\"overview\">\n<h2>1.Overview</h2>\n<p><strong>dsconnect</strong> is prepared for connecting multiple data source by using a single configuration file where a user can maintain a huge list of reusable connection list and can use it by calling single <strong>conid</strong> parameter.\nIts main features are the variety of popular data source connection capabilities. It is a single wrapper of all most popular data connection python libraries into a single library.</p>\n<p>dsconnect is purley implemented in Python.</p>\n</div>\n<div id=\"installation\">\n<h2>2.Installation</h2>\n<div>\n<div><strong>To install the library, use below command</strong></div>\n<div>\n<div>$ pip install dsconnect</div>\n</div>\n</div>\n<div>\n<p>Note</p>\n<p>During the installation of package please verify that all the required dependencies installed successfully, if not try to install them one by one.</p>\n</div>\n</div>\n<div id=\"usages-guidelines\">\n<h2>3.Usages-Guidelines</h2>\n<div>\n<div>This python library need a configured input file which will include list of all datasource details.File should be in below format:-</div>\n</div>\n<blockquote>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n</colgroup>\n<tbody>\n<tr><td><strong>conid</strong></td>\n<td><strong>host</strong></td>\n<td><strong>dbname</strong></td>\n<td><strong>port</strong></td>\n<td><strong>username</strong></td>\n<td><strong>password</strong></td>\n<td><strong>datasourcetype</strong></td>\n<td><strong>conString</strong></td>\n<td><strong>PythonLibrary</strong></td>\n</tr>\n<tr><td>1</td>\n<td>127.0.0.1</td>\n<td>employee</td>\n<td>5433</td>\n<td>livexyz</td>\n<td><a href=\"mailto:live%40123\">live<span>@</span>123</a></td>\n<td>Redshift</td>\n<td>NA</td>\n<td>psycopg2</td>\n</tr>\n</tbody>\n</table>\n</blockquote>\n<div>\n<div>Once file is prepared with all available datasource connection details, follow the below steps to get data/connect to respective datasource</div>\n</div>\n<div>\n<div><strong>Step 1:</strong> Load  connection details <em>.csv</em> file into pandas dataframe</div>\n<div>\n<div>&gt;&gt; import dsconnect as p</div>\n<div>&gt;&gt; &lt;pandas dataframe name&gt; = pandas.read_csv(&lt;filepath&gt;)</div>\n<div>&gt;&gt; con = p.config_df(df = &lt;pandas dataframe name&gt;)</div>\n</div>\n</div>\n<div>\n<div><strong>Step 2:</strong> Pass query with respective conid and get result into pandas</div>\n<div>\n<div>&gt;&gt; df = con.mysql(conid=1,sql=\u201dselect top 10 * from employeesalary\u201d)</div>\n<div>&gt;&gt; df = con.redshift(conid=2,sql=\u201dselect top 10 * from students\u201d)</div>\n</div>\n</div>\n<div>\n<p>Note</p>\n<ol>\n<li>Use the same header name which is provided in sample file format for more help a user can use <strong>p.config_df_sample()</strong> command to see structure of sample configuration file format.</li>\n<li>Before using conid, verify the datatype of your conid column and pass the same in query for eg. if 1 is string then pass \u20181\u2019, if 1 is int then pass 1.</li>\n</ol>\n</div>\n</div>\n<div id=\"examples\">\n<h2>4.Examples</h2>\n<div id=\"mysql\">\n<h3>MySQL</h3>\n<div>\n<div><em>Package Used:</em> mysql-connector-python</div>\n<div>Eg. df = con.mysql(conid=&lt;uniqueid&gt;,sql=\u201dselect top 10 * from &lt;table&gt;\u201d)</div>\n</div>\n</div>\n<div id=\"ms-sql-server\">\n<h3>MS SQL Server</h3>\n<div>\n<div><em>Package Used:</em> pyodbc</div>\n<div>Eg. df = con.mssql(conid=&lt;uniqueid&gt;,sql=\u201dselect top 10 * from &lt;table&gt;\u201d)</div>\n</div>\n</div>\n<div id=\"ms-azure-sql-database\">\n<h3>MS Azure SQL Database</h3>\n<div>\n<div><em>Package Used:</em> pyodbc</div>\n<div>Eg. df = con.msazuresql(conid=&lt;uniqueid&gt;,sql=\u201dselect top 10 * from &lt;table&gt;\u201d)</div>\n</div>\n</div>\n<div id=\"oracle\">\n<h3>Oracle</h3>\n<div>\n<div><em>Package Used:</em> cx_Oracle</div>\n<div>Eg. df = con.oracle(conid=&lt;uniqueid&gt;,sql=\u201dselect top 10 * from &lt;table&gt;\u201d)</div>\n</div>\n</div>\n<div id=\"db2\">\n<h3>DB2</h3>\n<div>\n<div><em>Package Used:</em> ibm_db</div>\n<div>Eg. df = con.ibmdb(conid=&lt;uniqueid&gt;,sql=\u201dselect top 10 * from &lt;table&gt;\u201d)</div>\n</div>\n</div>\n<div id=\"postgresql\">\n<h3>PostgreSQL</h3>\n<div>\n<div><em>Package Used:</em> psycopg2</div>\n<div>Eg. df = con.postgresql(conid=&lt;uniqueid&gt;,sql=\u201dselect top 10 * from &lt;table&gt;\u201d)</div>\n</div>\n</div>\n<div id=\"redshift\">\n<h3>Redshift</h3>\n<div>\n<div><em>Package Used:</em> psycopg2</div>\n<div>Eg. df = con.mysql(conid=&lt;uniqueid&gt;,sql=\u201dselect top 10 * from &lt;table&gt;\u201d)</div>\n</div>\n</div>\n<div id=\"gsheet\">\n<h3>Gsheet</h3>\n<div>\n<div><em>Package Used:</em> pygsheets</div>\n<div>Eg. con = con.gsheet(conid=&lt;uniqueid&gt;) then proceed with pygsheets documentation with <em>con</em> as connection object.</div>\n<div><strong>conString</strong> column should be use to store client_secret.json path(Obtained from Google Gsheet API OAuth).</div>\n</div>\n<blockquote>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n</colgroup>\n<tbody>\n<tr><td>conid</td>\n<td>host</td>\n<td>dbname</td>\n<td>port</td>\n<td>username</td>\n<td>password</td>\n<td>datasourcetype</td>\n<td>conString</td>\n<td>PythonLibrary</td>\n</tr>\n<tr><td>1</td>\n<td>NA</td>\n<td>NA</td>\n<td>NA</td>\n<td>NA</td>\n<td>NA</td>\n<td>Gsheet</td>\n<td>&lt;D:/Test/client_secret.json&gt;</td>\n<td>pygsheets</td>\n</tr>\n</tbody>\n</table>\n</blockquote>\n</div>\n<div id=\"url-download\">\n<h3>URL Download</h3>\n<div>\n<div><em>Package Used:</em> requests</div>\n<div>A user can directly pass download url.</div>\n<div>Eg. p.byurl(url&lt;download url&gt;,targetpath=&lt;path to store downloaded file&gt;)</div>\n</div>\n</div>\n<div id=\"sftp\">\n<h3>SFTP</h3>\n<div>\n<div><em>Package Used:</em> pysftp</div>\n<div>Eg. con = con.sftp(conid=1) then proceed with pysftp documentation with <em>con</em> as connection object.</div>\n</div>\n<blockquote>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n</colgroup>\n<tbody>\n<tr><td>conid</td>\n<td>host</td>\n<td>dbname</td>\n<td>port</td>\n<td>username</td>\n<td>password</td>\n<td>datasourcetype</td>\n<td>conString</td>\n<td>PythonLibrary</td>\n</tr>\n<tr><td>1</td>\n<td>127.0.0.1</td>\n<td>NA</td>\n<td>NA</td>\n<td>xxxxxx</td>\n<td>xxxxxx</td>\n<td>SFTP</td>\n<td>NA</td>\n<td>pysftp</td>\n</tr>\n</tbody>\n</table>\n</blockquote>\n</div>\n<div id=\"aws-s3\">\n<h3>AWS S3</h3>\n<div>\n<div><em>Package Used:</em> boto3</div>\n<div>Eg. con = con.s3connect(conid=1) then proceed with boto3 documentation with <em>con</em> as connection object for S3 bucket.</div>\n</div>\n<blockquote>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n</colgroup>\n<tbody>\n<tr><td>conid</td>\n<td>host</td>\n<td>dbname</td>\n<td>port</td>\n<td>username</td>\n<td>password</td>\n<td>datasourcetype</td>\n<td>conString</td>\n<td>PythonLibrary</td>\n</tr>\n<tr><td>1</td>\n<td>NA</td>\n<td>NA</td>\n<td>NA</td>\n<td>NA</td>\n<td>NA</td>\n<td>AWS S3</td>\n<td>{\u2018accesskey\u2019:\u2019XXX\u2019,\u2019secretkey\u2019:\u2019XXX\u2019}</td>\n<td>boto3</td>\n</tr>\n</tbody>\n</table>\n</blockquote>\n</div>\n<div id=\"s3-select\">\n<h3>S3 SELECT</h3>\n<div>\n<div><em>Package Used:</em> boto3</div>\n<div>Eg. df = con.s3select(conid=1,bucket=&lt;bucket name&gt;,select_stmnt=&lt;SQL expr&gt;,output_format=&lt;CSV/JSON&gt;,fielddelimiter=&lt;\u2019,\u2019,\u2019|\u2019 etc. Only applicable for csv/txt files&gt;)</div>\n</div>\n</div>\n</div>\n<div id=\"support\">\n<h2>5.Support</h2>\n<blockquote>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<tbody>\n<tr><td><strong>Operating System</strong></td>\n<td>Linux/OSX/Windows</td>\n</tr>\n<tr><td><strong>Python Version</strong></td>\n<td>2/2.7/3/3.2/3.3/3.4/3.5/3.7 etc.</td>\n</tr>\n</tbody>\n</table>\n</blockquote>\n</div>\n<div id=\"upcoming-integrations\">\n<h2>6.Upcoming-Integrations</h2>\n<div>\n<div>Below are the list of datasources planned to add in next version of <strong>dsconnect</strong></div>\n</div>\n<div>\n<div>01. Mixpanel</div>\n<div>02. ElasticSearch</div>\n<div>03. HDFS</div>\n<div>04. Hive</div>\n<div>05. Google Analytics</div>\n<div>06. Google Adwords</div>\n<div>07. Sisense BI - REST API Connect and many more.</div>\n<div>08. Dropbox</div>\n</div>\n</div>\n<div id=\"references\">\n<h2>7.References</h2>\n<div>\n<div>Many thanks to the developers of dependent packages. Please use the below links to get deeper knowledge about required packages:-</div>\n</div>\n<div>\n<div><strong>PYSFTP:</strong> <a href=\"https://pypi.org/project/pysftp/\" rel=\"nofollow\">https://pypi.org/project/pysftp/</a></div>\n<div><strong>ORACLE:</strong> <a href=\"https://pypi.org/project/cx_Oracle/\" rel=\"nofollow\">https://pypi.org/project/cx_Oracle/</a></div>\n<div><strong>MYSQL:</strong> <a href=\"https://pypi.org/project/mysql-connector-python/\" rel=\"nofollow\">https://pypi.org/project/mysql-connector-python/</a></div>\n<div><strong>PSYCOPG2:</strong> <a href=\"https://pypi.org/project/psycopg2/\" rel=\"nofollow\">https://pypi.org/project/psycopg2/</a></div>\n<div><strong>PYODBC:</strong> <a href=\"https://pypi.org/project/pyodbc/\" rel=\"nofollow\">https://pypi.org/project/pyodbc/</a></div>\n<div><strong>PYGSHEETS:</strong> <a href=\"https://pypi.org/project/pygsheets/\" rel=\"nofollow\">https://pypi.org/project/pygsheets/</a></div>\n<div><strong>BOTO3:</strong> <a href=\"https://pypi.org/project/boto3/\" rel=\"nofollow\">https://pypi.org/project/boto3/</a></div>\n<div><strong>IBM DB2:</strong> <a href=\"https://pypi.org/project/ibm_db/\" rel=\"nofollow\">https://pypi.org/project/ibm_db/</a></div>\n</div>\n</div>\n\n          </div>"}, "last_serial": 4667999, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "a50e30854cb7a576d2d665f42ac8729c", "sha256": "cb4b7fa228d2c9481de4696b8c097690654e047bdd3af4a4f0371c0870245b89"}, "downloads": -1, "filename": "dsconnect-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "a50e30854cb7a576d2d665f42ac8729c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6639, "upload_time": "2019-01-07T09:50:36", "upload_time_iso_8601": "2019-01-07T09:50:36.873214Z", "url": "https://files.pythonhosted.org/packages/a5/1c/86b7394ff5aae65213f7aa4cd19d4e8341f6a2c46caf30ad3dc08e46467c/dsconnect-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "bd5d4c903718d61ee3b187acf451fdda", "sha256": "cc9016e36d43f3aa3728cc12ddab53c45addf567158d7274a37e5756097e49ba"}, "downloads": -1, "filename": "dsconnect-0.0.1.tar.gz", "has_sig": false, "md5_digest": "bd5d4c903718d61ee3b187acf451fdda", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6029, "upload_time": "2019-01-07T09:50:38", "upload_time_iso_8601": "2019-01-07T09:50:38.911077Z", "url": "https://files.pythonhosted.org/packages/64/62/0aacc2ce8a5d72a50e74893e153033731c3320c6d896353262862013bb71/dsconnect-0.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "a50e30854cb7a576d2d665f42ac8729c", "sha256": "cb4b7fa228d2c9481de4696b8c097690654e047bdd3af4a4f0371c0870245b89"}, "downloads": -1, "filename": "dsconnect-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "a50e30854cb7a576d2d665f42ac8729c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6639, "upload_time": "2019-01-07T09:50:36", "upload_time_iso_8601": "2019-01-07T09:50:36.873214Z", "url": "https://files.pythonhosted.org/packages/a5/1c/86b7394ff5aae65213f7aa4cd19d4e8341f6a2c46caf30ad3dc08e46467c/dsconnect-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "bd5d4c903718d61ee3b187acf451fdda", "sha256": "cc9016e36d43f3aa3728cc12ddab53c45addf567158d7274a37e5756097e49ba"}, "downloads": -1, "filename": "dsconnect-0.0.1.tar.gz", "has_sig": false, "md5_digest": "bd5d4c903718d61ee3b187acf451fdda", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6029, "upload_time": "2019-01-07T09:50:38", "upload_time_iso_8601": "2019-01-07T09:50:38.911077Z", "url": "https://files.pythonhosted.org/packages/64/62/0aacc2ce8a5d72a50e74893e153033731c3320c6d896353262862013bb71/dsconnect-0.0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:49:25 2020"}