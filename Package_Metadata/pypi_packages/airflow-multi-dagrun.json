{"info": {"author": "Ihor Liubymov", "author_email": "infunt@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "[![Build Status](https://travis-ci.com/mastak/airflow_multi_dagrun.svg?branch=master)](https://travis-ci.com/mastak/airflow_multi_dagrun)\n\n# Multi dag run\n\nThis plugin contains operators for triggering a DAG run multiple times\nand you can dynamically specify how many DAG run instances create.\n\nIt can be useful when you have to handle a big data and you want to split it\ninto chunks and run multiple instances of the same task in parallel.\n\nWhen you see a lot launched target DAGs you can set up more workers.\nSo this makes it pretty easy to scale.\n\n## Install\n\n```bash\npip install airflow_multi_dagrun\n```\n\n## Example\n\nCode for scheduling dags\n\n```python\nimport datetime as dt\nfrom airflow import DAG\nfrom airflow.operators.dagrun_operator import DagRunOrder\nfrom airflow.operators.multi_dagrun import TriggerMultiDagRunOperator\n\n\ndef generate_dag_run():\n    for i in range(100):\n        yield DagRunOrder(payload={'index': i})\n\n\ndefault_args = {\n    'owner': 'airflow',\n    'start_date': dt.datetime(2015, 6, 1),\n}\n\n\ndag = DAG('reindex_scheduler', schedule_interval=None, default_args=default_args)\n\n\nran_dags = TriggerMultiDagRunOperator(\n    task_id='gen_target_dag_run',\n    dag=dag,\n    trigger_dag_id='example_target_dag',\n    python_callable=generate_dag_run,\n)\n```\n\nThis code will schedule dag with id `example_target_dag` 100 times and pass payload to it.\n\n\nExample of triggered dag:\n\n ```python\ndag = DAG(\n    dag_id='example_target_dag',\n    schedule_interval=None,\n    default_args={'start_date': datetime.utcnow(), 'owner': 'airflow'},\n)\n\n\ndef run_this_func(dag_run, **kwargs):\n    print(\"Chunk received: {}\".format(dag_run.conf['index']))\n\n\nchunk_handler = PythonOperator(\n    task_id='chunk_handler',\n    provide_context=True,\n    python_callable=run_this_func,\n    dag=dag\n)\n```\n\n## Run example\nThere is docker-compose config, so it requires docker to be installed: `docker`, `docker-compose`\n1. `make run` - start docker containers, init db, run airflow webserver\n2. `make down` - destroy docker containers\n\n## Contributions\nIf you have found a bug or have some idea for improvement feel free to create an issue\nor pull request.\n\n## License\nApache 2.0\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/mastak/airflow_multi_dagrun", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "airflow-multi-dagrun", "package_url": "https://pypi.org/project/airflow-multi-dagrun/", "platform": "", "project_url": "https://pypi.org/project/airflow-multi-dagrun/", "project_urls": {"Homepage": "https://github.com/mastak/airflow_multi_dagrun"}, "release_url": "https://pypi.org/project/airflow-multi-dagrun/1.2/", "requires_dist": null, "requires_python": ">=3.6.0", "summary": "MultiDagRunPlugin for airflow", "version": "1.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://travis-ci.com/mastak/airflow_multi_dagrun\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/74afea502332ba9bc63684517f81a0028255460d/68747470733a2f2f7472617669732d63692e636f6d2f6d617374616b2f616972666c6f775f6d756c74695f64616772756e2e7376673f6272616e63683d6d6173746572\"></a></p>\n<h1>Multi dag run</h1>\n<p>This plugin contains operators for triggering a DAG run multiple times\nand you can dynamically specify how many DAG run instances create.</p>\n<p>It can be useful when you have to handle a big data and you want to split it\ninto chunks and run multiple instances of the same task in parallel.</p>\n<p>When you see a lot launched target DAGs you can set up more workers.\nSo this makes it pretty easy to scale.</p>\n<h2>Install</h2>\n<pre>pip install airflow_multi_dagrun\n</pre>\n<h2>Example</h2>\n<p>Code for scheduling dags</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">datetime</span> <span class=\"k\">as</span> <span class=\"nn\">dt</span>\n<span class=\"kn\">from</span> <span class=\"nn\">airflow</span> <span class=\"kn\">import</span> <span class=\"n\">DAG</span>\n<span class=\"kn\">from</span> <span class=\"nn\">airflow.operators.dagrun_operator</span> <span class=\"kn\">import</span> <span class=\"n\">DagRunOrder</span>\n<span class=\"kn\">from</span> <span class=\"nn\">airflow.operators.multi_dagrun</span> <span class=\"kn\">import</span> <span class=\"n\">TriggerMultiDagRunOperator</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">generate_dag_run</span><span class=\"p\">():</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">):</span>\n        <span class=\"k\">yield</span> <span class=\"n\">DagRunOrder</span><span class=\"p\">(</span><span class=\"n\">payload</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'index'</span><span class=\"p\">:</span> <span class=\"n\">i</span><span class=\"p\">})</span>\n\n\n<span class=\"n\">default_args</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'owner'</span><span class=\"p\">:</span> <span class=\"s1\">'airflow'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'start_date'</span><span class=\"p\">:</span> <span class=\"n\">dt</span><span class=\"o\">.</span><span class=\"n\">datetime</span><span class=\"p\">(</span><span class=\"mi\">2015</span><span class=\"p\">,</span> <span class=\"mi\">6</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span>\n<span class=\"p\">}</span>\n\n\n<span class=\"n\">dag</span> <span class=\"o\">=</span> <span class=\"n\">DAG</span><span class=\"p\">(</span><span class=\"s1\">'reindex_scheduler'</span><span class=\"p\">,</span> <span class=\"n\">schedule_interval</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">default_args</span><span class=\"o\">=</span><span class=\"n\">default_args</span><span class=\"p\">)</span>\n\n\n<span class=\"n\">ran_dags</span> <span class=\"o\">=</span> <span class=\"n\">TriggerMultiDagRunOperator</span><span class=\"p\">(</span>\n    <span class=\"n\">task_id</span><span class=\"o\">=</span><span class=\"s1\">'gen_target_dag_run'</span><span class=\"p\">,</span>\n    <span class=\"n\">dag</span><span class=\"o\">=</span><span class=\"n\">dag</span><span class=\"p\">,</span>\n    <span class=\"n\">trigger_dag_id</span><span class=\"o\">=</span><span class=\"s1\">'example_target_dag'</span><span class=\"p\">,</span>\n    <span class=\"n\">python_callable</span><span class=\"o\">=</span><span class=\"n\">generate_dag_run</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n</pre>\n<p>This code will schedule dag with id <code>example_target_dag</code> 100 times and pass payload to it.</p>\n<p>Example of triggered dag:</p>\n<pre><span class=\"n\">dag</span> <span class=\"o\">=</span> <span class=\"n\">DAG</span><span class=\"p\">(</span>\n   <span class=\"n\">dag_id</span><span class=\"o\">=</span><span class=\"s1\">'example_target_dag'</span><span class=\"p\">,</span>\n   <span class=\"n\">schedule_interval</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n   <span class=\"n\">default_args</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'start_date'</span><span class=\"p\">:</span> <span class=\"n\">datetime</span><span class=\"o\">.</span><span class=\"n\">utcnow</span><span class=\"p\">(),</span> <span class=\"s1\">'owner'</span><span class=\"p\">:</span> <span class=\"s1\">'airflow'</span><span class=\"p\">},</span>\n<span class=\"p\">)</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">run_this_func</span><span class=\"p\">(</span><span class=\"n\">dag_run</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n   <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"Chunk received: </span><span class=\"si\">{}</span><span class=\"s2\">\"</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">dag_run</span><span class=\"o\">.</span><span class=\"n\">conf</span><span class=\"p\">[</span><span class=\"s1\">'index'</span><span class=\"p\">]))</span>\n\n\n<span class=\"n\">chunk_handler</span> <span class=\"o\">=</span> <span class=\"n\">PythonOperator</span><span class=\"p\">(</span>\n   <span class=\"n\">task_id</span><span class=\"o\">=</span><span class=\"s1\">'chunk_handler'</span><span class=\"p\">,</span>\n   <span class=\"n\">provide_context</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n   <span class=\"n\">python_callable</span><span class=\"o\">=</span><span class=\"n\">run_this_func</span><span class=\"p\">,</span>\n   <span class=\"n\">dag</span><span class=\"o\">=</span><span class=\"n\">dag</span>\n<span class=\"p\">)</span>\n</pre>\n<h2>Run example</h2>\n<p>There is docker-compose config, so it requires docker to be installed: <code>docker</code>, <code>docker-compose</code></p>\n<ol>\n<li><code>make run</code> - start docker containers, init db, run airflow webserver</li>\n<li><code>make down</code> - destroy docker containers</li>\n</ol>\n<h2>Contributions</h2>\n<p>If you have found a bug or have some idea for improvement feel free to create an issue\nor pull request.</p>\n<h2>License</h2>\n<p>Apache 2.0</p>\n\n          </div>"}, "last_serial": 6320574, "releases": {"1.0": [{"comment_text": "", "digests": {"md5": "6a52df81e722f88a956583b7d5697466", "sha256": "cd3f4641d07f7248334d0eed61afae154d940aa96c130d7f9bfa8cab59e0e5f9"}, "downloads": -1, "filename": "airflow_multi_dagrun-1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "6a52df81e722f88a956583b7d5697466", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 5622, "upload_time": "2019-12-17T20:52:14", "upload_time_iso_8601": "2019-12-17T20:52:14.551430Z", "url": "https://files.pythonhosted.org/packages/7f/64/8c5b29acb5ccf61582ca5d73c055bdfaa31dc53cc97ad0a907bc97af52f1/airflow_multi_dagrun-1.0-py3-none-any.whl", "yanked": false}], "1.1": [{"comment_text": "", "digests": {"md5": "544e949a46fa949631be32356f6d1126", "sha256": "fa39739ecba082dc1feb0f3c9574c62ab11fb6ec7c804bdbe909b75ac62c48e6"}, "downloads": -1, "filename": "airflow_multi_dagrun-1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "544e949a46fa949631be32356f6d1126", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 6610, "upload_time": "2019-12-17T20:58:49", "upload_time_iso_8601": "2019-12-17T20:58:49.372787Z", "url": "https://files.pythonhosted.org/packages/46/32/d25181654e2e72fc6bc0d5db67a272690e933dfd81f891a1673c2a7c51cc/airflow_multi_dagrun-1.1-py3-none-any.whl", "yanked": false}], "1.2": [{"comment_text": "", "digests": {"md5": "05e5c19d19ca6e4448da70dd1f6e42ef", "sha256": "a2f3fd29e2afe6d78c53fa9d07ca0ccb7da0cb1d19ddaf80e8d7c7093a3b973e"}, "downloads": -1, "filename": "airflow_multi_dagrun-1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "05e5c19d19ca6e4448da70dd1f6e42ef", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 13054, "upload_time": "2019-12-17T21:13:08", "upload_time_iso_8601": "2019-12-17T21:13:08.313421Z", "url": "https://files.pythonhosted.org/packages/af/41/e60dff951d002dbf14daf601b1323dfc48c0d24d2bc4e7d19ac72b19c3f6/airflow_multi_dagrun-1.2-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "05e5c19d19ca6e4448da70dd1f6e42ef", "sha256": "a2f3fd29e2afe6d78c53fa9d07ca0ccb7da0cb1d19ddaf80e8d7c7093a3b973e"}, "downloads": -1, "filename": "airflow_multi_dagrun-1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "05e5c19d19ca6e4448da70dd1f6e42ef", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 13054, "upload_time": "2019-12-17T21:13:08", "upload_time_iso_8601": "2019-12-17T21:13:08.313421Z", "url": "https://files.pythonhosted.org/packages/af/41/e60dff951d002dbf14daf601b1323dfc48c0d24d2bc4e7d19ac72b19c3f6/airflow_multi_dagrun-1.2-py3-none-any.whl", "yanked": false}], "timestamp": "Thu May  7 16:20:29 2020"}