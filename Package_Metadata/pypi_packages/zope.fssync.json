{"info": {"author": "Zope Corporation and Contributors", "author_email": "zope3-dev@zope.org", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Environment :: Web Environment", "Framework :: Zope3", "Intended Audience :: Developers", "License :: OSI Approved :: Zope Public License", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python", "Topic :: Internet :: WWW/HTTP"], "description": "===================\nzope.fssync Package\n===================\n\nThis package provides filesystem synchronization utilities for Zope\n3. It is used by the zope.app.fssync package.\n\n\n==========================\nFilesystem Synchronization\n==========================\n\nThis package provides an API for the synchronization of Python objects\nwith a serialized filesystem representation. This API does not address\nsecurity issues. (See zope.app.fssync for a protected web-based API).\nThis API is Zope and ZODB independent.\n\nThe main use cases are\n\n    - data export / import (e.g. moving data from one place to another)\n\n    - content management (e.g. managing a wiki or other collections of\n      documents offline)\n\nThe target representation depends on your use case. In the use case of\ndata export/import, for instance, it is crucial that all data are\nexported as completely as possible. Since the data need not be read\nby humans in most circumstances a pickle format may be the most\ncomplete and easy one to use.\nIn the use case of content management it may be more important that\nall metadata are readable by humans. In this case another format,\ne.g. RDFa, may be more appropriate.\n\nMain components\n===============\n\nA synchronizer serializes content objects and stores the serialized\ndata in a repository in an application specific format. It uses\ndeserializers to read the object back into the content space.\nThe serialization format must be rich enough to preserve various forms\nof references which should be reestablished on deserialization.\n\nAll these components should be replaceable. Application may use\ndifferent serialization formats with different references for\ndifferent purposes (e.g. backup vs. content management) and different\ntarget systems (e.g. a zip archive vs. a svn repository).\n\nThe main components are:\n\n    - ISyncTasks like Checkout, Check, and Commit which synchronize\n      a content space with a repository. These tasks uses serializers\n      to produce serialized data for a repository in an application\n      specific format. They use deserializers to read the data back.\n      The default implementation uses xmlpickle for python objects,\n      data streams for file contents, and special directories for\n      extras and metadata. Alternative implementations may use\n      standard pickles, a human readable format like RDFa, or\n      application specific formats.\n\n    - ISynchronizer: Synchronizers produce serialized pieces of a\n      Python object (the ISerializer part of a synchronizer) and\n      consume serialized data to (re-)create Python objects (the\n      IDeserializer part of a synchronizer).\n\n    - IPickler: An adapter that determines the pickle format.\n\n    - IRepository: represents a target system that can be used\n      to read and write serialized data.\n\n\nLet's take some samples:\n\n    >>> from StringIO import StringIO\n    >>> from zope import interface\n    >>> from zope import component\n    >>> from zope.fssync import interfaces\n    >>> from zope.fssync import task\n    >>> from zope.fssync import synchronizer\n    >>> from zope.fssync import repository\n    >>> from zope.fssync import pickle\n\n    >>> class A(object):\n    ...     data = 'data of a'\n    >>> class B(A):\n    ...     pass\n    >>> a = A()\n    >>> b = B()\n    >>> b.data = 'data of b'\n    >>> b.extra = 'extra of b'\n    >>> root = dict(a=a, b=b)\n\n\nPersistent References\n=====================\n\nMany applications use more than one system of persistent references.\nZope, for instance, uses p_oids, int ids, key references,\ntraversal paths, dotted names, named utilities, etc.\n\nOther systems might use generic reference systems like global unique\nids or primary keys together with domain specific references, like\nemails, URI, postal addresses, code numbers, etc.\nAll these references are candidates for exportable references as long\nas they can be resolved on import or reimport.\n\nIn our example we use simple integer ids:\n\n    >>> class GlobalIds(object):\n    ...     ids = dict()\n    ...     count = 0\n    ...     def getId(self, obj):\n    ...         for k, v in self.ids.iteritems():\n    ...             if obj == v:\n    ...                 return k\n    ...     def register(self, obj):\n    ...         uid = self.getId(obj)\n    ...         if uid is not None:\n    ...             return uid\n    ...         self.count += 1\n    ...         self.ids[self.count] = obj\n    ...         return self.count\n    ...     def resolve(self, uid):\n    ...         return self.ids.get(int(uid), None)\n\n    >>> globalIds = GlobalIds()\n    >>> globalIds.register(a)\n    1\n    >>> globalIds.register(b)\n    2\n    >>> globalIds.register(root)\n    3\n\nIn our example we use the int ids as a substitute for the default path\nreferences which are the most common references in Zope.\n\nIn our examples we use a SnarfRepository which can easily be examined:\n\n>>> snarf = repository.SnarfRepository(StringIO())\n>>> checkout = task.Checkout(synchronizer.getSynchronizer, snarf)\n\nSnarf is a Zope3 specific archive format where the key\nneed is for simple software. The format is dead simple: each file\nis represented by the string\n\n    '<size> <pathname>\\n'\n\nfollowed by exactly <size> bytes.  Directories are not represented\nexplicitly.\n\n\nEntry Ids\n=========\n\nPersistent ids are also used in the metadata files of fssync.\nThe references are generated by an IEntryId adapter which must\nhave a string representation in order to be saveable in a text file.\nTypically these object ids correspond to the persistent pickle ids, but\nthis is not necessarily the case.\n\nSince we do not have paths we use our integer ids:\n\n    >>> @component.adapter(interface.Interface)\n    ... @interface.implementer(interfaces.IEntryId)\n    ... def entryId(obj):\n    ...     global globalIds\n    ...     return globalIds.getId(obj)\n    >>> component.provideAdapter(entryId)\n\n\nSynchronizer\n============\n\nIn the use case of data export / import it is crucial that fssync is\nable to serialize \"all\" object data. Note that it isn't always obvious\nwhat data is intrinsic to an object. Therefore we must provide\nspecial serialization / de-serialization tools which take care of\nwriting and reading \"all\" data.\n\nAn obvious solution would be to use inheriting synchronization\nadapters. But this solution bears a risk. If someone created a subclass\nand forgot to create an adapter, then their data would be serialized\nincompletely. To give an example: What happens if someone has a\nserialization adapter for class Person which serializes every aspect of\nPerson instances and defines a subclass Employee(Person) later on?\nIf the Employee class has some extra aspects (for example additional\nattributes like insurance id, wage, etc.) these would never be serialized\nas long as there is no special serialization adapter for Employees\nwhich handles this extra aspects. The behavior is different if the\nadapters are looked up by their dotted class name (i.e. the most specific\nclass) and not their class or interface (which might led to adapters\nwritten for super classes). If no specific adapter exists a default\nserializer (e.g a xmlpickler) can serialize the object completely. So\neven if you forget to provide special serializers for all your classes\nyou can be sure that your data are complete.\n\nSince the component architecture doesn't support adapters that work\none class only (not their subclasses), we register the adapter classes\nas named ISynchronizerFactory utilities and use the dotted name of the\nclass as lookup key. The default synchronizer is registered as a\nunnamed ISynchronizerFactory utility. This synchronizer ensures that\nall data are pickled to the target repository.\n\n    >>> component.provideUtility(synchronizer.DefaultSynchronizer,\n    ...                             provides=interfaces.ISynchronizerFactory)\n\nAll special synchronizers are registered for a specific content class and\nnot an abstract interface. The class is represented by the dotted class\nname in the factory registration:\n\n    >>> class AFileSynchronizer(synchronizer.Synchronizer):\n    ...     interface.implements(interfaces.IFileSynchronizer)\n    ...     def dump(self, writeable):\n    ...         writeable.write(self.context.data)\n    ...     def load(self, readable):\n    ...         self.context.data = readable.read()\n\n    >>> component.provideUtility(AFileSynchronizer,\n    ...                             interfaces.ISynchronizerFactory,\n    ...                             name=synchronizer.dottedname(A))\n\nThe lookup of the utilities by the dotted class name is handled\nby the getSynchronizer function, which first tries to find\na named utility. The IDefaultSynchronizer utility is used as a fallback:\n\n    >>> synchronizer.getSynchronizer(a)\n    <zope.fssync.doctest.AFileSynchronizer object at ...>\n\nIf no named adapter is registered it returns the registered unnamed default\nadapter (as long as the permissions allow this):\n\n    >>> synchronizer.getSynchronizer(b)\n    <zope.fssync.synchronizer.DefaultSynchronizer object at ...>\n\nThis default serializer typically uses a pickle format, which is determined\nby the IPickler adapter. Here we use Zope's xmlpickle.\n\n    >>> component.provideAdapter(pickle.XMLPickler)\n    >>> component.provideAdapter(pickle.XMLUnpickler)\n\nFor container like objects we must provide an adapter that maps the\ncontainer to a directory. In our example we use the buildin dict class:\n\n    >>> component.provideUtility(synchronizer.DirectorySynchronizer,\n    ...                             interfaces.ISynchronizerFactory,\n    ...                             name=synchronizer.dottedname(dict))\n\n\nNow we can export the object to the snarf archive:\n\n    >>> checkout.perform(root, 'test')\n    >>> print snarf.stream.getvalue()\n    00000213 @@Zope/Entries.xml\n    <?xml version='1.0' encoding='utf-8'?>\n    <entries>\n      <entry name=\"test\"\n             keytype=\"__builtin__.str\"\n             type=\"__builtin__.dict\"\n             factory=\"__builtin__.dict\"\n             id=\"3\"\n             />\n    </entries>\n    00000339 test/@@Zope/Entries.xml\n    <?xml version='1.0' encoding='utf-8'?>\n    <entries>\n      <entry name=\"a\"\n             keytype=\"__builtin__.str\"\n             type=\"zope.fssync.doctest.A\"\n             factory=\"zope.fssync.doctest.A\"\n             id=\"1\"\n             />\n      <entry name=\"b\"\n             keytype=\"__builtin__.str\"\n             type=\"zope.fssync.doctest.B\"\n             id=\"2\"\n             />\n    </entries>\n    00000009 test/a\n    data of a00000370 test/b\n    <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n    <pickle>\n      <object>\n        <klass>\n          <global name=\"B\" module=\"zope.fssync.doctest\"/>\n        </klass>\n        <attributes>\n          <attribute name=\"data\">\n              <string>data of b</string>\n          </attribute>\n          <attribute name=\"extra\">\n              <string>extra of b</string>\n          </attribute>\n        </attributes>\n      </object>\n    </pickle>\n    <BLANKLINE>\n\nAfter the registration of the necessary generators we can reimport the\nserialized data from the repository:\n\n    >>> component.provideUtility(synchronizer.FileGenerator(),\n    ...                                 provides=interfaces.IFileGenerator)\n\n    >>> target = {}\n    >>> commit = task.Commit(synchronizer.getSynchronizer, snarf)\n    >>> commit.perform(target, 'root', 'test')\n    >>> sorted(target.keys())\n    ['root']\n    >>> sorted(target['root'].keys())\n    ['a', 'b']\n\n    >>> target['root']['a'].data\n    'data of a'\n\n    >>> target['root']['b'].extra\n    'extra of b'\n\nIf we want to commit the data back into the original place we must check\nwhether the repository is still consistent with the original content.\nWe modify the objects in place to see what happens:\n\n    >>> check = task.Check(synchronizer.getSynchronizer, snarf)\n    >>> check.check(root, '', 'test')\n    >>> check.errors()\n    []\n\n    >>> root['a'].data = 'overwritten'\n    >>> root['b'].extra = 'overwritten'\n\n    >>> check = task.Check(synchronizer.getSynchronizer, snarf)\n    >>> check.check(root, '', 'test')\n    >>> check.errors()\n    ['test/a', 'test/b']\n\n    >>> commit.perform(root, '', 'test')\n    >>> sorted(root.keys())\n    ['a', 'b']\n    >>> root['a'].data\n    'data of a'\n    >>> root['b'].extra\n    'extra of b'\n\n    >>> del root['a']\n    >>> commit.perform(root, '', 'test')\n    >>> sorted(root.keys())\n    ['a', 'b']\n\n    >>> del root['b']\n    >>> commit.perform(root, '', 'test')\n    >>> sorted(root.keys())\n    ['a', 'b']\n\n    >>> del root['a']\n    >>> del root['b']\n    >>> commit.perform(root, '', 'test')\n    >>> sorted(root.keys())\n    ['a', 'b']\n\n\nPickling\n========\n\nIn many data structures, large, complex objects are composed of\nsmaller objects.  These objects are typically stored in one of two\nways:\n\n    1.  The smaller objects are stored inside the larger object.\n\n    2.  The smaller objects are allocated in their own location,\n        and the larger object stores references to them.\n\nIn case 1 the object is self-contained and can be pickled\ncompletely. This is the default behavior of the fssync pickler:\n\n    >>> pickler = interfaces.IPickler([42])\n    >>> pickler\n    <zope.fssync.pickle.XMLPickler object at ...>\n    >>> print pickler.dumps()\n    <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n    <pickle>\n      <list>\n        <int>42</int>\n      </list>\n    </pickle>\n    <BLANKLINE>\n\nCase 2 is more complex since the pickler has to take persistent\nreferences into account.\n\n    >>> class Complex(object):\n    ...     def __init__(self, part1, part2):\n    ...         self.part1 = part1\n    ...         self.part2 = part2\n\nEverthing here depends on the definition of what we consider to be an intrinsic\nreference. In the examples above we simply considered all objects as intrinsic.\n\n    >>> from zope.fssync import pickle\n    >>> c = root['c'] = Complex(a, b)\n    >>> stream = StringIO()\n    >>> print interfaces.IPickler(c).dumps()\n    <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n    <pickle>\n      <initialized_object>\n        <klass>\n          <global id=\"o0\" name=\"_reconstructor\" module=\"copy_reg\"/>\n        </klass>\n        <arguments>\n          <tuple>\n            <global name=\"Complex\" module=\"zope.fssync.doctest\"/>\n            <global id=\"o1\" name=\"object\" module=\"__builtin__\"/>\n            <none/>\n          </tuple>\n        </arguments>\n        <state>\n          <dictionary>\n            <item key=\"part1\">\n                <object>\n                  <klass>\n                    <global name=\"A\" module=\"zope.fssync.doctest\"/>\n                  </klass>\n                  <attributes>\n                    <attribute name=\"data\">\n                        <string>data of a</string>\n                    </attribute>\n                  </attributes>\n                </object>\n            </item>\n            <item key=\"part2\">\n                <object>\n                  <klass>\n                    <global name=\"B\" module=\"zope.fssync.doctest\"/>\n                  </klass>\n                  <attributes>\n                    <attribute name=\"data\">\n                        <string>data of b</string>\n                    </attribute>\n                    <attribute name=\"extra\">\n                        <string>overwritten</string>\n                    </attribute>\n                  </attributes>\n                </object>\n            </item>\n          </dictionary>\n        </state>\n      </initialized_object>\n    </pickle>\n    <BLANKLINE>\n\nIn order to use persistent references we must define a\nPersistentIdGenerator for our pickler, which determines whether\nan object should be pickled completely or only by reference:\n\n    >>> class PersistentIdGenerator(object):\n    ...     interface.implements(interfaces.IPersistentIdGenerator)\n    ...     component.adapts(interfaces.IPickler)\n    ...     def __init__(self, pickler):\n    ...         self.pickler = pickler\n    ...     def id(self, obj):\n    ...         if isinstance(obj, Complex):\n    ...             return None\n    ...         return globalIds.getId(obj)\n\n    >>> component.provideAdapter(PersistentIdGenerator)\n\n    >>> globalIds.register(a)\n    1\n    >>> globalIds.register(b)\n    2\n    >>> globalIds.register(root)\n    3\n\n    >>> xml = interfaces.IPickler(c).dumps()\n    >>> print xml\n    <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n    <pickle>\n      <object>\n        <klass>\n          <global name=\"Complex\" module=\"zope.fssync.doctest\"/>\n        </klass>\n        <attributes>\n          <attribute name=\"part1\">\n              <persistent> <string>1</string> </persistent>\n          </attribute>\n          <attribute name=\"part2\">\n              <persistent> <string>2</string> </persistent>\n          </attribute>\n        </attributes>\n      </object>\n    </pickle>\n    <BLANKLINE>\n\nThe persistent ids can be loaded if we define and register\na IPersistentIdLoader adapter first:\n\n    >>> class PersistentIdLoader(object):\n    ...     interface.implements(interfaces.IPersistentIdLoader)\n    ...     component.adapts(interfaces.IUnpickler)\n    ...     def __init__(self, unpickler):\n    ...         self.unpickler = unpickler\n    ...     def load(self, id):\n    ...         global globalIds\n    ...         return globalIds.resolve(id)\n\n    >>> component.provideAdapter(PersistentIdLoader)\n    >>> c2 = interfaces.IUnpickler(None).loads(xml)\n    >>> c2.part1 == a\n    True\n\n\nAnnotations, Extras, and Metadata\n=================================\n\nComplex objects often combine metadata and content data in various ways.\nThe fssync package allows to distinguish between file content, extras,\nannotations, and fssync specific metadata:\n\n    - The file content or body is directly stored in a corresponding\n      file.\n    - The extras are object attributes which are part of the object but not\n      part of the file content. They are typically store in extra files.\n    - Annotations are content related metadata which can be stored as\n      attribute annotations or outside the object itself. They are typically\n      stored in seperate pickles for each annotation namespace.\n    - Metadata directly related to fssync are stored in Entries.xml\n      files.\n\nWhere exactly these aspects are stored is defined in the\nsynchronization format. The default format uses a @@Zope directory with\nsubdirectories for object extras and annotations. These @@Zope directories\nalso contain an Entries.xml metadata file which defines the following\nattributes:\n\n    - id: the system id of the object, in Zope typically a traversal path\n    - name: the filename of the serialized object\n    - factory: the factory of the object, typically a dotted name of a class\n    - type: a type identifier for pickled objects without factory\n    - provides: directly provided interfaces of the object\n    - key: the original name in the content space which is used\n           in cases where the repository is not able to store this key\n           unambigously\n    - binary: a flag that prevents merging of binary data\n    - flag: a status flag with the values 'added' or 'removed'\n\nIn part the metadata have to be delivered by the synchronizer. The base\nsynchronizer, for instance, returns the directly provided interfaces\nof an object as part of it's metadata:\n\n    >>> class IMarkerInterface(interface.Interface):\n    ...     pass\n    >>> interface.directlyProvides(a, IMarkerInterface)\n    >>> pprint(synchronizer.Synchronizer(a).metadata())\n    {'factory': 'zope.fssync.doctest.A',\n     'provides': 'zope.fssync.doctest.IMarkerInterface'}\n\nThe setmetadata method can be used to write metadata\nback to an object. Which metadata are consumed is up to the\nsynchronizer:\n\n    >>> metadata = {'provides': 'zope.fssync.doctest.IMarkerInterface'}\n    >>> synchronizer.Synchronizer(b).setmetadata(metadata)\n    >>> [x for x in interface.directlyProvidedBy(b)]\n    [<InterfaceClass zope.fssync.doctest.IMarkerInterface>]\n\nIn order to serialize annotations we must first provide a\nISynchronizableAnnotations adapter:\n\n    >>> snarf = repository.SnarfRepository(StringIO())\n    >>> checkout = task.Checkout(synchronizer.getSynchronizer, snarf)\n\n    >>> from zope import annotation\n    >>> from zope.annotation.attribute import AttributeAnnotations\n    >>> component.provideAdapter(AttributeAnnotations)\n    >>> class IAnnotatableSample(interface.Interface):\n    ...     pass\n    >>> class AnnotatableSample(object):\n    ...     interface.implements(IAnnotatableSample,\n    ...                             annotation.interfaces.IAttributeAnnotatable)\n    ...     data = 'Main file content'\n    ...     extra = None\n    >>> sample = AnnotatableSample()\n\n    >>> class ITestAnnotations(interface.Interface):\n    ...     a = interface.Attribute('A')\n    ...     b = interface.Attribute('B')\n    >>> import persistent\n    >>> class TestAnnotations(persistent.Persistent):\n    ...     interface.implements(ITestAnnotations,\n    ...                             annotation.interfaces.IAnnotations)\n    ...     component.adapts(IAnnotatableSample)\n    ...     def __init__(self):\n    ...         self.a = None\n    ...         self.b = None\n\n    >>> component.provideAdapter(synchronizer.SynchronizableAnnotations)\n\n\n\n    >>> from zope.annotation.factory import factory\n    >>> component.provideAdapter(factory(TestAnnotations))\n    >>> ITestAnnotations(sample).a = 'annotation a'\n    >>> ITestAnnotations(sample).a\n    'annotation a'\n    >>> sample.extra = 'extra'\n\nWithout a special serializer the annotations are pickled since\nthe annotations are stored in the __annotions__ attribute:\n\n    >>> root = dict()\n    >>> root['test'] = sample\n    >>> checkout.perform(root, 'test')\n    >>> print snarf.stream.getvalue()\n    00000197 @@Zope/Entries.xml\n    <?xml version='1.0' encoding='utf-8'?>\n    <entries>\n      <entry name=\"test\"\n             keytype=\"__builtin__.str\"\n             type=\"__builtin__.dict\"\n             factory=\"__builtin__.dict\"\n             />\n    </entries>\n    00000182 test/@@Zope/Entries.xml\n    <?xml version='1.0' encoding='utf-8'?>\n    <entries>\n      <entry name=\"test\"\n             keytype=\"__builtin__.str\"\n             type=\"zope.fssync.doctest.AnnotatableSample\"\n             />\n    </entries>\n    00001929 test/test\n    <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n    <pickle>\n      <object>\n        <klass>\n          <global name=\"AnnotatableSample\" module=\"zope.fssync.doctest\"/>\n        </klass>\n        ...\n        </attributes>\n      </object>\n    </pickle>\n    <BLANKLINE>\n\nIf we provide a directory serializer for annotations and extras we get a\nfile for each extra attribute and annotation namespace.\n\n    >>> component.provideUtility(\n    ...     synchronizer.DirectorySynchronizer,\n    ...     interfaces.ISynchronizerFactory,\n    ...     name=synchronizer.dottedname(synchronizer.Extras))\n\n    >>> component.provideUtility(\n    ...     synchronizer.DirectorySynchronizer,\n    ...     interfaces.ISynchronizerFactory,\n    ...     name=synchronizer.dottedname(\n    ...                 synchronizer.SynchronizableAnnotations))\n\nSince the annotations are already handled by the Synchronizer base class\nwe only need to specify the extra attribute here:\n\n    >>> class SampleFileSynchronizer(synchronizer.Synchronizer):\n    ...     interface.implements(interfaces.IFileSynchronizer)\n    ...     def dump(self, writeable):\n    ...         writeable.write(self.context.data)\n    ...     def extras(self):\n    ...         return synchronizer.Extras(extra=self.context.extra)\n    ...     def load(self, readable):\n    ...         self.context.data = readable.read()\n    >>> component.provideUtility(SampleFileSynchronizer,\n    ...     interfaces.ISynchronizerFactory,\n    ...     name=synchronizer.dottedname(AnnotatableSample))\n\n    >>> interface.directlyProvides(sample, IMarkerInterface)\n    >>> root['test'] = sample\n    >>> checkout.perform(root, 'test')\n    >>> print snarf.stream.getvalue()\n    00000197 @@Zope/Entries.xml\n    <?xml version='1.0' encoding='utf-8'?>\n    <entries>\n      <entry name=\"test\"\n             keytype=\"__builtin__.str\"\n             type=\"__builtin__.dict\"\n             factory=\"__builtin__.dict\"\n             />\n    </entries>\n    00000182 test/@@Zope/Entries.xml\n    <?xml version='1.0' encoding='utf-8'?>\n    <entries>\n      <entry name=\"test\"\n             keytype=\"__builtin__.str\"\n             type=\"zope.fssync.doctest.AnnotatableSample\"\n             />\n    </entries>\n    00001929 test/test\n    <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n    <pickle>\n      <object>\n        <klass>\n          <global name=\"AnnotatableSample\" module=\"zope.fssync.doctest\"/>\n        </klass>\n        <attributes>\n          <attribute name=\"__annotations__\">\n              ...\n          </attribute>\n          <attribute name=\"extra\">\n              <string>extra</string>\n          </attribute>\n        </attributes>\n      </object>\n    </pickle>\n    00000197 @@Zope/Entries.xml\n    <?xml version='1.0' encoding='utf-8'?>\n    <entries>\n      <entry name=\"test\"\n             keytype=\"__builtin__.str\"\n             type=\"__builtin__.dict\"\n             factory=\"__builtin__.dict\"\n             />\n    </entries>\n    00000296 test/@@Zope/Entries.xml\n    <?xml version='1.0' encoding='utf-8'?>\n    <entries>\n      <entry name=\"test\"\n             keytype=\"__builtin__.str\"\n             type=\"zope.fssync.doctest.AnnotatableSample\"\n             factory=\"zope.fssync.doctest.AnnotatableSample\"\n             provides=\"zope.fssync.doctest.IMarkerInterface\"\n             />\n    </entries>\n    00000211 test/@@Zope/Annotations/test/@@Zope/Entries.xml\n    <?xml version='1.0' encoding='utf-8'?>\n    <entries>\n      <entry name=\"zope.fssync.doctest.TestAnnotations\"\n             keytype=\"__builtin__.str\"\n             type=\"zope.fssync.doctest.TestAnnotations\"\n             />\n    </entries>\n    00000617 test/@@Zope/Annotations/test/zope.fssync.doctest.TestAnnotations\n    <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n    <pickle>\n    ...\n    </pickle>\n    00000161 test/@@Zope/Extra/test/@@Zope/Entries.xml\n    <?xml version='1.0' encoding='utf-8'?>\n    <entries>\n      <entry name=\"extra\"\n             keytype=\"__builtin__.str\"\n             type=\"__builtin__.str\"\n             />\n    </entries>\n    00000082 test/@@Zope/Extra/test/extra\n    <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n    <pickle> <string>extra</string> </pickle>\n    00000017 test/test\n    Main file content\n\nThe annotations and extras can of course also be deserialized. The default\ndeserializer handles both cases:\n\n    >>> target = {}\n    >>> commit = task.Commit(synchronizer.getSynchronizer, snarf)\n    >>> commit.perform(target, 'root', 'test')\n    >>> result = target['root']['test']\n    >>> result.extra\n    'extra'\n    >>> ITestAnnotations(result).a\n    'annotation a'\n\nSince we use an IDirectorySynchronizer each extra attribute and\nannotation namespace get's it's own file:\n\n    >>> for path in sorted(snarf.iterPaths()):\n    ...     print path\n    @@Zope/Entries.xml\n    test/@@Zope/Annotations/test/@@Zope/Entries.xml\n    test/@@Zope/Annotations/test/zope.fssync.doctest.TestAnnotations\n    test/@@Zope/Entries.xml\n    test/@@Zope/Extra/test/@@Zope/Entries.xml\n    test/@@Zope/Extra/test/extra\n    test/test\n\nThe number of files can be reduced if we provide the default synchronizer\nwhich uses a single file for all annotations and a single file for\nall extras:\n\n    >>> component.provideUtility(\n    ...     synchronizer.DefaultSynchronizer,\n    ...     interfaces.ISynchronizerFactory,\n    ...     name=synchronizer.dottedname(synchronizer.Extras))\n\n    >>> component.provideUtility(\n    ...     synchronizer.DefaultSynchronizer,\n    ...     interfaces.ISynchronizerFactory,\n    ...     name=synchronizer.dottedname(\n    ...                 synchronizer.SynchronizableAnnotations))\n\n    >>> root['test'] = sample\n    >>> snarf = repository.SnarfRepository(StringIO())\n    >>> checkout.repository = snarf\n    >>> checkout.perform(root, 'test')\n    >>> for path in sorted(snarf.iterPaths()):\n    ...     print path\n    @@Zope/Entries.xml\n    test/@@Zope/Annotations/test\n    test/@@Zope/Entries.xml\n    test/@@Zope/Extra/test\n    test/test\n\nThe annotations and extras can of course also be deserialized. The default\ndeserializer handles both\n\n    >>> target = {}\n    >>> commit = task.Commit(synchronizer.getSynchronizer, snarf)\n    >>> commit.perform(target, 'root', 'test')\n    >>> result = target['root']['test']\n    >>> result.extra\n    'extra'\n    >>> ITestAnnotations(result).a\n    'annotation a'\n    >>> [x for x in interface.directlyProvidedBy(result)]\n    [<InterfaceClass zope.fssync.doctest.IMarkerInterface>]\n\nIf we encounter an error, or multiple errors, while commiting we'll\nsee them in the traceback.\n\n    >>> def bad_sync(container, key, fspath, add_callback):\n    ...     raise ValueError('1','2','3')\n\n    >>> target = {}\n    >>> commit = task.Commit(synchronizer.getSynchronizer, snarf)\n    >>> old_sync_new = commit.synchNew\n    >>> commit.synchNew = bad_sync\n    >>> commit.perform(target, 'root', 'test')\n    Traceback (most recent call last):\n        ...\n    Exception: test: '1', '2', '3'\n\nNotice that if we encounter multiple exceptions we print them all\nout at the end.\n\n    >>> old_sync_old = commit.synchOld\n    >>> commit.synchOld = bad_sync\n    >>> commit.perform(target, 'root', 'test')\n    Traceback (most recent call last):\n        ...\n    Exceptions:\n        test: '1', '2', '3'\n        test: '1', '2', '3'\n\n    >>> commit.synchNew = old_sync_new\n    >>> commit.synchOld = old_sync_old\n\n\nChanges\n=======\n\n3.6.1 (2013-05-02)\n------------------\n\n- Fixed exception raising on unpickling errors when checking in.\n\n- Improved reporting of unpickling errors.\n\n\n3.6.0 (2012-03-15)\n------------------\n\n- Commit task will collect errors and send them all back rather\n  than stopping on the first error encountered.\n\n\n3.5.2 (2010-10-18)\n------------------\n\n- Fix tests; zope.location no longer exports TLocation.\n\n- Raise the right error in zope.fssync.synchronizer when the configured\n  synchronizer does not exist.\n\n- Update dependency information.\n\n- Minor code cleanups.\n\n\n3.5.1 (2009-07-24)\n------------------\n\n- Properly setup tests, so that they will work in a release as well.\n\n- Removed slugs.\n\n3.5 (????)\n----------\n\n- Added the support for empty directories in snarf format. Now\n  directories can be explicitly described by snarf.\n\n- Synchronizers can now return callbacks from the load\n  method. This allows for fix ups to be run later. This is useful\n  when adding multiple objects at the same time that depend on\n  each other. Callbacks can in turn return callbacks.\n\n- Add support to FSMerger to allow locally modified files to be\n  overwritten by files returned from the server. The purpose of\n  this is to avoid conflicts after commit on files that are\n  formatted differently on the server from local versions.\n\n3.4.0b1 (????)\n--------------\n\nRefactoring of zope.fssync and zope.app.fssync into two clearly\nseparated packages:\n\n- zope.fssync contains now a Python API that has no critical dependencies\n  on Zope, the ZODB, and the security machinery.\n\n- zope.app.fssync contains a protected web-based API and special\n  synchronizers for zope.app content types.\n\nOther major changes are\n\n- synchronizers (i.e. serialization/de-serialization adapters) are created\n  by named utilities which use dotted class names as lookup keys\n\n- added doctests\n\n- support for large files\n\n- adapters for pickler, unpickler and handling of persistent pickle ids\n\n- binaries are no longer merged\n\n- case-insensitive filesystems and repositories use disambiguated names on\n  export and the original names on import\n\n- export and import of directly provided interfaces\n\n- direct export to archives/direct import from archives\n\n- addressed encoding problems on Mac OSX", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://pypi.python.org/pypi/zope.fssync", "keywords": "zope3 serialization synchronization", "license": "ZPL 2.1", "maintainer": null, "maintainer_email": null, "name": "zope.fssync", "package_url": "https://pypi.org/project/zope.fssync/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/zope.fssync/", "project_urls": {"Download": "UNKNOWN", "Homepage": "http://pypi.python.org/pypi/zope.fssync"}, "release_url": "https://pypi.org/project/zope.fssync/3.6.1/", "requires_dist": null, "requires_python": null, "summary": "Filesystem synchronization utility for Zope 3.", "version": "3.6.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"zope-fssync-package\">\n<h2>zope.fssync Package</h2>\n<p>This package provides filesystem synchronization utilities for Zope\n3. It is used by the zope.app.fssync package.</p>\n</div>\n<div id=\"filesystem-synchronization\">\n<h2>Filesystem Synchronization</h2>\n<p>This package provides an API for the synchronization of Python objects\nwith a serialized filesystem representation. This API does not address\nsecurity issues. (See zope.app.fssync for a protected web-based API).\nThis API is Zope and ZODB independent.</p>\n<p>The main use cases are</p>\n<blockquote>\n<ul>\n<li>data export / import (e.g. moving data from one place to another)</li>\n<li>content management (e.g. managing a wiki or other collections of\ndocuments offline)</li>\n</ul>\n</blockquote>\n<p>The target representation depends on your use case. In the use case of\ndata export/import, for instance, it is crucial that all data are\nexported as completely as possible. Since the data need not be read\nby humans in most circumstances a pickle format may be the most\ncomplete and easy one to use.\nIn the use case of content management it may be more important that\nall metadata are readable by humans. In this case another format,\ne.g. RDFa, may be more appropriate.</p>\n<div id=\"main-components\">\n<h3>Main components</h3>\n<p>A synchronizer serializes content objects and stores the serialized\ndata in a repository in an application specific format. It uses\ndeserializers to read the object back into the content space.\nThe serialization format must be rich enough to preserve various forms\nof references which should be reestablished on deserialization.</p>\n<p>All these components should be replaceable. Application may use\ndifferent serialization formats with different references for\ndifferent purposes (e.g. backup vs. content management) and different\ntarget systems (e.g. a zip archive vs. a svn repository).</p>\n<p>The main components are:</p>\n<blockquote>\n<ul>\n<li>ISyncTasks like Checkout, Check, and Commit which synchronize\na content space with a repository. These tasks uses serializers\nto produce serialized data for a repository in an application\nspecific format. They use deserializers to read the data back.\nThe default implementation uses xmlpickle for python objects,\ndata streams for file contents, and special directories for\nextras and metadata. Alternative implementations may use\nstandard pickles, a human readable format like RDFa, or\napplication specific formats.</li>\n<li>ISynchronizer: Synchronizers produce serialized pieces of a\nPython object (the ISerializer part of a synchronizer) and\nconsume serialized data to (re-)create Python objects (the\nIDeserializer part of a synchronizer).</li>\n<li>IPickler: An adapter that determines the pickle format.</li>\n<li>IRepository: represents a target system that can be used\nto read and write serialized data.</li>\n</ul>\n</blockquote>\n<p>Let\u2019s take some samples:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; from StringIO import StringIO\n&gt;&gt;&gt; from zope import interface\n&gt;&gt;&gt; from zope import component\n&gt;&gt;&gt; from zope.fssync import interfaces\n&gt;&gt;&gt; from zope.fssync import task\n&gt;&gt;&gt; from zope.fssync import synchronizer\n&gt;&gt;&gt; from zope.fssync import repository\n&gt;&gt;&gt; from zope.fssync import pickle\n</pre>\n<pre>&gt;&gt;&gt; class A(object):\n...     data = 'data of a'\n&gt;&gt;&gt; class B(A):\n...     pass\n&gt;&gt;&gt; a = A()\n&gt;&gt;&gt; b = B()\n&gt;&gt;&gt; b.data = 'data of b'\n&gt;&gt;&gt; b.extra = 'extra of b'\n&gt;&gt;&gt; root = dict(a=a, b=b)\n</pre>\n</blockquote>\n</div>\n<div id=\"persistent-references\">\n<h3>Persistent References</h3>\n<p>Many applications use more than one system of persistent references.\nZope, for instance, uses p_oids, int ids, key references,\ntraversal paths, dotted names, named utilities, etc.</p>\n<p>Other systems might use generic reference systems like global unique\nids or primary keys together with domain specific references, like\nemails, URI, postal addresses, code numbers, etc.\nAll these references are candidates for exportable references as long\nas they can be resolved on import or reimport.</p>\n<p>In our example we use simple integer ids:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; class GlobalIds(object):\n...     ids = dict()\n...     count = 0\n...     def getId(self, obj):\n...         for k, v in self.ids.iteritems():\n...             if obj == v:\n...                 return k\n...     def register(self, obj):\n...         uid = self.getId(obj)\n...         if uid is not None:\n...             return uid\n...         self.count += 1\n...         self.ids[self.count] = obj\n...         return self.count\n...     def resolve(self, uid):\n...         return self.ids.get(int(uid), None)\n</pre>\n<pre>&gt;&gt;&gt; globalIds = GlobalIds()\n&gt;&gt;&gt; globalIds.register(a)\n1\n&gt;&gt;&gt; globalIds.register(b)\n2\n&gt;&gt;&gt; globalIds.register(root)\n3\n</pre>\n</blockquote>\n<p>In our example we use the int ids as a substitute for the default path\nreferences which are the most common references in Zope.</p>\n<p>In our examples we use a SnarfRepository which can easily be examined:</p>\n<pre>&gt;&gt;&gt; snarf = repository.SnarfRepository(StringIO())\n&gt;&gt;&gt; checkout = task.Checkout(synchronizer.getSynchronizer, snarf)\n</pre>\n<p>Snarf is a Zope3 specific archive format where the key\nneed is for simple software. The format is dead simple: each file\nis represented by the string</p>\n<blockquote>\n\u2018&lt;size&gt; &lt;pathname&gt;n\u2019</blockquote>\n<p>followed by exactly &lt;size&gt; bytes.  Directories are not represented\nexplicitly.</p>\n</div>\n<div id=\"entry-ids\">\n<h3>Entry Ids</h3>\n<p>Persistent ids are also used in the metadata files of fssync.\nThe references are generated by an IEntryId adapter which must\nhave a string representation in order to be saveable in a text file.\nTypically these object ids correspond to the persistent pickle ids, but\nthis is not necessarily the case.</p>\n<p>Since we do not have paths we use our integer ids:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; @component.adapter(interface.Interface)\n... @interface.implementer(interfaces.IEntryId)\n... def entryId(obj):\n...     global globalIds\n...     return globalIds.getId(obj)\n&gt;&gt;&gt; component.provideAdapter(entryId)\n</pre>\n</blockquote>\n</div>\n<div id=\"synchronizer\">\n<h3>Synchronizer</h3>\n<p>In the use case of data export / import it is crucial that fssync is\nable to serialize \u201call\u201d object data. Note that it isn\u2019t always obvious\nwhat data is intrinsic to an object. Therefore we must provide\nspecial serialization / de-serialization tools which take care of\nwriting and reading \u201call\u201d data.</p>\n<p>An obvious solution would be to use inheriting synchronization\nadapters. But this solution bears a risk. If someone created a subclass\nand forgot to create an adapter, then their data would be serialized\nincompletely. To give an example: What happens if someone has a\nserialization adapter for class Person which serializes every aspect of\nPerson instances and defines a subclass Employee(Person) later on?\nIf the Employee class has some extra aspects (for example additional\nattributes like insurance id, wage, etc.) these would never be serialized\nas long as there is no special serialization adapter for Employees\nwhich handles this extra aspects. The behavior is different if the\nadapters are looked up by their dotted class name (i.e. the most specific\nclass) and not their class or interface (which might led to adapters\nwritten for super classes). If no specific adapter exists a default\nserializer (e.g a xmlpickler) can serialize the object completely. So\neven if you forget to provide special serializers for all your classes\nyou can be sure that your data are complete.</p>\n<p>Since the component architecture doesn\u2019t support adapters that work\none class only (not their subclasses), we register the adapter classes\nas named ISynchronizerFactory utilities and use the dotted name of the\nclass as lookup key. The default synchronizer is registered as a\nunnamed ISynchronizerFactory utility. This synchronizer ensures that\nall data are pickled to the target repository.</p>\n<blockquote>\n<pre>&gt;&gt;&gt; component.provideUtility(synchronizer.DefaultSynchronizer,\n...                             provides=interfaces.ISynchronizerFactory)\n</pre>\n</blockquote>\n<p>All special synchronizers are registered for a specific content class and\nnot an abstract interface. The class is represented by the dotted class\nname in the factory registration:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; class AFileSynchronizer(synchronizer.Synchronizer):\n...     interface.implements(interfaces.IFileSynchronizer)\n...     def dump(self, writeable):\n...         writeable.write(self.context.data)\n...     def load(self, readable):\n...         self.context.data = readable.read()\n</pre>\n<pre>&gt;&gt;&gt; component.provideUtility(AFileSynchronizer,\n...                             interfaces.ISynchronizerFactory,\n...                             name=synchronizer.dottedname(A))\n</pre>\n</blockquote>\n<p>The lookup of the utilities by the dotted class name is handled\nby the getSynchronizer function, which first tries to find\na named utility. The IDefaultSynchronizer utility is used as a fallback:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; synchronizer.getSynchronizer(a)\n&lt;zope.fssync.doctest.AFileSynchronizer object at ...&gt;\n</pre>\n</blockquote>\n<p>If no named adapter is registered it returns the registered unnamed default\nadapter (as long as the permissions allow this):</p>\n<blockquote>\n<pre>&gt;&gt;&gt; synchronizer.getSynchronizer(b)\n&lt;zope.fssync.synchronizer.DefaultSynchronizer object at ...&gt;\n</pre>\n</blockquote>\n<p>This default serializer typically uses a pickle format, which is determined\nby the IPickler adapter. Here we use Zope\u2019s xmlpickle.</p>\n<blockquote>\n<pre>&gt;&gt;&gt; component.provideAdapter(pickle.XMLPickler)\n&gt;&gt;&gt; component.provideAdapter(pickle.XMLUnpickler)\n</pre>\n</blockquote>\n<p>For container like objects we must provide an adapter that maps the\ncontainer to a directory. In our example we use the buildin dict class:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; component.provideUtility(synchronizer.DirectorySynchronizer,\n...                             interfaces.ISynchronizerFactory,\n...                             name=synchronizer.dottedname(dict))\n</pre>\n</blockquote>\n<p>Now we can export the object to the snarf archive:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; checkout.perform(root, 'test')\n&gt;&gt;&gt; print snarf.stream.getvalue()\n00000213 @@Zope/Entries.xml\n&lt;?xml version='1.0' encoding='utf-8'?&gt;\n&lt;entries&gt;\n  &lt;entry name=\"test\"\n         keytype=\"__builtin__.str\"\n         type=\"__builtin__.dict\"\n         factory=\"__builtin__.dict\"\n         id=\"3\"\n         /&gt;\n&lt;/entries&gt;\n00000339 test/@@Zope/Entries.xml\n&lt;?xml version='1.0' encoding='utf-8'?&gt;\n&lt;entries&gt;\n  &lt;entry name=\"a\"\n         keytype=\"__builtin__.str\"\n         type=\"zope.fssync.doctest.A\"\n         factory=\"zope.fssync.doctest.A\"\n         id=\"1\"\n         /&gt;\n  &lt;entry name=\"b\"\n         keytype=\"__builtin__.str\"\n         type=\"zope.fssync.doctest.B\"\n         id=\"2\"\n         /&gt;\n&lt;/entries&gt;\n00000009 test/a\ndata of a00000370 test/b\n&lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt;\n&lt;pickle&gt;\n  &lt;object&gt;\n    &lt;klass&gt;\n      &lt;global name=\"B\" module=\"zope.fssync.doctest\"/&gt;\n    &lt;/klass&gt;\n    &lt;attributes&gt;\n      &lt;attribute name=\"data\"&gt;\n          &lt;string&gt;data of b&lt;/string&gt;\n      &lt;/attribute&gt;\n      &lt;attribute name=\"extra\"&gt;\n          &lt;string&gt;extra of b&lt;/string&gt;\n      &lt;/attribute&gt;\n    &lt;/attributes&gt;\n  &lt;/object&gt;\n&lt;/pickle&gt;\n&lt;BLANKLINE&gt;\n</pre>\n</blockquote>\n<p>After the registration of the necessary generators we can reimport the\nserialized data from the repository:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; component.provideUtility(synchronizer.FileGenerator(),\n...                                 provides=interfaces.IFileGenerator)\n</pre>\n<pre>&gt;&gt;&gt; target = {}\n&gt;&gt;&gt; commit = task.Commit(synchronizer.getSynchronizer, snarf)\n&gt;&gt;&gt; commit.perform(target, 'root', 'test')\n&gt;&gt;&gt; sorted(target.keys())\n['root']\n&gt;&gt;&gt; sorted(target['root'].keys())\n['a', 'b']\n</pre>\n<pre>&gt;&gt;&gt; target['root']['a'].data\n'data of a'\n</pre>\n<pre>&gt;&gt;&gt; target['root']['b'].extra\n'extra of b'\n</pre>\n</blockquote>\n<p>If we want to commit the data back into the original place we must check\nwhether the repository is still consistent with the original content.\nWe modify the objects in place to see what happens:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; check = task.Check(synchronizer.getSynchronizer, snarf)\n&gt;&gt;&gt; check.check(root, '', 'test')\n&gt;&gt;&gt; check.errors()\n[]\n</pre>\n<pre>&gt;&gt;&gt; root['a'].data = 'overwritten'\n&gt;&gt;&gt; root['b'].extra = 'overwritten'\n</pre>\n<pre>&gt;&gt;&gt; check = task.Check(synchronizer.getSynchronizer, snarf)\n&gt;&gt;&gt; check.check(root, '', 'test')\n&gt;&gt;&gt; check.errors()\n['test/a', 'test/b']\n</pre>\n<pre>&gt;&gt;&gt; commit.perform(root, '', 'test')\n&gt;&gt;&gt; sorted(root.keys())\n['a', 'b']\n&gt;&gt;&gt; root['a'].data\n'data of a'\n&gt;&gt;&gt; root['b'].extra\n'extra of b'\n</pre>\n<pre>&gt;&gt;&gt; del root['a']\n&gt;&gt;&gt; commit.perform(root, '', 'test')\n&gt;&gt;&gt; sorted(root.keys())\n['a', 'b']\n</pre>\n<pre>&gt;&gt;&gt; del root['b']\n&gt;&gt;&gt; commit.perform(root, '', 'test')\n&gt;&gt;&gt; sorted(root.keys())\n['a', 'b']\n</pre>\n<pre>&gt;&gt;&gt; del root['a']\n&gt;&gt;&gt; del root['b']\n&gt;&gt;&gt; commit.perform(root, '', 'test')\n&gt;&gt;&gt; sorted(root.keys())\n['a', 'b']\n</pre>\n</blockquote>\n</div>\n<div id=\"pickling\">\n<h3>Pickling</h3>\n<p>In many data structures, large, complex objects are composed of\nsmaller objects.  These objects are typically stored in one of two\nways:</p>\n<blockquote>\n<ol>\n<li>The smaller objects are stored inside the larger object.</li>\n<li>The smaller objects are allocated in their own location,\nand the larger object stores references to them.</li>\n</ol>\n</blockquote>\n<p>In case 1 the object is self-contained and can be pickled\ncompletely. This is the default behavior of the fssync pickler:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; pickler = interfaces.IPickler([42])\n&gt;&gt;&gt; pickler\n&lt;zope.fssync.pickle.XMLPickler object at ...&gt;\n&gt;&gt;&gt; print pickler.dumps()\n&lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt;\n&lt;pickle&gt;\n  &lt;list&gt;\n    &lt;int&gt;42&lt;/int&gt;\n  &lt;/list&gt;\n&lt;/pickle&gt;\n&lt;BLANKLINE&gt;\n</pre>\n</blockquote>\n<p>Case 2 is more complex since the pickler has to take persistent\nreferences into account.</p>\n<blockquote>\n<pre>&gt;&gt;&gt; class Complex(object):\n...     def __init__(self, part1, part2):\n...         self.part1 = part1\n...         self.part2 = part2\n</pre>\n</blockquote>\n<p>Everthing here depends on the definition of what we consider to be an intrinsic\nreference. In the examples above we simply considered all objects as intrinsic.</p>\n<blockquote>\n<pre>&gt;&gt;&gt; from zope.fssync import pickle\n&gt;&gt;&gt; c = root['c'] = Complex(a, b)\n&gt;&gt;&gt; stream = StringIO()\n&gt;&gt;&gt; print interfaces.IPickler(c).dumps()\n&lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt;\n&lt;pickle&gt;\n  &lt;initialized_object&gt;\n    &lt;klass&gt;\n      &lt;global id=\"o0\" name=\"_reconstructor\" module=\"copy_reg\"/&gt;\n    &lt;/klass&gt;\n    &lt;arguments&gt;\n      &lt;tuple&gt;\n        &lt;global name=\"Complex\" module=\"zope.fssync.doctest\"/&gt;\n        &lt;global id=\"o1\" name=\"object\" module=\"__builtin__\"/&gt;\n        &lt;none/&gt;\n      &lt;/tuple&gt;\n    &lt;/arguments&gt;\n    &lt;state&gt;\n      &lt;dictionary&gt;\n        &lt;item key=\"part1\"&gt;\n            &lt;object&gt;\n              &lt;klass&gt;\n                &lt;global name=\"A\" module=\"zope.fssync.doctest\"/&gt;\n              &lt;/klass&gt;\n              &lt;attributes&gt;\n                &lt;attribute name=\"data\"&gt;\n                    &lt;string&gt;data of a&lt;/string&gt;\n                &lt;/attribute&gt;\n              &lt;/attributes&gt;\n            &lt;/object&gt;\n        &lt;/item&gt;\n        &lt;item key=\"part2\"&gt;\n            &lt;object&gt;\n              &lt;klass&gt;\n                &lt;global name=\"B\" module=\"zope.fssync.doctest\"/&gt;\n              &lt;/klass&gt;\n              &lt;attributes&gt;\n                &lt;attribute name=\"data\"&gt;\n                    &lt;string&gt;data of b&lt;/string&gt;\n                &lt;/attribute&gt;\n                &lt;attribute name=\"extra\"&gt;\n                    &lt;string&gt;overwritten&lt;/string&gt;\n                &lt;/attribute&gt;\n              &lt;/attributes&gt;\n            &lt;/object&gt;\n        &lt;/item&gt;\n      &lt;/dictionary&gt;\n    &lt;/state&gt;\n  &lt;/initialized_object&gt;\n&lt;/pickle&gt;\n&lt;BLANKLINE&gt;\n</pre>\n</blockquote>\n<p>In order to use persistent references we must define a\nPersistentIdGenerator for our pickler, which determines whether\nan object should be pickled completely or only by reference:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; class PersistentIdGenerator(object):\n...     interface.implements(interfaces.IPersistentIdGenerator)\n...     component.adapts(interfaces.IPickler)\n...     def __init__(self, pickler):\n...         self.pickler = pickler\n...     def id(self, obj):\n...         if isinstance(obj, Complex):\n...             return None\n...         return globalIds.getId(obj)\n</pre>\n<pre>&gt;&gt;&gt; component.provideAdapter(PersistentIdGenerator)\n</pre>\n<pre>&gt;&gt;&gt; globalIds.register(a)\n1\n&gt;&gt;&gt; globalIds.register(b)\n2\n&gt;&gt;&gt; globalIds.register(root)\n3\n</pre>\n<pre>&gt;&gt;&gt; xml = interfaces.IPickler(c).dumps()\n&gt;&gt;&gt; print xml\n&lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt;\n&lt;pickle&gt;\n  &lt;object&gt;\n    &lt;klass&gt;\n      &lt;global name=\"Complex\" module=\"zope.fssync.doctest\"/&gt;\n    &lt;/klass&gt;\n    &lt;attributes&gt;\n      &lt;attribute name=\"part1\"&gt;\n          &lt;persistent&gt; &lt;string&gt;1&lt;/string&gt; &lt;/persistent&gt;\n      &lt;/attribute&gt;\n      &lt;attribute name=\"part2\"&gt;\n          &lt;persistent&gt; &lt;string&gt;2&lt;/string&gt; &lt;/persistent&gt;\n      &lt;/attribute&gt;\n    &lt;/attributes&gt;\n  &lt;/object&gt;\n&lt;/pickle&gt;\n&lt;BLANKLINE&gt;\n</pre>\n</blockquote>\n<p>The persistent ids can be loaded if we define and register\na IPersistentIdLoader adapter first:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; class PersistentIdLoader(object):\n...     interface.implements(interfaces.IPersistentIdLoader)\n...     component.adapts(interfaces.IUnpickler)\n...     def __init__(self, unpickler):\n...         self.unpickler = unpickler\n...     def load(self, id):\n...         global globalIds\n...         return globalIds.resolve(id)\n</pre>\n<pre>&gt;&gt;&gt; component.provideAdapter(PersistentIdLoader)\n&gt;&gt;&gt; c2 = interfaces.IUnpickler(None).loads(xml)\n&gt;&gt;&gt; c2.part1 == a\nTrue\n</pre>\n</blockquote>\n</div>\n<div id=\"annotations-extras-and-metadata\">\n<h3>Annotations, Extras, and Metadata</h3>\n<p>Complex objects often combine metadata and content data in various ways.\nThe fssync package allows to distinguish between file content, extras,\nannotations, and fssync specific metadata:</p>\n<blockquote>\n<ul>\n<li>The file content or body is directly stored in a corresponding\nfile.</li>\n<li>The extras are object attributes which are part of the object but not\npart of the file content. They are typically store in extra files.</li>\n<li>Annotations are content related metadata which can be stored as\nattribute annotations or outside the object itself. They are typically\nstored in seperate pickles for each annotation namespace.</li>\n<li>Metadata directly related to fssync are stored in Entries.xml\nfiles.</li>\n</ul>\n</blockquote>\n<p>Where exactly these aspects are stored is defined in the\nsynchronization format. The default format uses a @@Zope directory with\nsubdirectories for object extras and annotations. These @@Zope directories\nalso contain an Entries.xml metadata file which defines the following\nattributes:</p>\n<blockquote>\n<ul>\n<li>id: the system id of the object, in Zope typically a traversal path</li>\n<li>name: the filename of the serialized object</li>\n<li>factory: the factory of the object, typically a dotted name of a class</li>\n<li>type: a type identifier for pickled objects without factory</li>\n<li>provides: directly provided interfaces of the object</li>\n<li><dl>\n<dt>key: the original name in the content space which is used</dt>\n<dd>in cases where the repository is not able to store this key\nunambigously</dd>\n</dl>\n</li>\n<li>binary: a flag that prevents merging of binary data</li>\n<li>flag: a status flag with the values \u2018added\u2019 or \u2018removed\u2019</li>\n</ul>\n</blockquote>\n<p>In part the metadata have to be delivered by the synchronizer. The base\nsynchronizer, for instance, returns the directly provided interfaces\nof an object as part of it\u2019s metadata:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; class IMarkerInterface(interface.Interface):\n...     pass\n&gt;&gt;&gt; interface.directlyProvides(a, IMarkerInterface)\n&gt;&gt;&gt; pprint(synchronizer.Synchronizer(a).metadata())\n{'factory': 'zope.fssync.doctest.A',\n 'provides': 'zope.fssync.doctest.IMarkerInterface'}\n</pre>\n</blockquote>\n<p>The setmetadata method can be used to write metadata\nback to an object. Which metadata are consumed is up to the\nsynchronizer:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; metadata = {'provides': 'zope.fssync.doctest.IMarkerInterface'}\n&gt;&gt;&gt; synchronizer.Synchronizer(b).setmetadata(metadata)\n&gt;&gt;&gt; [x for x in interface.directlyProvidedBy(b)]\n[&lt;InterfaceClass zope.fssync.doctest.IMarkerInterface&gt;]\n</pre>\n</blockquote>\n<p>In order to serialize annotations we must first provide a\nISynchronizableAnnotations adapter:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; snarf = repository.SnarfRepository(StringIO())\n&gt;&gt;&gt; checkout = task.Checkout(synchronizer.getSynchronizer, snarf)\n</pre>\n<pre>&gt;&gt;&gt; from zope import annotation\n&gt;&gt;&gt; from zope.annotation.attribute import AttributeAnnotations\n&gt;&gt;&gt; component.provideAdapter(AttributeAnnotations)\n&gt;&gt;&gt; class IAnnotatableSample(interface.Interface):\n...     pass\n&gt;&gt;&gt; class AnnotatableSample(object):\n...     interface.implements(IAnnotatableSample,\n...                             annotation.interfaces.IAttributeAnnotatable)\n...     data = 'Main file content'\n...     extra = None\n&gt;&gt;&gt; sample = AnnotatableSample()\n</pre>\n<pre>&gt;&gt;&gt; class ITestAnnotations(interface.Interface):\n...     a = interface.Attribute('A')\n...     b = interface.Attribute('B')\n&gt;&gt;&gt; import persistent\n&gt;&gt;&gt; class TestAnnotations(persistent.Persistent):\n...     interface.implements(ITestAnnotations,\n...                             annotation.interfaces.IAnnotations)\n...     component.adapts(IAnnotatableSample)\n...     def __init__(self):\n...         self.a = None\n...         self.b = None\n</pre>\n<pre>&gt;&gt;&gt; component.provideAdapter(synchronizer.SynchronizableAnnotations)\n</pre>\n<pre>&gt;&gt;&gt; from zope.annotation.factory import factory\n&gt;&gt;&gt; component.provideAdapter(factory(TestAnnotations))\n&gt;&gt;&gt; ITestAnnotations(sample).a = 'annotation a'\n&gt;&gt;&gt; ITestAnnotations(sample).a\n'annotation a'\n&gt;&gt;&gt; sample.extra = 'extra'\n</pre>\n</blockquote>\n<p>Without a special serializer the annotations are pickled since\nthe annotations are stored in the __annotions__ attribute:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; root = dict()\n&gt;&gt;&gt; root['test'] = sample\n&gt;&gt;&gt; checkout.perform(root, 'test')\n&gt;&gt;&gt; print snarf.stream.getvalue()\n00000197 @@Zope/Entries.xml\n&lt;?xml version='1.0' encoding='utf-8'?&gt;\n&lt;entries&gt;\n  &lt;entry name=\"test\"\n         keytype=\"__builtin__.str\"\n         type=\"__builtin__.dict\"\n         factory=\"__builtin__.dict\"\n         /&gt;\n&lt;/entries&gt;\n00000182 test/@@Zope/Entries.xml\n&lt;?xml version='1.0' encoding='utf-8'?&gt;\n&lt;entries&gt;\n  &lt;entry name=\"test\"\n         keytype=\"__builtin__.str\"\n         type=\"zope.fssync.doctest.AnnotatableSample\"\n         /&gt;\n&lt;/entries&gt;\n00001929 test/test\n&lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt;\n&lt;pickle&gt;\n  &lt;object&gt;\n    &lt;klass&gt;\n      &lt;global name=\"AnnotatableSample\" module=\"zope.fssync.doctest\"/&gt;\n    &lt;/klass&gt;\n    ...\n    &lt;/attributes&gt;\n  &lt;/object&gt;\n&lt;/pickle&gt;\n&lt;BLANKLINE&gt;\n</pre>\n</blockquote>\n<p>If we provide a directory serializer for annotations and extras we get a\nfile for each extra attribute and annotation namespace.</p>\n<blockquote>\n<pre>&gt;&gt;&gt; component.provideUtility(\n...     synchronizer.DirectorySynchronizer,\n...     interfaces.ISynchronizerFactory,\n...     name=synchronizer.dottedname(synchronizer.Extras))\n</pre>\n<pre>&gt;&gt;&gt; component.provideUtility(\n...     synchronizer.DirectorySynchronizer,\n...     interfaces.ISynchronizerFactory,\n...     name=synchronizer.dottedname(\n...                 synchronizer.SynchronizableAnnotations))\n</pre>\n</blockquote>\n<p>Since the annotations are already handled by the Synchronizer base class\nwe only need to specify the extra attribute here:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; class SampleFileSynchronizer(synchronizer.Synchronizer):\n...     interface.implements(interfaces.IFileSynchronizer)\n...     def dump(self, writeable):\n...         writeable.write(self.context.data)\n...     def extras(self):\n...         return synchronizer.Extras(extra=self.context.extra)\n...     def load(self, readable):\n...         self.context.data = readable.read()\n&gt;&gt;&gt; component.provideUtility(SampleFileSynchronizer,\n...     interfaces.ISynchronizerFactory,\n...     name=synchronizer.dottedname(AnnotatableSample))\n</pre>\n<pre>&gt;&gt;&gt; interface.directlyProvides(sample, IMarkerInterface)\n&gt;&gt;&gt; root['test'] = sample\n&gt;&gt;&gt; checkout.perform(root, 'test')\n&gt;&gt;&gt; print snarf.stream.getvalue()\n00000197 @@Zope/Entries.xml\n&lt;?xml version='1.0' encoding='utf-8'?&gt;\n&lt;entries&gt;\n  &lt;entry name=\"test\"\n         keytype=\"__builtin__.str\"\n         type=\"__builtin__.dict\"\n         factory=\"__builtin__.dict\"\n         /&gt;\n&lt;/entries&gt;\n00000182 test/@@Zope/Entries.xml\n&lt;?xml version='1.0' encoding='utf-8'?&gt;\n&lt;entries&gt;\n  &lt;entry name=\"test\"\n         keytype=\"__builtin__.str\"\n         type=\"zope.fssync.doctest.AnnotatableSample\"\n         /&gt;\n&lt;/entries&gt;\n00001929 test/test\n&lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt;\n&lt;pickle&gt;\n  &lt;object&gt;\n    &lt;klass&gt;\n      &lt;global name=\"AnnotatableSample\" module=\"zope.fssync.doctest\"/&gt;\n    &lt;/klass&gt;\n    &lt;attributes&gt;\n      &lt;attribute name=\"__annotations__\"&gt;\n          ...\n      &lt;/attribute&gt;\n      &lt;attribute name=\"extra\"&gt;\n          &lt;string&gt;extra&lt;/string&gt;\n      &lt;/attribute&gt;\n    &lt;/attributes&gt;\n  &lt;/object&gt;\n&lt;/pickle&gt;\n00000197 @@Zope/Entries.xml\n&lt;?xml version='1.0' encoding='utf-8'?&gt;\n&lt;entries&gt;\n  &lt;entry name=\"test\"\n         keytype=\"__builtin__.str\"\n         type=\"__builtin__.dict\"\n         factory=\"__builtin__.dict\"\n         /&gt;\n&lt;/entries&gt;\n00000296 test/@@Zope/Entries.xml\n&lt;?xml version='1.0' encoding='utf-8'?&gt;\n&lt;entries&gt;\n  &lt;entry name=\"test\"\n         keytype=\"__builtin__.str\"\n         type=\"zope.fssync.doctest.AnnotatableSample\"\n         factory=\"zope.fssync.doctest.AnnotatableSample\"\n         provides=\"zope.fssync.doctest.IMarkerInterface\"\n         /&gt;\n&lt;/entries&gt;\n00000211 test/@@Zope/Annotations/test/@@Zope/Entries.xml\n&lt;?xml version='1.0' encoding='utf-8'?&gt;\n&lt;entries&gt;\n  &lt;entry name=\"zope.fssync.doctest.TestAnnotations\"\n         keytype=\"__builtin__.str\"\n         type=\"zope.fssync.doctest.TestAnnotations\"\n         /&gt;\n&lt;/entries&gt;\n00000617 test/@@Zope/Annotations/test/zope.fssync.doctest.TestAnnotations\n&lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt;\n&lt;pickle&gt;\n...\n&lt;/pickle&gt;\n00000161 test/@@Zope/Extra/test/@@Zope/Entries.xml\n&lt;?xml version='1.0' encoding='utf-8'?&gt;\n&lt;entries&gt;\n  &lt;entry name=\"extra\"\n         keytype=\"__builtin__.str\"\n         type=\"__builtin__.str\"\n         /&gt;\n&lt;/entries&gt;\n00000082 test/@@Zope/Extra/test/extra\n&lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt;\n&lt;pickle&gt; &lt;string&gt;extra&lt;/string&gt; &lt;/pickle&gt;\n00000017 test/test\nMain file content\n</pre>\n</blockquote>\n<p>The annotations and extras can of course also be deserialized. The default\ndeserializer handles both cases:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; target = {}\n&gt;&gt;&gt; commit = task.Commit(synchronizer.getSynchronizer, snarf)\n&gt;&gt;&gt; commit.perform(target, 'root', 'test')\n&gt;&gt;&gt; result = target['root']['test']\n&gt;&gt;&gt; result.extra\n'extra'\n&gt;&gt;&gt; ITestAnnotations(result).a\n'annotation a'\n</pre>\n</blockquote>\n<p>Since we use an IDirectorySynchronizer each extra attribute and\nannotation namespace get\u2019s it\u2019s own file:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; for path in sorted(snarf.iterPaths()):\n...     print path\n@@Zope/Entries.xml\ntest/@@Zope/Annotations/test/@@Zope/Entries.xml\ntest/@@Zope/Annotations/test/zope.fssync.doctest.TestAnnotations\ntest/@@Zope/Entries.xml\ntest/@@Zope/Extra/test/@@Zope/Entries.xml\ntest/@@Zope/Extra/test/extra\ntest/test\n</pre>\n</blockquote>\n<p>The number of files can be reduced if we provide the default synchronizer\nwhich uses a single file for all annotations and a single file for\nall extras:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; component.provideUtility(\n...     synchronizer.DefaultSynchronizer,\n...     interfaces.ISynchronizerFactory,\n...     name=synchronizer.dottedname(synchronizer.Extras))\n</pre>\n<pre>&gt;&gt;&gt; component.provideUtility(\n...     synchronizer.DefaultSynchronizer,\n...     interfaces.ISynchronizerFactory,\n...     name=synchronizer.dottedname(\n...                 synchronizer.SynchronizableAnnotations))\n</pre>\n<pre>&gt;&gt;&gt; root['test'] = sample\n&gt;&gt;&gt; snarf = repository.SnarfRepository(StringIO())\n&gt;&gt;&gt; checkout.repository = snarf\n&gt;&gt;&gt; checkout.perform(root, 'test')\n&gt;&gt;&gt; for path in sorted(snarf.iterPaths()):\n...     print path\n@@Zope/Entries.xml\ntest/@@Zope/Annotations/test\ntest/@@Zope/Entries.xml\ntest/@@Zope/Extra/test\ntest/test\n</pre>\n</blockquote>\n<p>The annotations and extras can of course also be deserialized. The default\ndeserializer handles both</p>\n<blockquote>\n<pre>&gt;&gt;&gt; target = {}\n&gt;&gt;&gt; commit = task.Commit(synchronizer.getSynchronizer, snarf)\n&gt;&gt;&gt; commit.perform(target, 'root', 'test')\n&gt;&gt;&gt; result = target['root']['test']\n&gt;&gt;&gt; result.extra\n'extra'\n&gt;&gt;&gt; ITestAnnotations(result).a\n'annotation a'\n&gt;&gt;&gt; [x for x in interface.directlyProvidedBy(result)]\n[&lt;InterfaceClass zope.fssync.doctest.IMarkerInterface&gt;]\n</pre>\n</blockquote>\n<p>If we encounter an error, or multiple errors, while commiting we\u2019ll\nsee them in the traceback.</p>\n<blockquote>\n<pre>&gt;&gt;&gt; def bad_sync(container, key, fspath, add_callback):\n...     raise ValueError('1','2','3')\n</pre>\n<pre>&gt;&gt;&gt; target = {}\n&gt;&gt;&gt; commit = task.Commit(synchronizer.getSynchronizer, snarf)\n&gt;&gt;&gt; old_sync_new = commit.synchNew\n&gt;&gt;&gt; commit.synchNew = bad_sync\n&gt;&gt;&gt; commit.perform(target, 'root', 'test')\nTraceback (most recent call last):\n    ...\nException: test: '1', '2', '3'\n</pre>\n</blockquote>\n<p>Notice that if we encounter multiple exceptions we print them all\nout at the end.</p>\n<blockquote>\n<pre>&gt;&gt;&gt; old_sync_old = commit.synchOld\n&gt;&gt;&gt; commit.synchOld = bad_sync\n&gt;&gt;&gt; commit.perform(target, 'root', 'test')\nTraceback (most recent call last):\n    ...\nExceptions:\n    test: '1', '2', '3'\n    test: '1', '2', '3'\n</pre>\n<pre>&gt;&gt;&gt; commit.synchNew = old_sync_new\n&gt;&gt;&gt; commit.synchOld = old_sync_old\n</pre>\n</blockquote>\n</div>\n<div id=\"changes\">\n<h3>Changes</h3>\n<div id=\"id1\">\n<h4>3.6.1 (2013-05-02)</h4>\n<ul>\n<li>Fixed exception raising on unpickling errors when checking in.</li>\n<li>Improved reporting of unpickling errors.</li>\n</ul>\n</div>\n<div id=\"id2\">\n<h4>3.6.0 (2012-03-15)</h4>\n<ul>\n<li>Commit task will collect errors and send them all back rather\nthan stopping on the first error encountered.</li>\n</ul>\n</div>\n<div id=\"id3\">\n<h4>3.5.2 (2010-10-18)</h4>\n<ul>\n<li>Fix tests; zope.location no longer exports TLocation.</li>\n<li>Raise the right error in zope.fssync.synchronizer when the configured\nsynchronizer does not exist.</li>\n<li>Update dependency information.</li>\n<li>Minor code cleanups.</li>\n</ul>\n</div>\n<div id=\"id4\">\n<h4>3.5.1 (2009-07-24)</h4>\n<ul>\n<li>Properly setup tests, so that they will work in a release as well.</li>\n<li>Removed slugs.</li>\n</ul>\n</div>\n<div id=\"id5\">\n<h4>3.5 (????)</h4>\n<ul>\n<li>Added the support for empty directories in snarf format. Now\ndirectories can be explicitly described by snarf.</li>\n<li>Synchronizers can now return callbacks from the load\nmethod. This allows for fix ups to be run later. This is useful\nwhen adding multiple objects at the same time that depend on\neach other. Callbacks can in turn return callbacks.</li>\n<li>Add support to FSMerger to allow locally modified files to be\noverwritten by files returned from the server. The purpose of\nthis is to avoid conflicts after commit on files that are\nformatted differently on the server from local versions.</li>\n</ul>\n</div>\n<div id=\"b1\">\n<h4>3.4.0b1 (????)</h4>\n<p>Refactoring of zope.fssync and zope.app.fssync into two clearly\nseparated packages:</p>\n<ul>\n<li>zope.fssync contains now a Python API that has no critical dependencies\non Zope, the ZODB, and the security machinery.</li>\n<li>zope.app.fssync contains a protected web-based API and special\nsynchronizers for zope.app content types.</li>\n</ul>\n<p>Other major changes are</p>\n<ul>\n<li>synchronizers (i.e. serialization/de-serialization adapters) are created\nby named utilities which use dotted class names as lookup keys</li>\n<li>added doctests</li>\n<li>support for large files</li>\n<li>adapters for pickler, unpickler and handling of persistent pickle ids</li>\n<li>binaries are no longer merged</li>\n<li>case-insensitive filesystems and repositories use disambiguated names on\nexport and the original names on import</li>\n<li>export and import of directly provided interfaces</li>\n<li>direct export to archives/direct import from archives</li>\n<li>addressed encoding problems on Mac OSX</li>\n</ul>\n</div>\n</div>\n</div>\n\n          </div>"}, "last_serial": 718563, "releases": {"3.5": [{"comment_text": "", "digests": {"md5": "211ee31e96c112fe65e24c55808ebefa", "sha256": "29a8e59c7c91aecbcbe846a11e4e0f9db0119b5a8cd774312f4af748ef403d11"}, "downloads": -1, "filename": "zope.fssync-3.5.tar.gz", "has_sig": false, "md5_digest": "211ee31e96c112fe65e24c55808ebefa", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 62661, "upload_time": "2009-03-13T15:07:38", "upload_time_iso_8601": "2009-03-13T15:07:38.402491Z", "url": "https://files.pythonhosted.org/packages/3e/a2/93ad89e2deb9af749ccac21800b2593b8d0b0f9c6798e3b54260485479d8/zope.fssync-3.5.tar.gz", "yanked": false}], "3.5.1": [{"comment_text": "", "digests": {"md5": "8c5a12f701694c0577312cbad4e77eef", "sha256": "05db6f532c37a405f7569c3de11c180d5d78992073a82c605940d70b3e06230e"}, "downloads": -1, "filename": "zope.fssync-3.5.1.tar.gz", "has_sig": false, "md5_digest": "8c5a12f701694c0577312cbad4e77eef", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 74258, "upload_time": "2009-07-24T19:15:12", "upload_time_iso_8601": "2009-07-24T19:15:12.542816Z", "url": "https://files.pythonhosted.org/packages/d3/01/a2ba1f4593e373c408bd4fae38207fab3ad3c1555b205559a0932b9e6e1c/zope.fssync-3.5.1.tar.gz", "yanked": false}], "3.5.2": [{"comment_text": "", "digests": {"md5": "014745b4405685649ddfa547ba6569e7", "sha256": "9ab0bdc5b0c2395a4f2f19255df75ee34604c1d19f0bc9c5373eec6dd994c8da"}, "downloads": -1, "filename": "zope.fssync-3.5.2.tar.gz", "has_sig": false, "md5_digest": "014745b4405685649ddfa547ba6569e7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 75029, "upload_time": "2010-10-18T20:21:59", "upload_time_iso_8601": "2010-10-18T20:21:59.511076Z", "url": "https://files.pythonhosted.org/packages/76/55/ca0224b1dd13f6761a30ba01ed7c0737bca951477affdc288c1e0e4a34e9/zope.fssync-3.5.2.tar.gz", "yanked": false}], "3.6.0": [{"comment_text": "", "digests": {"md5": "1754941b2ef894d5d8620f68282aa190", "sha256": "bcb50a2501e60c3ea2cc64e75a60e109468fd51df98264165777d4a18a5af74e"}, "downloads": -1, "filename": "zope.fssync-3.6.0.tar.gz", "has_sig": false, "md5_digest": "1754941b2ef894d5d8620f68282aa190", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 75968, "upload_time": "2012-03-15T16:37:44", "upload_time_iso_8601": "2012-03-15T16:37:44.803338Z", "url": "https://files.pythonhosted.org/packages/40/46/4642db82e453c77df48e32083e9c8974459b34e1aab085b20e6126457f54/zope.fssync-3.6.0.tar.gz", "yanked": false}], "3.6.1": [{"comment_text": "", "digests": {"md5": "f62812c50707178c95dc6c4c22b8572b", "sha256": "a23b56644a894405a270a1195076e7c79de68bbc4066ec61ef8c17781bc9208b"}, "downloads": -1, "filename": "zope.fssync-3.6.1.zip", "has_sig": false, "md5_digest": "f62812c50707178c95dc6c4c22b8572b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 100526, "upload_time": "2013-05-02T10:48:24", "upload_time_iso_8601": "2013-05-02T10:48:24.527833Z", "url": "https://files.pythonhosted.org/packages/2c/9c/7c738647ac8d8bf25de9ce2f52854fc9006a6dcca7cabf45bd62b606b184/zope.fssync-3.6.1.zip", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "f62812c50707178c95dc6c4c22b8572b", "sha256": "a23b56644a894405a270a1195076e7c79de68bbc4066ec61ef8c17781bc9208b"}, "downloads": -1, "filename": "zope.fssync-3.6.1.zip", "has_sig": false, "md5_digest": "f62812c50707178c95dc6c4c22b8572b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 100526, "upload_time": "2013-05-02T10:48:24", "upload_time_iso_8601": "2013-05-02T10:48:24.527833Z", "url": "https://files.pythonhosted.org/packages/2c/9c/7c738647ac8d8bf25de9ce2f52854fc9006a6dcca7cabf45bd62b606b184/zope.fssync-3.6.1.zip", "yanked": false}], "timestamp": "Fri May  8 03:13:48 2020"}