{"info": {"author": "Nilani Algiriyage", "author_email": "nilani@nic.lk", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha"], "description": "A simple python script to identify and classify possible crawlers through analysis of web server log files. The script categorizes identified web crawlers in to three as \"known\", \"suspicious\" and \"other\".This works with log files in Apache common log format.\r\n\r\nInformation about installation:\r\n\r\nhttp://code.google.com/p/crawler-detection/", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "UNKNOWN", "keywords": "Apache", "license": "GNU GPL v3", "maintainer": "Nilani Algiriyage", "maintainer_email": "nilani@nic.lk", "name": "crawler_detection", "package_url": "https://pypi.org/project/crawler_detection/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/crawler_detection/", "project_urls": {"Download": "UNKNOWN", "Homepage": "UNKNOWN"}, "release_url": "https://pypi.org/project/crawler_detection/0.1/", "requires_dist": null, "requires_python": null, "summary": "A simple python script to identify and classify possible crawlers through analysis of web server log files", "version": "0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>A simple python script to identify and classify possible crawlers through analysis of web server log files. The script categorizes identified web crawlers in to three as \u201cknown\u201d, \u201csuspicious\u201d and \u201cother\u201d.This works with log files in Apache common log format.</p>\n<p>Information about installation:</p>\n<p><a href=\"http://code.google.com/p/crawler-detection/\" rel=\"nofollow\">http://code.google.com/p/crawler-detection/</a></p>\n\n          </div>"}, "last_serial": 918293, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "67ed5a157109fedfcca0939b51246f79", "sha256": "4de31e61be1e710acaa8507f97d775690ba86548da10aa96224c2a286e724ba2"}, "downloads": -1, "filename": "crawler-detection.zip", "has_sig": false, "md5_digest": "67ed5a157109fedfcca0939b51246f79", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 68095, "upload_time": "2013-11-13T13:37:29", "upload_time_iso_8601": "2013-11-13T13:37:29.570279Z", "url": "https://files.pythonhosted.org/packages/4a/12/d09f97987b71e129a7e6d08e0f9004617e18c676bdf43b68bcba57fe6da7/crawler-detection.zip", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "67ed5a157109fedfcca0939b51246f79", "sha256": "4de31e61be1e710acaa8507f97d775690ba86548da10aa96224c2a286e724ba2"}, "downloads": -1, "filename": "crawler-detection.zip", "has_sig": false, "md5_digest": "67ed5a157109fedfcca0939b51246f79", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 68095, "upload_time": "2013-11-13T13:37:29", "upload_time_iso_8601": "2013-11-13T13:37:29.570279Z", "url": "https://files.pythonhosted.org/packages/4a/12/d09f97987b71e129a7e6d08e0f9004617e18c676bdf43b68bcba57fe6da7/crawler-detection.zip", "yanked": false}], "timestamp": "Fri May  8 00:42:26 2020"}