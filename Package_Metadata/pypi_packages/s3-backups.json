{"info": {"author": "Brent O'Connor", "author_email": "epicserve@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "S3 Backups\n==========\n\n.. image:: https://pypip.in/v/s3-backups/badge.png\n        :target: https://pypi.python.org/pypi/s3-backups\n\n.. image:: https://travis-ci.org/epicserve/s3-backups.png?branch=master\n    :alt: Build Status\n    :target: http://travis-ci.org/epicserve/epicserve\n\nOverview\n--------\n\nS3 Backups provides easy scripts that system administrators can use to backup\ndata from programs likes PostgreSQL, MySQL, Redis, etc.\n\nInstallation\n------------\n\nTo install s3-backups::\n\n    $ sudo pip install s3-backups\n\nUsage\n-----\n\nSetting Up S3 Backups to Run Automatically Using Cron\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\nPostgreSQL\n''''''''''\n\nAdd the following to the file ``/etc/cron.d/postgres_to_s3`` and then change the command arguments so the command is using your correct AWS credentials, backup bucket and the correct base S3 Key/base folder.\n\n::\n\n    0 */1 * * * postgres /usr/local/bin/postgres_to_s3.py --AWS_ACCESS_KEY_ID='xxxxxxxxxxxxxxxxxxxx' --AWS_SECRET_ACCESS_KEY='xxxxxxxxxxxxxxxxxxxx' --S3_BUCKET_NAME='my-backup-bucket' --S3_KEY_NAME='postgres/my-awesome-server' --backup --archive\n\nRedis\n'''''\n\nAdd the following to the file ``/etc/cron.d/redis_to_s3`` and then change the command arguments so the command is using your correct AWS credentials, backup bucket and the correct base S3 Key/base folder.\n\n::\n\n    0 */1 * * * root redis_to_s3.py --AWS_ACCESS_KEY_ID='xxxxxxxxxxxxxxxxxxxx' --AWS_SECRET_ACCESS_KEY='xxxxxxxxxxxxxxxxxxxx' --S3_BUCKET_NAME='my-backup-bucket' --S3_KEY_NAME='redis/my-awesome-server' --backup --archive\n\n\nMySQL\n'''''\n\nAdd the following to the file ``/etc/cron.d/mysql_to_s3`` and then change the command arguments so the command is using your correct AWS credentials, backup bucket and the correct base S3 Key/base folder.\n\n::\n\n    0 */1 * * * root mysql_to_s3.py --AWS_ACCESS_KEY_ID='xxxxxxxxxxxxxxxxxxxx' --AWS_SECRET_ACCESS_KEY='xxxxxxxxxxxxxxxxxxxx' --S3_BUCKET_NAME='my-backup-bucket' --S3_KEY_NAME='redis/my-awesome-server' --backup --archive\n\n\n\nManually Running Backups and Archiving\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nWhen running the archive command, S3 Backups moves backups into a\n``year/month`` sub folder (technically a S3 key) for archives it's scheduled\nto keep and removes all other archives. S3 Backups, will use the default\nschedule unless you you tell it to use a different schedule with the\n``--schedule_module`` argument.\n\nThe default archive schedule will ...\n\n- keep all archives for 7 days\n- keep midnight backups for every other day for 30 days\n- keep the first day of the month forever\n- remove all other files that aren't scheduled to be kept\n\nTo backup PostgreSQL, run the following::\n\n    $ postgres_to_s3.py \\\n    --AWS_ACCESS_KEY_ID='xxxxxxxxxxxxxxxxxxxx' \\\n    --AWS_SECRET_ACCESS_KEY='xxxxxxxxxxxxxxxxxxxx' \\\n    --S3_BUCKET_NAME='my-backup-bucket' \\\n    --S3_KEY_NAME='postgres/my-awesome-server' \\\n    --backup\n\nTo archive PostgreSQL backups, run the following::\n\n    $ postgres_to_s3.py \\\n    --AWS_ACCESS_KEY_ID='xxxxxxxxxxxxxxxxxxxx' \\\n    --AWS_SECRET_ACCESS_KEY='xxxxxxxxxxxxxxxxxxxx' \\\n    --S3_BUCKET_NAME='my-backup-bucket' \\\n    --S3_KEY_NAME='postgres/my-awesome-server' \\\n    --archive\n\nTo backup Redis, run the following::\n\n    $ redis_to_s3.py \\\n    --AWS_ACCESS_KEY_ID='xxxxxxxxxxxxxxxxxxxx' \\\n    --AWS_SECRET_ACCESS_KEY='xxxxxxxxxxxxxxxxxxxx' \\\n    --S3_BUCKET_NAME='my-backup-bucket' \\\n    --S3_KEY_NAME='redis/my-awesome-server' --backup\n\nTo archive Redis, run the following::\n\n    $ redis_to_s3.py \\\n    --AWS_ACCESS_KEY_ID='xxxxxxxxxxxxxxxxxxxx' \\\n    --AWS_SECRET_ACCESS_KEY='xxxxxxxxxxxxxxxxxxxx' \\\n    --S3_BUCKET_NAME='my-backup-bucket' \\\n    --S3_KEY_NAME='redis/my-awesome-server' --archive\n\nTo backup MySQL, run the following::\n\n    $ mysql_to_s3.py \\\n    --AWS_ACCESS_KEY_ID='xxxxxxxxxxxxxxxxxxxx' \\\n    --AWS_SECRET_ACCESS_KEY='xxxxxxxxxxxxxxxxxxxx' \\\n    --S3_BUCKET_NAME='my-backup-bucket' \\\n    --S3_KEY_NAME='redis/my-awesome-server' --backup\n\nTo archive MySQL, run the following::\n\n    $ mysql_to_s3.py \\\n    --AWS_ACCESS_KEY_ID='xxxxxxxxxxxxxxxxxxxx' \\\n    --AWS_SECRET_ACCESS_KEY='xxxxxxxxxxxxxxxxxxxx' \\\n    --S3_BUCKET_NAME='my-backup-bucket' \\\n    --S3_KEY_NAME='redis/my-awesome-server' --archive\n\nContribute\n----------\n\nIf you'd like to contribute, create an issue to get a dialog going about the\nfeature you want to add. After a plan is place then fork the repository and\ncreate your fix or feature on a new branch. When your finished, make a pull\nrequest to get your changes pulled in.\n", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/epicserve/s3-backups", "keywords": null, "license": "Copyright 2013 Brent O'Connor\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.", "maintainer": null, "maintainer_email": null, "name": "s3-backups", "package_url": "https://pypi.org/project/s3-backups/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/s3-backups/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/epicserve/s3-backups"}, "release_url": "https://pypi.org/project/s3-backups/0.1.0/", "requires_dist": null, "requires_python": null, "summary": "Backup stuff to S3", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://pypi.python.org/pypi/s3-backups\" rel=\"nofollow\"><img alt=\"https://pypip.in/v/s3-backups/badge.png\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4640581b57d6989359bd24d8c6a3afaccd941e93/68747470733a2f2f70797069702e696e2f762f73332d6261636b7570732f62616467652e706e67\"></a>\n<a href=\"http://travis-ci.org/epicserve/epicserve\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bf5b96bb1319b722ac36748571671875779664a3/68747470733a2f2f7472617669732d63692e6f72672f6570696373657276652f73332d6261636b7570732e706e673f6272616e63683d6d6173746572\"></a>\n<div id=\"overview\">\n<h2>Overview</h2>\n<p>S3 Backups provides easy scripts that system administrators can use to backup\ndata from programs likes PostgreSQL, MySQL, Redis, etc.</p>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>To install s3-backups:</p>\n<pre>$ sudo pip install s3-backups\n</pre>\n</div>\n<div id=\"usage\">\n<h2>Usage</h2>\n<div id=\"setting-up-s3-backups-to-run-automatically-using-cron\">\n<h3>Setting Up S3 Backups to Run Automatically Using Cron</h3>\n<div id=\"postgresql\">\n<h4>PostgreSQL</h4>\n<p>Add the following to the file <tt>/etc/cron.d/postgres_to_s3</tt> and then change the command arguments so the command is using your correct AWS credentials, backup bucket and the correct base S3 Key/base folder.</p>\n<pre>0 */1 * * * postgres /usr/local/bin/postgres_to_s3.py --AWS_ACCESS_KEY_ID='xxxxxxxxxxxxxxxxxxxx' --AWS_SECRET_ACCESS_KEY='xxxxxxxxxxxxxxxxxxxx' --S3_BUCKET_NAME='my-backup-bucket' --S3_KEY_NAME='postgres/my-awesome-server' --backup --archive\n</pre>\n</div>\n<div id=\"redis\">\n<h4>Redis</h4>\n<p>Add the following to the file <tt>/etc/cron.d/redis_to_s3</tt> and then change the command arguments so the command is using your correct AWS credentials, backup bucket and the correct base S3 Key/base folder.</p>\n<pre>0 */1 * * * root redis_to_s3.py --AWS_ACCESS_KEY_ID='xxxxxxxxxxxxxxxxxxxx' --AWS_SECRET_ACCESS_KEY='xxxxxxxxxxxxxxxxxxxx' --S3_BUCKET_NAME='my-backup-bucket' --S3_KEY_NAME='redis/my-awesome-server' --backup --archive\n</pre>\n</div>\n<div id=\"mysql\">\n<h4>MySQL</h4>\n<p>Add the following to the file <tt>/etc/cron.d/mysql_to_s3</tt> and then change the command arguments so the command is using your correct AWS credentials, backup bucket and the correct base S3 Key/base folder.</p>\n<pre>0 */1 * * * root mysql_to_s3.py --AWS_ACCESS_KEY_ID='xxxxxxxxxxxxxxxxxxxx' --AWS_SECRET_ACCESS_KEY='xxxxxxxxxxxxxxxxxxxx' --S3_BUCKET_NAME='my-backup-bucket' --S3_KEY_NAME='redis/my-awesome-server' --backup --archive\n</pre>\n</div>\n</div>\n<div id=\"manually-running-backups-and-archiving\">\n<h3>Manually Running Backups and Archiving</h3>\n<p>When running the archive command, S3 Backups moves backups into a\n<tt>year/month</tt> sub folder (technically a S3 key) for archives it\u2019s scheduled\nto keep and removes all other archives. S3 Backups, will use the default\nschedule unless you you tell it to use a different schedule with the\n<tt><span class=\"pre\">--schedule_module</span></tt> argument.</p>\n<p>The default archive schedule will \u2026</p>\n<ul>\n<li>keep all archives for 7 days</li>\n<li>keep midnight backups for every other day for 30 days</li>\n<li>keep the first day of the month forever</li>\n<li>remove all other files that aren\u2019t scheduled to be kept</li>\n</ul>\n<p>To backup PostgreSQL, run the following:</p>\n<pre>$ postgres_to_s3.py \\\n--AWS_ACCESS_KEY_ID='xxxxxxxxxxxxxxxxxxxx' \\\n--AWS_SECRET_ACCESS_KEY='xxxxxxxxxxxxxxxxxxxx' \\\n--S3_BUCKET_NAME='my-backup-bucket' \\\n--S3_KEY_NAME='postgres/my-awesome-server' \\\n--backup\n</pre>\n<p>To archive PostgreSQL backups, run the following:</p>\n<pre>$ postgres_to_s3.py \\\n--AWS_ACCESS_KEY_ID='xxxxxxxxxxxxxxxxxxxx' \\\n--AWS_SECRET_ACCESS_KEY='xxxxxxxxxxxxxxxxxxxx' \\\n--S3_BUCKET_NAME='my-backup-bucket' \\\n--S3_KEY_NAME='postgres/my-awesome-server' \\\n--archive\n</pre>\n<p>To backup Redis, run the following:</p>\n<pre>$ redis_to_s3.py \\\n--AWS_ACCESS_KEY_ID='xxxxxxxxxxxxxxxxxxxx' \\\n--AWS_SECRET_ACCESS_KEY='xxxxxxxxxxxxxxxxxxxx' \\\n--S3_BUCKET_NAME='my-backup-bucket' \\\n--S3_KEY_NAME='redis/my-awesome-server' --backup\n</pre>\n<p>To archive Redis, run the following:</p>\n<pre>$ redis_to_s3.py \\\n--AWS_ACCESS_KEY_ID='xxxxxxxxxxxxxxxxxxxx' \\\n--AWS_SECRET_ACCESS_KEY='xxxxxxxxxxxxxxxxxxxx' \\\n--S3_BUCKET_NAME='my-backup-bucket' \\\n--S3_KEY_NAME='redis/my-awesome-server' --archive\n</pre>\n<p>To backup MySQL, run the following:</p>\n<pre>$ mysql_to_s3.py \\\n--AWS_ACCESS_KEY_ID='xxxxxxxxxxxxxxxxxxxx' \\\n--AWS_SECRET_ACCESS_KEY='xxxxxxxxxxxxxxxxxxxx' \\\n--S3_BUCKET_NAME='my-backup-bucket' \\\n--S3_KEY_NAME='redis/my-awesome-server' --backup\n</pre>\n<p>To archive MySQL, run the following:</p>\n<pre>$ mysql_to_s3.py \\\n--AWS_ACCESS_KEY_ID='xxxxxxxxxxxxxxxxxxxx' \\\n--AWS_SECRET_ACCESS_KEY='xxxxxxxxxxxxxxxxxxxx' \\\n--S3_BUCKET_NAME='my-backup-bucket' \\\n--S3_KEY_NAME='redis/my-awesome-server' --archive\n</pre>\n</div>\n</div>\n<div id=\"contribute\">\n<h2>Contribute</h2>\n<p>If you\u2019d like to contribute, create an issue to get a dialog going about the\nfeature you want to add. After a plan is place then fork the repository and\ncreate your fix or feature on a new branch. When your finished, make a pull\nrequest to get your changes pulled in.</p>\n</div>\n\n          </div>"}, "last_serial": 706312, "releases": {"0.0.3": [{"comment_text": "", "digests": {"md5": "8cd70135e79a776f60e4f7a9fdb5a231", "sha256": "4a274bb975695eb12d4e5fcdc0931dc26745bf3419accc6646b0a49e53bc9e98"}, "downloads": -1, "filename": "s3-backups-0.0.3.tar.gz", "has_sig": false, "md5_digest": "8cd70135e79a776f60e4f7a9fdb5a231", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6378, "upload_time": "2013-05-25T22:53:12", "upload_time_iso_8601": "2013-05-25T22:53:12.613722Z", "url": "https://files.pythonhosted.org/packages/9c/80/67f1d45b6dc4ac9f107e9ce61188bb41adb6a569479bfdd81e0208739968/s3-backups-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "b79ddb66181b4711d515f4bf9f82a49a", "sha256": "b1ccacc5f37be10746bc8f2e4590d0e09b2a519003eaafe024ee6a06a4aa6e19"}, "downloads": -1, "filename": "s3-backups-0.0.4.tar.gz", "has_sig": false, "md5_digest": "b79ddb66181b4711d515f4bf9f82a49a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6468, "upload_time": "2013-05-25T23:55:01", "upload_time_iso_8601": "2013-05-25T23:55:01.912296Z", "url": "https://files.pythonhosted.org/packages/3c/eb/ebfc49afc7fa5b4c320cbe090200e86a0941b31e38301a7c433cbd0e53b1/s3-backups-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "c0f4d6d60117ae48b503ac1a512cd394", "sha256": "dc069f88c3dc2ad7559535580c1e273476c7fff7edee5e6311763ac6846b3d05"}, "downloads": -1, "filename": "s3-backups-0.0.5.tar.gz", "has_sig": false, "md5_digest": "c0f4d6d60117ae48b503ac1a512cd394", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7491, "upload_time": "2013-05-26T02:03:06", "upload_time_iso_8601": "2013-05-26T02:03:06.502648Z", "url": "https://files.pythonhosted.org/packages/d0/0b/a846cec2e153d87d8c721412032b0968abca9b61cdbfccf0670d374879f4/s3-backups-0.0.5.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "609941bccc66ecab8169e0c941632749", "sha256": "e0bca1da60245635ae2a19c1810021e6587f7e34eb9ffec42f1e78b509e3919f"}, "downloads": -1, "filename": "s3-backups-0.1.0.tar.gz", "has_sig": false, "md5_digest": "609941bccc66ecab8169e0c941632749", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7829, "upload_time": "2013-05-26T03:08:48", "upload_time_iso_8601": "2013-05-26T03:08:48.692949Z", "url": "https://files.pythonhosted.org/packages/2b/8b/b2988b537cad1bfb45cc1fd71032d6b395b218e117a33124794b37eb77b8/s3-backups-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "609941bccc66ecab8169e0c941632749", "sha256": "e0bca1da60245635ae2a19c1810021e6587f7e34eb9ffec42f1e78b509e3919f"}, "downloads": -1, "filename": "s3-backups-0.1.0.tar.gz", "has_sig": false, "md5_digest": "609941bccc66ecab8169e0c941632749", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7829, "upload_time": "2013-05-26T03:08:48", "upload_time_iso_8601": "2013-05-26T03:08:48.692949Z", "url": "https://files.pythonhosted.org/packages/2b/8b/b2988b537cad1bfb45cc1fd71032d6b395b218e117a33124794b37eb77b8/s3-backups-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:59:40 2020"}