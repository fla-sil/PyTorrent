{"info": {"author": "Max Halford, Vincent Lefoulon", "author_email": "maxhalford25@gmail.com, vincent.lefoulon@free.fr", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: BSD License", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: Implementation :: CPython", "Programming Language :: Python :: Implementation :: PyPy"], "description": "<div align=\"center\">\n  <h1>ethik</h1>\n</div>\n\n<div align=\"center\">\n  <!-- Travis -->\n  <a href=\"https://travis-ci.org/XAI-ANITI/ethik\">\n    <img src=\"https://img.shields.io/travis/MaxHalford/ethik/master.svg?style=for-the-badge\" alt=\"travis\" />\n  </a>\n  <!-- PyPI -->\n  <a href=\"https://pypi.org/project/ethik\">\n    <img src=\"https://img.shields.io/pypi/v/ethik.svg?style=for-the-badge\" alt=\"pypi\" />\n  </a>\n  <!-- Black -->\n  <a href=\"https://github.com/psf/black\">\n    <img src=\"https://img.shields.io/badge/code%20style-black-000000.svg?style=for-the-badge\" alt=\"black\" />\n  </a>\n  <!-- License -->\n  <a href=\"https://www.gnu.org/licenses/gpl-3.0.en.html\">\n    <img src=\"https://img.shields.io/badge/License-GPL%20v3-blue.svg?style=for-the-badge\" alt=\"gpl_3_license\"/>\n  </a>\n</div>\n\n## Table of contents\n\n* [Introduction](#introduction)\n* [Installation](#installation)\n* [User guide](#user-guide)\n    * [Measuring model influence](#measuring-model-influence)\n    * [Evaluating model reliability](#evaluating-model-reliability)\n    * [Support for image classification](#support-for-image-classification)\n* [Authors](#authors)\n* [License](#license)\n\n**The documentation can be found [here](https://xai-aniti.github.io/ethik/)**.\n\n## Introduction\n\n`ethik` is a Python package for performing [fair](https://perso.math.univ-toulouse.fr/loubes/fairness-robustness-in-machine-learning/) and [explainable](https://www.wikiwand.com/en/Explainable_artificial_intelligence) machine learning. At it's core, the approach of `ethik` is to build *counterfactual distributions* that permit answering \"what if?\" scenarios. The idea is that we are able to stress one or more variables and observe how a machine learning model reacts to the stress. The stress is based on a statistical re-weighting scheme called *entropic variable projection*. The main benefit of our method is that it will only consider realistic scenarios, and will not build fake examples. You may find more information by reading [this paper](https://arxiv.org/abs/1810.07924) as well as the [\"How It Works\" notebook](notebooks/how-it-works.ipynb).\n\n<div align=\"center\">\n  <img src=\"docs/assets/img/overview.svg\" width=\"660px\" alt=\"overview\"/>\n</div>\n\nCurrently, `ethik` can be used for:\n\n1. Detecting model influence with respect to one or more (protected) attributes.\n2. Identifying causes for why a model performs poorly on certain inputs.\n3. Visualizing regions of an image that influence a model's predictions.\n\nWe have more plans for the future.\n\n## Installation\n\n:warning: Python 3.6 or above is required :snake:\n\n**Via [PyPI](https://pypi.org/project/ethik/)**\n\n```shell\n>>> pip install ethik\n```\n\n**Via GitHub for the latest development version**\n\n```shell\n>>> pip install git+https://github.com/XAI-ANITI/ethik\n>>> #\u00a0Or through SSH:\n>>> pip install git+ssh://git@github.com/XAI-ANITI/ethik.git\n```\n\n**Development installation**\n\n```shell\n>>> git clone git@github.com:XAI-ANITI/ethik.git\n>>> cd ethik\n>>> make install_dev\n```\n\n## User guide\n\n:point_up: Please check out [this notebook](notebooks/binary-classification.ipynb) for more detailed code.\n\nIn the following example we'll be using the [\"Adult\" dataset](https://archive.ics.uci.edu/ml/datasets/adult). This dataset contains a binary label indicating if a person's annual income is larger than $50k. `ethik` can diagnose a model by looking at the predictions the model makes on a test set. Consequently, you first have to split your dataset in two (train and test).\n\n```python\nfrom sklearn import model_selection\n\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, shuffle=True, random_state=42)\n```\n\nYou then want to train your model on the training set and make predictions on the test set. In this example we'll train a gradient boosting classifier from the [LightGBM library](https://lightgbm.readthedocs.io/en/latest/). We'll use a variable named `y_pred` to store the predicted probabilities associated with the `True` label.\n\n```python\nimport lightgbm as lgb\n\nmodel = lgb.LGBMClassifier(random_state=42).fit(X_train, y_train)\n\n# We use a named pandas series to make plot labels more explicit\ny_pred = model.predict_proba(X_test)[:, 1]\ny_pred = pd.Series(y_pred, name='>$50k')\n```\n\nWe can now initialize an `ClassificationExplainer` using the default parameters.\n\n```python\nimport ethik\n\nexplainer = ethik.ClassificationExplainer()\n```\n\n### Measuring model influence\n\n`ethik` can be used to understand how the model predictions vary as a function of one or more features. For example we can look at how the model behaves with respect to the `age` feature.\n\n```python\nexplainer.plot_influence(X_test=X_test['age'], y_pred=y_pred)\n```\n\n<div align=\"center\">\n  <img src=\"docs/assets/img/age_influence.svg\" alt=\"Age influence\" />\n</div>\n\nRecall that the target indicates if a person's annual salary is above $50k. **We can see that the model predicts higher probabilities for older people**. This isn't a surprising result, and could have just as well been observed by looking at the data. However, we can see that the predictions plateau at around 50 years old. Indeed, although salary is correlated with age, some people may retire early or lose their job. Furthermore we can see that the model understands the fact that salaries shrink once people get in age of retiring. This up-and-down relationship is in nature non-linear, and isn't picked up by summary statistics such as correlation coefficients, [odds ratios](https://www.wikiwand.com/en/Odds_ratio), and feature importances in general. Although the observations we made are quite obvious and rather intuitive, it's always good to confirm what the model is thinking. The point is that the curves produced by `plot_predictions` represent the relationship between a variable and the target according to the model, rather than the data.\n\nWe can also plot the distribution of predictions for more than one variable. However, because different variables have different scales we have to use a common measure to display them together. For this purpose we plot the \u03c4 (\"tau\") values. These values are contained between -1 and 1 and simply reflect by how much the variable is shifted from it's mean towards it's lower and upper quantiles. In the following figure a tau value of -1 corresponds to just under 20 years old whereas a tau value of 1 refers to being slightly over 60 years old.\n\n```python\nexplainer.plot_influence(X_test=X_test[['age', 'education-num']], y_pred=y_pred)\n```\n\n<div align=\"center\">\n  <img src=\"docs/assets/img/age_education_influence.svg\" alt=\"Age and education influence\" />\n</div>\n\nWe can observe that the model assigns higher probabilities to people with higher degrees, which makes perfect sense. Again, this conveys much more of a story than summary statistics.\n\n### Evaluating model reliability\n\nOur methodology can also be used to evaluate the reliability of a model under different scenarios. Evaluation metrics that are commonly used in machine learning only tell you part of the story. Indeed they tell you the performance of a model *on average*. A more interesting approach is to visualize how accurate the model is with respect to the distribution of a variable.\n\n```python\nexplainer.plot_performance(\n    X_test=X_test['age'],\n    y_test=y_test,\n    y_pred=y_pred > 0.5,  # metrics.accuracy_score requires y_pred to be binary\n    metric=metrics.accuracy_score\n)\n```\n\n<div align=\"center\">\n  <img src=\"docs/assets/img/age_accuracy.svg\" alt=\"Age accuracy\" />\n</div>\n\nIn the above figure **we can see that the model is more reliable for younger people than for older ones**. Having a fine-grained understanding of the accuracy of a model can be of extreme help in real-life scenarios. Indeed this can help you understand where the error of the model is coming from and guide your data science process.\n\nSimilarly to the `plot_predictions` method, we can display the performance of the model for multiple variables.\n\n```python\nexplainer.plot_performance(\n    X_test=X_test[['age', 'education-num']],\n    y_test=y_test,\n    y_pred=y_pred > 0.5,\n    metric=metrics.accuracy_score\n)\n```\n\n<div align=\"center\">\n  <img src=\"docs/assets/img/age_education_accuracy.svg\" alt=\"Age and education accuracy\" />\n</div>\n\n### Support for image classification\n\nA special class named `ImageClassificationExplainer` can be used to analyze image classification models. It has the same API as `ClassificationExplainer`, but expects to be provided with an array of images. For instance, we can analyze a CNN run on the MNIST dataset [from the Keras documendation](https://keras.io/examples/mnist_cnn/). The model achieves an accuracy of around 99% on the test set. For the sake of brevity we will the skip the exact details of the model training.\n\n```python\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\ncnn.fit(x_train, y_train)\ny_pred = cnn.predict_proba(x_test)\n```\n\n`x_test` is a set of images of shape `(10000, 28, 28)` whilst `y_pred` is a set of probabilities predicted for digit by the CNN, and is thus of shape `(10000, 10)`. We can use the `plot_influence` method to display the importance of each pixel for the classifier with respect to each label.\n\n```python\nimport ethik\n\nexplainer = ethik.ImageClassificationExplainer()\nexplainer.plot_influence(x_test, y_pred)\n```\n\n<div align=\"center\">\n  <img width=\"75%\" src=\"docs/assets/img/mnist_influence_explanation.svg\" alt=\"Image influence explanation\" />\n</div>\n\nThis takes around 15 seconds to run on a mid-tier laptop. The previous plot highlights the regions of importance for identifying each digit. More precisely, the intensity of each pixel corresponds to the probability increase of saturating or not the pixel. A value of 0.28 means that saturating the pixel increases the probability predicted by the model by 0.28. Note that we do not saturate and desaturate the pixels independently. Instead, our method understands which pixels are linked together and saturates them in a realistic manner. The previous images show that the CNN seems to be using the same visual cues as a human. However, we can see that is uses very specific regions on images to identify particular digits. For instance, the top-right region of an image seems to trigger the \"5\" digit, whereas the bottom parts of the images seem to be linked with the \"7\" digit. Meanwhile, the colder areas correspond to regions that lower the predicted probabilities when the corresponding pixels are \"turned on\", which is why the center of the \"0\" digit figure is blue.\n\n## Authors\n\nThis work is led by members of the [Toulouse Institute of Mathematics](https://www.math.univ-toulouse.fr/?lang=en), namely:\n\n- [Fran\u00e7ois Bachoc](https://www.math.univ-toulouse.fr/~fbachoc/)\n- [Fabrice Gamboa](https://www.math.univ-toulouse.fr/~gamboa/newwab/Pages_Fabrice_Gamboa/Main_Page.html)\n- [Max Halford](https://maxhalford.github.io/)\n- [Vincent Lefoulon](https://vayel.github.io/)\n- [Jean-Michel Loubes](https://perso.math.univ-toulouse.fr/loubes/)\n- [Laurent Risser](http://laurent.risser.free.fr/menuEng.html)\n\nYou can contact us at [jm.loubes@gmail.com](mailto:jm.loubes@gmail.com) and/or [maxhalford25@gmail.com](mailto:maxhalford25@gmail.com).\n\nThis work is supported by the [Centre National de la Recherche Scientifique (CNRS)](http://www.cnrs.fr/) and is done in the context of the [Artificial and Natural Intelligence Toulouse Institute (ANITI)](https://en.univ-toulouse.fr/aniti) project.\n\n## License\n\nThis software is released under the [GPL license](LICENSE).", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/MaxHalford/ethik", "keywords": "", "license": "BSD-3", "maintainer": "", "maintainer_email": "", "name": "ethik", "package_url": "https://pypi.org/project/ethik/", "platform": "", "project_url": "https://pypi.org/project/ethik/", "project_urls": {"Homepage": "https://github.com/MaxHalford/ethik"}, "release_url": "https://pypi.org/project/ethik/0.0.4/", "requires_dist": null, "requires_python": ">=3.6.0", "summary": "A toolbox for fair and explainable machine learning", "version": "0.0.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div>\n  <h1>ethik</h1>\n</div>\n<div>\n  \n  <a href=\"https://travis-ci.org/XAI-ANITI/ethik\" rel=\"nofollow\">\n    <img alt=\"travis\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9e5e52d17a494a74b195bf765d0a3ecc85bd6928/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f4d617848616c666f72642f657468696b2f6d61737465722e7376673f7374796c653d666f722d7468652d6261646765\">\n  </a>\n  \n  <a href=\"https://pypi.org/project/ethik\" rel=\"nofollow\">\n    <img alt=\"pypi\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c9de00a22d8ccc8ebdf4a25fca09b659e34e8732/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f657468696b2e7376673f7374796c653d666f722d7468652d6261646765\">\n  </a>\n  \n  <a href=\"https://github.com/psf/black\" rel=\"nofollow\">\n    <img alt=\"black\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f680626f3780df10c85eee832fd8768d7af28a89/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e7376673f7374796c653d666f722d7468652d6261646765\">\n  </a>\n  \n  <a href=\"https://www.gnu.org/licenses/gpl-3.0.en.html\" rel=\"nofollow\">\n    <img alt=\"gpl_3_license\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/924253e7be1e187c11f959a6518dd10b83b08bc1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d47504c25323076332d626c75652e7376673f7374796c653d666f722d7468652d6261646765\">\n  </a>\n</div>\n<h2>Table of contents</h2>\n<ul>\n<li><a href=\"#introduction\" rel=\"nofollow\">Introduction</a></li>\n<li><a href=\"#installation\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#user-guide\" rel=\"nofollow\">User guide</a>\n<ul>\n<li><a href=\"#measuring-model-influence\" rel=\"nofollow\">Measuring model influence</a></li>\n<li><a href=\"#evaluating-model-reliability\" rel=\"nofollow\">Evaluating model reliability</a></li>\n<li><a href=\"#support-for-image-classification\" rel=\"nofollow\">Support for image classification</a></li>\n</ul>\n</li>\n<li><a href=\"#authors\" rel=\"nofollow\">Authors</a></li>\n<li><a href=\"#license\" rel=\"nofollow\">License</a></li>\n</ul>\n<p><strong>The documentation can be found <a href=\"https://xai-aniti.github.io/ethik/\" rel=\"nofollow\">here</a></strong>.</p>\n<h2>Introduction</h2>\n<p><code>ethik</code> is a Python package for performing <a href=\"https://perso.math.univ-toulouse.fr/loubes/fairness-robustness-in-machine-learning/\" rel=\"nofollow\">fair</a> and <a href=\"https://www.wikiwand.com/en/Explainable_artificial_intelligence\" rel=\"nofollow\">explainable</a> machine learning. At it's core, the approach of <code>ethik</code> is to build <em>counterfactual distributions</em> that permit answering \"what if?\" scenarios. The idea is that we are able to stress one or more variables and observe how a machine learning model reacts to the stress. The stress is based on a statistical re-weighting scheme called <em>entropic variable projection</em>. The main benefit of our method is that it will only consider realistic scenarios, and will not build fake examples. You may find more information by reading <a href=\"https://arxiv.org/abs/1810.07924\" rel=\"nofollow\">this paper</a> as well as the <a href=\"notebooks/how-it-works.ipynb\" rel=\"nofollow\">\"How It Works\" notebook</a>.</p>\n<div>\n  <img alt=\"overview\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ba69242944ad27ed7caf9ada528683f3cdbcc3e9/646f63732f6173736574732f696d672f6f766572766965772e737667\" width=\"660px\">\n</div>\n<p>Currently, <code>ethik</code> can be used for:</p>\n<ol>\n<li>Detecting model influence with respect to one or more (protected) attributes.</li>\n<li>Identifying causes for why a model performs poorly on certain inputs.</li>\n<li>Visualizing regions of an image that influence a model's predictions.</li>\n</ol>\n<p>We have more plans for the future.</p>\n<h2>Installation</h2>\n<p>:warning: Python 3.6 or above is required :snake:</p>\n<p><strong>Via <a href=\"https://pypi.org/project/ethik/\" rel=\"nofollow\">PyPI</a></strong></p>\n<pre>&gt;&gt;&gt; pip install ethik\n</pre>\n<p><strong>Via GitHub for the latest development version</strong></p>\n<pre>&gt;&gt;&gt; pip install git+https://github.com/XAI-ANITI/ethik\n&gt;&gt;&gt; <span class=\"c1\">#\u00a0Or through SSH:</span>\n&gt;&gt;&gt; pip install git+ssh://git@github.com/XAI-ANITI/ethik.git\n</pre>\n<p><strong>Development installation</strong></p>\n<pre>&gt;&gt;&gt; git clone git@github.com:XAI-ANITI/ethik.git\n&gt;&gt;&gt; <span class=\"nb\">cd</span> ethik\n&gt;&gt;&gt; make install_dev\n</pre>\n<h2>User guide</h2>\n<p>:point_up: Please check out <a href=\"notebooks/binary-classification.ipynb\" rel=\"nofollow\">this notebook</a> for more detailed code.</p>\n<p>In the following example we'll be using the <a href=\"https://archive.ics.uci.edu/ml/datasets/adult\" rel=\"nofollow\">\"Adult\" dataset</a>. This dataset contains a binary label indicating if a person's annual income is larger than $50k. <code>ethik</code> can diagnose a model by looking at the predictions the model makes on a test set. Consequently, you first have to split your dataset in two (train and test).</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">sklearn</span> <span class=\"kn\">import</span> <span class=\"n\">model_selection</span>\n\n<span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">X_test</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">y_test</span> <span class=\"o\">=</span> <span class=\"n\">model_selection</span><span class=\"o\">.</span><span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">shuffle</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n</pre>\n<p>You then want to train your model on the training set and make predictions on the test set. In this example we'll train a gradient boosting classifier from the <a href=\"https://lightgbm.readthedocs.io/en/latest/\" rel=\"nofollow\">LightGBM library</a>. We'll use a variable named <code>y_pred</code> to store the predicted probabilities associated with the <code>True</code> label.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">lightgbm</span> <span class=\"k\">as</span> <span class=\"nn\">lgb</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">lgb</span><span class=\"o\">.</span><span class=\"n\">LGBMClassifier</span><span class=\"p\">(</span><span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># We use a named pandas series to make plot labels more explicit</span>\n<span class=\"n\">y_pred</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">predict_proba</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"p\">)[:,</span> <span class=\"mi\">1</span><span class=\"p\">]</span>\n<span class=\"n\">y_pred</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">Series</span><span class=\"p\">(</span><span class=\"n\">y_pred</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'&gt;$50k'</span><span class=\"p\">)</span>\n</pre>\n<p>We can now initialize an <code>ClassificationExplainer</code> using the default parameters.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">ethik</span>\n\n<span class=\"n\">explainer</span> <span class=\"o\">=</span> <span class=\"n\">ethik</span><span class=\"o\">.</span><span class=\"n\">ClassificationExplainer</span><span class=\"p\">()</span>\n</pre>\n<h3>Measuring model influence</h3>\n<p><code>ethik</code> can be used to understand how the model predictions vary as a function of one or more features. For example we can look at how the model behaves with respect to the <code>age</code> feature.</p>\n<pre><span class=\"n\">explainer</span><span class=\"o\">.</span><span class=\"n\">plot_influence</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"o\">=</span><span class=\"n\">X_test</span><span class=\"p\">[</span><span class=\"s1\">'age'</span><span class=\"p\">],</span> <span class=\"n\">y_pred</span><span class=\"o\">=</span><span class=\"n\">y_pred</span><span class=\"p\">)</span>\n</pre>\n<div>\n  <img alt=\"Age influence\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fe5b9ab0294a2bc4252882f484a5a891c5aa4d4d/646f63732f6173736574732f696d672f6167655f696e666c75656e63652e737667\">\n</div>\n<p>Recall that the target indicates if a person's annual salary is above $50k. <strong>We can see that the model predicts higher probabilities for older people</strong>. This isn't a surprising result, and could have just as well been observed by looking at the data. However, we can see that the predictions plateau at around 50 years old. Indeed, although salary is correlated with age, some people may retire early or lose their job. Furthermore we can see that the model understands the fact that salaries shrink once people get in age of retiring. This up-and-down relationship is in nature non-linear, and isn't picked up by summary statistics such as correlation coefficients, <a href=\"https://www.wikiwand.com/en/Odds_ratio\" rel=\"nofollow\">odds ratios</a>, and feature importances in general. Although the observations we made are quite obvious and rather intuitive, it's always good to confirm what the model is thinking. The point is that the curves produced by <code>plot_predictions</code> represent the relationship between a variable and the target according to the model, rather than the data.</p>\n<p>We can also plot the distribution of predictions for more than one variable. However, because different variables have different scales we have to use a common measure to display them together. For this purpose we plot the \u03c4 (\"tau\") values. These values are contained between -1 and 1 and simply reflect by how much the variable is shifted from it's mean towards it's lower and upper quantiles. In the following figure a tau value of -1 corresponds to just under 20 years old whereas a tau value of 1 refers to being slightly over 60 years old.</p>\n<pre><span class=\"n\">explainer</span><span class=\"o\">.</span><span class=\"n\">plot_influence</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"o\">=</span><span class=\"n\">X_test</span><span class=\"p\">[[</span><span class=\"s1\">'age'</span><span class=\"p\">,</span> <span class=\"s1\">'education-num'</span><span class=\"p\">]],</span> <span class=\"n\">y_pred</span><span class=\"o\">=</span><span class=\"n\">y_pred</span><span class=\"p\">)</span>\n</pre>\n<div>\n  <img alt=\"Age and education influence\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ee90e047134e37e749c6a9b02b232d9548e27e06/646f63732f6173736574732f696d672f6167655f656475636174696f6e5f696e666c75656e63652e737667\">\n</div>\n<p>We can observe that the model assigns higher probabilities to people with higher degrees, which makes perfect sense. Again, this conveys much more of a story than summary statistics.</p>\n<h3>Evaluating model reliability</h3>\n<p>Our methodology can also be used to evaluate the reliability of a model under different scenarios. Evaluation metrics that are commonly used in machine learning only tell you part of the story. Indeed they tell you the performance of a model <em>on average</em>. A more interesting approach is to visualize how accurate the model is with respect to the distribution of a variable.</p>\n<pre><span class=\"n\">explainer</span><span class=\"o\">.</span><span class=\"n\">plot_performance</span><span class=\"p\">(</span>\n    <span class=\"n\">X_test</span><span class=\"o\">=</span><span class=\"n\">X_test</span><span class=\"p\">[</span><span class=\"s1\">'age'</span><span class=\"p\">],</span>\n    <span class=\"n\">y_test</span><span class=\"o\">=</span><span class=\"n\">y_test</span><span class=\"p\">,</span>\n    <span class=\"n\">y_pred</span><span class=\"o\">=</span><span class=\"n\">y_pred</span> <span class=\"o\">&gt;</span> <span class=\"mf\">0.5</span><span class=\"p\">,</span>  <span class=\"c1\"># metrics.accuracy_score requires y_pred to be binary</span>\n    <span class=\"n\">metric</span><span class=\"o\">=</span><span class=\"n\">metrics</span><span class=\"o\">.</span><span class=\"n\">accuracy_score</span>\n<span class=\"p\">)</span>\n</pre>\n<div>\n  <img alt=\"Age accuracy\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2155f1548fd0a3004d68afb0b31b5eb4d92915ee/646f63732f6173736574732f696d672f6167655f61636375726163792e737667\">\n</div>\n<p>In the above figure <strong>we can see that the model is more reliable for younger people than for older ones</strong>. Having a fine-grained understanding of the accuracy of a model can be of extreme help in real-life scenarios. Indeed this can help you understand where the error of the model is coming from and guide your data science process.</p>\n<p>Similarly to the <code>plot_predictions</code> method, we can display the performance of the model for multiple variables.</p>\n<pre><span class=\"n\">explainer</span><span class=\"o\">.</span><span class=\"n\">plot_performance</span><span class=\"p\">(</span>\n    <span class=\"n\">X_test</span><span class=\"o\">=</span><span class=\"n\">X_test</span><span class=\"p\">[[</span><span class=\"s1\">'age'</span><span class=\"p\">,</span> <span class=\"s1\">'education-num'</span><span class=\"p\">]],</span>\n    <span class=\"n\">y_test</span><span class=\"o\">=</span><span class=\"n\">y_test</span><span class=\"p\">,</span>\n    <span class=\"n\">y_pred</span><span class=\"o\">=</span><span class=\"n\">y_pred</span> <span class=\"o\">&gt;</span> <span class=\"mf\">0.5</span><span class=\"p\">,</span>\n    <span class=\"n\">metric</span><span class=\"o\">=</span><span class=\"n\">metrics</span><span class=\"o\">.</span><span class=\"n\">accuracy_score</span>\n<span class=\"p\">)</span>\n</pre>\n<div>\n  <img alt=\"Age and education accuracy\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4c66b898e220de1434c4f1bf9190fe27253baee0/646f63732f6173736574732f696d672f6167655f656475636174696f6e5f61636375726163792e737667\">\n</div>\n<h3>Support for image classification</h3>\n<p>A special class named <code>ImageClassificationExplainer</code> can be used to analyze image classification models. It has the same API as <code>ClassificationExplainer</code>, but expects to be provided with an array of images. For instance, we can analyze a CNN run on the MNIST dataset <a href=\"https://keras.io/examples/mnist_cnn/\" rel=\"nofollow\">from the Keras documendation</a>. The model achieves an accuracy of around 99% on the test set. For the sake of brevity we will the skip the exact details of the model training.</p>\n<pre><span class=\"p\">(</span><span class=\"n\">x_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"n\">x_test</span><span class=\"p\">,</span> <span class=\"n\">y_test</span><span class=\"p\">)</span> <span class=\"o\">=</span> <span class=\"n\">mnist</span><span class=\"o\">.</span><span class=\"n\">load_data</span><span class=\"p\">()</span>\n\n<span class=\"n\">cnn</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">x_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">)</span>\n<span class=\"n\">y_pred</span> <span class=\"o\">=</span> <span class=\"n\">cnn</span><span class=\"o\">.</span><span class=\"n\">predict_proba</span><span class=\"p\">(</span><span class=\"n\">x_test</span><span class=\"p\">)</span>\n</pre>\n<p><code>x_test</code> is a set of images of shape <code>(10000, 28, 28)</code> whilst <code>y_pred</code> is a set of probabilities predicted for digit by the CNN, and is thus of shape <code>(10000, 10)</code>. We can use the <code>plot_influence</code> method to display the importance of each pixel for the classifier with respect to each label.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">ethik</span>\n\n<span class=\"n\">explainer</span> <span class=\"o\">=</span> <span class=\"n\">ethik</span><span class=\"o\">.</span><span class=\"n\">ImageClassificationExplainer</span><span class=\"p\">()</span>\n<span class=\"n\">explainer</span><span class=\"o\">.</span><span class=\"n\">plot_influence</span><span class=\"p\">(</span><span class=\"n\">x_test</span><span class=\"p\">,</span> <span class=\"n\">y_pred</span><span class=\"p\">)</span>\n</pre>\n<div>\n  <img alt=\"Image influence explanation\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/34038a325cec7f037285259b7cf936cdacd58804/646f63732f6173736574732f696d672f6d6e6973745f696e666c75656e63655f6578706c616e6174696f6e2e737667\" width=\"75%\">\n</div>\n<p>This takes around 15 seconds to run on a mid-tier laptop. The previous plot highlights the regions of importance for identifying each digit. More precisely, the intensity of each pixel corresponds to the probability increase of saturating or not the pixel. A value of 0.28 means that saturating the pixel increases the probability predicted by the model by 0.28. Note that we do not saturate and desaturate the pixels independently. Instead, our method understands which pixels are linked together and saturates them in a realistic manner. The previous images show that the CNN seems to be using the same visual cues as a human. However, we can see that is uses very specific regions on images to identify particular digits. For instance, the top-right region of an image seems to trigger the \"5\" digit, whereas the bottom parts of the images seem to be linked with the \"7\" digit. Meanwhile, the colder areas correspond to regions that lower the predicted probabilities when the corresponding pixels are \"turned on\", which is why the center of the \"0\" digit figure is blue.</p>\n<h2>Authors</h2>\n<p>This work is led by members of the <a href=\"https://www.math.univ-toulouse.fr/?lang=en\" rel=\"nofollow\">Toulouse Institute of Mathematics</a>, namely:</p>\n<ul>\n<li><a href=\"https://www.math.univ-toulouse.fr/%7Efbachoc/\" rel=\"nofollow\">Fran\u00e7ois Bachoc</a></li>\n<li><a href=\"https://www.math.univ-toulouse.fr/%7Egamboa/newwab/Pages_Fabrice_Gamboa/Main_Page.html\" rel=\"nofollow\">Fabrice Gamboa</a></li>\n<li><a href=\"https://maxhalford.github.io/\" rel=\"nofollow\">Max Halford</a></li>\n<li><a href=\"https://vayel.github.io/\" rel=\"nofollow\">Vincent Lefoulon</a></li>\n<li><a href=\"https://perso.math.univ-toulouse.fr/loubes/\" rel=\"nofollow\">Jean-Michel Loubes</a></li>\n<li><a href=\"http://laurent.risser.free.fr/menuEng.html\" rel=\"nofollow\">Laurent Risser</a></li>\n</ul>\n<p>You can contact us at <a href=\"mailto:jm.loubes@gmail.com\">jm.loubes@gmail.com</a> and/or <a href=\"mailto:maxhalford25@gmail.com\">maxhalford25@gmail.com</a>.</p>\n<p>This work is supported by the <a href=\"http://www.cnrs.fr/\" rel=\"nofollow\">Centre National de la Recherche Scientifique (CNRS)</a> and is done in the context of the <a href=\"https://en.univ-toulouse.fr/aniti\" rel=\"nofollow\">Artificial and Natural Intelligence Toulouse Institute (ANITI)</a> project.</p>\n<h2>License</h2>\n<p>This software is released under the <a href=\"LICENSE\" rel=\"nofollow\">GPL license</a>.</p>\n\n          </div>"}, "last_serial": 6294502, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "6bc2bcf9e678a6da3f06f4733bd7f59b", "sha256": "b9b70c8f299c2f1486edc6758a46b2bef92e57e6d1bc960625b4a1e98b912693"}, "downloads": -1, "filename": "ethik-0.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "6bc2bcf9e678a6da3f06f4733bd7f59b", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6.0", "size": 35096, "upload_time": "2019-10-01T13:00:55", "upload_time_iso_8601": "2019-10-01T13:00:55.998960Z", "url": "https://files.pythonhosted.org/packages/11/14/cbf0d2179c31df085230b22175d0c9535b43660977842d03acfb1c83354e/ethik-0.0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8f5e96d6451fa1256449af66777d8a81", "sha256": "bacdd478feb5cb2a508b2a5c3201ca49a644f025f5fb1a3b9584bed3b21fd35f"}, "downloads": -1, "filename": "ethik-0.0.1.tar.gz", "has_sig": false, "md5_digest": "8f5e96d6451fa1256449af66777d8a81", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 24743, "upload_time": "2019-10-01T13:01:07", "upload_time_iso_8601": "2019-10-01T13:01:07.490946Z", "url": "https://files.pythonhosted.org/packages/81/21/d20709eabb648e2daab9e30d8172ab71d7c0a6be205452afb9a819a2db2d/ethik-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "94b9fd48efe36bca43ce47fb0d567509", "sha256": "f6a4e39f194ad3a63e6493726f623509781e4dfe752a7dc0dc628d91bae575eb"}, "downloads": -1, "filename": "ethik-0.0.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "94b9fd48efe36bca43ce47fb0d567509", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6.0", "size": 278756, "upload_time": "2019-10-02T15:51:02", "upload_time_iso_8601": "2019-10-02T15:51:02.782860Z", "url": "https://files.pythonhosted.org/packages/1c/ed/d5993f53761b39014ff489877cd869d10e796047e6028776ad487652a5ea/ethik-0.0.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0c638a67746112e489d2df256ba1705d", "sha256": "05edbc5151c14d63104f2dc6545111717d9193fe87c29cd31e12b69782010820"}, "downloads": -1, "filename": "ethik-0.0.2.tar.gz", "has_sig": false, "md5_digest": "0c638a67746112e489d2df256ba1705d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 25839, "upload_time": "2019-10-02T13:52:30", "upload_time_iso_8601": "2019-10-02T13:52:30.990781Z", "url": "https://files.pythonhosted.org/packages/75/80/ce33bca42b5fa811553f9ee67ea436e854018fa7049086e84ad54bbd5f03/ethik-0.0.2.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "195b9939698d1527413f9f9058458a49", "sha256": "ccb69bbda144ffcb47db685035ad38646b77f4645b111a9c05c6691e2a4c22f7"}, "downloads": -1, "filename": "ethik-0.0.4.tar.gz", "has_sig": false, "md5_digest": "195b9939698d1527413f9f9058458a49", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 37765, "upload_time": "2019-12-13T10:32:28", "upload_time_iso_8601": "2019-12-13T10:32:28.383116Z", "url": "https://files.pythonhosted.org/packages/1c/02/9b143df3aa52ee35a23ce0d7a8a4974c03c25a3d36ba4f6bc409b01ab592/ethik-0.0.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "195b9939698d1527413f9f9058458a49", "sha256": "ccb69bbda144ffcb47db685035ad38646b77f4645b111a9c05c6691e2a4c22f7"}, "downloads": -1, "filename": "ethik-0.0.4.tar.gz", "has_sig": false, "md5_digest": "195b9939698d1527413f9f9058458a49", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 37765, "upload_time": "2019-12-13T10:32:28", "upload_time_iso_8601": "2019-12-13T10:32:28.383116Z", "url": "https://files.pythonhosted.org/packages/1c/02/9b143df3aa52ee35a23ce0d7a8a4974c03c25a3d36ba4f6bc409b01ab592/ethik-0.0.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:45:27 2020"}