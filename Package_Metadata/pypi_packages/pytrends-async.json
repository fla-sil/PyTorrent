{"info": {"author": "Kyle Kreutzer", "author_email": "kyleakreutzer@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8"], "description": "# pytrends-async\n\n## Introduction\n\nA fork of pytrends with full async/await and retry support.\n\n## Table of contents\n\n* [Installation](#installation)\n\n* [API](#api)\n\n  * [API Methods](#api-methods)\n\n  * [Common API parameters](#common-api-parameters)\n\n    * [Interest Over Time](#interest-over-time)\n    * [Historical Hourly Interest](#historical-hourly-interest)\n    * [Interest by Region](#interest-by-region)\n    * [Related Topics](#related-topics)\n    * [Related Queries](#related-queries)\n    * [Trending Searches](#trending-searches)\n    * [Top Charts](#top-charts)\n    * [Suggestions](#suggestions)\n\n  * [Caveats](#caveats)\n\n* [Credits](#credits)\n\n## Installation\n\n    pip install pytrends-async\n\n## Requirements\n\n* Written for python 3.6+\n* Requires httpx==0.9.3, lxml, Pandas\n\n<sub><sup>[back to top](#pytrends)</sub></sup>\n\n## API\n\n### Connect to Google\n\n    from pytrendsasync.request import TrendReq\n\n    pytrends = TrendReq(hl='en-US', tz=360)\n\nor if you want to use proxies as you are blocked due to Google rate limit:\n\n\n    from pytrendsasync.request import TrendReq\n\n    pytrends = TrendReq(hl='en-US', tz=360, timeout=10, proxies=['https://34.203.233.13:80',])\n\n* `timeout(connect, read)`\n\n  - Timezone Offset\n  - For example US CST is ```'360'```\n\n* `proxies`\n\n  - https proxies Google passed ONLY\n  - list ```['https://34.203.233.13:80','https://35.201.123.31:880', ..., ...]```\n  \n* `retries`\n\n  - number of retries total/connect/read all represented by one scalar\n\n* `backoff_factor`\n\n  - A backoff factor to apply between attempts after the second try (most errors are resolved immediately by a second try without a delay). tenacity will sleep for: ```{backoff factor} * (2 ^ ({number of total retries} - 1))``` seconds. If the backoff_factor is 0.1, then sleep() will sleep for [0.0s, 0.2s, 0.4s, \u2026] between retries. By default, backoff is disabled (set to 0).\n\nNote: the parameter `hl` specifies host language for accessing Google Trends. \nNote: only https proxies will work, and you need to add the port number after the proxy ip address\n\n### Build Payload\n    kw_list = [\"Blockchain\"]\n    pytrends.build_payload(kw_list, cat=0, timeframe='today 5-y', geo='', gprop='')\n\nParameters\n\n* `kw_list`\n\n  - *Required*\n  - Keywords to get data for\n\n\n<sub><sup>[back to top](#API)</sub></sup>\n\n## API Methods\n\nThe following API methods are available:\n\n* [Interest Over Time](#interest-over-time): returns historical, indexed data for when the keyword was searched most as shown on Google Trends' Interest Over Time section.\n\n* [Historical Hourly Interest](#historical-hourly-interest): returns historical, indexed, hourly data for when the keyword was searched most as shown on Google Trends' Interest Over Time section. It sends multiple requests to Google, each retrieving one week of hourly data. It seems like this would be the only way to get historical, hourly data. \n\n* [Interest by Region](#interest-by-region): returns data for where the keyword is most searched as shown on Google Trends' Interest by Region section.\n\n* [Related Topics](#related-topics): returns data for the related keywords to a provided keyword shown on Google Trends' Related Topics section.\n\n* [Related Queries](#related-queries): returns data for the related keywords to a provided keyword shown on Google Trends' Related Queries section.\n\n* [Trending Searches](#trending-searches): returns data for latest trending searches shown on Google Trends' Trending Searches section.\n\n* [Top Charts](#top-charts): returns the data for a given topic shown in Google Trends' Top Charts section.\n\n* [Suggestions](#suggestions): returns a list of additional suggested keywords that can be used to refine a trend search.\n\n<sub><sup>[back to top](#api-methods)</sub></sup>\n\n## Common API parameters\n\nMany API methods use the following:\n\n* `kw_list`\n\n  - keywords to get data for\n  - Example ```['Pizza']```\n  - Up to five terms in a list: ```['Pizza', 'Italian', 'Spaghetti', 'Breadsticks', 'Sausage']```\n\n    * Advanced Keywords\n\n      - When using Google Trends dashboard Google may provide suggested narrowed search terms.\n      - For example ```\"iron\"``` will have a drop down of ```\"Iron Chemical Element, Iron Cross, Iron Man, etc\"```.\n      - Find the encoded topic by using the get_suggestions() function and choose the most relevant one for you.\n      - For example: ```https://www.google.com/trends/explore#q=%2Fm%2F025rw19&cmpt=q```\n      - ```\"%2Fm%2F025rw19\"``` is the topic \"Iron Chemical Element\" to use this with pytrends\n      - You can also use `pytrends.suggestions()` to automate this.\n\n* `cat`\n\n  - Category to narrow results\n  - Find available cateogies by inspecting the url when manually using Google Trends. The category starts after ```cat=``` and ends before the next ```&``` or view this [wiki page containing all available categories](https://github.com/pat310/google-trends-api/wiki/Google-Trends-Categories)\n  - For example: ```\"https://www.google.com/trends/explore#q=pizza&cat=71\"```\n  - ```'71'``` is the category\n  - Defaults to no category\n\n* `geo`\n\n  - Two letter country abbreviation\n  - For example United States is ```'US'```\n  - Defaults to World\n  - More detail available for States/Provinces by specifying additonal abbreviations\n  - For example: Alabama would be ```'US-AL'```\n  - For example: England would be ```'GB-ENG'```\n\n* `tz`\n\n  - Timezone Offset (in minutes)\n  - For more information of Timezone Offset, [view this wiki page containing about UCT offset](https://en.wikipedia.org/wiki/UTC_offset)\n  - For example US CST is ```'360'``` \n\n* `timeframe`\n\n  - Date to start from\n  - Defaults to last 5yrs, `'today 5-y'`.\n  - Everything `'all'`\n  - Specific dates, 'YYYY-MM-DD YYYY-MM-DD' example `'2016-12-14 2017-01-25'`\n  - Specific datetimes, 'YYYY-MM-DDTHH YYYY-MM-DDTHH' example `'2017-02-06T10 2017-02-12T07'`\n      - Note Time component is based off UTC\n\n  - Current Time Minus Time Pattern:\n\n    - By Month: ```'today #-m'``` where # is the number of months from that date to pull data for\n      - For example: ``'today 3-m'`` would get data from today to 3months ago\n      - **NOTE** Google uses UTC date as *'today'*\n      - Seems to only work for 1, 2, 3 months only\n\n    - Daily: ```'now #-d'``` where # is the number of days from that date to pull data for\n      - For example: ``'now 7-d'`` would get data from the last week\n      - Seems to only work for 1, 7 days only\n\n    - Hourly: ```'now #-H'``` where # is the number of hours from that date to pull data for\n      - For example: ``'now 1-H'`` would get data from the last hour\n      - Seems to only work for 1, 4 hours only\n\n* `gprop`\n\n  - What Google property to filter to\n  - Example ```'images'```\n  - Defaults to web searches\n  - Can be ```images```, ```news```, ```youtube``` or ```froogle``` (for Google Shopping results)\n\n\n<sub><sup>[back to top](#api-payload-keys)</sub></sup>\n\n### Interest Over Time\n\n    await pytrends.interest_over_time()\n\nReturns pandas.Dataframe\n\n<sub><sup>[back to top](#interest_over_time)</sub></sup>\n\n\n### Historical Hourly Interest\n\n    await pytrends.get_historical_interest(kw_list, year_start=2018, month_start=1, day_start=1, hour_start=0, year_end=2018, month_end=2, day_end=1, hour_end=0, cat=0, geo='', gprop='', sleep=0)\n    \nParameters \n\n* `kw_list`\n\n  - *Required*\n  - list of keywords that you would like the historical data\n\n* `year_start, month_start, day_start, hour_start, year_end, month_end, day_end, hour_end`\n\n  - the time period for which you would like the historical data\n  \n* `sleep`\n\n  - If you are rate-limited by Google, you should set this parameter to something (i.e. 60) to space off each API call. \n  \nReturns pandas.Dataframe\n\n<sub><sup>[back to top](#historical-hourly-interest)</sub></sup>\n\n### Interest by Region\n\n     await pytrends.interest_by_region(resolution='COUNTRY', inc_low_vol=True, inc_geo_code=False)\n\nParameters\n\n* `resolution`\n\n  - 'CITY' returns city level data\n  - 'COUNTRY' returns country level data\n  - 'DMA'  returns Metro level data\n  - 'REGION'  returns Region level data\n\n* `inc_low_vol`\n\n  - True/False (includes google trends data for low volume countries/regions as well)\n\n* `inc_geo_code`\n  \n  - True/False (includes ISO codes of countries along with the names in the data)\n\nReturns pandas.DataFrame\n\n<sub><sup>[back to top](#interest_by_region)</sub></sup>\n\n### Related Topics\n\n    await pytrends.related_topics()\n\nReturns dictionary of pandas.DataFrames\n\n<sub><sup>[back to top](#related_topics)</sub></sup>\n\n### Related Queries\n\n    await pytrends.related_queries()\n\nReturns dictionary of pandas.DataFrames\n\n<sub><sup>[back to top](#related_queries)</sub></sup>\n\n### Trending Searches\n\n\tawait pytrends.trending_searches(pn='united_states') # trending searches in real time for United States\n\tawait pytrends.trending_searches(pn='japan') # Japan\n\nReturns pandas.DataFrame\n\n<sub><sup>[back to top](#trending_searches)</sub></sup>\n\n### Top Charts\n\n    await pytrends.top_charts(date, hl='en-US', tz=300, geo='GLOBAL')\n\nParameters\n\n* `date`\n\n  - *Required*\n  - YYYY or YYYYMM integer\n  - Example `201611` for November 2016 Top Chart data\n\nReturns pandas.DataFrame\n\n<sub><sup>[back to top](#top_charts)</sub></sup>\n\n### Suggestions\n\n    await pytrends.suggestions(keyword)\n\nParameters\n\n* `keyword`\n\n  - *Required*\n  - keyword to get suggestions for\n\nReturns dictionary\n\n<sub><sup>[back to top](#suggestions)</sub></sup>\n\n### Categories\n\n    await pytrends.categories()\n\nReturns dictionary\n\n<sub><sup>[back to top](#suggestions)</sub></sup>\n\n# Caveats\n\n* This is not an official or supported API\n* Google may change aggregation level for items with very large or very small search volume\n* Rate Limit is not publicly known, let me know if you have a consistent estimate\n  * One user reports that 1,400 sequential requests of a 4 hours timeframe got them to the limit. (Replicated on 2 networks)\n  * It has been tested, and 60 seconds of sleep between requests (successful or not) is the correct amount once you reach the limit.\n* For certain configurations the dependency lib certifi requires the environment variable REQUESTS_CA_BUNDLE to be explicitly set and exported. This variable must contain the path where the ca-certificates are saved or a SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] error is given at runtime. \n\n# Credits\n\n* Major JSON revision ideas taken from pat310's JavaScript library\n\n  - https://github.com/pat310/google-trends-api\n\n* Connecting to google code heavily based off Stack Overflow post\n\n  - http://stackoverflow.com/questions/6754709/logging-in-to-google-using-python\n\n* With some ideas pulled from Matt Reid's Google Trends API\n\n  - https://bitbucket.org/mattreid9956/google-trend-api/overview\n\n\n# ChangeLog\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),\n\n## 0.3.2 (2019-12-23)\n\n### Changed\n- Updated underlying HTTPX library to 0.9.5 from 0.9.3\n\n## 0.3.1 (2019-12-08)\n\n### Fixed\n- Fixed import of `asyncio.sleep` in `dailydata.py`\n\n## 0.3.0 (2019-12-08)\n\n### Added\n- Retry support has been reintroduced (back by tenacity). Retry settings only apply when proxies are not in use.\n- Python 3.8 is now offically tested and supported.\n\n### Changed\n- Reintroduced `retries` and `backoff_factor` to `TrendsReq.__init__()`. `retries` and `backoff_factor` are disabled by default (set to 0). These parameters will only affect retrying if proxies are not in use. \n- Proxies that return a 429 (Too Many Requests) will no longer be removed the proxy list. Instead, another proxy (or no proxy if all proxies have been exausted) will be used in the next request.\n- Proxies that trigger an error that is not caused by a 429 response code (ConnectionRefusedError, SSLError) will be placed in `TrendReq.blacklisted_proxies` instead of removed from the proxies list.\n- Underyling httpx library has been updated to version 0.9.3.\n\n### Fixed\n- `dailydata.py` now uses `asyncio.sleep` instead of `time.sleep`.\n\n## 0.2.1 (2019-12-04)\n\n### Changed\n- Fixed importing issue\n\n## 0.2.0 (2019-12-04)\n\n### Added\n- This changelog :)\n- Proxy support has been introduced but still needs further testing.\n\n### Changed\n- `GetNewProxy()` replaced with internal method `_iterate_proxy()`\n- Protocol changed from HTTP/2 to HTTP/1.1. This resolves a KeyError that was occurring with the underlying http2 lib.\n- HTTP connections are now properly cleaned up after use.\n\n## 0.1.0 (2019-12-01)\n\n- Initial release of pytrends-async for testing purposes.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/KyleKreutzer/pytrends-async/archive/0.3.2.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/KyleKreutzer/pytrends-async", "keywords": "google trends api search async asyncio", "license": "Apache 2.0", "maintainer": "", "maintainer_email": "", "name": "pytrends-async", "package_url": "https://pypi.org/project/pytrends-async/", "platform": "", "project_url": "https://pypi.org/project/pytrends-async/", "project_urls": {"Download": "https://github.com/KyleKreutzer/pytrends-async/archive/0.3.2.tar.gz", "Homepage": "https://github.com/KyleKreutzer/pytrends-async"}, "release_url": "https://pypi.org/project/pytrends-async/0.3.2/", "requires_dist": null, "requires_python": "", "summary": "Pseudo API for Google Trends with asyncio support.", "version": "0.3.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>pytrends-async</h1>\n<h2>Introduction</h2>\n<p>A fork of pytrends with full async/await and retry support.</p>\n<h2>Table of contents</h2>\n<ul>\n<li>\n<p><a href=\"#installation\" rel=\"nofollow\">Installation</a></p>\n</li>\n<li>\n<p><a href=\"#api\" rel=\"nofollow\">API</a></p>\n<ul>\n<li>\n<p><a href=\"#api-methods\" rel=\"nofollow\">API Methods</a></p>\n</li>\n<li>\n<p><a href=\"#common-api-parameters\" rel=\"nofollow\">Common API parameters</a></p>\n<ul>\n<li><a href=\"#interest-over-time\" rel=\"nofollow\">Interest Over Time</a></li>\n<li><a href=\"#historical-hourly-interest\" rel=\"nofollow\">Historical Hourly Interest</a></li>\n<li><a href=\"#interest-by-region\" rel=\"nofollow\">Interest by Region</a></li>\n<li><a href=\"#related-topics\" rel=\"nofollow\">Related Topics</a></li>\n<li><a href=\"#related-queries\" rel=\"nofollow\">Related Queries</a></li>\n<li><a href=\"#trending-searches\" rel=\"nofollow\">Trending Searches</a></li>\n<li><a href=\"#top-charts\" rel=\"nofollow\">Top Charts</a></li>\n<li><a href=\"#suggestions\" rel=\"nofollow\">Suggestions</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#caveats\" rel=\"nofollow\">Caveats</a></p>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#credits\" rel=\"nofollow\">Credits</a></p>\n</li>\n</ul>\n<h2>Installation</h2>\n<pre><code>pip install pytrends-async\n</code></pre>\n<h2>Requirements</h2>\n<ul>\n<li>Written for python 3.6+</li>\n<li>Requires httpx==0.9.3, lxml, Pandas</li>\n</ul>\n<p><sub><sup><a href=\"#pytrends\" rel=\"nofollow\">back to top</a></sup></sub></p>\n<h2>API</h2>\n<h3>Connect to Google</h3>\n<pre><code>from pytrendsasync.request import TrendReq\n\npytrends = TrendReq(hl='en-US', tz=360)\n</code></pre>\n<p>or if you want to use proxies as you are blocked due to Google rate limit:</p>\n<pre><code>from pytrendsasync.request import TrendReq\n\npytrends = TrendReq(hl='en-US', tz=360, timeout=10, proxies=['https://34.203.233.13:80',])\n</code></pre>\n<ul>\n<li>\n<p><code>timeout(connect, read)</code></p>\n<ul>\n<li>Timezone Offset</li>\n<li>For example US CST is <code>'360'</code></li>\n</ul>\n</li>\n<li>\n<p><code>proxies</code></p>\n<ul>\n<li>https proxies Google passed ONLY</li>\n<li>list <code>['https://34.203.233.13:80','https://35.201.123.31:880', ..., ...]</code></li>\n</ul>\n</li>\n<li>\n<p><code>retries</code></p>\n<ul>\n<li>number of retries total/connect/read all represented by one scalar</li>\n</ul>\n</li>\n<li>\n<p><code>backoff_factor</code></p>\n<ul>\n<li>A backoff factor to apply between attempts after the second try (most errors are resolved immediately by a second try without a delay). tenacity will sleep for: <code>{backoff factor} * (2 ^ ({number of total retries} - 1))</code> seconds. If the backoff_factor is 0.1, then sleep() will sleep for [0.0s, 0.2s, 0.4s, \u2026] between retries. By default, backoff is disabled (set to 0).</li>\n</ul>\n</li>\n</ul>\n<p>Note: the parameter <code>hl</code> specifies host language for accessing Google Trends.\nNote: only https proxies will work, and you need to add the port number after the proxy ip address</p>\n<h3>Build Payload</h3>\n<pre><code>kw_list = [\"Blockchain\"]\npytrends.build_payload(kw_list, cat=0, timeframe='today 5-y', geo='', gprop='')\n</code></pre>\n<p>Parameters</p>\n<ul>\n<li>\n<p><code>kw_list</code></p>\n<ul>\n<li><em>Required</em></li>\n<li>Keywords to get data for</li>\n</ul>\n</li>\n</ul>\n<p><sub><sup><a href=\"#API\" rel=\"nofollow\">back to top</a></sup></sub></p>\n<h2>API Methods</h2>\n<p>The following API methods are available:</p>\n<ul>\n<li>\n<p><a href=\"#interest-over-time\" rel=\"nofollow\">Interest Over Time</a>: returns historical, indexed data for when the keyword was searched most as shown on Google Trends' Interest Over Time section.</p>\n</li>\n<li>\n<p><a href=\"#historical-hourly-interest\" rel=\"nofollow\">Historical Hourly Interest</a>: returns historical, indexed, hourly data for when the keyword was searched most as shown on Google Trends' Interest Over Time section. It sends multiple requests to Google, each retrieving one week of hourly data. It seems like this would be the only way to get historical, hourly data.</p>\n</li>\n<li>\n<p><a href=\"#interest-by-region\" rel=\"nofollow\">Interest by Region</a>: returns data for where the keyword is most searched as shown on Google Trends' Interest by Region section.</p>\n</li>\n<li>\n<p><a href=\"#related-topics\" rel=\"nofollow\">Related Topics</a>: returns data for the related keywords to a provided keyword shown on Google Trends' Related Topics section.</p>\n</li>\n<li>\n<p><a href=\"#related-queries\" rel=\"nofollow\">Related Queries</a>: returns data for the related keywords to a provided keyword shown on Google Trends' Related Queries section.</p>\n</li>\n<li>\n<p><a href=\"#trending-searches\" rel=\"nofollow\">Trending Searches</a>: returns data for latest trending searches shown on Google Trends' Trending Searches section.</p>\n</li>\n<li>\n<p><a href=\"#top-charts\" rel=\"nofollow\">Top Charts</a>: returns the data for a given topic shown in Google Trends' Top Charts section.</p>\n</li>\n<li>\n<p><a href=\"#suggestions\" rel=\"nofollow\">Suggestions</a>: returns a list of additional suggested keywords that can be used to refine a trend search.</p>\n</li>\n</ul>\n<p><sub><sup><a href=\"#api-methods\" rel=\"nofollow\">back to top</a></sup></sub></p>\n<h2>Common API parameters</h2>\n<p>Many API methods use the following:</p>\n<ul>\n<li>\n<p><code>kw_list</code></p>\n<ul>\n<li>\n<p>keywords to get data for</p>\n</li>\n<li>\n<p>Example <code>['Pizza']</code></p>\n</li>\n<li>\n<p>Up to five terms in a list: <code>['Pizza', 'Italian', 'Spaghetti', 'Breadsticks', 'Sausage']</code></p>\n<ul>\n<li>\n<p>Advanced Keywords</p>\n<ul>\n<li>When using Google Trends dashboard Google may provide suggested narrowed search terms.</li>\n<li>For example <code>\"iron\"</code> will have a drop down of <code>\"Iron Chemical Element, Iron Cross, Iron Man, etc\"</code>.</li>\n<li>Find the encoded topic by using the get_suggestions() function and choose the most relevant one for you.</li>\n<li>For example: <code>https://www.google.com/trends/explore#q=%2Fm%2F025rw19&amp;cmpt=q</code></li>\n<li><code>\"%2Fm%2F025rw19\"</code> is the topic \"Iron Chemical Element\" to use this with pytrends</li>\n<li>You can also use <code>pytrends.suggestions()</code> to automate this.</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><code>cat</code></p>\n<ul>\n<li>Category to narrow results</li>\n<li>Find available cateogies by inspecting the url when manually using Google Trends. The category starts after <code>cat=</code> and ends before the next <code>&amp;</code> or view this <a href=\"https://github.com/pat310/google-trends-api/wiki/Google-Trends-Categories\" rel=\"nofollow\">wiki page containing all available categories</a></li>\n<li>For example: <code>\"https://www.google.com/trends/explore#q=pizza&amp;cat=71\"</code></li>\n<li><code>'71'</code> is the category</li>\n<li>Defaults to no category</li>\n</ul>\n</li>\n<li>\n<p><code>geo</code></p>\n<ul>\n<li>Two letter country abbreviation</li>\n<li>For example United States is <code>'US'</code></li>\n<li>Defaults to World</li>\n<li>More detail available for States/Provinces by specifying additonal abbreviations</li>\n<li>For example: Alabama would be <code>'US-AL'</code></li>\n<li>For example: England would be <code>'GB-ENG'</code></li>\n</ul>\n</li>\n<li>\n<p><code>tz</code></p>\n<ul>\n<li>Timezone Offset (in minutes)</li>\n<li>For more information of Timezone Offset, <a href=\"https://en.wikipedia.org/wiki/UTC_offset\" rel=\"nofollow\">view this wiki page containing about UCT offset</a></li>\n<li>For example US CST is <code>'360'</code></li>\n</ul>\n</li>\n<li>\n<p><code>timeframe</code></p>\n<ul>\n<li>\n<p>Date to start from</p>\n</li>\n<li>\n<p>Defaults to last 5yrs, <code>'today 5-y'</code>.</p>\n</li>\n<li>\n<p>Everything <code>'all'</code></p>\n</li>\n<li>\n<p>Specific dates, 'YYYY-MM-DD YYYY-MM-DD' example <code>'2016-12-14 2017-01-25'</code></p>\n</li>\n<li>\n<p>Specific datetimes, 'YYYY-MM-DDTHH YYYY-MM-DDTHH' example <code>'2017-02-06T10 2017-02-12T07'</code></p>\n<ul>\n<li>Note Time component is based off UTC</li>\n</ul>\n</li>\n<li>\n<p>Current Time Minus Time Pattern:</p>\n<ul>\n<li>\n<p>By Month: <code>'today #-m'</code> where # is the number of months from that date to pull data for</p>\n<ul>\n<li>For example: <code>'today 3-m'</code> would get data from today to 3months ago</li>\n<li><strong>NOTE</strong> Google uses UTC date as <em>'today'</em></li>\n<li>Seems to only work for 1, 2, 3 months only</li>\n</ul>\n</li>\n<li>\n<p>Daily: <code>'now #-d'</code> where # is the number of days from that date to pull data for</p>\n<ul>\n<li>For example: <code>'now 7-d'</code> would get data from the last week</li>\n<li>Seems to only work for 1, 7 days only</li>\n</ul>\n</li>\n<li>\n<p>Hourly: <code>'now #-H'</code> where # is the number of hours from that date to pull data for</p>\n<ul>\n<li>For example: <code>'now 1-H'</code> would get data from the last hour</li>\n<li>Seems to only work for 1, 4 hours only</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><code>gprop</code></p>\n<ul>\n<li>What Google property to filter to</li>\n<li>Example <code>'images'</code></li>\n<li>Defaults to web searches</li>\n<li>Can be <code>images</code>, <code>news</code>, <code>youtube</code> or <code>froogle</code> (for Google Shopping results)</li>\n</ul>\n</li>\n</ul>\n<p><sub><sup><a href=\"#api-payload-keys\" rel=\"nofollow\">back to top</a></sup></sub></p>\n<h3>Interest Over Time</h3>\n<pre><code>await pytrends.interest_over_time()\n</code></pre>\n<p>Returns pandas.Dataframe</p>\n<p><sub><sup><a href=\"#interest_over_time\" rel=\"nofollow\">back to top</a></sup></sub></p>\n<h3>Historical Hourly Interest</h3>\n<pre><code>await pytrends.get_historical_interest(kw_list, year_start=2018, month_start=1, day_start=1, hour_start=0, year_end=2018, month_end=2, day_end=1, hour_end=0, cat=0, geo='', gprop='', sleep=0)\n</code></pre>\n<p>Parameters</p>\n<ul>\n<li>\n<p><code>kw_list</code></p>\n<ul>\n<li><em>Required</em></li>\n<li>list of keywords that you would like the historical data</li>\n</ul>\n</li>\n<li>\n<p><code>year_start, month_start, day_start, hour_start, year_end, month_end, day_end, hour_end</code></p>\n<ul>\n<li>the time period for which you would like the historical data</li>\n</ul>\n</li>\n<li>\n<p><code>sleep</code></p>\n<ul>\n<li>If you are rate-limited by Google, you should set this parameter to something (i.e. 60) to space off each API call.</li>\n</ul>\n</li>\n</ul>\n<p>Returns pandas.Dataframe</p>\n<p><sub><sup><a href=\"#historical-hourly-interest\" rel=\"nofollow\">back to top</a></sup></sub></p>\n<h3>Interest by Region</h3>\n<pre><code> await pytrends.interest_by_region(resolution='COUNTRY', inc_low_vol=True, inc_geo_code=False)\n</code></pre>\n<p>Parameters</p>\n<ul>\n<li>\n<p><code>resolution</code></p>\n<ul>\n<li>'CITY' returns city level data</li>\n<li>'COUNTRY' returns country level data</li>\n<li>'DMA'  returns Metro level data</li>\n<li>'REGION'  returns Region level data</li>\n</ul>\n</li>\n<li>\n<p><code>inc_low_vol</code></p>\n<ul>\n<li>True/False (includes google trends data for low volume countries/regions as well)</li>\n</ul>\n</li>\n<li>\n<p><code>inc_geo_code</code></p>\n<ul>\n<li>True/False (includes ISO codes of countries along with the names in the data)</li>\n</ul>\n</li>\n</ul>\n<p>Returns pandas.DataFrame</p>\n<p><sub><sup><a href=\"#interest_by_region\" rel=\"nofollow\">back to top</a></sup></sub></p>\n<h3>Related Topics</h3>\n<pre><code>await pytrends.related_topics()\n</code></pre>\n<p>Returns dictionary of pandas.DataFrames</p>\n<p><sub><sup><a href=\"#related_topics\" rel=\"nofollow\">back to top</a></sup></sub></p>\n<h3>Related Queries</h3>\n<pre><code>await pytrends.related_queries()\n</code></pre>\n<p>Returns dictionary of pandas.DataFrames</p>\n<p><sub><sup><a href=\"#related_queries\" rel=\"nofollow\">back to top</a></sup></sub></p>\n<h3>Trending Searches</h3>\n<pre><code>await pytrends.trending_searches(pn='united_states') # trending searches in real time for United States\nawait pytrends.trending_searches(pn='japan') # Japan\n</code></pre>\n<p>Returns pandas.DataFrame</p>\n<p><sub><sup><a href=\"#trending_searches\" rel=\"nofollow\">back to top</a></sup></sub></p>\n<h3>Top Charts</h3>\n<pre><code>await pytrends.top_charts(date, hl='en-US', tz=300, geo='GLOBAL')\n</code></pre>\n<p>Parameters</p>\n<ul>\n<li>\n<p><code>date</code></p>\n<ul>\n<li><em>Required</em></li>\n<li>YYYY or YYYYMM integer</li>\n<li>Example <code>201611</code> for November 2016 Top Chart data</li>\n</ul>\n</li>\n</ul>\n<p>Returns pandas.DataFrame</p>\n<p><sub><sup><a href=\"#top_charts\" rel=\"nofollow\">back to top</a></sup></sub></p>\n<h3>Suggestions</h3>\n<pre><code>await pytrends.suggestions(keyword)\n</code></pre>\n<p>Parameters</p>\n<ul>\n<li>\n<p><code>keyword</code></p>\n<ul>\n<li><em>Required</em></li>\n<li>keyword to get suggestions for</li>\n</ul>\n</li>\n</ul>\n<p>Returns dictionary</p>\n<p><sub><sup><a href=\"#suggestions\" rel=\"nofollow\">back to top</a></sup></sub></p>\n<h3>Categories</h3>\n<pre><code>await pytrends.categories()\n</code></pre>\n<p>Returns dictionary</p>\n<p><sub><sup><a href=\"#suggestions\" rel=\"nofollow\">back to top</a></sup></sub></p>\n<h1>Caveats</h1>\n<ul>\n<li>This is not an official or supported API</li>\n<li>Google may change aggregation level for items with very large or very small search volume</li>\n<li>Rate Limit is not publicly known, let me know if you have a consistent estimate\n<ul>\n<li>One user reports that 1,400 sequential requests of a 4 hours timeframe got them to the limit. (Replicated on 2 networks)</li>\n<li>It has been tested, and 60 seconds of sleep between requests (successful or not) is the correct amount once you reach the limit.</li>\n</ul>\n</li>\n<li>For certain configurations the dependency lib certifi requires the environment variable REQUESTS_CA_BUNDLE to be explicitly set and exported. This variable must contain the path where the ca-certificates are saved or a SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] error is given at runtime.</li>\n</ul>\n<h1>Credits</h1>\n<ul>\n<li>\n<p>Major JSON revision ideas taken from pat310's JavaScript library</p>\n<ul>\n<li><a href=\"https://github.com/pat310/google-trends-api\" rel=\"nofollow\">https://github.com/pat310/google-trends-api</a></li>\n</ul>\n</li>\n<li>\n<p>Connecting to google code heavily based off Stack Overflow post</p>\n<ul>\n<li><a href=\"http://stackoverflow.com/questions/6754709/logging-in-to-google-using-python\" rel=\"nofollow\">http://stackoverflow.com/questions/6754709/logging-in-to-google-using-python</a></li>\n</ul>\n</li>\n<li>\n<p>With some ideas pulled from Matt Reid's Google Trends API</p>\n<ul>\n<li><a href=\"https://bitbucket.org/mattreid9956/google-trend-api/overview\" rel=\"nofollow\">https://bitbucket.org/mattreid9956/google-trend-api/overview</a></li>\n</ul>\n</li>\n</ul>\n<h1>ChangeLog</h1>\n<p>All notable changes to this project will be documented in this file.</p>\n<p>The format is based on <a href=\"https://keepachangelog.com/en/1.0.0/\" rel=\"nofollow\">Keep a Changelog</a>,</p>\n<h2>0.3.2 (2019-12-23)</h2>\n<h3>Changed</h3>\n<ul>\n<li>Updated underlying HTTPX library to 0.9.5 from 0.9.3</li>\n</ul>\n<h2>0.3.1 (2019-12-08)</h2>\n<h3>Fixed</h3>\n<ul>\n<li>Fixed import of <code>asyncio.sleep</code> in <code>dailydata.py</code></li>\n</ul>\n<h2>0.3.0 (2019-12-08)</h2>\n<h3>Added</h3>\n<ul>\n<li>Retry support has been reintroduced (back by tenacity). Retry settings only apply when proxies are not in use.</li>\n<li>Python 3.8 is now offically tested and supported.</li>\n</ul>\n<h3>Changed</h3>\n<ul>\n<li>Reintroduced <code>retries</code> and <code>backoff_factor</code> to <code>TrendsReq.__init__()</code>. <code>retries</code> and <code>backoff_factor</code> are disabled by default (set to 0). These parameters will only affect retrying if proxies are not in use.</li>\n<li>Proxies that return a 429 (Too Many Requests) will no longer be removed the proxy list. Instead, another proxy (or no proxy if all proxies have been exausted) will be used in the next request.</li>\n<li>Proxies that trigger an error that is not caused by a 429 response code (ConnectionRefusedError, SSLError) will be placed in <code>TrendReq.blacklisted_proxies</code> instead of removed from the proxies list.</li>\n<li>Underyling httpx library has been updated to version 0.9.3.</li>\n</ul>\n<h3>Fixed</h3>\n<ul>\n<li><code>dailydata.py</code> now uses <code>asyncio.sleep</code> instead of <code>time.sleep</code>.</li>\n</ul>\n<h2>0.2.1 (2019-12-04)</h2>\n<h3>Changed</h3>\n<ul>\n<li>Fixed importing issue</li>\n</ul>\n<h2>0.2.0 (2019-12-04)</h2>\n<h3>Added</h3>\n<ul>\n<li>This changelog :)</li>\n<li>Proxy support has been introduced but still needs further testing.</li>\n</ul>\n<h3>Changed</h3>\n<ul>\n<li><code>GetNewProxy()</code> replaced with internal method <code>_iterate_proxy()</code></li>\n<li>Protocol changed from HTTP/2 to HTTP/1.1. This resolves a KeyError that was occurring with the underlying http2 lib.</li>\n<li>HTTP connections are now properly cleaned up after use.</li>\n</ul>\n<h2>0.1.0 (2019-12-01)</h2>\n<ul>\n<li>Initial release of pytrends-async for testing purposes.</li>\n</ul>\n\n          </div>"}, "last_serial": 6359260, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "ed9a8964734fe5a4230c4857c8f0c1b6", "sha256": "3f9d18f6c49eabb3220937769099158cc0d0b50cb589816a6c0775eb4c4e2abb"}, "downloads": -1, "filename": "pytrends-async-0.1.0.tar.gz", "has_sig": false, "md5_digest": "ed9a8964734fe5a4230c4857c8f0c1b6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14271, "upload_time": "2019-12-02T03:06:01", "upload_time_iso_8601": "2019-12-02T03:06:01.243434Z", "url": "https://files.pythonhosted.org/packages/4e/c7/396182124a92ffe6bc14e7ca5cc807e1ba89dcac33b9f89e8e7a15eff676/pytrends-async-0.1.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "3baef7c617214475ddb011b72ba5c74b", "sha256": "fc1bb2e13f171ab8d7bcdff2dc19e8341fc267e1e435e221903947a56c253fa8"}, "downloads": -1, "filename": "pytrends-async-0.2.0.tar.gz", "has_sig": false, "md5_digest": "3baef7c617214475ddb011b72ba5c74b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14255, "upload_time": "2019-12-04T22:54:19", "upload_time_iso_8601": "2019-12-04T22:54:19.781605Z", "url": "https://files.pythonhosted.org/packages/5c/9a/3006d2c67a6be6e47d6a67cece1673264b2ccbf8bb5a957b2500e13dd5c8/pytrends-async-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "093d15032e42b031e9ade24d8d796f4b", "sha256": "dc006542f8889b73f649ce92f587823d61c88034d65acdabb9d0c263dc160378"}, "downloads": -1, "filename": "pytrends-async-0.2.1.tar.gz", "has_sig": false, "md5_digest": "093d15032e42b031e9ade24d8d796f4b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14219, "upload_time": "2019-12-04T23:30:31", "upload_time_iso_8601": "2019-12-04T23:30:31.453924Z", "url": "https://files.pythonhosted.org/packages/fc/7d/82d57ee0a0261102af0a33bdbe90fb29c142eae273c2f306c4a633a472ba/pytrends-async-0.2.1.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "43abd8701c0fe12c76ec6de74c12070a", "sha256": "9382732835449a61277980f0bcd2ce9393fbab803d85e8087383c7e6034a2827"}, "downloads": -1, "filename": "pytrends-async-0.3.0.tar.gz", "has_sig": false, "md5_digest": "43abd8701c0fe12c76ec6de74c12070a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17034, "upload_time": "2019-12-09T00:08:25", "upload_time_iso_8601": "2019-12-09T00:08:25.977383Z", "url": "https://files.pythonhosted.org/packages/a4/79/4cf2ef2ee6e6233590afc080fc3c2eabfe30e99e9c17fd2ea17e529c76b7/pytrends-async-0.3.0.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "d972a029d9ae198911be02dd4cb829ec", "sha256": "4e547990014be0301aacebf5079207a233560c64054d75b6c0317e431062800e"}, "downloads": -1, "filename": "pytrends-async-0.3.1.tar.gz", "has_sig": false, "md5_digest": "d972a029d9ae198911be02dd4cb829ec", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17053, "upload_time": "2019-12-09T00:58:22", "upload_time_iso_8601": "2019-12-09T00:58:22.603891Z", "url": "https://files.pythonhosted.org/packages/17/22/2a4899d9114c532dcd822514f30fb856ea27fb62666d32a5d96a4ec7c543/pytrends-async-0.3.1.tar.gz", "yanked": false}], "0.3.2": [{"comment_text": "", "digests": {"md5": "64b394513d47f27b1c84912cfc529d84", "sha256": "47d5e15cd76410c55d2e8a9f85983a9411f5cd8393f3fff3ca6d22e1721964d2"}, "downloads": -1, "filename": "pytrends-async-0.3.2.tar.gz", "has_sig": false, "md5_digest": "64b394513d47f27b1c84912cfc529d84", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17122, "upload_time": "2019-12-25T18:16:17", "upload_time_iso_8601": "2019-12-25T18:16:17.192833Z", "url": "https://files.pythonhosted.org/packages/25/db/88d1872ac0325c15ab7b63c974b544dbf65a212e66fa698224a78bc3f1f3/pytrends-async-0.3.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "64b394513d47f27b1c84912cfc529d84", "sha256": "47d5e15cd76410c55d2e8a9f85983a9411f5cd8393f3fff3ca6d22e1721964d2"}, "downloads": -1, "filename": "pytrends-async-0.3.2.tar.gz", "has_sig": false, "md5_digest": "64b394513d47f27b1c84912cfc529d84", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17122, "upload_time": "2019-12-25T18:16:17", "upload_time_iso_8601": "2019-12-25T18:16:17.192833Z", "url": "https://files.pythonhosted.org/packages/25/db/88d1872ac0325c15ab7b63c974b544dbf65a212e66fa698224a78bc3f1f3/pytrends-async-0.3.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:13:16 2020"}