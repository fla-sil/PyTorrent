{"info": {"author": "dcronkite", "author_email": "dcronkite+pypi@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3 :: Only", "Topic :: Text Processing :: Linguistic"], "description": "# pytakes\nSimple entity extraction module released under the MIT license.\n\n## Overview\n\nThis module will look for a pre-defined set of terms in a corpus of text, and use a variation of the negex/context algorithm to determine whether these terms express negation, historical, or various other qualifiers. (The set of negation terms is also configurable.)\n\n## Requirements ##\n* Python 3.6+\n* See requirements.txt (`pip install -r requirements.txt`)\n    * Various requirements-_.txt files are provided depending on your needs:\n        * dev: for running tests, general development\n        * db: for connecting to database using pyodbc\n        * psql: connecting to postgres database\n        * sas: if data is stored in SAS\n      \n\n## Prerequisites ##\n1. Generate a word list of terms/concepts ('concept dictionary')\n    * in pyTAKES, a 'concept' is a set of terms with more or less the same meaning (e.g., ckd, chronic kidney disease)\n    * the minimal should be a CSV file with three columns:\n        * id - unique int for each line\n        * cui - string label for a 'concept' ('concept unique identifier')\n        * text - text to look for\n    * dictionary builder script is also provided which help generate variations of terms(documented below)\n2. A corpus with an id (for tracking, this will be in output) and text field (for processing, extracting concepts)\n\n## Doco ##\n\n### Basics ###\n\n* The entry point is `python example/run.py config.py`. \n    * You can see an example `config.py` at `example/simple/example.config.py`\n    * `pytakes` module must be on your PYTHONPATH, so `set/export PYTHONPATH=src` prior to running\n        \n\n### Install ###\n1. Clone from git repo: `git clone ...pytakes.git`\n2. `cd pytakes`\n3. (optional) build virtualenv\n    * `PYTHON_INSTALL/Scripts/virtualenv .venv`\n    * `pip install virtualenv` if not yet available\n4. Pip install prerequisites `pip install -r requirements.txt` \n5. Run tests (`pytest tests`)\n\n### Use ###\nYou will need to have an input `concepts.csv` file with at least three columns (`id`, `cui`, `text`). There are several examples in the `pytakes/tests/data` directory.\n\n#### Negation Table ####\nThis table implements a modified version of Chapman's ConText (see, e.g., http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.145.6566&rep=rep1&type=pdf, and https://code.google.com/archive/p/negex/).\n\nThis table is loosely based on the csv file here: https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/negex/lexical_kb.csv\n\nColumns:\n\n1. negex: negation (or related) term; capitalization and punctuation will be normalized (i.e., removed) so just include letters; I don't think regexes work\n2. type: four letter abbreviation for negation role with brackets (these will vary based on your text and what you want to extract)\n    * [IMPR]: improbable words (e.g., 'low probability')\n    * [NEGN]: negation words (e.g., 'denies')\n    * [PSEU]: pseudonegation (e.g., 'not only')\n    * [INDI]: indication (e.g., 'rule out')\n    * [HIST]: historical (e.g., 'previous')\n    * [CONJ]: conjunction - interferes with negation scope (e.g., 'though', 'except')\n    * [PROB]: probable (e.g., 'appears')\n    * [POSS]: possible (e.g., 'possible')\n    * [HYPO]: hypothetical (e.g., 'might')\n    * [OTHR]: other subject - refers to someone other than the subject (e.g., 'mother')\n    * [SUBJ]: subject - when reference of OTHR is still referring to the subject (e.g., 'by patient mother')\n    * [PREN]: prenegation <- not sure if this is supposed to be used\n    * [AFFM]: affirmed (e.g., 'obvious', 'positive for')\n    * [FUTP]: future possibility (e.g., 'risk for')\n3. direction\n    * 0: directionality doesn't make sense (e.g., CONJ)\n    * 1: term applies negation, etc. **backward** in the sentence (e.g., 'not seen')\n    * 2: term applies negation, etc. **forward** in the sentence (e.g., 'dont see')\n    * 3: term applies negation, etc. **forward and/or backward** in the sentence (e.g., 'likely')\n\n\n#### Concept/Term Table ####\nThis is the table containing the terms you want to search for (i.e., the entities you want extracted). I have added a script to autogenerate these based on some basic configuration files.\n\n    \u200bColumn\t\u200bType\t\u200bDescription\n    \u200bID\t\u200bint\t\u200bidentity column; unique integer for each row\n    \u200bCUI\t string\t\u200bcategory identifier; can be used to \"group\" different     terms together\n    \u200bText\t\u200bstring\t\u200bterm\n    \u200bRegexVariation\t\u200bint\t\u200bamount of variation: 0=none; 3=very; 1=default; -1=don't even allow suffixes, exact matches only; see #Rules#parameters below; I suggest you just use \"0\" or \"-1\"\n    \u200bWordOrder\t\u200bint\t\u200bhow accurate must the given word order be; 2=exactly; 1=fword constraint; 0=no word order\n    MaxIntervening\tint\thow many intervening words to allow when locating words; 'how many intervening words do I allow?'\n    MaxWords\tint\thow many words to look ahead to find the next word; is \u2018how far do I look ahead after each term?\u2019 \n    \nMaxIntervening and MaxWords should not be used together.\n    \nTo autogenerate this table format, use the `pytakes-build-dictionary` script installed into the Python Scripts directory. For an example, run this with the `--create-sample` option (optionally specify the output with the `--path C:\\somewhere` option. For additional specifications, see the \"Dictionary Builder\" section below.\n\n\n#### Document Table ####\nThis is the table containing the text you are in interesting in searching in.\n\nThe text itself must currently be labeled 'note_text'. The option to specify this is currently not implemented. Sorry.\n\nThe document table must also include a unique id for each note_text (just make an autoincrementing primary key). Specify this and any other meta information you want to pass along under `--meta-labels` option (**ensure that the unique doc_id is specified first**).\n\n\n#### Example Config File ####\nI prefer to specify the configuration file as a Python file (`config.py`). Yaml and json are also accepted. See an example below (copied from `example.config.py`). Please note that the `print(config`) at the end is required.\n\n    config = {\n        'corpus': {  # how to get the text data\n            'directories': [  # specify path to .txt files\n                r'PATH'\n            ],\n            'connections': [  # specify other connection types\n                {\n                    'name': 'TABLENAME',\n                    'name_col': 'TEXT ID COLUMN',\n                    'text_col': 'TEXT COLUMN',\n                    # specify either driver/server/database OR connection_string\n                    # connection string examples here: https://docs.sqlalchemy.org/en/13/core/engines.html\n                    'connection_string': 'SQLALCHEMY-LIKE CONNECTION_STRING',\n                    # db args: driver/server/database\n                    'driver': 'DRIVER',  # available listed in pytakes/iolib/sqlai.py, or use connection string\n                    'server': 'SERVER',\n                    'database': 'DATABASE',\n                }\n            ]\n        },\n        'keywords': [  # path to keyword files, usually stored as CSV\n            {\n                'path': r'PATH',\n                'regex_variation': 0  # set to -1 if you don't want any expansion\n            }\n        ],\n        'negation': {  # select either version or path (not both)\n            'path': r'PATH TO NEGATION CSV FILE',\n            'version': 1,  # int (version number), built-in/default\n            'skip': False,  # bool: if skip is True: don't do negation\n        },\n        'output': {\n            'path': r'PATH TO OUTPUT DIRECTORY',\n            'outfile': 'NAME.out.jsonl',  # name of output file (or given default name)\n            'hostname': ''\n        },\n    }\n    \n    print(config)\n\n    \n## Dictionary Builder ###\nFor a simple example, run (you will first need to install this package, run `python setup.py install` in the base directory): \n\n    pytakes-build-dictionary --create-sample --path OUTPUT_PATH\n    \n### COMMAND LINE ARGUMENTS ###\n \n    Short\u200b\t\u200bLong\t\u200bDescription\n    \u200b-p\t\u200b--path\t\u200bSpecifies parent directory of folders; program will prompt if unable to locate the directory\n    \u200b-o\t\u200b--output\t\u200bSpecify output CSV file; if \".csv\" is not included, it will be added\n    \u200b-t\t\u200b--table\t\u200bSpecify output table in specified database (See below)\n    \u200b-v\t\u200b--verbosity\t\u200bSpecify amount of log output to show: 3-most verbose; 0-least verbose\n    --driver\tIf -t is specified, driver where table should be created. Defaults to SQL Server\n    --server\tIf -t is specified, server where table should be created. \n    --database\tIf -t is specified, database where table should be created. \n   \n\n###  OUTPUT COLUMNS ####\nNot all of these output columns are required (most don't do anything). This was originally designed for building a dictionary using cTAKES.\n\n     Column\t\u200bType\t\u200bDescription\n     ID\t\u200bint\t\u200bidentity column; unique integer for each row\n     CUI\t\u200bvarchar(8)\t\u200bcategory identifier; can be used to \"group\" different terms together\n     Fword\t\u200bvarchar(80)\t\u200bfirst word of term\n     Text\t\u200bvarchar(8000)\t\u200bterm\n     Code\t\u200bvarchar(45)\t\u200bunimportant value required by cTAKES (legacy)\n     SourceType\t\u200bvarchar(45)\t\u200bunimportant value required by cTAKES (legacy)\n     TUI\t\u200bvarchar(4)\t\u200b\u200bunimportant value required by cTAKES (legacy)\n     TextLength\t\u200bint\t\u200blength of term (all characters including spaces)\n     RegexVariation\t\u200bint\t\u200bamount of variation: 0=none; 3=very; 1=default; see #Rules#parameters below\n     WordOrder\t\u200bint\t\u200bhow accurate must the given word order be; 2=exactly; 1=fword constraint; 0=no word order\n     Valence\t\u200bint\t\u200bthis should just be \"1\"; program is  not designed to work with this correctly\n\n\n### RULES ###\nRules are the text entries in the cTAKES-like dictionary, however, they can include \"categories\" in addition to just text.A category is any string of text surrounded by \"[\" and \"]\". The intervening text string is the name of a \"category\". The category must have a definition, and each item (synonym) in the definition will be used in the rule.\n\nFor example, if a rule is `[smart_person] is smart` and the category `smart_person` is defined by the terms \"Albert Einstein\", \"Old McDonald\", and \"Brain\", then the resulting output will be\n\n    Albert Einsten is smart\n    Old McDonald is smart\n    Brain is smart\n \n\nThe rule file consists of a set of rules (as above), and each rule must be on its own line.\n\n    [smart_person] is smart\n    smart [smart_person]\n    [smart_person] not dumb\n    [not_so_smart] not smart \n\nThe rule file must be named \"rules\" or \"rules.some-extension\" (e.g., \"rules.txt\"). \n\n####  Parameters ####\nRules may also maintain configuration parameters.The configurations are indexed in the following order (bold indicates the default parameter):\n\nRegexVariation (integers)\n\n    **0: no variation in regular expression coverage**\n    1: minimal variation in regular expression coverage\n    2: moderate variation in regular expression coverage\n    3: high flexibility in regular expression coverage\n    \nWordOrder\n\n    0: free word order\n    **1: enforce first word rule**\n    2: require precise word order\n    \nValence\n\n    **ALWAYS USE 1** or just ignore; NOT YET CORRECTLY IMPLEMENTED IN LCTAKES\n    \nThese are designated by the double percent ('%%') and follow the rule. \n\n    [category]%%REGEX_VARIATION,WORD_ORDER,VALENCE\n\nFor example:\n\n    [smart_person] is smart%%1,2   # minimal regex variation; requires precise word order \n    [smart_person]%%,2        # same as above: the first parameter is left blank, and the default is used\n    [smart_person] not dumb           # default for both parameters are used\n    [not_so_smart] not smart%%2    # default second parameter\n\n \n\n Definitions/categories (see below) can also be assigned parameters in exactly the same way. When the parameters collide/disagree (e.g., the rule asks for free word order, but the definition asks that the first word rule be enforced), the more conservative will be selected.\n\n####  DEFINITIONS ####\nThe definition (also called \"category\" files) provide a set of words to replace the name of a category in a particular rule.The definition file must either be within a \"cat\" directory, or must have the extension \".cat\". The program will choose one or the other--which one is undefined.There are several ways to write the definition for a particular category. Examples:\n\nIn the definition file smart_person.cat, each row will be considered a definition for the smart_person category. Also a not_so_smart.cat should be included.\nIn the definition file definitions.cat:\n\n    [smart_person]                       \n    Albert Einstein                       \n    Old McDonald                       \n    Brain                       \n    [not_so_smart]                       \n    Humpty Dumpty  \n\n####  Comments. ####\nAll lines beginning with \"#\" are ignored, and all characters occurring after a '#' are ignored as comments.     \n                  \n    # last updated by me, yesterday evening                       \n    [smart_person]                       \n    Albert Einstein       # comment here                       \n    Old McDonald                       \n    Brain                       \n    [not_so_smart]                       \n    # shouldn't there be others?!?                       \n    Humpty Dumpty  \n\n####  CUIs. ####\nCUIs are usually assigned uniquely for each rule, rather than for a category. A CUI can be included for a given definition of a category by assigning it with the syntax: C1025459==Albert Einstein\nOr, in the entire definition file:\n\n    [smart_person]                       \n    C1025459==Albert Einstein                       \n    C4495545==Old McDonald                       \n    Brain                       \n    [not_so_smart]                       \n    Humpty Dumpty   \n\nIn the above example, Humpty Dumpty and Brain are both assigned a default CUI. \n\n####  Word Variant Notation. ####\nDefinitions may also be written on a single line, separated by the double pipe (i.e., '||'). If more than three or four definitions are listed on a single line, the definitions file becomes somewhat unreadable. Thus, it is best practice to only include word variants on a single line.                       \n\n    [smart_person]                       \n    C1025459==Albert Einstein||Einstein                       \n    C4495545==Old McDonald||Ol' McDonald||Ole McDonald||Jeff                       \n    Brain                       \n    [not_so_smart]                       \n    Humpty Dumpty||Humpty-Dumpty # this is a common use for word-variant notation   \n\n#### Parameters ####\nFor definitions, see the parameters section under Rules.\n\nExample:\n\n    [smart_person]                       \n    C1025459==Albert Einstein%%1,2   # all rules involving this definition with have minimal regex variation; requires precise word order                       \n    C4495545==Old McDonald                       \n    Brain                       \n    [not_so_smart]                       \n    Humpty Dumpty              # will use the defaults\n\n \n\n**Conflict Resolution.**\n\nRegardless of how the conflict occurs, the more conservative of the rule and all relevant definitions will be chosen. NB: This process will never choose values that have been left as default (unless the default is specifically requested).\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/dcronkite/pytakes", "keywords": "nlp information extraction", "license": "", "maintainer": "", "maintainer_email": "", "name": "pytakes", "package_url": "https://pypi.org/project/pytakes/", "platform": "", "project_url": "https://pypi.org/project/pytakes/", "project_urls": {"Homepage": "https://github.com/dcronkite/pytakes"}, "release_url": "https://pypi.org/project/pytakes/1.0.5/", "requires_dist": ["regex"], "requires_python": ">=3.7", "summary": "Basic information extraction tool.", "version": "1.0.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>pytakes</h1>\n<p>Simple entity extraction module released under the MIT license.</p>\n<h2>Overview</h2>\n<p>This module will look for a pre-defined set of terms in a corpus of text, and use a variation of the negex/context algorithm to determine whether these terms express negation, historical, or various other qualifiers. (The set of negation terms is also configurable.)</p>\n<h2>Requirements</h2>\n<ul>\n<li>Python 3.6+</li>\n<li>See requirements.txt (<code>pip install -r requirements.txt</code>)\n<ul>\n<li>Various requirements-_.txt files are provided depending on your needs:\n<ul>\n<li>dev: for running tests, general development</li>\n<li>db: for connecting to database using pyodbc</li>\n<li>psql: connecting to postgres database</li>\n<li>sas: if data is stored in SAS</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2>Prerequisites</h2>\n<ol>\n<li>Generate a word list of terms/concepts ('concept dictionary')\n<ul>\n<li>in pyTAKES, a 'concept' is a set of terms with more or less the same meaning (e.g., ckd, chronic kidney disease)</li>\n<li>the minimal should be a CSV file with three columns:\n<ul>\n<li>id - unique int for each line</li>\n<li>cui - string label for a 'concept' ('concept unique identifier')</li>\n<li>text - text to look for</li>\n</ul>\n</li>\n<li>dictionary builder script is also provided which help generate variations of terms(documented below)</li>\n</ul>\n</li>\n<li>A corpus with an id (for tracking, this will be in output) and text field (for processing, extracting concepts)</li>\n</ol>\n<h2>Doco</h2>\n<h3>Basics</h3>\n<ul>\n<li>The entry point is <code>python example/run.py config.py</code>.\n<ul>\n<li>You can see an example <code>config.py</code> at <code>example/simple/example.config.py</code></li>\n<li><code>pytakes</code> module must be on your PYTHONPATH, so <code>set/export PYTHONPATH=src</code> prior to running</li>\n</ul>\n</li>\n</ul>\n<h3>Install</h3>\n<ol>\n<li>Clone from git repo: <code>git clone ...pytakes.git</code></li>\n<li><code>cd pytakes</code></li>\n<li>(optional) build virtualenv\n<ul>\n<li><code>PYTHON_INSTALL/Scripts/virtualenv .venv</code></li>\n<li><code>pip install virtualenv</code> if not yet available</li>\n</ul>\n</li>\n<li>Pip install prerequisites <code>pip install -r requirements.txt</code></li>\n<li>Run tests (<code>pytest tests</code>)</li>\n</ol>\n<h3>Use</h3>\n<p>You will need to have an input <code>concepts.csv</code> file with at least three columns (<code>id</code>, <code>cui</code>, <code>text</code>). There are several examples in the <code>pytakes/tests/data</code> directory.</p>\n<h4>Negation Table</h4>\n<p>This table implements a modified version of Chapman's ConText (see, e.g., <a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.145.6566&amp;rep=rep1&amp;type=pdf\" rel=\"nofollow\">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.145.6566&amp;rep=rep1&amp;type=pdf</a>, and <a href=\"https://code.google.com/archive/p/negex/\" rel=\"nofollow\">https://code.google.com/archive/p/negex/</a>).</p>\n<p>This table is loosely based on the csv file here: <a href=\"https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/negex/lexical_kb.csv\" rel=\"nofollow\">https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/negex/lexical_kb.csv</a></p>\n<p>Columns:</p>\n<ol>\n<li>negex: negation (or related) term; capitalization and punctuation will be normalized (i.e., removed) so just include letters; I don't think regexes work</li>\n<li>type: four letter abbreviation for negation role with brackets (these will vary based on your text and what you want to extract)\n<ul>\n<li>[IMPR]: improbable words (e.g., 'low probability')</li>\n<li>[NEGN]: negation words (e.g., 'denies')</li>\n<li>\n<li>\n<li>\n<li>[CONJ]: conjunction - interferes with negation scope (e.g., 'though', 'except')</li>\n<li>\n<li>\n<li>\n<li>[OTHR]: other subject - refers to someone other than the subject (e.g., 'mother')</li>\n<li>[SUBJ]: subject - when reference of OTHR is still referring to the subject (e.g., 'by patient mother')</li>\n<li>[PREN]: prenegation &lt;- not sure if this is supposed to be used</li>\n<li>\n<li>[FUTP]: future possibility (e.g., 'risk for')</li>\n</ul>\n</li>\n<li>direction\n<ul>\n<li>0: directionality doesn't make sense (e.g., CONJ)</li>\n<li>1: term applies negation, etc. <strong>backward</strong> in the sentence (e.g., 'not seen')</li>\n<li>2: term applies negation, etc. <strong>forward</strong> in the sentence (e.g., 'dont see')</li>\n<li>3: term applies negation, etc. <strong>forward and/or backward</strong> in the sentence (e.g., 'likely')</li>\n</ul>\n</li>\n</ol>\n<h4>Concept/Term Table</h4>\n<p>This is the table containing the terms you want to search for (i.e., the entities you want extracted). I have added a script to autogenerate these based on some basic configuration files.</p>\n<pre><code>\u200bColumn\t\u200bType\t\u200bDescription\n\u200bID\t\u200bint\t\u200bidentity column; unique integer for each row\n\u200bCUI\t string\t\u200bcategory identifier; can be used to \"group\" different     terms together\n\u200bText\t\u200bstring\t\u200bterm\n\u200bRegexVariation\t\u200bint\t\u200bamount of variation: 0=none; 3=very; 1=default; -1=don't even allow suffixes, exact matches only; see #Rules#parameters below; I suggest you just use \"0\" or \"-1\"\n\u200bWordOrder\t\u200bint\t\u200bhow accurate must the given word order be; 2=exactly; 1=fword constraint; 0=no word order\nMaxIntervening\tint\thow many intervening words to allow when locating words; 'how many intervening words do I allow?'\nMaxWords\tint\thow many words to look ahead to find the next word; is \u2018how far do I look ahead after each term?\u2019 \n</code></pre>\n<p>MaxIntervening and MaxWords should not be used together.</p>\n<p>To autogenerate this table format, use the <code>pytakes-build-dictionary</code> script installed into the Python Scripts directory. For an example, run this with the <code>--create-sample</code> option (optionally specify the output with the <code>--path C:\\somewhere</code> option. For additional specifications, see the \"Dictionary Builder\" section below.</p>\n<h4>Document Table</h4>\n<p>This is the table containing the text you are in interesting in searching in.</p>\n<p>The text itself must currently be labeled 'note_text'. The option to specify this is currently not implemented. Sorry.</p>\n<p>The document table must also include a unique id for each note_text (just make an autoincrementing primary key). Specify this and any other meta information you want to pass along under <code>--meta-labels</code> option (<strong>ensure that the unique doc_id is specified first</strong>).</p>\n<h4>Example Config File</h4>\n<p>I prefer to specify the configuration file as a Python file (<code>config.py</code>). Yaml and json are also accepted. See an example below (copied from <code>example.config.py</code>). Please note that the <code>print(config</code>) at the end is required.</p>\n<pre><code>config = {\n    'corpus': {  # how to get the text data\n        'directories': [  # specify path to .txt files\n            r'PATH'\n        ],\n        'connections': [  # specify other connection types\n            {\n                'name': 'TABLENAME',\n                'name_col': 'TEXT ID COLUMN',\n                'text_col': 'TEXT COLUMN',\n                # specify either driver/server/database OR connection_string\n                # connection string examples here: https://docs.sqlalchemy.org/en/13/core/engines.html\n                'connection_string': 'SQLALCHEMY-LIKE CONNECTION_STRING',\n                # db args: driver/server/database\n                'driver': 'DRIVER',  # available listed in pytakes/iolib/sqlai.py, or use connection string\n                'server': 'SERVER',\n                'database': 'DATABASE',\n            }\n        ]\n    },\n    'keywords': [  # path to keyword files, usually stored as CSV\n        {\n            'path': r'PATH',\n            'regex_variation': 0  # set to -1 if you don't want any expansion\n        }\n    ],\n    'negation': {  # select either version or path (not both)\n        'path': r'PATH TO NEGATION CSV FILE',\n        'version': 1,  # int (version number), built-in/default\n        'skip': False,  # bool: if skip is True: don't do negation\n    },\n    'output': {\n        'path': r'PATH TO OUTPUT DIRECTORY',\n        'outfile': 'NAME.out.jsonl',  # name of output file (or given default name)\n        'hostname': ''\n    },\n}\n\nprint(config)\n</code></pre>\n<h2>Dictionary Builder</h2>\n<p>For a simple example, run (you will first need to install this package, run <code>python setup.py install</code> in the base directory):</p>\n<pre><code>pytakes-build-dictionary --create-sample --path OUTPUT_PATH\n</code></pre>\n<h3>COMMAND LINE ARGUMENTS</h3>\n<pre><code>Short\u200b\t\u200bLong\t\u200bDescription\n\u200b-p\t\u200b--path\t\u200bSpecifies parent directory of folders; program will prompt if unable to locate the directory\n\u200b-o\t\u200b--output\t\u200bSpecify output CSV file; if \".csv\" is not included, it will be added\n\u200b-t\t\u200b--table\t\u200bSpecify output table in specified database (See below)\n\u200b-v\t\u200b--verbosity\t\u200bSpecify amount of log output to show: 3-most verbose; 0-least verbose\n--driver\tIf -t is specified, driver where table should be created. Defaults to SQL Server\n--server\tIf -t is specified, server where table should be created. \n--database\tIf -t is specified, database where table should be created. \n</code></pre>\n<h3>OUTPUT COLUMNS</h3>\n<p>Not all of these output columns are required (most don't do anything). This was originally designed for building a dictionary using cTAKES.</p>\n<pre><code> Column\t\u200bType\t\u200bDescription\n ID\t\u200bint\t\u200bidentity column; unique integer for each row\n CUI\t\u200bvarchar(8)\t\u200bcategory identifier; can be used to \"group\" different terms together\n Fword\t\u200bvarchar(80)\t\u200bfirst word of term\n Text\t\u200bvarchar(8000)\t\u200bterm\n Code\t\u200bvarchar(45)\t\u200bunimportant value required by cTAKES (legacy)\n SourceType\t\u200bvarchar(45)\t\u200bunimportant value required by cTAKES (legacy)\n TUI\t\u200bvarchar(4)\t\u200b\u200bunimportant value required by cTAKES (legacy)\n TextLength\t\u200bint\t\u200blength of term (all characters including spaces)\n RegexVariation\t\u200bint\t\u200bamount of variation: 0=none; 3=very; 1=default; see #Rules#parameters below\n WordOrder\t\u200bint\t\u200bhow accurate must the given word order be; 2=exactly; 1=fword constraint; 0=no word order\n Valence\t\u200bint\t\u200bthis should just be \"1\"; program is  not designed to work with this correctly\n</code></pre>\n<h3>RULES</h3>\n<p>Rules are the text entries in the cTAKES-like dictionary, however, they can include \"categories\" in addition to just text.A category is any string of text surrounded by \"[\" and \"]\". The intervening text string is the name of a \"category\". The category must have a definition, and each item (synonym) in the definition will be used in the rule.</p>\n<p>For example, if a rule is <code>[smart_person] is smart</code> and the category <code>smart_person</code> is defined by the terms \"Albert Einstein\", \"Old McDonald\", and \"Brain\", then the resulting output will be</p>\n<pre><code>Albert Einsten is smart\nOld McDonald is smart\nBrain is smart\n</code></pre>\n<p>The rule file consists of a set of rules (as above), and each rule must be on its own line.</p>\n<pre><code>[smart_person] is smart\nsmart [smart_person]\n[smart_person] not dumb\n[not_so_smart] not smart \n</code></pre>\n<p>The rule file must be named \"rules\" or \"rules.some-extension\" (e.g., \"rules.txt\").</p>\n<h4>Parameters</h4>\n<p>Rules may also maintain configuration parameters.The configurations are indexed in the following order (bold indicates the default parameter):</p>\n<p>RegexVariation (integers)</p>\n<pre><code>**0: no variation in regular expression coverage**\n1: minimal variation in regular expression coverage\n2: moderate variation in regular expression coverage\n3: high flexibility in regular expression coverage\n</code></pre>\n<p>WordOrder</p>\n<pre><code>0: free word order\n**1: enforce first word rule**\n2: require precise word order\n</code></pre>\n<p>Valence</p>\n<pre><code>**ALWAYS USE 1** or just ignore; NOT YET CORRECTLY IMPLEMENTED IN LCTAKES\n</code></pre>\n<p>These are designated by the double percent ('%%') and follow the rule.</p>\n<pre><code>[category]%%REGEX_VARIATION,WORD_ORDER,VALENCE\n</code></pre>\n<p>For example:</p>\n<pre><code>[smart_person] is smart%%1,2   # minimal regex variation; requires precise word order \n[smart_person]%%,2        # same as above: the first parameter is left blank, and the default is used\n[smart_person] not dumb           # default for both parameters are used\n[not_so_smart] not smart%%2    # default second parameter\n</code></pre>\n<p>Definitions/categories (see below) can also be assigned parameters in exactly the same way. When the parameters collide/disagree (e.g., the rule asks for free word order, but the definition asks that the first word rule be enforced), the more conservative will be selected.</p>\n<h4>DEFINITIONS</h4>\n<p>The definition (also called \"category\" files) provide a set of words to replace the name of a category in a particular rule.The definition file must either be within a \"cat\" directory, or must have the extension \".cat\". The program will choose one or the other--which one is undefined.There are several ways to write the definition for a particular category. Examples:</p>\n<p>In the definition file smart_person.cat, each row will be considered a definition for the smart_person category. Also a not_so_smart.cat should be included.\nIn the definition file definitions.cat:</p>\n<pre><code>[smart_person]                       \nAlbert Einstein                       \nOld McDonald                       \nBrain                       \n[not_so_smart]                       \nHumpty Dumpty  \n</code></pre>\n<h4>Comments.</h4>\n<p>All lines beginning with \"#\" are ignored, and all characters occurring after a '#' are ignored as comments.</p>\n<pre><code># last updated by me, yesterday evening                       \n[smart_person]                       \nAlbert Einstein       # comment here                       \nOld McDonald                       \nBrain                       \n[not_so_smart]                       \n# shouldn't there be others?!?                       \nHumpty Dumpty  \n</code></pre>\n<h4>CUIs.</h4>\n<p>CUIs are usually assigned uniquely for each rule, rather than for a category. A CUI can be included for a given definition of a category by assigning it with the syntax: C1025459==Albert Einstein\nOr, in the entire definition file:</p>\n<pre><code>[smart_person]                       \nC1025459==Albert Einstein                       \nC4495545==Old McDonald                       \nBrain                       \n[not_so_smart]                       \nHumpty Dumpty   \n</code></pre>\n<p>In the above example, Humpty Dumpty and Brain are both assigned a default CUI.</p>\n<h4>Word Variant Notation.</h4>\n<p>Definitions may also be written on a single line, separated by the double pipe (i.e., '||'). If more than three or four definitions are listed on a single line, the definitions file becomes somewhat unreadable. Thus, it is best practice to only include word variants on a single line.</p>\n<pre><code>[smart_person]                       \nC1025459==Albert Einstein||Einstein                       \nC4495545==Old McDonald||Ol' McDonald||Ole McDonald||Jeff                       \nBrain                       \n[not_so_smart]                       \nHumpty Dumpty||Humpty-Dumpty # this is a common use for word-variant notation   \n</code></pre>\n<h4>Parameters</h4>\n<p>For definitions, see the parameters section under Rules.</p>\n<p>Example:</p>\n<pre><code>[smart_person]                       \nC1025459==Albert Einstein%%1,2   # all rules involving this definition with have minimal regex variation; requires precise word order                       \nC4495545==Old McDonald                       \nBrain                       \n[not_so_smart]                       \nHumpty Dumpty              # will use the defaults\n</code></pre>\n<p><strong>Conflict Resolution.</strong></p>\n<p>Regardless of how the conflict occurs, the more conservative of the rule and all relevant definitions will be chosen. NB: This process will never choose values that have been left as default (unless the default is specifically requested).</p>\n\n          </div>"}, "last_serial": 7108394, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "d58f1dce1973cc91903b127fb4a64814", "sha256": "59e2283f46951b4fe987aac39c1da45628108cd782abbdf0a3d7ea3be304b68e"}, "downloads": -1, "filename": "pytakes-0.1.zip", "has_sig": false, "md5_digest": "d58f1dce1973cc91903b127fb4a64814", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 49484, "upload_time": "2016-02-22T23:41:48", "upload_time_iso_8601": "2016-02-22T23:41:48.747501Z", "url": "https://files.pythonhosted.org/packages/3b/ee/7a14d1e529947c4c94488221ef3e22a014ef45df0b523ea3cd8edacec026/pytakes-0.1.zip", "yanked": false}], "1.0.5": [{"comment_text": "", "digests": {"md5": "945aaab85b449cf11e29437968088d25", "sha256": "aa300ed0325db64aa72cdb4920dab0e534f391a46198aed7025c739d7df72ea0"}, "downloads": -1, "filename": "pytakes-1.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "945aaab85b449cf11e29437968088d25", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 1653999, "upload_time": "2020-04-27T03:32:01", "upload_time_iso_8601": "2020-04-27T03:32:01.016042Z", "url": "https://files.pythonhosted.org/packages/fd/18/3c2f38849a3594fe085cb86ab4980996320c10d6b9b16bcdb93a5dee9c39/pytakes-1.0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0df5567415009ddd7c6b38c1f23d2278", "sha256": "daaf77e6be1e1a4964f92502a6983af99eea3f8590fe5bc95c9ac8a90a67e550"}, "downloads": -1, "filename": "pytakes-1.0.5.tar.gz", "has_sig": false, "md5_digest": "0df5567415009ddd7c6b38c1f23d2278", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 1717309, "upload_time": "2020-04-27T03:32:02", "upload_time_iso_8601": "2020-04-27T03:32:02.215775Z", "url": "https://files.pythonhosted.org/packages/f3/86/b8bb0168471977340d3ee8028a3c79d55c332fe925dbc0d838371b188f99/pytakes-1.0.5.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "945aaab85b449cf11e29437968088d25", "sha256": "aa300ed0325db64aa72cdb4920dab0e534f391a46198aed7025c739d7df72ea0"}, "downloads": -1, "filename": "pytakes-1.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "945aaab85b449cf11e29437968088d25", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 1653999, "upload_time": "2020-04-27T03:32:01", "upload_time_iso_8601": "2020-04-27T03:32:01.016042Z", "url": "https://files.pythonhosted.org/packages/fd/18/3c2f38849a3594fe085cb86ab4980996320c10d6b9b16bcdb93a5dee9c39/pytakes-1.0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0df5567415009ddd7c6b38c1f23d2278", "sha256": "daaf77e6be1e1a4964f92502a6983af99eea3f8590fe5bc95c9ac8a90a67e550"}, "downloads": -1, "filename": "pytakes-1.0.5.tar.gz", "has_sig": false, "md5_digest": "0df5567415009ddd7c6b38c1f23d2278", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 1717309, "upload_time": "2020-04-27T03:32:02", "upload_time_iso_8601": "2020-04-27T03:32:02.215775Z", "url": "https://files.pythonhosted.org/packages/f3/86/b8bb0168471977340d3ee8028a3c79d55c332fe925dbc0d838371b188f99/pytakes-1.0.5.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:55:39 2020"}