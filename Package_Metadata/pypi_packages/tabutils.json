{"info": {"author": "Reuben Cummings", "author_email": "reubano@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Console", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Operating System :: MacOS :: MacOS X", "Operating System :: Microsoft :: Windows", "Operating System :: POSIX :: Linux", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: Implementation :: PyPy", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "tabutils: A Python toolkit for processing tabular data\n======================================================\n\n|travis| |versions| |pypi|\n\nIndex\n-----\n\n`Introduction`_ | `Requirements`_ | `Motivation`_ | `Usage`_ | `Interoperability`_ |\n`Installation`_ | `Project Structure`_ | `Design Principles`_ | `Readers`_ |\n`Scripts`_ | `Contributing`_ | `Credits`_ | `License`_\n\nIntroduction\n------------\n\n**tabutils** is a Python `library`_ for reading and processing tabular data.\nIt has a functional programming style API, excels at reading, large files,\nand can process 10+ file types.\n\nWith tabutils, you can\n\n- Read csv/xls/xlsx/mdb/dbf files, and more!\n- Type cast records (date, float, text...)\n- Process U\u00f1ic\u00f4d\u00eb text\n- Lazily stream files by default\n- and much more...\n\nRequirements\n------------\n\ntabutils has been tested and is known to work on Python 2.7, 3.4, and 3.5;\nPyPy 4.0; and PyPy3 2.4\n\nOptional Dependencies\n^^^^^^^^^^^^^^^^^^^^^\n\n==================================  ==============  ==============================  =======================\nFunction                            Dependency      Installation                    File type / extension\n==================================  ==============  ==============================  =======================\n``tabutils.io.read_mdb``            `mdbtools`_     ``sudo port install mdbtools``  Microsoft Access / mdb\n``tabutils.io.read_html``           `lxml`_ [#]_    ``pip install lxml``            HTML / html\n``tabutils.convert.records2array``  `NumPy`_ [#]_   ``pip install numpy``           n/a\n``tabutils.convert.records2df``     `pandas`_       ``pip install pandas``          n/a\n==================================  ==============  ==============================  =======================\n\nNotes\n^^^^^\n\n.. [#] If ``lxml`` isn't present, ``read_html`` will default to the builtin Python html reader\n\n.. [#] ``records2array`` can be used without ``numpy`` by passing ``native=True`` in the function call. This will convert ``records`` into a list of native ``array.array`` objects.\n\nMotivation\n----------\n\npandas is great, but installing it isn't exactly a `walk in the park`_. It also\ndoesn't play nice with `PyPy`_. `csvkit`_ is an equally useful project, but it\ndoesn't expose the same API when used as `a library`_ as it does via the command\nline. I designed **tabutils** to provide much of same functionality as\npandas and csvkit, while using functional programming methods.\n\nA simple data processing example is shown below:\n\nFirst create a simple csv file (in bash)\n\n.. code-block:: bash\n\n    echo 'col1,col2,col3\\nhello,5/4/82,1\\none,1/1/15,2\\nhappy,7/1/92,3\\n' > data.csv\n\nNow we can read the file, manipulate the data a bit, and write the manipulated\ndata back to a new file.\n\n.. code-block:: python\n\n    from tabutils import io, process as pr, convert as cv\n    from io import open\n\n    # Load the csv file\n    records = io.read_csv('data.csv')\n\n    # `records` are iterators over the rows\n    row = next(records)\n    row\n    >>> {'col1': 'hello', 'col2': '5/4/82', 'col3': '1'}\n\n    # Let's replace the first row so as not to loose any data\n    records = pr.prepend(records, row)\n\n    # Guess column types. Note: `detect_types` returns a new `records`\n    # generator since it consumes rows during type detection\n    records, result = pr.detect_types(records)\n    {t['id']: t['type'] for t in result['types']}\n    >>> {'col1': 'text', 'col2': 'date', 'col3': 'int'}\n\n    # Now type cast the records. Note: most `tabutils.process` functions return\n    # generators, so lets wrap the result in a list to view the data\n    casted = list(pr.type_cast(records, result['types']))\n    casted[0]\n    >>> {'col1': 'hello', 'col2': datetime.date(1982, 5, 4), 'col3': 1}\n\n    # Cut out the first column of data and merge the rows to get the max value\n    # of the remaining columns. Note: since `merge` (by definition) will always\n    # contain just one row, it is returned as is (not wrapped in a generator)\n    cut_recs = pr.cut(casted, ['col1'], exclude=True)\n    merged = pr.merge(cut_recs, pred=bool, op=max)\n    merged\n    >>> {'col2': datetime.date(2015, 1, 1), 'col3': 3}\n\n    # Now write merged data back to a new csv file.\n    io.write('out.csv', cv.records2csv(merged))\n\n    # View the result\n    with open('out.csv', 'utf-8') as f:\n        f.read()\n    >>> 'col2,col3\\n2015-01-01,3\\n'\n\nUsage\n-----\n\ntabutils is intended to be used directly as a Python library.\n\nUsage Index\n^^^^^^^^^^^\n\n- `Reading data`_\n- `Processing data`_\n\n  + `Numerical analysis (\u00e0 la pandas)`_\n  + `Text processing (\u00e0 la csvkit)`_\n  + `Geo processing (\u00e0 la mapbox)`_\n\n- `Writing data`_\n- `Cookbook`_\n\nReading data\n^^^^^^^^^^^^\n\ntabutils can read both filepaths and file-like objects. Additionally, all readers\nreturn equivalent `records` iterators, i.e., a generator of dictionaries with\nkeys corresponding to the column names.\n\n.. code-block:: python\n\n    from io import open, StringIO\n    from tabutils import io\n\n    \"\"\"Read a filepath\"\"\"\n    records = io.read_json('path/to/file.json')\n\n    \"\"\"Read a file like object and de-duplicate the header\"\"\"\n    f = StringIO('col,col\\nhello,world\\n')\n    records = io.read_csv(f, dedupe=True)\n\n    \"\"\"View the first row\"\"\"\n    next(records)\n    >>> {'col': 'hello', 'col_2': 'world'}\n\n    \"\"\"Read the 1st sheet of an xls file object opened in text mode.\"\"\"\n    # Also, santize the header names by converting them to lowercase and\n    # replacing whitespace and invalid characters with `_`.\n    with open('path/to/file.xls', 'utf-8') as f:\n        for row in io.read_xls(f, sanitize=True):\n            # do something with the `row`\n            pass\n\n    \"\"\"Read the 2nd sheet of an xlsx file object opened in binary mode\"\"\"\n    # Note: sheets are zero indexed\n    with open('path/to/file.xlsx') as f:\n        records = io.read_xls(f, encoding='utf-8', sheet=1)\n        first_row = next(records)\n        # do something with the `first_row`\n\n    \"\"\"Read any recognized file\"\"\"\n    records = io.read('path/to/file.geojson')\n    f.seek(0)\n    records = io.read(f, ext='csv', dedupe=True)\n\nPlease see `Readers`_ for a complete list of available readers and recognized\nfile types.\n\nProcessing data\n^^^^^^^^^^^^^^^\n\nNumerical analysis (\u00e0 la pandas) [#]_\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nIn the following example, ``pandas`` equivalent methods are preceded by ``-->``,\nand command output is preceded by ``>>>``.\n\n.. code-block:: python\n\n    import itertools as it\n    import random\n\n    from io import StringIO\n    from tabutils import io, process as pr, convert as cv, stats\n\n    # Create some data in the same structure as what the various `read...`\n    # functions output\n    header = ['A', 'B', 'C', 'D']\n    data = [(random.random() for _ in range(4)) for x in range(7)]\n    df = [dict(zip(header, d)) for d in data]\n    df[0]\n    >>> {'A': 0.53908..., 'B': 0.28919..., 'C': 0.03003..., 'D': 0.65363...}\n\n    \"\"\"Sort records by the value of column `B` --> df.sort_values(by='B')\"\"\"\n    next(pr.sort(df, 'B'))\n    >>> {'A': 0.53520..., 'B': 0.06763..., 'C': 0.02351..., 'D': 0.80529...}\n\n    \"\"\"Select column `A` --> df['A']\"\"\"\n    next(pr.cut(df, ['A']))\n    >>> {'A': 0.53908170489952006}\n\n    \"\"\"Select the first the rows of data --> df[0:3]\"\"\"\n    len(list(it.islice(df, 3)))\n    >>> 3\n\n    \"\"\"Select all data whose value for column `A` is less than 0.5\n    --> df[df.A < 0.5]\n    \"\"\"\n    next(pr.tfilter(df, 'A', lambda x: x < 0.5))\n    >>> {'A': 0.21000..., 'B': 0.25727..., 'C': 0.39719..., 'D': 0.64157...}\n\n    # Note: since `aggregate` and `merge` (by definition) return just one row,\n    # they return them as is (not wrapped in a generator).\n    \"\"\"Calculate the mean of column `A` across all data --> df.mean()['A']\"\"\"\n    pr.aggregate(df, 'A', stats.mean)['A']\n    >>> 0.5410437473067938\n\n    \"\"\"Calculate the sum of each column across all data --> df.sum()\"\"\"\n    pr.merge(df, pred=bool, op=sum)\n    >>> {'A': 3.78730..., 'C': 2.82875..., 'B': 3.14195..., 'D': 5.26330...}\n\nText processing (\u00e0 la csvkit) [#]_\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nIn the following example, ``csvkit`` equivalent commands are preceded by ``-->``,\nand command output is preceded by ``>>>``.\n\nFirst create a few simple csv files (in bash)\n\n.. code-block:: bash\n\n    echo 'col_1,col_2,col_3\\n1,dill,male\\n2,bob,male\\n3,jane,female' > file1.csv\n    echo 'col_1,col_2,col_3\\n4,tom,male\\n5,dick,male\\n6,jill,female' > file2.csv\n\nNow we can read the files, manipulate the data, convert the manipulated data to\njson, and write the json back to a new file. Also, note that since all readers\nreturn equivalent `records` iterators, you can use them interchangeably (in\nplace of ``read_csv``) to open any supported file. E.g., ``read_xls``,\n``read_sqlite``, etc.\n\n.. code-block:: python\n\n    import itertools as it\n\n    from tabutils import io, process as pr, convert as cv\n\n    \"\"\"Combine the files into one iterator\n    --> csvstack file1.csv file2.csv\n    \"\"\"\n    records = io.join('file1.csv', 'file2.csv')\n    next(records)\n    >>> {'col_1': '1', 'col_2': 'dill', 'col_3': 'male'}\n    next(it.islice(records, 4, None))\n    >>> {'col_1': '6', 'col_2': 'jill', 'col_3': 'female'}\n\n    # Now let's create a persistant records list\n    records = list(io.read_csv('file1.csv'))\n\n    \"\"\"Sort records by the value of column `col_2`\n    --> csvsort -c col_2 file1.csv\n    \"\"\"\n    next(pr.sort(records, 'col_2'))\n    >>> {'col_1': '2', 'col_2': 'bob', 'col_3': 'male'\n\n    \"\"\"Select column `col_2` --> csvcut -c col_2 file1.csv\"\"\"\n    next(pr.cut(records, ['col_2']))\n    >>> {'col_2': 'dill'}\n\n    \"\"\"Select all data whose value for column `col_2` contains `jan`\n    --> csvgrep -c col_2 -m jan file1.csv\n    \"\"\"\n    next(pr.grep(records, [{'pattern': 'jan'}], ['col_2']))\n    >>> {'col_1': '3', 'col_2': 'jane', 'col_3': 'female'}\n\n    \"\"\"Convert a csv file to json --> csvjson -i 4 file1.csv\"\"\"\n    io.write('file.json', cv.records2json(records))\n\n    # View the result\n    with open('file.json', 'utf-8') as f:\n        f.read()\n    >>> '[{\"col_1\": \"1\", \"col_2\": \"dill\", \"col_3\": \"male\"}, {\"col_1\": \"2\",\n    ... \"col_2\": \"bob\", \"col_3\": \"male\"}, {\"col_1\": \"3\", \"col_2\": \"jane\",\n    ... \"col_3\": \"female\"}]'\n\nGeo processing (\u00e0 la mapbox) [#]_\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nIn the following example, ``mapbox`` equivalent commands are preceded by ``-->``,\nand command output is preceded by ``>>>``.\n\nFirst create a geojson file (in bash)\n\n.. code-block:: bash\n\n    echo '{\"type\": \"FeatureCollection\",\"features\": [' > file.geojson\n    echo '{\"type\": \"Feature\", \"id\": 11, \"geometry\": {\"type\": \"Point\", \"coordinates\": [10, 20]}},' >> file.geojson\n    echo '{\"type\": \"Feature\", \"id\": 12, \"geometry\": {\"type\": \"Point\", \"coordinates\": [5, 15]}}]}' >> file.geojson\n\nNow we can open the file, split the data by id, and finally convert the split data\nto a new geojson file-like object.\n\n.. code-block:: python\n\n    from tabutils import io, process as pr, convert as cv\n\n    # Load the geojson file and peek at the results\n    records, peek = pr.peek(io.read_geojson('file.geojson'))\n    peek[0]\n    >>> {'lat': 20, 'type': 'Point', 'lon': 10, 'id': 11}\n\n    \"\"\"Split the records by feature ``id`` and select the first feature\n    --> geojsplit -k id file.geojson\n    \"\"\"\n    splits = pr.split(records, 'id')\n    feature_records, name = next(splits)\n    name\n    >>> 11\n\n    \"\"\"Convert the feature records into a GeoJSON file-like object\"\"\"\n    geojson = cv.records2geojson(feature_records)\n    geojson.readline()\n    >>> '{\"type\": \"FeatureCollection\", \"bbox\": [10, 20, 10, 20], \"features\": '\n    ... '[{\"type\": \"Feature\", \"id\": 11, \"geometry\": {\"type\": \"Point\", '\n    ... '\"coordinates\": [10, 20]}, \"properties\": {\"id\": 11}}], \"crs\": {\"type\": '\n    ... '\"name\", \"properties\": {\"name\": \"urn:ogc:def:crs:OGC:1.3:CRS84\"}}}'\n\n    # Note: you can also write back to a file as shown previously\n    # io.write('file.geojson', geojson)\n\nWriting data\n^^^^^^^^^^^^\n\ntabutils can persist ``records`` to disk via the following functions:\n\n- ``tabutils.convert.records2csv``\n- ``tabutils.convert.records2json``\n- ``tabutils.convert.records2geojson``\n\nEach function returns a file-like object that you can write to disk via\n``tabutils.io.write('/path/to/file', result)``.\n\n.. code-block:: python\n\n    from tabutils import io, convert as cv\n    from io import StringIO, open\n\n    # First let's create a simple tsv file like object\n    f = StringIO('col1\\tcol2\\nhello\\tworld\\n')\n    f.seek(0)\n\n    # Next create a records list so we can reuse it\n    records = list(io.read_tsv(f))\n    records[0]\n    >>> {'col1': 'hello', 'col2': 'world'}\n\n    # Now we're ready to write the records data to file\n\n    \"\"\"Create a csv file like object\"\"\"\n    cv.records2csv(records).readline()\n    >>> 'col1,col2\\n'\n\n    \"\"\"Create a json file like object\"\"\"\n    cv.records2json(records).readline()\n    >>> '[{\"col1\": \"hello\", \"col2\": \"world\"}]'\n\n    \"\"\"Write back csv to a filepath\"\"\"\n    io.write('file.csv', cv.records2csv(records))\n    with open('file.csv', 'utf-8') as f_in:\n        f_in.read()\n    >>> 'col1,col2\\nhello,world\\n'\n\n    \"\"\"Write back json to a filepath\"\"\"\n    io.write('file.json', cv.records2json(records))\n    with open('file.json', 'utf-8') as f_in:\n        f_in.readline()\n    >>> '[{\"col1\": \"hello\", \"col2\": \"world\"}]'\n\nCookbook\n^^^^^^^^\n\nPlease see the `cookbook guide`_ for more examples.\n\nNotes\n^^^^^\n\n.. [#] http://pandas.pydata.org/pandas-docs/stable/10min.html#min\n.. [#] https://csvkit.readthedocs.org/en/0.9.1/cli.html#processing\n.. [#] https://github.com/mapbox?utf8=%E2%9C%93&query=geojson\n\nInteroperability\n----------------\n\ntabutils plays nicely with NumPy and friends out of the box\n\nsetup\n^^^^^\n\n.. code-block:: python\n\n    from tabutils import process as pr\n\n    # First create some records and types. Also, convert the records to a list\n    # so we can reuse them.\n    records = [{'a': 'one', 'b': 2}, {'a': 'five', 'b': 10, 'c': 20.1}]\n    records, result = pr.detect_types(records)\n    records, types = list(records), result['types']\n    types\n    >>> [\n    ...     {'type': 'text', 'id': 'a'},\n    ...     {'type': 'int', 'id': 'b'},\n    ...     {'type': 'float', 'id': 'c'}]\n\n\nfrom records to pandas.DataFrame to records\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n.. code-block:: python\n\n    import pandas as pd\n    from tabutils import convert as cv\n\n    \"\"\"Convert the records to a DataFrame\"\"\"\n    df = cv.records2df(records, types)\n    df\n    >>>         a   b   c\n    ... 0   one   2   NaN\n    ... 1  five  10  20.1\n    # Alternatively, you can do `pd.DataFrame(records)`\n\n    \"\"\"Convert the DataFrame back to records\"\"\"\n    next(cv.df2records(df))\n    >>> {'a': 'one', 'b': 2, 'c': nan}\n\nfrom records to arrays to records\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n.. code-block:: python\n\n    import numpy as np\n\n    from array import array\n    from tabutils import convert as cv\n\n    \"\"\"Convert records to a structured array\"\"\"\n    recarray = cv.records2array(records, types)\n    recarray\n    >>> rec.array([('one', 2, nan), ('five', 10, 20.100000381469727)],\n    ...           dtype=[('a', 'O'), ('b', '<i4'), ('c', '<f4')])\n    recarray.b\n    >>> array([ 2, 10], dtype=int32)\n\n    \"\"\"Convert records to a native array\"\"\"\n    narray = cv.records2array(records, types, native=True)\n    narray\n    >>> [[array('u', 'a'), array('u', 'b'), array('u', 'c')],\n    ... [array('u', 'one'), array('u', 'five')],\n    ... array('i', [2, 10]),\n    ... array('f', [0.0, 20.100000381469727])]\n\n    \"\"\"Convert a 2-D NumPy array to a records generator\"\"\"\n    data = np.array([[1, 2, 3], [4, 5, 6]], np.int32)\n    data\n    >>> array([[1, 2, 3],\n    ...        [4, 5, 6]], dtype=int32)\n    next(cv.array2records(data))\n    >>> {'column_1': 1, 'column_2': 2, 'column_3': 3}\n\n    \"\"\"Convert the structured array back to a records generator\"\"\"\n    next(cv.array2records(recarray))\n    >>> {'a': 'one', 'b': 2, 'c': nan}\n\n    \"\"\"Convert the native array back to records generator\"\"\"\n    next(cv.array2records(narray, native=True))\n    {'a': 'one', 'b': 2, 'c': 0.0}\n\nInstallation\n------------\n\n(You are using a `virtualenv`_, right?)\n\nAt the command line, install tabutils using either ``pip`` (*recommended*)\n\n.. code-block:: bash\n\n    pip install tabutils\n\nor ``easy_install``\n\n.. code-block:: bash\n\n    easy_install tabutils\n\nPlease see the `installation doc`_ for more details.\n\nProject Structure\n-----------------\n\n.. code-block:: bash\n\n    \u250c\u2500\u2500 AUTHORS.rst\n    \u251c\u2500\u2500 CHANGES.rst\n    \u251c\u2500\u2500 CONTRIBUTING.rst\n    \u251c\u2500\u2500 INSTALLATION.rst\n    \u251c\u2500\u2500 LICENSE\n    \u251c\u2500\u2500 MANIFEST.in\n    \u251c\u2500\u2500 Makefile\n    \u251c\u2500\u2500 README.rst\n    \u251c\u2500\u2500 TODO.rst\n    \u251c\u2500\u2500 data\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 converted\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 dbf.csv\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 fixed.csv\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 geo.csv\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 geojson.csv\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 json.csv\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 json_multiline.csv\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 sheet_2.csv\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 test\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 fixed.txt\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 fixed_w_header.txt\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 iris.csv\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 irismeta.csv\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 latin1.csv\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 mac_newlines.csv\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 newline.json\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 no_header_row.csv\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 test.csv\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 test.dbf\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 test.geojson\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 test.html\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 test.json\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 test.mdb\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 test.sqlite\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 test.tsv\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 test.xls\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 test.xlsx\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 test.yml\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 utf16_big.csv\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 utf16_little.csv\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 utf8.csv\n    \u251c\u2500\u2500 dev-requirements.txt\n    \u251c\u2500\u2500 examples.py\n    \u251c\u2500\u2500 helpers\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 check-stage\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 clean\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 pippy\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 srcdist\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 wheel\n    \u251c\u2500\u2500 manage.py\n    \u251c\u2500\u2500 py2-requirements.txt\n    \u251c\u2500\u2500 requirements.txt\n    \u251c\u2500\u2500 setup.cfg\n    \u251c\u2500\u2500 setup.py\n    \u251c\u2500\u2500 tabutils\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 convert.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 dbf.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 fntools.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 io.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 process.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 stats.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 typetools.py\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 unicsv.py\n    \u251c\u2500\u2500 tests\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 standard.rc\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 test_fntools.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 test_io.py\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 test_process.py\n    \u2514\u2500\u2500 tox.ini\n\nDesign Principles\n-----------------\n\n- prefer functions over objects\n- provide enough functionality out of the box to easily implement the most common data analysis use cases\n- make conversion between ``records``, ``arrays``, and ``DataFrames`` dead simple\n- whenever possible, lazily read objects and stream the result [#]_\n\n.. [#] Notable exceptions are ``tabutils.process.group``, ``tabutils.process.sort``, ``tabutils.io.read_dbf``, ``tabutils.io.read_yaml``, and ``tabutils.io.read_html``. These functions read the entire contents into memory up front.\n\nReaders\n-------\n\ntabutils' available readers are outlined below:\n\n+-----------------------+-------------------------+----------------+\n| File type             | Recognized extension(s) | Default reader |\n+=======================+=========================+================+\n| Comma separated file  | csv                     | read_csv       |\n+-----------------------+-------------------------+----------------+\n| dBASE/FoxBASE         | dbf                     | read_dbf       |\n+-----------------------+-------------------------+----------------+\n| Fixed width file      | fixed                   | read_fixed_fmt |\n+-----------------------+-------------------------+----------------+\n| GeoJSON               | geojson, geojson.json   | read_geojson   |\n+-----------------------+-------------------------+----------------+\n| HTML table            | html                    | read_html      |\n+-----------------------+-------------------------+----------------+\n| JSON                  | json                    | read_json      |\n+-----------------------+-------------------------+----------------+\n| Microsoft Access      | mdb                     | read_mdb       |\n+-----------------------+-------------------------+----------------+\n| SQLite                | sqlite                  | read_sqlite    |\n+-----------------------+-------------------------+----------------+\n| Tab separated file    | tsv                     | read_tsv       |\n+-----------------------+-------------------------+----------------+\n| Microsoft Excel       | xls, xlsx               | read_xls       |\n+-----------------------+-------------------------+----------------+\n| YAML                  | yml, yaml               | read_yaml      |\n+-----------------------+-------------------------+----------------+\n\nAlternatively, tabutils provides a universal reader which will select the\nappropriate reader based on the file extension as specified in the above\ntable.\n\n.. code-block:: python\n\n    from io import open\n    from tabutils import io\n\n    records1 = io.read('path/to/file.csv')\n    records2 = io.read('path/to/file.xls')\n\n    with open('path/to/file.json', encoding='utf-8') as f:\n        records3 = io.read(f, ext='json')\n\nArgs\n^^^^\n\nMost readers take as their first argument, either a file path or file like object.\nThe notable execption is ``read_mdb`` which only accepts a file path.\nFile like objects should be opened using Python's stdlib ``io.open``. If the file\nis opened in binary mode ``io.open('/path/to/file')``, be sure to pass the proper\nencoding if it is anything other than ``utf-8``, e.g.,\n\n.. code-block:: python\n\n    from io import open\n    from tabutils import io\n\n    with open('path/to/file.xlsx') as f:\n        records = io.read_xls(f, encoding='latin-1')\n\nKwargs\n^^^^^^\n\nWhile each reader has kwargs specific to itself, the following table outlines\nthe most common ones.\n\n==========  ====  =======================================  =======  =====================================================================================================\nkwarg       type  description                              default  implementing readers\n==========  ====  =======================================  =======  =====================================================================================================\nmode        str   File open mode                           rU       read_csv, read_fixed_fmt, read_geojson, read_html, read_json, read_tsv, read_xls, read_yaml\nencoding    str   File encoding                            utf-8    read_csv, read_dbf, read_fixed_fmt, read_geojson, read_html, read_json, read_tsv, read_xls, read_yaml\nhas_header  bool  Data has a header row?                   True     read_csv, read_fixed_fmt, read_tsv, read_xls\nfirst_row   int   First row to read (zero indexed)         0        read_csv, read_fixed_fmt, read_tsv, read_xls\nfirst_col   int   First column to read (zero indexed)      0        read_csv, read_fixed_fmt, read_tsv, read_xls\nsanitize    bool  Underscorify and lowercase field names?  False    read_csv, read_dbf, read_fixed_fmt, read_html, read_mdb, read_tsv, read_xls\ndedupe      bool  Deduplicate field names?                 False    read_csv, read_fixed_fmt, read_html, read_mdb, read_tsv, read_xls\nsheet       int   Sheet to read (zero indexed)             0        read_xls\ntable       int   Table to read (zero indexed)             0        read_dbf, read_html, read_mdb, read_sqlite\n==========  ====  =======================================  =======  =====================================================================================================\n\nScripts\n-------\n\ntabutils comes with a built in task manager ``manage.py``\n\nSetup\n^^^^^\n\n.. code-block:: bash\n\n    pip install -r dev-requirements.txt\n\nExamples\n^^^^^^^^\n\n*Run python linter and nose tests*\n\n.. code-block:: bash\n\n    manage lint\n    manage test\n\nContributing\n------------\n\nPlease mimic the coding style/conventions used in this repo.\nIf you add new classes or functions, please add the appropriate doc blocks with\nexamples. Also, make sure the python linter and nose tests pass.\n\nPlease see the `contributing doc`_ for more details.\n\nCredits\n-------\n\nShoutouts to `csvkit`_, `messytables`_, and `pandas`_ for heavily inspiring tabutils.\n\nLicense\n-------\n\ntabutils is distributed under the `MIT License`_.\n\n.. |travis| image:: https://img.shields.io/travis/reubano/tabutils/master.svg\n    :target: https://travis-ci.org/reubano/tabutils\n\n.. |versions| image:: https://img.shields.io/pypi/pyversions/tabutils.svg\n    :target: https://pypi.python.org/pypi/tabutils\n\n.. |pypi| image:: https://img.shields.io/pypi/v/tabutils.svg\n    :target: https://pypi.python.org/pypi/tabutils\n\n.. _mdbtools: http://sourceforge.net/projects/mdbtools/\n.. _lxml: http://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser\n.. _library: #usage\n.. _NumPy: https://github.com/numpy/numpy\n.. _a library: https://csvkit.readthedocs.org/en/0.9.1/api/csvkit.py3.html\n.. _PyPy: https://github.com/pydata/pandas/issues/9532\n.. _walk in the park: http://pandas.pydata.org/pandas-docs/stable/install.html#installing-pandas-with-anaconda\n.. _csvkit: https://github.com/onyxfish/csvkit\n.. _messytables: https://github.com/okfn/messytables\n.. _pandas: https://github.com/pydata/pandas\n.. _MIT License: http://opensource.org/licenses/MIT\n.. _virtualenv: http://www.virtualenv.org/en/latest/index.html\n.. _contributing doc: https://github.com/reubano/tabutils/blob/master/CONTRIBUTING.rst\n.. _installation doc: https://github.com/reubano/tabutils/blob/master/INSTALLATION.rst\n.. _cookbook guide: https://github.com/reubano/tabutils/blob/master/COOKBOOK.rst\n\n\n=========\nChangelog\n=========\n\nHere you can find the recent changes to pygogo..\n\n.. changelog::\n    :version: dev\n    :released: Ongoing\n\n    .. change::\n        :tags:  docs\n\n        Updated CHANGES.\n\n.. changelog::\n    :version: 0.1.0\n    :released: 2015-12-05\n\n    .. change::\n        :tags: docs\n\n        First release on PyPi.\n\n.. todo:: vim: set filetype=rst:", "description_content_type": null, "docs_url": null, "download_url": "https://github.com/reubano/tabutils/archive/v0.27.2.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/reubano/tabutils", "keywords": "tabutils,A,(tabular),data,processing,toolkit", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "tabutils", "package_url": "https://pypi.org/project/tabutils/", "platform": "MacOS X,Windows,Linux", "project_url": "https://pypi.org/project/tabutils/", "project_urls": {"Download": "https://github.com/reubano/tabutils/archive/v0.27.2.tar.gz", "Homepage": "https://github.com/reubano/tabutils"}, "release_url": "https://pypi.org/project/tabutils/0.27.2/", "requires_dist": ["PyYAML (>=3.11,<4.0)", "beautifulsoup4 (>=4.4.1,<5.0.0)", "chardet (>=2.3.0,<3.0.0)", "dbfread (==2.0.4)", "ijson (>=2.2,<3.0)", "pkutils (>=0.12.4,<0.13.0)", "python-dateutil (>=2.4.2,<3.0.0)", "python-slugify (>=0.0.7,<0.1.0)", "requests (>=2.8.1,<3.0.0)", "six (>=1.9.0,<2.0.0)", "xlrd (>=0.9.3,<0.10.0)", "future (>=0.15.2); python_version<\"3.0\""], "requires_python": "", "summary": "A (tabular) data processing toolkit", "version": "0.27.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            tabutils: A Python toolkit for processing tabular data<br>======================================================<br><br>|travis| |versions| |pypi|<br><br>Index<br>-----<br><br>`Introduction`_ | `Requirements`_ | `Motivation`_ | `Usage`_ | `Interoperability`_ |<br>`Installation`_ | `Project Structure`_ | `Design Principles`_ | `Readers`_ |<br>`Scripts`_ | `Contributing`_ | `Credits`_ | `License`_<br><br>Introduction<br>------------<br><br>**tabutils** is a Python `library`_ for reading and processing tabular data.<br>It has a functional programming style API, excels at reading, large files,<br>and can process 10+ file types.<br><br>With tabutils, you can<br><br>- Read csv/xls/xlsx/mdb/dbf files, and more!<br>- Type cast records (date, float, text...)<br>- Process U\u00f1ic\u00f4d\u00eb text<br>- Lazily stream files by default<br>- and much more...<br><br>Requirements<br>------------<br><br>tabutils has been tested and is known to work on Python 2.7, 3.4, and 3.5;<br>PyPy 4.0; and PyPy3 2.4<br><br>Optional Dependencies<br>^^^^^^^^^^^^^^^^^^^^^<br><br>==================================  ==============  ==============================  =======================<br>Function                            Dependency      Installation                    File type / extension<br>==================================  ==============  ==============================  =======================<br>``tabutils.io.read_mdb``            `mdbtools`_     ``sudo port install mdbtools``  Microsoft Access / mdb<br>``tabutils.io.read_html``           `lxml`_ [#]_    ``pip install lxml``            HTML / html<br>``tabutils.convert.records2array``  `NumPy`_ [#]_   ``pip install numpy``           n/a<br>``tabutils.convert.records2df``     `pandas`_       ``pip install pandas``          n/a<br>==================================  ==============  ==============================  =======================<br><br>Notes<br>^^^^^<br><br>.. [#] If ``lxml`` isn't present, ``read_html`` will default to the builtin Python html reader<br><br>.. [#] ``records2array`` can be used without ``numpy`` by passing ``native=True`` in the function call. This will convert ``records`` into a list of native ``array.array`` objects.<br><br>Motivation<br>----------<br><br>pandas is great, but installing it isn't exactly a `walk in the park`_. It also<br>doesn't play nice with `PyPy`_. `csvkit`_ is an equally useful project, but it<br>doesn't expose the same API when used as `a library`_ as it does via the command<br>line. I designed **tabutils** to provide much of same functionality as<br>pandas and csvkit, while using functional programming methods.<br><br>A simple data processing example is shown below:<br><br>First create a simple csv file (in bash)<br><br>.. code-block:: bash<br><br>    echo 'col1,col2,col3\\nhello,5/4/82,1\\none,1/1/15,2\\nhappy,7/1/92,3\\n' &gt; data.csv<br><br>Now we can read the file, manipulate the data a bit, and write the manipulated<br>data back to a new file.<br><br>.. code-block:: python<br><br>    from tabutils import io, process as pr, convert as cv<br>    from io import open<br><br>    # Load the csv file<br>    records = io.read_csv('data.csv')<br><br>    # `records` are iterators over the rows<br>    row = next(records)<br>    row<br>    &gt;&gt;&gt; {'col1': 'hello', 'col2': '5/4/82', 'col3': '1'}<br><br>    # Let's replace the first row so as not to loose any data<br>    records = pr.prepend(records, row)<br><br>    # Guess column types. Note: `detect_types` returns a new `records`<br>    # generator since it consumes rows during type detection<br>    records, result = pr.detect_types(records)<br>    {t['id']: t['type'] for t in result['types']}<br>    &gt;&gt;&gt; {'col1': 'text', 'col2': 'date', 'col3': 'int'}<br><br>    # Now type cast the records. Note: most `tabutils.process` functions return<br>    # generators, so lets wrap the result in a list to view the data<br>    casted = list(pr.type_cast(records, result['types']))<br>    casted[0]<br>    &gt;&gt;&gt; {'col1': 'hello', 'col2': datetime.date(1982, 5, 4), 'col3': 1}<br><br>    # Cut out the first column of data and merge the rows to get the max value<br>    # of the remaining columns. Note: since `merge` (by definition) will always<br>    # contain just one row, it is returned as is (not wrapped in a generator)<br>    cut_recs = pr.cut(casted, ['col1'], exclude=True)<br>    merged = pr.merge(cut_recs, pred=bool, op=max)<br>    merged<br>    &gt;&gt;&gt; {'col2': datetime.date(2015, 1, 1), 'col3': 3}<br><br>    # Now write merged data back to a new csv file.<br>    io.write('out.csv', cv.records2csv(merged))<br><br>    # View the result<br>    with open('out.csv', 'utf-8') as f:<br>        f.read()<br>    &gt;&gt;&gt; 'col2,col3\\n2015-01-01,3\\n'<br><br>Usage<br>-----<br><br>tabutils is intended to be used directly as a Python library.<br><br>Usage Index<br>^^^^^^^^^^^<br><br>- `Reading data`_<br>- `Processing data`_<br><br>  + `Numerical analysis (\u00e0 la pandas)`_<br>  + `Text processing (\u00e0 la csvkit)`_<br>  + `Geo processing (\u00e0 la mapbox)`_<br><br>- `Writing data`_<br>- `Cookbook`_<br><br>Reading data<br>^^^^^^^^^^^^<br><br>tabutils can read both filepaths and file-like objects. Additionally, all readers<br>return equivalent `records` iterators, i.e., a generator of dictionaries with<br>keys corresponding to the column names.<br><br>.. code-block:: python<br><br>    from io import open, StringIO<br>    from tabutils import io<br><br>    \"\"\"Read a filepath\"\"\"<br>    records = io.read_json('path/to/file.json')<br><br>    \"\"\"Read a file like object and de-duplicate the header\"\"\"<br>    f = StringIO('col,col\\nhello,world\\n')<br>    records = io.read_csv(f, dedupe=True)<br><br>    \"\"\"View the first row\"\"\"<br>    next(records)<br>    &gt;&gt;&gt; {'col': 'hello', 'col_2': 'world'}<br><br>    \"\"\"Read the 1st sheet of an xls file object opened in text mode.\"\"\"<br>    # Also, santize the header names by converting them to lowercase and<br>    # replacing whitespace and invalid characters with `_`.<br>    with open('path/to/file.xls', 'utf-8') as f:<br>        for row in io.read_xls(f, sanitize=True):<br>            # do something with the `row`<br>            pass<br><br>    \"\"\"Read the 2nd sheet of an xlsx file object opened in binary mode\"\"\"<br>    # Note: sheets are zero indexed<br>    with open('path/to/file.xlsx') as f:<br>        records = io.read_xls(f, encoding='utf-8', sheet=1)<br>        first_row = next(records)<br>        # do something with the `first_row`<br><br>    \"\"\"Read any recognized file\"\"\"<br>    records = io.read('path/to/file.geojson')<br>    f.seek(0)<br>    records = io.read(f, ext='csv', dedupe=True)<br><br>Please see `Readers`_ for a complete list of available readers and recognized<br>file types.<br><br>Processing data<br>^^^^^^^^^^^^^^^<br><br>Numerical analysis (\u00e0 la pandas) [#]_<br>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~<br><br>In the following example, ``pandas`` equivalent methods are preceded by ``--&gt;``,<br>and command output is preceded by ``&gt;&gt;&gt;``.<br><br>.. code-block:: python<br><br>    import itertools as it<br>    import random<br><br>    from io import StringIO<br>    from tabutils import io, process as pr, convert as cv, stats<br><br>    # Create some data in the same structure as what the various `read...`<br>    # functions output<br>    header = ['A', 'B', 'C', 'D']<br>    data = [(random.random() for _ in range(4)) for x in range(7)]<br>    df = [dict(zip(header, d)) for d in data]<br>    df[0]<br>    &gt;&gt;&gt; {'A': 0.53908..., 'B': 0.28919..., 'C': 0.03003..., 'D': 0.65363...}<br><br>    \"\"\"Sort records by the value of column `B` --&gt; df.sort_values(by='B')\"\"\"<br>    next(pr.sort(df, 'B'))<br>    &gt;&gt;&gt; {'A': 0.53520..., 'B': 0.06763..., 'C': 0.02351..., 'D': 0.80529...}<br><br>    \"\"\"Select column `A` --&gt; df['A']\"\"\"<br>    next(pr.cut(df, ['A']))<br>    &gt;&gt;&gt; {'A': 0.53908170489952006}<br><br>    \"\"\"Select the first the rows of data --&gt; df[0:3]\"\"\"<br>    len(list(it.islice(df, 3)))<br>    &gt;&gt;&gt; 3<br><br>    \"\"\"Select all data whose value for column `A` is less than 0.5<br>    --&gt; df[df.A &lt; 0.5]<br>    \"\"\"<br>    next(pr.tfilter(df, 'A', lambda x: x &lt; 0.5))<br>    &gt;&gt;&gt; {'A': 0.21000..., 'B': 0.25727..., 'C': 0.39719..., 'D': 0.64157...}<br><br>    # Note: since `aggregate` and `merge` (by definition) return just one row,<br>    # they return them as is (not wrapped in a generator).<br>    \"\"\"Calculate the mean of column `A` across all data --&gt; df.mean()['A']\"\"\"<br>    pr.aggregate(df, 'A', stats.mean)['A']<br>    &gt;&gt;&gt; 0.5410437473067938<br><br>    \"\"\"Calculate the sum of each column across all data --&gt; df.sum()\"\"\"<br>    pr.merge(df, pred=bool, op=sum)<br>    &gt;&gt;&gt; {'A': 3.78730..., 'C': 2.82875..., 'B': 3.14195..., 'D': 5.26330...}<br><br>Text processing (\u00e0 la csvkit) [#]_<br>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~<br><br>In the following example, ``csvkit`` equivalent commands are preceded by ``--&gt;``,<br>and command output is preceded by ``&gt;&gt;&gt;``.<br><br>First create a few simple csv files (in bash)<br><br>.. code-block:: bash<br><br>    echo 'col_1,col_2,col_3\\n1,dill,male\\n2,bob,male\\n3,jane,female' &gt; file1.csv<br>    echo 'col_1,col_2,col_3\\n4,tom,male\\n5,dick,male\\n6,jill,female' &gt; file2.csv<br><br>Now we can read the files, manipulate the data, convert the manipulated data to<br>json, and write the json back to a new file. Also, note that since all readers<br>return equivalent `records` iterators, you can use them interchangeably (in<br>place of ``read_csv``) to open any supported file. E.g., ``read_xls``,<br>``read_sqlite``, etc.<br><br>.. code-block:: python<br><br>    import itertools as it<br><br>    from tabutils import io, process as pr, convert as cv<br><br>    \"\"\"Combine the files into one iterator<br>    --&gt; csvstack file1.csv file2.csv<br>    \"\"\"<br>    records = io.join('file1.csv', 'file2.csv')<br>    next(records)<br>    &gt;&gt;&gt; {'col_1': '1', 'col_2': 'dill', 'col_3': 'male'}<br>    next(it.islice(records, 4, None))<br>    &gt;&gt;&gt; {'col_1': '6', 'col_2': 'jill', 'col_3': 'female'}<br><br>    # Now let's create a persistant records list<br>    records = list(io.read_csv('file1.csv'))<br><br>    \"\"\"Sort records by the value of column `col_2`<br>    --&gt; csvsort -c col_2 file1.csv<br>    \"\"\"<br>    next(pr.sort(records, 'col_2'))<br>    &gt;&gt;&gt; {'col_1': '2', 'col_2': 'bob', 'col_3': 'male'<br><br>    \"\"\"Select column `col_2` --&gt; csvcut -c col_2 file1.csv\"\"\"<br>    next(pr.cut(records, ['col_2']))<br>    &gt;&gt;&gt; {'col_2': 'dill'}<br><br>    \"\"\"Select all data whose value for column `col_2` contains `jan`<br>    --&gt; csvgrep -c col_2 -m jan file1.csv<br>    \"\"\"<br>    next(pr.grep(records, [{'pattern': 'jan'}], ['col_2']))<br>    &gt;&gt;&gt; {'col_1': '3', 'col_2': 'jane', 'col_3': 'female'}<br><br>    \"\"\"Convert a csv file to json --&gt; csvjson -i 4 file1.csv\"\"\"<br>    io.write('file.json', cv.records2json(records))<br><br>    # View the result<br>    with open('file.json', 'utf-8') as f:<br>        f.read()<br>    &gt;&gt;&gt; '[{\"col_1\": \"1\", \"col_2\": \"dill\", \"col_3\": \"male\"}, {\"col_1\": \"2\",<br>    ... \"col_2\": \"bob\", \"col_3\": \"male\"}, {\"col_1\": \"3\", \"col_2\": \"jane\",<br>    ... \"col_3\": \"female\"}]'<br><br>Geo processing (\u00e0 la mapbox) [#]_<br>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~<br><br>In the following example, ``mapbox`` equivalent commands are preceded by ``--&gt;``,<br>and command output is preceded by ``&gt;&gt;&gt;``.<br><br>First create a geojson file (in bash)<br><br>.. code-block:: bash<br><br>    echo '{\"type\": \"FeatureCollection\",\"features\": [' &gt; file.geojson<br>    echo '{\"type\": \"Feature\", \"id\": 11, \"geometry\": {\"type\": \"Point\", \"coordinates\": [10, 20]}},' &gt;&gt; file.geojson<br>    echo '{\"type\": \"Feature\", \"id\": 12, \"geometry\": {\"type\": \"Point\", \"coordinates\": [5, 15]}}]}' &gt;&gt; file.geojson<br><br>Now we can open the file, split the data by id, and finally convert the split data<br>to a new geojson file-like object.<br><br>.. code-block:: python<br><br>    from tabutils import io, process as pr, convert as cv<br><br>    # Load the geojson file and peek at the results<br>    records, peek = pr.peek(io.read_geojson('file.geojson'))<br>    peek[0]<br>    &gt;&gt;&gt; {'lat': 20, 'type': 'Point', 'lon': 10, 'id': 11}<br><br>    \"\"\"Split the records by feature ``id`` and select the first feature<br>    --&gt; geojsplit -k id file.geojson<br>    \"\"\"<br>    splits = pr.split(records, 'id')<br>    feature_records, name = next(splits)<br>    name<br>    &gt;&gt;&gt; 11<br><br>    \"\"\"Convert the feature records into a GeoJSON file-like object\"\"\"<br>    geojson = cv.records2geojson(feature_records)<br>    geojson.readline()<br>    &gt;&gt;&gt; '{\"type\": \"FeatureCollection\", \"bbox\": [10, 20, 10, 20], \"features\": '<br>    ... '[{\"type\": \"Feature\", \"id\": 11, \"geometry\": {\"type\": \"Point\", '<br>    ... '\"coordinates\": [10, 20]}, \"properties\": {\"id\": 11}}], \"crs\": {\"type\": '<br>    ... '\"name\", \"properties\": {\"name\": \"urn:ogc:def:crs:OGC:1.3:CRS84\"}}}'<br><br>    # Note: you can also write back to a file as shown previously<br>    # io.write('file.geojson', geojson)<br><br>Writing data<br>^^^^^^^^^^^^<br><br>tabutils can persist ``records`` to disk via the following functions:<br><br>- ``tabutils.convert.records2csv``<br>- ``tabutils.convert.records2json``<br>- ``tabutils.convert.records2geojson``<br><br>Each function returns a file-like object that you can write to disk via<br>``tabutils.io.write('/path/to/file', result)``.<br><br>.. code-block:: python<br><br>    from tabutils import io, convert as cv<br>    from io import StringIO, open<br><br>    # First let's create a simple tsv file like object<br>    f = StringIO('col1\\tcol2\\nhello\\tworld\\n')<br>    f.seek(0)<br><br>    # Next create a records list so we can reuse it<br>    records = list(io.read_tsv(f))<br>    records[0]<br>    &gt;&gt;&gt; {'col1': 'hello', 'col2': 'world'}<br><br>    # Now we're ready to write the records data to file<br><br>    \"\"\"Create a csv file like object\"\"\"<br>    cv.records2csv(records).readline()<br>    &gt;&gt;&gt; 'col1,col2\\n'<br><br>    \"\"\"Create a json file like object\"\"\"<br>    cv.records2json(records).readline()<br>    &gt;&gt;&gt; '[{\"col1\": \"hello\", \"col2\": \"world\"}]'<br><br>    \"\"\"Write back csv to a filepath\"\"\"<br>    io.write('file.csv', cv.records2csv(records))<br>    with open('file.csv', 'utf-8') as f_in:<br>        f_in.read()<br>    &gt;&gt;&gt; 'col1,col2\\nhello,world\\n'<br><br>    \"\"\"Write back json to a filepath\"\"\"<br>    io.write('file.json', cv.records2json(records))<br>    with open('file.json', 'utf-8') as f_in:<br>        f_in.readline()<br>    &gt;&gt;&gt; '[{\"col1\": \"hello\", \"col2\": \"world\"}]'<br><br>Cookbook<br>^^^^^^^^<br><br>Please see the `cookbook guide`_ for more examples.<br><br>Notes<br>^^^^^<br><br>.. [#] http://pandas.pydata.org/pandas-docs/stable/10min.html#min<br>.. [#] https://csvkit.readthedocs.org/en/0.9.1/cli.html#processing<br>.. [#] https://github.com/mapbox?utf8=%E2%9C%93&amp;query=geojson<br><br>Interoperability<br>----------------<br><br>tabutils plays nicely with NumPy and friends out of the box<br><br>setup<br>^^^^^<br><br>.. code-block:: python<br><br>    from tabutils import process as pr<br><br>    # First create some records and types. Also, convert the records to a list<br>    # so we can reuse them.<br>    records = [{'a': 'one', 'b': 2}, {'a': 'five', 'b': 10, 'c': 20.1}]<br>    records, result = pr.detect_types(records)<br>    records, types = list(records), result['types']<br>    types<br>    &gt;&gt;&gt; [<br>    ...     {'type': 'text', 'id': 'a'},<br>    ...     {'type': 'int', 'id': 'b'},<br>    ...     {'type': 'float', 'id': 'c'}]<br><br><br>from records to pandas.DataFrame to records<br>^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br><br>.. code-block:: python<br><br>    import pandas as pd<br>    from tabutils import convert as cv<br><br>    \"\"\"Convert the records to a DataFrame\"\"\"<br>    df = cv.records2df(records, types)<br>    df<br>    &gt;&gt;&gt;         a   b   c<br>    ... 0   one   2   NaN<br>    ... 1  five  10  20.1<br>    # Alternatively, you can do `pd.DataFrame(records)`<br><br>    \"\"\"Convert the DataFrame back to records\"\"\"<br>    next(cv.df2records(df))<br>    &gt;&gt;&gt; {'a': 'one', 'b': 2, 'c': nan}<br><br>from records to arrays to records<br>^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br><br>.. code-block:: python<br><br>    import numpy as np<br><br>    from array import array<br>    from tabutils import convert as cv<br><br>    \"\"\"Convert records to a structured array\"\"\"<br>    recarray = cv.records2array(records, types)<br>    recarray<br>    &gt;&gt;&gt; rec.array([('one', 2, nan), ('five', 10, 20.100000381469727)],<br>    ...           dtype=[('a', 'O'), ('b', '&lt;i4'), ('c', '&lt;f4')])<br>    recarray.b<br>    &gt;&gt;&gt; array([ 2, 10], dtype=int32)<br><br>    \"\"\"Convert records to a native array\"\"\"<br>    narray = cv.records2array(records, types, native=True)<br>    narray<br>    &gt;&gt;&gt; [[array('u', 'a'), array('u', 'b'), array('u', 'c')],<br>    ... [array('u', 'one'), array('u', 'five')],<br>    ... array('i', [2, 10]),<br>    ... array('f', [0.0, 20.100000381469727])]<br><br>    \"\"\"Convert a 2-D NumPy array to a records generator\"\"\"<br>    data = np.array([[1, 2, 3], [4, 5, 6]], np.int32)<br>    data<br>    &gt;&gt;&gt; array([[1, 2, 3],<br>    ...        [4, 5, 6]], dtype=int32)<br>    next(cv.array2records(data))<br>    &gt;&gt;&gt; {'column_1': 1, 'column_2': 2, 'column_3': 3}<br><br>    \"\"\"Convert the structured array back to a records generator\"\"\"<br>    next(cv.array2records(recarray))<br>    &gt;&gt;&gt; {'a': 'one', 'b': 2, 'c': nan}<br><br>    \"\"\"Convert the native array back to records generator\"\"\"<br>    next(cv.array2records(narray, native=True))<br>    {'a': 'one', 'b': 2, 'c': 0.0}<br><br>Installation<br>------------<br><br>(You are using a `virtualenv`_, right?)<br><br>At the command line, install tabutils using either ``pip`` (*recommended*)<br><br>.. code-block:: bash<br><br>    pip install tabutils<br><br>or ``easy_install``<br><br>.. code-block:: bash<br><br>    easy_install tabutils<br><br>Please see the `installation doc`_ for more details.<br><br>Project Structure<br>-----------------<br><br>.. code-block:: bash<br><br>    \u250c\u2500\u2500 AUTHORS.rst<br>    \u251c\u2500\u2500 CHANGES.rst<br>    \u251c\u2500\u2500 CONTRIBUTING.rst<br>    \u251c\u2500\u2500 INSTALLATION.rst<br>    \u251c\u2500\u2500 LICENSE<br>    \u251c\u2500\u2500 MANIFEST.in<br>    \u251c\u2500\u2500 Makefile<br>    \u251c\u2500\u2500 README.rst<br>    \u251c\u2500\u2500 TODO.rst<br>    \u251c\u2500\u2500 data<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 converted<br>    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 dbf.csv<br>    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 fixed.csv<br>    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 geo.csv<br>    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 geojson.csv<br>    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 json.csv<br>    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 json_multiline.csv<br>    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 sheet_2.csv<br>    \u2502\u00a0\u00a0 \u2514\u2500\u2500 test<br>    \u2502\u00a0\u00a0     \u251c\u2500\u2500 fixed.txt<br>    \u2502\u00a0\u00a0     \u251c\u2500\u2500 fixed_w_header.txt<br>    \u2502\u00a0\u00a0     \u251c\u2500\u2500 iris.csv<br>    \u2502\u00a0\u00a0     \u251c\u2500\u2500 irismeta.csv<br>    \u2502\u00a0\u00a0     \u251c\u2500\u2500 latin1.csv<br>    \u2502\u00a0\u00a0     \u251c\u2500\u2500 mac_newlines.csv<br>    \u2502\u00a0\u00a0     \u251c\u2500\u2500 newline.json<br>    \u2502\u00a0\u00a0     \u251c\u2500\u2500 no_header_row.csv<br>    \u2502\u00a0\u00a0     \u251c\u2500\u2500 test.csv<br>    \u2502\u00a0\u00a0     \u251c\u2500\u2500 test.dbf<br>    \u2502\u00a0\u00a0     \u251c\u2500\u2500 test.geojson<br>    \u2502\u00a0\u00a0     \u251c\u2500\u2500 test.html<br>    \u2502\u00a0\u00a0     \u251c\u2500\u2500 test.json<br>    \u2502\u00a0\u00a0     \u251c\u2500\u2500 test.mdb<br>    \u2502\u00a0\u00a0     \u251c\u2500\u2500 test.sqlite<br>    \u2502\u00a0\u00a0     \u251c\u2500\u2500 test.tsv<br>    \u2502\u00a0\u00a0     \u251c\u2500\u2500 test.xls<br>    \u2502\u00a0\u00a0     \u251c\u2500\u2500 test.xlsx<br>    \u2502\u00a0\u00a0     \u251c\u2500\u2500 test.yml<br>    \u2502\u00a0\u00a0     \u251c\u2500\u2500 utf16_big.csv<br>    \u2502\u00a0\u00a0     \u251c\u2500\u2500 utf16_little.csv<br>    \u2502\u00a0\u00a0     \u2514\u2500\u2500 utf8.csv<br>    \u251c\u2500\u2500 dev-requirements.txt<br>    \u251c\u2500\u2500 examples.py<br>    \u251c\u2500\u2500 helpers<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 check-stage<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 clean<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 pippy<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 srcdist<br>    \u2502\u00a0\u00a0 \u2514\u2500\u2500 wheel<br>    \u251c\u2500\u2500 manage.py<br>    \u251c\u2500\u2500 py2-requirements.txt<br>    \u251c\u2500\u2500 requirements.txt<br>    \u251c\u2500\u2500 setup.cfg<br>    \u251c\u2500\u2500 setup.py<br>    \u251c\u2500\u2500 tabutils<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 convert.py<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 dbf.py<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 fntools.py<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 io.py<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 process.py<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 stats.py<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 typetools.py<br>    \u2502\u00a0\u00a0 \u2514\u2500\u2500 unicsv.py<br>    \u251c\u2500\u2500 tests<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 standard.rc<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 test_fntools.py<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 test_io.py<br>    \u2502\u00a0\u00a0 \u2514\u2500\u2500 test_process.py<br>    \u2514\u2500\u2500 tox.ini<br><br>Design Principles<br>-----------------<br><br>- prefer functions over objects<br>- provide enough functionality out of the box to easily implement the most common data analysis use cases<br>- make conversion between ``records``, ``arrays``, and ``DataFrames`` dead simple<br>- whenever possible, lazily read objects and stream the result [#]_<br><br>.. [#] Notable exceptions are ``tabutils.process.group``, ``tabutils.process.sort``, ``tabutils.io.read_dbf``, ``tabutils.io.read_yaml``, and ``tabutils.io.read_html``. These functions read the entire contents into memory up front.<br><br>Readers<br>-------<br><br>tabutils' available readers are outlined below:<br><br>+-----------------------+-------------------------+----------------+<br>| File type             | Recognized extension(s) | Default reader |<br>+=======================+=========================+================+<br>| Comma separated file  | csv                     | read_csv       |<br>+-----------------------+-------------------------+----------------+<br>| dBASE/FoxBASE         | dbf                     | read_dbf       |<br>+-----------------------+-------------------------+----------------+<br>| Fixed width file      | fixed                   | read_fixed_fmt |<br>+-----------------------+-------------------------+----------------+<br>| GeoJSON               | geojson, geojson.json   | read_geojson   |<br>+-----------------------+-------------------------+----------------+<br>| HTML table            | html                    | read_html      |<br>+-----------------------+-------------------------+----------------+<br>| JSON                  | json                    | read_json      |<br>+-----------------------+-------------------------+----------------+<br>| Microsoft Access      | mdb                     | read_mdb       |<br>+-----------------------+-------------------------+----------------+<br>| SQLite                | sqlite                  | read_sqlite    |<br>+-----------------------+-------------------------+----------------+<br>| Tab separated file    | tsv                     | read_tsv       |<br>+-----------------------+-------------------------+----------------+<br>| Microsoft Excel       | xls, xlsx               | read_xls       |<br>+-----------------------+-------------------------+----------------+<br>| YAML                  | yml, yaml               | read_yaml      |<br>+-----------------------+-------------------------+----------------+<br><br>Alternatively, tabutils provides a universal reader which will select the<br>appropriate reader based on the file extension as specified in the above<br>table.<br><br>.. code-block:: python<br><br>    from io import open<br>    from tabutils import io<br><br>    records1 = io.read('path/to/file.csv')<br>    records2 = io.read('path/to/file.xls')<br><br>    with open('path/to/file.json', encoding='utf-8') as f:<br>        records3 = io.read(f, ext='json')<br><br>Args<br>^^^^<br><br>Most readers take as their first argument, either a file path or file like object.<br>The notable execption is ``read_mdb`` which only accepts a file path.<br>File like objects should be opened using Python's stdlib ``io.open``. If the file<br>is opened in binary mode ``io.open('/path/to/file')``, be sure to pass the proper<br>encoding if it is anything other than ``utf-8``, e.g.,<br><br>.. code-block:: python<br><br>    from io import open<br>    from tabutils import io<br><br>    with open('path/to/file.xlsx') as f:<br>        records = io.read_xls(f, encoding='latin-1')<br><br>Kwargs<br>^^^^^^<br><br>While each reader has kwargs specific to itself, the following table outlines<br>the most common ones.<br><br>==========  ====  =======================================  =======  =====================================================================================================<br>kwarg       type  description                              default  implementing readers<br>==========  ====  =======================================  =======  =====================================================================================================<br>mode        str   File open mode                           rU       read_csv, read_fixed_fmt, read_geojson, read_html, read_json, read_tsv, read_xls, read_yaml<br>encoding    str   File encoding                            utf-8    read_csv, read_dbf, read_fixed_fmt, read_geojson, read_html, read_json, read_tsv, read_xls, read_yaml<br>has_header  bool  Data has a header row?                   True     read_csv, read_fixed_fmt, read_tsv, read_xls<br>first_row   int   First row to read (zero indexed)         0        read_csv, read_fixed_fmt, read_tsv, read_xls<br>first_col   int   First column to read (zero indexed)      0        read_csv, read_fixed_fmt, read_tsv, read_xls<br>sanitize    bool  Underscorify and lowercase field names?  False    read_csv, read_dbf, read_fixed_fmt, read_html, read_mdb, read_tsv, read_xls<br>dedupe      bool  Deduplicate field names?                 False    read_csv, read_fixed_fmt, read_html, read_mdb, read_tsv, read_xls<br>sheet       int   Sheet to read (zero indexed)             0        read_xls<br>table       int   Table to read (zero indexed)             0        read_dbf, read_html, read_mdb, read_sqlite<br>==========  ====  =======================================  =======  =====================================================================================================<br><br>Scripts<br>-------<br><br>tabutils comes with a built in task manager ``manage.py``<br><br>Setup<br>^^^^^<br><br>.. code-block:: bash<br><br>    pip install -r dev-requirements.txt<br><br>Examples<br>^^^^^^^^<br><br>*Run python linter and nose tests*<br><br>.. code-block:: bash<br><br>    manage lint<br>    manage test<br><br>Contributing<br>------------<br><br>Please mimic the coding style/conventions used in this repo.<br>If you add new classes or functions, please add the appropriate doc blocks with<br>examples. Also, make sure the python linter and nose tests pass.<br><br>Please see the `contributing doc`_ for more details.<br><br>Credits<br>-------<br><br>Shoutouts to `csvkit`_, `messytables`_, and `pandas`_ for heavily inspiring tabutils.<br><br>License<br>-------<br><br>tabutils is distributed under the `MIT License`_.<br><br>.. |travis| image:: https://img.shields.io/travis/reubano/tabutils/master.svg<br>    :target: https://travis-ci.org/reubano/tabutils<br><br>.. |versions| image:: https://img.shields.io/pypi/pyversions/tabutils.svg<br>    :target: https://pypi.python.org/pypi/tabutils<br><br>.. |pypi| image:: https://img.shields.io/pypi/v/tabutils.svg<br>    :target: https://pypi.python.org/pypi/tabutils<br><br>.. _mdbtools: http://sourceforge.net/projects/mdbtools/<br>.. _lxml: http://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser<br>.. _library: #usage<br>.. _NumPy: https://github.com/numpy/numpy<br>.. _a library: https://csvkit.readthedocs.org/en/0.9.1/api/csvkit.py3.html<br>.. _PyPy: https://github.com/pydata/pandas/issues/9532<br>.. _walk in the park: http://pandas.pydata.org/pandas-docs/stable/install.html#installing-pandas-with-anaconda<br>.. _csvkit: https://github.com/onyxfish/csvkit<br>.. _messytables: https://github.com/okfn/messytables<br>.. _pandas: https://github.com/pydata/pandas<br>.. _MIT License: http://opensource.org/licenses/MIT<br>.. _virtualenv: http://www.virtualenv.org/en/latest/index.html<br>.. _contributing doc: https://github.com/reubano/tabutils/blob/master/CONTRIBUTING.rst<br>.. _installation doc: https://github.com/reubano/tabutils/blob/master/INSTALLATION.rst<br>.. _cookbook guide: https://github.com/reubano/tabutils/blob/master/COOKBOOK.rst<br><br><br>=========<br>Changelog<br>=========<br><br>Here you can find the recent changes to pygogo..<br><br>.. changelog::<br>    :version: dev<br>    :released: Ongoing<br><br>    .. change::<br>        :tags:  docs<br><br>        Updated CHANGES.<br><br>.. changelog::<br>    :version: 0.1.0<br>    :released: 2015-12-05<br><br>    .. change::<br>        :tags: docs<br><br>        First release on PyPi.<br><br>.. todo:: vim: set filetype=rst:\n          </div>"}, "last_serial": 2061943, "releases": {"0.10.0": [{"comment_text": "", "digests": {"md5": "ca33859982534a90b1131bdfd1f3eabc", "sha256": "ec43ccaa04093db2352d0e6e8bbac9fb11dfdb60f54471a255d6c1f00b456aa6"}, "downloads": -1, "filename": "tabutils-0.10.0-py27-none-any.whl", "has_sig": true, "md5_digest": "ca33859982534a90b1131bdfd1f3eabc", "packagetype": "bdist_wheel", "python_version": "py27", "requires_python": null, "size": 30986, "upload_time": "2015-10-02T14:40:24", "upload_time_iso_8601": "2015-10-02T14:40:24.616328Z", "url": "https://files.pythonhosted.org/packages/1b/a2/842d8bb9fa3b0b22df5814f7a6b1dd5066c60ec3f0b411f830b433490807/tabutils-0.10.0-py27-none-any.whl", "yanked": false}], "0.12.0": [{"comment_text": "", "digests": {"md5": "f04decf10b9946301b3a2021a56f5756", "sha256": "9284acdf79e5cd48cf58a54ebe90cfb0e19549800ca90ecc0ea85a6b4727e549"}, "downloads": -1, "filename": "tabutils-0.12.0-py27-none-any.whl", "has_sig": true, "md5_digest": "f04decf10b9946301b3a2021a56f5756", "packagetype": "bdist_wheel", "python_version": "py27", "requires_python": null, "size": 37080, "upload_time": "2015-10-02T14:41:37", "upload_time_iso_8601": "2015-10-02T14:41:37.579387Z", "url": "https://files.pythonhosted.org/packages/ad/1a/c2badaf65dbc80b83da48f7b7f0790fbfe014aa8636fe3b0b914369007f6/tabutils-0.12.0-py27-none-any.whl", "yanked": false}], "0.13.0": [{"comment_text": "", "digests": {"md5": "38ac65aea850964db06159a0762fcd9f", "sha256": "03ccc62fa986ea6cae90c6050128af7c4ed59a700c7dd06d2a78c0e62c811cd1"}, "downloads": -1, "filename": "tabutils-0.13.0-py27-none-any.whl", "has_sig": true, "md5_digest": "38ac65aea850964db06159a0762fcd9f", "packagetype": "bdist_wheel", "python_version": "py27", "requires_python": null, "size": 27940, "upload_time": "2015-10-07T12:04:36", "upload_time_iso_8601": "2015-10-07T12:04:36.487257Z", "url": "https://files.pythonhosted.org/packages/32/e2/d931ae2e5669204f3d18e8b82cdf82e8dda2c4d846d1f7d687b9d527145f/tabutils-0.13.0-py27-none-any.whl", "yanked": false}], "0.16.0": [{"comment_text": "", "digests": {"md5": "9593e507d80339aab3b7b965ceaa741a", "sha256": "b6b8a3c59aee86fc05dcaa3fe220b4d307271f6378dc7a6805fceac1798e7231"}, "downloads": -1, "filename": "tabutils-0.16.0-py27-none-any.whl", "has_sig": true, "md5_digest": "9593e507d80339aab3b7b965ceaa741a", "packagetype": "bdist_wheel", "python_version": "py27", "requires_python": null, "size": 26785, "upload_time": "2015-11-30T12:23:58", "upload_time_iso_8601": "2015-11-30T12:23:58.913672Z", "url": "https://files.pythonhosted.org/packages/a1/86/2561db9e1401faee123324f3e67cd27340042d6d6b8bb2ea78c4214c186a/tabutils-0.16.0-py27-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f804cc1ebec029492f96c26ff2d6664c", "sha256": "eced1ef22491d986d69b06c3b77b78a99c4b219b73d485dfc65ce4d0dff5aa4e"}, "downloads": -1, "filename": "tabutils-0.16.0-py2-none-any.whl", "has_sig": true, "md5_digest": "f804cc1ebec029492f96c26ff2d6664c", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 26816, "upload_time": "2016-04-13T14:31:11", "upload_time_iso_8601": "2016-04-13T14:31:11.478240Z", "url": "https://files.pythonhosted.org/packages/6e/00/a98550d4b8e1e0da5817637d75a4d503a1ea833f491fb77b692505755e2d/tabutils-0.16.0-py2-none-any.whl", "yanked": false}], "0.18.0": [{"comment_text": "", "digests": {"md5": "84ca535441c80ce99b729a7486500443", "sha256": "86d5d0f8b212017727d7f354aba81455a8aa3530b450030492701a835776329e"}, "downloads": -1, "filename": "tabutils-0.18.0-py27-none-any.whl", "has_sig": true, "md5_digest": "84ca535441c80ce99b729a7486500443", "packagetype": "bdist_wheel", "python_version": "py27", "requires_python": null, "size": 35105, "upload_time": "2015-10-17T05:40:26", "upload_time_iso_8601": "2015-10-17T05:40:26.389562Z", "url": "https://files.pythonhosted.org/packages/9c/84/42706b6b7f82cb6b7c561984c63b21b87d395fd574cebb2f3b082ba3f0ef/tabutils-0.18.0-py27-none-any.whl", "yanked": false}], "0.18.1": [{"comment_text": "", "digests": {"md5": "efaec5e1d4261193b0835a9b71f03921", "sha256": "ad9b52641d2f2e93f06097d60c44ca5f82be157061fb4848f9887d05b34b31e9"}, "downloads": -1, "filename": "tabutils-0.18.1-py27-none-any.whl", "has_sig": true, "md5_digest": "efaec5e1d4261193b0835a9b71f03921", "packagetype": "bdist_wheel", "python_version": "py27", "requires_python": null, "size": 35108, "upload_time": "2015-10-17T06:34:54", "upload_time_iso_8601": "2015-10-17T06:34:54.754855Z", "url": "https://files.pythonhosted.org/packages/a4/cf/5fc780de2c185b0613730ac0e05178deb421fc20f297a14f483e915be7e2/tabutils-0.18.1-py27-none-any.whl", "yanked": false}], "0.19.1": [{"comment_text": "", "digests": {"md5": "03bfe3f3fc5ab432b9b607fd04fede3c", "sha256": "614c79faeef8dec99051e167eb95a48959be734d94d05e71da729284fbf5826f"}, "downloads": -1, "filename": "tabutils-0.19.1-py27-none-any.whl", "has_sig": true, "md5_digest": "03bfe3f3fc5ab432b9b607fd04fede3c", "packagetype": "bdist_wheel", "python_version": "py27", "requires_python": null, "size": 35987, "upload_time": "2015-11-12T13:47:33", "upload_time_iso_8601": "2015-11-12T13:47:33.772212Z", "url": "https://files.pythonhosted.org/packages/c1/ca/884290f05fe2c40a2175679fb14ef44a4e554a226b66b3ac1cd74e9ceb24/tabutils-0.19.1-py27-none-any.whl", "yanked": false}], "0.19.3": [{"comment_text": "", "digests": {"md5": "0a9f206e70a7a48a7754b76584c6358d", "sha256": "f06fa1df06f988d46cf9c8a4d23f30d2429dd35a80542fa57d9e7221dc80b6bd"}, "downloads": -1, "filename": "tabutils-0.19.3-py27-none-any.whl", "has_sig": true, "md5_digest": "0a9f206e70a7a48a7754b76584c6358d", "packagetype": "bdist_wheel", "python_version": "py27", "requires_python": null, "size": 36717, "upload_time": "2015-11-21T16:22:30", "upload_time_iso_8601": "2015-11-21T16:22:30.259684Z", "url": "https://files.pythonhosted.org/packages/69/2e/b6f500f9c3930574f04aceb7d4af10566162645df1f2c7ba72f3cd7238c1/tabutils-0.19.3-py27-none-any.whl", "yanked": false}], "0.21.0": [{"comment_text": "", "digests": {"md5": "4141ea294054b8ae92c758cb871dbda2", "sha256": "1196733abbce99507b869a3b8558a0e158d4acc6d5cf20871208303eed998888"}, "downloads": -1, "filename": "tabutils-0.21.0-py27-none-any.whl", "has_sig": true, "md5_digest": "4141ea294054b8ae92c758cb871dbda2", "packagetype": "bdist_wheel", "python_version": "py27", "requires_python": null, "size": 35758, "upload_time": "2015-11-25T13:55:53", "upload_time_iso_8601": "2015-11-25T13:55:53.753508Z", "url": "https://files.pythonhosted.org/packages/36/40/d07c2ec2eb8ba4f37702e38c9e752e8754ed3719588d9ef3d372b83f6d67/tabutils-0.21.0-py27-none-any.whl", "yanked": false}], "0.21.1": [{"comment_text": "", "digests": {"md5": "487f59596c834bbacd313ef30b685b94", "sha256": "ec138fae57115152d2748a2704f6323e3adab596580215dbd2282b092a6a2807"}, "downloads": -1, "filename": "tabutils-0.21.1-py27-none-any.whl", "has_sig": true, "md5_digest": "487f59596c834bbacd313ef30b685b94", "packagetype": "bdist_wheel", "python_version": "py27", "requires_python": null, "size": 35771, "upload_time": "2015-11-25T14:44:03", "upload_time_iso_8601": "2015-11-25T14:44:03.967592Z", "url": "https://files.pythonhosted.org/packages/9c/f6/d334aab9401dc4fbaac5f763a6361ff1f37566df271b074e17015f369480/tabutils-0.21.1-py27-none-any.whl", "yanked": false}], "0.22.0": [{"comment_text": "", "digests": {"md5": "ab6076559c2138362995c45e832ad90c", "sha256": "9df89caae1684cad59762f9cf51cc5bc7ecd859984528ab1b7324b2bbce19ac8"}, "downloads": -1, "filename": "tabutils-0.22.0-py27-none-any.whl", "has_sig": true, "md5_digest": "ab6076559c2138362995c45e832ad90c", "packagetype": "bdist_wheel", "python_version": "py27", "requires_python": null, "size": 36047, "upload_time": "2015-11-25T15:36:48", "upload_time_iso_8601": "2015-11-25T15:36:48.738330Z", "url": "https://files.pythonhosted.org/packages/fc/03/0fc5c9543698b54d7c040a22a31fea9050faa6858673020eb4a40ea2e67d/tabutils-0.22.0-py27-none-any.whl", "yanked": false}], "0.22.1": [{"comment_text": "", "digests": {"md5": "285b04783c7470c0964ce7f1db32e8e5", "sha256": "5598b87466d944e5b0db52fbc5cd15308d3ed0bf17b6a9ee6e8de03b8087c2cb"}, "downloads": -1, "filename": "tabutils-0.22.1-py27-none-any.whl", "has_sig": true, "md5_digest": "285b04783c7470c0964ce7f1db32e8e5", "packagetype": "bdist_wheel", "python_version": "py27", "requires_python": null, "size": 36019, "upload_time": "2015-11-25T15:54:32", "upload_time_iso_8601": "2015-11-25T15:54:32.711617Z", "url": "https://files.pythonhosted.org/packages/da/06/9a3e6e6f78defe33d73bcd455fc32876923161a7bfafa4c9bdcecba79f27/tabutils-0.22.1-py27-none-any.whl", "yanked": false}], "0.23.0": [{"comment_text": "", "digests": {"md5": "3161bc1fcbc88bc89c593d64dde1210a", "sha256": "bec094108170fbc79c13425023b31021688e79cc9f50f89fef029404282425c5"}, "downloads": -1, "filename": "tabutils-0.23.0-py27-none-any.whl", "has_sig": true, "md5_digest": "3161bc1fcbc88bc89c593d64dde1210a", "packagetype": "bdist_wheel", "python_version": "py27", "requires_python": null, "size": 36132, "upload_time": "2015-11-30T15:11:36", "upload_time_iso_8601": "2015-11-30T15:11:36.334906Z", "url": "https://files.pythonhosted.org/packages/b2/15/e425b746d446f6574179123d2651849ebe5ea597b1fe0867351e31b0fe4d/tabutils-0.23.0-py27-none-any.whl", "yanked": false}], "0.23.1": [{"comment_text": "", "digests": {"md5": "2fc50198032d191a189481861192c635", "sha256": "660abbf320d181ea040ab8d739f9638408bfc382e5e236a9f28bde88fdd1e671"}, "downloads": -1, "filename": "tabutils-0.23.1-py27-none-any.whl", "has_sig": true, "md5_digest": "2fc50198032d191a189481861192c635", "packagetype": "bdist_wheel", "python_version": "py27", "requires_python": null, "size": 36139, "upload_time": "2015-12-03T15:19:56", "upload_time_iso_8601": "2015-12-03T15:19:56.489607Z", "url": "https://files.pythonhosted.org/packages/18/9e/d7c9648efc49facaf132d079bc8f58e46e4fa8d633978a0d4ae87e753428/tabutils-0.23.1-py27-none-any.whl", "yanked": false}], "0.23.2": [{"comment_text": "", "digests": {"md5": "3a6d283527ce6315297a6e0a514810e4", "sha256": "7138fe70e70ea7ffe6f79c1cdabf27a6f9eb43e361c6ae15b22a3e1935766056"}, "downloads": -1, "filename": "tabutils-0.23.2-py2-none-any.whl", "has_sig": true, "md5_digest": "3a6d283527ce6315297a6e0a514810e4", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 38271, "upload_time": "2016-01-07T11:26:45", "upload_time_iso_8601": "2016-01-07T11:26:45.400496Z", "url": "https://files.pythonhosted.org/packages/e7/02/d71e2db900edc93805fbcb81e694a4128d0fe01943db9eca5d1001026d30/tabutils-0.23.2-py2-none-any.whl", "yanked": false}], "0.23.3": [{"comment_text": "", "digests": {"md5": "d5dfd60e13f3b46df376131beac87ad4", "sha256": "da9823290b6d045a3e6eeb374d35bfb934da07bdfed8fe6723c6301774044e6d"}, "downloads": -1, "filename": "tabutils-0.23.3-py2-none-any.whl", "has_sig": true, "md5_digest": "d5dfd60e13f3b46df376131beac87ad4", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 38360, "upload_time": "2016-01-07T12:48:06", "upload_time_iso_8601": "2016-01-07T12:48:06.192977Z", "url": "https://files.pythonhosted.org/packages/dd/15/5a2f4bc58e8df59a77bde4c3259d0717737f4a730de023ed4a111cbe27d9/tabutils-0.23.3-py2-none-any.whl", "yanked": false}], "0.27.0": [{"comment_text": "", "digests": {"md5": "39c380df2abd086afaf25e43496aa065", "sha256": "3615c1bc328819096184c0fa76e57a3e35847abb0d604e6f90a01a550d90db6f"}, "downloads": -1, "filename": "tabutils-0.27.0-py2.py3-none-any.whl", "has_sig": true, "md5_digest": "39c380df2abd086afaf25e43496aa065", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 59683, "upload_time": "2016-01-20T16:56:54", "upload_time_iso_8601": "2016-01-20T16:56:54.400006Z", "url": "https://files.pythonhosted.org/packages/ef/ae/92f9b1dd8af4e40a1eb6398cf3cf25ae78b3926f7cd2342fc4dd94157453/tabutils-0.27.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "72349390f1c059b3762139e036981aa1", "sha256": "13563439b1c03bba7cd7195c1f8cb7e490bff2dc275c2925b39f3069c998743d"}, "downloads": -1, "filename": "tabutils-0.27.0.tar.gz", "has_sig": true, "md5_digest": "72349390f1c059b3762139e036981aa1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 142423, "upload_time": "2016-01-20T16:57:36", "upload_time_iso_8601": "2016-01-20T16:57:36.095990Z", "url": "https://files.pythonhosted.org/packages/9d/6b/0631f14923c0fa858467a67fd0d238a8e2036b01a3d7aa4fe38b49404eec/tabutils-0.27.0.tar.gz", "yanked": false}], "0.27.1": [{"comment_text": "", "digests": {"md5": "226e467f236fa5eee2f741db0241159a", "sha256": "3d9b76f7ad2be5df77883a95c94bb5e27171979075a9e7a5dabc2716c26b4dfc"}, "downloads": -1, "filename": "tabutils-0.27.1-py2.py3-none-any.whl", "has_sig": true, "md5_digest": "226e467f236fa5eee2f741db0241159a", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 59703, "upload_time": "2016-01-20T17:15:58", "upload_time_iso_8601": "2016-01-20T17:15:58.383277Z", "url": "https://files.pythonhosted.org/packages/c0/c8/3836146b8e6aed609b0f021419f38ae605c7d5384a35d188e91c7f1f354e/tabutils-0.27.1-py2.py3-none-any.whl", "yanked": false}], "0.27.2": [{"comment_text": "", "digests": {"md5": "bfedd8c4f1588c16d7672cd73e97a839", "sha256": "21dcde2bdd1658b1354b82f80eabfe3a99cd65ebe4693c45f00e8eb6af207b97"}, "downloads": -1, "filename": "tabutils-0.27.2-py2.py3-none-any.whl", "has_sig": true, "md5_digest": "bfedd8c4f1588c16d7672cd73e97a839", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 59357, "upload_time": "2016-01-21T12:14:09", "upload_time_iso_8601": "2016-01-21T12:14:09.116331Z", "url": "https://files.pythonhosted.org/packages/2a/a7/d0325ce1a0916b711230f0017ed665b41db3a478450bf3b2dcc8ee5fda85/tabutils-0.27.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0fbd9976be52c0785c81f80ddb3a8859", "sha256": "303179997a64a537b010dac022c51574f58772801707168c3837bce9109b98b9"}, "downloads": -1, "filename": "tabutils-0.27.2.tar.gz", "has_sig": true, "md5_digest": "0fbd9976be52c0785c81f80ddb3a8859", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 141447, "upload_time": "2016-01-21T12:15:13", "upload_time_iso_8601": "2016-01-21T12:15:13.154322Z", "url": "https://files.pythonhosted.org/packages/92/5f/f1357b2f13c5b7d2d2512360675c2ad6d75b6a0b77972a9746742a721e51/tabutils-0.27.2.tar.gz", "yanked": false}], "0.9.0": [], "0.9.1": [{"comment_text": "", "digests": {"md5": "2a83547367a66e533a413d382027e2fc", "sha256": "b8a7c516f34eb02af3cde78c603f0b7bb813a3cf96fe40d0148ad4b36280fa0f"}, "downloads": -1, "filename": "tabutils-0.9.1-py2.py3-none-any.whl", "has_sig": true, "md5_digest": "2a83547367a66e533a413d382027e2fc", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 26154, "upload_time": "2015-08-25T15:54:49", "upload_time_iso_8601": "2015-08-25T15:54:49.495085Z", "url": "https://files.pythonhosted.org/packages/49/c0/3d3a3befae13ca76282afe41eb1b2b5e478334456284be902a03cfc3fb30/tabutils-0.9.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fb57a4edebde7a9d53297596b161072c", "sha256": "064d8f9eaf9005fb2163bf50f15a949d7867eb43a62c7e6373659db2b5c338f4"}, "downloads": -1, "filename": "tabutils-0.9.1.tar.gz", "has_sig": true, "md5_digest": "fb57a4edebde7a9d53297596b161072c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18650, "upload_time": "2015-08-25T15:54:56", "upload_time_iso_8601": "2015-08-25T15:54:56.980924Z", "url": "https://files.pythonhosted.org/packages/41/c0/58019a13d6214ed36dc22fc17ac16a866f39f0483604a87b90ed9a79b82d/tabutils-0.9.1.tar.gz", "yanked": false}], "0.9.4": [{"comment_text": "", "digests": {"md5": "84b2915a8ad0f49fc035664f07c67c1d", "sha256": "2ae3a7684fdb23de122ba25f4dcb213e417ee5d9d7d2e1de47f24351de492dab"}, "downloads": -1, "filename": "tabutils-0.9.4-py2.py3-none-any.whl", "has_sig": true, "md5_digest": "84b2915a8ad0f49fc035664f07c67c1d", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 26126, "upload_time": "2015-08-25T17:49:12", "upload_time_iso_8601": "2015-08-25T17:49:12.627889Z", "url": "https://files.pythonhosted.org/packages/96/7c/5fc226cbefcbcc3f3fa0812005a8825c579d3d27b6fb80ba9b98c8e98623/tabutils-0.9.4-py2.py3-none-any.whl", "yanked": false}], "0.9.5": [{"comment_text": "", "digests": {"md5": "da743709b4a34830cba2928b73cfc462", "sha256": "47cc1acbe92a66a723d26e85add88a44447bc3ede250e62962ccffd275990739"}, "downloads": -1, "filename": "tabutils-0.9.5-py2.py3-none-any.whl", "has_sig": true, "md5_digest": "da743709b4a34830cba2928b73cfc462", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 26167, "upload_time": "2015-08-26T13:54:57", "upload_time_iso_8601": "2015-08-26T13:54:57.969319Z", "url": "https://files.pythonhosted.org/packages/1b/70/3c87fd57dbf522d2fca396062176198c921bf85b0c10e0246285636001ab/tabutils-0.9.5-py2.py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "bfedd8c4f1588c16d7672cd73e97a839", "sha256": "21dcde2bdd1658b1354b82f80eabfe3a99cd65ebe4693c45f00e8eb6af207b97"}, "downloads": -1, "filename": "tabutils-0.27.2-py2.py3-none-any.whl", "has_sig": true, "md5_digest": "bfedd8c4f1588c16d7672cd73e97a839", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 59357, "upload_time": "2016-01-21T12:14:09", "upload_time_iso_8601": "2016-01-21T12:14:09.116331Z", "url": "https://files.pythonhosted.org/packages/2a/a7/d0325ce1a0916b711230f0017ed665b41db3a478450bf3b2dcc8ee5fda85/tabutils-0.27.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0fbd9976be52c0785c81f80ddb3a8859", "sha256": "303179997a64a537b010dac022c51574f58772801707168c3837bce9109b98b9"}, "downloads": -1, "filename": "tabutils-0.27.2.tar.gz", "has_sig": true, "md5_digest": "0fbd9976be52c0785c81f80ddb3a8859", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 141447, "upload_time": "2016-01-21T12:15:13", "upload_time_iso_8601": "2016-01-21T12:15:13.154322Z", "url": "https://files.pythonhosted.org/packages/92/5f/f1357b2f13c5b7d2d2512360675c2ad6d75b6a0b77972a9746742a721e51/tabutils-0.27.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:58:33 2020"}