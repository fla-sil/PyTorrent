{"info": {"author": "Maksym Surzhynskyi", "author_email": "maksym.surzhynskyi@gmail.com", "bugtrack_url": null, "classifiers": ["Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "# What is it?\n\n**`Spltr`** is a simple PyTorch-based data loader and splitter.\nIt may be used to load i) arrays and ii) matrices or iii) Pandas \nDataFrames and iv) CSV files containing numerical data with\nsubsequent split it into `Train, Test (Validation)` subsets in\nthe form of `PyTorch DataLoader` objects. The special emphesis was \ngiven to ease of usage and automation of some frequent data-handling procedures.\n\nOriginally it was developed in order to speed up a data preparation stage\nfor number of trivial ML tasks. Hope it may be useful for you as well.\n\n# Main Features\n\n`Spltr.process_x|y` : converts loaded Input/Target data into PyTorch Tensors \n    with ability to i) preview, ii) define tensor dtype, iii) set the desired \n    device of returned tensor (CPU/GPU), iv) use selected rows/columns from \n    Input/Target data sources or process a single data table (for CSV and \n    Pandas DataFrame only).\n\n`Spltr.reshape_xy` : reshapes subsets.\n\n`Spltr.split_data` : splits data subsets into train, test (validation) \n    PyTorch DataLoader objects.\n\n`Spltr.clean_space` : optimizes memory by deleting unnecessary variables.\n\n# Installation\n\n```python\npip install spltr\n```\n\n# License\n\nOSI Approved :: MIT License\n\n# Documentation\n\nhttps://github.com/maksymsur/Spltr\n\n# Dependencies\n\n+ torch >= 1.1.0\n\n+ numpy >= 1.16.4\n\n+ pandas >= 0.24.2\n\n# What's new\n\n* **Version 0.3.2** brings i) bug fixes and ii) extension of `.split_data` method by including native DataLoader methods like `num_workers`, `pin_memory`, `worker_init_fn`, `multiprocessing_context` and others as per PyTorch documentation.\n\n# Example of usage\n\nHereunder we'll build a simple neural network and describe how `Spltr` may be used in the process.\n\n**STEP 1:** Let's start with loading and reading an Iris dataset to be used as an example. The dataset may be found at: https://github.com/maksymsur/Spltr/blob/master/dataset/iris_num.csv\n\n\n```python\nimport pandas as pd\n\nlink = 'https://raw.githubusercontent.com/maksymsur/spltr/master/dataset/iris_num.csv'\ndb = pd.read_csv(link)\nprint(db.info())\n```\n\n    <class 'pandas.core.frame.DataFrame'>\n    RangeIndex: 150 entries, 0 to 149\n    Data columns (total 5 columns):\n    sepal.length    150 non-null float64\n    sepal.width     150 non-null float64\n    petal.length    150 non-null float64\n    petal.width     150 non-null float64\n    variety         150 non-null int64\n    dtypes: float64(4), int64(1)\n    memory usage: 6.0 KB\n    None\n\n\nBy building a neural network we'll try to predict a 'variety' column. This column identifies Iris species: Setosa = 0, Versicolor = 1 and Virginica = 2. Let's verify that it is comprised from the mentioned 3 unique values.\n\n\n```python\nprint(db.variety.unique())\n```\n\n    [0 1 2]\n\n\n**STEP 2:** Making **`X`** (Input) dataset and excluding the 5th 'variety' column (our Target).\n\n\n```python\nbase_db = db.iloc[:,:-1]\nprint(base_db.head())\n```\n\n       sepal.length  sepal.width  petal.length  petal.width\n    0           5.1          3.5           1.4          0.2\n    1           4.9          3.0           1.4          0.2\n    2           4.7          3.2           1.3          0.2\n    3           4.6          3.1           1.5          0.2\n    4           5.0          3.6           1.4          0.2\n\n\n**STEP 3:** Building **`y`** (Target) dataset out of 'variety' column.\n\n\n```python\ntarget_db = db.iloc[:,-1]\nprint(target_db.head())\n```\n\n    0    0\n    1    0\n    2    0\n    3    0\n    4    0\n    Name: variety, dtype: int64\n\n\n**STEP 4:** Loading necessary packages including `Spltr`. Note: for `Spltr` to work properly `torch`, `numpy` and `pandas` shall be installed as well.\n\n\n```python\nimport torch\nimport numpy as np\nfrom spltr import Spltr\n```\n\n**STEP 5.1:** Now let's instantiate a Spltr object by including **`X,y`** datasets into it.\n\n\n```python\nsplt = Spltr(base_db,target_db)\n```\n\n**STEP 5.2:** Alternatively we may load whole datasets and apply basic preprocessing scenarios (exclude columns, change shape and type of the data, etc.). That allows to quickly iterate and find the best approach to current ML task. To demonstrate that, let's reinstantiate `base_db` & `target_db`\n\n\n```python\nbase_db = pd.read_csv(link) # Now 'base_db' is a 5-column dataset that includes the 'target' (5th) column.\ntarget_db = link # And 'target_db' is a simple link to the same 5-column dataset.\n\nsplt = Spltr(base_db,target_db)\n```\n\nHere we start with processing **`X`** by selecting only 4 feature columns and, thus, excluding the target (5th column). Pls note that presented vocabulary-type selection `{column start : column finish}` works only for DataFrames as for now.\n\n\n```python\nsplt.process_x(preview=True, usecols={0:4})\n```\n\n    [X]: The following DataFrame was loaded:\n\n       sepal.length  sepal.width  petal.length  petal.width\n    0           5.1          3.5           1.4          0.2\n    1           4.9          3.0           1.4          0.2\n\n    [X]: Tensor of shape torch.Size([150, 4]) was created\n\n\nAnd continue with processing **`y`** by using just the 5th column named 'variety'. Note that CSV columns may be selected as per official pd.read_csv documentation.\n\n\n```python\nsplt.process_y(preview=True, usecols=['variety'])\n```\n\n    [y]: The following CSV was loaded:\n\n       variety\n    0        0\n    1        0\n\n    [y]: Tensor of shape torch.Size([150, 1]) was created\n\n\n\n```python\nsplt.reshape_xy(y_shape=-1) # Reshaping 'y' to be easily used in a classification task\nprint(splt.shape_y_)\n```\n\n    torch.Size([150])\n\n\n**STEP 6:** Splitting the dataset into train - 30%, test - 20%, which makes validation set equal to 50% (calculated automatically: val = 100% - train - test), and initializing permutation of the data. \n\n`Spltr.split_data` method may use native `DataLoader` methods like `num_workers`, `pin_memory`, `worker_init_fn`, `multiprocessing_context` and others as per PyTorch documentation.\n\n\n```python\nsplt.split_data(splits=(0.3,0.2), perm_seed=3, batch_size=1, num_workers = 1, shuffle=True)\n```\n\n    [X,y]: The Data is splitted into 3 datasets of length: Train 45, Test 30, Validation 75.\n\n\n**STEP 7:** Now let's clean unnecessary variables saved in the memory. This step may be especially useful if you are dealing with a huge datasets and don't want for `X,y tensors` to share the memory with `X,y DataLoader objects`.\n\n\n```python\nsplt.clean_space()\n```\n\n    All variables are deleted. Only Train-Test (Validation) sets are left.\n\n\n**STEP 8:** Setting up a very simple neural network. Pls mind that the presented network architecture is comprised only to demonstrate how `Spltr` may be adopted. That's not an optimal way to solve Iris classification problem.\n\n\n```python\nfrom torch import nn, optim\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n\n        self.input = nn.Linear(4,8)\n        self.output = nn.Linear(8,3)\n\n    def forward(self,x):\n\n        x = F.softsign(self.input(x))\n        x = self.output(x)\n        return x\n\nmodel = Net()\ncriterion = nn.CrossEntropyLoss(reduction='none')\noptimizer = optim.RMSprop(model.parameters(), lr=0.01, alpha=0.9, eps=1e-08)\n\nfor n in range(7):\n    train_loss = 0.0\n\n    # Fitting a dataset for Training\n\n    for train_data, train_target in splt.xy_train:\n        model.zero_grad()\n        train_result = model(train_data.float())\n        loss = criterion(train_result, train_target)\n        train_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n\n    test_correct = 0\n    with torch.no_grad():\n\n        # Fitting a dataset for Testing\n\n        for test_data, test_target in splt.xy_test:\n            test_result = model(test_data.float())\n            _, predicted = torch.max(test_result, 1)\n            test_correct += (predicted == test_target).sum().item()\n\n    print(f'Epoch {n+1}. Train loss: ', round(train_loss/len(splt.xy_train), 5))\n    print(f'Testing: Correctly identified samples {test_correct} out of {len(splt.xy_test)}', end='\\n\\n')\n\nval_correct = 0\n\nwith torch.no_grad():\n\n    # Fitting a dataset for Validation\n\n    for val_data, val_target in splt.xy_val:\n        val_result = model(val_data.float())\n        _, val_predicted = torch.max(val_result, 1)\n        val_correct += (val_predicted == val_target).sum().item()\n\nprint(f'VALIDATION: Correctly identified samples {val_correct} out of {len(splt.xy_val)}', end='\\n\\n')\n```\n\n    Epoch 1. Train loss:  1.09528\n    Testing: Correctly identified samples 21 out of 30\n\n    Epoch 2. Train loss:  0.80778\n    Testing: Correctly identified samples 21 out of 30\n\n    Epoch 3. Train loss:  0.58353\n    Testing: Correctly identified samples 24 out of 30\n\n    Epoch 4. Train loss:  0.48647\n    Testing: Correctly identified samples 26 out of 30\n\n    Epoch 5. Train loss:  0.43741\n    Testing: Correctly identified samples 21 out of 30\n\n    Epoch 6. Train loss:  0.41516\n    Testing: Correctly identified samples 27 out of 30\n\n    Epoch 7. Train loss:  0.38361\n    Testing: Correctly identified samples 30 out of 30\n\n    VALIDATION: Correctly identified samples 73 out of 75\n\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/maksymsur/spltr", "keywords": "PyTorch,Data loader,Data splitter,DataLoader,random_split,train test,train test validation split,data preprocessing,pytorch dataset split", "license": "", "maintainer": "", "maintainer_email": "", "name": "spltr", "package_url": "https://pypi.org/project/spltr/", "platform": "", "project_url": "https://pypi.org/project/spltr/", "project_urls": {"Homepage": "https://github.com/maksymsur/spltr"}, "release_url": "https://pypi.org/project/spltr/0.3.2/", "requires_dist": null, "requires_python": ">=3.6", "summary": "A simple PyTorch-based data loader and splitter", "version": "0.3.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>What is it?</h1>\n<p><strong><code>Spltr</code></strong> is a simple PyTorch-based data loader and splitter.\nIt may be used to load i) arrays and ii) matrices or iii) Pandas\nDataFrames and iv) CSV files containing numerical data with\nsubsequent split it into <code>Train, Test (Validation)</code> subsets in\nthe form of <code>PyTorch DataLoader</code> objects. The special emphesis was\ngiven to ease of usage and automation of some frequent data-handling procedures.</p>\n<p>Originally it was developed in order to speed up a data preparation stage\nfor number of trivial ML tasks. Hope it may be useful for you as well.</p>\n<h1>Main Features</h1>\n<p><code>Spltr.process_x|y</code> : converts loaded Input/Target data into PyTorch Tensors\nwith ability to i) preview, ii) define tensor dtype, iii) set the desired\ndevice of returned tensor (CPU/GPU), iv) use selected rows/columns from\nInput/Target data sources or process a single data table (for CSV and\nPandas DataFrame only).</p>\n<p><code>Spltr.reshape_xy</code> : reshapes subsets.</p>\n<p><code>Spltr.split_data</code> : splits data subsets into train, test (validation)\nPyTorch DataLoader objects.</p>\n<p><code>Spltr.clean_space</code> : optimizes memory by deleting unnecessary variables.</p>\n<h1>Installation</h1>\n<pre><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">spltr</span>\n</pre>\n<h1>License</h1>\n<p>OSI Approved :: MIT License</p>\n<h1>Documentation</h1>\n<p><a href=\"https://github.com/maksymsur/Spltr\" rel=\"nofollow\">https://github.com/maksymsur/Spltr</a></p>\n<h1>Dependencies</h1>\n<ul>\n<li>\n<p>torch &gt;= 1.1.0</p>\n</li>\n<li>\n<p>numpy &gt;= 1.16.4</p>\n</li>\n<li>\n<p>pandas &gt;= 0.24.2</p>\n</li>\n</ul>\n<h1>What's new</h1>\n<ul>\n<li><strong>Version 0.3.2</strong> brings i) bug fixes and ii) extension of <code>.split_data</code> method by including native DataLoader methods like <code>num_workers</code>, <code>pin_memory</code>, <code>worker_init_fn</code>, <code>multiprocessing_context</code> and others as per PyTorch documentation.</li>\n</ul>\n<h1>Example of usage</h1>\n<p>Hereunder we'll build a simple neural network and describe how <code>Spltr</code> may be used in the process.</p>\n<p><strong>STEP 1:</strong> Let's start with loading and reading an Iris dataset to be used as an example. The dataset may be found at: <a href=\"https://github.com/maksymsur/Spltr/blob/master/dataset/iris_num.csv\" rel=\"nofollow\">https://github.com/maksymsur/Spltr/blob/master/dataset/iris_num.csv</a></p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n\n<span class=\"n\">link</span> <span class=\"o\">=</span> <span class=\"s1\">'https://raw.githubusercontent.com/maksymsur/spltr/master/dataset/iris_num.csv'</span>\n<span class=\"n\">db</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"n\">link</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">())</span>\n</pre>\n<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 150 entries, 0 to 149\nData columns (total 5 columns):\nsepal.length    150 non-null float64\nsepal.width     150 non-null float64\npetal.length    150 non-null float64\npetal.width     150 non-null float64\nvariety         150 non-null int64\ndtypes: float64(4), int64(1)\nmemory usage: 6.0 KB\nNone\n</code></pre>\n<p>By building a neural network we'll try to predict a 'variety' column. This column identifies Iris species: Setosa = 0, Versicolor = 1 and Virginica = 2. Let's verify that it is comprised from the mentioned 3 unique values.</p>\n<pre><span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">variety</span><span class=\"o\">.</span><span class=\"n\">unique</span><span class=\"p\">())</span>\n</pre>\n<pre><code>[0 1 2]\n</code></pre>\n<p><strong>STEP 2:</strong> Making <strong><code>X</code></strong> (Input) dataset and excluding the 5th 'variety' column (our Target).</p>\n<pre><span class=\"n\">base_db</span> <span class=\"o\">=</span> <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">iloc</span><span class=\"p\">[:,:</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">base_db</span><span class=\"o\">.</span><span class=\"n\">head</span><span class=\"p\">())</span>\n</pre>\n<pre><code>   sepal.length  sepal.width  petal.length  petal.width\n0           5.1          3.5           1.4          0.2\n1           4.9          3.0           1.4          0.2\n2           4.7          3.2           1.3          0.2\n3           4.6          3.1           1.5          0.2\n4           5.0          3.6           1.4          0.2\n</code></pre>\n<p><strong>STEP 3:</strong> Building <strong><code>y</code></strong> (Target) dataset out of 'variety' column.</p>\n<pre><span class=\"n\">target_db</span> <span class=\"o\">=</span> <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">iloc</span><span class=\"p\">[:,</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">target_db</span><span class=\"o\">.</span><span class=\"n\">head</span><span class=\"p\">())</span>\n</pre>\n<pre><code>0    0\n1    0\n2    0\n3    0\n4    0\nName: variety, dtype: int64\n</code></pre>\n<p><strong>STEP 4:</strong> Loading necessary packages including <code>Spltr</code>. Note: for <code>Spltr</code> to work properly <code>torch</code>, <code>numpy</code> and <code>pandas</code> shall be installed as well.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">from</span> <span class=\"nn\">spltr</span> <span class=\"kn\">import</span> <span class=\"n\">Spltr</span>\n</pre>\n<p><strong>STEP 5.1:</strong> Now let's instantiate a Spltr object by including <strong><code>X,y</code></strong> datasets into it.</p>\n<pre><span class=\"n\">splt</span> <span class=\"o\">=</span> <span class=\"n\">Spltr</span><span class=\"p\">(</span><span class=\"n\">base_db</span><span class=\"p\">,</span><span class=\"n\">target_db</span><span class=\"p\">)</span>\n</pre>\n<p><strong>STEP 5.2:</strong> Alternatively we may load whole datasets and apply basic preprocessing scenarios (exclude columns, change shape and type of the data, etc.). That allows to quickly iterate and find the best approach to current ML task. To demonstrate that, let's reinstantiate <code>base_db</code> &amp; <code>target_db</code></p>\n<pre><span class=\"n\">base_db</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"n\">link</span><span class=\"p\">)</span> <span class=\"c1\"># Now 'base_db' is a 5-column dataset that includes the 'target' (5th) column.</span>\n<span class=\"n\">target_db</span> <span class=\"o\">=</span> <span class=\"n\">link</span> <span class=\"c1\"># And 'target_db' is a simple link to the same 5-column dataset.</span>\n\n<span class=\"n\">splt</span> <span class=\"o\">=</span> <span class=\"n\">Spltr</span><span class=\"p\">(</span><span class=\"n\">base_db</span><span class=\"p\">,</span><span class=\"n\">target_db</span><span class=\"p\">)</span>\n</pre>\n<p>Here we start with processing <strong><code>X</code></strong> by selecting only 4 feature columns and, thus, excluding the target (5th column). Pls note that presented vocabulary-type selection <code>{column start : column finish}</code> works only for DataFrames as for now.</p>\n<pre><span class=\"n\">splt</span><span class=\"o\">.</span><span class=\"n\">process_x</span><span class=\"p\">(</span><span class=\"n\">preview</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">usecols</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"mi\">0</span><span class=\"p\">:</span><span class=\"mi\">4</span><span class=\"p\">})</span>\n</pre>\n<pre><code>[X]: The following DataFrame was loaded:\n\n   sepal.length  sepal.width  petal.length  petal.width\n0           5.1          3.5           1.4          0.2\n1           4.9          3.0           1.4          0.2\n\n[X]: Tensor of shape torch.Size([150, 4]) was created\n</code></pre>\n<p>And continue with processing <strong><code>y</code></strong> by using just the 5th column named 'variety'. Note that CSV columns may be selected as per official pd.read_csv documentation.</p>\n<pre><span class=\"n\">splt</span><span class=\"o\">.</span><span class=\"n\">process_y</span><span class=\"p\">(</span><span class=\"n\">preview</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">usecols</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'variety'</span><span class=\"p\">])</span>\n</pre>\n<pre><code>[y]: The following CSV was loaded:\n\n   variety\n0        0\n1        0\n\n[y]: Tensor of shape torch.Size([150, 1]) was created\n</code></pre>\n<pre><span class=\"n\">splt</span><span class=\"o\">.</span><span class=\"n\">reshape_xy</span><span class=\"p\">(</span><span class=\"n\">y_shape</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"c1\"># Reshaping 'y' to be easily used in a classification task</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">splt</span><span class=\"o\">.</span><span class=\"n\">shape_y_</span><span class=\"p\">)</span>\n</pre>\n<pre><code>torch.Size([150])\n</code></pre>\n<p><strong>STEP 6:</strong> Splitting the dataset into train - 30%, test - 20%, which makes validation set equal to 50% (calculated automatically: val = 100% - train - test), and initializing permutation of the data.</p>\n<p><code>Spltr.split_data</code> method may use native <code>DataLoader</code> methods like <code>num_workers</code>, <code>pin_memory</code>, <code>worker_init_fn</code>, <code>multiprocessing_context</code> and others as per PyTorch documentation.</p>\n<pre><span class=\"n\">splt</span><span class=\"o\">.</span><span class=\"n\">split_data</span><span class=\"p\">(</span><span class=\"n\">splits</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mf\">0.3</span><span class=\"p\">,</span><span class=\"mf\">0.2</span><span class=\"p\">),</span> <span class=\"n\">perm_seed</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">num_workers</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">shuffle</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<pre><code>[X,y]: The Data is splitted into 3 datasets of length: Train 45, Test 30, Validation 75.\n</code></pre>\n<p><strong>STEP 7:</strong> Now let's clean unnecessary variables saved in the memory. This step may be especially useful if you are dealing with a huge datasets and don't want for <code>X,y tensors</code> to share the memory with <code>X,y DataLoader objects</code>.</p>\n<pre><span class=\"n\">splt</span><span class=\"o\">.</span><span class=\"n\">clean_space</span><span class=\"p\">()</span>\n</pre>\n<pre><code>All variables are deleted. Only Train-Test (Validation) sets are left.\n</code></pre>\n<p><strong>STEP 8:</strong> Setting up a very simple neural network. Pls mind that the presented network architecture is comprised only to demonstrate how <code>Spltr</code> may be adopted. That's not an optimal way to solve Iris classification problem.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torch</span> <span class=\"kn\">import</span> <span class=\"n\">nn</span><span class=\"p\">,</span> <span class=\"n\">optim</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch.nn.functional</span> <span class=\"k\">as</span> <span class=\"nn\">F</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">Net</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">Net</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">input</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">,</span><span class=\"mi\">8</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span><span class=\"n\">x</span><span class=\"p\">):</span>\n\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">softsign</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">input</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">))</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">output</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">x</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Net</span><span class=\"p\">()</span>\n<span class=\"n\">criterion</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">CrossEntropyLoss</span><span class=\"p\">(</span><span class=\"n\">reduction</span><span class=\"o\">=</span><span class=\"s1\">'none'</span><span class=\"p\">)</span>\n<span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">RMSprop</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">(),</span> <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">0.01</span><span class=\"p\">,</span> <span class=\"n\">alpha</span><span class=\"o\">=</span><span class=\"mf\">0.9</span><span class=\"p\">,</span> <span class=\"n\">eps</span><span class=\"o\">=</span><span class=\"mf\">1e-08</span><span class=\"p\">)</span>\n\n<span class=\"k\">for</span> <span class=\"n\">n</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">7</span><span class=\"p\">):</span>\n    <span class=\"n\">train_loss</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>\n\n    <span class=\"c1\"># Fitting a dataset for Training</span>\n\n    <span class=\"k\">for</span> <span class=\"n\">train_data</span><span class=\"p\">,</span> <span class=\"n\">train_target</span> <span class=\"ow\">in</span> <span class=\"n\">splt</span><span class=\"o\">.</span><span class=\"n\">xy_train</span><span class=\"p\">:</span>\n        <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">zero_grad</span><span class=\"p\">()</span>\n        <span class=\"n\">train_result</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">train_data</span><span class=\"o\">.</span><span class=\"n\">float</span><span class=\"p\">())</span>\n        <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">criterion</span><span class=\"p\">(</span><span class=\"n\">train_result</span><span class=\"p\">,</span> <span class=\"n\">train_target</span><span class=\"p\">)</span>\n        <span class=\"n\">train_loss</span> <span class=\"o\">+=</span> <span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">()</span>\n        <span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">()</span>\n        <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n\n    <span class=\"n\">test_correct</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n    <span class=\"k\">with</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">no_grad</span><span class=\"p\">():</span>\n\n        <span class=\"c1\"># Fitting a dataset for Testing</span>\n\n        <span class=\"k\">for</span> <span class=\"n\">test_data</span><span class=\"p\">,</span> <span class=\"n\">test_target</span> <span class=\"ow\">in</span> <span class=\"n\">splt</span><span class=\"o\">.</span><span class=\"n\">xy_test</span><span class=\"p\">:</span>\n            <span class=\"n\">test_result</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">test_data</span><span class=\"o\">.</span><span class=\"n\">float</span><span class=\"p\">())</span>\n            <span class=\"n\">_</span><span class=\"p\">,</span> <span class=\"n\">predicted</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">test_result</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n            <span class=\"n\">test_correct</span> <span class=\"o\">+=</span> <span class=\"p\">(</span><span class=\"n\">predicted</span> <span class=\"o\">==</span> <span class=\"n\">test_target</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">()</span>\n\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">'Epoch </span><span class=\"si\">{</span><span class=\"n\">n</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"si\">}</span><span class=\"s1\">. Train loss: '</span><span class=\"p\">,</span> <span class=\"nb\">round</span><span class=\"p\">(</span><span class=\"n\">train_loss</span><span class=\"o\">/</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">splt</span><span class=\"o\">.</span><span class=\"n\">xy_train</span><span class=\"p\">),</span> <span class=\"mi\">5</span><span class=\"p\">))</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">'Testing: Correctly identified samples </span><span class=\"si\">{</span><span class=\"n\">test_correct</span><span class=\"si\">}</span><span class=\"s1\"> out of </span><span class=\"si\">{</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">splt</span><span class=\"o\">.</span><span class=\"n\">xy_test</span><span class=\"p\">)</span><span class=\"si\">}</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"o\">=</span><span class=\"s1\">'</span><span class=\"se\">\\n\\n</span><span class=\"s1\">'</span><span class=\"p\">)</span>\n\n<span class=\"n\">val_correct</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n\n<span class=\"k\">with</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">no_grad</span><span class=\"p\">():</span>\n\n    <span class=\"c1\"># Fitting a dataset for Validation</span>\n\n    <span class=\"k\">for</span> <span class=\"n\">val_data</span><span class=\"p\">,</span> <span class=\"n\">val_target</span> <span class=\"ow\">in</span> <span class=\"n\">splt</span><span class=\"o\">.</span><span class=\"n\">xy_val</span><span class=\"p\">:</span>\n        <span class=\"n\">val_result</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">val_data</span><span class=\"o\">.</span><span class=\"n\">float</span><span class=\"p\">())</span>\n        <span class=\"n\">_</span><span class=\"p\">,</span> <span class=\"n\">val_predicted</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">val_result</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n        <span class=\"n\">val_correct</span> <span class=\"o\">+=</span> <span class=\"p\">(</span><span class=\"n\">val_predicted</span> <span class=\"o\">==</span> <span class=\"n\">val_target</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">()</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">'VALIDATION: Correctly identified samples </span><span class=\"si\">{</span><span class=\"n\">val_correct</span><span class=\"si\">}</span><span class=\"s1\"> out of </span><span class=\"si\">{</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">splt</span><span class=\"o\">.</span><span class=\"n\">xy_val</span><span class=\"p\">)</span><span class=\"si\">}</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"o\">=</span><span class=\"s1\">'</span><span class=\"se\">\\n\\n</span><span class=\"s1\">'</span><span class=\"p\">)</span>\n</pre>\n<pre><code>Epoch 1. Train loss:  1.09528\nTesting: Correctly identified samples 21 out of 30\n\nEpoch 2. Train loss:  0.80778\nTesting: Correctly identified samples 21 out of 30\n\nEpoch 3. Train loss:  0.58353\nTesting: Correctly identified samples 24 out of 30\n\nEpoch 4. Train loss:  0.48647\nTesting: Correctly identified samples 26 out of 30\n\nEpoch 5. Train loss:  0.43741\nTesting: Correctly identified samples 21 out of 30\n\nEpoch 6. Train loss:  0.41516\nTesting: Correctly identified samples 27 out of 30\n\nEpoch 7. Train loss:  0.38361\nTesting: Correctly identified samples 30 out of 30\n\nVALIDATION: Correctly identified samples 73 out of 75\n</code></pre>\n\n          </div>"}, "last_serial": 6089702, "releases": {"0.3": [{"comment_text": "", "digests": {"md5": "696f939cd967a87d8bd6f50fe2306248", "sha256": "e1f9ea54fe28156e82a690132fcff61f1ccd165f8fc7e615b7c32220a7af9e07"}, "downloads": -1, "filename": "spltr-0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "696f939cd967a87d8bd6f50fe2306248", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 7784, "upload_time": "2019-07-20T12:52:30", "upload_time_iso_8601": "2019-07-20T12:52:30.200099Z", "url": "https://files.pythonhosted.org/packages/39/da/a6c168353228bcc20e5cca9a06c1256a558d673c96fec01decd65df5b25e/spltr-0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ca8432b0f9d01b308013b9a5d06db889", "sha256": "09f9acca98f92794d6af42eee96ae231b2427af97c20395b28ea96ef6382bec6"}, "downloads": -1, "filename": "spltr-0.3.tar.gz", "has_sig": false, "md5_digest": "ca8432b0f9d01b308013b9a5d06db889", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 10006, "upload_time": "2019-07-20T12:52:32", "upload_time_iso_8601": "2019-07-20T12:52:32.638184Z", "url": "https://files.pythonhosted.org/packages/fc/5d/3c05f642acb5f14e3ef9dd0ccf7e470b9ffc683ad8e6f8e1524555f53830/spltr-0.3.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "36bf2207a1bd846ab18caa2e62588bc3", "sha256": "2aa734141df19dea4bad9f75e07f9e3ebdddece0d17a726da80ea28e6c8a838d"}, "downloads": -1, "filename": "spltr-0.3.1-py3-none-any.whl", "has_sig": false, "md5_digest": "36bf2207a1bd846ab18caa2e62588bc3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 8343, "upload_time": "2019-07-22T08:20:13", "upload_time_iso_8601": "2019-07-22T08:20:13.430209Z", "url": "https://files.pythonhosted.org/packages/fd/4c/5d5fe24ee814971f1d40a1a25104139723d547481c8570fb33a21e3684fa/spltr-0.3.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1df1075582adfcd96247a4e23434ee6d", "sha256": "91381e392c6b6bccfd0cdac8bead217e451d0bb54b0b573b14982300fd6a0397"}, "downloads": -1, "filename": "spltr-0.3.1.tar.gz", "has_sig": false, "md5_digest": "1df1075582adfcd96247a4e23434ee6d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 11081, "upload_time": "2019-07-22T08:20:15", "upload_time_iso_8601": "2019-07-22T08:20:15.042441Z", "url": "https://files.pythonhosted.org/packages/db/fe/d52dab2ecf843b75c6544a794817dac67d3f91f4f221ce949741be614a94/spltr-0.3.1.tar.gz", "yanked": false}], "0.3.2": [{"comment_text": "", "digests": {"md5": "487ec31f29c120db2e6c7338724c682e", "sha256": "9e95a0b66a640253ed746b32d235027e345acdeafdaef62f125978db6d8d37c0"}, "downloads": -1, "filename": "spltr-0.3.2-py3-none-any.whl", "has_sig": false, "md5_digest": "487ec31f29c120db2e6c7338724c682e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 9459, "upload_time": "2019-11-06T21:18:11", "upload_time_iso_8601": "2019-11-06T21:18:11.633572Z", "url": "https://files.pythonhosted.org/packages/29/41/57ca20e01cac5134b9b7b15f2ab4c8fe240bc539c2841f256ec4916e929d/spltr-0.3.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9ea8414a0bd90260ae6f5aec9b46758c", "sha256": "5b4988dde610f04889ab53609b358b985761b838f8125a381b268b5fa3e95856"}, "downloads": -1, "filename": "spltr-0.3.2.tar.gz", "has_sig": false, "md5_digest": "9ea8414a0bd90260ae6f5aec9b46758c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 12028, "upload_time": "2019-11-06T21:18:13", "upload_time_iso_8601": "2019-11-06T21:18:13.189243Z", "url": "https://files.pythonhosted.org/packages/de/59/7e233806cc42d30f4fc4ec97a2b7e0e99a6456cd2327b4aff59b015d54f1/spltr-0.3.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "487ec31f29c120db2e6c7338724c682e", "sha256": "9e95a0b66a640253ed746b32d235027e345acdeafdaef62f125978db6d8d37c0"}, "downloads": -1, "filename": "spltr-0.3.2-py3-none-any.whl", "has_sig": false, "md5_digest": "487ec31f29c120db2e6c7338724c682e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 9459, "upload_time": "2019-11-06T21:18:11", "upload_time_iso_8601": "2019-11-06T21:18:11.633572Z", "url": "https://files.pythonhosted.org/packages/29/41/57ca20e01cac5134b9b7b15f2ab4c8fe240bc539c2841f256ec4916e929d/spltr-0.3.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9ea8414a0bd90260ae6f5aec9b46758c", "sha256": "5b4988dde610f04889ab53609b358b985761b838f8125a381b268b5fa3e95856"}, "downloads": -1, "filename": "spltr-0.3.2.tar.gz", "has_sig": false, "md5_digest": "9ea8414a0bd90260ae6f5aec9b46758c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 12028, "upload_time": "2019-11-06T21:18:13", "upload_time_iso_8601": "2019-11-06T21:18:13.189243Z", "url": "https://files.pythonhosted.org/packages/de/59/7e233806cc42d30f4fc4ec97a2b7e0e99a6456cd2327b4aff59b015d54f1/spltr-0.3.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:04:40 2020"}