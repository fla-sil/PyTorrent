{"info": {"author": "Jan Trienes", "author_email": "jan.trienes@nedap.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# deidentify\n\nA Python library to de-identify medical records with state-of-the-art NLP methods. Pre-trained models for the Dutch language are available.\n\nThis repository shares the resources developed in the following paper:\n\n> J. Trienes, D. Trieschnigg, C. Seifert, and D. Hiemstra. Comparing Rule-based, Feature-based and Deep Neural Methods for De-identification of Dutch Medical Records. In: *Proceedings of the 1st ACM WSDM Health Search and Data Mining Workshop (HSDM)*, 2020.\n\nYou can get the authors' version of the paper from this link: [paper](https://djoerdhiemstra.com/wp-content/uploads/hsdm20.pdf).\n\n## Quick Start\n\n### Installation\n\nCreate a new virtual environment with an environment manager of your choice. Then, install `deidentify`:\n\n```sh\npip install deidentify\n```\n\nWe use the spaCy tokenizer. For good compatibility with the pre-trained models, we recommend using the same spaCy tokenization models that were used at de-identification model training time:\n\n```sh\npip install https://github.com/explosion/spacy-models/releases/download/nl_core_news_sm-2.2.1/nl_core_news_sm-2.2.1.tar.gz#egg=nl_core_news_sm==2.2.1\n```\n\n### Example Usage\n\nBelow, we will create an example document and run a pre-trained de-identification model over it. First, let's download a pre-trained model and save it in the model cache at `~/.deidentify`. See below for a [list of available models](#pre-trained-models).\n\n```sh\npython -m deidentify.util.download_model model_bilstmcrf_ons_fast-v0.1.0\n```\n\nThen, we can create a document, load the tagger with the pre-trained model, and finally annotate the document.\n\n```py\nfrom deidentify.base import Document\nfrom deidentify.taggers import FlairTagger\nfrom deidentify.tokenizer import TokenizerFactory\n\n# Create some text\ntext = (\n    \"Dit is stukje tekst met daarin de naam Jan Jansen. De patient J. Jansen (e: \"\n    \"j.jnsen@email.com, t: 06-12345678) is 64 jaar oud en woonachtig in Utrecht. Hij werd op 10 \"\n    \"oktober door arts Peter de Visser ontslagen van de kliniek van het UMCU.\"\n)\n\n# Wrap text in document\ndocuments = [\n    Document(name='doc_01', text=text)\n]\n\n# Select downloaded model\nmodel = 'model_bilstmcrf_ons_fast-v0.1.0'\n\n# Instantiate tokenizer\ntokenizer = TokenizerFactory().tokenizer(corpus='ons', disable=(\"tagger\", \"ner\"))\n\n# Load tagger with a downloaded model file and tokenizer\ntagger = FlairTagger(model=model, tokenizer=tokenizer, verbose=False)\n\n# Annotate your documents\nannotated_docs = tagger.annotate(documents)\n```\n\nThis completes the annotation stage. Let's inspect the entities that the tagger found:\n\n```py\nfrom pprint import pprint\n\nfirst_doc = annotated_docs[0]\npprint(first_doc.annotations)\n```\n\nThis should print the entities of the first document.\n\n```py\n[Annotation(text='Jan Jansen', start=39, end=49, tag='Name', doc_id='', ann_id='T0'),\n Annotation(text='J. Jansen', start=62, end=71, tag='Name', doc_id='', ann_id='T1'),\n Annotation(text='j.jnsen@email.com', start=76, end=93, tag='Email', doc_id='', ann_id='T2'),\n Annotation(text='06-12345678', start=98, end=109, tag='Phone_fax', doc_id='', ann_id='T3'),\n Annotation(text='64 jaar', start=114, end=121, tag='Age', doc_id='', ann_id='T4'),\n Annotation(text='Utrecht', start=143, end=150, tag='Address', doc_id='', ann_id='T5'),\n Annotation(text='10 oktober', start=164, end=174, tag='Date', doc_id='', ann_id='T6'),\n Annotation(text='Peter de Visser', start=185, end=200, tag='Name', doc_id='', ann_id='T7'),\n Annotation(text='UMCU', start=234, end=238, tag='Hospital', doc_id='', ann_id='T8')]\n```\n\nAfterwards, you can replace the discovered entities from the documents using a utility function:\n\n```py\nfrom deidentify.util import mask_annotations\n\nmasked_doc = mask_annotations(first_doc)\nprint(masked_doc.text)\n```\n\nWhich should print:\n\n> Dit is stukje tekst met daarin de naam [NAME]. De patient [NAME] (e: [EMAIL], t: [PHONE_FAX]) is [AGE] oud en woonachtig in [ADDRESS]. Hij werd op [DATE] door arts [NAME] ontslagen van de kliniek van het [HOSPITAL].\n\n\n### Available Taggers\n\nThere are currently three taggers that you can use:\n\n   * `deidentify.taggers.DeduceTagger`: A wrapper around the DEDUCE tagger by Menger et al. (2018, [code](https://github.com/vmenger/deduce), [paper](https://www.sciencedirect.com/science/article/abs/pii/S0736585316307365))\n   * `deidentify.taggers.CRFTagger`: A CRF tagger using the feature set by Liu et al. (2015, [paper](https://www.sciencedirect.com/science/article/pii/S1532046415001197))\n   * `deidentify.taggers.FlairTagger`: A wrapper around the Flair [`SequenceTagger`](https://github.com/zalandoresearch/flair/blob/2d6e89bdfe05644b4e5c7e8327f6ecc6b834ec9e/flair/models/sequence_tagger_model.py#L68) allowing the use of neural architectures such as BiLSTM-CRF. The pre-trained models below use contextualized string embeddings by Akbik et al. (2018, [paper](https://www.aclweb.org/anthology/C18-1139/))\n\nAll taggers implement the `deidentify.taggers.TextTagger` interface which you can implement to provide your own taggers.\n\n### Pre-trained Models\n\nWe provide a number of pre-trained models for the Dutch language. The models were developed on the Nedap/University of Twente (NUT) dataset. The dataset consists of 1260 documents from three domains of Dutch healthcare: elderly care, mental care and disabled care (note: in the codebase we sometimes also refer to this dataset as `ons`). More information on the design of the dataset can be found in [our paper](TODO).\n\n\n| Name | Tagger | Language | Dataset | F1* | Precision* | Recall* | Tags |\n|------|--------|----------|---------|----|-----------|--------|--------|\n| [DEDUCE (Menger et al., 2018)](https://www.sciencedirect.com/science/article/abs/pii/S0736585316307365)** | `DeduceTagger` | Dutch | NUT | 0.7564 | 0.9092 | 0.6476 | [8 PHI Tags](https://github.com/nedap/deidentify/blob/168ad67aec586263250900faaf5a756d3b8dd6fa/deidentify/methods/deduce/run_deduce.py#L17) |\n| [model_crf_ons_tuned-v0.1.0](https://github.com/nedap/deidentify/releases/tag/model_crf_ons_tuned-v0.1.0) | `CRFTagger` | Dutch | NUT | 0.9048 | 0.9632 | 0.8530 | [15 PHI Tags](https://github.com/nedap/deidentify/releases/tag/model_crf_ons_tuned-v0.1.0) |\n| [model_bilstmcrf_ons_fast-v0.1.0](https://github.com/nedap/deidentify/releases/tag/model_bilstmcrf_ons_fast-v0.1.0) | `FlairTagger`  | Dutch | NUT | 0.9461 | 0.9591 | 0.9335 | [15 PHI Tags](https://github.com/nedap/deidentify/releases/tag/model_bilstmcrf_ons_fast-v0.1.0) |\n| [model_bilstmcrf_ons_large-v0.1.0](https://github.com/nedap/deidentify/releases/tag/model_bilstmcrf_ons_large-v0.1.0) | `FlairTagger` | Dutch | NUT | 0.9505 | 0.9683 | 0.9333 | [15 PHI Tags](https://github.com/nedap/deidentify/releases/tag/model_bilstmcrf_ons_large-v0.1.0) |\n\n*\\*All scores are micro-averaged, blind token-level precision/recall/F1 obtained on the test portion of each dataset. For additional metrics, see the corresponding model release.*\n\n*\\*\\*DEDUCE was developed on a dataset of psychiatric nursing notes and treatment plans. The numbers reported here were obtained by applying DEDUCE to our NUT dataset. For more information on the development of DEDUCE, see the paper by [Menger et al. (2018)](https://www.sciencedirect.com/science/article/abs/pii/S0736585316307365).*\n\n## Running Experiments and Training Models\n\nIf you have your own dataset of annotated documents and you want to train your own models on it, you can take a look at the following guides:\n\n   * [Convert your data into our corpus format](docs/01_data_format.md)\n   * [Train and evaluate your own models](docs/02_train_evaluate_models.md)\n   * [Logging and pipeline verbosity](docs/06_pipeline_verbosity.md)\n\nIf you want more information on the experiments in our paper, have a look here:\n\n   * [NUT annotation guidelines](docs/03_hsdm2020_nut_annotation_guidelines.md)\n   * [Surrogate generation procedure](docs/04_hsdm2020_surrogate_generation.md)\n   * [Experiments on English corpora: i2b2/UTHealth and nursing notes](docs/05_hsdm2020_english_datasets.md)\n\n### Computational Environment\n\nWhen you want to run your own experiments, we assume that you clone this code base locally and execute all scripts under `deidentify/` within the following conda environment:\n\n```sh\n# Install package dependencies and add local files to the Python path of that environment.\nconda env create -f environment.yml\nconda activate deidentify && export PYTHONPATH=\"${PYTHONPATH}:$(pwd)\"\n```\n\n## Citation\n\nPlease cite the following paper when using `deidentify`:\n\n```bibtex\n@inproceedings{Trienes:2020:CRF,\n  title={Comparing Rule-based, Feature-based and Deep Neural Methods for De-identification of Dutch Medical Records},\n  author={Trienes, Jan and Trieschnigg, Dolf and Seifert, Christin and Hiemstra, Djoerd},\n  booktitle = {Proceedings of the 1st ACM WSDM Health Search and Data Mining Workshop},\n  series = {{HSDM} 2020},\n  year = {2020}\n}\n```\n\n## Contact\n\nIf you have any question, please contact Jan Trienes at jan.trienes@nedap.com.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/nedap/deidentify", "keywords": "", "license": "MIT License", "maintainer": "", "maintainer_email": "", "name": "deidentify", "package_url": "https://pypi.org/project/deidentify/", "platform": "", "project_url": "https://pypi.org/project/deidentify/", "project_urls": {"Homepage": "https://github.com/nedap/deidentify"}, "release_url": "https://pypi.org/project/deidentify/0.3.2/", "requires_dist": ["requests", "flair (!=0.4.4,>=0.4.3)", "torch (<1.4.0,>=1.1.0)", "spacy (>=2.2.1)", "tqdm (>=4.29)", "deduce (>=1.0.2)", "loguru (>=0.2.5)", "sklearn-crfsuite (>=0.3.6)", "unidecode (>=1.0.23)", "pandas (>=0.23.4)"], "requires_python": ">=3.7", "summary": "De-identify free-text medical records", "version": "0.3.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>deidentify</h1>\n<p>A Python library to de-identify medical records with state-of-the-art NLP methods. Pre-trained models for the Dutch language are available.</p>\n<p>This repository shares the resources developed in the following paper:</p>\n<blockquote>\n<p>J. Trienes, D. Trieschnigg, C. Seifert, and D. Hiemstra. Comparing Rule-based, Feature-based and Deep Neural Methods for De-identification of Dutch Medical Records. In: <em>Proceedings of the 1st ACM WSDM Health Search and Data Mining Workshop (HSDM)</em>, 2020.</p>\n</blockquote>\n<p>You can get the authors' version of the paper from this link: <a href=\"https://djoerdhiemstra.com/wp-content/uploads/hsdm20.pdf\" rel=\"nofollow\">paper</a>.</p>\n<h2>Quick Start</h2>\n<h3>Installation</h3>\n<p>Create a new virtual environment with an environment manager of your choice. Then, install <code>deidentify</code>:</p>\n<pre>pip install deidentify\n</pre>\n<p>We use the spaCy tokenizer. For good compatibility with the pre-trained models, we recommend using the same spaCy tokenization models that were used at de-identification model training time:</p>\n<pre>pip install https://github.com/explosion/spacy-models/releases/download/nl_core_news_sm-2.2.1/nl_core_news_sm-2.2.1.tar.gz#egg<span class=\"o\">=</span><span class=\"nv\">nl_core_news_sm</span><span class=\"o\">==</span><span class=\"m\">2</span>.2.1\n</pre>\n<h3>Example Usage</h3>\n<p>Below, we will create an example document and run a pre-trained de-identification model over it. First, let's download a pre-trained model and save it in the model cache at <code>~/.deidentify</code>. See below for a <a href=\"#pre-trained-models\" rel=\"nofollow\">list of available models</a>.</p>\n<pre>python -m deidentify.util.download_model model_bilstmcrf_ons_fast-v0.1.0\n</pre>\n<p>Then, we can create a document, load the tagger with the pre-trained model, and finally annotate the document.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">deidentify.base</span> <span class=\"kn\">import</span> <span class=\"n\">Document</span>\n<span class=\"kn\">from</span> <span class=\"nn\">deidentify.taggers</span> <span class=\"kn\">import</span> <span class=\"n\">FlairTagger</span>\n<span class=\"kn\">from</span> <span class=\"nn\">deidentify.tokenizer</span> <span class=\"kn\">import</span> <span class=\"n\">TokenizerFactory</span>\n\n<span class=\"c1\"># Create some text</span>\n<span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"p\">(</span>\n    <span class=\"s2\">\"Dit is stukje tekst met daarin de naam Jan Jansen. De patient J. Jansen (e: \"</span>\n    <span class=\"s2\">\"j.jnsen@email.com, t: 06-12345678) is 64 jaar oud en woonachtig in Utrecht. Hij werd op 10 \"</span>\n    <span class=\"s2\">\"oktober door arts Peter de Visser ontslagen van de kliniek van het UMCU.\"</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\"># Wrap text in document</span>\n<span class=\"n\">documents</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n    <span class=\"n\">Document</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'doc_01'</span><span class=\"p\">,</span> <span class=\"n\">text</span><span class=\"o\">=</span><span class=\"n\">text</span><span class=\"p\">)</span>\n<span class=\"p\">]</span>\n\n<span class=\"c1\"># Select downloaded model</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"s1\">'model_bilstmcrf_ons_fast-v0.1.0'</span>\n\n<span class=\"c1\"># Instantiate tokenizer</span>\n<span class=\"n\">tokenizer</span> <span class=\"o\">=</span> <span class=\"n\">TokenizerFactory</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">tokenizer</span><span class=\"p\">(</span><span class=\"n\">corpus</span><span class=\"o\">=</span><span class=\"s1\">'ons'</span><span class=\"p\">,</span> <span class=\"n\">disable</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"s2\">\"tagger\"</span><span class=\"p\">,</span> <span class=\"s2\">\"ner\"</span><span class=\"p\">))</span>\n\n<span class=\"c1\"># Load tagger with a downloaded model file and tokenizer</span>\n<span class=\"n\">tagger</span> <span class=\"o\">=</span> <span class=\"n\">FlairTagger</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"o\">=</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">tokenizer</span><span class=\"o\">=</span><span class=\"n\">tokenizer</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Annotate your documents</span>\n<span class=\"n\">annotated_docs</span> <span class=\"o\">=</span> <span class=\"n\">tagger</span><span class=\"o\">.</span><span class=\"n\">annotate</span><span class=\"p\">(</span><span class=\"n\">documents</span><span class=\"p\">)</span>\n</pre>\n<p>This completes the annotation stage. Let's inspect the entities that the tagger found:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pprint</span> <span class=\"kn\">import</span> <span class=\"n\">pprint</span>\n\n<span class=\"n\">first_doc</span> <span class=\"o\">=</span> <span class=\"n\">annotated_docs</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n<span class=\"n\">pprint</span><span class=\"p\">(</span><span class=\"n\">first_doc</span><span class=\"o\">.</span><span class=\"n\">annotations</span><span class=\"p\">)</span>\n</pre>\n<p>This should print the entities of the first document.</p>\n<pre><span class=\"p\">[</span><span class=\"n\">Annotation</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"s1\">'Jan Jansen'</span><span class=\"p\">,</span> <span class=\"n\">start</span><span class=\"o\">=</span><span class=\"mi\">39</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"o\">=</span><span class=\"mi\">49</span><span class=\"p\">,</span> <span class=\"n\">tag</span><span class=\"o\">=</span><span class=\"s1\">'Name'</span><span class=\"p\">,</span> <span class=\"n\">doc_id</span><span class=\"o\">=</span><span class=\"s1\">''</span><span class=\"p\">,</span> <span class=\"n\">ann_id</span><span class=\"o\">=</span><span class=\"s1\">'T0'</span><span class=\"p\">),</span>\n <span class=\"n\">Annotation</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"s1\">'J. Jansen'</span><span class=\"p\">,</span> <span class=\"n\">start</span><span class=\"o\">=</span><span class=\"mi\">62</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"o\">=</span><span class=\"mi\">71</span><span class=\"p\">,</span> <span class=\"n\">tag</span><span class=\"o\">=</span><span class=\"s1\">'Name'</span><span class=\"p\">,</span> <span class=\"n\">doc_id</span><span class=\"o\">=</span><span class=\"s1\">''</span><span class=\"p\">,</span> <span class=\"n\">ann_id</span><span class=\"o\">=</span><span class=\"s1\">'T1'</span><span class=\"p\">),</span>\n <span class=\"n\">Annotation</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"s1\">'j.jnsen@email.com'</span><span class=\"p\">,</span> <span class=\"n\">start</span><span class=\"o\">=</span><span class=\"mi\">76</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"o\">=</span><span class=\"mi\">93</span><span class=\"p\">,</span> <span class=\"n\">tag</span><span class=\"o\">=</span><span class=\"s1\">'Email'</span><span class=\"p\">,</span> <span class=\"n\">doc_id</span><span class=\"o\">=</span><span class=\"s1\">''</span><span class=\"p\">,</span> <span class=\"n\">ann_id</span><span class=\"o\">=</span><span class=\"s1\">'T2'</span><span class=\"p\">),</span>\n <span class=\"n\">Annotation</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"s1\">'06-12345678'</span><span class=\"p\">,</span> <span class=\"n\">start</span><span class=\"o\">=</span><span class=\"mi\">98</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"o\">=</span><span class=\"mi\">109</span><span class=\"p\">,</span> <span class=\"n\">tag</span><span class=\"o\">=</span><span class=\"s1\">'Phone_fax'</span><span class=\"p\">,</span> <span class=\"n\">doc_id</span><span class=\"o\">=</span><span class=\"s1\">''</span><span class=\"p\">,</span> <span class=\"n\">ann_id</span><span class=\"o\">=</span><span class=\"s1\">'T3'</span><span class=\"p\">),</span>\n <span class=\"n\">Annotation</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"s1\">'64 jaar'</span><span class=\"p\">,</span> <span class=\"n\">start</span><span class=\"o\">=</span><span class=\"mi\">114</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"o\">=</span><span class=\"mi\">121</span><span class=\"p\">,</span> <span class=\"n\">tag</span><span class=\"o\">=</span><span class=\"s1\">'Age'</span><span class=\"p\">,</span> <span class=\"n\">doc_id</span><span class=\"o\">=</span><span class=\"s1\">''</span><span class=\"p\">,</span> <span class=\"n\">ann_id</span><span class=\"o\">=</span><span class=\"s1\">'T4'</span><span class=\"p\">),</span>\n <span class=\"n\">Annotation</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"s1\">'Utrecht'</span><span class=\"p\">,</span> <span class=\"n\">start</span><span class=\"o\">=</span><span class=\"mi\">143</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"o\">=</span><span class=\"mi\">150</span><span class=\"p\">,</span> <span class=\"n\">tag</span><span class=\"o\">=</span><span class=\"s1\">'Address'</span><span class=\"p\">,</span> <span class=\"n\">doc_id</span><span class=\"o\">=</span><span class=\"s1\">''</span><span class=\"p\">,</span> <span class=\"n\">ann_id</span><span class=\"o\">=</span><span class=\"s1\">'T5'</span><span class=\"p\">),</span>\n <span class=\"n\">Annotation</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"s1\">'10 oktober'</span><span class=\"p\">,</span> <span class=\"n\">start</span><span class=\"o\">=</span><span class=\"mi\">164</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"o\">=</span><span class=\"mi\">174</span><span class=\"p\">,</span> <span class=\"n\">tag</span><span class=\"o\">=</span><span class=\"s1\">'Date'</span><span class=\"p\">,</span> <span class=\"n\">doc_id</span><span class=\"o\">=</span><span class=\"s1\">''</span><span class=\"p\">,</span> <span class=\"n\">ann_id</span><span class=\"o\">=</span><span class=\"s1\">'T6'</span><span class=\"p\">),</span>\n <span class=\"n\">Annotation</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"s1\">'Peter de Visser'</span><span class=\"p\">,</span> <span class=\"n\">start</span><span class=\"o\">=</span><span class=\"mi\">185</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"o\">=</span><span class=\"mi\">200</span><span class=\"p\">,</span> <span class=\"n\">tag</span><span class=\"o\">=</span><span class=\"s1\">'Name'</span><span class=\"p\">,</span> <span class=\"n\">doc_id</span><span class=\"o\">=</span><span class=\"s1\">''</span><span class=\"p\">,</span> <span class=\"n\">ann_id</span><span class=\"o\">=</span><span class=\"s1\">'T7'</span><span class=\"p\">),</span>\n <span class=\"n\">Annotation</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"s1\">'UMCU'</span><span class=\"p\">,</span> <span class=\"n\">start</span><span class=\"o\">=</span><span class=\"mi\">234</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"o\">=</span><span class=\"mi\">238</span><span class=\"p\">,</span> <span class=\"n\">tag</span><span class=\"o\">=</span><span class=\"s1\">'Hospital'</span><span class=\"p\">,</span> <span class=\"n\">doc_id</span><span class=\"o\">=</span><span class=\"s1\">''</span><span class=\"p\">,</span> <span class=\"n\">ann_id</span><span class=\"o\">=</span><span class=\"s1\">'T8'</span><span class=\"p\">)]</span>\n</pre>\n<p>Afterwards, you can replace the discovered entities from the documents using a utility function:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">deidentify.util</span> <span class=\"kn\">import</span> <span class=\"n\">mask_annotations</span>\n\n<span class=\"n\">masked_doc</span> <span class=\"o\">=</span> <span class=\"n\">mask_annotations</span><span class=\"p\">(</span><span class=\"n\">first_doc</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">masked_doc</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">)</span>\n</pre>\n<p>Which should print:</p>\n<blockquote>\n<p>Dit is stukje tekst met daarin de naam [NAME]. De patient [NAME] (e: [EMAIL], t: [PHONE_FAX]) is [AGE] oud en woonachtig in [ADDRESS]. Hij werd op [DATE] door arts [NAME] ontslagen van de kliniek van het [HOSPITAL].</p>\n</blockquote>\n<h3>Available Taggers</h3>\n<p>There are currently three taggers that you can use:</p>\n<ul>\n<li><code>deidentify.taggers.DeduceTagger</code>: A wrapper around the DEDUCE tagger by Menger et al. (2018, <a href=\"https://github.com/vmenger/deduce\" rel=\"nofollow\">code</a>, <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0736585316307365\" rel=\"nofollow\">paper</a>)</li>\n<li><code>deidentify.taggers.CRFTagger</code>: A CRF tagger using the feature set by Liu et al. (2015, <a href=\"https://www.sciencedirect.com/science/article/pii/S1532046415001197\" rel=\"nofollow\">paper</a>)</li>\n<li><code>deidentify.taggers.FlairTagger</code>: A wrapper around the Flair <a href=\"https://github.com/zalandoresearch/flair/blob/2d6e89bdfe05644b4e5c7e8327f6ecc6b834ec9e/flair/models/sequence_tagger_model.py#L68\" rel=\"nofollow\"><code>SequenceTagger</code></a> allowing the use of neural architectures such as BiLSTM-CRF. The pre-trained models below use contextualized string embeddings by Akbik et al. (2018, <a href=\"https://www.aclweb.org/anthology/C18-1139/\" rel=\"nofollow\">paper</a>)</li>\n</ul>\n<p>All taggers implement the <code>deidentify.taggers.TextTagger</code> interface which you can implement to provide your own taggers.</p>\n<h3>Pre-trained Models</h3>\n<p>We provide a number of pre-trained models for the Dutch language. The models were developed on the Nedap/University of Twente (NUT) dataset. The dataset consists of 1260 documents from three domains of Dutch healthcare: elderly care, mental care and disabled care (note: in the codebase we sometimes also refer to this dataset as <code>ons</code>). More information on the design of the dataset can be found in <a href=\"TODO\" rel=\"nofollow\">our paper</a>.</p>\n<table>\n<thead>\n<tr>\n<th>Name</th>\n<th>Tagger</th>\n<th>Language</th>\n<th>Dataset</th>\n<th>F1*</th>\n<th>Precision*</th>\n<th>Recall*</th>\n<th>Tags</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0736585316307365\" rel=\"nofollow\">DEDUCE (Menger et al., 2018)</a>**</td>\n<td><code>DeduceTagger</code></td>\n<td>Dutch</td>\n<td>NUT</td>\n<td>0.7564</td>\n<td>0.9092</td>\n<td>0.6476</td>\n<td><a href=\"https://github.com/nedap/deidentify/blob/168ad67aec586263250900faaf5a756d3b8dd6fa/deidentify/methods/deduce/run_deduce.py#L17\" rel=\"nofollow\">8 PHI Tags</a></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/nedap/deidentify/releases/tag/model_crf_ons_tuned-v0.1.0\" rel=\"nofollow\">model_crf_ons_tuned-v0.1.0</a></td>\n<td><code>CRFTagger</code></td>\n<td>Dutch</td>\n<td>NUT</td>\n<td>0.9048</td>\n<td>0.9632</td>\n<td>0.8530</td>\n<td><a href=\"https://github.com/nedap/deidentify/releases/tag/model_crf_ons_tuned-v0.1.0\" rel=\"nofollow\">15 PHI Tags</a></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/nedap/deidentify/releases/tag/model_bilstmcrf_ons_fast-v0.1.0\" rel=\"nofollow\">model_bilstmcrf_ons_fast-v0.1.0</a></td>\n<td><code>FlairTagger</code></td>\n<td>Dutch</td>\n<td>NUT</td>\n<td>0.9461</td>\n<td>0.9591</td>\n<td>0.9335</td>\n<td><a href=\"https://github.com/nedap/deidentify/releases/tag/model_bilstmcrf_ons_fast-v0.1.0\" rel=\"nofollow\">15 PHI Tags</a></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/nedap/deidentify/releases/tag/model_bilstmcrf_ons_large-v0.1.0\" rel=\"nofollow\">model_bilstmcrf_ons_large-v0.1.0</a></td>\n<td><code>FlairTagger</code></td>\n<td>Dutch</td>\n<td>NUT</td>\n<td>0.9505</td>\n<td>0.9683</td>\n<td>0.9333</td>\n<td><a href=\"https://github.com/nedap/deidentify/releases/tag/model_bilstmcrf_ons_large-v0.1.0\" rel=\"nofollow\">15 PHI Tags</a></td>\n</tr></tbody></table>\n<p><em>*All scores are micro-averaged, blind token-level precision/recall/F1 obtained on the test portion of each dataset. For additional metrics, see the corresponding model release.</em></p>\n<p><em>**DEDUCE was developed on a dataset of psychiatric nursing notes and treatment plans. The numbers reported here were obtained by applying DEDUCE to our NUT dataset. For more information on the development of DEDUCE, see the paper by <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0736585316307365\" rel=\"nofollow\">Menger et al. (2018)</a>.</em></p>\n<h2>Running Experiments and Training Models</h2>\n<p>If you have your own dataset of annotated documents and you want to train your own models on it, you can take a look at the following guides:</p>\n<ul>\n<li><a href=\"docs/01_data_format.md\" rel=\"nofollow\">Convert your data into our corpus format</a></li>\n<li><a href=\"docs/02_train_evaluate_models.md\" rel=\"nofollow\">Train and evaluate your own models</a></li>\n<li><a href=\"docs/06_pipeline_verbosity.md\" rel=\"nofollow\">Logging and pipeline verbosity</a></li>\n</ul>\n<p>If you want more information on the experiments in our paper, have a look here:</p>\n<ul>\n<li><a href=\"docs/03_hsdm2020_nut_annotation_guidelines.md\" rel=\"nofollow\">NUT annotation guidelines</a></li>\n<li><a href=\"docs/04_hsdm2020_surrogate_generation.md\" rel=\"nofollow\">Surrogate generation procedure</a></li>\n<li><a href=\"docs/05_hsdm2020_english_datasets.md\" rel=\"nofollow\">Experiments on English corpora: i2b2/UTHealth and nursing notes</a></li>\n</ul>\n<h3>Computational Environment</h3>\n<p>When you want to run your own experiments, we assume that you clone this code base locally and execute all scripts under <code>deidentify/</code> within the following conda environment:</p>\n<pre><span class=\"c1\"># Install package dependencies and add local files to the Python path of that environment.</span>\nconda env create -f environment.yml\nconda activate deidentify <span class=\"o\">&amp;&amp;</span> <span class=\"nb\">export</span> <span class=\"nv\">PYTHONPATH</span><span class=\"o\">=</span><span class=\"s2\">\"</span><span class=\"si\">${</span><span class=\"nv\">PYTHONPATH</span><span class=\"si\">}</span><span class=\"s2\">:</span><span class=\"k\">$(</span><span class=\"nb\">pwd</span><span class=\"k\">)</span><span class=\"s2\">\"</span>\n</pre>\n<h2>Citation</h2>\n<p>Please cite the following paper when using <code>deidentify</code>:</p>\n<pre><span class=\"nc\">@inproceedings</span><span class=\"p\">{</span><span class=\"nl\">Trienes:2020:CRF</span><span class=\"p\">,</span>\n  <span class=\"na\">title</span><span class=\"p\">=</span><span class=\"s\">{Comparing Rule-based, Feature-based and Deep Neural Methods for De-identification of Dutch Medical Records}</span><span class=\"p\">,</span>\n  <span class=\"na\">author</span><span class=\"p\">=</span><span class=\"s\">{Trienes, Jan and Trieschnigg, Dolf and Seifert, Christin and Hiemstra, Djoerd}</span><span class=\"p\">,</span>\n  <span class=\"na\">booktitle</span> <span class=\"p\">=</span> <span class=\"s\">{Proceedings of the 1st ACM WSDM Health Search and Data Mining Workshop}</span><span class=\"p\">,</span>\n  <span class=\"na\">series</span> <span class=\"p\">=</span> <span class=\"s\">{{HSDM} 2020}</span><span class=\"p\">,</span>\n  <span class=\"na\">year</span> <span class=\"p\">=</span> <span class=\"s\">{2020}</span>\n<span class=\"p\">}</span>\n</pre>\n<h2>Contact</h2>\n<p>If you have any question, please contact Jan Trienes at <a href=\"mailto:jan.trienes@nedap.com\">jan.trienes@nedap.com</a>.</p>\n\n          </div>"}, "last_serial": 6806289, "releases": {"0.3.0": [{"comment_text": "", "digests": {"md5": "6ebf0d827f23a9a2f6b13508a9dd38f4", "sha256": "da004bb3abf5eb8b80d6534d48a0ef028cd0266c8272b7a0dc80f2b1cb882d2b"}, "downloads": -1, "filename": "deidentify-0.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "6ebf0d827f23a9a2f6b13508a9dd38f4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 74390, "upload_time": "2020-01-16T06:44:31", "upload_time_iso_8601": "2020-01-16T06:44:31.585275Z", "url": "https://files.pythonhosted.org/packages/7b/91/8a0a45350fbdbce482d4fee202552347df727dc7ce53cb70bab13ca8573f/deidentify-0.3.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5b39588ffa485b3838a1de773a0057e1", "sha256": "1b3b3f208870a6bfe4f487be9074c2a3442385aa65d484167122d01b5cb7b23e"}, "downloads": -1, "filename": "deidentify-0.3.0.tar.gz", "has_sig": false, "md5_digest": "5b39588ffa485b3838a1de773a0057e1", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 53334, "upload_time": "2020-01-16T06:44:34", "upload_time_iso_8601": "2020-01-16T06:44:34.230160Z", "url": "https://files.pythonhosted.org/packages/1e/15/f95a5ea0bb8c371877666d1db1cf9887d0b2c04ddc7d1d20e866eab03d49/deidentify-0.3.0.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "93eb8dbc2e0aba19de10d1b55e62ed7a", "sha256": "e24433ded2497bd8ab978e22606206990512a0c11e239c997ce0baae85e6a8e7"}, "downloads": -1, "filename": "deidentify-0.3.1-py3-none-any.whl", "has_sig": false, "md5_digest": "93eb8dbc2e0aba19de10d1b55e62ed7a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 74400, "upload_time": "2020-01-16T07:18:38", "upload_time_iso_8601": "2020-01-16T07:18:38.134054Z", "url": "https://files.pythonhosted.org/packages/12/b8/2b583a6aa7ba9576f59b16d354feba2888d0359db1d8058ad6ae60ecf7c8/deidentify-0.3.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "44a3c69964213502d6def89f769c8643", "sha256": "1c531e8166e0a5124309446b3186a63c01db220f222af65135c51f9ab48994b8"}, "downloads": -1, "filename": "deidentify-0.3.1.tar.gz", "has_sig": false, "md5_digest": "44a3c69964213502d6def89f769c8643", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 53343, "upload_time": "2020-01-16T07:18:39", "upload_time_iso_8601": "2020-01-16T07:18:39.912606Z", "url": "https://files.pythonhosted.org/packages/b6/eb/12b8eba37e949322b98f9e57278bbf1f3f4e7f9b687549786dbc546ed652/deidentify-0.3.1.tar.gz", "yanked": false}], "0.3.2": [{"comment_text": "", "digests": {"md5": "246f0a4a6d818394ad30d904bb9a0507", "sha256": "8890767d430d78024a4320167a9b7c12a1e27d632255337375767c53ce44b9c4"}, "downloads": -1, "filename": "deidentify-0.3.2-py3-none-any.whl", "has_sig": false, "md5_digest": "246f0a4a6d818394ad30d904bb9a0507", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 74399, "upload_time": "2020-01-16T07:31:26", "upload_time_iso_8601": "2020-01-16T07:31:26.109176Z", "url": "https://files.pythonhosted.org/packages/9e/b9/02f50bef37df7d531a984d6645f6cb33b2fae2dd2ee5a29ea832361a36a8/deidentify-0.3.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "59264a5f2c0fd5135dbe4c43a4d4cb5d", "sha256": "9c5c427a3afcbc93e081928bf6c1ffad6334fc1bdaa7034c47609880cbc1a8ab"}, "downloads": -1, "filename": "deidentify-0.3.2.tar.gz", "has_sig": false, "md5_digest": "59264a5f2c0fd5135dbe4c43a4d4cb5d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 53353, "upload_time": "2020-01-16T07:31:27", "upload_time_iso_8601": "2020-01-16T07:31:27.781958Z", "url": "https://files.pythonhosted.org/packages/97/0d/6d541f6c26d4e04599bfc6ce52a124efd5cca7ffa47d3a212c9ecacb93ec/deidentify-0.3.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "246f0a4a6d818394ad30d904bb9a0507", "sha256": "8890767d430d78024a4320167a9b7c12a1e27d632255337375767c53ce44b9c4"}, "downloads": -1, "filename": "deidentify-0.3.2-py3-none-any.whl", "has_sig": false, "md5_digest": "246f0a4a6d818394ad30d904bb9a0507", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 74399, "upload_time": "2020-01-16T07:31:26", "upload_time_iso_8601": "2020-01-16T07:31:26.109176Z", "url": "https://files.pythonhosted.org/packages/9e/b9/02f50bef37df7d531a984d6645f6cb33b2fae2dd2ee5a29ea832361a36a8/deidentify-0.3.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "59264a5f2c0fd5135dbe4c43a4d4cb5d", "sha256": "9c5c427a3afcbc93e081928bf6c1ffad6334fc1bdaa7034c47609880cbc1a8ab"}, "downloads": -1, "filename": "deidentify-0.3.2.tar.gz", "has_sig": false, "md5_digest": "59264a5f2c0fd5135dbe4c43a4d4cb5d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 53353, "upload_time": "2020-01-16T07:31:27", "upload_time_iso_8601": "2020-01-16T07:31:27.781958Z", "url": "https://files.pythonhosted.org/packages/97/0d/6d541f6c26d4e04599bfc6ce52a124efd5cca7ffa47d3a212c9ecacb93ec/deidentify-0.3.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:39:14 2020"}