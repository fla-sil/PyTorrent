{"info": {"author": "Joseph TOUZET", "author_email": "joseph.touzet@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: GNU General Public License v3 (GPLv3)", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "A library to compute N-D convolutions, transposed convolutions and recursive convolution in pytorch, using `Linear` filter or arbitrary functions as filter. It also gives the option of automaticly finding convolution parameters to match a desired output shape.\n\n# Instalation\n\nUse `pip3 install torchConvNd`\n\n# Documentation\n\n## convNd\n```python\nconvNd(x, weight, kernel, stride=1, dilation=1, padding=0, bias=None, padding_mode='constant', padding_value=0)\n```\n\nN-Dimensional convolution.\n\n#### *Inputs* :\n\n__x__ : `torch.tensor` of shape `(batch_size, C_in, *shape)`.\n\n__Weight__ : `torch.tensor` of size `(C_in * kernel[0] * kernel[1] * ...kernel[n_dims], C_out)`.\n\n__kernel__ : array-like or int, kernel size of the convolution.\n\n__stride__ : array-like or int, stride length of the convolution.\n\n__dilation__ : array-like or int, dilation of the convolution.\n\n__padding__ : `None`, array-like or int, padding size.\n\n__bias__ : `None` or `torch.tensor` of size `(C_out, )`.\n\n__padding\\_mode__,  __padding\\_value__: see [`pad`](#pad).\n\n#### _Outputs_ :\n\n__out__ : `torch.tensor` of shape `(batch_size, C_out, *shape_out)`.\n\n## ConvNd\n```python\nConvNd(in_channels, out_channels, kernel, stride=1, dilation=1, padding=0, bias=False, padding_mode='constant', padding_value=0)\n```\n\nEquivalent of [`convNd`](#convNd) as a `torch.nn.Module` class.\n\n#### *Inputs* :\n\n__in\\_channels__ : int, number of in channels.\n\n__out\\_channels__ : int, number of out channels.\n\n__bias__ : boolean, controls the usage or not of biases.\n\n__kernel__, __stride__, __dilation__, __padding__, __padding\\_mode__,  __padding\\_value__: Same as in [`convNd`](#convNd).\n\n## convTransposeNd\n```python\nconvTransposeNd(x, weight, kernel, stride=1, dilation=1, padding=0, bias=None, padding_mode='constant', padding_value=0)\n```\n\nTransposed convolution (using [`repeat_intereleave`](https://pytorch.org/docs/stable/torch.html#torch.repeat_interleave)).\n\n#### *Inputs* :\n\n__x__ : `torch.tensor` of shape `(batch_size, C_in, *shape)`.\n\n__Weight__ : `torch.tensor` of size `(C_in * kernel[0] * kernel[1] * ...kernel[n_dims], C_out)`.\n\n__kernel__ : array-like or int, kernel size of the transposed convolution.\n\n__stride__ : array-like or int, stride length of the transposed convolution.\n\n__dilation__ : array-like or int, dilation of the convolution.\n\n__padding__ : `None`, array-like or int, padding size.\n\n__bias__ : `None` or `torch.tensor` of size `(C_out, )`.\n\n__padding\\_mode__,  __padding\\_value__: see [`pad`](#pad).\n\n#### _Outputs_ :\n\n__out__ : `torch.tensor` of shape `(batch_size, *shape_out)`.\n\n## ConvTransposeNd\n```python\nConvTransposeNd(in_channels, out_channels, kernel, stride=1, dilation=1, padding=0, bias=None, padding_mode='constant', padding_value=0)\n```\n\nEquivalent of [`convTransposeNd`](#convTransposeNd) as a `torch.nn.Module` class.\n\n#### *Inputs* :\n\n__in\\_channels__ : int, number of in channels.\n\n__out\\_channels__ : int, number of out channels.\n\n__bias__ : boolean, controls the usage or not of biases.\n\n__kernel__, __stride__, __dilation__, __padding__, __padding\\_mode__,  __padding\\_value__: Same as in [`convTransposeNd`](#convTransposeNd).\n\n\n## convNdFunc\n```python\nconvNdFunc(x, func, kernel, stride=1, padding=0, stride_transpose=1, padding_mode='constant', padding_value=0, *args)\n```\n\nEquivalent of [`convNd`](#convNd) using an arbitrary filter `func`.\n\n#### *Inputs* :\n\n__x__ : `torch.tensor` of shape `(batch_size, C_in, *shape)`.\n\n__func__ : function, taking a `torch.tensor` of shape `(batch_size, C_in, *kernel)` and outputs a `torch.tensor` of shape `(batch_size, C_out)`.\n\n__kernel__ : array-like or int, kernel size of the  convolution.\n\n__stride__ : array-like or int, stride length of the convolution.\n\n__dilation__ : array-like or int, dilation of the convolution.\n\n__padding__ : `None`, array-like or int, padding size.\n\n__stride\\_transpose__ : array-like or int, equivalent to `stride` in [`convTransposeNd`](#convTransposeNd).\n\n__padding\\_mode__,  __padding\\_value__: see [`pad`](#pad).\n\n__*args__: additional arguments to pass to `func`.\n\n#### _Outputs_ :\n\n__out__ : `torch.tensor` of shape `(batch_size, *shape_out)`.\n\n__*(additional returns)__ : any additional returns of `func`.\n\n## ConvNdFunc\n```python\nConvNdFunc(func, kernel, stride=1, padding=0, padding_mode='constant', padding_value=0)\n```\n\nEquivalent of [`convNdFunc`](#convNdFunc) as a `torch.nn.Module` class.\n\n#### *Inputs* :\n\n__func__, __kernel__, __stride__, __dilation__, __padding__, __stride\\_transpose__, __padding\\_mode__, __padding\\_value__ : Same as in [`convNdFunc`](#convNdFunc).\n\n# torchConvNd.Utils\n\n## listify\n```python\nlistify(x, dims=1)\n```\n\nTransform `x` to an iterable if it is not.\n\n#### *Inputs* :\n\n__x__ : array like or non iterable object (or string), object to listify.\n\n__dims__ : int, array size to obtain.\n\n#### _Outputs_ :\n\n__out__ :  array like, listified version of x.\n\n## convShape\n```python\nconvShape(input_shape, kernel, stride=1, dilation=1, padding=0, stride_transpose=1)\n```\n\nCompute the ouput shape of a convolution.\n\n#### *Inputs* :\n\n__input\\_shape__ : array-like or int, shape of the input tensor.\n\n__kernel__ : array-like or int, kernel size of the convolution.\n\n__stride__ : array-like or int, stride length of the convolution.\n\n__dilation__ : array-like or int, dilation of the convolution.\n\n__padding__ : `None`, array-like or int, padding size.\n\n__stride\\_transpose__ : array-like or int, equivalent to `stride` in [`convTransposeNd`](#convTransposeNd).\n\n#### _Outputs_ :\n\n__shape__ : array-like or int, predicted output shape of the convolution.\n\n## autoShape\n```python\nautoShape(input_shape, kernel, output_shape, max_dilation=3)\n```\n\nCompute the optimal parameters `stride`, `dilation`, `padding` and `stride_transpose` to match `output_shape`.\n\n#### *Inputs* :\n\n__input\\_shape__ : array-like or int, shape of the input tensor.\n\n__kernel__ : array-like or int, kernel size of the  convolution.\n\n__output\\_shape__ : array-like or int, target shape of the convolution.\n\n__max\\_dilation__ : array-like or int, maximum value of dialtion.\n\n#### _Outputs_ :\n\n__kernel__ : array-like or int, `listified(kernel, len(input_shape))` if `input_shape` is a list, else `kernel`.\n\n__stride__ : array-like or int, stride length of the convolution.\n\n__dilation__ : array-like or int, dilation of the convolution.\n\n__padding__ : array-like or int, padding size.\n\n__stride\\_transpose__ : array-like or int, equivalent to `stride` in [`convTransposeNd`](#convTransposeNd).\n\n## pad\n```python\npad(x, padding, padding_mode='constant', padding_value=0)\n```\n\nBased on [torch.nn.functional.pad](https://pytorch.org/docs/stable/nn.functional.html#pad).\n\n#### *Inputs* :\n\n__x__ :  `torch.tensor`, input tensor.\n\n__padding__ : array-like or int, size of the padding (identical on each size).\n\n__padding\\_mode__ : 'constant', 'reflect', 'replicate' or 'circular', see [torch.nn.functional.pad](https://pytorch.org/docs/stable/nn.functional.html#pad).\n\n__padding\\_value__ : float, value to pad with if `padding_mode` id 'constant'.\n\n#### _Outputs_ :\n\n__out__ :  `torch.tensor`, paded tensor.\n\n## Pad\n```python\nPad(padding, padding_mode='constant', padding_value=0)\n```\n\nEquivalent of [`pad`](#pad) which returns a function.\n\n#### *Inputs* :\n\n__padding__, __padding\\_mode__, __padding\\_value__ : same as with [`pad`](#pad)\n\n## view\n```python\nview(x, kernel, stride=1)\n```\n\nGenerate a view (for a convolution) with parameters `kernel` and `stride`.\n\n#### *Inputs* :\n\n__x__ :  `torch.tensor`, input tensor.\n\n__kernel__ : array-like or int, kernel size of the convolution.\n\n__stride__ : array-like or int, stride length of the convolution.\n\n#### *Outputs* :\n\n__out__ :  `torch.tensor`, strided tensor.\n\n## View\n```python\nView(kernel, stride=1)\n```\n\nEquivalent of [`view`](#view) which returns a function.\n\n#### *Inputs* :\n\n__kernel__, __stride__ : same as in [`view`](#view).\n\n## Flatten\n```python\nFlatten()\n```\n\nA `torch.nn.Module` class that takes a tensor of shape `(N, i, j, k...)` and reshape it to `(N, i*j*k*...)`.\n\n## Reshape\n```python\nReshape(shape)\n```\n\nA `torch.nn.Module` class that takes a tensor of shape `(N, i)` and reshape it to `(N, *shape)`.\n\n#### *Inputs* :\n\n__shape__ : array-like or int, shape to obtain.\n\n## Clip\n```python\nClip(shape)\n```\n\nA `torch.nn.Module` that takes a slice of a tensor of size `shape` (in the center).\n\n#### *Inputs* :\n\n__shape__ : array-like or int, shape to obtain (doesn't affect an axis where `shape=-1`).\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/jolatechno/torchConvNd", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "torchConvNd", "package_url": "https://pypi.org/project/torchConvNd/", "platform": "", "project_url": "https://pypi.org/project/torchConvNd/", "project_urls": {"Homepage": "https://github.com/jolatechno/torchConvNd"}, "release_url": "https://pypi.org/project/torchConvNd/0.2.0/", "requires_dist": ["numpy (>=1.18.0)", "torch (>=1.3.1)"], "requires_python": ">=3.6", "summary": "a library to create convolution from any torch network", "version": "0.2.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>A library to compute N-D convolutions, transposed convolutions and recursive convolution in pytorch, using <code>Linear</code> filter or arbitrary functions as filter. It also gives the option of automaticly finding convolution parameters to match a desired output shape.</p>\n<h1>Instalation</h1>\n<p>Use <code>pip3 install torchConvNd</code></p>\n<h1>Documentation</h1>\n<h2>convNd</h2>\n<pre><span class=\"n\">convNd</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">weight</span><span class=\"p\">,</span> <span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">dilation</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">padding_mode</span><span class=\"o\">=</span><span class=\"s1\">'constant'</span><span class=\"p\">,</span> <span class=\"n\">padding_value</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n</pre>\n<p>N-Dimensional convolution.</p>\n<h4><em>Inputs</em> :</h4>\n<p><strong>x</strong> : <code>torch.tensor</code> of shape <code>(batch_size, C_in, *shape)</code>.</p>\n<p><strong>Weight</strong> : <code>torch.tensor</code> of size <code>(C_in * kernel[0] * kernel[1] * ...kernel[n_dims], C_out)</code>.</p>\n<p><strong>kernel</strong> : array-like or int, kernel size of the convolution.</p>\n<p><strong>stride</strong> : array-like or int, stride length of the convolution.</p>\n<p><strong>dilation</strong> : array-like or int, dilation of the convolution.</p>\n<p><strong>padding</strong> : <code>None</code>, array-like or int, padding size.</p>\n<p><strong>bias</strong> : <code>None</code> or <code>torch.tensor</code> of size <code>(C_out, )</code>.</p>\n<p><strong>padding_mode</strong>,  <strong>padding_value</strong>: see <a href=\"#pad\" rel=\"nofollow\"><code>pad</code></a>.</p>\n<h4><em>Outputs</em> :</h4>\n<p><strong>out</strong> : <code>torch.tensor</code> of shape <code>(batch_size, C_out, *shape_out)</code>.</p>\n<h2>ConvNd</h2>\n<pre><span class=\"n\">ConvNd</span><span class=\"p\">(</span><span class=\"n\">in_channels</span><span class=\"p\">,</span> <span class=\"n\">out_channels</span><span class=\"p\">,</span> <span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">dilation</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">padding_mode</span><span class=\"o\">=</span><span class=\"s1\">'constant'</span><span class=\"p\">,</span> <span class=\"n\">padding_value</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n</pre>\n<p>Equivalent of <a href=\"#convNd\" rel=\"nofollow\"><code>convNd</code></a> as a <code>torch.nn.Module</code> class.</p>\n<h4><em>Inputs</em> :</h4>\n<p><strong>in_channels</strong> : int, number of in channels.</p>\n<p><strong>out_channels</strong> : int, number of out channels.</p>\n<p><strong>bias</strong> : boolean, controls the usage or not of biases.</p>\n<p><strong>kernel</strong>, <strong>stride</strong>, <strong>dilation</strong>, <strong>padding</strong>, <strong>padding_mode</strong>,  <strong>padding_value</strong>: Same as in <a href=\"#convNd\" rel=\"nofollow\"><code>convNd</code></a>.</p>\n<h2>convTransposeNd</h2>\n<pre><span class=\"n\">convTransposeNd</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">weight</span><span class=\"p\">,</span> <span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">dilation</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">padding_mode</span><span class=\"o\">=</span><span class=\"s1\">'constant'</span><span class=\"p\">,</span> <span class=\"n\">padding_value</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n</pre>\n<p>Transposed convolution (using <a href=\"https://pytorch.org/docs/stable/torch.html#torch.repeat_interleave\" rel=\"nofollow\"><code>repeat_intereleave</code></a>).</p>\n<h4><em>Inputs</em> :</h4>\n<p><strong>x</strong> : <code>torch.tensor</code> of shape <code>(batch_size, C_in, *shape)</code>.</p>\n<p><strong>Weight</strong> : <code>torch.tensor</code> of size <code>(C_in * kernel[0] * kernel[1] * ...kernel[n_dims], C_out)</code>.</p>\n<p><strong>kernel</strong> : array-like or int, kernel size of the transposed convolution.</p>\n<p><strong>stride</strong> : array-like or int, stride length of the transposed convolution.</p>\n<p><strong>dilation</strong> : array-like or int, dilation of the convolution.</p>\n<p><strong>padding</strong> : <code>None</code>, array-like or int, padding size.</p>\n<p><strong>bias</strong> : <code>None</code> or <code>torch.tensor</code> of size <code>(C_out, )</code>.</p>\n<p><strong>padding_mode</strong>,  <strong>padding_value</strong>: see <a href=\"#pad\" rel=\"nofollow\"><code>pad</code></a>.</p>\n<h4><em>Outputs</em> :</h4>\n<p><strong>out</strong> : <code>torch.tensor</code> of shape <code>(batch_size, *shape_out)</code>.</p>\n<h2>ConvTransposeNd</h2>\n<pre><span class=\"n\">ConvTransposeNd</span><span class=\"p\">(</span><span class=\"n\">in_channels</span><span class=\"p\">,</span> <span class=\"n\">out_channels</span><span class=\"p\">,</span> <span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">dilation</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">padding_mode</span><span class=\"o\">=</span><span class=\"s1\">'constant'</span><span class=\"p\">,</span> <span class=\"n\">padding_value</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n</pre>\n<p>Equivalent of <a href=\"#convTransposeNd\" rel=\"nofollow\"><code>convTransposeNd</code></a> as a <code>torch.nn.Module</code> class.</p>\n<h4><em>Inputs</em> :</h4>\n<p><strong>in_channels</strong> : int, number of in channels.</p>\n<p><strong>out_channels</strong> : int, number of out channels.</p>\n<p><strong>bias</strong> : boolean, controls the usage or not of biases.</p>\n<p><strong>kernel</strong>, <strong>stride</strong>, <strong>dilation</strong>, <strong>padding</strong>, <strong>padding_mode</strong>,  <strong>padding_value</strong>: Same as in <a href=\"#convTransposeNd\" rel=\"nofollow\"><code>convTransposeNd</code></a>.</p>\n<h2>convNdFunc</h2>\n<pre><span class=\"n\">convNdFunc</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">func</span><span class=\"p\">,</span> <span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">stride_transpose</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">padding_mode</span><span class=\"o\">=</span><span class=\"s1\">'constant'</span><span class=\"p\">,</span> <span class=\"n\">padding_value</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">)</span>\n</pre>\n<p>Equivalent of <a href=\"#convNd\" rel=\"nofollow\"><code>convNd</code></a> using an arbitrary filter <code>func</code>.</p>\n<h4><em>Inputs</em> :</h4>\n<p><strong>x</strong> : <code>torch.tensor</code> of shape <code>(batch_size, C_in, *shape)</code>.</p>\n<p><strong>func</strong> : function, taking a <code>torch.tensor</code> of shape <code>(batch_size, C_in, *kernel)</code> and outputs a <code>torch.tensor</code> of shape <code>(batch_size, C_out)</code>.</p>\n<p><strong>kernel</strong> : array-like or int, kernel size of the  convolution.</p>\n<p><strong>stride</strong> : array-like or int, stride length of the convolution.</p>\n<p><strong>dilation</strong> : array-like or int, dilation of the convolution.</p>\n<p><strong>padding</strong> : <code>None</code>, array-like or int, padding size.</p>\n<p><strong>stride_transpose</strong> : array-like or int, equivalent to <code>stride</code> in <a href=\"#convTransposeNd\" rel=\"nofollow\"><code>convTransposeNd</code></a>.</p>\n<p><strong>padding_mode</strong>,  <strong>padding_value</strong>: see <a href=\"#pad\" rel=\"nofollow\"><code>pad</code></a>.</p>\n<p><strong>*args</strong>: additional arguments to pass to <code>func</code>.</p>\n<h4><em>Outputs</em> :</h4>\n<p><strong>out</strong> : <code>torch.tensor</code> of shape <code>(batch_size, *shape_out)</code>.</p>\n<p><strong>*(additional returns)</strong> : any additional returns of <code>func</code>.</p>\n<h2>ConvNdFunc</h2>\n<pre><span class=\"n\">ConvNdFunc</span><span class=\"p\">(</span><span class=\"n\">func</span><span class=\"p\">,</span> <span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">padding_mode</span><span class=\"o\">=</span><span class=\"s1\">'constant'</span><span class=\"p\">,</span> <span class=\"n\">padding_value</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n</pre>\n<p>Equivalent of <a href=\"#convNdFunc\" rel=\"nofollow\"><code>convNdFunc</code></a> as a <code>torch.nn.Module</code> class.</p>\n<h4><em>Inputs</em> :</h4>\n<p><strong>func</strong>, <strong>kernel</strong>, <strong>stride</strong>, <strong>dilation</strong>, <strong>padding</strong>, <strong>stride_transpose</strong>, <strong>padding_mode</strong>, <strong>padding_value</strong> : Same as in <a href=\"#convNdFunc\" rel=\"nofollow\"><code>convNdFunc</code></a>.</p>\n<h1>torchConvNd.Utils</h1>\n<h2>listify</h2>\n<pre><span class=\"n\">listify</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">dims</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</pre>\n<p>Transform <code>x</code> to an iterable if it is not.</p>\n<h4><em>Inputs</em> :</h4>\n<p><strong>x</strong> : array like or non iterable object (or string), object to listify.</p>\n<p><strong>dims</strong> : int, array size to obtain.</p>\n<h4><em>Outputs</em> :</h4>\n<p><strong>out</strong> :  array like, listified version of x.</p>\n<h2>convShape</h2>\n<pre><span class=\"n\">convShape</span><span class=\"p\">(</span><span class=\"n\">input_shape</span><span class=\"p\">,</span> <span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">dilation</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">stride_transpose</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</pre>\n<p>Compute the ouput shape of a convolution.</p>\n<h4><em>Inputs</em> :</h4>\n<p><strong>input_shape</strong> : array-like or int, shape of the input tensor.</p>\n<p><strong>kernel</strong> : array-like or int, kernel size of the convolution.</p>\n<p><strong>stride</strong> : array-like or int, stride length of the convolution.</p>\n<p><strong>dilation</strong> : array-like or int, dilation of the convolution.</p>\n<p><strong>padding</strong> : <code>None</code>, array-like or int, padding size.</p>\n<p><strong>stride_transpose</strong> : array-like or int, equivalent to <code>stride</code> in <a href=\"#convTransposeNd\" rel=\"nofollow\"><code>convTransposeNd</code></a>.</p>\n<h4><em>Outputs</em> :</h4>\n<p><strong>shape</strong> : array-like or int, predicted output shape of the convolution.</p>\n<h2>autoShape</h2>\n<pre><span class=\"n\">autoShape</span><span class=\"p\">(</span><span class=\"n\">input_shape</span><span class=\"p\">,</span> <span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"n\">output_shape</span><span class=\"p\">,</span> <span class=\"n\">max_dilation</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n</pre>\n<p>Compute the optimal parameters <code>stride</code>, <code>dilation</code>, <code>padding</code> and <code>stride_transpose</code> to match <code>output_shape</code>.</p>\n<h4><em>Inputs</em> :</h4>\n<p><strong>input_shape</strong> : array-like or int, shape of the input tensor.</p>\n<p><strong>kernel</strong> : array-like or int, kernel size of the  convolution.</p>\n<p><strong>output_shape</strong> : array-like or int, target shape of the convolution.</p>\n<p><strong>max_dilation</strong> : array-like or int, maximum value of dialtion.</p>\n<h4><em>Outputs</em> :</h4>\n<p><strong>kernel</strong> : array-like or int, <code>listified(kernel, len(input_shape))</code> if <code>input_shape</code> is a list, else <code>kernel</code>.</p>\n<p><strong>stride</strong> : array-like or int, stride length of the convolution.</p>\n<p><strong>dilation</strong> : array-like or int, dilation of the convolution.</p>\n<p><strong>padding</strong> : array-like or int, padding size.</p>\n<p><strong>stride_transpose</strong> : array-like or int, equivalent to <code>stride</code> in <a href=\"#convTransposeNd\" rel=\"nofollow\"><code>convTransposeNd</code></a>.</p>\n<h2>pad</h2>\n<pre><span class=\"n\">pad</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">padding</span><span class=\"p\">,</span> <span class=\"n\">padding_mode</span><span class=\"o\">=</span><span class=\"s1\">'constant'</span><span class=\"p\">,</span> <span class=\"n\">padding_value</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n</pre>\n<p>Based on <a href=\"https://pytorch.org/docs/stable/nn.functional.html#pad\" rel=\"nofollow\">torch.nn.functional.pad</a>.</p>\n<h4><em>Inputs</em> :</h4>\n<p><strong>x</strong> :  <code>torch.tensor</code>, input tensor.</p>\n<p><strong>padding</strong> : array-like or int, size of the padding (identical on each size).</p>\n<p><strong>padding_mode</strong> : 'constant', 'reflect', 'replicate' or 'circular', see <a href=\"https://pytorch.org/docs/stable/nn.functional.html#pad\" rel=\"nofollow\">torch.nn.functional.pad</a>.</p>\n<p><strong>padding_value</strong> : float, value to pad with if <code>padding_mode</code> id 'constant'.</p>\n<h4><em>Outputs</em> :</h4>\n<p><strong>out</strong> :  <code>torch.tensor</code>, paded tensor.</p>\n<h2>Pad</h2>\n<pre><span class=\"n\">Pad</span><span class=\"p\">(</span><span class=\"n\">padding</span><span class=\"p\">,</span> <span class=\"n\">padding_mode</span><span class=\"o\">=</span><span class=\"s1\">'constant'</span><span class=\"p\">,</span> <span class=\"n\">padding_value</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n</pre>\n<p>Equivalent of <a href=\"#pad\" rel=\"nofollow\"><code>pad</code></a> which returns a function.</p>\n<h4><em>Inputs</em> :</h4>\n<p><strong>padding</strong>, <strong>padding_mode</strong>, <strong>padding_value</strong> : same as with <a href=\"#pad\" rel=\"nofollow\"><code>pad</code></a></p>\n<h2>view</h2>\n<pre><span class=\"n\">view</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</pre>\n<p>Generate a view (for a convolution) with parameters <code>kernel</code> and <code>stride</code>.</p>\n<h4><em>Inputs</em> :</h4>\n<p><strong>x</strong> :  <code>torch.tensor</code>, input tensor.</p>\n<p><strong>kernel</strong> : array-like or int, kernel size of the convolution.</p>\n<p><strong>stride</strong> : array-like or int, stride length of the convolution.</p>\n<h4><em>Outputs</em> :</h4>\n<p><strong>out</strong> :  <code>torch.tensor</code>, strided tensor.</p>\n<h2>View</h2>\n<pre><span class=\"n\">View</span><span class=\"p\">(</span><span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</pre>\n<p>Equivalent of <a href=\"#view\" rel=\"nofollow\"><code>view</code></a> which returns a function.</p>\n<h4><em>Inputs</em> :</h4>\n<p><strong>kernel</strong>, <strong>stride</strong> : same as in <a href=\"#view\" rel=\"nofollow\"><code>view</code></a>.</p>\n<h2>Flatten</h2>\n<pre><span class=\"n\">Flatten</span><span class=\"p\">()</span>\n</pre>\n<p>A <code>torch.nn.Module</code> class that takes a tensor of shape <code>(N, i, j, k...)</code> and reshape it to <code>(N, i*j*k*...)</code>.</p>\n<h2>Reshape</h2>\n<pre><span class=\"n\">Reshape</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"p\">)</span>\n</pre>\n<p>A <code>torch.nn.Module</code> class that takes a tensor of shape <code>(N, i)</code> and reshape it to <code>(N, *shape)</code>.</p>\n<h4><em>Inputs</em> :</h4>\n<p><strong>shape</strong> : array-like or int, shape to obtain.</p>\n<h2>Clip</h2>\n<pre><span class=\"n\">Clip</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"p\">)</span>\n</pre>\n<p>A <code>torch.nn.Module</code> that takes a slice of a tensor of size <code>shape</code> (in the center).</p>\n<h4><em>Inputs</em> :</h4>\n<p><strong>shape</strong> : array-like or int, shape to obtain (doesn't affect an axis where <code>shape=-1</code>).</p>\n\n          </div>"}, "last_serial": 6516605, "releases": {"0.1.9": [{"comment_text": "", "digests": {"md5": "83344bc6514513aaae680646ddb51a04", "sha256": "2d3c65f3e61183d728ae2417e7f52479ed8721044ea9a4b9a738ceff28c064af"}, "downloads": -1, "filename": "torchConvNd-0.1.9-py3-none-any.whl", "has_sig": false, "md5_digest": "83344bc6514513aaae680646ddb51a04", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 21052, "upload_time": "2020-01-15T19:04:58", "upload_time_iso_8601": "2020-01-15T19:04:58.883549Z", "url": "https://files.pythonhosted.org/packages/6d/68/c54975c1dfbc39eae89a17dea49ccb5f581c0fd8a0dc20da097b6d3d8850/torchConvNd-0.1.9-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "dbd600a53d661010046e22bc5ea5b90c", "sha256": "fc407ec6ba4f36c3dce509795e4e27d03f2ad72985c1429a06200333a518e580"}, "downloads": -1, "filename": "torchConvNd-0.1.9.tar.gz", "has_sig": false, "md5_digest": "dbd600a53d661010046e22bc5ea5b90c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 6499, "upload_time": "2020-01-15T19:05:00", "upload_time_iso_8601": "2020-01-15T19:05:00.593357Z", "url": "https://files.pythonhosted.org/packages/ba/da/6a7f2ace69459f6d9869715451d16079f9e3c89821cf93055fa172ebc1e1/torchConvNd-0.1.9.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "9a1975ce38fe0281655fe448a8a0458c", "sha256": "093cd2d70a926867785f3fb1ac36da2373c0526f0d7d517924035fe781b75020"}, "downloads": -1, "filename": "torchConvNd-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "9a1975ce38fe0281655fe448a8a0458c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 21018, "upload_time": "2020-01-24T22:37:02", "upload_time_iso_8601": "2020-01-24T22:37:02.285445Z", "url": "https://files.pythonhosted.org/packages/47/80/6973e60c0da1ceea31b5b538c5a34f4a0b0e845d463f3dea49cfabc6d627/torchConvNd-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "aaa66358588626a541a515663eded722", "sha256": "9f0fa648f82ebd504222cf58b86b3400ba0b2509f37a36df060af319f0456a85"}, "downloads": -1, "filename": "torchConvNd-0.2.0.tar.gz", "has_sig": false, "md5_digest": "aaa66358588626a541a515663eded722", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 6016, "upload_time": "2020-01-24T22:37:04", "upload_time_iso_8601": "2020-01-24T22:37:04.594694Z", "url": "https://files.pythonhosted.org/packages/ea/9b/73f0d25f2ff6305c482a78e593cdb89dd0435c69dc6a9083e0a0f8a2cb29/torchConvNd-0.2.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "9a1975ce38fe0281655fe448a8a0458c", "sha256": "093cd2d70a926867785f3fb1ac36da2373c0526f0d7d517924035fe781b75020"}, "downloads": -1, "filename": "torchConvNd-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "9a1975ce38fe0281655fe448a8a0458c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 21018, "upload_time": "2020-01-24T22:37:02", "upload_time_iso_8601": "2020-01-24T22:37:02.285445Z", "url": "https://files.pythonhosted.org/packages/47/80/6973e60c0da1ceea31b5b538c5a34f4a0b0e845d463f3dea49cfabc6d627/torchConvNd-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "aaa66358588626a541a515663eded722", "sha256": "9f0fa648f82ebd504222cf58b86b3400ba0b2509f37a36df060af319f0456a85"}, "downloads": -1, "filename": "torchConvNd-0.2.0.tar.gz", "has_sig": false, "md5_digest": "aaa66358588626a541a515663eded722", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 6016, "upload_time": "2020-01-24T22:37:04", "upload_time_iso_8601": "2020-01-24T22:37:04.594694Z", "url": "https://files.pythonhosted.org/packages/ea/9b/73f0d25f2ff6305c482a78e593cdb89dd0435c69dc6a9083e0a0f8a2cb29/torchConvNd-0.2.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:50:34 2020"}