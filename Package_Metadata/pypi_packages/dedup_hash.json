{"info": {"author": "Marius van den Beek", "author_email": "m.vandenbeek@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Environment :: Console", "Intended Audience :: Developers", "Natural Language :: English", "Operating System :: POSIX", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Topic :: Scientific/Engineering :: Bio-Informatics"], "description": ".. image:: https://travis-ci.org/mvdbeek/dedup_hash.svg?branch=master\n    :target: https://travis-ci.org/mvdbeek/dedup_hash\n\ndedup_hash\n----------------------------\n\n\nThis is a commandline utility to remove exact duplicate reads\nfrom paired-end fastq files. Reads are assumed to be in 2 separate\nfiles. Read sequences are then concatenated and a short hash is calculated on\nthe concatenated sequence. If the hash has been previsouly seen the read will\nbe dropped from the output file.  This means that reads that have the same\nstart and end coordinate, but differ in lengths will not be removed (but those\nwill be \"flattened\" to at most 1 occurence).\n\nThis algorithm is very simple and fast, and saves memory as compared to\nreading the whole fastq file into memory, such as fastuniq does.\n\nInstallation\n------------\n\ndepdup_city relies on the cityhash python package,\nwhich supports python-2.7 exclusively.\n\n``pip install dedup_hash``\n\n\n\n\n\nHistory\n-------\n\n.. to_doc\n\n---------------------\n0.1.1 (2016-11-23)\n---------------------\n* Make python2/3 compatible\n* Use smhasher as default hasher and add options for cityhash and hashxx\n* Testing enhancements\n\n* Initial version\n---------------------\n0.1.0 (2016-11-16)\n---------------------\n\n* Initial version", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/mvdbeek/dedup_hash", "keywords": "Bioinformatics", "license": "MIT", "maintainer": null, "maintainer_email": null, "name": "dedup_hash", "package_url": "https://pypi.org/project/dedup_hash/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/dedup_hash/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/mvdbeek/dedup_hash"}, "release_url": "https://pypi.org/project/dedup_hash/0.1.1/", "requires_dist": null, "requires_python": null, "summary": "Finds and discards exact duplicate reads in fastq files.", "version": "0.1.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            .. image:: https://travis-ci.org/mvdbeek/dedup_hash.svg?branch=master<br>    :target: https://travis-ci.org/mvdbeek/dedup_hash<br><br>dedup_hash<br>----------------------------<br><br><br>This is a commandline utility to remove exact duplicate reads<br>from paired-end fastq files. Reads are assumed to be in 2 separate<br>files. Read sequences are then concatenated and a short hash is calculated on<br>the concatenated sequence. If the hash has been previsouly seen the read will<br>be dropped from the output file.  This means that reads that have the same<br>start and end coordinate, but differ in lengths will not be removed (but those<br>will be \"flattened\" to at most 1 occurence).<br><br>This algorithm is very simple and fast, and saves memory as compared to<br>reading the whole fastq file into memory, such as fastuniq does.<br><br>Installation<br>------------<br><br>depdup_city relies on the cityhash python package,<br>which supports python-2.7 exclusively.<br><br>``pip install dedup_hash``<br><br><br><br><br><br>History<br>-------<br><br>.. to_doc<br><br>---------------------<br>0.1.1 (2016-11-23)<br>---------------------<br>* Make python2/3 compatible<br>* Use smhasher as default hasher and add options for cityhash and hashxx<br>* Testing enhancements<br><br>* Initial version<br>---------------------<br>0.1.0 (2016-11-16)<br>---------------------<br><br>* Initial version\n          </div>"}, "last_serial": 2480314, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "4f32c7408f3e9b6d10935b800f202b5c", "sha256": "ac133768d692d81eab349bfd04a17691d3884e3fe3d564d4227d710b57c0f3d5"}, "downloads": -1, "filename": "dedup_hash-0.1.0.tar.gz", "has_sig": false, "md5_digest": "4f32c7408f3e9b6d10935b800f202b5c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3041, "upload_time": "2016-11-16T17:33:20", "upload_time_iso_8601": "2016-11-16T17:33:20.262541Z", "url": "https://files.pythonhosted.org/packages/6d/1d/ee1e294bf1202202feab3f18b9e54b76bfaee2f3a539777a2d533d0c2b96/dedup_hash-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "80ed0ca4d57e3952a2f00ac226ed74a5", "sha256": "ee849dc53ce9d01c41c99733f66603d16ad75f7a38b7f4162e0adc4b96636ab4"}, "downloads": -1, "filename": "dedup_hash-0.1.1.tar.gz", "has_sig": false, "md5_digest": "80ed0ca4d57e3952a2f00ac226ed74a5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4289, "upload_time": "2016-11-24T08:05:35", "upload_time_iso_8601": "2016-11-24T08:05:35.937908Z", "url": "https://files.pythonhosted.org/packages/dd/e9/16cddfdc0952839332b695d1a1ee31232950d9fbe3f433f363dba9b8a61d/dedup_hash-0.1.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "80ed0ca4d57e3952a2f00ac226ed74a5", "sha256": "ee849dc53ce9d01c41c99733f66603d16ad75f7a38b7f4162e0adc4b96636ab4"}, "downloads": -1, "filename": "dedup_hash-0.1.1.tar.gz", "has_sig": false, "md5_digest": "80ed0ca4d57e3952a2f00ac226ed74a5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4289, "upload_time": "2016-11-24T08:05:35", "upload_time_iso_8601": "2016-11-24T08:05:35.937908Z", "url": "https://files.pythonhosted.org/packages/dd/e9/16cddfdc0952839332b695d1a1ee31232950d9fbe3f433f363dba9b8a61d/dedup_hash-0.1.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:39:31 2020"}