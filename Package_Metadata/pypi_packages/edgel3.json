{"info": {"author": "Sangeeta Kumari", "author_email": "kumari.14@osu.edu", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Topic :: Multimedia :: Sound/Audio :: Analysis"], "description": "# edgel3\n\n\n[![PyPI](https://img.shields.io/badge/python-2.7%2C%203.5%2C%203.6-blue.svg)](https://pypi.python.org/pypi/edgel3)\n[![MIT license](https://img.shields.io/badge/License-MIT-blue.svg)](https://choosealicense.com/licenses/mit/)\n[![Build Status](https://travis-ci.com/ksangeeta2429/edgel3.svg?branch=master)](https://travis-ci.com/ksangeeta2429/edgel3)\n[![Coverage Status](https://coveralls.io/repos/github/ksangeeta2429/edgel3/badge.svg?branch=master)](https://coveralls.io/github/ksangeeta2429/edgel3?branch=master)\n[![Documentation Status](https://readthedocs.org/projects/edgel3/badge/?version=latest)](https://edgel3.readthedocs.io/en/latest/?badge=latest)\n\nLook, Listen, and Learn (L3) [3],  a  recently  proposed  state-of-the-art  transfer learning technique, helps to train self-supervised deep audio embedding through binary Audio-Visual Correspondence. This embedding can be used to train a variety of downstream audio classification tasks which has limited data. However, with close to 4.7 million parameters, L3-Net is 18 MB in size making it infeasible for small edge devices, such as 'motes' that use a single microcontroller and limited memory to achieve long-lived self-powered operation. \n\nIn [EdgeL3](https://github.com/ksangeeta2429/Publications/raw/master/EdgeL3_Compressing_L3_Net_for_Mote_Scale.pdf) [1], we comprehensively explore the feasibility of compressing the L3-Net for mote-scale inference. We used pruning, ablation, and knowledge distillation techniques to show that the originally proposed L3-Net architecture is substantially overparameterized, not  only for AVC but for the target task of sound classification as evaluated on two popular downstream datasets, US8K and ESC50. EdgeL3, a 95.45% sparsified version of L3-Net, provides a useful reference model for approximating L3 audio embedding for transfer learning.\n\n``edgel3`` is an open-source Python library for downloading the sparsified L3 models and computing deep audio embeddings from such models. The sparse audio embedding models provided have been re-trained using two different mechanisms as described in the [paper](https://github.com/ksangeeta2429/Publications/raw/master/EdgeL3_Compressing_L3_Net_for_Mote_Scale.pdf). The code for the model and training implementation can be found [here](https://github.com/ksangeeta2429/l3embedding/tree/dcompression)\n\nDownload the original L3 model used by EdgeL3 as baseline [here](https://github.com/ksangeeta2429/l3embedding/raw/dcompression/models/cnn_l3_melspec2_recent/model_best_valid_accuracy.h5). For non-sparse models and embedding, please refer to [OpenL3](https://github.com/marl/openl3) [2]\n\n# Installing EdgeL3\n\nDependencies\n------------\n#### Tensorflow\nInstall Tensorflow (CPU-only/GPU) variant that best fits your usecase.\n\nOn most platforms, either of the following commands should properly install Tensorflow:\n\n    pip install tensorflow # CPU-only version\n    pip install tensorflow-gpu # GPU version\n\nFor more detailed information, please consult the\n[Tensorflow installation documentation](https://www.tensorflow.org/install/).\n\n#### libsndfile\nEdgeL3 depends on the `pysoundfile` module to load audio files, which depends on the non-Python library ``libsndfile``. On Windows and macOS, these will be installed via ``pip`` and you can therefore skip this step.\nHowever, on Linux this must be installed manually via your platform's package manager.\nFor Debian-based distributions (such as Ubuntu), this can be done by simply running\n\n    apt-get install libsndfile1\n\nFor more detailed information, please consult the\n[`pysoundfile` installation documentation](https://pysoundfile.readthedocs.io/en/0.9.0/#installation>).\n\n\nInstalling EdgeL3\n-----------------\nThe simplest way to install EdgeL3 is by using ``pip``, which will also install the additional required dependencies\nif needed. To install EdgeL3 using ``pip``, simply run\n\n    pip install edgel3\n\nTo install the latest version of EdgeL3 from source:\n\n1. Clone or pull the lastest version:\n\n        git clone https://github.com/ksangeeta2429/edgel3.git\n\n2. Install using pip to handle python dependencies:\n        cd edgel3\n        pip install -e .\n\n# Using EdgeL3\n\nTo help you get started with EdgeL3 please see the [tutorial](https://edgel3.readthedocs.io/en/latest/tutorial.html) and [module usage](https://edgel3.readthedocs.io/en/latest/edgel3.html).\n\n\n# References\n\nPlease cite the following papers when using EdgeL3 in your work:\n\n[1] **[EdgeL3: Compressing L3-Net for Mote-Scale Urban Noise Monitoring](https://github.com/ksangeeta2429/Publications/raw/master/EdgeL3_Compressing_L3_Net_for_Mote_Scale.pdf)** <br/>\nSangeeta Kumari, Dhrubojyoti Roy, Mark Cartwright, Juan Pablo Bello, and Anish Arora. </br>\nParallel AI and Systems for the Edge (PAISE), Rio de Janeiro, Brazil, May 2019.\n\n[2] **Look, Listen and Learn More: Design Choices for Deep Audio Embeddings** <br/>\nJason Cramer, Ho-Hsiang Wu, Justin Salamon, and Juan Pablo Bello.<br/>\nIEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP), pages 3852\u20133856, Brighton, UK, May 2019.\n\n[3] **Look, Listen and Learn**<br/>\nRelja Arandjelovi\u0107 and Andrew Zisserman<br/>\nIEEE International Conference on Computer Vision (ICCV), Venice, Italy, Oct. 2017.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/ksangeeta2429/edgel3", "keywords": "deep audio embeddings machine listening learning tensorflow keras pruning compression", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "edgel3", "package_url": "https://pypi.org/project/edgel3/", "platform": "", "project_url": "https://pypi.org/project/edgel3/", "project_urls": {"Documentation": "https://readthedocs.org/projects/edgel3/", "Homepage": "https://github.com/ksangeeta2429/edgel3", "Source": "https://github.com/ksangeeta2429/edgel3", "Tracker": "https://github.com/ksangeeta2429/edgel3/issues"}, "release_url": "https://pypi.org/project/edgel3/0.1.0/", "requires_dist": null, "requires_python": "", "summary": "Audio embeddings based on pruned Look, Listen, and Learn (L3) models for the Edge", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>edgel3</h1>\n<p><a href=\"https://pypi.python.org/pypi/edgel3\" rel=\"nofollow\"><img alt=\"PyPI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8e840b6eaf47a19aef39dee5ac3730b9c8b7312b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d322e37253243253230332e35253243253230332e362d626c75652e737667\"></a>\n<a href=\"https://choosealicense.com/licenses/mit/\" rel=\"nofollow\"><img alt=\"MIT license\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4150014b4dfdd7b565fa18de88e9bb1b8ccd7c08/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d626c75652e737667\"></a>\n<a href=\"https://travis-ci.com/ksangeeta2429/edgel3\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8dcd8adece1f352c4a6d7f029666d5597bee06a4/68747470733a2f2f7472617669732d63692e636f6d2f6b73616e6765657461323432392f656467656c332e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://coveralls.io/github/ksangeeta2429/edgel3?branch=master\" rel=\"nofollow\"><img alt=\"Coverage Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9c5712f80b9990ea4ac479bf947944cb2362fa19/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f6b73616e6765657461323432392f656467656c332f62616467652e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://edgel3.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a4d2064cd180a8383d99cca769e9b14f41343b55/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f656467656c332f62616467652f3f76657273696f6e3d6c6174657374\"></a></p>\n<p>Look, Listen, and Learn (L3) [3],  a  recently  proposed  state-of-the-art  transfer learning technique, helps to train self-supervised deep audio embedding through binary Audio-Visual Correspondence. This embedding can be used to train a variety of downstream audio classification tasks which has limited data. However, with close to 4.7 million parameters, L3-Net is 18 MB in size making it infeasible for small edge devices, such as 'motes' that use a single microcontroller and limited memory to achieve long-lived self-powered operation.</p>\n<p>In <a href=\"https://github.com/ksangeeta2429/Publications/raw/master/EdgeL3_Compressing_L3_Net_for_Mote_Scale.pdf\" rel=\"nofollow\">EdgeL3</a> [1], we comprehensively explore the feasibility of compressing the L3-Net for mote-scale inference. We used pruning, ablation, and knowledge distillation techniques to show that the originally proposed L3-Net architecture is substantially overparameterized, not  only for AVC but for the target task of sound classification as evaluated on two popular downstream datasets, US8K and ESC50. EdgeL3, a 95.45% sparsified version of L3-Net, provides a useful reference model for approximating L3 audio embedding for transfer learning.</p>\n<p><code>edgel3</code> is an open-source Python library for downloading the sparsified L3 models and computing deep audio embeddings from such models. The sparse audio embedding models provided have been re-trained using two different mechanisms as described in the <a href=\"https://github.com/ksangeeta2429/Publications/raw/master/EdgeL3_Compressing_L3_Net_for_Mote_Scale.pdf\" rel=\"nofollow\">paper</a>. The code for the model and training implementation can be found <a href=\"https://github.com/ksangeeta2429/l3embedding/tree/dcompression\" rel=\"nofollow\">here</a></p>\n<p>Download the original L3 model used by EdgeL3 as baseline <a href=\"https://github.com/ksangeeta2429/l3embedding/raw/dcompression/models/cnn_l3_melspec2_recent/model_best_valid_accuracy.h5\" rel=\"nofollow\">here</a>. For non-sparse models and embedding, please refer to <a href=\"https://github.com/marl/openl3\" rel=\"nofollow\">OpenL3</a> [2]</p>\n<h1>Installing EdgeL3</h1>\n<h2>Dependencies</h2>\n<h4>Tensorflow</h4>\n<p>Install Tensorflow (CPU-only/GPU) variant that best fits your usecase.</p>\n<p>On most platforms, either of the following commands should properly install Tensorflow:</p>\n<pre><code>pip install tensorflow # CPU-only version\npip install tensorflow-gpu # GPU version\n</code></pre>\n<p>For more detailed information, please consult the\n<a href=\"https://www.tensorflow.org/install/\" rel=\"nofollow\">Tensorflow installation documentation</a>.</p>\n<h4>libsndfile</h4>\n<p>EdgeL3 depends on the <code>pysoundfile</code> module to load audio files, which depends on the non-Python library <code>libsndfile</code>. On Windows and macOS, these will be installed via <code>pip</code> and you can therefore skip this step.\nHowever, on Linux this must be installed manually via your platform's package manager.\nFor Debian-based distributions (such as Ubuntu), this can be done by simply running</p>\n<pre><code>apt-get install libsndfile1\n</code></pre>\n<p>For more detailed information, please consult the\n<a href=\"https://pysoundfile.readthedocs.io/en/0.9.0/#installation%3E\" rel=\"nofollow\"><code>pysoundfile</code> installation documentation</a>.</p>\n<h2>Installing EdgeL3</h2>\n<p>The simplest way to install EdgeL3 is by using <code>pip</code>, which will also install the additional required dependencies\nif needed. To install EdgeL3 using <code>pip</code>, simply run</p>\n<pre><code>pip install edgel3\n</code></pre>\n<p>To install the latest version of EdgeL3 from source:</p>\n<ol>\n<li>\n<p>Clone or pull the lastest version:</p>\n<pre><code> git clone https://github.com/ksangeeta2429/edgel3.git\n</code></pre>\n</li>\n<li>\n<p>Install using pip to handle python dependencies:\ncd edgel3\npip install -e .</p>\n</li>\n</ol>\n<h1>Using EdgeL3</h1>\n<p>To help you get started with EdgeL3 please see the <a href=\"https://edgel3.readthedocs.io/en/latest/tutorial.html\" rel=\"nofollow\">tutorial</a> and <a href=\"https://edgel3.readthedocs.io/en/latest/edgel3.html\" rel=\"nofollow\">module usage</a>.</p>\n<h1>References</h1>\n<p>Please cite the following papers when using EdgeL3 in your work:</p>\n<p>[1] <strong><a href=\"https://github.com/ksangeeta2429/Publications/raw/master/EdgeL3_Compressing_L3_Net_for_Mote_Scale.pdf\" rel=\"nofollow\">EdgeL3: Compressing L3-Net for Mote-Scale Urban Noise Monitoring</a></strong> <br>\nSangeeta Kumari, Dhrubojyoti Roy, Mark Cartwright, Juan Pablo Bello, and Anish Arora. <br>\nParallel AI and Systems for the Edge (PAISE), Rio de Janeiro, Brazil, May 2019.</p>\n<p>[2] <strong>Look, Listen and Learn More: Design Choices for Deep Audio Embeddings</strong> <br>\nJason Cramer, Ho-Hsiang Wu, Justin Salamon, and Juan Pablo Bello.<br>\nIEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP), pages 3852\u20133856, Brighton, UK, May 2019.</p>\n<p>[3] <strong>Look, Listen and Learn</strong><br>\nRelja Arandjelovi\u0107 and Andrew Zisserman<br>\nIEEE International Conference on Computer Vision (ICCV), Venice, Italy, Oct. 2017.</p>\n\n          </div>"}, "last_serial": 5278396, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "cd4177c0d7498e95e4090c06263e2c26", "sha256": "d78209d5372ca64b20ba15d200df829cf75d6c1b910463c2bc9726e8dd56f804"}, "downloads": -1, "filename": "edgel3-0.1.0.tar.gz", "has_sig": false, "md5_digest": "cd4177c0d7498e95e4090c06263e2c26", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17932, "upload_time": "2019-05-16T16:43:32", "upload_time_iso_8601": "2019-05-16T16:43:32.399274Z", "url": "https://files.pythonhosted.org/packages/a9/5a/d85ac4b72754a79b4e294d676cd2acc631320dcf419a178391135a3004cd/edgel3-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "cd4177c0d7498e95e4090c06263e2c26", "sha256": "d78209d5372ca64b20ba15d200df829cf75d6c1b910463c2bc9726e8dd56f804"}, "downloads": -1, "filename": "edgel3-0.1.0.tar.gz", "has_sig": false, "md5_digest": "cd4177c0d7498e95e4090c06263e2c26", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17932, "upload_time": "2019-05-16T16:43:32", "upload_time_iso_8601": "2019-05-16T16:43:32.399274Z", "url": "https://files.pythonhosted.org/packages/a9/5a/d85ac4b72754a79b4e294d676cd2acc631320dcf419a178391135a3004cd/edgel3-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:47:46 2020"}