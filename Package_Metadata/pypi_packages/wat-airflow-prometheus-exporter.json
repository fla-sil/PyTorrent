{"info": {"author": "Robinhood Markets, Inc.", "author_email": "open-source@robinhood.com", "bugtrack_url": null, "classifiers": ["Intended Audience :: Developers", "License :: OSI Approved :: BSD License", "Natural Language :: English", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3 :: Only"], "description": "# Airflow Prometheus Exporter\n\n[![Build Status](https://travis-ci.org/robinhood/airflow-prometheus-exporter.svg?branch=master)](https://travis-ci.org/robinhood/airflow-prometheus-exporter)\n\nThe Airflow Prometheus Exporter exposes various metrics about the Scheduler, DAGs and Tasks which helps improve the observability of an Airflow cluster.\n\nThe exporter is based on this [prometheus exporter for Airflow](https://github.com/epoch8/airflow-exporter).\n\n## Requirements\n\nThe plugin has been tested with:\n\n- Airflow >= 1.10.4\n- Python 3.6+\n\nThe scheduler metrics assume that there is a DAG named `canary_dag`. In our setup, the `canary_dag` is a DAG which has a tasks which perform very simple actions such as establishing database connections. This DAG is used to test the uptime of the Airflow scheduler itself.\n\n## Installation\n\nThe exporter can be installed as an Airflow Plugin using:\n\n```pip install airflow-prometheus-exporter```\n\nThis should ideally be installed in your Airflow virtualenv.\n\n## Metrics\n\nMetrics will be available at\n\n`http://<your_airflow_host_and_port>/admin/metrics/`\n\n### Task Specific Metrics\n\n#### `airflow_task_status`\n\nNumber of tasks with a specific status.\n\nAll the possible states are listed [here](https://github.com/apache/airflow/blob/master/airflow/utils/state.py#L46).\n\n#### `airflow_task_duration`\n\nDuration of successful tasks in seconds.\n\n#### `airflow_task_fail_count`\n\nNumber of times a particular task has failed.\n\n#### `airflow_xcom_param`\n\nvalue of configurable parameter in xcom table\n\nxcom fields is deserialized as a dictionary and if key is found for a paticular task-id, the value is reported as a guage\n\nAdd task / key combinations in config.yaml:\n\n```bash\nxcom_params:\n  -\n    task_id: abc\n    key: count\n  -\n    task_id: def\n    key: errors\n\n```\n\n\na task_id of 'all' will match against all airflow tasks:\n\n```\nxcom_params:\n -\n    task_id: all\n    key: count\n```\n\n\n\n### Dag Specific Metrics\n\n#### `airflow_dag_status`\n\nNumber of DAGs with a specific status.\n\nAll the possible states are listed [here](https://github.com/apache/airflow/blob/master/airflow/utils/state.py#L59)\n\n#### `airflow_dag_run_duration`\nDuration of successful DagRun in seconds.\n\n### Scheduler Metrics\n\n#### `airflow_dag_scheduler_delay`\n\nScheduling delay for a DAG Run in seconds. This metric assumes there is a `canary_dag`.\n\nThe scheduling delay is measured as the delay between when a DAG is marked as `SCHEDULED` and when it actually starts `RUNNING`.\n\n#### `airflow_task_scheduler_delay`\n\nScheduling delay for a Task in seconds. This metric assumes there is a `canary_dag`.\n\n#### `airflow_num_queued_tasks`\n\nNumber of tasks in the `QUEUED` state at any given instance.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/fazzani/airflow_prometheus_exporter", "keywords": "airflow_prometheus_exporter", "license": "BSD 3-Clause", "maintainer": "", "maintainer_email": "", "name": "wat-airflow-prometheus-exporter", "package_url": "https://pypi.org/project/wat-airflow-prometheus-exporter/", "platform": "", "project_url": "https://pypi.org/project/wat-airflow-prometheus-exporter/", "project_urls": {"Homepage": "https://github.com/fazzani/airflow_prometheus_exporter"}, "release_url": "https://pypi.org/project/wat-airflow-prometheus-exporter/1.0.8/", "requires_dist": ["apache-airflow (>=1.10.4)", "prometheus-client (>=0.4.2)", "bumpversion ; extra == 'dev'", "tox ; extra == 'dev'", "twine ; extra == 'dev'"], "requires_python": "", "summary": "Prometheus Exporter for Airflow Metrics", "version": "1.0.8", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Airflow Prometheus Exporter</h1>\n<p><a href=\"https://travis-ci.org/robinhood/airflow-prometheus-exporter\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ec155719ea8ef846c247bec3674f95cd902016e0/68747470733a2f2f7472617669732d63692e6f72672f726f62696e686f6f642f616972666c6f772d70726f6d6574686575732d6578706f727465722e7376673f6272616e63683d6d6173746572\"></a></p>\n<p>The Airflow Prometheus Exporter exposes various metrics about the Scheduler, DAGs and Tasks which helps improve the observability of an Airflow cluster.</p>\n<p>The exporter is based on this <a href=\"https://github.com/epoch8/airflow-exporter\" rel=\"nofollow\">prometheus exporter for Airflow</a>.</p>\n<h2>Requirements</h2>\n<p>The plugin has been tested with:</p>\n<ul>\n<li>Airflow &gt;= 1.10.4</li>\n<li>Python 3.6+</li>\n</ul>\n<p>The scheduler metrics assume that there is a DAG named <code>canary_dag</code>. In our setup, the <code>canary_dag</code> is a DAG which has a tasks which perform very simple actions such as establishing database connections. This DAG is used to test the uptime of the Airflow scheduler itself.</p>\n<h2>Installation</h2>\n<p>The exporter can be installed as an Airflow Plugin using:</p>\n<p><code>pip install airflow-prometheus-exporter</code></p>\n<p>This should ideally be installed in your Airflow virtualenv.</p>\n<h2>Metrics</h2>\n<p>Metrics will be available at</p>\n<p><code>http://&lt;your_airflow_host_and_port&gt;/admin/metrics/</code></p>\n<h3>Task Specific Metrics</h3>\n<h4><code>airflow_task_status</code></h4>\n<p>Number of tasks with a specific status.</p>\n<p>All the possible states are listed <a href=\"https://github.com/apache/airflow/blob/master/airflow/utils/state.py#L46\" rel=\"nofollow\">here</a>.</p>\n<h4><code>airflow_task_duration</code></h4>\n<p>Duration of successful tasks in seconds.</p>\n<h4><code>airflow_task_fail_count</code></h4>\n<p>Number of times a particular task has failed.</p>\n<h4><code>airflow_xcom_param</code></h4>\n<p>value of configurable parameter in xcom table</p>\n<p>xcom fields is deserialized as a dictionary and if key is found for a paticular task-id, the value is reported as a guage</p>\n<p>Add task / key combinations in config.yaml:</p>\n<pre>xcom_params:\n  -\n    task_id: abc\n    key: count\n  -\n    task_id: def\n    key: errors\n</pre>\n<p>a task_id of 'all' will match against all airflow tasks:</p>\n<pre><code>xcom_params:\n -\n    task_id: all\n    key: count\n</code></pre>\n<h3>Dag Specific Metrics</h3>\n<h4><code>airflow_dag_status</code></h4>\n<p>Number of DAGs with a specific status.</p>\n<p>All the possible states are listed <a href=\"https://github.com/apache/airflow/blob/master/airflow/utils/state.py#L59\" rel=\"nofollow\">here</a></p>\n<h4><code>airflow_dag_run_duration</code></h4>\n<p>Duration of successful DagRun in seconds.</p>\n<h3>Scheduler Metrics</h3>\n<h4><code>airflow_dag_scheduler_delay</code></h4>\n<p>Scheduling delay for a DAG Run in seconds. This metric assumes there is a <code>canary_dag</code>.</p>\n<p>The scheduling delay is measured as the delay between when a DAG is marked as <code>SCHEDULED</code> and when it actually starts <code>RUNNING</code>.</p>\n<h4><code>airflow_task_scheduler_delay</code></h4>\n<p>Scheduling delay for a Task in seconds. This metric assumes there is a <code>canary_dag</code>.</p>\n<h4><code>airflow_num_queued_tasks</code></h4>\n<p>Number of tasks in the <code>QUEUED</code> state at any given instance.</p>\n\n          </div>"}, "last_serial": 6619746, "releases": {"1.0.8": [{"comment_text": "", "digests": {"md5": "c869201b7c29629f55d622818a7b9860", "sha256": "d2b71bdb1d6da8f64eb0570dfc667fab950f5dc827cfa4954589517f3598ed1e"}, "downloads": -1, "filename": "wat_airflow_prometheus_exporter-1.0.8-py3-none-any.whl", "has_sig": false, "md5_digest": "c869201b7c29629f55d622818a7b9860", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 8880, "upload_time": "2020-02-12T22:54:01", "upload_time_iso_8601": "2020-02-12T22:54:01.730685Z", "url": "https://files.pythonhosted.org/packages/ec/7b/886ce20559ccd80cbd1548a5358ffcb3f278cc330d4f3c9f736b78262aaf/wat_airflow_prometheus_exporter-1.0.8-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e55984b532e3433800fd4ec96523c00f", "sha256": "d5bbb77cf77467d0b58244fc0df3b7e6f3edc57340c5831b66fe5ac0948e7180"}, "downloads": -1, "filename": "wat_airflow_prometheus_exporter-1.0.8.tar.gz", "has_sig": false, "md5_digest": "e55984b532e3433800fd4ec96523c00f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6806, "upload_time": "2020-02-12T22:54:04", "upload_time_iso_8601": "2020-02-12T22:54:04.108360Z", "url": "https://files.pythonhosted.org/packages/21/e6/63536ccdce6e8a543380b733347c6d01ce61ef392c1e8e8a83481fa3b96b/wat_airflow_prometheus_exporter-1.0.8.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "c869201b7c29629f55d622818a7b9860", "sha256": "d2b71bdb1d6da8f64eb0570dfc667fab950f5dc827cfa4954589517f3598ed1e"}, "downloads": -1, "filename": "wat_airflow_prometheus_exporter-1.0.8-py3-none-any.whl", "has_sig": false, "md5_digest": "c869201b7c29629f55d622818a7b9860", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 8880, "upload_time": "2020-02-12T22:54:01", "upload_time_iso_8601": "2020-02-12T22:54:01.730685Z", "url": "https://files.pythonhosted.org/packages/ec/7b/886ce20559ccd80cbd1548a5358ffcb3f278cc330d4f3c9f736b78262aaf/wat_airflow_prometheus_exporter-1.0.8-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e55984b532e3433800fd4ec96523c00f", "sha256": "d5bbb77cf77467d0b58244fc0df3b7e6f3edc57340c5831b66fe5ac0948e7180"}, "downloads": -1, "filename": "wat_airflow_prometheus_exporter-1.0.8.tar.gz", "has_sig": false, "md5_digest": "e55984b532e3433800fd4ec96523c00f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6806, "upload_time": "2020-02-12T22:54:04", "upload_time_iso_8601": "2020-02-12T22:54:04.108360Z", "url": "https://files.pythonhosted.org/packages/21/e6/63536ccdce6e8a543380b733347c6d01ce61ef392c1e8e8a83481fa3b96b/wat_airflow_prometheus_exporter-1.0.8.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:32:15 2020"}