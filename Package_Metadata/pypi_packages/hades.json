{"info": {"author": "Miljan Karadzic", "author_email": "miljank _at_ gmail.com", "bugtrack_url": null, "classifiers": ["Intended Audience :: Developers", "Operating System :: POSIX :: Linux", "Operating System :: Unix", "Programming Language :: Python", "Programming Language :: Python :: 2.7", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "======\nHades\n======\n\nHades is an multithreaded asynchronous job processing class. It allows you to register different job types and associate processor functions or classes with those job types.\n\nJob processor function needs to expect job data as input. If a job processor is a class, it needs to have run() method that expects job data as input.\n\nJobs are discovered by watching a folder on the file system for new files. If a file is correctly formated it is parsed and processed passing the parsed data to the registered processor.\n\nA file needs to be a json document with a 'type' key matching one of the registered job types.\n\nWhen the class is initialized it expects a path to the folder to watch. The folder needs to have three subfolders: 'in' for incoming jobs, 'cur' for storing successfully processed jobs (this can be disabled by passing save_successful=False to the class), and 'err' for storing failed jobs (this can be disabled by passing save_failed=False to the class).\n\nBy default a pool of 5 processing threads will be started. This can be tuned by passing threads=N to the class.\n\nIf a job processing fails, it will be reprocessed few more times as defined by retries attribute (default is 3). If this is not desired it can be disabled by passing retries=0 to the class.\n\n*******\nUsage\n*******\n\nThe usage is very simple. You need to define processors, initialize Hades with the path to the folder to watch, register processors with Hades and call start() method to start all the threads. By default Hades runs in interactive mode. If you want to run it in a daemon mode, just pass 'daemon=True' to the start() method.\n\n::\n\n    import hades\n\n    class Download:\n        def run(self, task):\n            print(\"Downloading page: {0}\".format(task['url']))\n            return True\n\n    def send_email(task):\n        print(\"Email for: {0}\".format(task['rcpt']))\n        return True\n\n    if __name__ == '__main__':\n        hades = hades.Hades('/tmp/jobs')\n        hades.register({'email':    send_email})\n        hades.register({'download': Download})\n        hades.start(daemon=True)\n\nTo send jobs, just deserialize a json object containing the data for your jobs and save them into the defined folder. Hades will pick it up from there.\n\n::\n\n    import json\n\n    email = {'type':    'email',\n             'from':    'no@mail.com',\n             'rcpt':    'test@example.com',\n             'subject': 'Test email',\n             'body':    'Hi there!'}\n\n    download = {'type': 'download',\n                'url':  'http://www.miljan.org/',\n                'file': '/tmp/miljan.org.html'}\n\n    json.dump(email, open(\"/tmp/jobs/in/email\", \"w\"))\n    json.dump(download, open(\"/tmp/jobs/in/download\", \"w\"))", "description_content_type": null, "docs_url": null, "download_url": "http://pypi.python.org/pypi/hades", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/miljank/hades", "keywords": "asynchronous,job,processing,json,tasks", "license": "GPLv2", "maintainer": null, "maintainer_email": null, "name": "hades", "package_url": "https://pypi.org/project/hades/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/hades/", "project_urls": {"Download": "http://pypi.python.org/pypi/hades", "Homepage": "https://github.com/miljank/hades"}, "release_url": "https://pypi.org/project/hades/0.2.0/", "requires_dist": null, "requires_python": null, "summary": "A daemon for asynchronous job processing", "version": "0.2.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>Hades is an multithreaded asynchronous job processing class. It allows you to register different job types and associate processor functions or classes with those job types.</p>\n<p>Job processor function needs to expect job data as input. If a job processor is a class, it needs to have run() method that expects job data as input.</p>\n<p>Jobs are discovered by watching a folder on the file system for new files. If a file is correctly formated it is parsed and processed passing the parsed data to the registered processor.</p>\n<p>A file needs to be a json document with a \u2018type\u2019 key matching one of the registered job types.</p>\n<p>When the class is initialized it expects a path to the folder to watch. The folder needs to have three subfolders: \u2018in\u2019 for incoming jobs, \u2018cur\u2019 for storing successfully processed jobs (this can be disabled by passing save_successful=False to the class), and \u2018err\u2019 for storing failed jobs (this can be disabled by passing save_failed=False to the class).</p>\n<p>By default a pool of 5 processing threads will be started. This can be tuned by passing threads=N to the class.</p>\n<p>If a job processing fails, it will be reprocessed few more times as defined by retries attribute (default is 3). If this is not desired it can be disabled by passing retries=0 to the class.</p>\n<div id=\"usage\">\n<h2>Usage</h2>\n<p>The usage is very simple. You need to define processors, initialize Hades with the path to the folder to watch, register processors with Hades and call start() method to start all the threads. By default Hades runs in interactive mode. If you want to run it in a daemon mode, just pass \u2018daemon=True\u2019 to the start() method.</p>\n<pre>import hades\n\nclass Download:\n    def run(self, task):\n        print(\"Downloading page: {0}\".format(task['url']))\n        return True\n\ndef send_email(task):\n    print(\"Email for: {0}\".format(task['rcpt']))\n    return True\n\nif __name__ == '__main__':\n    hades = hades.Hades('/tmp/jobs')\n    hades.register({'email':    send_email})\n    hades.register({'download': Download})\n    hades.start(daemon=True)\n</pre>\n<p>To send jobs, just deserialize a json object containing the data for your jobs and save them into the defined folder. Hades will pick it up from there.</p>\n<pre>import json\n\nemail = {'type':    'email',\n         'from':    'no@mail.com',\n         'rcpt':    'test@example.com',\n         'subject': 'Test email',\n         'body':    'Hi there!'}\n\ndownload = {'type': 'download',\n            'url':  'http://www.miljan.org/',\n            'file': '/tmp/miljan.org.html'}\n\njson.dump(email, open(\"/tmp/jobs/in/email\", \"w\"))\njson.dump(download, open(\"/tmp/jobs/in/download\", \"w\"))\n</pre>\n</div>\n\n          </div>"}, "last_serial": 706475, "releases": {"0.2.0": [{"comment_text": "", "digests": {"md5": "10233ee1947fb887eda8e0cfa870f457", "sha256": "422dc00a1691fdc263784688b3060a768ef14f4382f1647b88403cdee2946406"}, "downloads": -1, "filename": "hades-0.2.0.tar.gz", "has_sig": false, "md5_digest": "10233ee1947fb887eda8e0cfa870f457", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4458, "upload_time": "2013-05-26T11:07:37", "upload_time_iso_8601": "2013-05-26T11:07:37.043144Z", "url": "https://files.pythonhosted.org/packages/f2/72/dc3dfa52e9c933c4dc95017978d8281d2b132d5a2d4a9f685ce742a70ec9/hades-0.2.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "10233ee1947fb887eda8e0cfa870f457", "sha256": "422dc00a1691fdc263784688b3060a768ef14f4382f1647b88403cdee2946406"}, "downloads": -1, "filename": "hades-0.2.0.tar.gz", "has_sig": false, "md5_digest": "10233ee1947fb887eda8e0cfa870f457", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4458, "upload_time": "2013-05-26T11:07:37", "upload_time_iso_8601": "2013-05-26T11:07:37.043144Z", "url": "https://files.pythonhosted.org/packages/f2/72/dc3dfa52e9c933c4dc95017978d8281d2b132d5a2d4a9f685ce742a70ec9/hades-0.2.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:52:47 2020"}