{"info": {"author": "Patrick Chirdon", "author_email": "pc419714@ohio.edu", "bugtrack_url": null, "classifiers": ["Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "Tutorial\nTarget Prediction\nSupport Vector Machine\n46 models. Metrics for test data:\naccuracy 97.59 +/- 2.41\nsensitivity 91.9 +/- 8.1\nspecificity 98.6 +/- 1.4\n215/247 87% correct mechanism on independent test set.\n======================================\nChembl Target Prediction\nMulticlass Classifier\nNumber of unique targets 560\nIon channel 5\nkinase 96\nnuclear receptor 21\nGPCR 180\nOthers 258\naccuracy .87\nauc .92\nsensitivity .76\nspecificity .92\nprecision .82\n225/225 100% correct mechanism on independent test set. Note-- 1 is considered positive and zero is negative for a given target.\n======================================\nInterpreting output:  For the target predictions, the green represents a positive region for the molecule, the red represents a negative region of the molecule for a tested property, and gray represents no detection. For more on this method please read Similarity maps-- a visualization strategy for molecular fingerprints and machine learning methods.\n======================================\nInside the target prediction folder, there should be .png images for each of the smiles in the output folder. Make sure to change the directory to the output directory of the targetprediction folder under the images menu. Since there are 46 models it is best to only use a few smiles at a time.\n======================================\nCreating your own models:  https://pubchem.ncbi.nlm.nih.gov/#query=interferon&tab=assay, Also see chembl bioassays. These assays must be saved as .txt files with two columns-- the first for the smiles and the next column for either 1 or zero (active and inactive respectively).  The text file with the smiles and 1's and 0's should be in the targetprediction folder.  The text file names should contain the name of the assay.  You want a model with both good sensitivity and specificity (as close to one as possible).  It is important to note that a model can appear highly accurate but if sensitivity is zero, then the model does not detect positives.\n======================================\nconfusion matrix\ntn fp\nfn tp\nIt is important to note that column 1, row 1 is NOT true positive as you might expect from stats class.  Sensitive models will not have 0 in the bottom right corner.  If you are not getting good sensitivity and specificity, then you may want to change the penalty C=500000 to some other value.  By default the SVC is set up to use a RBF best fit but this can be changed as per the scikit learn documentation.  The output files will be saved as .pkl files that can later be loaded for future use.\n======================================\nPan Assay Interference\nSee Seven Year Itch: Pan-Assay Interference Compounds (PAINS) in 2017\u2014Utility and Limitations New Substructure Filters for Removal of Pan Assay Interference Compounds (PAINS) from Screening Libraries and for Their Exclusion in Bioassays. Pan Assay Interference Compounds commonly result in false positives in biological screening assays.\nSince they bind everything, they are not selective and therefore do not make good drug targets.  We found that the higher the drug score in Data Warrior http://www.openmolecules.org/datawarrior/ the lower the frequency of compounds containing PAINS.  Using data warrior\u2019s evolutionary algorithm (be sure to use the wand tool if you want to fix the scaffold), evolve a few runs by taking the compounds with the top drug scores (macro \u2192 run macro \u2192 calculate properties) by taking the top 5 scoring compounds as starting points for evolution until you get drug scores greater than .9.  Select based on skelsphere similarity and the algorithm will generate a large number of compounds that have high drug scores, which are oftentimes painless.\nThe program will tell you what functional groups for each compound were responsible for a positive PAINFUL test result.  The program also tells you the fraction of SP3 hybridized carbons.  Compounds with scores > .47 are more selective binders.  Note that double bonds reduce the fraction of sp3 hybridization, as they make the compound more flat.  See Escape from flatland: increasing saturation as an approach to improving clinical success. Pains are defined as follows:\nDoveston R, et al. A Unified Lead-oriented Synthesis of over Fifty Molecular Scaffolds. Org Biomol Chem 13 (2014) 859D65. doi:10.1039/C4OB02287D\nJadhav A, et al, Quantitative Analyses of Aggregation, Autofluorescence, and Reactivity Artifacts in a Screen for Inhibitors of Thiol Protease.  J Med Chem 53 (2009) 37D51. doi:10.1021/jm901070c\n======================================\nFragmenter\nInput a list of smiles.  These will be recombined into new combinations.  When you take the lowest energy ligands from a docking program and recombine these there may be some compounds that bind with lower energy than the original.\n======================================\nMake Spreadsheet\nInput smiles.  The output will be a spreadsheet called test.xlsx in the target prediction folder that contains images of the molecules.\n======================================\nSolubility\nPredicts log S.  Log S greater than -4 is soluble.\nRoot mean square error of 1.27 on a scale from -4 to 4.\nlinear regression\n======================================\nBuild a SAR model\ncross entropy- default loss function for binary classification problems. Summarizes the average difference between the actual and predicted probability.\nhinge- alternative to cross entropy binary classification developed with SVM models used with support vector machine models\nmse-default loss to use for regression problems. calculated as the average of the squared differences between the predicted and actual values\nmae-for regression problems.  used in cases where there are outliers. average of the absolute difference between actual and predicted values\n\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "bmetoolkit", "package_url": "https://pypi.org/project/bmetoolkit/", "platform": "", "project_url": "https://pypi.org/project/bmetoolkit/", "project_urls": null, "release_url": "https://pypi.org/project/bmetoolkit/1/", "requires_dist": null, "requires_python": "", "summary": "chemoinformatics toolkit", "version": "1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Tutorial\nTarget Prediction\nSupport Vector Machine\n46 models. Metrics for test data:\naccuracy 97.59 +/- 2.41\nsensitivity 91.9 +/- 8.1\nspecificity 98.6 +/- 1.4\n215/247 87% correct mechanism on independent test set.</h1>\n<h1>Chembl Target Prediction\nMulticlass Classifier\nNumber of unique targets 560\nIon channel 5\nkinase 96\nnuclear receptor 21\nGPCR 180\nOthers 258\naccuracy .87\nauc .92\nsensitivity .76\nspecificity .92\nprecision .82\n225/225 100% correct mechanism on independent test set. Note-- 1 is considered positive and zero is negative for a given target.</h1>\n<h1>Interpreting output:  For the target predictions, the green represents a positive region for the molecule, the red represents a negative region of the molecule for a tested property, and gray represents no detection. For more on this method please read Similarity maps-- a visualization strategy for molecular fingerprints and machine learning methods.</h1>\n<h1>Inside the target prediction folder, there should be .png images for each of the smiles in the output folder. Make sure to change the directory to the output directory of the targetprediction folder under the images menu. Since there are 46 models it is best to only use a few smiles at a time.</h1>\n<h1>Creating your own models:  <a href=\"https://pubchem.ncbi.nlm.nih.gov/#query=interferon&amp;tab=assay\" rel=\"nofollow\">https://pubchem.ncbi.nlm.nih.gov/#query=interferon&amp;tab=assay</a>, Also see chembl bioassays. These assays must be saved as .txt files with two columns-- the first for the smiles and the next column for either 1 or zero (active and inactive respectively).  The text file with the smiles and 1's and 0's should be in the targetprediction folder.  The text file names should contain the name of the assay.  You want a model with both good sensitivity and specificity (as close to one as possible).  It is important to note that a model can appear highly accurate but if sensitivity is zero, then the model does not detect positives.</h1>\n<h1>confusion matrix\ntn fp\nfn tp\nIt is important to note that column 1, row 1 is NOT true positive as you might expect from stats class.  Sensitive models will not have 0 in the bottom right corner.  If you are not getting good sensitivity and specificity, then you may want to change the penalty C=500000 to some other value.  By default the SVC is set up to use a RBF best fit but this can be changed as per the scikit learn documentation.  The output files will be saved as .pkl files that can later be loaded for future use.</h1>\n<h1>Pan Assay Interference\nSee Seven Year Itch: Pan-Assay Interference Compounds (PAINS) in 2017\u2014Utility and Limitations New Substructure Filters for Removal of Pan Assay Interference Compounds (PAINS) from Screening Libraries and for Their Exclusion in Bioassays. Pan Assay Interference Compounds commonly result in false positives in biological screening assays.\nSince they bind everything, they are not selective and therefore do not make good drug targets.  We found that the higher the drug score in Data Warrior <a href=\"http://www.openmolecules.org/datawarrior/\" rel=\"nofollow\">http://www.openmolecules.org/datawarrior/</a> the lower the frequency of compounds containing PAINS.  Using data warrior\u2019s evolutionary algorithm (be sure to use the wand tool if you want to fix the scaffold), evolve a few runs by taking the compounds with the top drug scores (macro \u2192 run macro \u2192 calculate properties) by taking the top 5 scoring compounds as starting points for evolution until you get drug scores greater than .9.  Select based on skelsphere similarity and the algorithm will generate a large number of compounds that have high drug scores, which are oftentimes painless.\nThe program will tell you what functional groups for each compound were responsible for a positive PAINFUL test result.  The program also tells you the fraction of SP3 hybridized carbons.  Compounds with scores &gt; .47 are more selective binders.  Note that double bonds reduce the fraction of sp3 hybridization, as they make the compound more flat.  See Escape from flatland: increasing saturation as an approach to improving clinical success. Pains are defined as follows:\nDoveston R, et al. A Unified Lead-oriented Synthesis of over Fifty Molecular Scaffolds. Org Biomol Chem 13 (2014) 859D65. doi:10.1039/C4OB02287D\nJadhav A, et al, Quantitative Analyses of Aggregation, Autofluorescence, and Reactivity Artifacts in a Screen for Inhibitors of Thiol Protease.  J Med Chem 53 (2009) 37D51. doi:10.1021/jm901070c</h1>\n<h1>Fragmenter\nInput a list of smiles.  These will be recombined into new combinations.  When you take the lowest energy ligands from a docking program and recombine these there may be some compounds that bind with lower energy than the original.</h1>\n<h1>Make Spreadsheet\nInput smiles.  The output will be a spreadsheet called test.xlsx in the target prediction folder that contains images of the molecules.</h1>\n<h1>Solubility\nPredicts log S.  Log S greater than -4 is soluble.\nRoot mean square error of 1.27 on a scale from -4 to 4.\nlinear regression</h1>\n<p>Build a SAR model\ncross entropy- default loss function for binary classification problems. Summarizes the average difference between the actual and predicted probability.\nhinge- alternative to cross entropy binary classification developed with SVM models used with support vector machine models\nmse-default loss to use for regression problems. calculated as the average of the squared differences between the predicted and actual values\nmae-for regression problems.  used in cases where there are outliers. average of the absolute difference between actual and predicted values</p>\n\n          </div>"}, "last_serial": 5615662, "releases": {"1": [{"comment_text": "", "digests": {"md5": "b23cae1c717ba85bb463ebce0b217c78", "sha256": "279f00abefb4008fca5f6f6877c61fcb2426e2ce9c7d230fb18f76ec21711960"}, "downloads": -1, "filename": "bmetoolkit-2-py3-none-any.whl", "has_sig": false, "md5_digest": "b23cae1c717ba85bb463ebce0b217c78", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10337, "upload_time": "2019-07-31T21:17:17", "upload_time_iso_8601": "2019-07-31T21:17:17.150964Z", "url": "https://files.pythonhosted.org/packages/81/90/ed3da881e27c0557f7c8a4166601e5f359ac9d9b72528d336a60ebae0a76/bmetoolkit-2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "27e818eff5615545bd7579fdaf437edc", "sha256": "43f684138e297dca860811b1334803cd4cac72a52f139ca5d0f6710820410640"}, "downloads": -1, "filename": "bmetoolkit-2.tar.gz", "has_sig": false, "md5_digest": "27e818eff5615545bd7579fdaf437edc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8016, "upload_time": "2019-07-31T21:17:19", "upload_time_iso_8601": "2019-07-31T21:17:19.822152Z", "url": "https://files.pythonhosted.org/packages/53/66/0165d3f2727610b538687fe31b5c3346b62948da28f6fc018f5b2c8f2590/bmetoolkit-2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "b23cae1c717ba85bb463ebce0b217c78", "sha256": "279f00abefb4008fca5f6f6877c61fcb2426e2ce9c7d230fb18f76ec21711960"}, "downloads": -1, "filename": "bmetoolkit-2-py3-none-any.whl", "has_sig": false, "md5_digest": "b23cae1c717ba85bb463ebce0b217c78", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10337, "upload_time": "2019-07-31T21:17:17", "upload_time_iso_8601": "2019-07-31T21:17:17.150964Z", "url": "https://files.pythonhosted.org/packages/81/90/ed3da881e27c0557f7c8a4166601e5f359ac9d9b72528d336a60ebae0a76/bmetoolkit-2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "27e818eff5615545bd7579fdaf437edc", "sha256": "43f684138e297dca860811b1334803cd4cac72a52f139ca5d0f6710820410640"}, "downloads": -1, "filename": "bmetoolkit-2.tar.gz", "has_sig": false, "md5_digest": "27e818eff5615545bd7579fdaf437edc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8016, "upload_time": "2019-07-31T21:17:19", "upload_time_iso_8601": "2019-07-31T21:17:19.822152Z", "url": "https://files.pythonhosted.org/packages/53/66/0165d3f2727610b538687fe31b5c3346b62948da28f6fc018f5b2c8f2590/bmetoolkit-2.tar.gz", "yanked": false}], "timestamp": "Thu May  7 22:36:56 2020"}