{"info": {"author": "Jan Kalkan", "author_email": "jan.kalkan@mailbox.org", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved :: Apache Software License", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "\n<h1 align=\"center\">\n    \ud83c\udf9b lazycluster\n    <br>\n</h1>\n\n<p align=\"center\">\n    <strong>Distributed machine learning made simple.</strong><br/>\n    Use your preferred distributed ML framework like a <a href=\"https://youtu.be/UXSSJENiZiw\">lazy engineer</a>.\n</p>\n\n<p align=\"center\">\n    <a href=\"https://github.com/ml-tooling/lazycluster/blob/master/LICENSE\" title=\"ML Hub License\"><img src=\"https://img.shields.io/badge/License-Apache%202.0-green.svg\"></a>\n    <a href=\"https://gitter.im/ml-tooling/lazycluster\" title=\"Chat on Gitter\"><img src=\"https://badges.gitter.im/ml-tooling/lazycluster.svg\"></a>\n    <a href=\"https://twitter.com/mltooling\" title=\"ML Tooling on Twitter\"><img src=\"https://img.shields.io/twitter/follow/mltooling.svg?style=social\"></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"#getting-started\">Getting Started</a> \u2022\n  <a href=\"#highlights\">Highlights</a> \u2022\n  <a href=\"#features\">Features</a> \u2022\n  <a href=\"./docs\">API Docs</a> \u2022\n  <a href=\"#support\">Support</a> \u2022\n  <a href=\"https://github.com/ml-tooling/ml-workspace/issues/new?labels=bug&template=01_bug-report.md\">Report a Bug</a> \u2022\n  <a href=\"#contribution\">Contribution</a>\n</p>\n\n**lazycluster** is a Python library intended to liberate data scientists and machine learning engineers by abstracting \naway cluster management and configuration so that they are able to focus on their actual tasks. Especially, the easy \nand convenient cluster setup with Python for various distributed machine learning frameworks is emphasized.\n\n## Highlights\n\n- **High-Level API for starting clusters:** \n    - [DASK](https://distributed.dask.org/en/latest/)\n    - [Hyperopt](https://github.com/hyperopt/hyperopt) \n    - *More *lazyclusters* (e.g. Ray, PyTorch, Tensorflow, Horovod, Spark) to come ...*\n- **Lower-level API for:**\n    - Managing [Runtimes](./docs/runtimes.md#runtime-class) or [RuntimeGroups](./docs/runtime_mgmt.md#runtimegroup-class) to:\n        - A-/synchronously execute [RuntimeTasks](./docs/runtimes.md#runtimetask-class) by leveraging the power of ssh\n        - Expose services (e.g. a DB) from or to a `Runtime` or in a whole `RuntimeGroup`\n- **Command line interface (CLI)**\n    - List all available `Runtimes`\n    - Add a `Runtime` configuration\n    - Delete a `Runtime` configuration\n\n<br/>\n\n![API layer](./docs/img/layer-concept.png)\n\n> **Concept Definition:** *[Runtime](./docs/runtimes.md#runtime-class)* <a name=\"runtime\"></a>\n>\n> A `Runtime` is the logical representation of a remote host. Typically, the host is another server or a virtual machine / container on another server. This python class provides several methods for utilizing remote resources such as the port exposure from / to a `Runtime` as well as the execution of [RuntimeTasks](#task). A `Runtime` has a working directory. Usually, the execution of a `RuntimeTask` is conducted relatively to this directory if no other path is explicitly given. The working directory can be manually set during the initialization. Otherwise, a temporary directory gets created that might eventually be removed.\n\n\n> **Concept Definition:** *[RuntimeGroup](./docs/runtimes.md#runtimetask-class)* \n>\n> A `RuntimeGroup` is the representation of logically related `Runtimes` and provides convenient methods for managing those related `Runtimes`. Most methods are wrappers around their counterparts in the `Runtime` class. Typical usage examples are exposing a port (i.e. a service such as a DB) in the `RuntimeGroup`, transfer files, or execute  a `RuntimeTask` on the `Runtimes`. Additionally, all concrete [RuntimeCluster](./docs/cluster.runtime_cluster.md#runtimecluster-class) (e.g. the [HyperoptCluster](./docs/cluster.hyperopt_cluster.md#hyperoptcluster-class)) implementations rely on `RuntimeGroups` for example.\n\n\n> **Concept Definition:** *Manager*<a name=\"manager\"></a>\n>\n> The `manager` refers to the host where you are actually using the lazycluster library, since all desired lazycluster entities are managed from here. **Caution**: It is not to be confused with the [RuntimeManager](./docs/runtime_mgmt.md#runtimemanager-class) class.\n\n> **Concept Definition:** *[RuntimeTask](./docs/runtimes.md#runtimetask-class)* <a name=\"task\"></a>\n>\n> A `RuntimeTask` is a composition of multiple elemantary task steps, namely `send file`, `get file`, `run command` (shell), `run function` (python). A `RuntimeTask` can be executed on a remote host either by handing it over to a `Runtime` object or standalone by handing over a [fabric Connection](http://docs.fabfile.org/en/2.5/api/connection.html) object to the execute method of the `RuntimeTask`. Consequently, all invididual task steps are executed sequentially. Moreover, a `RuntimeTask` object captures the output (stdout/stderr) of the remote execution in its execution log. An example for a `RuntimeTask` could be to send a csv file to a `Runtime`, execute a python function that is transforming the csv file and finally get the file back. \n---\n<br>\n\n## Getting started\n\n### Installation\n```bash\npip install lazycluster\n``` \n```bash\n# Most up-to-date development version\npip install --upgrade git+https://github.com/ml-tooling/lazycluster.git@develop\n``` \n\n### Prerequisites\n\n**For lazycluster usage on the [manager](#manager):**\n- Unix based OS\n- Python >= 3.6\n- ssh client (e.g. openssh-client)\n- Passwordless ssh access to the `Runtime` hosts **(recommended)**\n<a name=\"passwordless-ssh\"></a>\n<details>\n<summary>Configure passwordless ssh access (click to expand...)</summary>\n\n   - Create a key pair on the manager as described [here](https://www.ssh.com/ssh/keygen#creating-an-ssh-key-pair-for-user-authentication) or use an existing one\n    - [Install](#installation) lazycluster on the manager\n    - Create the ssh configuration for each host to be used as Runtime by using the lazycluster CLI command `lazycluster add-runtime` as described [here](#add-host-to-ssh-config) and **do not forget** to specify the `--id-file` argument.\n    - Finally, enable the passwordless ssh access by copying the public key to each Runtime as descibed [here](https://www.ssh.com/ssh/keygen#copying-the-public-key-to-the-server)\n</details>\n<br/>\n\n**[Runtime](#runtime) host requirements:**\n- Unix based OS\n- Python >= 3.6\n- ssh server (e.g. openssh-server)\n\n**Note:**\n\n  Passwordless ssh needs to be setup for the hosts to be used as [Runtimes](./docs/runtimes.md#runtime-class) for the most convenient user experience. Otherwise, you need to pass the connection details to Runtime.\\_\\_init__ via connection_kwargs. These parameters will be passed on to the [fabric.Connection](http://docs.fabfile.org/en/2.4/api/connection.html#connect-kwargs-arg).\n\n### Usage example high-level API\nStart a [Dask](https://distributed.dask.org/en/latest/) cluster.\n```python\nfrom lazycluster import RuntimeManager\nfrom lazycluster.cluster import DaskCluster\n\n# Automatically generate a group based on the ssh configuration\nruntime_manager = RuntimeManager()\nruntime_group = runtime_manager.create_group() \n\n# Start the Dask cluster instances using the RuntimeGroup\ndask_cluster = DaskCluster(runtime_group)\ndask_cluster.start()\n\n# => Now, you can start using the running Dask cluster\n\n# Get Dask client to interact with the cluster\n# Note: This will give you a dask.distributed.Client which is not \n#       a lazycluster cluster but a Dask one instead\nclient = cluster.get_client()\n```  \n\n### Usage example lower-level API\nExecute a Python function on a remote host and access the return data.\n```python\nfrom lazycluster import RuntimeTask, Runtime\n\n# Define a Python function which will be executed remotely\ndef hello(name:str):\n    return 'Hello ' + name + '!'\n\n# Compose a `RuntimeTask`\ntask = RuntimeTask('my-first_task').run_command('echo Hello World!') \\\n                                   .run_function(hello, name='World')\n\n# Actually execute it remotely in a `Runtime`                                   \ntask = Runtime('host-1').execute_task(task, execute_async=False)\n\n# The stdout from from the executing `Runtime` can be accessed \n# via the execution log of the `RuntimeTask`\ntask.print_log()\n\n# Print the return of the `hello()` call\ngenerator = task.function_returns\nprint(next(generator))\n```\n\n---\n\n## Support\n\nThe **lazycluster** project is maintained by [Jan Kalkan](https://www.linkedin.com/in/jan-kalkan-b5390284/). Please \nunderstand that we won't be able to provide individual support via email. We also believe that help is much more\nvaluable if it's shared publicly so that more people can benefit from it.\n\n| Type                     | Channel                                              |\n| ------------------------ | ------------------------------------------------------ |\n| \ud83d\udea8 **Bug Reports**       | <a href=\"https://github.com/ml-tooling/lazycluster/issues?utf8=%E2%9C%93&q=is%3Aopen+is%3Aissue+label%3Abug+sort%3Areactions-%2B1-desc+\" title=\"Open Bug Report\"><img src=\"https://img.shields.io/github/issues/ml-tooling/lazycluster/bug.svg\"></a>                                 |\n| \ud83c\udf81 **Feature Requests**  | <a href=\"https://github.com/ml-tooling/lazycluster/issues?q=is%3Aopen+is%3Aissue+label%3Afeature-request+sort%3Areactions-%2B1-desc\" title=\"Open Feature Request\"><img src=\"https://img.shields.io/github/issues/ml-tooling/lazycluster/feature-request.svg?label=feature%20requests\"></a>                                 |\n| \ud83d\udc69\u200d\ud83d\udcbb **Usage Questions**   |  <a href=\"https://stackoverflow.com/questions/tagged/ml-tooling\" title=\"Open Question on Stackoverflow\"><img src=\"https://img.shields.io/badge/stackoverflow-ml--tooling-orange.svg\"></a> <a href=\"https://gitter.im/ml-tooling/lazycluster\" title=\"Chat on Gitter\"><img src=\"https://badges.gitter.im/ml-tooling/lazycluster.svg\"></a> |\n| \ud83d\uddef **General Discussion** | <a href=\"https://gitter.im/ml-tooling/lazycluster\" title=\"Chat on Gitter\"><img src=\"https://badges.gitter.im/ml-tooling/lazycluster.svg\"></a>  <a href=\"https://twitter.com/mltooling\" title=\"ML Tooling on Twitter\"><img src=\"https://img.shields.io/twitter/follow/mltooling.svg?style=social\"></a>\n\n---\n\n\n## Features\n\n### Use the Command Line Interface (`CLI`) to manage local ssh configuration to enable `Runtime` usage\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n\nFor a full list of CLI commands please use `lazycluster --help`. For the help of a specific command please use `lazycluster COMMAND --help`.\n\n#### List all available runtimes incl. additional information like cpu, memory, etc.\nMoreover, also incative hosts will be shown. Inactive means, that the host could not be reached via ssh and instantiated as a valid Runtime.\n```bash\n# Will print a short list of active / inactive Runtimes\nlazycluster list-runtimes     \n```\n![List Runtimes](./docs/img/cli-list-runtimes.png)\n```bash\n# will print a list of active / inactive Runtimes incl. additional host information\n# Note: This is slower as compared to omittin the -l option\nlazycluster list-runtimes -l  \n```\n![List Runtimes in long format](./docs/img/cli-list-runtimes-l.png)\n\n#### Add host to ssh config \nThe host is named `localhost` for user `root` accessible on `localhost` port `22` using the private key file found under \n~/.ssh/id_rsa.\n\n**Note:** Add command will only add the ssh configuration on the [manager](#manager). For a complete guide on how to setup passwordless ssh check the [prerequisites section](#passwordless-ssh). \n\n```bash\nlazycluster add-runtime localhost root@localhost:22 --id_file ~/.ssh/id_rsa\n```\n![Runtime Added](./docs/img/cli-runtime-added.png)\n\n#### Delete the ssh config of `Runtime`\n*Note:* Corresponding remote ikernel will be deleted too if present.\n```bash\nlazycluster delete-runtime host-1\n```\n![Runtime Deleted](./docs/img/cli-runtime-deleted.png)\n</details>\n\n### Create `Runtimes` & `RuntimeGroups`\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n\nA `Runtime` has a working directory. Usually, the execution of a [RuntimeTask](#task) is conducted relatively to this directory if no other path is explicitly given. The working directory can be manually set during the initialization. Otherwise, a temporary directory gets created that might eventually be removed.\n\n```python\nfrom lazycluster import Runtime, RuntimeGroup\n\nrt_1 = Runtime('host-1')\nrt_2 = Runtime('host-2', working_dir='/workspace')\n\n# In this case you get a group where both Runtimes have different working directories.\n# The working directory on host-1 will be a temp one and gets removed eventually.\nruntime_group = RuntimeGroup([rt_1, rt_2])\n\n# Here, the group internally creates Runtimes for both hosts and sets its working directory.\nruntime_group = RuntimeGroup(hosts=['host-1', 'host-2'], working_dir='/workspace')\n```\nMoreover, you can set environment variables for the Runtimes. These variables can then be accessed when executing a Python function on the Runtime or executing a shell command. Per default the working directory is set as an env variable and the class constant `Runtime.WORKING_DIR_ENV_VAR_NAME` will give you the name of the variable. The working directory is always accessible also if manually update the env_variables.\n```python\n# Directly set the env vars per Runtimes\nrt = Runtime('host-1')\nrt.env_variables = {'foo': 'bar'}\n\n# Or use the convenient method to the the env vars  \n# for all Runtimes in a RuntimeGroup\nruntime_group = RuntimeGroup(hosts=['host-1', 'host-2'])\ngroup.set_env_variables({'foo': 'bar'})\n```\n</details>\n\n### Use the `RuntimeManager` to create a `RuntimeGroup` based on the manager's ssh config\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n\nThe [RuntimeManager](./docs/runtime_mgmt.md#runtimemanager-class) can automatically detect all available [Runtimes](./docs/runtimes.md#runtime-class) based on the [manager's](#manager) local ssh config and eventually create a necessary [RuntimeGroup](./docs/runtime_mgmt.md#runtimegroup-class) for you.\n\n```python\nfrom lazycluster import RuntimeManager, RuntimeGroup\n\nruntime_group = RuntimeManager().create_group()\n```\n</details>\n\n### Start a [Dask](https://dask.org/) cluster for scalable analytics\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n\nMost simple way to use Dask in a cluster based on a [RuntimeGroup](./docs/runtime_mgmt.md#runtimegroup-class) created by the [RuntimeManager](./docs/runtime_mgmt.md#runtimemanager-class). The `RuntimeManager` can automatically detect all available [Runtimes](./docs/runtimes.md#runtime-class) based on the [manager's](#manager) ssh config and eventually create a necessary `RuntimeGroup` for you. This `RuntimeGroup` is then handed over to [DaskCluster](./docs/cluster.dask_cluster.md#daskcluster-class) during initialization.\n\nThe DASK `scheduler` instance gets started on the [manager](#manager). Additionally, multiple DASK `worker` processes get started in the `RuntimeGroup`, i.e. in the `Runtimes`. The default number of workers is equal to the number of `Runtimes` in the `RuntimeGroup`.\n\n**Prerequisite**:\n    Please make sure that you have Dask installed on the [manager](#manager). This can be done using `pip install -q \"dask[complete]\"`.\n\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n\n```python\nfrom lazycluster import RuntimeManager\nfrom lazycluster.cluster import DaskCluster\n\n# 1st: Create a RuntimeGroup, e.g. by letting the RuntimeManager detect \n#      available hosts (i.e. Runtimes) and create the group for you. \nruntime_group = RuntimeManager().create_group()\n\n# 2nd: Create the DaskCluster instance with the RuntimeGroup.\ncluster = DaskCluster(runtime_group)\n\n# 3rd: Let the DaskCluster instantiate all entities on Runtimes \n#      of the RuntimeGroup using default values. For custom \n#      configuration check the DaskCluster API documentation.\ncluster.start()\n\n# => Now, all cluster entities should be started and you can simply use \n#    it as documented in the hyperopt documentation.\n```\n\nTest the cluster setup\n\n```python\n# Define test functions to be executed in parallel via DASK\ndef square(x):\n    return x ** 2\n\ndef neg(x):\n    return -x\n\n# Get a DASK client instance\nclient = cluster.get_client()\n\n# Execute the computation\nA = client.map(square, range(10))\nB = client.map(neg, A)\ntotal = client.submit(sum, B, )\nres = total.result()\n\nprint('Result: ' + str(res))\n```\n</details>\n<br/>\nUse different strategies for launching the master and the worker instances.\n\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n\nUse different strategies for launching the master and the worker instance by providing custom implementation of `lazycluster.cluster.MasterLauncher` and `lazycluster.cluster.WorkerLauncher`. The default implementations are `lazycluster.cluster.dask_cluster.LocalMasterLauncher` and `lazycluster.cluster.dask_cluster.RoundRobinLauncher`.\n\n```python\ncluster = DaskCluster(RuntimeManager().create_group(),\n                      MyMasterLauncherImpl(),\n                      MyWorkerLauncherImpl())\ncluster.start()\n```\n</details>\n</details>\n\n### Distributed hyperparameter tuning with [Hyperopt](https://github.com/hyperopt/hyperopt/wiki/Parallelizing-Evaluations-During-Search-via-MongoDB)\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n\nMost simple way to use Hyperopt in a cluster based on a [RuntimeGroup](./docs/runtime_mgmt.md#runtimegroup-class) created by the [RuntimeManager](./docs/runtime_mgmt.md#runtimemanager-class). The `RuntimeManager` can automatically detect all available [Runtimes](./docs/runtimes.md#runtime-class) based on the [manager's](#manager) ssh config and eventually create a necessary `RuntimeGroup` for you. This `RuntimeGroup` is then handed over to [HyperoptCluster](./docs/cluster.hyperopt_cluster.md#hyperoptcluster-class) during initialization.\n\nA MongoDB instance gets started on the [manager](#manager). Additionally, multiple hyperopt `worker` processes get started in the `RuntimeGroup`, i.e. on the contained `Runtimes`. The default number of workers is equal to the number of `Runtimes` in the `RuntimeGroup`.\n\n**Prerequisites:** \n- [MongoDB](https://docs.mongodb.com/manual/administration/install-on-linux/) server must be installed on the [manager](#manager).\n  - **Note:** When using the [ml-workspace](https://github.com/ml-tooling/ml-workspace) as the `master` then you can use the provided install script for MongoDB which can be found under `/resources/tools`.\n- [Hyperopt must be installed ](https://github.com/hyperopt/hyperopt) on all `Runtimes` where hyperopt workers will be started\n    - **Note:** When using the [ml-workspace](https://github.com/ml-tooling/ml-workspace) as hosts for the `Runtimes` then hyperopt is already pre-installed.\n\n<details>\n<summary><b>Launch a cluster</b> (click to expand...)</summary>\n\nFor a detailed documentation of customizing options and default values check out the [API docs](./docs/cluster.hyperopt_cluster.md#hyperoptcluster-class)\n\n```python\nfrom lazycluster import RuntimeManager\nfrom lazycluster.cluster import HyperoptCluster\n\n# 1st: Create a RuntimeGroup, e.g. by letting the RuntimeManager detect \n#      available hosts (i.e. Runtimes) and create the group for you. \nruntime_group = RuntimeManager().create_group()\n\n# 2nd: Create the HyperoptCluster instance with the RuntimeGroup.\ncluster = HyperoptCluster(runtime_group)\n\n# 3rd: Let the HyperoptCluster instantiate all entities on Runtimes of the RuntimeGroup using default values. For custom \n#      configuration check the HyperoptCluster API documentation.\ncluster.start()\n\n# => Now, all cluster entities should be started and you can simply use \n#    it as documented in the hyperopt documentation. We recommend to call \n#    cluster.cleanup() once you are done.\n\n```\n\nTest the cluster setup using the simple [example](https://github.com/hyperopt/hyperopt/wiki/Parallelizing-Evaluations-During-Search-via-MongoDB) to minimize the sin function. \n\n**Note:** The call to `fmin` is also done on the [manager](#manager). The `objective_function` gets sent to the hyperopt workers by fmin via MongoDB. So there is no need to trigger the execution of `fmin` or the `objective_function` on the individual `Runtimes`. See [hyperopt docs](https://github.com/hyperopt/hyperopt/wiki/Parallelizing-Evaluations-During-Search-via-MongoDB) for detailed explanation.  \n\n```python\nimport math\nfrom hyperopt import fmin, tpe, hp\nfrom hyperopt.mongoexp import MongoTrials\n\n# You can retrieve the the actual url required by MongoTrials form the cluster instance\ntrials = MongoTrials(cluster.mongo_trial_url, exp_key='exp1')\nobjective_function = math.sin\nbest = fmin(objective_function, hp.uniform('x', -2, 2), trials=trials, algo=tpe.suggest, max_evals=10)\n# Ensures that MongoDB gets stopped and other resources  \ncluster.cleanup()\n```\n\nNow, we will cenceptually demonstrate how to use `lazycluster` w/ hyperopt to optimize hyperparameters of a [fasttext](https://github.com/facebookresearch/fastText) model. Note, this should not be a fasttext demo and thus the actual usage of fasttext is not optimized. Thus, you should read the related docs for this purpose. The example should just highlight how to get fasttext up and running in a distributed setting using lazycluster. \n\n```python\nfrom lazycluster import RuntimeManager\nfrom lazycluster.cluster.hyperopt_cluster import HyperoptCluster\nimport os\n\n# 1st: Create a RuntimeGroup, e.g. by letting the RuntimeManager detect \n#      available hosts (i.e. Runtimes) and create the group with a persistent \n#      working directory for you. \nruntime_group = RuntimeManager().create_group(working_dir='~/hyperopt')\n\n# 2nd: Send the training - and test dataset to all Runtimes\npath_to_datasets = '/path_on_manager'\ntrain_file_name = 'train.csv'\ntrain_path = os.path.join(path_to_datasets, train_file_name)\ntest_file_name = 'train.csv'\ntest_path = os.path.join(path_to_datasets, test_file_name)\n\n# Per default the file will be send asynchronously to Runtime's working directory\nruntime_group.send_file(train_file_name)\nruntime_group.send_file(test_file_name)\n\n# 3rd: Create the HyperoptCluster instance with the RuntimeGroup.\ncluster = HyperoptCluster(runtime_group)\n\n# 4th: Let the HyperoptCluster instantiate all entities on \n# Runtimes of the RuntimeGroup using default values. \n# For custom  configuration check the HyperoptCluster API documentation.\ncluster.start()\n\n# 5th: Ensure that the processes for sending the files terminated already,\n#      since we sent the files async in 2nd step.\nruntime_group.join()\n\n# => Now, all cluster entities are started, datasets transferred, and you\n#    can simply use the lcuster as documented in the hyperopt documentation. \n\n# 6th: Define the objective function to be minimized by Hyperopt in order to find the\n#      best hyperparameter combination.\ndef train(params):\n\n    import fasttext\n    import os\n\n    train_path = os.path.join(os.environ['WORKING_DIR'], params['train_set_file_name']) \n    test_path = os.path.join(os.environ['WORKING_DIR'], params['test_set_file_name'])\n\n    model = fasttext.train_supervised(\n        input = train_path, \n        lr = float(params['learning_rate']),\n        dim = int(params['vector_dim']),\n        ws = int(params['window_size']),\n        epoch = int(params['epochs']),\n        minCount = int(params['min_count']),\n        neg = int(params['negativ_sampling']),\n        t = float(params['sampling']),\n        wordNgrams = 1, # word ngrams other than 1 crash\n        bucket = int(params['bucket']),\n        pretrainedVectors = str(params['pretrained_vectors']),\n        lrUpdateRate = int(params['lr_update_rate']),\n        thread = int(params['threads']),\n        verbose = 2\n    )\n\n    number_of_classes, precision, recall = model.test(test_path)\n\n    f1 = 2 * ((precision * recall) / (precision + recall))\n\n    # Return value must be negative because hyperopt's fmin tries to minimize the objective\n    # function. You can think of it as minimizing an artificial loss function.\n    return -1 * f1\n\nfrom hyperopt import fmin, tpe, hp\nfrom hyperopt.mongoexp import MongoTrials\n\n# 7th: Define the searh space for the paramters to be optimized. Check further functions \n#      of Hyperopt's hp module that might suit your specific requirement. This should just\n#      give you an idea and not show how to best use fasttext.\nsearch_space = {\n    'min_count': hp.quniform('min_count', 2, 20, 1),\n    'window_size': hp.quniform('window_size', 4, 15, 1), \n    'vector_dim': hp.quniform('vector_dim', 100, 300, 1), \n    'learning_rate': 0.4, \n    'lr_update_rate': 100,\n    'negativ_sampling': hp.quniform('negativ_sampling', 5, 20, 1), \n    'sampling': hp.uniform('sampling', 0, 10**-3), \n    'bucket': 2000000,\n    'epochs': hp.quniform('epochs', 3, 30, 1), \n    'pretrained_vectors': '', \n    'threads': 8, \n    'train_set_file_name': train_file_name, \n    'test_set_file_name': test_file_name \n}\n\n# 8th: Actually, execute the hyperparameter optimization. Use the mongo_trial_url\n#      property of your HyperoptCluster instance to get the url in the format \n#      required by MongoTrials.\ntrials = MongoTrials(cluster.mongo_trial_url, exp_key='exp1')\nbest = fmin(train, search_space, tpe.suggest, 500, trials)\nprint(best)\n```\n\n</details>\n<br />\n<details>\n<summary><b>Debugging</b> (click to expand...)</summary>\n\nIn general you should read the [Logging, exception handling and debugging](#logging-exception-handling-and-debugging) section first so that you are aware of the general options lazycluster offers for debugging.<br/>\nSo the first step is to successfully launch a Hyperopt cluster by using the corresponding lazycluster class. If you experience problems until this point you should analyze the exceptions which should guide you forward to a solution. If this given error is not self explaining then please consider to provide meaningful feedback here so that it will be soon. Common problems until the cluster is started are:\n- **MongoDB or hyperopt are not installed**, i.e. the prerequisites are not yet fulfilled.\n  => Ensure that the prerequisites are fulfilled. Consider using [ml-workspace](https://github.com/ml-tooling/ml-workspace) to get rid of dependency problems.\n- **MongoDB is already running** (under the same dbpath). This might especially happen if you started a cluster before and the cleanup did not happen correctly. Usually, the cleanup should happen [atexit](https://docs.python.org/3.6/library/atexit.html) but sometimes it simply does not work depending on your execution environment.\n    => to prevent this problem you can and should explicitly call the `cleanup()` method of the `HyperoptCluster` instance\n    => to solve the problem if MongoDB is still running just type `lsof -i | grep mongod` into a terminal. Finally, use the `kill pid` command with the process ID you got from issuing the previous command.  \n\nOnce the Hyperopt cluster is running, you can start [using it](https://github.com/hyperopt/hyperopt/wiki/Parallelizing-Evaluations-During-Search-via-MongoDB#3-run-hyperopt-mongo-worker). It should be noted, that the following is mainly about finding Hyperopt related issues since lazycluster basically did its job already. Typically, this means you have a bug in your objective function that you try to minimize with Hyperopt. <br/>\nFirst, you could use the `print_log()` method of your hyperopt to check the execution log. If you can't find any error here, then check the [execution log files](#execution-log) or redirect the execution log from files to stdout of the [manager](#manager) by setting `debug=True` in the start methods of the [HyperoptCluster](./docs/cluster.hyperopt_cluster.md#hyperoptcluster-class) class. <br/>\nAlternatively, you can ssh into one of your `Runtimes` and manually start a hyperopt-worker process. You can find the respective shell command in the [hyperopt docs](https://github.com/hyperopt/hyperopt/wiki/Parallelizing-Evaluations-During-Search-via-MongoDB#3-run-hyperopt-mongo-worker). Moreover, you can get the necessary url for the `--mongo` argument by accessing the python property `mongo_url` from your `HyperoptCluster` instance once its running. Consequently, the newly started worker will poll a job from the master (i.e. MongoDB) and start its execution. Now you should see the error in the terminal once it occurs.\n\nWe found two common bug types related to the objective function. First, make sure that the hyper-/parameters you are passing to your model have the correct datatypes. Sounds trivial, right? :) <br/>\nNext, you typically use some training - and test dataset on your Runtimes inside your objective function. So the correct file paths may be a bit tricky at first. You should understand that the objective function gets communicated to the hyperopt worker processes by `fmin()` via MongoDB. Consequently, the objective function gets executed as it is on the Runtimes and the paths must exist on the `Runtimes`. The `Runtime's` working directory as documented in the [API docs](./docs/runtimes.md#runtime-class) is of interest here. It should be noted, that the path of this directory is available on the Runtimes. Consequently, we recommend that you manually set a working directory on your `Runtimes` and move the training - and test dataset files relative to the working directory. This can also be done on `RuntimeGroup` level. Now, you can create a relative path to the files inside your objective_function with ``` os.path.join(os.environ['WORKING_DIR'], 'relative_file_path') ```. **Note:** The advantage of manually setting a working directory in this case is that a manually set working directory does not get removed at the end. Consequently, you do not  need to move the files each time you start the execution. This hint can safe you quite a lot of time especially when you need to restart the exectuion mutliple times while debugging. \n\n</details>\n\n<br />\n\nUse different strategies for launching the master and the worker instances.\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n\nUse different strategies for launching the master and the worker instances by providing custom implementation of `lazycluster.cluster.MasterLauncher` and `lazycluster.cluster.WorkerLauncher`. The default implementations are `lazycluster.cluster.hyperopt_cluster.LocalMongoLauncher` and `lazycluster.cluster.hyperopt_cluster.RoundRobinLauncher`. \n\n```python\ncluster = HyperoptCluster(RuntimeManager().create_group(),\n                          MyMasterLauncherImpl(),\n                          MyWorkerLauncherImpl())\ncluster.start()\n```\n</details>\n</details>\n\n### Expose services \n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n\n#### Expose a service from a `Runtime`\nA DB is running on a remote host on port `runtime_port` and the DB is only accessible from the remote host. \nBut you also want to access the service from the [manager](#manager) on port `local_port`. Then you can use this \nmethod to expose the service which is running on the remote host to the [manager](#manager).\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n\n```python\nfrom lazycluster import Runtime\n\n# Create a Runtime\nruntime = Runtime('host-1')\n\n# Make the port 50000 from the Runtime accessible on localhost\nruntime.expose_port_from_runtime(50000)\n\n# Make the local port 40000 accessible on the Runtime\nruntime.expose_port_to_runtime(40000)\n```\n</details>\n\n#### Expose a service to a `Runtime`\nA DB is running on the [manager](#manager) on port `local_port` and the DB is only accessible from the manager. \nBut you also want to access the service on the remote `Runtime` on port `runtime_port`. Then you can use \nthis method to expose the service which is running on the manager to the remote host.\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n\n```python\nfrom lazycluster import Runtime\n\n# Create a Runtime\nruntime = Runtime('host-1')\n\n# Make the port 50000 from the Runtime accessible on localhost\nruntime.expose_port_from_runtime(50000)\n\n# Make the local port 40000 accessible on the Runtime\nruntime.expose_port_to_runtime(40000)\n```\n</details>\n\n#### Service exposure \nNow, we extend the previous example by using a `RuntimeGroup` instead of just a single `Runtime`. This means we want to expose a service which is running on the [manager](#manager) to a group of `Runtimes`.\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n\n```python\nfrom lazycluster import RuntimeGroup\n\n# Create a RuntimeGroup\nruntime_group = RuntimeGroup('host1', 'host-2', 'host-3')\n\n# Make the local port 50000 accessible on all Runtimes in the RuntimeGroup.\nruntime_group.expose_port_to_runtimes(50000)\n\n# Note: The port can also be exposed to a subset of the Runtimes by using the\n# method parameter exclude_hosts.\nruntime_group.expose_port_to_runtimes(50000, exclude_hosts='host-3')\n```\n</details>\n\n#### Expose a service from a `Runtime` to the other `Runtimes` in the `RuntimeGroup`\nAssume you have service which is running on Runtime `host-1`. Now, you can expose the service to the remaining `Runtimes` in the `RuntimeGroup.` \n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n\n```python\nfrom lazycluster import RuntimeGroup\n\n# Create a RuntimeGroup\nruntime_group = RuntimeGroup('host1', 'host-2', 'host-3')\n\n# Make the port 40000 which is running on host-1 accessible on all other Runtimes in the RuntimeGroup\nruntime_group.expose_port_from_runtime_to_group('host-1', 40000)\n```\n</details>\n</details>\n\n### File Transfer\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n\nA `RuntimeTask` is capable of sending a file from the [manager](#manager) to a `Runtime` or vice versa. Moreover, the `Runtime` class as well as the `RuntimeGroup` provide convenient methods for this purpose that internally creates the `RuntimeTasks` for you.\n\nIn the following example, the `file.csv` will be transferred to the `Runtime's` working directory. Another path on the Runtime can be specified by supplying a `remote_path` as argument. See [Runtime](./docs/runtimes.md#runtime-class) docs for further details on the working directory.\n\n```python\nfrom lazycluster import RuntimeTask, Runtime\n\ntask = RuntimeTask('file-transfer')\ntask.send_file('local_path/file.csv')\n\nruntime = Runtime('host-1')\nruntime.execute_task(task, exec_async=False)\n```\n\nThe explicit creation of a `RuntimeTask` is only necessary if you intend to add further steps to the `RuntimeTask` instead of just transferring a file. For example, you want to send a file, execute a Python function, and transfer the file back. If not, you can use the file transfer methods of the `Runtime` or `RuntimeGroup`.\nIn the case of sending a file to a `RuntimeGroup` you should send the files asynchronously. Otherwise, each file will be transferred sequentially. Do not forget to call `join()`, if you need the files to be transferred before proceeding.\n\n```python\nfrom lazycluster import RuntimeTask, Runtime, RuntimeGroup, RuntimeManager\n\n# Send a file to a single Runtime\nruntime = Runtime('host-1')\nsend_file('local_path/file.csv', execute_async=False)\n\n# Send a file to a whole RuntimeGroup\ngroup = RuntimeManager().create_group()\ngroup.send_file('local_path/file.csv', execute_async=True)\ngroup.join()\n```\nThe usage of get_file is similar and documented [here](./docs/runtimes.md#runtime-class).\n</details>\n\n\n\n### Simple preprocessing example\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n\nRead a local CSV file (on the [manager](#manager)) and upper case chunks in parallel using [RuntimeTasks](./docs/runtimes.md#runtimetask-class)\nand a [RuntimeGroup](./docs/runtime_mgmt.md#runtimegroup-class).\n\n```python\nfrom typing import List\nimport pandas as pd\nfrom lazycluster import RuntimeTask, RuntimeManager\n\n# Define the function to be executed remotely\ndef preprocess(docs: List[str]):\n    return [str(doc).lower() for doc in docs]\n\nfile_path = '/path/to/file.csv'\n\nruntime_group = RuntimeManager().create_group()\n\ntasks = []\n\n# Distribute chunks of the csv and start the preprocessing in parallel in the RuntimeGroup\nfor df_chunk in pd.read_csv(file_path, sep=';', chunksize=500):\n\n    task = RuntimeTask().run_function(preprocess, docs=df_chunk['text'].tolist())\n\n    tasks.append(runtime_group.execute_task(task))\n\n# Wait until all executions are done   \nruntime_group.join()    \n\n# Get the return data and print it\nindex = 0\nfor chunk in runtime_group.function_returns:  \n    print('Chunk: ' + str(index))\n    index += 1\n    print(chunk)\n```\n</details>\n\n### Logging, exception handling and debugging\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n\n`lazycluster` aims to abstract away the complexity implied by using multiple distributed [Runtimes](./docs/runtimes.md#runtime-class) and provides an intuitive high level API fur this purpose. The lazycluster [manager](#manager) orchestrates the individual components of the distributed setup. A common use case could be to use lazycluster in order to launch a distributed [hyperopt cluster](https://github.com/hyperopt/hyperopt/wiki/Parallelizing-Evaluations-During-Search-via-MongoDB). In this case, we have the lazycluster [manager](#manager), that starts a [MongoDB](https://www.mongodb.com/) instance, starts the hyperopt worker processes on multiple `Runtimes` and ensures the required communication via ssh between these instances. Each individual component could potentially fail including the 3rd party ones such as hyperopt workers. Since `lazycluster` is a generic library and debugging a distributed system is  an instrinsically non-trivial task, we tried to emphasize logging and good exception handling practices so that you can stay lazy.\n\n#### Standard Python log\nWe use the standard Python [logging module](https://docs.python.org/3.6/library/logging.html#formatter-objects) in order to log everything of interest that happens on the [manager](#manager).\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n\nPer default we recommend to set the basicConfig log level to `logging.INFO`. Consequently, you will get relevant status updates about the progress of launching a cluster for example. Of course, you can adjust the log level to `logging.DEBUG` or anything you like. \n\nWe like to use the following basic configuration when using lazycluster in a [Jupyter](https://jupyter.org/) notebook:\n```python\nimport logging\n\nlogging.basicConfig(format='[%(levelname)s] %(message)s', level=logging.INFO)\n```\n\n**Note:**\nSome 3rd party libraries produce a lot of INFO messages, which are usually not of interest for the user. This is particular true for [Paramiko](http://www.paramiko.org/). We base most ssh handling on [Fabric](http://www.fabfile.org/) which is based on Paramiko. We decided to set the log level for these libraries to `logging.Error` per default. This happens in the `__init__.py` module of the lazycluster package. And will be set once when importing the first module or class from `lazycluster`. If you want to change the log level of 3rd party libs you can set it the following way:\n```python\nimport logging\nfrom lazycluster import Environment\n\n# Effects logs of all libraries that were initially set to logging.ERROR\nlazycluster.Environment.set_third_party_log_level(logging.INFO)\n\n# Of course, you can set the log level manually for each library / module\nlogging.getLogger('paramiko').setLevel(logging.DEBUG)\nlogging.getLogger('lazycluster').setLevel(logging.INFO)\n```\nSee `set_third_party_log_level()` of the [Environment](./docs/utils.md#environment) class for a full list of affected libraries.\n</details>\n\n\n#### Execution log\nThe execution log aims to provide a central access point to output produced on the Runtimes.\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n\nThis type of log contains mainly the stdout/stderr produced when executing a [RuntimeTask](#task) on a [Runtime](#runtime). If you are new to lazycluster or you never used the lower level API directly, then you might think the execution log is not relevant for you. But it is :) Also the concrete cluster implementations (e.g. [DaskCluster](./docs/cluster.dask_cluster.md#daskcluster-class) or [HyperoptCluster](./docs/cluster.hyperopt_cluster.md#hyperoptcluster-class)) are built on top of the lower-level API. You can think of it as the kind of log which you can use to understand what actually happened on your `Runtimes`. You can access the execution log in 3 different ways.\n\nThe 1st option is by accessing the excution log files. The stdout/stderr generated on the `Runtimes` is streamed to log files. The respective directory is per default `./lazycluster/execution_log` on the [manager](#manager). The log directory contains a subfolder for each Runtime (i.e. host) that executed at least one `RuntimeTask`. Inside a Runtime folder you will find one log file per executed RuntimeTask. Each logfile name is generated by concatenating the name of the `RuntimeTask` and a current timestamp. You can configure the path were the log directory gets created by adjusting the lazycluster main directory. See [Environment](./docs/utils.md#environment) for this purpose. Moreover, the respective file path can be programmatically accessed via `RuntimeTask.execution_log_file_path`. This property gets updated each time the `RuntimeTask` gets executed.\n\nThe 2nd option is to redirect the execution log (i.e. stdout/stderr from the Runtimes) to the stdout of the [manager](#manager). Hereby, you can quickly spot errors. The drawback here is that you can not directly distinguish which Runtime generated which output, since the output of potentially multiple Runtimes is directly streamed to the manager's stdout as it occurs. To enable this feature you need to pass on the `debug` flag to the respective methods (i.e. RuntimeTask.execute(), Runtime.execute_task(), RuntimeGroup.execute_task()). All cluster related `start()` methods (e.g. `HyperoptCluster.start()`, `DaskCluster.start()` etc.) provide the debug option too. Example:\n\n```python\nfrom lazycluster import RuntimeGroup, RuntimeTask\n\ntask = RuntimeTask('debug-test').run_command('python --version')\ngroup = RuntimeGroup(hosts=['gaia-1', 'gaia-2'])\ntasks = group.execute_task(task, debug=True)\n```\n\n The 3rd option is to access the `execution_log` property of a `RuntimeTask`. Additionally, the `Runtime` as well as the `RuntimeGroup` provide a `print_log()` function which prints the `execution_log` of the `RuntimeTasks` that were executed on the `Runtimes`. The `execution_log` property is a list and can be accessed via index. Each log entry corresponds to the output of a single (fully executed) step of a `RuntimeTask`. This means the stdout/stderr is not streamed to the manager can only be accessed after its execution. This kind of log might be useful if you need to access the ouput of a concrete `RuntimeTask` step programmatically. See the [concept definition](#task) and the [class documentation](./docs/runtimes.md#runtimetask-class) of the `RuntimeTask` for further details.\n\n**Note:**\nIt should be noted that `RuntimeTask.run_function()` is actually not a single task step. A call to this method will produce multiple steps, since the Python function that needs to be executed will be send as a pickle file to the remote host. There it gets unpickled, executed and the return data is sent back as a pickle file. This means if you intend to access the exectution log you should be aware that the log contains multiple log entries for the `run_function()` call. But the number of steps per call is fixed. Moreover, you should think about using the return value of a a remotely executed Python function instead of using the execution log for this purpose.\n\n```python\nfrom lazycluster import Runtime, RuntimeTask\n\n# Create the task\ntask = RuntimeTask('exec-log-demo')\n\n# Add 2 individual task steps\ntask.run_command('echo Hello')\ntask.run_command('echo lazycluster!')\n\n# Create a Runtime \nruntime = Runtime('host-1')\n\n# Execute the task remotely on the Runtime\nruntime.execute_task(task)\n\n# Access th elog per index\nprint(task.execution_log[0]) # => 'Hello'\nprint(task.execution_log[1]) # => 'lazycluster!'\n\n# Let the Runtime print the log\n# an equivalent method exists for RuntimeGroup\nruntime.print_log()\n```\n</details>\n\n\n#### Exception handling\n\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n\nOur exception handling concept follows the idea to use standard python classes whenever appropriate. Otherwise, we create a library specific error (i.e. exception) class. \n\nEach created error class inherits from our base class [LazyclusterError](./docs/exceptions#lazyclusterError) which in turn inherits from Pythons's [Exception](https://docs.python.org/3.6/tutorial/errors.html#user-defined-exceptions) class. We aim to be informative as possible with our used exceptions to guide you to a solution to your problem. So feel encouraged to provide feedback on misleading or unclear error messages, since we strongly believe that guided errors are essential so that you can stay as lazy as possible.\n\n</details>\n</details>\n\n---\n\n## Contribution\n\n- Pull requests are encouraged and always welcome. Read [`CONTRIBUTING.md`](https://github.com/ml-tooling/lazycluster/tree/master/CONTRIBUTING.md) and check out [help-wanted](https://github.com/ml-tooling/lazycluster/issues?utf8=%E2%9C%93&q=is%3Aopen+is%3Aissue+label%3A\"help+wanted\"+sort%3Areactions-%2B1-desc+) issues.\n- Submit github issues for any [feature enhancements](https://github.com/ml-tooling/lazycluster/issues/new?assignees=&labels=feature-request&template=02_feature-request.md&title=), [bugs](https://github.com/ml-tooling/lazycluster/issues/new?assignees=&labels=bug&template=01_bug-report.md&title=), or [documentation](https://github.com/ml-tooling/lazycluster/issues/new?assignees=&labels=enhancement%2C+docs&template=03_documentation.md&title=) problems. \n- By participating in this project you agree to abide by its [Code of Conduct](https://github.com/ml-tooling/lazycluster/tree/master/CODE_OF_CONDUCT.md).\n\n---\n\nLicensed **Apache 2.0**. Created and maintained with \u2764\ufe0f by developers from SAP in Berlin.\n\n\nRequirements:\n['fabric >= 2.2', 'stormssh', 'cloudpickle >= 1.0.0', 'psutil', 'click-spinner']\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/ml-tooling/lazycluster.git", "keywords": "", "license": "Apache License 2.0", "maintainer": "", "maintainer_email": "", "name": "lazycluster", "package_url": "https://pypi.org/project/lazycluster/", "platform": "", "project_url": "https://pypi.org/project/lazycluster/", "project_urls": {"Homepage": "https://github.com/ml-tooling/lazycluster.git"}, "release_url": "https://pypi.org/project/lazycluster/0.2.0/", "requires_dist": ["fabric (>=2.2)", "stormssh", "cloudpickle (>=1.0.0)", "psutil", "click-spinner"], "requires_python": ">=3.6", "summary": "Distributed machine learning made simple.", "version": "0.2.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>\n    \ud83c\udf9b lazycluster\n    <br>\n</h1>\n<p align=\"center\">\n    <strong>Distributed machine learning made simple.</strong><br>\n    Use your preferred distributed ML framework like a <a href=\"https://youtu.be/UXSSJENiZiw\" rel=\"nofollow\">lazy engineer</a>.\n</p>\n<p align=\"center\">\n    <a href=\"https://github.com/ml-tooling/lazycluster/blob/master/LICENSE\" rel=\"nofollow\" title=\"ML Hub License\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6ce2445e20193078c53d5081d27923ea7e3e4713/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d677265656e2e737667\"></a>\n    <a href=\"https://gitter.im/ml-tooling/lazycluster\" rel=\"nofollow\" title=\"Chat on Gitter\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1595614cf0b68cb6294d34ad9e8875b9d7d4394f/68747470733a2f2f6261646765732e6769747465722e696d2f6d6c2d746f6f6c696e672f6c617a79636c75737465722e737667\"></a>\n    <a href=\"https://twitter.com/mltooling\" rel=\"nofollow\" title=\"ML Tooling on Twitter\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/88d5b55f5dc624187445b28b996ebce063ceeb92/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f6d6c746f6f6c696e672e7376673f7374796c653d736f6369616c\"></a>\n</p>\n<p align=\"center\">\n  <a href=\"#getting-started\" rel=\"nofollow\">Getting Started</a> \u2022\n  <a href=\"#highlights\" rel=\"nofollow\">Highlights</a> \u2022\n  <a href=\"#features\" rel=\"nofollow\">Features</a> \u2022\n  <a href=\"./docs\" rel=\"nofollow\">API Docs</a> \u2022\n  <a href=\"#support\" rel=\"nofollow\">Support</a> \u2022\n  <a href=\"https://github.com/ml-tooling/ml-workspace/issues/new?labels=bug&amp;template=01_bug-report.md\" rel=\"nofollow\">Report a Bug</a> \u2022\n  <a href=\"#contribution\" rel=\"nofollow\">Contribution</a>\n</p>\n<p><strong>lazycluster</strong> is a Python library intended to liberate data scientists and machine learning engineers by abstracting\naway cluster management and configuration so that they are able to focus on their actual tasks. Especially, the easy\nand convenient cluster setup with Python for various distributed machine learning frameworks is emphasized.</p>\n<h2>Highlights</h2>\n<ul>\n<li><strong>High-Level API for starting clusters:</strong>\n<ul>\n<li><a href=\"https://distributed.dask.org/en/latest/\" rel=\"nofollow\">DASK</a></li>\n<li><a href=\"https://github.com/hyperopt/hyperopt\" rel=\"nofollow\">Hyperopt</a></li>\n<li><em>More <em>lazyclusters</em> (e.g. Ray, PyTorch, Tensorflow, Horovod, Spark) to come ...</em></li>\n</ul>\n</li>\n<li><strong>Lower-level API for:</strong>\n<ul>\n<li>Managing <a href=\"./docs/runtimes.md#runtime-class\" rel=\"nofollow\">Runtimes</a> or <a href=\"./docs/runtime_mgmt.md#runtimegroup-class\" rel=\"nofollow\">RuntimeGroups</a> to:\n<ul>\n<li>A-/synchronously execute <a href=\"./docs/runtimes.md#runtimetask-class\" rel=\"nofollow\">RuntimeTasks</a> by leveraging the power of ssh</li>\n<li>Expose services (e.g. a DB) from or to a <code>Runtime</code> or in a whole <code>RuntimeGroup</code></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><strong>Command line interface (CLI)</strong>\n<ul>\n<li>List all available <code>Runtimes</code></li>\n<li>Add a <code>Runtime</code> configuration</li>\n<li>Delete a <code>Runtime</code> configuration</li>\n</ul>\n</li>\n</ul>\n<br>\n<p><img alt=\"API layer\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8aa5c2492ce273f939511c4f076fc98235f20990/2e2f646f63732f696d672f6c617965722d636f6e636570742e706e67\"></p>\n<blockquote>\n<p><strong>Concept Definition:</strong> <em><a href=\"./docs/runtimes.md#runtime-class\" rel=\"nofollow\">Runtime</a></em> <a></a></p>\n<p>A <code>Runtime</code> is the logical representation of a remote host. Typically, the host is another server or a virtual machine / container on another server. This python class provides several methods for utilizing remote resources such as the port exposure from / to a <code>Runtime</code> as well as the execution of <a href=\"#task\" rel=\"nofollow\">RuntimeTasks</a>. A <code>Runtime</code> has a working directory. Usually, the execution of a <code>RuntimeTask</code> is conducted relatively to this directory if no other path is explicitly given. The working directory can be manually set during the initialization. Otherwise, a temporary directory gets created that might eventually be removed.</p>\n</blockquote>\n<blockquote>\n<p><strong>Concept Definition:</strong> <em><a href=\"./docs/runtimes.md#runtimetask-class\" rel=\"nofollow\">RuntimeGroup</a></em></p>\n<p>A <code>RuntimeGroup</code> is the representation of logically related <code>Runtimes</code> and provides convenient methods for managing those related <code>Runtimes</code>. Most methods are wrappers around their counterparts in the <code>Runtime</code> class. Typical usage examples are exposing a port (i.e. a service such as a DB) in the <code>RuntimeGroup</code>, transfer files, or execute  a <code>RuntimeTask</code> on the <code>Runtimes</code>. Additionally, all concrete <a href=\"./docs/cluster.runtime_cluster.md#runtimecluster-class\" rel=\"nofollow\">RuntimeCluster</a> (e.g. the <a href=\"./docs/cluster.hyperopt_cluster.md#hyperoptcluster-class\" rel=\"nofollow\">HyperoptCluster</a>) implementations rely on <code>RuntimeGroups</code> for example.</p>\n</blockquote>\n<blockquote>\n<p><strong>Concept Definition:</strong> <em>Manager</em><a></a></p>\n<p>The <code>manager</code> refers to the host where you are actually using the lazycluster library, since all desired lazycluster entities are managed from here. <strong>Caution</strong>: It is not to be confused with the <a href=\"./docs/runtime_mgmt.md#runtimemanager-class\" rel=\"nofollow\">RuntimeManager</a> class.</p>\n</blockquote>\n<blockquote>\n<p><strong>Concept Definition:</strong> <em><a href=\"./docs/runtimes.md#runtimetask-class\" rel=\"nofollow\">RuntimeTask</a></em> <a></a></p>\n<p>A <code>RuntimeTask</code> is a composition of multiple elemantary task steps, namely <code>send file</code>, <code>get file</code>, <code>run command</code> (shell), <code>run function</code> (python). A <code>RuntimeTask</code> can be executed on a remote host either by handing it over to a <code>Runtime</code> object or standalone by handing over a <a href=\"http://docs.fabfile.org/en/2.5/api/connection.html\" rel=\"nofollow\">fabric Connection</a> object to the execute method of the <code>RuntimeTask</code>. Consequently, all invididual task steps are executed sequentially. Moreover, a <code>RuntimeTask</code> object captures the output (stdout/stderr) of the remote execution in its execution log. An example for a <code>RuntimeTask</code> could be to send a csv file to a <code>Runtime</code>, execute a python function that is transforming the csv file and finally get the file back.</p>\n</blockquote>\n<hr>\n<br>\n<h2>Getting started</h2>\n<h3>Installation</h3>\n<pre>pip install lazycluster\n</pre>\n<pre><span class=\"c1\"># Most up-to-date development version</span>\npip install --upgrade git+https://github.com/ml-tooling/lazycluster.git@develop\n</pre>\n<h3>Prerequisites</h3>\n<p><strong>For lazycluster usage on the <a href=\"#manager\" rel=\"nofollow\">manager</a>:</strong></p>\n<ul>\n<li>Unix based OS</li>\n<li>Python &gt;= 3.6</li>\n<li>ssh client (e.g. openssh-client)</li>\n<li>Passwordless ssh access to the <code>Runtime</code> hosts <strong>(recommended)</strong>\n<a></a></li>\n</ul>\n<details>\n<summary>Configure passwordless ssh access (click to expand...)</summary>\n<ul>\n<li>Create a key pair on the manager as described <a href=\"https://www.ssh.com/ssh/keygen#creating-an-ssh-key-pair-for-user-authentication\" rel=\"nofollow\">here</a> or use an existing one</li>\n<li><a href=\"#installation\" rel=\"nofollow\">Install</a> lazycluster on the manager</li>\n<li>Create the ssh configuration for each host to be used as Runtime by using the lazycluster CLI command <code>lazycluster add-runtime</code> as described <a href=\"#add-host-to-ssh-config\" rel=\"nofollow\">here</a> and <strong>do not forget</strong> to specify the <code>--id-file</code> argument.</li>\n<li>Finally, enable the passwordless ssh access by copying the public key to each Runtime as descibed <a href=\"https://www.ssh.com/ssh/keygen#copying-the-public-key-to-the-server\" rel=\"nofollow\">here</a></li>\n</ul>\n</details>\n<br>\n<p><strong><a href=\"#runtime\" rel=\"nofollow\">Runtime</a> host requirements:</strong></p>\n<ul>\n<li>Unix based OS</li>\n<li>Python &gt;= 3.6</li>\n<li>ssh server (e.g. openssh-server)</li>\n</ul>\n<p><strong>Note:</strong></p>\n<p>Passwordless ssh needs to be setup for the hosts to be used as <a href=\"./docs/runtimes.md#runtime-class\" rel=\"nofollow\">Runtimes</a> for the most convenient user experience. Otherwise, you need to pass the connection details to Runtime.__init__ via connection_kwargs. These parameters will be passed on to the <a href=\"http://docs.fabfile.org/en/2.4/api/connection.html#connect-kwargs-arg\" rel=\"nofollow\">fabric.Connection</a>.</p>\n<h3>Usage example high-level API</h3>\n<p>Start a <a href=\"https://distributed.dask.org/en/latest/\" rel=\"nofollow\">Dask</a> cluster.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">lazycluster</span> <span class=\"kn\">import</span> <span class=\"n\">RuntimeManager</span>\n<span class=\"kn\">from</span> <span class=\"nn\">lazycluster.cluster</span> <span class=\"kn\">import</span> <span class=\"n\">DaskCluster</span>\n\n<span class=\"c1\"># Automatically generate a group based on the ssh configuration</span>\n<span class=\"n\">runtime_manager</span> <span class=\"o\">=</span> <span class=\"n\">RuntimeManager</span><span class=\"p\">()</span>\n<span class=\"n\">runtime_group</span> <span class=\"o\">=</span> <span class=\"n\">runtime_manager</span><span class=\"o\">.</span><span class=\"n\">create_group</span><span class=\"p\">()</span> \n\n<span class=\"c1\"># Start the Dask cluster instances using the RuntimeGroup</span>\n<span class=\"n\">dask_cluster</span> <span class=\"o\">=</span> <span class=\"n\">DaskCluster</span><span class=\"p\">(</span><span class=\"n\">runtime_group</span><span class=\"p\">)</span>\n<span class=\"n\">dask_cluster</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># =&gt; Now, you can start using the running Dask cluster</span>\n\n<span class=\"c1\"># Get Dask client to interact with the cluster</span>\n<span class=\"c1\"># Note: This will give you a dask.distributed.Client which is not </span>\n<span class=\"c1\">#       a lazycluster cluster but a Dask one instead</span>\n<span class=\"n\">client</span> <span class=\"o\">=</span> <span class=\"n\">cluster</span><span class=\"o\">.</span><span class=\"n\">get_client</span><span class=\"p\">()</span>\n</pre>\n<h3>Usage example lower-level API</h3>\n<p>Execute a Python function on a remote host and access the return data.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">lazycluster</span> <span class=\"kn\">import</span> <span class=\"n\">RuntimeTask</span><span class=\"p\">,</span> <span class=\"n\">Runtime</span>\n\n<span class=\"c1\"># Define a Python function which will be executed remotely</span>\n<span class=\"k\">def</span> <span class=\"nf\">hello</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"p\">:</span><span class=\"nb\">str</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"s1\">'Hello '</span> <span class=\"o\">+</span> <span class=\"n\">name</span> <span class=\"o\">+</span> <span class=\"s1\">'!'</span>\n\n<span class=\"c1\"># Compose a `RuntimeTask`</span>\n<span class=\"n\">task</span> <span class=\"o\">=</span> <span class=\"n\">RuntimeTask</span><span class=\"p\">(</span><span class=\"s1\">'my-first_task'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">run_command</span><span class=\"p\">(</span><span class=\"s1\">'echo Hello World!'</span><span class=\"p\">)</span> \\\n                                   <span class=\"o\">.</span><span class=\"n\">run_function</span><span class=\"p\">(</span><span class=\"n\">hello</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'World'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Actually execute it remotely in a `Runtime`                                   </span>\n<span class=\"n\">task</span> <span class=\"o\">=</span> <span class=\"n\">Runtime</span><span class=\"p\">(</span><span class=\"s1\">'host-1'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">execute_task</span><span class=\"p\">(</span><span class=\"n\">task</span><span class=\"p\">,</span> <span class=\"n\">execute_async</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># The stdout from from the executing `Runtime` can be accessed </span>\n<span class=\"c1\"># via the execution log of the `RuntimeTask`</span>\n<span class=\"n\">task</span><span class=\"o\">.</span><span class=\"n\">print_log</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># Print the return of the `hello()` call</span>\n<span class=\"n\">generator</span> <span class=\"o\">=</span> <span class=\"n\">task</span><span class=\"o\">.</span><span class=\"n\">function_returns</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"nb\">next</span><span class=\"p\">(</span><span class=\"n\">generator</span><span class=\"p\">))</span>\n</pre>\n<hr>\n<h2>Support</h2>\n<p>The <strong>lazycluster</strong> project is maintained by <a href=\"https://www.linkedin.com/in/jan-kalkan-b5390284/\" rel=\"nofollow\">Jan Kalkan</a>. Please\nunderstand that we won't be able to provide individual support via email. We also believe that help is much more\nvaluable if it's shared publicly so that more people can benefit from it.</p>\n<table>\n<thead>\n<tr>\n<th>Type</th>\n<th>Channel</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>\ud83d\udea8 <strong>Bug Reports</strong></td>\n<td><a href=\"https://github.com/ml-tooling/lazycluster/issues?utf8=%E2%9C%93&amp;q=is%3Aopen+is%3Aissue+label%3Abug+sort%3Areactions-%2B1-desc+\" rel=\"nofollow\" title=\"Open Bug Report\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ce1dfab32d7e5e3402d414faf72938e5bc966b0e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f6d6c2d746f6f6c696e672f6c617a79636c75737465722f6275672e737667\"></a></td>\n</tr>\n<tr>\n<td>\ud83c\udf81 <strong>Feature Requests</strong></td>\n<td><a href=\"https://github.com/ml-tooling/lazycluster/issues?q=is%3Aopen+is%3Aissue+label%3Afeature-request+sort%3Areactions-%2B1-desc\" rel=\"nofollow\" title=\"Open Feature Request\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a7e54ab290f4605f14a53f56efca7ced88d2accc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f6d6c2d746f6f6c696e672f6c617a79636c75737465722f666561747572652d726571756573742e7376673f6c6162656c3d666561747572652532307265717565737473\"></a></td>\n</tr>\n<tr>\n<td>\ud83d\udc69\u200d\ud83d\udcbb <strong>Usage Questions</strong></td>\n<td><a href=\"https://stackoverflow.com/questions/tagged/ml-tooling\" rel=\"nofollow\" title=\"Open Question on Stackoverflow\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/306cb9812635aac97b7579651969872a3efcaacd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737461636b6f766572666c6f772d6d6c2d2d746f6f6c696e672d6f72616e67652e737667\"></a> <a href=\"https://gitter.im/ml-tooling/lazycluster\" rel=\"nofollow\" title=\"Chat on Gitter\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1595614cf0b68cb6294d34ad9e8875b9d7d4394f/68747470733a2f2f6261646765732e6769747465722e696d2f6d6c2d746f6f6c696e672f6c617a79636c75737465722e737667\"></a></td>\n</tr>\n<tr>\n<td>\ud83d\uddef <strong>General Discussion</strong></td>\n<td><a href=\"https://gitter.im/ml-tooling/lazycluster\" rel=\"nofollow\" title=\"Chat on Gitter\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1595614cf0b68cb6294d34ad9e8875b9d7d4394f/68747470733a2f2f6261646765732e6769747465722e696d2f6d6c2d746f6f6c696e672f6c617a79636c75737465722e737667\"></a>  <a href=\"https://twitter.com/mltooling\" rel=\"nofollow\" title=\"ML Tooling on Twitter\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/88d5b55f5dc624187445b28b996ebce063ceeb92/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f6d6c746f6f6c696e672e7376673f7374796c653d736f6369616c\"></a></td>\n</tr></tbody></table>\n<hr>\n<h2>Features</h2>\n<h3>Use the Command Line Interface (<code>CLI</code>) to manage local ssh configuration to enable <code>Runtime</code> usage</h3>\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n<p>For a full list of CLI commands please use <code>lazycluster --help</code>. For the help of a specific command please use <code>lazycluster COMMAND --help</code>.</p>\n<h4>List all available runtimes incl. additional information like cpu, memory, etc.</h4>\n<p>Moreover, also incative hosts will be shown. Inactive means, that the host could not be reached via ssh and instantiated as a valid Runtime.</p>\n<pre><span class=\"c1\"># Will print a short list of active / inactive Runtimes</span>\nlazycluster list-runtimes     \n</pre>\n<p><img alt=\"List Runtimes\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2433dbccaec0dd9dbca657887c754c4de673d556/2e2f646f63732f696d672f636c692d6c6973742d72756e74696d65732e706e67\"></p>\n<pre><span class=\"c1\"># will print a list of active / inactive Runtimes incl. additional host information</span>\n<span class=\"c1\"># Note: This is slower as compared to omittin the -l option</span>\nlazycluster list-runtimes -l  \n</pre>\n<p><img alt=\"List Runtimes in long format\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4babc382af6ceb08d2fb091af329766956616449/2e2f646f63732f696d672f636c692d6c6973742d72756e74696d65732d6c2e706e67\"></p>\n<h4>Add host to ssh config</h4>\n<p>The host is named <code>localhost</code> for user <code>root</code> accessible on <code>localhost</code> port <code>22</code> using the private key file found under\n~/.ssh/id_rsa.</p>\n<p><strong>Note:</strong> Add command will only add the ssh configuration on the <a href=\"#manager\" rel=\"nofollow\">manager</a>. For a complete guide on how to setup passwordless ssh check the <a href=\"#passwordless-ssh\" rel=\"nofollow\">prerequisites section</a>.</p>\n<pre>lazycluster add-runtime localhost root@localhost:22 --id_file ~/.ssh/id_rsa\n</pre>\n<p><img alt=\"Runtime Added\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/41339fede38d31e0e062df3027cff46956e77872/2e2f646f63732f696d672f636c692d72756e74696d652d61646465642e706e67\"></p>\n<h4>Delete the ssh config of <code>Runtime</code></h4>\n<p><em>Note:</em> Corresponding remote ikernel will be deleted too if present.</p>\n<pre>lazycluster delete-runtime host-1\n</pre>\n<p><img alt=\"Runtime Deleted\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3594dbd1d29170bdf8d6eedd51a929cfb5faae01/2e2f646f63732f696d672f636c692d72756e74696d652d64656c657465642e706e67\"></p>\n</details>\n<h3>Create <code>Runtimes</code> &amp; <code>RuntimeGroups</code></h3>\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n<p>A <code>Runtime</code> has a working directory. Usually, the execution of a <a href=\"#task\" rel=\"nofollow\">RuntimeTask</a> is conducted relatively to this directory if no other path is explicitly given. The working directory can be manually set during the initialization. Otherwise, a temporary directory gets created that might eventually be removed.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">lazycluster</span> <span class=\"kn\">import</span> <span class=\"n\">Runtime</span><span class=\"p\">,</span> <span class=\"n\">RuntimeGroup</span>\n\n<span class=\"n\">rt_1</span> <span class=\"o\">=</span> <span class=\"n\">Runtime</span><span class=\"p\">(</span><span class=\"s1\">'host-1'</span><span class=\"p\">)</span>\n<span class=\"n\">rt_2</span> <span class=\"o\">=</span> <span class=\"n\">Runtime</span><span class=\"p\">(</span><span class=\"s1\">'host-2'</span><span class=\"p\">,</span> <span class=\"n\">working_dir</span><span class=\"o\">=</span><span class=\"s1\">'/workspace'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># In this case you get a group where both Runtimes have different working directories.</span>\n<span class=\"c1\"># The working directory on host-1 will be a temp one and gets removed eventually.</span>\n<span class=\"n\">runtime_group</span> <span class=\"o\">=</span> <span class=\"n\">RuntimeGroup</span><span class=\"p\">([</span><span class=\"n\">rt_1</span><span class=\"p\">,</span> <span class=\"n\">rt_2</span><span class=\"p\">])</span>\n\n<span class=\"c1\"># Here, the group internally creates Runtimes for both hosts and sets its working directory.</span>\n<span class=\"n\">runtime_group</span> <span class=\"o\">=</span> <span class=\"n\">RuntimeGroup</span><span class=\"p\">(</span><span class=\"n\">hosts</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'host-1'</span><span class=\"p\">,</span> <span class=\"s1\">'host-2'</span><span class=\"p\">],</span> <span class=\"n\">working_dir</span><span class=\"o\">=</span><span class=\"s1\">'/workspace'</span><span class=\"p\">)</span>\n</pre>\n<p>Moreover, you can set environment variables for the Runtimes. These variables can then be accessed when executing a Python function on the Runtime or executing a shell command. Per default the working directory is set as an env variable and the class constant <code>Runtime.WORKING_DIR_ENV_VAR_NAME</code> will give you the name of the variable. The working directory is always accessible also if manually update the env_variables.</p>\n<pre><span class=\"c1\"># Directly set the env vars per Runtimes</span>\n<span class=\"n\">rt</span> <span class=\"o\">=</span> <span class=\"n\">Runtime</span><span class=\"p\">(</span><span class=\"s1\">'host-1'</span><span class=\"p\">)</span>\n<span class=\"n\">rt</span><span class=\"o\">.</span><span class=\"n\">env_variables</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'foo'</span><span class=\"p\">:</span> <span class=\"s1\">'bar'</span><span class=\"p\">}</span>\n\n<span class=\"c1\"># Or use the convenient method to the the env vars  </span>\n<span class=\"c1\"># for all Runtimes in a RuntimeGroup</span>\n<span class=\"n\">runtime_group</span> <span class=\"o\">=</span> <span class=\"n\">RuntimeGroup</span><span class=\"p\">(</span><span class=\"n\">hosts</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'host-1'</span><span class=\"p\">,</span> <span class=\"s1\">'host-2'</span><span class=\"p\">])</span>\n<span class=\"n\">group</span><span class=\"o\">.</span><span class=\"n\">set_env_variables</span><span class=\"p\">({</span><span class=\"s1\">'foo'</span><span class=\"p\">:</span> <span class=\"s1\">'bar'</span><span class=\"p\">})</span>\n</pre>\n</details>\n<h3>Use the <code>RuntimeManager</code> to create a <code>RuntimeGroup</code> based on the manager's ssh config</h3>\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n<p>The <a href=\"./docs/runtime_mgmt.md#runtimemanager-class\" rel=\"nofollow\">RuntimeManager</a> can automatically detect all available <a href=\"./docs/runtimes.md#runtime-class\" rel=\"nofollow\">Runtimes</a> based on the <a href=\"#manager\" rel=\"nofollow\">manager's</a> local ssh config and eventually create a necessary <a href=\"./docs/runtime_mgmt.md#runtimegroup-class\" rel=\"nofollow\">RuntimeGroup</a> for you.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">lazycluster</span> <span class=\"kn\">import</span> <span class=\"n\">RuntimeManager</span><span class=\"p\">,</span> <span class=\"n\">RuntimeGroup</span>\n\n<span class=\"n\">runtime_group</span> <span class=\"o\">=</span> <span class=\"n\">RuntimeManager</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">create_group</span><span class=\"p\">()</span>\n</pre>\n</details>\n<h3>Start a <a href=\"https://dask.org/\" rel=\"nofollow\">Dask</a> cluster for scalable analytics</h3>\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n<p>Most simple way to use Dask in a cluster based on a <a href=\"./docs/runtime_mgmt.md#runtimegroup-class\" rel=\"nofollow\">RuntimeGroup</a> created by the <a href=\"./docs/runtime_mgmt.md#runtimemanager-class\" rel=\"nofollow\">RuntimeManager</a>. The <code>RuntimeManager</code> can automatically detect all available <a href=\"./docs/runtimes.md#runtime-class\" rel=\"nofollow\">Runtimes</a> based on the <a href=\"#manager\" rel=\"nofollow\">manager's</a> ssh config and eventually create a necessary <code>RuntimeGroup</code> for you. This <code>RuntimeGroup</code> is then handed over to <a href=\"./docs/cluster.dask_cluster.md#daskcluster-class\" rel=\"nofollow\">DaskCluster</a> during initialization.</p>\n<p>The DASK <code>scheduler</code> instance gets started on the <a href=\"#manager\" rel=\"nofollow\">manager</a>. Additionally, multiple DASK <code>worker</code> processes get started in the <code>RuntimeGroup</code>, i.e. in the <code>Runtimes</code>. The default number of workers is equal to the number of <code>Runtimes</code> in the <code>RuntimeGroup</code>.</p>\n<p><strong>Prerequisite</strong>:\nPlease make sure that you have Dask installed on the <a href=\"#manager\" rel=\"nofollow\">manager</a>. This can be done using <code>pip install -q \"dask[complete]\"</code>.</p>\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">lazycluster</span> <span class=\"kn\">import</span> <span class=\"n\">RuntimeManager</span>\n<span class=\"kn\">from</span> <span class=\"nn\">lazycluster.cluster</span> <span class=\"kn\">import</span> <span class=\"n\">DaskCluster</span>\n\n<span class=\"c1\"># 1st: Create a RuntimeGroup, e.g. by letting the RuntimeManager detect </span>\n<span class=\"c1\">#      available hosts (i.e. Runtimes) and create the group for you. </span>\n<span class=\"n\">runtime_group</span> <span class=\"o\">=</span> <span class=\"n\">RuntimeManager</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">create_group</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># 2nd: Create the DaskCluster instance with the RuntimeGroup.</span>\n<span class=\"n\">cluster</span> <span class=\"o\">=</span> <span class=\"n\">DaskCluster</span><span class=\"p\">(</span><span class=\"n\">runtime_group</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 3rd: Let the DaskCluster instantiate all entities on Runtimes </span>\n<span class=\"c1\">#      of the RuntimeGroup using default values. For custom </span>\n<span class=\"c1\">#      configuration check the DaskCluster API documentation.</span>\n<span class=\"n\">cluster</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># =&gt; Now, all cluster entities should be started and you can simply use </span>\n<span class=\"c1\">#    it as documented in the hyperopt documentation.</span>\n</pre>\n<p>Test the cluster setup</p>\n<pre><span class=\"c1\"># Define test functions to be executed in parallel via DASK</span>\n<span class=\"k\">def</span> <span class=\"nf\">square</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"n\">x</span> <span class=\"o\">**</span> <span class=\"mi\">2</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">neg</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"o\">-</span><span class=\"n\">x</span>\n\n<span class=\"c1\"># Get a DASK client instance</span>\n<span class=\"n\">client</span> <span class=\"o\">=</span> <span class=\"n\">cluster</span><span class=\"o\">.</span><span class=\"n\">get_client</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># Execute the computation</span>\n<span class=\"n\">A</span> <span class=\"o\">=</span> <span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">map</span><span class=\"p\">(</span><span class=\"n\">square</span><span class=\"p\">,</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">))</span>\n<span class=\"n\">B</span> <span class=\"o\">=</span> <span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">map</span><span class=\"p\">(</span><span class=\"n\">neg</span><span class=\"p\">,</span> <span class=\"n\">A</span><span class=\"p\">)</span>\n<span class=\"n\">total</span> <span class=\"o\">=</span> <span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">submit</span><span class=\"p\">(</span><span class=\"nb\">sum</span><span class=\"p\">,</span> <span class=\"n\">B</span><span class=\"p\">,</span> <span class=\"p\">)</span>\n<span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"n\">total</span><span class=\"o\">.</span><span class=\"n\">result</span><span class=\"p\">()</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Result: '</span> <span class=\"o\">+</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">))</span>\n</pre>\n</details>\n<br>\nUse different strategies for launching the master and the worker instances.\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n<p>Use different strategies for launching the master and the worker instance by providing custom implementation of <code>lazycluster.cluster.MasterLauncher</code> and <code>lazycluster.cluster.WorkerLauncher</code>. The default implementations are <code>lazycluster.cluster.dask_cluster.LocalMasterLauncher</code> and <code>lazycluster.cluster.dask_cluster.RoundRobinLauncher</code>.</p>\n<pre><span class=\"n\">cluster</span> <span class=\"o\">=</span> <span class=\"n\">DaskCluster</span><span class=\"p\">(</span><span class=\"n\">RuntimeManager</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">create_group</span><span class=\"p\">(),</span>\n                      <span class=\"n\">MyMasterLauncherImpl</span><span class=\"p\">(),</span>\n                      <span class=\"n\">MyWorkerLauncherImpl</span><span class=\"p\">())</span>\n<span class=\"n\">cluster</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">()</span>\n</pre>\n</details>\n</details>\n<h3>Distributed hyperparameter tuning with <a href=\"https://github.com/hyperopt/hyperopt/wiki/Parallelizing-Evaluations-During-Search-via-MongoDB\" rel=\"nofollow\">Hyperopt</a></h3>\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n<p>Most simple way to use Hyperopt in a cluster based on a <a href=\"./docs/runtime_mgmt.md#runtimegroup-class\" rel=\"nofollow\">RuntimeGroup</a> created by the <a href=\"./docs/runtime_mgmt.md#runtimemanager-class\" rel=\"nofollow\">RuntimeManager</a>. The <code>RuntimeManager</code> can automatically detect all available <a href=\"./docs/runtimes.md#runtime-class\" rel=\"nofollow\">Runtimes</a> based on the <a href=\"#manager\" rel=\"nofollow\">manager's</a> ssh config and eventually create a necessary <code>RuntimeGroup</code> for you. This <code>RuntimeGroup</code> is then handed over to <a href=\"./docs/cluster.hyperopt_cluster.md#hyperoptcluster-class\" rel=\"nofollow\">HyperoptCluster</a> during initialization.</p>\n<p>A MongoDB instance gets started on the <a href=\"#manager\" rel=\"nofollow\">manager</a>. Additionally, multiple hyperopt <code>worker</code> processes get started in the <code>RuntimeGroup</code>, i.e. on the contained <code>Runtimes</code>. The default number of workers is equal to the number of <code>Runtimes</code> in the <code>RuntimeGroup</code>.</p>\n<p><strong>Prerequisites:</strong></p>\n<ul>\n<li><a href=\"https://docs.mongodb.com/manual/administration/install-on-linux/\" rel=\"nofollow\">MongoDB</a> server must be installed on the <a href=\"#manager\" rel=\"nofollow\">manager</a>.\n<ul>\n<li><strong>Note:</strong> When using the <a href=\"https://github.com/ml-tooling/ml-workspace\" rel=\"nofollow\">ml-workspace</a> as the <code>master</code> then you can use the provided install script for MongoDB which can be found under <code>/resources/tools</code>.</li>\n</ul>\n</li>\n<li><a href=\"https://github.com/hyperopt/hyperopt\" rel=\"nofollow\">Hyperopt must be installed </a> on all <code>Runtimes</code> where hyperopt workers will be started\n<ul>\n<li><strong>Note:</strong> When using the <a href=\"https://github.com/ml-tooling/ml-workspace\" rel=\"nofollow\">ml-workspace</a> as hosts for the <code>Runtimes</code> then hyperopt is already pre-installed.</li>\n</ul>\n</li>\n</ul>\n<details>\n<summary><b>Launch a cluster</b> (click to expand...)</summary>\n<p>For a detailed documentation of customizing options and default values check out the <a href=\"./docs/cluster.hyperopt_cluster.md#hyperoptcluster-class\" rel=\"nofollow\">API docs</a></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">lazycluster</span> <span class=\"kn\">import</span> <span class=\"n\">RuntimeManager</span>\n<span class=\"kn\">from</span> <span class=\"nn\">lazycluster.cluster</span> <span class=\"kn\">import</span> <span class=\"n\">HyperoptCluster</span>\n\n<span class=\"c1\"># 1st: Create a RuntimeGroup, e.g. by letting the RuntimeManager detect </span>\n<span class=\"c1\">#      available hosts (i.e. Runtimes) and create the group for you. </span>\n<span class=\"n\">runtime_group</span> <span class=\"o\">=</span> <span class=\"n\">RuntimeManager</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">create_group</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># 2nd: Create the HyperoptCluster instance with the RuntimeGroup.</span>\n<span class=\"n\">cluster</span> <span class=\"o\">=</span> <span class=\"n\">HyperoptCluster</span><span class=\"p\">(</span><span class=\"n\">runtime_group</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 3rd: Let the HyperoptCluster instantiate all entities on Runtimes of the RuntimeGroup using default values. For custom </span>\n<span class=\"c1\">#      configuration check the HyperoptCluster API documentation.</span>\n<span class=\"n\">cluster</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># =&gt; Now, all cluster entities should be started and you can simply use </span>\n<span class=\"c1\">#    it as documented in the hyperopt documentation. We recommend to call </span>\n<span class=\"c1\">#    cluster.cleanup() once you are done.</span>\n</pre>\n<p>Test the cluster setup using the simple <a href=\"https://github.com/hyperopt/hyperopt/wiki/Parallelizing-Evaluations-During-Search-via-MongoDB\" rel=\"nofollow\">example</a> to minimize the sin function.</p>\n<p><strong>Note:</strong> The call to <code>fmin</code> is also done on the <a href=\"#manager\" rel=\"nofollow\">manager</a>. The <code>objective_function</code> gets sent to the hyperopt workers by fmin via MongoDB. So there is no need to trigger the execution of <code>fmin</code> or the <code>objective_function</code> on the individual <code>Runtimes</code>. See <a href=\"https://github.com/hyperopt/hyperopt/wiki/Parallelizing-Evaluations-During-Search-via-MongoDB\" rel=\"nofollow\">hyperopt docs</a> for detailed explanation.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">math</span>\n<span class=\"kn\">from</span> <span class=\"nn\">hyperopt</span> <span class=\"kn\">import</span> <span class=\"n\">fmin</span><span class=\"p\">,</span> <span class=\"n\">tpe</span><span class=\"p\">,</span> <span class=\"n\">hp</span>\n<span class=\"kn\">from</span> <span class=\"nn\">hyperopt.mongoexp</span> <span class=\"kn\">import</span> <span class=\"n\">MongoTrials</span>\n\n<span class=\"c1\"># You can retrieve the the actual url required by MongoTrials form the cluster instance</span>\n<span class=\"n\">trials</span> <span class=\"o\">=</span> <span class=\"n\">MongoTrials</span><span class=\"p\">(</span><span class=\"n\">cluster</span><span class=\"o\">.</span><span class=\"n\">mongo_trial_url</span><span class=\"p\">,</span> <span class=\"n\">exp_key</span><span class=\"o\">=</span><span class=\"s1\">'exp1'</span><span class=\"p\">)</span>\n<span class=\"n\">objective_function</span> <span class=\"o\">=</span> <span class=\"n\">math</span><span class=\"o\">.</span><span class=\"n\">sin</span>\n<span class=\"n\">best</span> <span class=\"o\">=</span> <span class=\"n\">fmin</span><span class=\"p\">(</span><span class=\"n\">objective_function</span><span class=\"p\">,</span> <span class=\"n\">hp</span><span class=\"o\">.</span><span class=\"n\">uniform</span><span class=\"p\">(</span><span class=\"s1\">'x'</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">),</span> <span class=\"n\">trials</span><span class=\"o\">=</span><span class=\"n\">trials</span><span class=\"p\">,</span> <span class=\"n\">algo</span><span class=\"o\">=</span><span class=\"n\">tpe</span><span class=\"o\">.</span><span class=\"n\">suggest</span><span class=\"p\">,</span> <span class=\"n\">max_evals</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n<span class=\"c1\"># Ensures that MongoDB gets stopped and other resources  </span>\n<span class=\"n\">cluster</span><span class=\"o\">.</span><span class=\"n\">cleanup</span><span class=\"p\">()</span>\n</pre>\n<p>Now, we will cenceptually demonstrate how to use <code>lazycluster</code> w/ hyperopt to optimize hyperparameters of a <a href=\"https://github.com/facebookresearch/fastText\" rel=\"nofollow\">fasttext</a> model. Note, this should not be a fasttext demo and thus the actual usage of fasttext is not optimized. Thus, you should read the related docs for this purpose. The example should just highlight how to get fasttext up and running in a distributed setting using lazycluster.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">lazycluster</span> <span class=\"kn\">import</span> <span class=\"n\">RuntimeManager</span>\n<span class=\"kn\">from</span> <span class=\"nn\">lazycluster.cluster.hyperopt_cluster</span> <span class=\"kn\">import</span> <span class=\"n\">HyperoptCluster</span>\n<span class=\"kn\">import</span> <span class=\"nn\">os</span>\n\n<span class=\"c1\"># 1st: Create a RuntimeGroup, e.g. by letting the RuntimeManager detect </span>\n<span class=\"c1\">#      available hosts (i.e. Runtimes) and create the group with a persistent </span>\n<span class=\"c1\">#      working directory for you. </span>\n<span class=\"n\">runtime_group</span> <span class=\"o\">=</span> <span class=\"n\">RuntimeManager</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">create_group</span><span class=\"p\">(</span><span class=\"n\">working_dir</span><span class=\"o\">=</span><span class=\"s1\">'~/hyperopt'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 2nd: Send the training - and test dataset to all Runtimes</span>\n<span class=\"n\">path_to_datasets</span> <span class=\"o\">=</span> <span class=\"s1\">'/path_on_manager'</span>\n<span class=\"n\">train_file_name</span> <span class=\"o\">=</span> <span class=\"s1\">'train.csv'</span>\n<span class=\"n\">train_path</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">path_to_datasets</span><span class=\"p\">,</span> <span class=\"n\">train_file_name</span><span class=\"p\">)</span>\n<span class=\"n\">test_file_name</span> <span class=\"o\">=</span> <span class=\"s1\">'train.csv'</span>\n<span class=\"n\">test_path</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">path_to_datasets</span><span class=\"p\">,</span> <span class=\"n\">test_file_name</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Per default the file will be send asynchronously to Runtime's working directory</span>\n<span class=\"n\">runtime_group</span><span class=\"o\">.</span><span class=\"n\">send_file</span><span class=\"p\">(</span><span class=\"n\">train_file_name</span><span class=\"p\">)</span>\n<span class=\"n\">runtime_group</span><span class=\"o\">.</span><span class=\"n\">send_file</span><span class=\"p\">(</span><span class=\"n\">test_file_name</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 3rd: Create the HyperoptCluster instance with the RuntimeGroup.</span>\n<span class=\"n\">cluster</span> <span class=\"o\">=</span> <span class=\"n\">HyperoptCluster</span><span class=\"p\">(</span><span class=\"n\">runtime_group</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 4th: Let the HyperoptCluster instantiate all entities on </span>\n<span class=\"c1\"># Runtimes of the RuntimeGroup using default values. </span>\n<span class=\"c1\"># For custom  configuration check the HyperoptCluster API documentation.</span>\n<span class=\"n\">cluster</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># 5th: Ensure that the processes for sending the files terminated already,</span>\n<span class=\"c1\">#      since we sent the files async in 2nd step.</span>\n<span class=\"n\">runtime_group</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># =&gt; Now, all cluster entities are started, datasets transferred, and you</span>\n<span class=\"c1\">#    can simply use the lcuster as documented in the hyperopt documentation. </span>\n\n<span class=\"c1\"># 6th: Define the objective function to be minimized by Hyperopt in order to find the</span>\n<span class=\"c1\">#      best hyperparameter combination.</span>\n<span class=\"k\">def</span> <span class=\"nf\">train</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">):</span>\n\n    <span class=\"kn\">import</span> <span class=\"nn\">fasttext</span>\n    <span class=\"kn\">import</span> <span class=\"nn\">os</span>\n\n    <span class=\"n\">train_path</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">environ</span><span class=\"p\">[</span><span class=\"s1\">'WORKING_DIR'</span><span class=\"p\">],</span> <span class=\"n\">params</span><span class=\"p\">[</span><span class=\"s1\">'train_set_file_name'</span><span class=\"p\">])</span> \n    <span class=\"n\">test_path</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">environ</span><span class=\"p\">[</span><span class=\"s1\">'WORKING_DIR'</span><span class=\"p\">],</span> <span class=\"n\">params</span><span class=\"p\">[</span><span class=\"s1\">'test_set_file_name'</span><span class=\"p\">])</span>\n\n    <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">fasttext</span><span class=\"o\">.</span><span class=\"n\">train_supervised</span><span class=\"p\">(</span>\n        <span class=\"nb\">input</span> <span class=\"o\">=</span> <span class=\"n\">train_path</span><span class=\"p\">,</span> \n        <span class=\"n\">lr</span> <span class=\"o\">=</span> <span class=\"nb\">float</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">[</span><span class=\"s1\">'learning_rate'</span><span class=\"p\">]),</span>\n        <span class=\"n\">dim</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">[</span><span class=\"s1\">'vector_dim'</span><span class=\"p\">]),</span>\n        <span class=\"n\">ws</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">[</span><span class=\"s1\">'window_size'</span><span class=\"p\">]),</span>\n        <span class=\"n\">epoch</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">[</span><span class=\"s1\">'epochs'</span><span class=\"p\">]),</span>\n        <span class=\"n\">minCount</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">[</span><span class=\"s1\">'min_count'</span><span class=\"p\">]),</span>\n        <span class=\"n\">neg</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">[</span><span class=\"s1\">'negativ_sampling'</span><span class=\"p\">]),</span>\n        <span class=\"n\">t</span> <span class=\"o\">=</span> <span class=\"nb\">float</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">[</span><span class=\"s1\">'sampling'</span><span class=\"p\">]),</span>\n        <span class=\"n\">wordNgrams</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"c1\"># word ngrams other than 1 crash</span>\n        <span class=\"n\">bucket</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">[</span><span class=\"s1\">'bucket'</span><span class=\"p\">]),</span>\n        <span class=\"n\">pretrainedVectors</span> <span class=\"o\">=</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">[</span><span class=\"s1\">'pretrained_vectors'</span><span class=\"p\">]),</span>\n        <span class=\"n\">lrUpdateRate</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">[</span><span class=\"s1\">'lr_update_rate'</span><span class=\"p\">]),</span>\n        <span class=\"n\">thread</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">[</span><span class=\"s1\">'threads'</span><span class=\"p\">]),</span>\n        <span class=\"n\">verbose</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>\n    <span class=\"p\">)</span>\n\n    <span class=\"n\">number_of_classes</span><span class=\"p\">,</span> <span class=\"n\">precision</span><span class=\"p\">,</span> <span class=\"n\">recall</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">test</span><span class=\"p\">(</span><span class=\"n\">test_path</span><span class=\"p\">)</span>\n\n    <span class=\"n\">f1</span> <span class=\"o\">=</span> <span class=\"mi\">2</span> <span class=\"o\">*</span> <span class=\"p\">((</span><span class=\"n\">precision</span> <span class=\"o\">*</span> <span class=\"n\">recall</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"p\">(</span><span class=\"n\">precision</span> <span class=\"o\">+</span> <span class=\"n\">recall</span><span class=\"p\">))</span>\n\n    <span class=\"c1\"># Return value must be negative because hyperopt's fmin tries to minimize the objective</span>\n    <span class=\"c1\"># function. You can think of it as minimizing an artificial loss function.</span>\n    <span class=\"k\">return</span> <span class=\"o\">-</span><span class=\"mi\">1</span> <span class=\"o\">*</span> <span class=\"n\">f1</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">hyperopt</span> <span class=\"kn\">import</span> <span class=\"n\">fmin</span><span class=\"p\">,</span> <span class=\"n\">tpe</span><span class=\"p\">,</span> <span class=\"n\">hp</span>\n<span class=\"kn\">from</span> <span class=\"nn\">hyperopt.mongoexp</span> <span class=\"kn\">import</span> <span class=\"n\">MongoTrials</span>\n\n<span class=\"c1\"># 7th: Define the searh space for the paramters to be optimized. Check further functions </span>\n<span class=\"c1\">#      of Hyperopt's hp module that might suit your specific requirement. This should just</span>\n<span class=\"c1\">#      give you an idea and not show how to best use fasttext.</span>\n<span class=\"n\">search_space</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'min_count'</span><span class=\"p\">:</span> <span class=\"n\">hp</span><span class=\"o\">.</span><span class=\"n\">quniform</span><span class=\"p\">(</span><span class=\"s1\">'min_count'</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span>\n    <span class=\"s1\">'window_size'</span><span class=\"p\">:</span> <span class=\"n\">hp</span><span class=\"o\">.</span><span class=\"n\">quniform</span><span class=\"p\">(</span><span class=\"s1\">'window_size'</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">15</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span> \n    <span class=\"s1\">'vector_dim'</span><span class=\"p\">:</span> <span class=\"n\">hp</span><span class=\"o\">.</span><span class=\"n\">quniform</span><span class=\"p\">(</span><span class=\"s1\">'vector_dim'</span><span class=\"p\">,</span> <span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">300</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span> \n    <span class=\"s1\">'learning_rate'</span><span class=\"p\">:</span> <span class=\"mf\">0.4</span><span class=\"p\">,</span> \n    <span class=\"s1\">'lr_update_rate'</span><span class=\"p\">:</span> <span class=\"mi\">100</span><span class=\"p\">,</span>\n    <span class=\"s1\">'negativ_sampling'</span><span class=\"p\">:</span> <span class=\"n\">hp</span><span class=\"o\">.</span><span class=\"n\">quniform</span><span class=\"p\">(</span><span class=\"s1\">'negativ_sampling'</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span> \n    <span class=\"s1\">'sampling'</span><span class=\"p\">:</span> <span class=\"n\">hp</span><span class=\"o\">.</span><span class=\"n\">uniform</span><span class=\"p\">(</span><span class=\"s1\">'sampling'</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"o\">**-</span><span class=\"mi\">3</span><span class=\"p\">),</span> \n    <span class=\"s1\">'bucket'</span><span class=\"p\">:</span> <span class=\"mi\">2000000</span><span class=\"p\">,</span>\n    <span class=\"s1\">'epochs'</span><span class=\"p\">:</span> <span class=\"n\">hp</span><span class=\"o\">.</span><span class=\"n\">quniform</span><span class=\"p\">(</span><span class=\"s1\">'epochs'</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">30</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span> \n    <span class=\"s1\">'pretrained_vectors'</span><span class=\"p\">:</span> <span class=\"s1\">''</span><span class=\"p\">,</span> \n    <span class=\"s1\">'threads'</span><span class=\"p\">:</span> <span class=\"mi\">8</span><span class=\"p\">,</span> \n    <span class=\"s1\">'train_set_file_name'</span><span class=\"p\">:</span> <span class=\"n\">train_file_name</span><span class=\"p\">,</span> \n    <span class=\"s1\">'test_set_file_name'</span><span class=\"p\">:</span> <span class=\"n\">test_file_name</span> \n<span class=\"p\">}</span>\n\n<span class=\"c1\"># 8th: Actually, execute the hyperparameter optimization. Use the mongo_trial_url</span>\n<span class=\"c1\">#      property of your HyperoptCluster instance to get the url in the format </span>\n<span class=\"c1\">#      required by MongoTrials.</span>\n<span class=\"n\">trials</span> <span class=\"o\">=</span> <span class=\"n\">MongoTrials</span><span class=\"p\">(</span><span class=\"n\">cluster</span><span class=\"o\">.</span><span class=\"n\">mongo_trial_url</span><span class=\"p\">,</span> <span class=\"n\">exp_key</span><span class=\"o\">=</span><span class=\"s1\">'exp1'</span><span class=\"p\">)</span>\n<span class=\"n\">best</span> <span class=\"o\">=</span> <span class=\"n\">fmin</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">search_space</span><span class=\"p\">,</span> <span class=\"n\">tpe</span><span class=\"o\">.</span><span class=\"n\">suggest</span><span class=\"p\">,</span> <span class=\"mi\">500</span><span class=\"p\">,</span> <span class=\"n\">trials</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">best</span><span class=\"p\">)</span>\n</pre>\n</details>\n<br>\n<details>\n<summary><b>Debugging</b> (click to expand...)</summary>\n<p>In general you should read the <a href=\"#logging-exception-handling-and-debugging\" rel=\"nofollow\">Logging, exception handling and debugging</a> section first so that you are aware of the general options lazycluster offers for debugging.<br>\nSo the first step is to successfully launch a Hyperopt cluster by using the corresponding lazycluster class. If you experience problems until this point you should analyze the exceptions which should guide you forward to a solution. If this given error is not self explaining then please consider to provide meaningful feedback here so that it will be soon. Common problems until the cluster is started are:</p>\n<ul>\n<li><strong>MongoDB or hyperopt are not installed</strong>, i.e. the prerequisites are not yet fulfilled.\n=&gt; Ensure that the prerequisites are fulfilled. Consider using <a href=\"https://github.com/ml-tooling/ml-workspace\" rel=\"nofollow\">ml-workspace</a> to get rid of dependency problems.</li>\n<li><strong>MongoDB is already running</strong> (under the same dbpath). This might especially happen if you started a cluster before and the cleanup did not happen correctly. Usually, the cleanup should happen <a href=\"https://docs.python.org/3.6/library/atexit.html\" rel=\"nofollow\">atexit</a> but sometimes it simply does not work depending on your execution environment.\n=&gt; to prevent this problem you can and should explicitly call the <code>cleanup()</code> method of the <code>HyperoptCluster</code> instance\n=&gt; to solve the problem if MongoDB is still running just type <code>lsof -i | grep mongod</code> into a terminal. Finally, use the <code>kill pid</code> command with the process ID you got from issuing the previous command.</li>\n</ul>\n<p>Once the Hyperopt cluster is running, you can start <a href=\"https://github.com/hyperopt/hyperopt/wiki/Parallelizing-Evaluations-During-Search-via-MongoDB#3-run-hyperopt-mongo-worker\" rel=\"nofollow\">using it</a>. It should be noted, that the following is mainly about finding Hyperopt related issues since lazycluster basically did its job already. Typically, this means you have a bug in your objective function that you try to minimize with Hyperopt. <br>\nFirst, you could use the <code>print_log()</code> method of your hyperopt to check the execution log. If you can't find any error here, then check the <a href=\"#execution-log\" rel=\"nofollow\">execution log files</a> or redirect the execution log from files to stdout of the <a href=\"#manager\" rel=\"nofollow\">manager</a> by setting <code>debug=True</code> in the start methods of the <a href=\"./docs/cluster.hyperopt_cluster.md#hyperoptcluster-class\" rel=\"nofollow\">HyperoptCluster</a> class. <br>\nAlternatively, you can ssh into one of your <code>Runtimes</code> and manually start a hyperopt-worker process. You can find the respective shell command in the <a href=\"https://github.com/hyperopt/hyperopt/wiki/Parallelizing-Evaluations-During-Search-via-MongoDB#3-run-hyperopt-mongo-worker\" rel=\"nofollow\">hyperopt docs</a>. Moreover, you can get the necessary url for the <code>--mongo</code> argument by accessing the python property <code>mongo_url</code> from your <code>HyperoptCluster</code> instance once its running. Consequently, the newly started worker will poll a job from the master (i.e. MongoDB) and start its execution. Now you should see the error in the terminal once it occurs.</p>\n<p>We found two common bug types related to the objective function. First, make sure that the hyper-/parameters you are passing to your model have the correct datatypes. Sounds trivial, right? :) <br>\nNext, you typically use some training - and test dataset on your Runtimes inside your objective function. So the correct file paths may be a bit tricky at first. You should understand that the objective function gets communicated to the hyperopt worker processes by <code>fmin()</code> via MongoDB. Consequently, the objective function gets executed as it is on the Runtimes and the paths must exist on the <code>Runtimes</code>. The <code>Runtime's</code> working directory as documented in the <a href=\"./docs/runtimes.md#runtime-class\" rel=\"nofollow\">API docs</a> is of interest here. It should be noted, that the path of this directory is available on the Runtimes. Consequently, we recommend that you manually set a working directory on your <code>Runtimes</code> and move the training - and test dataset files relative to the working directory. This can also be done on <code>RuntimeGroup</code> level. Now, you can create a relative path to the files inside your objective_function with <code>os.path.join(os.environ['WORKING_DIR'], 'relative_file_path')</code>. <strong>Note:</strong> The advantage of manually setting a working directory in this case is that a manually set working directory does not get removed at the end. Consequently, you do not  need to move the files each time you start the execution. This hint can safe you quite a lot of time especially when you need to restart the exectuion mutliple times while debugging.</p>\n</details>\n<br>\n<p>Use different strategies for launching the master and the worker instances.</p>\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n<p>Use different strategies for launching the master and the worker instances by providing custom implementation of <code>lazycluster.cluster.MasterLauncher</code> and <code>lazycluster.cluster.WorkerLauncher</code>. The default implementations are <code>lazycluster.cluster.hyperopt_cluster.LocalMongoLauncher</code> and <code>lazycluster.cluster.hyperopt_cluster.RoundRobinLauncher</code>.</p>\n<pre><span class=\"n\">cluster</span> <span class=\"o\">=</span> <span class=\"n\">HyperoptCluster</span><span class=\"p\">(</span><span class=\"n\">RuntimeManager</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">create_group</span><span class=\"p\">(),</span>\n                          <span class=\"n\">MyMasterLauncherImpl</span><span class=\"p\">(),</span>\n                          <span class=\"n\">MyWorkerLauncherImpl</span><span class=\"p\">())</span>\n<span class=\"n\">cluster</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">()</span>\n</pre>\n</details>\n</details>\n<h3>Expose services</h3>\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n<h4>Expose a service from a <code>Runtime</code></h4>\n<p>A DB is running on a remote host on port <code>runtime_port</code> and the DB is only accessible from the remote host.\nBut you also want to access the service from the <a href=\"#manager\" rel=\"nofollow\">manager</a> on port <code>local_port</code>. Then you can use this\nmethod to expose the service which is running on the remote host to the <a href=\"#manager\" rel=\"nofollow\">manager</a>.</p>\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">lazycluster</span> <span class=\"kn\">import</span> <span class=\"n\">Runtime</span>\n\n<span class=\"c1\"># Create a Runtime</span>\n<span class=\"n\">runtime</span> <span class=\"o\">=</span> <span class=\"n\">Runtime</span><span class=\"p\">(</span><span class=\"s1\">'host-1'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Make the port 50000 from the Runtime accessible on localhost</span>\n<span class=\"n\">runtime</span><span class=\"o\">.</span><span class=\"n\">expose_port_from_runtime</span><span class=\"p\">(</span><span class=\"mi\">50000</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Make the local port 40000 accessible on the Runtime</span>\n<span class=\"n\">runtime</span><span class=\"o\">.</span><span class=\"n\">expose_port_to_runtime</span><span class=\"p\">(</span><span class=\"mi\">40000</span><span class=\"p\">)</span>\n</pre>\n</details>\n<h4>Expose a service to a <code>Runtime</code></h4>\n<p>A DB is running on the <a href=\"#manager\" rel=\"nofollow\">manager</a> on port <code>local_port</code> and the DB is only accessible from the manager.\nBut you also want to access the service on the remote <code>Runtime</code> on port <code>runtime_port</code>. Then you can use\nthis method to expose the service which is running on the manager to the remote host.</p>\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">lazycluster</span> <span class=\"kn\">import</span> <span class=\"n\">Runtime</span>\n\n<span class=\"c1\"># Create a Runtime</span>\n<span class=\"n\">runtime</span> <span class=\"o\">=</span> <span class=\"n\">Runtime</span><span class=\"p\">(</span><span class=\"s1\">'host-1'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Make the port 50000 from the Runtime accessible on localhost</span>\n<span class=\"n\">runtime</span><span class=\"o\">.</span><span class=\"n\">expose_port_from_runtime</span><span class=\"p\">(</span><span class=\"mi\">50000</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Make the local port 40000 accessible on the Runtime</span>\n<span class=\"n\">runtime</span><span class=\"o\">.</span><span class=\"n\">expose_port_to_runtime</span><span class=\"p\">(</span><span class=\"mi\">40000</span><span class=\"p\">)</span>\n</pre>\n</details>\n<h4>Service exposure</h4>\n<p>Now, we extend the previous example by using a <code>RuntimeGroup</code> instead of just a single <code>Runtime</code>. This means we want to expose a service which is running on the <a href=\"#manager\" rel=\"nofollow\">manager</a> to a group of <code>Runtimes</code>.</p>\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">lazycluster</span> <span class=\"kn\">import</span> <span class=\"n\">RuntimeGroup</span>\n\n<span class=\"c1\"># Create a RuntimeGroup</span>\n<span class=\"n\">runtime_group</span> <span class=\"o\">=</span> <span class=\"n\">RuntimeGroup</span><span class=\"p\">(</span><span class=\"s1\">'host1'</span><span class=\"p\">,</span> <span class=\"s1\">'host-2'</span><span class=\"p\">,</span> <span class=\"s1\">'host-3'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Make the local port 50000 accessible on all Runtimes in the RuntimeGroup.</span>\n<span class=\"n\">runtime_group</span><span class=\"o\">.</span><span class=\"n\">expose_port_to_runtimes</span><span class=\"p\">(</span><span class=\"mi\">50000</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Note: The port can also be exposed to a subset of the Runtimes by using the</span>\n<span class=\"c1\"># method parameter exclude_hosts.</span>\n<span class=\"n\">runtime_group</span><span class=\"o\">.</span><span class=\"n\">expose_port_to_runtimes</span><span class=\"p\">(</span><span class=\"mi\">50000</span><span class=\"p\">,</span> <span class=\"n\">exclude_hosts</span><span class=\"o\">=</span><span class=\"s1\">'host-3'</span><span class=\"p\">)</span>\n</pre>\n</details>\n<h4>Expose a service from a <code>Runtime</code> to the other <code>Runtimes</code> in the <code>RuntimeGroup</code></h4>\n<p>Assume you have service which is running on Runtime <code>host-1</code>. Now, you can expose the service to the remaining <code>Runtimes</code> in the <code>RuntimeGroup.</code></p>\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">lazycluster</span> <span class=\"kn\">import</span> <span class=\"n\">RuntimeGroup</span>\n\n<span class=\"c1\"># Create a RuntimeGroup</span>\n<span class=\"n\">runtime_group</span> <span class=\"o\">=</span> <span class=\"n\">RuntimeGroup</span><span class=\"p\">(</span><span class=\"s1\">'host1'</span><span class=\"p\">,</span> <span class=\"s1\">'host-2'</span><span class=\"p\">,</span> <span class=\"s1\">'host-3'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Make the port 40000 which is running on host-1 accessible on all other Runtimes in the RuntimeGroup</span>\n<span class=\"n\">runtime_group</span><span class=\"o\">.</span><span class=\"n\">expose_port_from_runtime_to_group</span><span class=\"p\">(</span><span class=\"s1\">'host-1'</span><span class=\"p\">,</span> <span class=\"mi\">40000</span><span class=\"p\">)</span>\n</pre>\n</details>\n</details>\n<h3>File Transfer</h3>\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n<p>A <code>RuntimeTask</code> is capable of sending a file from the <a href=\"#manager\" rel=\"nofollow\">manager</a> to a <code>Runtime</code> or vice versa. Moreover, the <code>Runtime</code> class as well as the <code>RuntimeGroup</code> provide convenient methods for this purpose that internally creates the <code>RuntimeTasks</code> for you.</p>\n<p>In the following example, the <code>file.csv</code> will be transferred to the <code>Runtime's</code> working directory. Another path on the Runtime can be specified by supplying a <code>remote_path</code> as argument. See <a href=\"./docs/runtimes.md#runtime-class\" rel=\"nofollow\">Runtime</a> docs for further details on the working directory.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">lazycluster</span> <span class=\"kn\">import</span> <span class=\"n\">RuntimeTask</span><span class=\"p\">,</span> <span class=\"n\">Runtime</span>\n\n<span class=\"n\">task</span> <span class=\"o\">=</span> <span class=\"n\">RuntimeTask</span><span class=\"p\">(</span><span class=\"s1\">'file-transfer'</span><span class=\"p\">)</span>\n<span class=\"n\">task</span><span class=\"o\">.</span><span class=\"n\">send_file</span><span class=\"p\">(</span><span class=\"s1\">'local_path/file.csv'</span><span class=\"p\">)</span>\n\n<span class=\"n\">runtime</span> <span class=\"o\">=</span> <span class=\"n\">Runtime</span><span class=\"p\">(</span><span class=\"s1\">'host-1'</span><span class=\"p\">)</span>\n<span class=\"n\">runtime</span><span class=\"o\">.</span><span class=\"n\">execute_task</span><span class=\"p\">(</span><span class=\"n\">task</span><span class=\"p\">,</span> <span class=\"n\">exec_async</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n</pre>\n<p>The explicit creation of a <code>RuntimeTask</code> is only necessary if you intend to add further steps to the <code>RuntimeTask</code> instead of just transferring a file. For example, you want to send a file, execute a Python function, and transfer the file back. If not, you can use the file transfer methods of the <code>Runtime</code> or <code>RuntimeGroup</code>.\nIn the case of sending a file to a <code>RuntimeGroup</code> you should send the files asynchronously. Otherwise, each file will be transferred sequentially. Do not forget to call <code>join()</code>, if you need the files to be transferred before proceeding.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">lazycluster</span> <span class=\"kn\">import</span> <span class=\"n\">RuntimeTask</span><span class=\"p\">,</span> <span class=\"n\">Runtime</span><span class=\"p\">,</span> <span class=\"n\">RuntimeGroup</span><span class=\"p\">,</span> <span class=\"n\">RuntimeManager</span>\n\n<span class=\"c1\"># Send a file to a single Runtime</span>\n<span class=\"n\">runtime</span> <span class=\"o\">=</span> <span class=\"n\">Runtime</span><span class=\"p\">(</span><span class=\"s1\">'host-1'</span><span class=\"p\">)</span>\n<span class=\"n\">send_file</span><span class=\"p\">(</span><span class=\"s1\">'local_path/file.csv'</span><span class=\"p\">,</span> <span class=\"n\">execute_async</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Send a file to a whole RuntimeGroup</span>\n<span class=\"n\">group</span> <span class=\"o\">=</span> <span class=\"n\">RuntimeManager</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">create_group</span><span class=\"p\">()</span>\n<span class=\"n\">group</span><span class=\"o\">.</span><span class=\"n\">send_file</span><span class=\"p\">(</span><span class=\"s1\">'local_path/file.csv'</span><span class=\"p\">,</span> <span class=\"n\">execute_async</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"n\">group</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">()</span>\n</pre>\n<p>The usage of get_file is similar and documented <a href=\"./docs/runtimes.md#runtime-class\" rel=\"nofollow\">here</a>.</p>\n</details>\n<h3>Simple preprocessing example</h3>\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n<p>Read a local CSV file (on the <a href=\"#manager\" rel=\"nofollow\">manager</a>) and upper case chunks in parallel using <a href=\"./docs/runtimes.md#runtimetask-class\" rel=\"nofollow\">RuntimeTasks</a>\nand a <a href=\"./docs/runtime_mgmt.md#runtimegroup-class\" rel=\"nofollow\">RuntimeGroup</a>.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">typing</span> <span class=\"kn\">import</span> <span class=\"n\">List</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n<span class=\"kn\">from</span> <span class=\"nn\">lazycluster</span> <span class=\"kn\">import</span> <span class=\"n\">RuntimeTask</span><span class=\"p\">,</span> <span class=\"n\">RuntimeManager</span>\n\n<span class=\"c1\"># Define the function to be executed remotely</span>\n<span class=\"k\">def</span> <span class=\"nf\">preprocess</span><span class=\"p\">(</span><span class=\"n\">docs</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]):</span>\n    <span class=\"k\">return</span> <span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">doc</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">lower</span><span class=\"p\">()</span> <span class=\"k\">for</span> <span class=\"n\">doc</span> <span class=\"ow\">in</span> <span class=\"n\">docs</span><span class=\"p\">]</span>\n\n<span class=\"n\">file_path</span> <span class=\"o\">=</span> <span class=\"s1\">'/path/to/file.csv'</span>\n\n<span class=\"n\">runtime_group</span> <span class=\"o\">=</span> <span class=\"n\">RuntimeManager</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">create_group</span><span class=\"p\">()</span>\n\n<span class=\"n\">tasks</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n\n<span class=\"c1\"># Distribute chunks of the csv and start the preprocessing in parallel in the RuntimeGroup</span>\n<span class=\"k\">for</span> <span class=\"n\">df_chunk</span> <span class=\"ow\">in</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"n\">file_path</span><span class=\"p\">,</span> <span class=\"n\">sep</span><span class=\"o\">=</span><span class=\"s1\">';'</span><span class=\"p\">,</span> <span class=\"n\">chunksize</span><span class=\"o\">=</span><span class=\"mi\">500</span><span class=\"p\">):</span>\n\n    <span class=\"n\">task</span> <span class=\"o\">=</span> <span class=\"n\">RuntimeTask</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">run_function</span><span class=\"p\">(</span><span class=\"n\">preprocess</span><span class=\"p\">,</span> <span class=\"n\">docs</span><span class=\"o\">=</span><span class=\"n\">df_chunk</span><span class=\"p\">[</span><span class=\"s1\">'text'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">())</span>\n\n    <span class=\"n\">tasks</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">runtime_group</span><span class=\"o\">.</span><span class=\"n\">execute_task</span><span class=\"p\">(</span><span class=\"n\">task</span><span class=\"p\">))</span>\n\n<span class=\"c1\"># Wait until all executions are done   </span>\n<span class=\"n\">runtime_group</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">()</span>    \n\n<span class=\"c1\"># Get the return data and print it</span>\n<span class=\"n\">index</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n<span class=\"k\">for</span> <span class=\"n\">chunk</span> <span class=\"ow\">in</span> <span class=\"n\">runtime_group</span><span class=\"o\">.</span><span class=\"n\">function_returns</span><span class=\"p\">:</span>  \n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Chunk: '</span> <span class=\"o\">+</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">index</span><span class=\"p\">))</span>\n    <span class=\"n\">index</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">chunk</span><span class=\"p\">)</span>\n</pre>\n</details>\n<h3>Logging, exception handling and debugging</h3>\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n<p><code>lazycluster</code> aims to abstract away the complexity implied by using multiple distributed <a href=\"./docs/runtimes.md#runtime-class\" rel=\"nofollow\">Runtimes</a> and provides an intuitive high level API fur this purpose. The lazycluster <a href=\"#manager\" rel=\"nofollow\">manager</a> orchestrates the individual components of the distributed setup. A common use case could be to use lazycluster in order to launch a distributed <a href=\"https://github.com/hyperopt/hyperopt/wiki/Parallelizing-Evaluations-During-Search-via-MongoDB\" rel=\"nofollow\">hyperopt cluster</a>. In this case, we have the lazycluster <a href=\"#manager\" rel=\"nofollow\">manager</a>, that starts a <a href=\"https://www.mongodb.com/\" rel=\"nofollow\">MongoDB</a> instance, starts the hyperopt worker processes on multiple <code>Runtimes</code> and ensures the required communication via ssh between these instances. Each individual component could potentially fail including the 3rd party ones such as hyperopt workers. Since <code>lazycluster</code> is a generic library and debugging a distributed system is  an instrinsically non-trivial task, we tried to emphasize logging and good exception handling practices so that you can stay lazy.</p>\n<h4>Standard Python log</h4>\n<p>We use the standard Python <a href=\"https://docs.python.org/3.6/library/logging.html#formatter-objects\" rel=\"nofollow\">logging module</a> in order to log everything of interest that happens on the <a href=\"#manager\" rel=\"nofollow\">manager</a>.</p>\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n<p>Per default we recommend to set the basicConfig log level to <code>logging.INFO</code>. Consequently, you will get relevant status updates about the progress of launching a cluster for example. Of course, you can adjust the log level to <code>logging.DEBUG</code> or anything you like.</p>\n<p>We like to use the following basic configuration when using lazycluster in a <a href=\"https://jupyter.org/\" rel=\"nofollow\">Jupyter</a> notebook:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n\n<span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">basicConfig</span><span class=\"p\">(</span><span class=\"nb\">format</span><span class=\"o\">=</span><span class=\"s1\">'[</span><span class=\"si\">%(levelname)s</span><span class=\"s1\">] </span><span class=\"si\">%(message)s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">level</span><span class=\"o\">=</span><span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">INFO</span><span class=\"p\">)</span>\n</pre>\n<p><strong>Note:</strong>\nSome 3rd party libraries produce a lot of INFO messages, which are usually not of interest for the user. This is particular true for <a href=\"http://www.paramiko.org/\" rel=\"nofollow\">Paramiko</a>. We base most ssh handling on <a href=\"http://www.fabfile.org/\" rel=\"nofollow\">Fabric</a> which is based on Paramiko. We decided to set the log level for these libraries to <code>logging.Error</code> per default. This happens in the <code>__init__.py</code> module of the lazycluster package. And will be set once when importing the first module or class from <code>lazycluster</code>. If you want to change the log level of 3rd party libs you can set it the following way:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"kn\">from</span> <span class=\"nn\">lazycluster</span> <span class=\"kn\">import</span> <span class=\"n\">Environment</span>\n\n<span class=\"c1\"># Effects logs of all libraries that were initially set to logging.ERROR</span>\n<span class=\"n\">lazycluster</span><span class=\"o\">.</span><span class=\"n\">Environment</span><span class=\"o\">.</span><span class=\"n\">set_third_party_log_level</span><span class=\"p\">(</span><span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">INFO</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Of course, you can set the log level manually for each library / module</span>\n<span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">getLogger</span><span class=\"p\">(</span><span class=\"s1\">'paramiko'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">setLevel</span><span class=\"p\">(</span><span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">DEBUG</span><span class=\"p\">)</span>\n<span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">getLogger</span><span class=\"p\">(</span><span class=\"s1\">'lazycluster'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">setLevel</span><span class=\"p\">(</span><span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">INFO</span><span class=\"p\">)</span>\n</pre>\n<p>See <code>set_third_party_log_level()</code> of the <a href=\"./docs/utils.md#environment\" rel=\"nofollow\">Environment</a> class for a full list of affected libraries.</p>\n</details>\n<h4>Execution log</h4>\n<p>The execution log aims to provide a central access point to output produced on the Runtimes.</p>\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n<p>This type of log contains mainly the stdout/stderr produced when executing a <a href=\"#task\" rel=\"nofollow\">RuntimeTask</a> on a <a href=\"#runtime\" rel=\"nofollow\">Runtime</a>. If you are new to lazycluster or you never used the lower level API directly, then you might think the execution log is not relevant for you. But it is :) Also the concrete cluster implementations (e.g. <a href=\"./docs/cluster.dask_cluster.md#daskcluster-class\" rel=\"nofollow\">DaskCluster</a> or <a href=\"./docs/cluster.hyperopt_cluster.md#hyperoptcluster-class\" rel=\"nofollow\">HyperoptCluster</a>) are built on top of the lower-level API. You can think of it as the kind of log which you can use to understand what actually happened on your <code>Runtimes</code>. You can access the execution log in 3 different ways.</p>\n<p>The 1st option is by accessing the excution log files. The stdout/stderr generated on the <code>Runtimes</code> is streamed to log files. The respective directory is per default <code>./lazycluster/execution_log</code> on the <a href=\"#manager\" rel=\"nofollow\">manager</a>. The log directory contains a subfolder for each Runtime (i.e. host) that executed at least one <code>RuntimeTask</code>. Inside a Runtime folder you will find one log file per executed RuntimeTask. Each logfile name is generated by concatenating the name of the <code>RuntimeTask</code> and a current timestamp. You can configure the path were the log directory gets created by adjusting the lazycluster main directory. See <a href=\"./docs/utils.md#environment\" rel=\"nofollow\">Environment</a> for this purpose. Moreover, the respective file path can be programmatically accessed via <code>RuntimeTask.execution_log_file_path</code>. This property gets updated each time the <code>RuntimeTask</code> gets executed.</p>\n<p>The 2nd option is to redirect the execution log (i.e. stdout/stderr from the Runtimes) to the stdout of the <a href=\"#manager\" rel=\"nofollow\">manager</a>. Hereby, you can quickly spot errors. The drawback here is that you can not directly distinguish which Runtime generated which output, since the output of potentially multiple Runtimes is directly streamed to the manager's stdout as it occurs. To enable this feature you need to pass on the <code>debug</code> flag to the respective methods (i.e. RuntimeTask.execute(), Runtime.execute_task(), RuntimeGroup.execute_task()). All cluster related <code>start()</code> methods (e.g. <code>HyperoptCluster.start()</code>, <code>DaskCluster.start()</code> etc.) provide the debug option too. Example:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">lazycluster</span> <span class=\"kn\">import</span> <span class=\"n\">RuntimeGroup</span><span class=\"p\">,</span> <span class=\"n\">RuntimeTask</span>\n\n<span class=\"n\">task</span> <span class=\"o\">=</span> <span class=\"n\">RuntimeTask</span><span class=\"p\">(</span><span class=\"s1\">'debug-test'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">run_command</span><span class=\"p\">(</span><span class=\"s1\">'python --version'</span><span class=\"p\">)</span>\n<span class=\"n\">group</span> <span class=\"o\">=</span> <span class=\"n\">RuntimeGroup</span><span class=\"p\">(</span><span class=\"n\">hosts</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'gaia-1'</span><span class=\"p\">,</span> <span class=\"s1\">'gaia-2'</span><span class=\"p\">])</span>\n<span class=\"n\">tasks</span> <span class=\"o\">=</span> <span class=\"n\">group</span><span class=\"o\">.</span><span class=\"n\">execute_task</span><span class=\"p\">(</span><span class=\"n\">task</span><span class=\"p\">,</span> <span class=\"n\">debug</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<p>The 3rd option is to access the <code>execution_log</code> property of a <code>RuntimeTask</code>. Additionally, the <code>Runtime</code> as well as the <code>RuntimeGroup</code> provide a <code>print_log()</code> function which prints the <code>execution_log</code> of the <code>RuntimeTasks</code> that were executed on the <code>Runtimes</code>. The <code>execution_log</code> property is a list and can be accessed via index. Each log entry corresponds to the output of a single (fully executed) step of a <code>RuntimeTask</code>. This means the stdout/stderr is not streamed to the manager can only be accessed after its execution. This kind of log might be useful if you need to access the ouput of a concrete <code>RuntimeTask</code> step programmatically. See the <a href=\"#task\" rel=\"nofollow\">concept definition</a> and the <a href=\"./docs/runtimes.md#runtimetask-class\" rel=\"nofollow\">class documentation</a> of the <code>RuntimeTask</code> for further details.</p>\n<p><strong>Note:</strong>\nIt should be noted that <code>RuntimeTask.run_function()</code> is actually not a single task step. A call to this method will produce multiple steps, since the Python function that needs to be executed will be send as a pickle file to the remote host. There it gets unpickled, executed and the return data is sent back as a pickle file. This means if you intend to access the exectution log you should be aware that the log contains multiple log entries for the <code>run_function()</code> call. But the number of steps per call is fixed. Moreover, you should think about using the return value of a a remotely executed Python function instead of using the execution log for this purpose.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">lazycluster</span> <span class=\"kn\">import</span> <span class=\"n\">Runtime</span><span class=\"p\">,</span> <span class=\"n\">RuntimeTask</span>\n\n<span class=\"c1\"># Create the task</span>\n<span class=\"n\">task</span> <span class=\"o\">=</span> <span class=\"n\">RuntimeTask</span><span class=\"p\">(</span><span class=\"s1\">'exec-log-demo'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Add 2 individual task steps</span>\n<span class=\"n\">task</span><span class=\"o\">.</span><span class=\"n\">run_command</span><span class=\"p\">(</span><span class=\"s1\">'echo Hello'</span><span class=\"p\">)</span>\n<span class=\"n\">task</span><span class=\"o\">.</span><span class=\"n\">run_command</span><span class=\"p\">(</span><span class=\"s1\">'echo lazycluster!'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Create a Runtime </span>\n<span class=\"n\">runtime</span> <span class=\"o\">=</span> <span class=\"n\">Runtime</span><span class=\"p\">(</span><span class=\"s1\">'host-1'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Execute the task remotely on the Runtime</span>\n<span class=\"n\">runtime</span><span class=\"o\">.</span><span class=\"n\">execute_task</span><span class=\"p\">(</span><span class=\"n\">task</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Access th elog per index</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">task</span><span class=\"o\">.</span><span class=\"n\">execution_log</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span> <span class=\"c1\"># =&gt; 'Hello'</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">task</span><span class=\"o\">.</span><span class=\"n\">execution_log</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">])</span> <span class=\"c1\"># =&gt; 'lazycluster!'</span>\n\n<span class=\"c1\"># Let the Runtime print the log</span>\n<span class=\"c1\"># an equivalent method exists for RuntimeGroup</span>\n<span class=\"n\">runtime</span><span class=\"o\">.</span><span class=\"n\">print_log</span><span class=\"p\">()</span>\n</pre>\n</details>\n<h4>Exception handling</h4>\n<details>\n<summary><b>Details</b> (click to expand...)</summary>\n<p>Our exception handling concept follows the idea to use standard python classes whenever appropriate. Otherwise, we create a library specific error (i.e. exception) class.</p>\n<p>Each created error class inherits from our base class <a href=\"./docs/exceptions#lazyclusterError\" rel=\"nofollow\">LazyclusterError</a> which in turn inherits from Pythons's <a href=\"https://docs.python.org/3.6/tutorial/errors.html#user-defined-exceptions\" rel=\"nofollow\">Exception</a> class. We aim to be informative as possible with our used exceptions to guide you to a solution to your problem. So feel encouraged to provide feedback on misleading or unclear error messages, since we strongly believe that guided errors are essential so that you can stay as lazy as possible.</p>\n</details>\n</details>\n<hr>\n<h2>Contribution</h2>\n<ul>\n<li>Pull requests are encouraged and always welcome. Read <a href=\"https://github.com/ml-tooling/lazycluster/tree/master/CONTRIBUTING.md\" rel=\"nofollow\"><code>CONTRIBUTING.md</code></a> and check out <a href=\"https://github.com/ml-tooling/lazycluster/issues?utf8=%E2%9C%93&amp;q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22+sort%3Areactions-%2B1-desc+\" rel=\"nofollow\">help-wanted</a> issues.</li>\n<li>Submit github issues for any <a href=\"https://github.com/ml-tooling/lazycluster/issues/new?assignees=&amp;labels=feature-request&amp;template=02_feature-request.md&amp;title=\" rel=\"nofollow\">feature enhancements</a>, <a href=\"https://github.com/ml-tooling/lazycluster/issues/new?assignees=&amp;labels=bug&amp;template=01_bug-report.md&amp;title=\" rel=\"nofollow\">bugs</a>, or <a href=\"https://github.com/ml-tooling/lazycluster/issues/new?assignees=&amp;labels=enhancement%2C+docs&amp;template=03_documentation.md&amp;title=\" rel=\"nofollow\">documentation</a> problems.</li>\n<li>By participating in this project you agree to abide by its <a href=\"https://github.com/ml-tooling/lazycluster/tree/master/CODE_OF_CONDUCT.md\" rel=\"nofollow\">Code of Conduct</a>.</li>\n</ul>\n<hr>\n<p>Licensed <strong>Apache 2.0</strong>. Created and maintained with \u2764\ufe0f by developers from SAP in Berlin.</p>\n<p>Requirements:\n['fabric &gt;= 2.2', 'stormssh', 'cloudpickle &gt;= 1.0.0', 'psutil', 'click-spinner']</p>\n\n          </div>"}, "last_serial": 6577131, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "f3089d5d9d735bfd49733d953358fd07", "sha256": "7891266935f853b78d1e3831b00ada097850fb39bce7ea2d8eec7187d9c4c869"}, "downloads": -1, "filename": "lazycluster-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "f3089d5d9d735bfd49733d953358fd07", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 33384, "upload_time": "2019-08-09T15:19:02", "upload_time_iso_8601": "2019-08-09T15:19:02.817284Z", "url": "https://files.pythonhosted.org/packages/39/93/bdf27d439d43d404bb1e29edd517096aa0a37a55fea7e1522fb90e712af7/lazycluster-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ab7268dd16a25efa5fabe40d5fa08aea", "sha256": "f04202d4f87e0c843d3570f1429282dcd9a2282b544a0d9ab70e70ef2ef0cc22"}, "downloads": -1, "filename": "lazycluster-0.1.0.tar.gz", "has_sig": false, "md5_digest": "ab7268dd16a25efa5fabe40d5fa08aea", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 27389, "upload_time": "2019-08-09T15:19:05", "upload_time_iso_8601": "2019-08-09T15:19:05.885184Z", "url": "https://files.pythonhosted.org/packages/96/b4/02156a7e60103ffc12baabfedd9eadde1e738cd7309d66dbfcbbeb745de0/lazycluster-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "d5a456a82d8a30e011177e04456a8524", "sha256": "9bdc22e4bee71e16666f6d2acbc6c7b536216264db450a74303d161ad3df947e"}, "downloads": -1, "filename": "lazycluster-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "d5a456a82d8a30e011177e04456a8524", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 36456, "upload_time": "2019-08-19T12:12:55", "upload_time_iso_8601": "2019-08-19T12:12:55.656210Z", "url": "https://files.pythonhosted.org/packages/de/bc/a3884ecd233a2fdab89936b9b6fc8e786eecb8ff77691cb6368998e09f7f/lazycluster-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "23b8ac8ba1a17ec231f6788c3a4a6289", "sha256": "3803d97e25147494079d631303252874a0f4e9df12fba9f6594484707a223d1a"}, "downloads": -1, "filename": "lazycluster-0.1.1.tar.gz", "has_sig": false, "md5_digest": "23b8ac8ba1a17ec231f6788c3a4a6289", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 30612, "upload_time": "2019-08-19T12:12:57", "upload_time_iso_8601": "2019-08-19T12:12:57.540490Z", "url": "https://files.pythonhosted.org/packages/16/3b/97798d74f4d80b9a1aa39cfc322a4cbf8e7a1b40207aa73b4ab535e48164/lazycluster-0.1.1.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "60ee899239c2b83733b4c4d70c7e8b5d", "sha256": "9fb1a5a6c25bcfe70fe8efb326e20d77d8d45aeea41b41f1f1078d2ef940007c"}, "downloads": -1, "filename": "lazycluster-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "60ee899239c2b83733b4c4d70c7e8b5d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 69422, "upload_time": "2020-02-05T17:05:02", "upload_time_iso_8601": "2020-02-05T17:05:02.851757Z", "url": "https://files.pythonhosted.org/packages/10/5a/19984a6af07259e6a9048dcf31cb7fb4b32bde1132fc844dbc614b3dccb7/lazycluster-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "82df55a2675ec00e9d7420b1fdb63597", "sha256": "9ff2709ce56dfe06feb7a720a98650d08511b07ae62abc72a55d34ce6b99f0bb"}, "downloads": -1, "filename": "lazycluster-0.2.0.tar.gz", "has_sig": false, "md5_digest": "82df55a2675ec00e9d7420b1fdb63597", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 83478, "upload_time": "2020-02-05T17:05:05", "upload_time_iso_8601": "2020-02-05T17:05:05.329528Z", "url": "https://files.pythonhosted.org/packages/22/28/21b44a05e6d111ad7fa567df8721c4336db7775c6683f7c99b5ec2a1b6b4/lazycluster-0.2.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "60ee899239c2b83733b4c4d70c7e8b5d", "sha256": "9fb1a5a6c25bcfe70fe8efb326e20d77d8d45aeea41b41f1f1078d2ef940007c"}, "downloads": -1, "filename": "lazycluster-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "60ee899239c2b83733b4c4d70c7e8b5d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 69422, "upload_time": "2020-02-05T17:05:02", "upload_time_iso_8601": "2020-02-05T17:05:02.851757Z", "url": "https://files.pythonhosted.org/packages/10/5a/19984a6af07259e6a9048dcf31cb7fb4b32bde1132fc844dbc614b3dccb7/lazycluster-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "82df55a2675ec00e9d7420b1fdb63597", "sha256": "9ff2709ce56dfe06feb7a720a98650d08511b07ae62abc72a55d34ce6b99f0bb"}, "downloads": -1, "filename": "lazycluster-0.2.0.tar.gz", "has_sig": false, "md5_digest": "82df55a2675ec00e9d7420b1fdb63597", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 83478, "upload_time": "2020-02-05T17:05:05", "upload_time_iso_8601": "2020-02-05T17:05:05.329528Z", "url": "https://files.pythonhosted.org/packages/22/28/21b44a05e6d111ad7fa567df8721c4336db7775c6683f7c99b5ec2a1b6b4/lazycluster-0.2.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:47:37 2020"}