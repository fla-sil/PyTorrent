{"info": {"author": "Lilian Besson", "author_email": "naereen@crans.org", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Console", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Operating System :: Unix", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Topic :: Scientific/Engineering", "Topic :: Scientific/Engineering :: Mathematics"], "description": "*SMPyBandits*\n=============\n\n**Open-Source Python package for Single- and Multi-Players multi-armed Bandits algorithms**.\n\nThis repository contains the code of `Lilian Besson\u2019s <http://perso.crans.org/besson/>`__ numerical environment, written in `Python (2 or 3) <https://www.python.org/>`__, for numerical simulations on *single*-player and *multi*-players `Multi-Armed Bandits (MAB) <https://en.wikipedia.org/wiki/Multi-armed_bandit>`__ algorithms.\n\nA complete Sphinx-generated documentation is on `SMPyBandits.GitHub.io <https://smpybandits.github.io/>`__.\n\nQuick presentation\n------------------\n\n*SMPyBandits* contains the most complete collection of single-player (classical) bandit algorithms on the Internet (`over 65! <https://smpybandits.github.io/docs/Policies.html>`__), as well as implementation of all the state-of-the-art `multi-player algorithms <https://smpybandits.github.io/docs/PoliciesMultiPlayers.html>`__.\n\nI follow very actively the latest publications related to Multi-Armed Bandits (MAB) research, and usually implement quite quickly the new algorithms (see for instance, `Exp3++ <https://smpybandits.github.io/docs/Policies.Exp3PlusPlus.html>`__, `CORRAL <https://smpybandits.github.io/docs/Policies.CORRAL.html>`__ and `SparseUCB <https://smpybandits.github.io/docs/Policies.SparseUCB.html>`__ were each introduced by articles (`for Exp3++ <https://arxiv.org/pdf/1702.06103>`__, `for CORRAL <https://arxiv.org/abs/1612.06246v2>`__, `for SparseUCB <https://arxiv.org/abs/1706.01383>`__) presented at COLT in July 2017, `LearnExp <https://smpybandits.github.io/docs/Policies.LearnExp.html>`__ comes from a `NIPS 2017 paper <https://arxiv.org/abs/1702.04825>`__, and `kl-UCB++ <https://smpybandits.github.io/docs/Policies.klUCBPlusPlus.html>`__ from an `ALT 2017 paper <https://hal.inria.fr/hal-01475078>`__.).\n\n-  Classical MAB have a lot of applications, from clinical trials, A/B testing, game tree exploration, and online content recommendation (my framework does *not* implement contextual bandit - yet).\n-  `Multi-player MAB <MultiPlayers.md>`__ have applications in Cognitive Radio, and my framework implements `all the collision models <https://smpybandits.github.io/docs/Environment/CollisionModels.html>`__ found in the literature, as well as all the algorithms from the last 10 years or so (`rhoRand <https://smpybandits.github.io/docs/PoliciesMultiPlayers/rhoRand.html>`__ from 2009, `MEGA <https://smpybandits.github.io/docs/Policies/MEGA.html>`__ from 2015, `MusicalChair <https://smpybandits.github.io/docs/Policies/MusicalChair.html>`__, and our state-of-the-art algorithms `RandTopM <https://smpybandits.github.io/docs/PoliciesMultiPlayers/RandTopM.html>`__ and `MCTopM <https://smpybandits.github.io/docs/PoliciesMultiPlayers/MCTopM.html>`__).\n\nWith this numerical framework, simulations can run on a single CPU or a multi-core machine, and summary plots are automatically saved as high-quality PNG, PDF and EPS (ready for being used in research article). Making new simulations is very easy, one only needs to write a configuration script and basically no code! See `these examples <https://github.com/SMPyBandits/SMPyBandits/search?l=Python&q=configuration&type=&utf8=%E2%9C%93>`__ (files named ``configuration_...py``).\n\nA complete `Sphinx <http://sphinx-doc.org/>`__ documentation for each algorithms and every piece of code (included constants in the configurations!) is available here: `SMPyBandits.GitHub.io <https://smpybandits.github.io/>`__.\n\n|PyPI implementation| |PyPI pyversions| |Maintenance| |Ask Me Anything|\n\n\n.. note::\n\n    - `I (Lilian Besson) <http://perso.crans.org/besson/>`__ have `started my PhD <http://perso.crans.org/besson/phd/>`__ in October 2016, and this is a part of my **on going** research since December 2016.\n    - I launched the `documentation <https://smpybandits.github.io/>`__ on March 2017, I wrote my first research articles using this framework in 2017 and decided to (finally) open-source my project in February 2018.\n\n--------------\n\nHow to cite this work?\n----------------------\n\nIf you use this package for your own work, please consider citing it with `this piece of BibTeX <https://github.com/SMPyBandits/SMPyBandits/raw/master/SMPyBandits.bib>`__:\n\n.. code:: bibtex\n\n    @misc{SMPyBandits,\n        title =   {{SMPyBandits: an Open-Source Research Framework for Single and Multi-Players Multi-Arms Bandits (MAB) Algorithms in Python}},\n        author =  {Lilian Besson},\n        year =    {2018},\n        url =     {https://github.com/SMPyBandits/SMPyBandits/},\n        howpublished = {Online at: \\url{github.com/SMPyBandits/SMPyBandits}},\n        note =    {Code at https://github.com/SMPyBandits/SMPyBandits/, documentation at https://smpybandits.github.io/}\n    }\n\nI also wrote a small paper to present *SMPyBandits*, and I will send it to `JMLR MLOSS <http://jmlr.org/mloss/>`__. The paper can be consulted `here on my website <https://perso.crans.org/besson/articles/SMPyBandits.pdf>`__.\n\n--------------\n\nOther interesting things\n------------------------\n\n`Single-player Policies <https://smpybandits.github.io/docs/Policies.html>`__\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n-  More than 65 algorithms, including all known variants of the `UCB <https://smpybandits.github.io/docs/Policies/UCB.html>`__, `kl-UCB <https://smpybandits.github.io/docs/Policies/klUCB.html>`__, `MOSS <https://smpybandits.github.io/docs/Policies/MOSS.html>`__ and `Thompson Sampling <https://smpybandits.github.io/docs/Policies/Thompson.html>`__ algorithms, as well as other less known algorithms (`OCUCB <https://smpybandits.github.io/docs/Policies/OCUCB.html>`__, `BESA <https://smpybandits.github.io/docs/Policies/OCUCB.html>`__, `OSSB <https://smpybandits.github.io/docs/Policies/OSSB.html>`__ etc).\n-  `SparseWrapper <https://smpybandits.github.io/docs/Policies.SparseWrapper.html#module-Policies.SparseWrapper>`__ is a generalization of `the SparseUCB from this article <https://arxiv.org/pdf/1706.01383/>`__.\n-  Implementation of very recent Multi-Armed Bandits algorithms, e.g., `kl-UCB++ <https://smpybandits.github.io/docs/Policies.klUCBPlusPlus.html>`__ (from `this article <https://hal.inria.fr/hal-01475078>`__), `UCB-dagger <https://smpybandits.github.io/docs/Policies.UCBdagger.html>`__ (from `this article <https://arxiv.org/pdf/1507.07880>`__), or `MOSS-anytime <https://smpybandits.github.io/docs/Policies.MOSSAnytime.html>`__ (from `this article <http://proceedings.mlr.press/v48/degenne16.pdf>`__).\n-  Experimental policies: `BlackBoxOpt <https://smpybandits.github.io/docs/Policies.BlackBoxOpt.html>`__ or `UnsupervisedLearning <https://smpybandits.github.io/docs/Policies.UnsupervisedLearning.html>`__ (using Gaussian processes to learn the arms distributions).\n\nArms and problems\n~~~~~~~~~~~~~~~~~\n\n-  My framework mainly targets stochastic bandits, with arms following\n   `Bernoulli <https://smpybandits.github.io/docs/Arms/Bernoulli.html>`__, bounded\n   (SMPyBandits/truncated) or unbounded\n   `Gaussian <https://smpybandits.github.io/docs/Arms/Gaussian.html>`__,\n   `Exponential <https://smpybandits.github.io/docs/Arms/Exponential.html>`__,\n   `Gamma <https://smpybandits.github.io/docs/Arms/Gamma.html>`__ or\n   `Poisson <https://smpybandits.github.io/docs/Arms/Poisson.html>`__ distributions.\n-  The default configuration is to use a fixed problem for N repetitions (e.g. 1000 repetitions, use `MAB.MAB <https://smpybandits.github.io/docs/Environment/MAB.html>`__), but there is also a perfect support for \"Bayesian\" problems where the mean vector \u00b51,\u2026,\u00b5K change *at every repetition* (see `MAB.DynamicMAB <https://smpybandits.github.io/docs/Environment/MAB.html>`__).\n-  There is also a good support for Markovian problems, see `MAB.MarkovianMAB <https://smpybandits.github.io/docs/Environment/MAB.html>`__, even though I didn\u2019t implement any policies tailored for Markovian problems.\n\nOther remarks\n~~~~~~~~~~~~~\n\n-  Everything here is done in an imperative, object oriented style. The API of the Arms, Policy and MultiPlayersPolicy classes is documented `in this page <https://smpybandits.github.io/API.html>`__.\n-  The code is `clean <https://smpybandits.github.io/logs/main_pylint_log.txt>`__, valid for both `Python 2 <https://smpybandits.github.io/logs/main_pylint_log.txt>`__ and `Python 3 <https://smpybandits.github.io/logs/main_pylint3_log.txt>`__.\n-  Some piece of code come from the `pymaBandits <http://mloss.org/software/view/415/>`__ project, but most of them were refactored. Thanks to the initial project!\n-  `G.Varoquaux <http://gael-varoquaux.info/>`__\\ \u2019s `joblib <https://joblib.readthedocs.io/>`__ is used for the `Evaluator <https://smpybandits.github.io/docs/Environment/Evaluator.html>`__ and `EvaluatorMultiPlayers <https://smpybandits.github.io/docs/Environment/EvaluatorMultiPlayers.html>`__ classes, so the simulations are easily parallelized on multi-core machines. (Put ``n_jobs = -1`` or ``PARALLEL = True`` in the config file to use all your CPU cores, as it is by default).\n\n--------------\n\n`How to run the experiments ? <How_to_run_the_code.md>`__\n---------------------------------------------------------\n\n    See this document: `How_to_run_the_code.md <https://smpybandits.github.io/How_to_run_the_code.html>`__ for more details.\n\nTL;DR: this short bash snippet shows how to clone the code, install the requirements for Python 3 (in a `virtualenv <https://virtualenv.pypa.io/en/stable/>`__, and starts some simulation for N=100 repetitions of the default non-Bayesian Bernoulli-distributed problem, for K=9 arms, an horizon of T=10000 and on 4 CPUs (it should take about 20 minutes for each simulations):\n\n.. code:: bash\n\n    cd /tmp/\n    # just be sure you have the latest virtualenv from Python 3\n    sudo pip3 install --upgrade --force-reinstall virtualenv\n\n    # create and active the virtualenv\n    virtualenv venv\n    . venv/bin/activate\n    type pip  # check it is /tmp/venv/bin/pip\n    type python  # check it is /tmp/venv/bin/python\n\n    pip install SMPyBandits  # pulls latest version from https://pypi.org/project/SMPyBandits/\n    # or you can also\n    pip install git+https://github.com/SMPyBandits/SMPyBandits/#egg=SMPyBandits[full]  # pulls latest version from https://github.com/SMPyBandits/SMPyBandits/\n\n    # run a single-player simulation!\n    N=100 T=10000 K=9 N_JOBS=4 make single\n    # run a multi-player simulation!\n    N=100 T=10000 M=3 K=9 N_JOBS=4 make more\n\n..\n\n-  If speed matters to you and you want to use algorithms based on `kl-UCB <https://smpybandits.github.io/docs/Policies/klUCB.html>`__, you should take the time to build and install the fast C implementation of the utilities KL functions. Default is to use `kullback.py <https://smpybandits.github.io/docs/Policies/kullback.html>`__, but using `the C version from Policies/C/ <github.com/SMPyBandits/SMPyBandits/tree/master/SMPyBandits/Policies/C/>`__ really speeds up the computations. Just follow the instructions, it should work well (you need ``gcc`` to be installed).\n-  And if speed matters, be sure that you have a working version of `Numba <https://numba.pydata.org/>`__, it is used by many small functions to (try to automatically) speed up the computations.\n\n--------------\n\nWarning\n~~~~~~~\n\n-  This work is still **experimental**! It\u2019s `active research <https://github.com/SMPyBandits/SMPyBandits/graphs/contributors>`__. It should be completely bug free and every single module/file should work perfectly(as `this pylint log <https://smpybandits.github.io/logs/main_pylint_log.txt>`__ and `this other one <https://smpybandits.github.io/logs/main_pylint3_log.txt>`__ says), but bugs are sometimes hard to spot so if you encounter any issue, `please fill a bug ticket <https://github.com/SMPyBandits/SMPyBandits/issues/new>`__.\n-  Whenever I add a new feature, I run experiments to check that nothing is broken. But *there is no unittest* (I don\u2019t have time). You would have to trust me!\n-  This project is NOT meant to be a library that you can use elsewhere, but a research tool. In particular, I don\u2019t take ensure that any of the Python modules can be imported from another directory than the main directory.\n\nContributing?\n-------------\n\nContributions (issues, questions, pull requests) are of course welcome, but this project is and will stay a personal environment designed for quick research experiments, and will never try to be an industry-ready module for applications of Multi-Armed Bandits algorithms.\n\nIf you want to contribute, please have a look to the `CONTRIBUTING <https://smpybandits.github.io/CONTRIBUTING.html>`__ page, and if you want to be more seriously involved, read the `CODE_OF_CONDUCT <https://smpybandits.github.io/CODE_OF_CONDUCT.html>`__ page.\n\n-  You are welcome to `submit an issue <https://github.com/SMPyBandits/SMPyBandits/issues/new>`__, if it was not previously answered,\n-  If you have interesting example of use of SMPyBandits, please share it! (`Jupyter Notebooks <https://www.jupyter.org/>`__ are preferred). And fill a pull request to `add it to the notebooks examples <https://smpybandits.github.io/notebooks/README.html>`__.\n\n--------------\n\nLicense ? |GitHub license|\n--------------------------\n\n`MIT Licensed <https://lbesson.mit-license.org/>`__ (file `LICENSE <https://smpybandits.github.io/LICENSE>`__).\n\n\u00a9 2016-2018 `Lilian Besson <https://GitHub.com/Naereen>`__.\n\n|Maintenance| |Ask Me Anything| |Analytics| |PyPI implementation|\n|PyPI pyversions| |Documentation Status| |ForTheBadge uses-badges| |ForTheBadge uses-git|\n\n|forthebadge made-with-python| |ForTheBadge built-with-science|\n\n.. |PyPI implementation| image:: https://img.shields.io/pypi/implementation/smpybandits.svg\n.. |PyPI pyversions| image:: https://img.shields.io/pypi/pyversions/smpybandits.svg\n.. |Maintenance| image:: https://img.shields.io/badge/Maintained%3F-yes-green.svg\n   :target: https://GitHub.com/SMPyBandits/SMPyBandits/graphs/commit-activity\n.. |Ask Me Anything| image:: https://img.shields.io/badge/Ask%20me-anything-1abc9c.svg\n   :target: https://GitHub.com/Naereen/ama\n.. |GitHub license| image:: https://img.shields.io/github/license/SMPyBandits/SMPyBandits.svg\n   :target: https://github.com/SMPyBandits/SMPyBandits/blob/master/LICENSE\n.. |Analytics| image:: https://ga-beacon.appspot.com/UA-38514290-17/github.com/SMPyBandits/SMPyBandits/README.md?pixel\n   :target: https://GitHub.com/SMPyBandits/SMPyBandits/\n.. |Documentation Status| image:: https://readthedocs.org/projects/smpybandits/badge/?version=latest\n   :target: https://smpybandits.readthedocs.io/en/latest/?badge=latest\n.. |ForTheBadge uses-badges| image:: http://ForTheBadge.com/images/badges/uses-badges.svg\n   :target: http://ForTheBadge.com\n.. |ForTheBadge uses-git| image:: http://ForTheBadge.com/images/badges/uses-git.svg\n   :target: https://GitHub.com/\n.. |forthebadge made-with-python| image:: http://ForTheBadge.com/images/badges/made-with-python.svg\n   :target: https://www.python.org/\n.. |ForTheBadge built-with-science| image:: http://ForTheBadge.com/images/badges/built-with-science.svg\n   :target: https://GitHub.com/Naereen/\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "https://github.com/SMPyBandits/SMPyBandits/releases/", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/SMPyBandits/SMPyBandits/", "keywords": "multi-arm-bandits simulations learning-theory centralized-algorithms decentralized-algorithms cognitive-radio", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "SMPyBandits", "package_url": "https://pypi.org/project/SMPyBandits/", "platform": "GNU/Linux", "project_url": "https://pypi.org/project/SMPyBandits/", "project_urls": {"Bug Reports": "https://github.com/SMPyBandits/SMPyBandits/issues", "Documentation": "https://smpybandits.github.io/", "Download": "https://github.com/SMPyBandits/SMPyBandits/releases/", "Homepage": "https://github.com/SMPyBandits/SMPyBandits/", "Source": "https://github.com/SMPyBandits/SMPyBandits/tree/master/"}, "release_url": "https://pypi.org/project/SMPyBandits/0.9.7/", "requires_dist": ["numpy", "scipy (>0.9)", "matplotlib (>=2)", "joblib", "seaborn", "scikit-learn", "scikit-optimize", "sphinx-rtd-theme ; extra == 'doc'", "recommonmark ; extra == 'doc'", "nbsphinx ; extra == 'doc'", "pyreverse ; extra == 'doc'", "tqdm ; extra == 'full'", "numba ; extra == 'full'", "docopt ; extra == 'full'", "ipython ; extra == 'full'"], "requires_python": "", "summary": "SMPyBandits: Open-Source Python package for Single- and Multi-Players multi-armed Bandits algorithms.", "version": "0.9.7", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><strong>Open-Source Python package for Single- and Multi-Players multi-armed Bandits algorithms</strong>.</p>\n<p>This repository contains the code of <a href=\"http://perso.crans.org/besson/\" rel=\"nofollow\">Lilian Besson\u2019s</a> numerical environment, written in <a href=\"https://www.python.org/\" rel=\"nofollow\">Python (2 or 3)</a>, for numerical simulations on <em>single</em>-player and <em>multi</em>-players <a href=\"https://en.wikipedia.org/wiki/Multi-armed_bandit\" rel=\"nofollow\">Multi-Armed Bandits (MAB)</a> algorithms.</p>\n<p>A complete Sphinx-generated documentation is on <a href=\"https://smpybandits.github.io/\" rel=\"nofollow\">SMPyBandits.GitHub.io</a>.</p>\n<div id=\"quick-presentation\">\n<h2>Quick presentation</h2>\n<p><em>SMPyBandits</em> contains the most complete collection of single-player (classical) bandit algorithms on the Internet (<a href=\"https://smpybandits.github.io/docs/Policies.html\" rel=\"nofollow\">over 65!</a>), as well as implementation of all the state-of-the-art <a href=\"https://smpybandits.github.io/docs/PoliciesMultiPlayers.html\" rel=\"nofollow\">multi-player algorithms</a>.</p>\n<p>I follow very actively the latest publications related to Multi-Armed Bandits (MAB) research, and usually implement quite quickly the new algorithms (see for instance, <a href=\"https://smpybandits.github.io/docs/Policies.Exp3PlusPlus.html\" rel=\"nofollow\">Exp3++</a>, <a href=\"https://smpybandits.github.io/docs/Policies.CORRAL.html\" rel=\"nofollow\">CORRAL</a> and <a href=\"https://smpybandits.github.io/docs/Policies.SparseUCB.html\" rel=\"nofollow\">SparseUCB</a> were each introduced by articles (<a href=\"https://arxiv.org/pdf/1702.06103\" rel=\"nofollow\">for Exp3++</a>, <a href=\"https://arxiv.org/abs/1612.06246v2\" rel=\"nofollow\">for CORRAL</a>, <a href=\"https://arxiv.org/abs/1706.01383\" rel=\"nofollow\">for SparseUCB</a>) presented at COLT in July 2017, <a href=\"https://smpybandits.github.io/docs/Policies.LearnExp.html\" rel=\"nofollow\">LearnExp</a> comes from a <a href=\"https://arxiv.org/abs/1702.04825\" rel=\"nofollow\">NIPS 2017 paper</a>, and <a href=\"https://smpybandits.github.io/docs/Policies.klUCBPlusPlus.html\" rel=\"nofollow\">kl-UCB++</a> from an <a href=\"https://hal.inria.fr/hal-01475078\" rel=\"nofollow\">ALT 2017 paper</a>.).</p>\n<ul>\n<li>Classical MAB have a lot of applications, from clinical trials, A/B testing, game tree exploration, and online content recommendation (my framework does <em>not</em> implement contextual bandit - yet).</li>\n<li><a href=\"MultiPlayers.md\" rel=\"nofollow\">Multi-player MAB</a> have applications in Cognitive Radio, and my framework implements <a href=\"https://smpybandits.github.io/docs/Environment/CollisionModels.html\" rel=\"nofollow\">all the collision models</a> found in the literature, as well as all the algorithms from the last 10 years or so (<a href=\"https://smpybandits.github.io/docs/PoliciesMultiPlayers/rhoRand.html\" rel=\"nofollow\">rhoRand</a> from 2009, <a href=\"https://smpybandits.github.io/docs/Policies/MEGA.html\" rel=\"nofollow\">MEGA</a> from 2015, <a href=\"https://smpybandits.github.io/docs/Policies/MusicalChair.html\" rel=\"nofollow\">MusicalChair</a>, and our state-of-the-art algorithms <a href=\"https://smpybandits.github.io/docs/PoliciesMultiPlayers/RandTopM.html\" rel=\"nofollow\">RandTopM</a> and <a href=\"https://smpybandits.github.io/docs/PoliciesMultiPlayers/MCTopM.html\" rel=\"nofollow\">MCTopM</a>).</li>\n</ul>\n<p>With this numerical framework, simulations can run on a single CPU or a multi-core machine, and summary plots are automatically saved as high-quality PNG, PDF and EPS (ready for being used in research article). Making new simulations is very easy, one only needs to write a configuration script and basically no code! See <a href=\"https://github.com/SMPyBandits/SMPyBandits/search?l=Python&amp;q=configuration&amp;type=&amp;utf8=%E2%9C%93\" rel=\"nofollow\">these examples</a> (files named <tt><span class=\"pre\">configuration_...py</span></tt>).</p>\n<p>A complete <a href=\"http://sphinx-doc.org/\" rel=\"nofollow\">Sphinx</a> documentation for each algorithms and every piece of code (included constants in the configurations!) is available here: <a href=\"https://smpybandits.github.io/\" rel=\"nofollow\">SMPyBandits.GitHub.io</a>.</p>\n<p><img alt=\"PyPI implementation\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ab606b8d94e5e83be581e0812ea4fdc56566aefb/68747470733a2f2f696d672e736869656c64732e696f2f707970692f696d706c656d656e746174696f6e2f736d707962616e646974732e737667\"> <img alt=\"PyPI pyversions\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f24a4f353b8b5b63736eab6eefffc58d1c4ec7bf/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f736d707962616e646974732e737667\"> <a href=\"https://GitHub.com/SMPyBandits/SMPyBandits/graphs/commit-activity\" rel=\"nofollow\"><img alt=\"Maintenance\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/90bf1b2a4d99698c4dffbc494b9734690a777fec/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d61696e7461696e65642533462d7965732d677265656e2e737667\"></a> <a href=\"https://GitHub.com/Naereen/ama\" rel=\"nofollow\"><img alt=\"Ask Me Anything\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3e0b9eb17e703b59a8d52789d632dbbd15dbaca1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f41736b2532306d652d616e797468696e672d3161626339632e737667\"></a></p>\n<div>\n<p>Note</p>\n<ul>\n<li><a href=\"http://perso.crans.org/besson/\" rel=\"nofollow\">I (Lilian Besson)</a> have <a href=\"http://perso.crans.org/besson/phd/\" rel=\"nofollow\">started my PhD</a> in October 2016, and this is a part of my <strong>on going</strong> research since December 2016.</li>\n<li>I launched the <a href=\"https://smpybandits.github.io/\" rel=\"nofollow\">documentation</a> on March 2017, I wrote my first research articles using this framework in 2017 and decided to (finally) open-source my project in February 2018.</li>\n</ul>\n</div>\n</div>\n<hr class=\"docutils\">\n<div id=\"how-to-cite-this-work\">\n<h2>How to cite this work?</h2>\n<p>If you use this package for your own work, please consider citing it with <a href=\"https://github.com/SMPyBandits/SMPyBandits/raw/master/SMPyBandits.bib\" rel=\"nofollow\">this piece of BibTeX</a>:</p>\n<pre><span class=\"nc\">@misc</span><span class=\"p\">{</span><span class=\"nl\">SMPyBandits</span><span class=\"p\">,</span>\n    <span class=\"na\">title</span> <span class=\"p\">=</span>   <span class=\"s\">{{SMPyBandits: an Open-Source Research Framework for Single and Multi-Players Multi-Arms Bandits (MAB) Algorithms in Python}}</span><span class=\"p\">,</span>\n    <span class=\"na\">author</span> <span class=\"p\">=</span>  <span class=\"s\">{Lilian Besson}</span><span class=\"p\">,</span>\n    <span class=\"na\">year</span> <span class=\"p\">=</span>    <span class=\"s\">{2018}</span><span class=\"p\">,</span>\n    <span class=\"na\">url</span> <span class=\"p\">=</span>     <span class=\"s\">{https://github.com/SMPyBandits/SMPyBandits/}</span><span class=\"p\">,</span>\n    <span class=\"na\">howpublished</span> <span class=\"p\">=</span> <span class=\"s\">{Online at: \\url{github.com/SMPyBandits/SMPyBandits}}</span><span class=\"p\">,</span>\n    <span class=\"na\">note</span> <span class=\"p\">=</span>    <span class=\"s\">{Code at https://github.com/SMPyBandits/SMPyBandits/, documentation at https://smpybandits.github.io/}</span>\n<span class=\"p\">}</span>\n</pre>\n<p>I also wrote a small paper to present <em>SMPyBandits</em>, and I will send it to <a href=\"http://jmlr.org/mloss/\" rel=\"nofollow\">JMLR MLOSS</a>. The paper can be consulted <a href=\"https://perso.crans.org/besson/articles/SMPyBandits.pdf\" rel=\"nofollow\">here on my website</a>.</p>\n</div>\n<hr class=\"docutils\">\n<div id=\"other-interesting-things\">\n<h2>Other interesting things</h2>\n<div id=\"single-player-policies\">\n<h3><a href=\"https://smpybandits.github.io/docs/Policies.html\" rel=\"nofollow\">Single-player Policies</a></h3>\n<ul>\n<li>More than 65 algorithms, including all known variants of the <a href=\"https://smpybandits.github.io/docs/Policies/UCB.html\" rel=\"nofollow\">UCB</a>, <a href=\"https://smpybandits.github.io/docs/Policies/klUCB.html\" rel=\"nofollow\">kl-UCB</a>, <a href=\"https://smpybandits.github.io/docs/Policies/MOSS.html\" rel=\"nofollow\">MOSS</a> and <a href=\"https://smpybandits.github.io/docs/Policies/Thompson.html\" rel=\"nofollow\">Thompson Sampling</a> algorithms, as well as other less known algorithms (<a href=\"https://smpybandits.github.io/docs/Policies/OCUCB.html\" rel=\"nofollow\">OCUCB</a>, <a href=\"https://smpybandits.github.io/docs/Policies/OCUCB.html\" rel=\"nofollow\">BESA</a>, <a href=\"https://smpybandits.github.io/docs/Policies/OSSB.html\" rel=\"nofollow\">OSSB</a> etc).</li>\n<li><a href=\"https://smpybandits.github.io/docs/Policies.SparseWrapper.html#module-Policies.SparseWrapper\" rel=\"nofollow\">SparseWrapper</a> is a generalization of <a href=\"https://arxiv.org/pdf/1706.01383/\" rel=\"nofollow\">the SparseUCB from this article</a>.</li>\n<li>Implementation of very recent Multi-Armed Bandits algorithms, e.g., <a href=\"https://smpybandits.github.io/docs/Policies.klUCBPlusPlus.html\" rel=\"nofollow\">kl-UCB++</a> (from <a href=\"https://hal.inria.fr/hal-01475078\" rel=\"nofollow\">this article</a>), <a href=\"https://smpybandits.github.io/docs/Policies.UCBdagger.html\" rel=\"nofollow\">UCB-dagger</a> (from <a href=\"https://arxiv.org/pdf/1507.07880\" rel=\"nofollow\">this article</a>), or <a href=\"https://smpybandits.github.io/docs/Policies.MOSSAnytime.html\" rel=\"nofollow\">MOSS-anytime</a> (from <a href=\"http://proceedings.mlr.press/v48/degenne16.pdf\" rel=\"nofollow\">this article</a>).</li>\n<li>Experimental policies: <a href=\"https://smpybandits.github.io/docs/Policies.BlackBoxOpt.html\" rel=\"nofollow\">BlackBoxOpt</a> or <a href=\"https://smpybandits.github.io/docs/Policies.UnsupervisedLearning.html\" rel=\"nofollow\">UnsupervisedLearning</a> (using Gaussian processes to learn the arms distributions).</li>\n</ul>\n</div>\n<div id=\"arms-and-problems\">\n<h3>Arms and problems</h3>\n<ul>\n<li>My framework mainly targets stochastic bandits, with arms following\n<a href=\"https://smpybandits.github.io/docs/Arms/Bernoulli.html\" rel=\"nofollow\">Bernoulli</a>, bounded\n(SMPyBandits/truncated) or unbounded\n<a href=\"https://smpybandits.github.io/docs/Arms/Gaussian.html\" rel=\"nofollow\">Gaussian</a>,\n<a href=\"https://smpybandits.github.io/docs/Arms/Exponential.html\" rel=\"nofollow\">Exponential</a>,\n<a href=\"https://smpybandits.github.io/docs/Arms/Gamma.html\" rel=\"nofollow\">Gamma</a> or\n<a href=\"https://smpybandits.github.io/docs/Arms/Poisson.html\" rel=\"nofollow\">Poisson</a> distributions.</li>\n<li>The default configuration is to use a fixed problem for N repetitions (e.g. 1000 repetitions, use <a href=\"https://smpybandits.github.io/docs/Environment/MAB.html\" rel=\"nofollow\">MAB.MAB</a>), but there is also a perfect support for \u201cBayesian\u201d problems where the mean vector \u00b51,\u2026,\u00b5K change <em>at every repetition</em> (see <a href=\"https://smpybandits.github.io/docs/Environment/MAB.html\" rel=\"nofollow\">MAB.DynamicMAB</a>).</li>\n<li>There is also a good support for Markovian problems, see <a href=\"https://smpybandits.github.io/docs/Environment/MAB.html\" rel=\"nofollow\">MAB.MarkovianMAB</a>, even though I didn\u2019t implement any policies tailored for Markovian problems.</li>\n</ul>\n</div>\n<div id=\"other-remarks\">\n<h3>Other remarks</h3>\n<ul>\n<li>Everything here is done in an imperative, object oriented style. The API of the Arms, Policy and MultiPlayersPolicy classes is documented <a href=\"https://smpybandits.github.io/API.html\" rel=\"nofollow\">in this page</a>.</li>\n<li>The code is <a href=\"https://smpybandits.github.io/logs/main_pylint_log.txt\" rel=\"nofollow\">clean</a>, valid for both <a href=\"https://smpybandits.github.io/logs/main_pylint_log.txt\" rel=\"nofollow\">Python 2</a> and <a href=\"https://smpybandits.github.io/logs/main_pylint3_log.txt\" rel=\"nofollow\">Python 3</a>.</li>\n<li>Some piece of code come from the <a href=\"http://mloss.org/software/view/415/\" rel=\"nofollow\">pymaBandits</a> project, but most of them were refactored. Thanks to the initial project!</li>\n<li><a href=\"http://gael-varoquaux.info/\" rel=\"nofollow\">G.Varoquaux</a>\u2019s <a href=\"https://joblib.readthedocs.io/\" rel=\"nofollow\">joblib</a> is used for the <a href=\"https://smpybandits.github.io/docs/Environment/Evaluator.html\" rel=\"nofollow\">Evaluator</a> and <a href=\"https://smpybandits.github.io/docs/Environment/EvaluatorMultiPlayers.html\" rel=\"nofollow\">EvaluatorMultiPlayers</a> classes, so the simulations are easily parallelized on multi-core machines. (Put <tt>n_jobs = <span class=\"pre\">-1</span></tt> or <tt>PARALLEL = True</tt> in the config file to use all your CPU cores, as it is by default).</li>\n</ul>\n</div>\n</div>\n<hr class=\"docutils\">\n<div id=\"how-to-run-the-experiments\">\n<h2><a href=\"How_to_run_the_code.md\" rel=\"nofollow\">How to run the experiments ?</a></h2>\n<blockquote>\nSee this document: <a href=\"https://smpybandits.github.io/How_to_run_the_code.html\" rel=\"nofollow\">How_to_run_the_code.md</a> for more details.</blockquote>\n<p>TL;DR: this short bash snippet shows how to clone the code, install the requirements for Python 3 (in a <a href=\"https://virtualenv.pypa.io/en/stable/\" rel=\"nofollow\">virtualenv</a>, and starts some simulation for N=100 repetitions of the default non-Bayesian Bernoulli-distributed problem, for K=9 arms, an horizon of T=10000 and on 4 CPUs (it should take about 20 minutes for each simulations):</p>\n<pre><span class=\"nb\">cd</span> /tmp/\n<span class=\"c1\"># just be sure you have the latest virtualenv from Python 3\n</span>sudo pip3 install --upgrade --force-reinstall virtualenv\n\n<span class=\"c1\"># create and active the virtualenv\n</span>virtualenv venv\n. venv/bin/activate\n<span class=\"nb\">type</span> pip  <span class=\"c1\"># check it is /tmp/venv/bin/pip\n</span><span class=\"nb\">type</span> python  <span class=\"c1\"># check it is /tmp/venv/bin/python\n</span>\npip install SMPyBandits  <span class=\"c1\"># pulls latest version from https://pypi.org/project/SMPyBandits/\n# or you can also\n</span>pip install git+https://github.com/SMPyBandits/SMPyBandits/#egg<span class=\"o\">=</span>SMPyBandits<span class=\"o\">[</span>full<span class=\"o\">]</span>  <span class=\"c1\"># pulls latest version from https://github.com/SMPyBandits/SMPyBandits/\n</span>\n<span class=\"c1\"># run a single-player simulation!\n</span><span class=\"nv\">N</span><span class=\"o\">=</span><span class=\"m\">100</span> <span class=\"nv\">T</span><span class=\"o\">=</span><span class=\"m\">10000</span> <span class=\"nv\">K</span><span class=\"o\">=</span><span class=\"m\">9</span> <span class=\"nv\">N_JOBS</span><span class=\"o\">=</span><span class=\"m\">4</span> make single\n<span class=\"c1\"># run a multi-player simulation!\n</span><span class=\"nv\">N</span><span class=\"o\">=</span><span class=\"m\">100</span> <span class=\"nv\">T</span><span class=\"o\">=</span><span class=\"m\">10000</span> <span class=\"nv\">M</span><span class=\"o\">=</span><span class=\"m\">3</span> <span class=\"nv\">K</span><span class=\"o\">=</span><span class=\"m\">9</span> <span class=\"nv\">N_JOBS</span><span class=\"o\">=</span><span class=\"m\">4</span> make more\n</pre>\n<ul>\n<li>If speed matters to you and you want to use algorithms based on <a href=\"https://smpybandits.github.io/docs/Policies/klUCB.html\" rel=\"nofollow\">kl-UCB</a>, you should take the time to build and install the fast C implementation of the utilities KL functions. Default is to use <a href=\"https://smpybandits.github.io/docs/Policies/kullback.html\" rel=\"nofollow\">kullback.py</a>, but using <a href=\"github.com/SMPyBandits/SMPyBandits/tree/master/SMPyBandits/Policies/C/\" rel=\"nofollow\">the C version from Policies/C/</a> really speeds up the computations. Just follow the instructions, it should work well (you need <tt>gcc</tt> to be installed).</li>\n<li>And if speed matters, be sure that you have a working version of <a href=\"https://numba.pydata.org/\" rel=\"nofollow\">Numba</a>, it is used by many small functions to (try to automatically) speed up the computations.</li>\n</ul>\n<hr class=\"docutils\">\n<div id=\"warning\">\n<h3>Warning</h3>\n<ul>\n<li>This work is still <strong>experimental</strong>! It\u2019s <a href=\"https://github.com/SMPyBandits/SMPyBandits/graphs/contributors\" rel=\"nofollow\">active research</a>. It should be completely bug free and every single module/file should work perfectly(as <a href=\"https://smpybandits.github.io/logs/main_pylint_log.txt\" rel=\"nofollow\">this pylint log</a> and <a href=\"https://smpybandits.github.io/logs/main_pylint3_log.txt\" rel=\"nofollow\">this other one</a> says), but bugs are sometimes hard to spot so if you encounter any issue, <a href=\"https://github.com/SMPyBandits/SMPyBandits/issues/new\" rel=\"nofollow\">please fill a bug ticket</a>.</li>\n<li>Whenever I add a new feature, I run experiments to check that nothing is broken. But <em>there is no unittest</em> (I don\u2019t have time). You would have to trust me!</li>\n<li>This project is NOT meant to be a library that you can use elsewhere, but a research tool. In particular, I don\u2019t take ensure that any of the Python modules can be imported from another directory than the main directory.</li>\n</ul>\n</div>\n</div>\n<div id=\"contributing\">\n<h2>Contributing?</h2>\n<p>Contributions (issues, questions, pull requests) are of course welcome, but this project is and will stay a personal environment designed for quick research experiments, and will never try to be an industry-ready module for applications of Multi-Armed Bandits algorithms.</p>\n<p>If you want to contribute, please have a look to the <a href=\"https://smpybandits.github.io/CONTRIBUTING.html\" rel=\"nofollow\">CONTRIBUTING</a> page, and if you want to be more seriously involved, read the <a href=\"https://smpybandits.github.io/CODE_OF_CONDUCT.html\" rel=\"nofollow\">CODE_OF_CONDUCT</a> page.</p>\n<ul>\n<li>You are welcome to <a href=\"https://github.com/SMPyBandits/SMPyBandits/issues/new\" rel=\"nofollow\">submit an issue</a>, if it was not previously answered,</li>\n<li>If you have interesting example of use of SMPyBandits, please share it! (<a href=\"https://www.jupyter.org/\" rel=\"nofollow\">Jupyter Notebooks</a> are preferred). And fill a pull request to <a href=\"https://smpybandits.github.io/notebooks/README.html\" rel=\"nofollow\">add it to the notebooks examples</a>.</li>\n</ul>\n</div>\n<hr class=\"docutils\">\n<div id=\"license-github-license\">\n<h2>License ? <a href=\"https://github.com/SMPyBandits/SMPyBandits/blob/master/LICENSE\" rel=\"nofollow\"><img alt=\"GitHub license\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b4fc587b9c215a1025c77409833fbe5a8beed221/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f534d507942616e646974732f534d507942616e646974732e737667\"></a></h2>\n<p><a href=\"https://lbesson.mit-license.org/\" rel=\"nofollow\">MIT Licensed</a> (file <a href=\"https://smpybandits.github.io/LICENSE\" rel=\"nofollow\">LICENSE</a>).</p>\n<p>\u00a9 2016-2018 <a href=\"https://GitHub.com/Naereen\" rel=\"nofollow\">Lilian Besson</a>.</p>\n<p><a href=\"https://GitHub.com/SMPyBandits/SMPyBandits/graphs/commit-activity\" rel=\"nofollow\"><img alt=\"Maintenance\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/90bf1b2a4d99698c4dffbc494b9734690a777fec/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d61696e7461696e65642533462d7965732d677265656e2e737667\"></a> <a href=\"https://GitHub.com/Naereen/ama\" rel=\"nofollow\"><img alt=\"Ask Me Anything\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3e0b9eb17e703b59a8d52789d632dbbd15dbaca1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f41736b2532306d652d616e797468696e672d3161626339632e737667\"></a> <a href=\"https://GitHub.com/SMPyBandits/SMPyBandits/\" rel=\"nofollow\"><img alt=\"Analytics\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f98aa6feb5dbc424bdca12f7e83f70518af23301/68747470733a2f2f67612d626561636f6e2e61707073706f742e636f6d2f55412d33383531343239302d31372f6769746875622e636f6d2f534d507942616e646974732f534d507942616e646974732f524541444d452e6d643f706978656c\"></a> <img alt=\"PyPI implementation\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ab606b8d94e5e83be581e0812ea4fdc56566aefb/68747470733a2f2f696d672e736869656c64732e696f2f707970692f696d706c656d656e746174696f6e2f736d707962616e646974732e737667\">\n<img alt=\"PyPI pyversions\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f24a4f353b8b5b63736eab6eefffc58d1c4ec7bf/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f736d707962616e646974732e737667\"> <a href=\"https://smpybandits.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/295e8e9263ce4ea7cb4d35a280b54f381de0c8a8/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f736d707962616e646974732f62616467652f3f76657273696f6e3d6c6174657374\"></a> <a href=\"http://ForTheBadge.com\" rel=\"nofollow\"><img alt=\"ForTheBadge uses-badges\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a46638f466b6ead87b2934739aa61b02e8a54569/687474703a2f2f466f7254686542616467652e636f6d2f696d616765732f6261646765732f757365732d6261646765732e737667\"></a> <a href=\"https://GitHub.com/\" rel=\"nofollow\"><img alt=\"ForTheBadge uses-git\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fae624a5dfdaa11287995d6492c4b3b2bc16f39e/687474703a2f2f466f7254686542616467652e636f6d2f696d616765732f6261646765732f757365732d6769742e737667\"></a></p>\n<p><a href=\"https://www.python.org/\" rel=\"nofollow\"><img alt=\"forthebadge made-with-python\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c389fc25d835c23e3f833bf61244db7530f53e46/687474703a2f2f466f7254686542616467652e636f6d2f696d616765732f6261646765732f6d6164652d776974682d707974686f6e2e737667\"></a> <a href=\"https://GitHub.com/Naereen/\" rel=\"nofollow\"><img alt=\"ForTheBadge built-with-science\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/379ad23390a066780ffd34e85a0c096afcc37a81/687474703a2f2f466f7254686542616467652e636f6d2f696d616765732f6261646765732f6275696c742d776974682d736369656e63652e737667\"></a></p>\n</div>\n\n          </div>"}, "last_serial": 6029551, "releases": {"0.9.2": [{"comment_text": "", "digests": {"md5": "5cec1af4001b13d38f1d2a4deb0613ce", "sha256": "b2c98e3555da59bc8a1ebc427e9a9e8a8604f6cd349ad0f9abf9fbddef668998"}, "downloads": -1, "filename": "SMPyBandits-0.9.2-py2.py3-none-any.whl", "has_sig": true, "md5_digest": "5cec1af4001b13d38f1d2a4deb0613ce", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 401582, "upload_time": "2018-03-07T15:05:14", "upload_time_iso_8601": "2018-03-07T15:05:14.306921Z", "url": "https://files.pythonhosted.org/packages/ef/85/6be28df19f65354fa45fe12f139bf026249cf7f7dfd2e77aadc66ecc4a61/SMPyBandits-0.9.2-py2.py3-none-any.whl", "yanked": false}], "0.9.3": [{"comment_text": "", "digests": {"md5": "ec66bd64df90828ed3554a8ce889a673", "sha256": "52b0f9d3271f5734a2c0abd0f0df6204daac73e1ed6b56457752f5475fa28612"}, "downloads": -1, "filename": "SMPyBandits-0.9.3-py2.py3-none-any.whl", "has_sig": true, "md5_digest": "ec66bd64df90828ed3554a8ce889a673", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 487977, "upload_time": "2018-11-09T21:26:13", "upload_time_iso_8601": "2018-11-09T21:26:13.477931Z", "url": "https://files.pythonhosted.org/packages/14/2d/866590b59fba3c0792060effed3c52ba878c0c3242bdb7163a7108424e1b/SMPyBandits-0.9.3-py2.py3-none-any.whl", "yanked": false}], "0.9.4": [{"comment_text": "", "digests": {"md5": "364fd733796edcb9aa544fce543fdc6e", "sha256": "407c62f3eb8f1e186d9b33263c72aea39f0242a2645da74a5e5b61b019a27edd"}, "downloads": -1, "filename": "SMPyBandits-0.9.4-py2.py3-none-any.whl", "has_sig": true, "md5_digest": "364fd733796edcb9aa544fce543fdc6e", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 487986, "upload_time": "2018-11-09T21:48:13", "upload_time_iso_8601": "2018-11-09T21:48:13.161110Z", "url": "https://files.pythonhosted.org/packages/07/15/440f090019e2f8552726957507370699092f76745ba24d871c65ab6860f8/SMPyBandits-0.9.4-py2.py3-none-any.whl", "yanked": false}], "0.9.5": [{"comment_text": "", "digests": {"md5": "8c7326f5df34118cbae5fc362a7ff4a2", "sha256": "e7864755135123a06e0f9b514b69f9c9a8c5bc366a690cdab29dff0604550c0c"}, "downloads": -1, "filename": "SMPyBandits-0.9.5-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "8c7326f5df34118cbae5fc362a7ff4a2", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 517066, "upload_time": "2019-01-17T09:23:24", "upload_time_iso_8601": "2019-01-17T09:23:24.599723Z", "url": "https://files.pythonhosted.org/packages/e9/1e/6abea2ff26a0978c879a17b133982c0d3025983b1213546411ebdc20cecd/SMPyBandits-0.9.5-py2.py3-none-any.whl", "yanked": false}], "0.9.6": [{"comment_text": "", "digests": {"md5": "43fe96884f2af42c3c2d241934823a1d", "sha256": "e3530ef364f4d178e18673046d9e00d02bb6df0b84a12ce7ce94c99ca8f95bfa"}, "downloads": -1, "filename": "SMPyBandits-0.9.6-py2.py3-none-any.whl", "has_sig": true, "md5_digest": "43fe96884f2af42c3c2d241934823a1d", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 551957, "upload_time": "2019-07-12T09:52:59", "upload_time_iso_8601": "2019-07-12T09:52:59.910643Z", "url": "https://files.pythonhosted.org/packages/ce/7f/dc30ec12e1b3e5b6a03fa0865e3ddd4406a928d1ee720195e5e291b619a6/SMPyBandits-0.9.6-py2.py3-none-any.whl", "yanked": false}], "0.9.7": [{"comment_text": "", "digests": {"md5": "7ac75a69c7e3933db1e46e5b5f76f204", "sha256": "441da15f005519c480ab60f27a73c1b06cfcb8b864d1051adbb9ecdefb17ea7f"}, "downloads": -1, "filename": "SMPyBandits-0.9.7-py2.py3-none-any.whl", "has_sig": true, "md5_digest": "7ac75a69c7e3933db1e46e5b5f76f204", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 552532, "upload_time": "2019-10-25T13:20:44", "upload_time_iso_8601": "2019-10-25T13:20:44.435371Z", "url": "https://files.pythonhosted.org/packages/01/5f/515fffa380f0e381740bca33dfadf1717b2c8a3dc85cae1526d82761e0dd/SMPyBandits-0.9.7-py2.py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "7ac75a69c7e3933db1e46e5b5f76f204", "sha256": "441da15f005519c480ab60f27a73c1b06cfcb8b864d1051adbb9ecdefb17ea7f"}, "downloads": -1, "filename": "SMPyBandits-0.9.7-py2.py3-none-any.whl", "has_sig": true, "md5_digest": "7ac75a69c7e3933db1e46e5b5f76f204", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 552532, "upload_time": "2019-10-25T13:20:44", "upload_time_iso_8601": "2019-10-25T13:20:44.435371Z", "url": "https://files.pythonhosted.org/packages/01/5f/515fffa380f0e381740bca33dfadf1717b2c8a3dc85cae1526d82761e0dd/SMPyBandits-0.9.7-py2.py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 03:07:46 2020"}