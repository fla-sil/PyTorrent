{"info": {"author": "uberVU", "author_email": "development at ubervu com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable"], "description": "hackernews-scraper\r\n        ==================\r\n        \r\n        Scrape [hacker news](https://news.ycombinator.com) comments and posts\r\n        using the [Algolia API](http://hn.algolia.com/api/).\r\n        \r\n        \r\n        Usage\r\n        =====\r\n        \r\n        ```python\r\n        from hackernews-scraper import CommentScraper\r\n        \r\n        CommentScraper.getComments(since=1394039447)\r\n        ```\r\n        \r\n        The above will return a generator that will yield one comment at a time.\r\n        It will keep on going until there are no more comments to fetch, or until\r\n        it reaches the 50 pages limit set by hacker news. In the latter case, a\r\n        `TooManyItemsException` will be raised.\r\n        \r\n        If the hacker news API response is missing any required fields, the scraper\r\n        will raise `KeyError`.\r\n        \r\n        \r\n        Response format\r\n        ===============\r\n        \r\n        Comments:\r\n        ```\r\n        {\r\n         'author': u'dhmholley',\r\n         'comment_id': u'7531026',\r\n         'comment_text': u'Are people still blowing this whistle?...',\r\n         'created_at': u'2014-04-04T12:57:38.000Z',\r\n         'parent_id': 7530853,\r\n         'points': 1,\r\n         'story_id': None,\r\n         'story_title': None,\r\n         'story_url': None,\r\n         'timestamp': 1396616258,\r\n         'title': None,\r\n         'url': None\r\n        }\r\n        ```\r\n        \r\n        Stories:\r\n        ```\r\n        {\r\n         'author': u'sethco',\r\n         'created_at': u'2014-04-04T12:56:23.000Z',\r\n         'objectID': None,\r\n         'points': 1,\r\n         'story_text': 1,\r\n         'timestamp': 1396616183,\r\n         'title': u'Opower IPO today',\r\n         'url': u'http://www.businesswire.com/news/home/20140403006541/en#.Uz4cbq1dVih'\r\n        }\r\n        ```\r\n        \r\n        Testing\r\n        =======\r\n        \r\n        You need to have [httpretty](https://github.com/gabrielfalcao/HTTPretty)\r\n        and [factory-boy](https://github.com/rbarrois/factory_boy) installed.\r\n        \r\n        Run `nosetests` in the root folder or the `tests` folder.", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/NiGhTTraX/hackernews-scraper", "keywords": null, "license": "MIT", "maintainer": null, "maintainer_email": null, "name": "hackernews_scraper", "package_url": "https://pypi.org/project/hackernews_scraper/", "platform": "any", "project_url": "https://pypi.org/project/hackernews_scraper/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/NiGhTTraX/hackernews-scraper"}, "release_url": "https://pypi.org/project/hackernews_scraper/1.0.2/", "requires_dist": null, "requires_python": null, "summary": "Python library for retrieving comments and stories from HackerNews", "version": "1.0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            hackernews-scraper\n<br>        ==================\n<br>        \n<br>        Scrape [hacker news](https://news.ycombinator.com) comments and posts\n<br>        using the [Algolia API](http://hn.algolia.com/api/).\n<br>        \n<br>        \n<br>        Usage\n<br>        =====\n<br>        \n<br>        ```python\n<br>        from hackernews-scraper import CommentScraper\n<br>        \n<br>        CommentScraper.getComments(since=1394039447)\n<br>        ```\n<br>        \n<br>        The above will return a generator that will yield one comment at a time.\n<br>        It will keep on going until there are no more comments to fetch, or until\n<br>        it reaches the 50 pages limit set by hacker news. In the latter case, a\n<br>        `TooManyItemsException` will be raised.\n<br>        \n<br>        If the hacker news API response is missing any required fields, the scraper\n<br>        will raise `KeyError`.\n<br>        \n<br>        \n<br>        Response format\n<br>        ===============\n<br>        \n<br>        Comments:\n<br>        ```\n<br>        {\n<br>         'author': u'dhmholley',\n<br>         'comment_id': u'7531026',\n<br>         'comment_text': u'Are people still blowing this whistle?...',\n<br>         'created_at': u'2014-04-04T12:57:38.000Z',\n<br>         'parent_id': 7530853,\n<br>         'points': 1,\n<br>         'story_id': None,\n<br>         'story_title': None,\n<br>         'story_url': None,\n<br>         'timestamp': 1396616258,\n<br>         'title': None,\n<br>         'url': None\n<br>        }\n<br>        ```\n<br>        \n<br>        Stories:\n<br>        ```\n<br>        {\n<br>         'author': u'sethco',\n<br>         'created_at': u'2014-04-04T12:56:23.000Z',\n<br>         'objectID': None,\n<br>         'points': 1,\n<br>         'story_text': 1,\n<br>         'timestamp': 1396616183,\n<br>         'title': u'Opower IPO today',\n<br>         'url': u'http://www.businesswire.com/news/home/20140403006541/en#.Uz4cbq1dVih'\n<br>        }\n<br>        ```\n<br>        \n<br>        Testing\n<br>        =======\n<br>        \n<br>        You need to have [httpretty](https://github.com/gabrielfalcao/HTTPretty)\n<br>        and [factory-boy](https://github.com/rbarrois/factory_boy) installed.\n<br>        \n<br>        Run `nosetests` in the root folder or the `tests` folder.\n          </div>"}, "last_serial": 1164004, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "5f17d40ca7374338670e9151a294276e", "sha256": "933b7253f3d20f07669987f166d986dc62be5c7b163177df72cfb5a631a7e766"}, "downloads": -1, "filename": "hackernews_scraper-1.0.0.tar.gz", "has_sig": false, "md5_digest": "5f17d40ca7374338670e9151a294276e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4922, "upload_time": "2014-07-11T12:05:59", "upload_time_iso_8601": "2014-07-11T12:05:59.715567Z", "url": "https://files.pythonhosted.org/packages/b6/af/b90a177a31a4a92ed4009ac480230e9511ea4949d95be57a7e966b5da033/hackernews_scraper-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "1d57df555b9384e92977b22a3da5a432", "sha256": "89057baae37168921344516f4b9c574fd47958f6cac14b3cfafaa92d63e2add9"}, "downloads": -1, "filename": "hackernews_scraper-1.0.1.tar.gz", "has_sig": false, "md5_digest": "1d57df555b9384e92977b22a3da5a432", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5312, "upload_time": "2014-07-11T13:08:20", "upload_time_iso_8601": "2014-07-11T13:08:20.970064Z", "url": "https://files.pythonhosted.org/packages/7b/fd/802520a940ccccd5e96d25c8b0c7bb65f4e9722aa81ef2c8c6e5a2c77fac/hackernews_scraper-1.0.1.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "71cab268b526b0997e4e5fdceb744e5b", "sha256": "83e78a533c0db1e4a5288c2d55efa302c5523072c6fbbbafefb00c8b0b51ef3d"}, "downloads": -1, "filename": "hackernews_scraper-1.0.2.tar.gz", "has_sig": false, "md5_digest": "71cab268b526b0997e4e5fdceb744e5b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5360, "upload_time": "2014-07-21T08:34:19", "upload_time_iso_8601": "2014-07-21T08:34:19.672214Z", "url": "https://files.pythonhosted.org/packages/e4/42/248201768b9bceef4fb7e463d9377e45d9c434ef8ac255df857486729383/hackernews_scraper-1.0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "71cab268b526b0997e4e5fdceb744e5b", "sha256": "83e78a533c0db1e4a5288c2d55efa302c5523072c6fbbbafefb00c8b0b51ef3d"}, "downloads": -1, "filename": "hackernews_scraper-1.0.2.tar.gz", "has_sig": false, "md5_digest": "71cab268b526b0997e4e5fdceb744e5b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5360, "upload_time": "2014-07-21T08:34:19", "upload_time_iso_8601": "2014-07-21T08:34:19.672214Z", "url": "https://files.pythonhosted.org/packages/e4/42/248201768b9bceef4fb7e463d9377e45d9c434ef8ac255df857486729383/hackernews_scraper-1.0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:52:50 2020"}