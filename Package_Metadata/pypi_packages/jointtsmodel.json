{"info": {"author": "Ayan Sengupta", "author_email": "ayan.sengupta007@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "## jointtsmodel\n\n[![License](http://img.shields.io/badge/license-MIT-brightgreen.svg?style=flat)](LICENSE.md)\n\nThis is a consolidated library for joint topic-sentiment (jst) models. \n\n### Description\n\nJoint topic-sentiment models extract topical as well as sentiment information for each text. This library contains different jst models - JST, RJST, TSM, sLDA and TSWE.\n\n### Installation\n\n```\ngit clone https://github.com/victor7246/jointtsmodel.git\ncd jointtsmodel\npython setup.py install\n```\n\nOr from pip:\n\n```\npip install jointtsmodel\n```\n\n### Usage\n\nWe can use vectorized texts to run joint topic-sentiment models.\n\n```\nfrom jointtsmodel.RJST import RJST\nfrom jointtsmodel.JST import JST\nfrom jointtsmodel.sLDA import sLDA\nfrom jointtsmodel.TSM import TSM\nfrom jointtsmodel.TSWE import TSWE\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.datasets import fetch_20newsgroups\nfrom jointtsmodel.utils import *\n\n# This produces a feature matrix of token counts, similar to what\n# CountVectorizer would produce on text.\ndata, _ = fetch_20newsgroups(shuffle=True, random_state=1,\n                         remove=('headers', 'footers', 'quotes'),\n                         return_X_y=True)\ndata = data[:1000]\nvectorizer = CountVectorizer(max_df=0.7, min_df=10,\n                            max_features=5000,\n                            stop_words='english')\nX = vectorizer.fit_transform(data)\nvocabulary = vectorizer.get_feature_names()\ninv_vocabulary = dict(zip(vocabulary,np.arange(len(vocabulary))))\nlexicon_data = pd.read_excel('lexicon/prior_sentiment.xlsx')\nlexicon_data = lexicon_data.dropna()\nlexicon_dict = dict(zip(lexicon_data['Word'],lexicon_data['Sentiment']))\n```\n\nFor JST model use\n```\nmodel = JST(n_topic_components=5,n_sentiment_components=5,random_state=123,evaluate_every=2)\nmodel.fit(X.toarray(), lexicon_dict)\n\nmodel.transform()[:2]\n\ntop_words = list(model.getTopKWords(vocabulary).values())\ncoherence_score_uci(X.toarray(),inv_vocabulary,top_words)\nHscore(model.transform())\n```\n\nFor RJST model use\n```\nmodel = RJST(n_topic_components=5,n_sentiment_components=5,random_state=123,evaluate_every=2)\nmodel.fit(X.toarray(), lexicon_dict)\n\nmodel.transform()[:2]\n\ntop_words = list(model.getTopKWords(vocabulary).values())\ncoherence_score_uci(X.toarray(),inv_vocabulary,top_words)\nHscore(model.transform())\n```\n\nFor TSM use\n```\nmodel = TSM(n_topic_components=5,n_sentiment_components=5,random_state=123,evaluate_every=2)\nmodel.fit(X.toarray(), lexicon_dict)\n\nmodel.transform()[:2]\n\ntop_words = list(model.getTopKWords(vocabulary).values())\ncoherence_score_uci(X.toarray(),inv_vocabulary,top_words)\nHscore(model.transform())\n```\n\nFor sLDA model use\n```\nmodel = sLDA(n_topic_components=5,n_sentiment_components=5,random_state=123,evaluate_every=2)\nmodel.fit(X.toarray(), vocabulary)\n\nmodel.transform()[:2]\n\ntop_words = list(model.getTopKWords(vocabulary).values())\ncoherence_score_uci(X.toarray(),inv_vocabulary,top_words)\nHscore(model.transform())\n```\n\nFor TSWE model we need word embedding matrix as an input. \n```\nembeddings_index = {}\nf = open('embeddings/glove.6B.100d.txt','r',encoding='utf8')\n\nfor i, line in enumerate(f):\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\n\nprint('Found %s word vectors.' % len(embeddings_index))\n\nembedding_matrix = np.zeros((X.shape[1], 100))\n\nfor i, word in enumerate(vocabulary):\n    if word in embeddings_index:\n        embedding_matrix[i] = embeddings_index[word]\n    else:\n        embedding_matrix[i] = np.zeros(100)\n```\n\nRun TSWE model\n```\nmodel = TSWE(embedding_dim=100,n_topic_components=5,n_sentiment_components=5,random_state=123,evaluate_every=2)\nmodel.fit(X.toarray(), lexicon_dict, embedding_matrix)\n\nmodel.transform()[:2]\n\ntop_words = list(model.getTopKWords(vocabulary).values())\ncoherence_score_uci(X.toarray(),inv_vocabulary,top_words)\nHscore(model.transform())\n```\n### To do\n\n* Add parallelization for faster execution\n* Handle sparse matrix\n* Add online JST models\n\n### References -\n\n[1] https://www.researchgate.net/figure/JST-and-Reverse-JST-sentiment-classification-results-with-multiple-topics_fig1_47454505\n\n[2] https://www.aaai.org/ocs/index.php/AAAI/AAAI10/paper/viewFile/1913/2215\n\n[3] https://hal.archives-ouvertes.fr/hal-02052354/document\n\n[4] https://github.com/ayushjain91/Sentiment-LDA\n\n[5] https://gist.github.com/mblondel/542786\n\n[6] http://ceur-ws.org/Vol-1646/paper6.pdf\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/victor7246/jointtsmodel", "keywords": "", "license": "MIT License", "maintainer": "", "maintainer_email": "", "name": "jointtsmodel", "package_url": "https://pypi.org/project/jointtsmodel/", "platform": "", "project_url": "https://pypi.org/project/jointtsmodel/", "project_urls": {"Homepage": "https://github.com/victor7246/jointtsmodel"}, "release_url": "https://pypi.org/project/jointtsmodel/1.5/", "requires_dist": ["pandas", "numpy", "scipy", "nltk", "sklearn"], "requires_python": "", "summary": "jointtsmodel - library of joint topic-sentiment models", "version": "1.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h2>jointtsmodel</h2>\n<p><a href=\"LICENSE.md\" rel=\"nofollow\"><img alt=\"License\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5bce10e8e48e6c0a122e9f07c0b94cad805796fb/687474703a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d627269676874677265656e2e7376673f7374796c653d666c6174\"></a></p>\n<p>This is a consolidated library for joint topic-sentiment (jst) models.</p>\n<h3>Description</h3>\n<p>Joint topic-sentiment models extract topical as well as sentiment information for each text. This library contains different jst models - JST, RJST, TSM, sLDA and TSWE.</p>\n<h3>Installation</h3>\n<pre><code>git clone https://github.com/victor7246/jointtsmodel.git\ncd jointtsmodel\npython setup.py install\n</code></pre>\n<p>Or from pip:</p>\n<pre><code>pip install jointtsmodel\n</code></pre>\n<h3>Usage</h3>\n<p>We can use vectorized texts to run joint topic-sentiment models.</p>\n<pre><code>from jointtsmodel.RJST import RJST\nfrom jointtsmodel.JST import JST\nfrom jointtsmodel.sLDA import sLDA\nfrom jointtsmodel.TSM import TSM\nfrom jointtsmodel.TSWE import TSWE\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.datasets import fetch_20newsgroups\nfrom jointtsmodel.utils import *\n\n# This produces a feature matrix of token counts, similar to what\n# CountVectorizer would produce on text.\ndata, _ = fetch_20newsgroups(shuffle=True, random_state=1,\n                         remove=('headers', 'footers', 'quotes'),\n                         return_X_y=True)\ndata = data[:1000]\nvectorizer = CountVectorizer(max_df=0.7, min_df=10,\n                            max_features=5000,\n                            stop_words='english')\nX = vectorizer.fit_transform(data)\nvocabulary = vectorizer.get_feature_names()\ninv_vocabulary = dict(zip(vocabulary,np.arange(len(vocabulary))))\nlexicon_data = pd.read_excel('lexicon/prior_sentiment.xlsx')\nlexicon_data = lexicon_data.dropna()\nlexicon_dict = dict(zip(lexicon_data['Word'],lexicon_data['Sentiment']))\n</code></pre>\n<p>For JST model use</p>\n<pre><code>model = JST(n_topic_components=5,n_sentiment_components=5,random_state=123,evaluate_every=2)\nmodel.fit(X.toarray(), lexicon_dict)\n\nmodel.transform()[:2]\n\ntop_words = list(model.getTopKWords(vocabulary).values())\ncoherence_score_uci(X.toarray(),inv_vocabulary,top_words)\nHscore(model.transform())\n</code></pre>\n<p>For RJST model use</p>\n<pre><code>model = RJST(n_topic_components=5,n_sentiment_components=5,random_state=123,evaluate_every=2)\nmodel.fit(X.toarray(), lexicon_dict)\n\nmodel.transform()[:2]\n\ntop_words = list(model.getTopKWords(vocabulary).values())\ncoherence_score_uci(X.toarray(),inv_vocabulary,top_words)\nHscore(model.transform())\n</code></pre>\n<p>For TSM use</p>\n<pre><code>model = TSM(n_topic_components=5,n_sentiment_components=5,random_state=123,evaluate_every=2)\nmodel.fit(X.toarray(), lexicon_dict)\n\nmodel.transform()[:2]\n\ntop_words = list(model.getTopKWords(vocabulary).values())\ncoherence_score_uci(X.toarray(),inv_vocabulary,top_words)\nHscore(model.transform())\n</code></pre>\n<p>For sLDA model use</p>\n<pre><code>model = sLDA(n_topic_components=5,n_sentiment_components=5,random_state=123,evaluate_every=2)\nmodel.fit(X.toarray(), vocabulary)\n\nmodel.transform()[:2]\n\ntop_words = list(model.getTopKWords(vocabulary).values())\ncoherence_score_uci(X.toarray(),inv_vocabulary,top_words)\nHscore(model.transform())\n</code></pre>\n<p>For TSWE model we need word embedding matrix as an input.</p>\n<pre><code>embeddings_index = {}\nf = open('embeddings/glove.6B.100d.txt','r',encoding='utf8')\n\nfor i, line in enumerate(f):\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\n\nprint('Found %s word vectors.' % len(embeddings_index))\n\nembedding_matrix = np.zeros((X.shape[1], 100))\n\nfor i, word in enumerate(vocabulary):\n    if word in embeddings_index:\n        embedding_matrix[i] = embeddings_index[word]\n    else:\n        embedding_matrix[i] = np.zeros(100)\n</code></pre>\n<p>Run TSWE model</p>\n<pre><code>model = TSWE(embedding_dim=100,n_topic_components=5,n_sentiment_components=5,random_state=123,evaluate_every=2)\nmodel.fit(X.toarray(), lexicon_dict, embedding_matrix)\n\nmodel.transform()[:2]\n\ntop_words = list(model.getTopKWords(vocabulary).values())\ncoherence_score_uci(X.toarray(),inv_vocabulary,top_words)\nHscore(model.transform())\n</code></pre>\n<h3>To do</h3>\n<ul>\n<li>Add parallelization for faster execution</li>\n<li>Handle sparse matrix</li>\n<li>Add online JST models</li>\n</ul>\n<h3>References -</h3>\n<p>[1] <a href=\"https://www.researchgate.net/figure/JST-and-Reverse-JST-sentiment-classification-results-with-multiple-topics_fig1_47454505\" rel=\"nofollow\">https://www.researchgate.net/figure/JST-and-Reverse-JST-sentiment-classification-results-with-multiple-topics_fig1_47454505</a></p>\n<p>[2] <a href=\"https://www.aaai.org/ocs/index.php/AAAI/AAAI10/paper/viewFile/1913/2215\" rel=\"nofollow\">https://www.aaai.org/ocs/index.php/AAAI/AAAI10/paper/viewFile/1913/2215</a></p>\n<p>[3] <a href=\"https://hal.archives-ouvertes.fr/hal-02052354/document\" rel=\"nofollow\">https://hal.archives-ouvertes.fr/hal-02052354/document</a></p>\n<p>[4] <a href=\"https://github.com/ayushjain91/Sentiment-LDA\" rel=\"nofollow\">https://github.com/ayushjain91/Sentiment-LDA</a></p>\n<p>[5] <a href=\"https://gist.github.com/mblondel/542786\" rel=\"nofollow\">https://gist.github.com/mblondel/542786</a></p>\n<p>[6] <a href=\"http://ceur-ws.org/Vol-1646/paper6.pdf\" rel=\"nofollow\">http://ceur-ws.org/Vol-1646/paper6.pdf</a></p>\n\n          </div>"}, "last_serial": 7076596, "releases": {"0.2": [{"comment_text": "", "digests": {"md5": "ca6373b9729113e1725b9081730dc16e", "sha256": "a460bcaa41ed952d293fa88d2396485caeb0cd2c6332a9ea074b45192a68cb43"}, "downloads": -1, "filename": "jointtsmodel-0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "ca6373b9729113e1725b9081730dc16e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 24987, "upload_time": "2020-01-19T17:20:02", "upload_time_iso_8601": "2020-01-19T17:20:02.742962Z", "url": "https://files.pythonhosted.org/packages/ee/d1/2b45fc9bc23fd0fea52897594ed80c0277fb66bef31e1e07b410367bfd71/jointtsmodel-0.2-py3-none-any.whl", "yanked": false}], "1.1": [{"comment_text": "", "digests": {"md5": "0788c627d986b11a624e226f84f3d361", "sha256": "c04e1145132fa853abfd8411f26f04eadafb3bc9abc2b3b6f41431b26db24a46"}, "downloads": -1, "filename": "jointtsmodel-1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "0788c627d986b11a624e226f84f3d361", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 28139, "upload_time": "2020-01-20T05:09:08", "upload_time_iso_8601": "2020-01-20T05:09:08.857403Z", "url": "https://files.pythonhosted.org/packages/68/a2/89ab9c2d4aedb2ac50faba2cd9533bc6b8075c6c253f0957346db7a736c4/jointtsmodel-1.1-py3-none-any.whl", "yanked": false}], "1.2": [{"comment_text": "", "digests": {"md5": "f667dd47f05a7be0a743dabd6edaf1da", "sha256": "a83d2e3916e68c99bd877ca7eecda085229ad5c698ad1628c7dfd3d7f2e7d180"}, "downloads": -1, "filename": "jointtsmodel-1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "f667dd47f05a7be0a743dabd6edaf1da", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 81887, "upload_time": "2020-01-30T09:33:13", "upload_time_iso_8601": "2020-01-30T09:33:13.672732Z", "url": "https://files.pythonhosted.org/packages/9d/8d/928b99a15a795eb023e278365751d99314cac70f55c0aabfcd7d36cac2f8/jointtsmodel-1.2-py3-none-any.whl", "yanked": false}], "1.3": [{"comment_text": "", "digests": {"md5": "bb1cfadf186a6ba9530191bdd6d5228e", "sha256": "dbea0da971f0ed04d64234b4ebbf054a7bd7ef1589d9f615cd1d4abfbbce34e9"}, "downloads": -1, "filename": "jointtsmodel-1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "bb1cfadf186a6ba9530191bdd6d5228e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 33800, "upload_time": "2020-04-06T07:28:49", "upload_time_iso_8601": "2020-04-06T07:28:49.410223Z", "url": "https://files.pythonhosted.org/packages/44/53/9e7c4d87a0ae16bca582b7f93fd6b207e8acc19abc51634f8b82788049a7/jointtsmodel-1.3-py3-none-any.whl", "yanked": false}], "1.4": [{"comment_text": "", "digests": {"md5": "f285fb27714b69b99394e3fb34691e5e", "sha256": "a8026264877339e242007c4bcd1368a94a1bd89a8f07a3ed12ff4a9e16bb43cc"}, "downloads": -1, "filename": "jointtsmodel-1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "f285fb27714b69b99394e3fb34691e5e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 34339, "upload_time": "2020-04-22T13:09:02", "upload_time_iso_8601": "2020-04-22T13:09:02.828975Z", "url": "https://files.pythonhosted.org/packages/88/fb/45913f0519b6af1990a46b724800bd83336a0f84cd8f61704814192ae7b9/jointtsmodel-1.4-py3-none-any.whl", "yanked": false}], "1.5": [{"comment_text": "", "digests": {"md5": "26ecdbe920ffdb76681df7e791576501", "sha256": "43e96fa2fce22d7c1408c3390b5d002d0dc60fe9d94473fb8190c4f9e488034e"}, "downloads": -1, "filename": "jointtsmodel-1.5-py3-none-any.whl", "has_sig": false, "md5_digest": "26ecdbe920ffdb76681df7e791576501", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 32171, "upload_time": "2020-04-22T13:30:09", "upload_time_iso_8601": "2020-04-22T13:30:09.625409Z", "url": "https://files.pythonhosted.org/packages/91/09/f25b9c5890c0fa55300151e2637d6637f3aa6211051cc0ab198b593d7635/jointtsmodel-1.5-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "26ecdbe920ffdb76681df7e791576501", "sha256": "43e96fa2fce22d7c1408c3390b5d002d0dc60fe9d94473fb8190c4f9e488034e"}, "downloads": -1, "filename": "jointtsmodel-1.5-py3-none-any.whl", "has_sig": false, "md5_digest": "26ecdbe920ffdb76681df7e791576501", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 32171, "upload_time": "2020-04-22T13:30:09", "upload_time_iso_8601": "2020-04-22T13:30:09.625409Z", "url": "https://files.pythonhosted.org/packages/91/09/f25b9c5890c0fa55300151e2637d6637f3aa6211051cc0ab198b593d7635/jointtsmodel-1.5-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 00:52:16 2020"}