{"info": {"author": "Andreas Kirsch", "author_email": "blackhc+batchbald@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: Apache Software License", "Natural Language :: English", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8"], "description": "# BatchBALD Redux\n> Clean reimplementation of \\\"BatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian Active Learning\\\"\n\n\nFor an introduction & more information, see  http://batchbald.ml/. The paper can be found at http://arxiv.org/abs/1906.08158.\n\nThe original implementation used in the paper is available at https://github.com/BlackHC/BatchBALD.\n\nWe are grateful for fastai's [nbdev](https://nbdev.fast.ai/) which is powering this package.\n\n## Install\n\n`pip install batchbald_redux`\n\n## Motivation\n\nBatchBALD is an algorithm and acquisition function for Active Learning in a Bayesian setting using BNNs and MC dropout.\n\nThe aquisition function is the mutual information between the joint of a candidate batch and the model parameters $\\omega$:\n\n{% raw %}\n$$a_{\\text{BatchBALD}}((y_b)_B) = I[(y_b)_B;\\omega]$$\n{% endraw %}\n\nThe best candidate batch is one that maximizes this acquisition function. \n\nIn the paper, we show that this function satisfies sub-modularity, which provides us an optimality guarantee for a greedy algorithm. The candidate batch is selected using greedy expansion.\n\nJoint entropies are hard to estimate and, for everything to work, one also has to use consistent MC dropout, which keeps a set of dropout masks fixed while scoring the pool set.\n\nTo aid reproducibility and baseline reproduction, we provide this simpler and clearer reimplementation.\n\n\n## How to use\n\nWe provide a simple example experiment that uses this package [here](https://blackhc.github.io/batchbald_redux/example_experiment/). \n\nTo get a candidate batch using BatchBALD, we provide a simple API in [`batchbald_redux.batchbald`](https://blackhc.github.io/batchbald_redux/batchbald/):\n\n```python\nfrom nbdev.showdoc import *\nfrom batchbald_redux.batchbald import get_batchbald_batch\n\nshow_doc(get_batchbald_batch)\n\n```\n\n\n<h4 id=\"get_batchbald_batch\" class=\"doc_header\"><code>get_batchbald_batch</code><a href=\"https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/batchbald.py#L110\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>get_batchbald_batch</code>(**`logits_N_K_C`**:`Tensor`, **`batch_size`**:`int`, **`num_samples`**:`int`, **`dtype`**=*`None`*, **`device`**=*`None`*)\n\n\n\n\nWe also provide a simple implementation of consistent MC dropout in [`batchbald_redux.consistent_mc_dropout`](https://blackhc.github.io/batchbald_redux/consistent_mc_dropout/).\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/blackhc/batchbald_redux/tree/master/", "keywords": "Active Learning,Machine Learning,PyTorch", "license": "Apache Software License 2.0", "maintainer": "", "maintainer_email": "", "name": "batchbald-redux", "package_url": "https://pypi.org/project/batchbald-redux/", "platform": "", "project_url": "https://pypi.org/project/batchbald-redux/", "project_urls": {"Homepage": "https://github.com/blackhc/batchbald_redux/tree/master/"}, "release_url": "https://pypi.org/project/batchbald-redux/1.0.1/", "requires_dist": ["torch (~=1.4.0)", "torchvision (==0.5)", "numpy", "tqdm (~=4.45)", "blackhc.project (~=2.1)", "toma (~=1.1.0)"], "requires_python": ">=3.7", "summary": "An implementation of the BatchBALD algorithm", "version": "1.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>BatchBALD Redux</h1>\n<blockquote>\n<p>Clean reimplementation of \"BatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian Active Learning\"</p>\n</blockquote>\n<p>For an introduction &amp; more information, see  <a href=\"http://batchbald.ml/\" rel=\"nofollow\">http://batchbald.ml/</a>. The paper can be found at <a href=\"http://arxiv.org/abs/1906.08158\" rel=\"nofollow\">http://arxiv.org/abs/1906.08158</a>.</p>\n<p>The original implementation used in the paper is available at <a href=\"https://github.com/BlackHC/BatchBALD\" rel=\"nofollow\">https://github.com/BlackHC/BatchBALD</a>.</p>\n<p>We are grateful for fastai's <a href=\"https://nbdev.fast.ai/\" rel=\"nofollow\">nbdev</a> which is powering this package.</p>\n<h2>Install</h2>\n<p><code>pip install batchbald_redux</code></p>\n<h2>Motivation</h2>\n<p>BatchBALD is an algorithm and acquisition function for Active Learning in a Bayesian setting using BNNs and MC dropout.</p>\n<p>The aquisition function is the mutual information between the joint of a candidate batch and the model parameters $\\omega$:</p>\n<p>{% raw %}\n$$a_{\\text{BatchBALD}}((y_b)_B) = I[(y_b)_B;\\omega]$$\n{% endraw %}</p>\n<p>The best candidate batch is one that maximizes this acquisition function.</p>\n<p>In the paper, we show that this function satisfies sub-modularity, which provides us an optimality guarantee for a greedy algorithm. The candidate batch is selected using greedy expansion.</p>\n<p>Joint entropies are hard to estimate and, for everything to work, one also has to use consistent MC dropout, which keeps a set of dropout masks fixed while scoring the pool set.</p>\n<p>To aid reproducibility and baseline reproduction, we provide this simpler and clearer reimplementation.</p>\n<h2>How to use</h2>\n<p>We provide a simple example experiment that uses this package <a href=\"https://blackhc.github.io/batchbald_redux/example_experiment/\" rel=\"nofollow\">here</a>.</p>\n<p>To get a candidate batch using BatchBALD, we provide a simple API in <a href=\"https://blackhc.github.io/batchbald_redux/batchbald/\" rel=\"nofollow\"><code>batchbald_redux.batchbald</code></a>:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">nbdev.showdoc</span> <span class=\"kn\">import</span> <span class=\"o\">*</span>\n<span class=\"kn\">from</span> <span class=\"nn\">batchbald_redux.batchbald</span> <span class=\"kn\">import</span> <span class=\"n\">get_batchbald_batch</span>\n\n<span class=\"n\">show_doc</span><span class=\"p\">(</span><span class=\"n\">get_batchbald_batch</span><span class=\"p\">)</span>\n</pre>\n<h4 id=\"get_batchbald_batch\"><code>get_batchbald_batch</code><a href=\"https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/batchbald.py#L110\" rel=\"nofollow\">[source]</a></h4>\n<blockquote>\n<p><code>get_batchbald_batch</code>(<strong><code>logits_N_K_C</code></strong>:<code>Tensor</code>, <strong><code>batch_size</code></strong>:<code>int</code>, <strong><code>num_samples</code></strong>:<code>int</code>, <strong><code>dtype</code></strong>=<em><code>None</code></em>, <strong><code>device</code></strong>=<em><code>None</code></em>)</p>\n</blockquote>\n<p>We also provide a simple implementation of consistent MC dropout in <a href=\"https://blackhc.github.io/batchbald_redux/consistent_mc_dropout/\" rel=\"nofollow\"><code>batchbald_redux.consistent_mc_dropout</code></a>.</p>\n\n          </div>"}, "last_serial": 7112012, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "9739af15e8b9fc78ee05ffd767665dd8", "sha256": "81ea4d1a30ccc59cf51e9f126329f5caeac97a26254cd7efd83a94cf8751ec65"}, "downloads": -1, "filename": "batchbald_redux-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "9739af15e8b9fc78ee05ffd767665dd8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 16685, "upload_time": "2020-04-27T14:07:22", "upload_time_iso_8601": "2020-04-27T14:07:22.857920Z", "url": "https://files.pythonhosted.org/packages/af/93/0671653b48fab62634bdee9dc69e1acdd80a9aa8e05c99acbfd26aadf246/batchbald_redux-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "dc5126f94f68b47887e9aebea7a751ea", "sha256": "7747ad5b06415fb4bd889cd71ae4a6686e52fb3e52bb4f4b3d13f32ccebd2f01"}, "downloads": -1, "filename": "batchbald_redux-1.0.0.tar.gz", "has_sig": false, "md5_digest": "dc5126f94f68b47887e9aebea7a751ea", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 17580, "upload_time": "2020-04-27T14:07:25", "upload_time_iso_8601": "2020-04-27T14:07:25.188446Z", "url": "https://files.pythonhosted.org/packages/23/e9/f131734d0b090edb0d41e924843936c1c733f93bf3e9f22e31709d11d36a/batchbald_redux-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "b37b69f3f1a901fe4042592c92f1ddb5", "sha256": "91ed07a545c40fac745b07c861b4e439b39674b6f089b5ce512a31b25a3e885b"}, "downloads": -1, "filename": "batchbald_redux-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "b37b69f3f1a901fe4042592c92f1ddb5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 16694, "upload_time": "2020-04-27T14:11:36", "upload_time_iso_8601": "2020-04-27T14:11:36.358559Z", "url": "https://files.pythonhosted.org/packages/aa/9a/3bf5cf4a9609cb8f623ff374aa4d57f843d811d30657fee06cc4068c1a63/batchbald_redux-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "90931ff826ccdb13a399ca6bf086db34", "sha256": "d7d35edd815b08457cb1e66abb33fe7e861883cdacf905da6a4851bd205cc90a"}, "downloads": -1, "filename": "batchbald_redux-1.0.1.tar.gz", "has_sig": false, "md5_digest": "90931ff826ccdb13a399ca6bf086db34", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 16994, "upload_time": "2020-04-27T14:11:37", "upload_time_iso_8601": "2020-04-27T14:11:37.674742Z", "url": "https://files.pythonhosted.org/packages/18/4e/a75e54687b48e1e6aa489a7ef510408335ccf465ef441fdba5fa5e3f496a/batchbald_redux-1.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "b37b69f3f1a901fe4042592c92f1ddb5", "sha256": "91ed07a545c40fac745b07c861b4e439b39674b6f089b5ce512a31b25a3e885b"}, "downloads": -1, "filename": "batchbald_redux-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "b37b69f3f1a901fe4042592c92f1ddb5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 16694, "upload_time": "2020-04-27T14:11:36", "upload_time_iso_8601": "2020-04-27T14:11:36.358559Z", "url": "https://files.pythonhosted.org/packages/aa/9a/3bf5cf4a9609cb8f623ff374aa4d57f843d811d30657fee06cc4068c1a63/batchbald_redux-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "90931ff826ccdb13a399ca6bf086db34", "sha256": "d7d35edd815b08457cb1e66abb33fe7e861883cdacf905da6a4851bd205cc90a"}, "downloads": -1, "filename": "batchbald_redux-1.0.1.tar.gz", "has_sig": false, "md5_digest": "90931ff826ccdb13a399ca6bf086db34", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 16994, "upload_time": "2020-04-27T14:11:37", "upload_time_iso_8601": "2020-04-27T14:11:37.674742Z", "url": "https://files.pythonhosted.org/packages/18/4e/a75e54687b48e1e6aa489a7ef510408335ccf465ef441fdba5fa5e3f496a/batchbald_redux-1.0.1.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:14:45 2020"}