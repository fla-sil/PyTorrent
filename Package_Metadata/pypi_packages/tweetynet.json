{"info": {"author": "Yarden Cohen, David Nicholson", "author_email": "yardenc@bu.edu", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "License :: OSI Approved :: BSD License", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: Implementation :: CPython"], "description": "\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.2667812.svg)](https://doi.org/10.5281/zenodo.2667812)\n[![PyPI version](https://badge.fury.io/py/tweetynet.svg)](https://badge.fury.io/py/tweetynet)\n\n# TweetyNet\n<p align=\"center\"><img src=\"./doc/tweetynet.gif\" alt=\"tweetynet image\" width=400></p>\n\n## A hybrid convolutional-recurrent neural network that segments and labels birdsong and other vocalizations.\n\n![sample annotation](doc/sample_phrase_annotation.png)\nCanary song segmented into phrases\n\n## Installation\nTo install, run the following command at the command line:  \n`pip install tweetynet`\n\nBefore you install, you'll want to set up a virtual environment\n(for an explanation of why, see\nhttps://www.geeksforgeeks.org/python-virtual-environment/).\nCreating a virtual environment is not as hard as it might sound;\nhere's a primer: https://realpython.com/python-virtual-environments-a-primer/  \nFor many scientific packages that depend on libraries written in  \nlanguages besides Python, you may find it easier to use \na platform dedicated to managing those dependencies, such as\n[Anaconda](https://www.anaconda.com/download) (which is free).\nYou can use the `conda` command-line tool developed by Anaconda  \nto create environments and install the scientific libraries that this package \ndepends on. In addition, using `conda` to install the dependencies may give you some performance gains \n(see https://www.anaconda.com/blog/developer-blog/tensorflow-in-anaconda/).  \nHere's how you'd set up a `conda` environment:  \n`/home/you/code/ $ conda create -n tweetyenv python=3.6 numpy scipy joblib tensorflow-gpu ipython jupyter`    \n`/home/you/code/ $ source activate tweetyenv`  \n(You don't have to `source` on Windows: `> activate tweetyenv`)  \n\nYou can then use `pip` inside a `conda` environment:  \n`(tweetyenv)/home/you/code/ $ pip install tweetynet`\n\n## Usage\n### Training `tweetynet` models to segment and label birdsong\nYou train `tweetynet` models with the [`vak`](https://github.com/NickleDave/vak) library.\nThe `vak` library is configured with `config.ini` files, using one of a handful of command-line flags.\nAs an example, here's how you'd run `vak` from the command line to train a single `config.ini` file:  \n`(tweetyenv)$ vak train ./configs/config_bird0.ini`  \n\nFor more details, please see the [vak documentation](https://github.com/NickleDave/vak).\n\n### Data and folder structures\nTo train models, you must supply training data in the form of audio files or \nspectrogram files, and annotations for each spectrogram.\n\n#### Spectrograms and labels\nThe package can generate spectrograms from `.wav` or `.cbin` audio files.\nIt can also accept spectrograms in the form of Matlab `.mat` files.\n\n### Important model parameters\n* The following parameters must be correctly defined in the configuration `.ini` [file](doc/README_config.md).\n  * `n_syllables` - Must be the correct number of labels, including a label for silent periods between syllables.\n  * `time_bins` - The number of time bins in each window from the spectrogram shown to the network.\n  During training, the network sees batches of windows grabbed randomly from the data whose width are equal to `time_bins`.\n  Intuitively, the bigger the time steps, the more temporal context the network has, but the longer it will take \n  to train. In practice, for Bengalese finch song, we achieve good accuracy with 88 time bins, and with canary song, \n  we achieve good accuracy with ~250 time bins. \n\n* The following parameters can be changed if needed:\n  * `num_epochs` - Number of times the network should see all the training data.\n  * `batch_size` - The number of snippets in each training batch (currently 11)\n  * `learning_rate` - The training step rate coefficient (currently 0.001)\nOther parameters that specify the network itself can be changed in the code but require knowledge of tensorflow.\n\n## Preparing training files\n\nIt is possible to train on any manually annotated data but there are some useful guidelines:\n* __Use as many examples as possible__ - The results will just be better. Specifically, this code will not label correctly syllables it did not encounter while training and will most probably generalize to the nearest sample or ignore the syllable.\n* __Use noise examples__ - This will make the code very good in ignoring noise.\n* __Examples of syllables on noise are important__ - It is a good practice to start with clean recordings. The code will not perform miracles and is most likely to fail if the audio is too corrupt or masked by noise. Still, training with examples of syllables on the background of cage noises will be beneficial.\n\n### Results of running the code\n\n__It is recommended to apply post processing when extracting the actual syllable tag and onset and offset timesfrom the estimates.__\n\n## Predicting new labels\n\nYou can predict new labels by adding a [PREDICT] section to the `config.ini` file, and \nthen running the command-line interface with the `predict` command, like so:  \n`(tweetyenv)$ vak predict ./configs/config_bird0.ini`\nAn example of what a `config.ini` file with a [PREDICT] section is \nin the doc folder [here](./doc/template_predict.ini).\n\nFor users with some scripting / Tensorflow experience, you can\nreload a saved model using a checkpoint file saved by the\nTensorflow checkpoint saver. Here's an example of how to do this, taken \nfrom the `vak.train_utils.learn_curve` function:\n```Python\nmeta_file = glob(os.path.join(training_records_dir, 'checkpoint*meta*'))[0]\ndata_file = glob(os.path.join(training_records_dir, 'checkpoint*data*'))[0]\n\nmodel = TweetyNet(n_syllables=n_syllables,\n                  input_vec_size=input_vec_size,\n                  batch_size=batch_size)\n\nwith tf.Session(graph=model.graph) as sess:\n    model.restore(sess=sess,\n                  meta_file=meta_file,\n                  data_file=data_file)\n```\n\n## Model architecture\nThe architecture of this deep neural network is based on these papers:\n* S. B\u00f6ck and M. Schedl, \"Polyphonic piano note transcription with recurrent neural networks,\" 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Kyoto, 2012, pp. 121-124.\ndoi: 10.1109/ICASSP.2012.6287832 (http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6287832&isnumber=6287775)\n* Parascandolo, Huttunen, and Virtanen, \u201cRecurrent Neural Networks for Polyphonic Sound Event Detection in Real Life Recordings.\u201d (https://arxiv.org/abs/1604.00861)\n\nThe deep net. structure, used in this code, contains 3 elements:\n* 2 convolutional and max pooling layers - A convolutional layer convolves the spectrogram with a set of tunable features and the max pooling is used to limit the number of parameters. These layers allow extracting local spectral and temporal features of syllables and noise.\n* A long-short-term-memory recurrent layer (LSTM) - This layer allows the model to incorporate the temporal dependencies in the signal, such as canary trills and the duration of various syllables. The code contains an option to adding more LSTM layers but, since it isn't needed, those are not used.\n* A projection layer - For each time bin, this layer projects the previous layer's output on the set of possible syllables. \n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/yardencsGitHub/tweetynet", "keywords": "", "license": "BSD", "maintainer": "", "maintainer_email": "", "name": "tweetynet", "package_url": "https://pypi.org/project/tweetynet/", "platform": "", "project_url": "https://pypi.org/project/tweetynet/", "project_urls": {"Homepage": "https://github.com/yardencsGitHub/tweetynet"}, "release_url": "https://pypi.org/project/tweetynet/0.4.2/", "requires_dist": ["torch", "vak", "vak ; extra == 'article'", "crowsetta (>=2.1.0) ; extra == 'article'", "joblib ; extra == 'article'", "pandas ; extra == 'article'", "seaborn ; extra == 'article'", "jupyterlab ; extra == 'article'", "pytest ; extra == 'tests'"], "requires_python": ">=3.6.0", "summary": "neural network that segments and labels birdsong", "version": "0.4.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://doi.org/10.5281/zenodo.2667812\" rel=\"nofollow\"><img alt=\"DOI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/92b8f36dbdef1eb7845d1d71c8c49f5ebc95cc87/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e323636373831322e737667\"></a>\n<a href=\"https://badge.fury.io/py/tweetynet\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1fbfbffd91a7b01e3e9361e1da2c1bc9c1ef1822/68747470733a2f2f62616467652e667572792e696f2f70792f7477656574796e65742e737667\"></a></p>\n<h1>TweetyNet</h1>\n<p align=\"center\"><img alt=\"tweetynet image\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/04cee92c846ade7b1e95b2e7cd73b2f2fa99d13c/2e2f646f632f7477656574796e65742e676966\" width=\"400\"></p>\n<h2>A hybrid convolutional-recurrent neural network that segments and labels birdsong and other vocalizations.</h2>\n<p><img alt=\"sample annotation\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9ed9fed75131098a5b98d95018bee5fe327d864d/646f632f73616d706c655f7068726173655f616e6e6f746174696f6e2e706e67\">\nCanary song segmented into phrases</p>\n<h2>Installation</h2>\n<p>To install, run the following command at the command line:<br>\n<code>pip install tweetynet</code></p>\n<p>Before you install, you'll want to set up a virtual environment\n(for an explanation of why, see\n<a href=\"https://www.geeksforgeeks.org/python-virtual-environment/\" rel=\"nofollow\">https://www.geeksforgeeks.org/python-virtual-environment/</a>).\nCreating a virtual environment is not as hard as it might sound;\nhere's a primer: <a href=\"https://realpython.com/python-virtual-environments-a-primer/\" rel=\"nofollow\">https://realpython.com/python-virtual-environments-a-primer/</a><br>\nFor many scientific packages that depend on libraries written in<br>\nlanguages besides Python, you may find it easier to use\na platform dedicated to managing those dependencies, such as\n<a href=\"https://www.anaconda.com/download\" rel=\"nofollow\">Anaconda</a> (which is free).\nYou can use the <code>conda</code> command-line tool developed by Anaconda<br>\nto create environments and install the scientific libraries that this package\ndepends on. In addition, using <code>conda</code> to install the dependencies may give you some performance gains\n(see <a href=\"https://www.anaconda.com/blog/developer-blog/tensorflow-in-anaconda/\" rel=\"nofollow\">https://www.anaconda.com/blog/developer-blog/tensorflow-in-anaconda/</a>).<br>\nHere's how you'd set up a <code>conda</code> environment:<br>\n<code>/home/you/code/ $ conda create -n tweetyenv python=3.6 numpy scipy joblib tensorflow-gpu ipython jupyter</code><br>\n<code>/home/you/code/ $ source activate tweetyenv</code><br>\n(You don't have to <code>source</code> on Windows: <code>&gt; activate tweetyenv</code>)</p>\n<p>You can then use <code>pip</code> inside a <code>conda</code> environment:<br>\n<code>(tweetyenv)/home/you/code/ $ pip install tweetynet</code></p>\n<h2>Usage</h2>\n<h3>Training <code>tweetynet</code> models to segment and label birdsong</h3>\n<p>You train <code>tweetynet</code> models with the <a href=\"https://github.com/NickleDave/vak\" rel=\"nofollow\"><code>vak</code></a> library.\nThe <code>vak</code> library is configured with <code>config.ini</code> files, using one of a handful of command-line flags.\nAs an example, here's how you'd run <code>vak</code> from the command line to train a single <code>config.ini</code> file:<br>\n<code>(tweetyenv)$ vak train ./configs/config_bird0.ini</code></p>\n<p>For more details, please see the <a href=\"https://github.com/NickleDave/vak\" rel=\"nofollow\">vak documentation</a>.</p>\n<h3>Data and folder structures</h3>\n<p>To train models, you must supply training data in the form of audio files or\nspectrogram files, and annotations for each spectrogram.</p>\n<h4>Spectrograms and labels</h4>\n<p>The package can generate spectrograms from <code>.wav</code> or <code>.cbin</code> audio files.\nIt can also accept spectrograms in the form of Matlab <code>.mat</code> files.</p>\n<h3>Important model parameters</h3>\n<ul>\n<li>\n<p>The following parameters must be correctly defined in the configuration <code>.ini</code> <a href=\"doc/README_config.md\" rel=\"nofollow\">file</a>.</p>\n<ul>\n<li><code>n_syllables</code> - Must be the correct number of labels, including a label for silent periods between syllables.</li>\n<li><code>time_bins</code> - The number of time bins in each window from the spectrogram shown to the network.\nDuring training, the network sees batches of windows grabbed randomly from the data whose width are equal to <code>time_bins</code>.\nIntuitively, the bigger the time steps, the more temporal context the network has, but the longer it will take\nto train. In practice, for Bengalese finch song, we achieve good accuracy with 88 time bins, and with canary song,\nwe achieve good accuracy with ~250 time bins.</li>\n</ul>\n</li>\n<li>\n<p>The following parameters can be changed if needed:</p>\n<ul>\n<li><code>num_epochs</code> - Number of times the network should see all the training data.</li>\n<li><code>batch_size</code> - The number of snippets in each training batch (currently 11)</li>\n<li><code>learning_rate</code> - The training step rate coefficient (currently 0.001)\nOther parameters that specify the network itself can be changed in the code but require knowledge of tensorflow.</li>\n</ul>\n</li>\n</ul>\n<h2>Preparing training files</h2>\n<p>It is possible to train on any manually annotated data but there are some useful guidelines:</p>\n<ul>\n<li><strong>Use as many examples as possible</strong> - The results will just be better. Specifically, this code will not label correctly syllables it did not encounter while training and will most probably generalize to the nearest sample or ignore the syllable.</li>\n<li><strong>Use noise examples</strong> - This will make the code very good in ignoring noise.</li>\n<li><strong>Examples of syllables on noise are important</strong> - It is a good practice to start with clean recordings. The code will not perform miracles and is most likely to fail if the audio is too corrupt or masked by noise. Still, training with examples of syllables on the background of cage noises will be beneficial.</li>\n</ul>\n<h3>Results of running the code</h3>\n<p><strong>It is recommended to apply post processing when extracting the actual syllable tag and onset and offset timesfrom the estimates.</strong></p>\n<h2>Predicting new labels</h2>\n<p>You can predict new labels by adding a [PREDICT] section to the <code>config.ini</code> file, and\nthen running the command-line interface with the <code>predict</code> command, like so:<br>\n<code>(tweetyenv)$ vak predict ./configs/config_bird0.ini</code>\nAn example of what a <code>config.ini</code> file with a [PREDICT] section is\nin the doc folder <a href=\"./doc/template_predict.ini\" rel=\"nofollow\">here</a>.</p>\n<p>For users with some scripting / Tensorflow experience, you can\nreload a saved model using a checkpoint file saved by the\nTensorflow checkpoint saver. Here's an example of how to do this, taken\nfrom the <code>vak.train_utils.learn_curve</code> function:</p>\n<pre><span class=\"n\">meta_file</span> <span class=\"o\">=</span> <span class=\"n\">glob</span><span class=\"p\">(</span><span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">training_records_dir</span><span class=\"p\">,</span> <span class=\"s1\">'checkpoint*meta*'</span><span class=\"p\">))[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n<span class=\"n\">data_file</span> <span class=\"o\">=</span> <span class=\"n\">glob</span><span class=\"p\">(</span><span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">training_records_dir</span><span class=\"p\">,</span> <span class=\"s1\">'checkpoint*data*'</span><span class=\"p\">))[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">TweetyNet</span><span class=\"p\">(</span><span class=\"n\">n_syllables</span><span class=\"o\">=</span><span class=\"n\">n_syllables</span><span class=\"p\">,</span>\n                  <span class=\"n\">input_vec_size</span><span class=\"o\">=</span><span class=\"n\">input_vec_size</span><span class=\"p\">,</span>\n                  <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"n\">batch_size</span><span class=\"p\">)</span>\n\n<span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Session</span><span class=\"p\">(</span><span class=\"n\">graph</span><span class=\"o\">=</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">sess</span><span class=\"p\">:</span>\n    <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">restore</span><span class=\"p\">(</span><span class=\"n\">sess</span><span class=\"o\">=</span><span class=\"n\">sess</span><span class=\"p\">,</span>\n                  <span class=\"n\">meta_file</span><span class=\"o\">=</span><span class=\"n\">meta_file</span><span class=\"p\">,</span>\n                  <span class=\"n\">data_file</span><span class=\"o\">=</span><span class=\"n\">data_file</span><span class=\"p\">)</span>\n</pre>\n<h2>Model architecture</h2>\n<p>The architecture of this deep neural network is based on these papers:</p>\n<ul>\n<li>S. B\u00f6ck and M. Schedl, \"Polyphonic piano note transcription with recurrent neural networks,\" 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Kyoto, 2012, pp. 121-124.\ndoi: 10.1109/ICASSP.2012.6287832 (<a href=\"http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6287832&amp;isnumber=6287775\" rel=\"nofollow\">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6287832&amp;isnumber=6287775</a>)</li>\n<li>Parascandolo, Huttunen, and Virtanen, \u201cRecurrent Neural Networks for Polyphonic Sound Event Detection in Real Life Recordings.\u201d (<a href=\"https://arxiv.org/abs/1604.00861\" rel=\"nofollow\">https://arxiv.org/abs/1604.00861</a>)</li>\n</ul>\n<p>The deep net. structure, used in this code, contains 3 elements:</p>\n<ul>\n<li>2 convolutional and max pooling layers - A convolutional layer convolves the spectrogram with a set of tunable features and the max pooling is used to limit the number of parameters. These layers allow extracting local spectral and temporal features of syllables and noise.</li>\n<li>A long-short-term-memory recurrent layer (LSTM) - This layer allows the model to incorporate the temporal dependencies in the signal, such as canary trills and the duration of various syllables. The code contains an option to adding more LSTM layers but, since it isn't needed, those are not used.</li>\n<li>A projection layer - For each time bin, this layer projects the previous layer's output on the set of possible syllables.</li>\n</ul>\n\n          </div>"}, "last_serial": 7101363, "releases": {"0.1.1a1": [{"comment_text": "", "digests": {"md5": "c43fb209051bb02add25364b279e8c14", "sha256": "2137f5b8eb4130e715b401a679133710c3e87bb8b86625fb339dc98dfb571823"}, "downloads": -1, "filename": "tweetynet-0.1.1a1-py3-none-any.whl", "has_sig": false, "md5_digest": "c43fb209051bb02add25364b279e8c14", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5.0", "size": 51076, "upload_time": "2018-11-04T15:24:08", "upload_time_iso_8601": "2018-11-04T15:24:08.250393Z", "url": "https://files.pythonhosted.org/packages/4f/38/3ace0ab868d6d14f9c9ba59236797cb395f0a7447b136771e58b46819776/tweetynet-0.1.1a1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "229803610f33c533fa2e88a969f04481", "sha256": "58b0e1b5272b7629bdb9693d5633ad4b13e22bd6a3974cd1bca26d5a4c2edbf6"}, "downloads": -1, "filename": "tweetynet-0.1.1a1.tar.gz", "has_sig": false, "md5_digest": "229803610f33c533fa2e88a969f04481", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 46372, "upload_time": "2018-11-04T15:24:10", "upload_time_iso_8601": "2018-11-04T15:24:10.262702Z", "url": "https://files.pythonhosted.org/packages/98/4a/e6a71975693cc732e959da497b3376e870ddc09c6da7833f127f930ad396/tweetynet-0.1.1a1.tar.gz", "yanked": false}], "0.1.1a2": [{"comment_text": "", "digests": {"md5": "9a36f4bb55986e0e63a7968f707931dd", "sha256": "42c832e683cefd9fd7577e213ca41befa4d663e0c4f5c1887d07a1c83d8e7ee5"}, "downloads": -1, "filename": "tweetynet-0.1.1a2-py3-none-any.whl", "has_sig": false, "md5_digest": "9a36f4bb55986e0e63a7968f707931dd", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5.0", "size": 13024, "upload_time": "2018-11-17T20:47:57", "upload_time_iso_8601": "2018-11-17T20:47:57.728880Z", "url": "https://files.pythonhosted.org/packages/b5/59/3f9f8049e4fd01c31b65dc736fb224d457cacf55925c7d6dbe66dd6f1bdd/tweetynet-0.1.1a2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "536e36bbd1796190acca53b0ac0f10fd", "sha256": "fe6bb074ee571209821c05431b219577b9136f81b9730627b0cf809033714896"}, "downloads": -1, "filename": "tweetynet-0.1.1a2.tar.gz", "has_sig": false, "md5_digest": "536e36bbd1796190acca53b0ac0f10fd", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 15506, "upload_time": "2018-11-17T20:47:59", "upload_time_iso_8601": "2018-11-17T20:47:59.391981Z", "url": "https://files.pythonhosted.org/packages/a7/14/1d8910b753e43b3a2d4d4afb53a2d5c4786e6117d9e7749da23ee9e8314b/tweetynet-0.1.1a2.tar.gz", "yanked": false}], "0.1.1a3": [{"comment_text": "", "digests": {"md5": "6ef34fb71a01017bd6c8ceec16478e6e", "sha256": "3681f76a5ab66b0efdb274f60f5e9b4fa1cca26389e3789706169ae49d78dc85"}, "downloads": -1, "filename": "tweetynet-0.1.1a3-py3-none-any.whl", "has_sig": false, "md5_digest": "6ef34fb71a01017bd6c8ceec16478e6e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 16743, "upload_time": "2019-03-03T14:44:53", "upload_time_iso_8601": "2019-03-03T14:44:53.105018Z", "url": "https://files.pythonhosted.org/packages/09/56/dc1df5b85ba787b18549608aca02ef2e987cd20a078f50c2ba57fa84e4ad/tweetynet-0.1.1a3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "db095d15025db29ed69790fb90f3a1a3", "sha256": "9e6f7a0fefbf08361310f1b895c0ab89748fd257d1619af0e38f9ad80f0e0126"}, "downloads": -1, "filename": "tweetynet-0.1.1a3.tar.gz", "has_sig": false, "md5_digest": "db095d15025db29ed69790fb90f3a1a3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 11854, "upload_time": "2019-03-03T14:44:54", "upload_time_iso_8601": "2019-03-03T14:44:54.541795Z", "url": "https://files.pythonhosted.org/packages/11/e6/3aa28a3387a4bbee6a6a8077edecf4692752e224a01d6b8ac008b83890a8/tweetynet-0.1.1a3.tar.gz", "yanked": false}], "0.1.1a4": [{"comment_text": "", "digests": {"md5": "edec8d7fcf27e15fefed264cce75b3a9", "sha256": "75802086d71fe444a90d4b82d5904b137f129f48f036f5d9af7dd1e5b6b5625c"}, "downloads": -1, "filename": "tweetynet-0.1.1a4-py3-none-any.whl", "has_sig": false, "md5_digest": "edec8d7fcf27e15fefed264cce75b3a9", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 9862, "upload_time": "2019-03-18T02:19:11", "upload_time_iso_8601": "2019-03-18T02:19:11.803572Z", "url": "https://files.pythonhosted.org/packages/8a/6f/39eb7c7c06e2c88f0b4b8c61c58775910ddc94f697b11da9139cc7affc00/tweetynet-0.1.1a4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fe8baf7a65444720793a45b67238839b", "sha256": "cd988a825fe7d4c798440be4a61b867562db07578eae57a6d99802fbc103b993"}, "downloads": -1, "filename": "tweetynet-0.1.1a4.tar.gz", "has_sig": false, "md5_digest": "fe8baf7a65444720793a45b67238839b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 9811, "upload_time": "2019-03-18T02:19:13", "upload_time_iso_8601": "2019-03-18T02:19:13.002505Z", "url": "https://files.pythonhosted.org/packages/43/10/6b0aebb3513b38d96c8d8b40e9a3e33037c62fc5e80d0da51b23b3fab56a/tweetynet-0.1.1a4.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "c1b514c036a9034944c341e220fe5a25", "sha256": "ff82e0d2aef7a580a9e2394d123d0f090ea95aaf6059e6f89f402a1babbf689e"}, "downloads": -1, "filename": "tweetynet-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "c1b514c036a9034944c341e220fe5a25", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 12371, "upload_time": "2019-05-06T01:20:20", "upload_time_iso_8601": "2019-05-06T01:20:20.045281Z", "url": "https://files.pythonhosted.org/packages/60/9c/b94f9810be7e114fbec37d46170866fc94b2815014fb033659aa446a8133/tweetynet-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "de71f98a9177ae087fe2b67d537e39d3", "sha256": "f41147c7ace3730156d1f6e3b83c73120f7678ff47fbd84d45579abfc1673b57"}, "downloads": -1, "filename": "tweetynet-0.2.0.tar.gz", "has_sig": false, "md5_digest": "de71f98a9177ae087fe2b67d537e39d3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 14955, "upload_time": "2019-05-06T01:20:21", "upload_time_iso_8601": "2019-05-06T01:20:21.313790Z", "url": "https://files.pythonhosted.org/packages/eb/bc/3cad38e87be4554619de083eac59530529afa40cb02a09f4518d2ba46ad2/tweetynet-0.2.0.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "8df83dec8e222618c47a700d37a22f21", "sha256": "5d72e0f40e242ef795c134c7a6eff3e28e6024d9bd33e61ad3fb1f04d1bed398"}, "downloads": -1, "filename": "tweetynet-0.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "8df83dec8e222618c47a700d37a22f21", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 19304, "upload_time": "2020-02-09T17:41:47", "upload_time_iso_8601": "2020-02-09T17:41:47.643955Z", "url": "https://files.pythonhosted.org/packages/3b/97/79ff0699f7610f9c10940026ad075f548e77979a1831cc75749b10c98a29/tweetynet-0.3.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ebf13631f4db1fdf1c700951e54b93cb", "sha256": "4136e49fe00d5fa4a158ba5cfe704462694b1cf179a5808b0f1f3c4f18de51fd"}, "downloads": -1, "filename": "tweetynet-0.3.0.tar.gz", "has_sig": false, "md5_digest": "ebf13631f4db1fdf1c700951e54b93cb", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 20537, "upload_time": "2020-02-09T17:41:49", "upload_time_iso_8601": "2020-02-09T17:41:49.235452Z", "url": "https://files.pythonhosted.org/packages/9c/2b/6dd01f4d6db8ca2b90b4869b8ad1b120a2dc5bbf487041f45af754bb6db2/tweetynet-0.3.0.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "bcf9fdab1600adae10cdfdbbdcc96c64", "sha256": "81f7c8d3085b40a84c78faa66f312ca71564d2fd980dc94fb0522183a47652a7"}, "downloads": -1, "filename": "tweetynet-0.3.1-py3-none-any.whl", "has_sig": false, "md5_digest": "bcf9fdab1600adae10cdfdbbdcc96c64", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 19350, "upload_time": "2020-03-31T00:35:30", "upload_time_iso_8601": "2020-03-31T00:35:30.175280Z", "url": "https://files.pythonhosted.org/packages/52/36/d24df401d70e4889e825a49aed6711477a13bdcba99ce37745a3582bbcbc/tweetynet-0.3.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "da01923792086a0b36320fb9234afaaf", "sha256": "aa0d31d9c59563bbba55d946d0f1e168041ef2c522ab66967ec4acb3eead160f"}, "downloads": -1, "filename": "tweetynet-0.3.1.tar.gz", "has_sig": false, "md5_digest": "da01923792086a0b36320fb9234afaaf", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 17358, "upload_time": "2020-03-31T00:35:31", "upload_time_iso_8601": "2020-03-31T00:35:31.431468Z", "url": "https://files.pythonhosted.org/packages/af/16/4347dc058b9baf57c331932a399b4446920bdd9ccc7aca811eb2d1c2cade/tweetynet-0.3.1.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "f4dd768a732540a13d5a26a7566fd927", "sha256": "7d295a086876d38d4aa580d641e97c8aaf21b95b84043046be34df6a6f159a73"}, "downloads": -1, "filename": "tweetynet-0.4.0-py3-none-any.whl", "has_sig": false, "md5_digest": "f4dd768a732540a13d5a26a7566fd927", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 19363, "upload_time": "2020-04-10T00:42:04", "upload_time_iso_8601": "2020-04-10T00:42:04.651622Z", "url": "https://files.pythonhosted.org/packages/0b/5e/7c47c4ad743fc248808dcb7ca593ed5dde82ce13a020ed4c4577e5b0faf7/tweetynet-0.4.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f91109687d63ca2f711c4acab7950156", "sha256": "47b748f802888f9c57fc2fd7a8b7428b88065ea24d5eadb6e3acaed06279f84c"}, "downloads": -1, "filename": "tweetynet-0.4.0.tar.gz", "has_sig": false, "md5_digest": "f91109687d63ca2f711c4acab7950156", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 17381, "upload_time": "2020-04-10T00:42:06", "upload_time_iso_8601": "2020-04-10T00:42:06.219507Z", "url": "https://files.pythonhosted.org/packages/7a/29/eb01204d8a9997766de41d5dc4465e470ffcdfe30e13680cd8655e920302/tweetynet-0.4.0.tar.gz", "yanked": false}], "0.4.1": [{"comment_text": "", "digests": {"md5": "8ecc1a70bb198b12bcc6c84d42423c71", "sha256": "8acf2717c4ba9eb2c0e43941b2fe7eeb009db3338aa61cdfd593d502bb08fce5"}, "downloads": -1, "filename": "tweetynet-0.4.1-py3-none-any.whl", "has_sig": false, "md5_digest": "8ecc1a70bb198b12bcc6c84d42423c71", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 19359, "upload_time": "2020-04-19T20:58:24", "upload_time_iso_8601": "2020-04-19T20:58:24.451998Z", "url": "https://files.pythonhosted.org/packages/42/25/4c5b4092c2022960fdbf6655110decde03c4db0d37acf21e457f5cdeb6ca/tweetynet-0.4.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b06ea8dd83b35e19195bd7a064d656a5", "sha256": "043f3f29e269606d65893478c4cb76de42a20dce80ca196e621300f6a57f94a1"}, "downloads": -1, "filename": "tweetynet-0.4.1.tar.gz", "has_sig": false, "md5_digest": "b06ea8dd83b35e19195bd7a064d656a5", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 17367, "upload_time": "2020-04-19T20:58:25", "upload_time_iso_8601": "2020-04-19T20:58:25.408365Z", "url": "https://files.pythonhosted.org/packages/4b/77/19d5afeac65ab8a07974c60cc7ca986ea77043787b436f69c528b38b974d/tweetynet-0.4.1.tar.gz", "yanked": false}], "0.4.2": [{"comment_text": "", "digests": {"md5": "13165e4e37566691667749fbfe12cf50", "sha256": "e45145c86850f823d42e6b59280d9a7ed44b4523fa8b3b8ada7ba4d959dc6725"}, "downloads": -1, "filename": "tweetynet-0.4.2-py3-none-any.whl", "has_sig": false, "md5_digest": "13165e4e37566691667749fbfe12cf50", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 19406, "upload_time": "2020-04-25T21:35:14", "upload_time_iso_8601": "2020-04-25T21:35:14.219882Z", "url": "https://files.pythonhosted.org/packages/46/db/1fc8fc9a8d9a0ddc2b72003819d00a16c26a3e9cd32af339e02f3d563544/tweetynet-0.4.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7f17847b66300fd82ab34dde5b39919c", "sha256": "7e563f0132db48ca1f52a2480e0649918670edf00f7b1dcb6587b57bc00494d1"}, "downloads": -1, "filename": "tweetynet-0.4.2.tar.gz", "has_sig": false, "md5_digest": "7f17847b66300fd82ab34dde5b39919c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 17402, "upload_time": "2020-04-25T21:35:15", "upload_time_iso_8601": "2020-04-25T21:35:15.354256Z", "url": "https://files.pythonhosted.org/packages/1c/d0/6a330d55ee8c2f0bdff08095861c2bd4af5b49eb9a5c214ee799b797202f/tweetynet-0.4.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "13165e4e37566691667749fbfe12cf50", "sha256": "e45145c86850f823d42e6b59280d9a7ed44b4523fa8b3b8ada7ba4d959dc6725"}, "downloads": -1, "filename": "tweetynet-0.4.2-py3-none-any.whl", "has_sig": false, "md5_digest": "13165e4e37566691667749fbfe12cf50", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 19406, "upload_time": "2020-04-25T21:35:14", "upload_time_iso_8601": "2020-04-25T21:35:14.219882Z", "url": "https://files.pythonhosted.org/packages/46/db/1fc8fc9a8d9a0ddc2b72003819d00a16c26a3e9cd32af339e02f3d563544/tweetynet-0.4.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7f17847b66300fd82ab34dde5b39919c", "sha256": "7e563f0132db48ca1f52a2480e0649918670edf00f7b1dcb6587b57bc00494d1"}, "downloads": -1, "filename": "tweetynet-0.4.2.tar.gz", "has_sig": false, "md5_digest": "7f17847b66300fd82ab34dde5b39919c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 17402, "upload_time": "2020-04-25T21:35:15", "upload_time_iso_8601": "2020-04-25T21:35:15.354256Z", "url": "https://files.pythonhosted.org/packages/1c/d0/6a330d55ee8c2f0bdff08095861c2bd4af5b49eb9a5c214ee799b797202f/tweetynet-0.4.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:44:05 2020"}