{"info": {"author": "massquantity", "author_email": "wdmjjxg@163.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "# LibRecommender\n\n## Overview\n\n**LibRecommender** is an easy-to-use recommender system focused on end-to-end recommendation. The main features are:\n\n+ Implement a number of popular recommendation algorithms such as SVD, DeepFM, BPR etc.\n\n+ A hybrid system, allow user to use either collaborative-filtering or content-based features.\n\n+ Ease of memory usage, automatically convert categorical features to sparse representation.\n\n+ Suitable for both explicit and implicit datasets, and negative sampling can be used for implicit dataset.\n\n+ Making use of Cython or Tensorflow to accelerate model training.\n\n+ Provide end-to-end workflow, i.e. data handling / preprocessing -> model training -> evaluate -> serving.\n\n\n\n## Usage\n\n##### _pure collaborative-filtering example_ : \n\n```python\nfrom libreco.dataset import DatasetPure   # pure data, algorithm svd++\nfrom libreco.algorithms import SVDpp\n\nconf = {\n    \"data_path\": \"path/to/your/data\",\n    \"length\": \"all\",\n}\n\ndataset = DatasetPure()\ndataset.build_dataset(**conf)\n\nsvd = SVDpp(n_factors=32, n_epochs=200, lr=0.001, batch_size=4096, task=\"rating\")\nsvd.fit(dataset, verbose=1)\nprint(svd.predict(1, 2))\t     # predict preference of user 1 to item 2\nprint(svd.recommend_user(1, 7))\t # recommend 7 items for user 1\n```\n\n##### _include features example_ : \n\n```python\nfrom libreco.dataset import DatasetFeat   # feat data, algorithm DeepFM\nfrom libreco.algorithms import DeepFmFeat\n\nconf = {\n    \"data_path\": \"path/to/your/data\",\n    \"length\": 500000,\n    \"user_col\": 0,\n    \"item_col\": 1,\n    \"label_col\": 2,\n    \"numerical_col\": [4],\n    \"categorical_col\": [3, 5, 6, 7, 8],\n    \"merged_categorical_col\": None,\n    \"user_feature_cols\": [3, 4, 5],\n    \"item_feature_cols\": [6, 7, 8],\n    \"convert_implicit\": True,\n    \"build_negative\": True,\n    \"num_neg\": 2,\n    \"sep\": \",\",\n}\n\ndataset = DatasetFeat(include_features=True)\ndataset.build_dataset(**conf)\n\ndfm = DeepFmFeat(lr=0.0002, n_epochs=10000, reg=0.1, embed_size=50,\n                 batch_size=2048, dropout_rate=0.0, task=\"ranking\", neg_sampling=True)\ndfm.fit(dataset, pre_sampling=False, verbose=1)\nprint(dfm.predict(1, 10))             # predict preference of user 1 to item 10\nprint(dfm.recommend_user(1, 7))   # recommend 7 items for user 1\n```\n\n\n## Data Format\nJUST normal data format, each line represents a sample. By default, model assumes that `user`, `item`, and `label` column index are 0, 1, and 2, respectively. But you need to specify `user`, `item`, and `label` column index if that\u2019s not the case. For Example, the `movielens-1m` dataset:\n\n> 1::1193::5::978300760<br>\n> 1::661::3::978302109<br>\n> 1::914::3::978301968<br>\n> 1::3408::4::978300275\n\nleads to the following settings in `conf` dict : `\"user_col\": 0,  \"item_col\": 1,  \"label_col\": 2, \"sep\": \"::\"` .\n\nBesides, if you want to use some other meta features (e.g., age, sex, category etc.), `numerical` and `categorical` column index must be assigned. For example, `\"numerical_col\": [4], \"categorical_col\": [3, 5, 6, 7, 8]`, which means all features must be in a same table.\n\n\n\n## Installation & Dependencies \n\nFrom pypi:  `pip install LibRecommender`\n\n\n\n- Python 3.5 +\n- tensorflow >= 1.12\n- numpy >= 1.15.4\n- pandas >= 0.23.4\n- scipy >= 1.2.1\n- scikit-learn >= 0.20.0\n\n\n\n\n\n## References\n\n|     Algorithm     | Category | Paper                                                        |\n| :---------------: | :------: | :----------------------------------------------------------- |\n| userKNN / itemKNN |   pure   | [Item-Based Collaborative Filtering Recommendation Algorithms](http://www.ra.ethz.ch/cdstore/www10/papers/pdf/p519.pdf) |\n|        SVD        |   pure   | [Matrix Factorization Techniques for Recommender Systems](https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf) |\n|      SVD ++       |   pure   | [Factorization Meets the Neighborhood: a Multifaceted Collaborative Filtering Model](https://dl.acm.org/citation.cfm?id=1401944) |\n|     superSVD      |   pure   | [Factorization Meets the Neighborhood: a Multifaceted Collaborative Filtering Model](https://dl.acm.org/citation.cfm?id=1401944) |\n|        ALS        |   pure   | 1. [Matrix Completion via Alternating Least Square(ALS)](https://stanford.edu/~rezab/classes/cme323/S15/notes/lec14.pdf) / <br>2. [Collaborative Filtering for Implicit Feedback Datasets](http://yifanhu.net/PUB/cf.pdf) / <br>3. [Applications of the Conjugate Gradient Method for Implicit Feedback Collaborative Filtering](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.379.6473&rep=rep1&type=pdf) |\n|        NCF        |   pure   | [Neural Collaborative Filtering](https://arxiv.org/pdf/1708.05031.pdf) |\n|        BPR        |   pure   | [BPR: Bayesian Personalized Ranking from Implicit Feedback](https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf) |\n|    Wide & Deep    |   feat   | [Wide & Deep Learning for Recommender Systems](https://arxiv.org/pdf/1606.07792.pdf) |\n|        FM         |   feat   | [Factorization Machines](https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf) |\n|      DeepFM       |   feat   | [DeepFM: A Factorization-Machine based Neural Network for CTR Prediction](https://arxiv.org/pdf/1703.04247.pdf) |\n|    YouTubeRec     |   feat   | [Deep Neural Networks for YouTube Recommendations](<https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45530.pdf>) |\n\n\n## License\n\n#### MIT\n\n<br>", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/massquantity/LibRecommender", "keywords": "Matrix Factorization,Collaborative Filtering,Content-Based,Recommender System,Deep Learning,Data Mining", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "LibRecommender", "package_url": "https://pypi.org/project/LibRecommender/", "platform": "", "project_url": "https://pypi.org/project/LibRecommender/", "project_urls": {"Homepage": "https://github.com/massquantity/LibRecommender"}, "release_url": "https://pypi.org/project/LibRecommender/0.0.1/", "requires_dist": null, "requires_python": "", "summary": "A collaborative-filtering and content-based recommender system for both explicit and implicit datasets.", "version": "0.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>LibRecommender</h1>\n<h2>Overview</h2>\n<p><strong>LibRecommender</strong> is an easy-to-use recommender system focused on end-to-end recommendation. The main features are:</p>\n<ul>\n<li>\n<p>Implement a number of popular recommendation algorithms such as SVD, DeepFM, BPR etc.</p>\n</li>\n<li>\n<p>A hybrid system, allow user to use either collaborative-filtering or content-based features.</p>\n</li>\n<li>\n<p>Ease of memory usage, automatically convert categorical features to sparse representation.</p>\n</li>\n<li>\n<p>Suitable for both explicit and implicit datasets, and negative sampling can be used for implicit dataset.</p>\n</li>\n<li>\n<p>Making use of Cython or Tensorflow to accelerate model training.</p>\n</li>\n<li>\n<p>Provide end-to-end workflow, i.e. data handling / preprocessing -&gt; model training -&gt; evaluate -&gt; serving.</p>\n</li>\n</ul>\n<h2>Usage</h2>\n<h5><em>pure collaborative-filtering example</em> :</h5>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">libreco.dataset</span> <span class=\"kn\">import</span> <span class=\"n\">DatasetPure</span>   <span class=\"c1\"># pure data, algorithm svd++</span>\n<span class=\"kn\">from</span> <span class=\"nn\">libreco.algorithms</span> <span class=\"kn\">import</span> <span class=\"n\">SVDpp</span>\n\n<span class=\"n\">conf</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s2\">\"data_path\"</span><span class=\"p\">:</span> <span class=\"s2\">\"path/to/your/data\"</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"length\"</span><span class=\"p\">:</span> <span class=\"s2\">\"all\"</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">DatasetPure</span><span class=\"p\">()</span>\n<span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">build_dataset</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">conf</span><span class=\"p\">)</span>\n\n<span class=\"n\">svd</span> <span class=\"o\">=</span> <span class=\"n\">SVDpp</span><span class=\"p\">(</span><span class=\"n\">n_factors</span><span class=\"o\">=</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"n\">n_epochs</span><span class=\"o\">=</span><span class=\"mi\">200</span><span class=\"p\">,</span> <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">0.001</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">4096</span><span class=\"p\">,</span> <span class=\"n\">task</span><span class=\"o\">=</span><span class=\"s2\">\"rating\"</span><span class=\"p\">)</span>\n<span class=\"n\">svd</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">svd</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">))</span>\t     <span class=\"c1\"># predict preference of user 1 to item 2</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">svd</span><span class=\"o\">.</span><span class=\"n\">recommend_user</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">))</span>\t <span class=\"c1\"># recommend 7 items for user 1</span>\n</pre>\n<h5><em>include features example</em> :</h5>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">libreco.dataset</span> <span class=\"kn\">import</span> <span class=\"n\">DatasetFeat</span>   <span class=\"c1\"># feat data, algorithm DeepFM</span>\n<span class=\"kn\">from</span> <span class=\"nn\">libreco.algorithms</span> <span class=\"kn\">import</span> <span class=\"n\">DeepFmFeat</span>\n\n<span class=\"n\">conf</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s2\">\"data_path\"</span><span class=\"p\">:</span> <span class=\"s2\">\"path/to/your/data\"</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"length\"</span><span class=\"p\">:</span> <span class=\"mi\">500000</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"user_col\"</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"item_col\"</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"label_col\"</span><span class=\"p\">:</span> <span class=\"mi\">2</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"numerical_col\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">],</span>\n    <span class=\"s2\">\"categorical_col\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">6</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">],</span>\n    <span class=\"s2\">\"merged_categorical_col\"</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"user_feature_cols\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">],</span>\n    <span class=\"s2\">\"item_feature_cols\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">],</span>\n    <span class=\"s2\">\"convert_implicit\"</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"build_negative\"</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"num_neg\"</span><span class=\"p\">:</span> <span class=\"mi\">2</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"sep\"</span><span class=\"p\">:</span> <span class=\"s2\">\",\"</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">DatasetFeat</span><span class=\"p\">(</span><span class=\"n\">include_features</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">build_dataset</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">conf</span><span class=\"p\">)</span>\n\n<span class=\"n\">dfm</span> <span class=\"o\">=</span> <span class=\"n\">DeepFmFeat</span><span class=\"p\">(</span><span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">0.0002</span><span class=\"p\">,</span> <span class=\"n\">n_epochs</span><span class=\"o\">=</span><span class=\"mi\">10000</span><span class=\"p\">,</span> <span class=\"n\">reg</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">,</span> <span class=\"n\">embed_size</span><span class=\"o\">=</span><span class=\"mi\">50</span><span class=\"p\">,</span>\n                 <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">2048</span><span class=\"p\">,</span> <span class=\"n\">dropout_rate</span><span class=\"o\">=</span><span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"n\">task</span><span class=\"o\">=</span><span class=\"s2\">\"ranking\"</span><span class=\"p\">,</span> <span class=\"n\">neg_sampling</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"n\">dfm</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"p\">,</span> <span class=\"n\">pre_sampling</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">dfm</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">))</span>             <span class=\"c1\"># predict preference of user 1 to item 10</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">dfm</span><span class=\"o\">.</span><span class=\"n\">recommend_user</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">))</span>   <span class=\"c1\"># recommend 7 items for user 1</span>\n</pre>\n<h2>Data Format</h2>\n<p>JUST normal data format, each line represents a sample. By default, model assumes that <code>user</code>, <code>item</code>, and <code>label</code> column index are 0, 1, and 2, respectively. But you need to specify <code>user</code>, <code>item</code>, and <code>label</code> column index if that\u2019s not the case. For Example, the <code>movielens-1m</code> dataset:</p>\n<blockquote>\n<p>1::1193::5::978300760<br>\n1::661::3::978302109<br>\n1::914::3::978301968<br>\n1::3408::4::978300275</p>\n</blockquote>\n<p>leads to the following settings in <code>conf</code> dict : <code>\"user_col\": 0, \"item_col\": 1, \"label_col\": 2, \"sep\": \"::\"</code> .</p>\n<p>Besides, if you want to use some other meta features (e.g., age, sex, category etc.), <code>numerical</code> and <code>categorical</code> column index must be assigned. For example, <code>\"numerical_col\": [4], \"categorical_col\": [3, 5, 6, 7, 8]</code>, which means all features must be in a same table.</p>\n<h2>Installation &amp; Dependencies</h2>\n<p>From pypi:  <code>pip install LibRecommender</code></p>\n<ul>\n<li>Python 3.5 +</li>\n<li>tensorflow &gt;= 1.12</li>\n<li>numpy &gt;= 1.15.4</li>\n<li>pandas &gt;= 0.23.4</li>\n<li>scipy &gt;= 1.2.1</li>\n<li>scikit-learn &gt;= 0.20.0</li>\n</ul>\n<h2>References</h2>\n<table>\n<thead>\n<tr>\n<th align=\"center\">Algorithm</th>\n<th align=\"center\">Category</th>\n<th align=\"left\">Paper</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">userKNN / itemKNN</td>\n<td align=\"center\">pure</td>\n<td align=\"left\"><a href=\"http://www.ra.ethz.ch/cdstore/www10/papers/pdf/p519.pdf\" rel=\"nofollow\">Item-Based Collaborative Filtering Recommendation Algorithms</a></td>\n</tr>\n<tr>\n<td align=\"center\">SVD</td>\n<td align=\"center\">pure</td>\n<td align=\"left\"><a href=\"https://datajobs.com/data-science-repo/Recommender-Systems-%5BNetflix%5D.pdf\" rel=\"nofollow\">Matrix Factorization Techniques for Recommender Systems</a></td>\n</tr>\n<tr>\n<td align=\"center\">SVD ++</td>\n<td align=\"center\">pure</td>\n<td align=\"left\"><a href=\"https://dl.acm.org/citation.cfm?id=1401944\" rel=\"nofollow\">Factorization Meets the Neighborhood: a Multifaceted Collaborative Filtering Model</a></td>\n</tr>\n<tr>\n<td align=\"center\">superSVD</td>\n<td align=\"center\">pure</td>\n<td align=\"left\"><a href=\"https://dl.acm.org/citation.cfm?id=1401944\" rel=\"nofollow\">Factorization Meets the Neighborhood: a Multifaceted Collaborative Filtering Model</a></td>\n</tr>\n<tr>\n<td align=\"center\">ALS</td>\n<td align=\"center\">pure</td>\n<td align=\"left\">1. <a href=\"https://stanford.edu/%7Erezab/classes/cme323/S15/notes/lec14.pdf\" rel=\"nofollow\">Matrix Completion via Alternating Least Square(ALS)</a> / <br>2. <a href=\"http://yifanhu.net/PUB/cf.pdf\" rel=\"nofollow\">Collaborative Filtering for Implicit Feedback Datasets</a> / <br>3. <a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.379.6473&amp;rep=rep1&amp;type=pdf\" rel=\"nofollow\">Applications of the Conjugate Gradient Method for Implicit Feedback Collaborative Filtering</a></td>\n</tr>\n<tr>\n<td align=\"center\">NCF</td>\n<td align=\"center\">pure</td>\n<td align=\"left\"><a href=\"https://arxiv.org/pdf/1708.05031.pdf\" rel=\"nofollow\">Neural Collaborative Filtering</a></td>\n</tr>\n<tr>\n<td align=\"center\">BPR</td>\n<td align=\"center\">pure</td>\n<td align=\"left\"><a href=\"https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf\" rel=\"nofollow\">BPR: Bayesian Personalized Ranking from Implicit Feedback</a></td>\n</tr>\n<tr>\n<td align=\"center\">Wide &amp; Deep</td>\n<td align=\"center\">feat</td>\n<td align=\"left\"><a href=\"https://arxiv.org/pdf/1606.07792.pdf\" rel=\"nofollow\">Wide &amp; Deep Learning for Recommender Systems</a></td>\n</tr>\n<tr>\n<td align=\"center\">FM</td>\n<td align=\"center\">feat</td>\n<td align=\"left\"><a href=\"https://www.csie.ntu.edu.tw/%7Eb97053/paper/Rendle2010FM.pdf\" rel=\"nofollow\">Factorization Machines</a></td>\n</tr>\n<tr>\n<td align=\"center\">DeepFM</td>\n<td align=\"center\">feat</td>\n<td align=\"left\"><a href=\"https://arxiv.org/pdf/1703.04247.pdf\" rel=\"nofollow\">DeepFM: A Factorization-Machine based Neural Network for CTR Prediction</a></td>\n</tr>\n<tr>\n<td align=\"center\">YouTubeRec</td>\n<td align=\"center\">feat</td>\n<td align=\"left\"><a href=\"https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45530.pdf\" rel=\"nofollow\">Deep Neural Networks for YouTube Recommendations</a></td>\n</tr></tbody></table>\n<h2>License</h2>\n<h4>MIT</h4>\n<br>\n\n          </div>"}, "last_serial": 6044369, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "fc8c5d0a24d12e99a44fb77fa8dc9eba", "sha256": "5b5b3f6cad3c8493ebadf6bf754f65d3fde910fe1eeaf09d18f9880dc38cbeb9"}, "downloads": -1, "filename": "LibRecommender-0.0.1.tar.gz", "has_sig": false, "md5_digest": "fc8c5d0a24d12e99a44fb77fa8dc9eba", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 864867, "upload_time": "2019-10-28T22:59:37", "upload_time_iso_8601": "2019-10-28T22:59:37.739831Z", "url": "https://files.pythonhosted.org/packages/a3/06/c80ed1103394ee9e6dc9f31b1ac53ed66d00741f14d0b56acb1cd0d1e824/LibRecommender-0.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "fc8c5d0a24d12e99a44fb77fa8dc9eba", "sha256": "5b5b3f6cad3c8493ebadf6bf754f65d3fde910fe1eeaf09d18f9880dc38cbeb9"}, "downloads": -1, "filename": "LibRecommender-0.0.1.tar.gz", "has_sig": false, "md5_digest": "fc8c5d0a24d12e99a44fb77fa8dc9eba", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 864867, "upload_time": "2019-10-28T22:59:37", "upload_time_iso_8601": "2019-10-28T22:59:37.739831Z", "url": "https://files.pythonhosted.org/packages/a3/06/c80ed1103394ee9e6dc9f31b1ac53ed66d00741f14d0b56acb1cd0d1e824/LibRecommender-0.0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:46:23 2020"}