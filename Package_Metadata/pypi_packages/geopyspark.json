{"info": {"author": "Jacob Bouffard, James McClain", "author_email": "jbouffard@azavea.com, jmcclain@azavea.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Topic :: Scientific/Engineering", "Topic :: Scientific/Engineering :: GIS", "Topic :: Scientific/Engineering :: Information Analysis"], "description": "GeoPySpark\n**********\n\n.. image:: https://travis-ci.org/locationtech-labs/geopyspark.svg?branch=master\n   :target: https://travis-ci.org/locationtech-labs/geopyspark\n\n.. image:: https://readthedocs.org/projects/geopyspark/badge/?version=latest\n   :target: https://geopyspark.readthedocs.io/en/latest/?badge=latest\n\n.. image:: https://badges.gitter.im/locationtech-labs/geopyspark.png\n   :target: https://gitter.im/geotrellis/geotrellis\n\nGeoPySpark is a Python bindings library for `GeoTrellis <http://geotrellis.io>`_, a Scala\nlibrary for working with geospatial data in a distributed environment.\nBy using `PySpark <http://spark.apache.org/docs/latest/api/python/pyspark.html>`_, GeoPySpark is\nable to provide an interface into the GeoTrellis framework.\n\nLinks\n-----\n\n * `Documentation <https://geopyspark.readthedocs.io>`_\n * `Gitter <https://gitter.im/geotrellis/geotrellis>`_\n\nA Quick Example\n---------------\n\nHere is a quick example of GeoPySpark. In the following code, we take NLCD data\nof the state of Pennsylvania from 2011, and do a masking operation on it with\na Polygon that represents an area of interest. This masked layer is then saved.\n\nIf you wish to follow along with this example, you will need to download the\nNLCD data and unzip it.. Running these two commands will complete these tasks\nfor you:\n\n.. code:: console\n\n   curl -o /tmp/NLCD2011_LC_Pennsylvania.zip \"https://s3-us-west-2.amazonaws.com/prd-tnm/StagedProducts/NLCD/data/2011/landcover/states/NLCD2011_LC_Pennsylvania.zip?ORIG=513_SBDDG\"\n   unzip -d /tmp /tmp/NLCD2011_LC_Pennsylvania.zip\n\n.. code:: python\n\n  import geopyspark as gps\n\n  from pyspark import SparkContext\n  from shapely.geometry import box\n\n\n  # Create the SparkContext\n  conf = gps.geopyspark_conf(appName=\"geopyspark-example\", master=\"local[*]\")\n  sc = SparkContext(conf=conf)\n\n  # Read in the NLCD tif that has been saved locally.\n  # This tif represents the state of Pennsylvania.\n  raster_layer = gps.geotiff.get(layer_type=gps.LayerType.SPATIAL,\n                                 uri='/tmp/NLCD2011_LC_Pennsylvania.tif',\n                                 num_partitions=100)\n\n  # Tile the rasters within the layer and reproject them to Web Mercator.\n  tiled_layer = raster_layer.tile_to_layout(layout=gps.GlobalLayout(), target_crs=3857)\n\n  # Creates a Polygon that covers roughly the north-west section of Philadelphia.\n  # This is the region that will be masked.\n  area_of_interest = box(-75.229225, 40.003686, -75.107345, 40.084375)\n\n  # Mask the tiles within the layer with the area of interest\n  masked = tiled_layer.mask(geometries=area_of_interest)\n\n  # We will now pyramid the masked TiledRasterLayer so that we can use it in a TMS server later.\n  pyramided_mask = masked.pyramid()\n\n  # Save each layer of the pyramid locally so that it can be accessed at a later time.\n  for pyramid in pyramided_mask.levels.values():\n      gps.write(uri='file:///tmp/pa-nlcd-2011',\n                layer_name='north-west-philly',\n                tiled_raster_layer=pyramid)\n\nFor additional examples, check out the `Jupyter notebook demos <./notebook-demos>`_.\n\nRequirements\n------------\n\n============ ============\nRequirement  Version\n============ ============\nJava         >=1.8\nScala        >=2.11\nPython       3.3 - 3.6\nSpark        >=2.1.1\n============ ============\n\nJava 8 and Scala 2.11 are needed for GeoPySpark to work, as they are required by\nGeoTrellis. In addition, Spark needs to be installed and configured with the\nenvironment variable ``SPARK_HOME`` set.\n\nYou can test to see if Spark is installed properly by running the following in\nthe terminal:\n\n.. code:: console\n\n   > echo $SPARK_HOME\n   /usr/local/bin/spark\n\nIf the return is a path leading to your Spark folder, then it means that Spark\nhas been configured correctly. If ``SPARK_HOME`` is unset or empty, you'll need to add it\nto your ``PATH`` after noting where Spark is installed on your system. For example,\na MacOS installation of Spark 2.3.0 via HomeBrew would set ``SPARK_HOME`` as follows:\n\n.. code:: bash\n\n   # In ~/.bash_profile\n   export SPARK_HOME=/usr/local/Cellar/apache-spark/2.3.0/libexec/\n\nInstallation\n------------\n\nBefore installing, check the above `Requirements`_ table to make sure that the\nrequirements are met.\n\nInstalling From Pip\n~~~~~~~~~~~~~~~~~~~\n\nTo install via ``pip`` open the terminal and run the following:\n\n.. code:: console\n\n   pip install geopyspark\n   geopyspark install-jar\n\nThe first command installs the python code and the `geopyspark` command\nfrom PyPi. The second downloads the backend jar file, which is too large\nto be included in the pip package, and installs it to the GeoPySpark\ninstallation directory. For more information about the ``geopyspark``\ncommand, see the `GeoPySpark CLI`_ section.\n\nInstalling From Source\n~~~~~~~~~~~~~~~~~~~~~~\n\nIf you would rather install from source, clone the GeoPySpark repo and enter it.\n\n.. code:: console\n\n   git clone https://github.com/locationtech-labs/geopyspark.git\n   cd geopyspark\n   make install\n\nThis will assemble the backend-end ``jar`` that contains the Scala code,\nmove it to the ``jars`` sub-package, and then runs the ``setup.py`` script.\n\nNote:\n  If you have altered the global behavior of ``sbt`` this install may\n  not work the way it was intended.\n\nUninstalling\n~~~~~~~~~~~~\n\nTo uninstall GeoPySpark, run the following in the terminal:\n\n.. code:: console\n\n   pip uninstall geopyspark\n   rm .local/bin/geopyspark\n\nContact and Support\n-------------------\n\nIf you need help, have questions, or like to talk to the developers (let us\nknow what you're working on!) you can contact us at:\n\n * `Gitter <https://gitter.im/geotrellis/geotrellis>`_\n * `Mailing list <https://locationtech.org/mailman/listinfo/geotrellis-user>`_\n\nAs you may have noticed from the above links, those are links to the GeoTrellis\ngitter channel and mailing list. This is because this project is currently an\noffshoot of GeoTrellis, and we will be using their mailing list and gitter\nchannel as a means of contact. However, we will form our own if there is a need\nfor it.\n\nGeoPySpark CLI\n--------------\n\nWhen GeoPySpark is installed, it comes with a script which can be accessed\nfrom anywhere on you computer. This script is used to facilitate management\nof the GeoPySpark jar file that must be installed in order for GeoPySpark to\nwork correctly. Here are the available commands:\n\n.. code:: console\n\n   geopyspark -h, --help // return help string and exit\n   geopyspark install-jar // downloads jar file to default location, which is geopyspark install dir\n   geopyspark install-jar -p, --path [download/path] //downloads the jar file to location specified\n   geopyspark jar-path //returns the relative path of the jar file\n   geopyspark jar-path -a, --absolute //returns the absolute path of the jar file\n\n``geopyspark install-jar`` is only needed when installing GeoPySpark through\n``pip``; and it **must** be ran before using GeoPySpark. If no path is selected,\nthen the jar will be installed wherever GeoPySpark was installed.\n\nThe second and third commands are for getting the location of the jar file.\nThese can be used regardless of installation method. However, if installed\nthrough ``pip``, then the jar must be downloaded first or these commands\nwill not work.\n\nDeveloping GeoPySpark\n---------------------\n\nContributing\n~~~~~~~~~~~~\n\nFeedback and contributions to GeoPySpark are always welcomed.\nA CLA is required for contribution, see `Contributing <docs/contributing.rst>`_ for more\ninformation.\n\nInstalling for Developers\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. code:: console\n\n   make build\n   pip install -e .\n\n``make build`` will assemble the back-end ``jar`` and move it the ``jars``\nsub-package. The second command will install GeoPySpark in \"editable\" mode.\nMeaning any changes to the source files will also appear in your system\ninstallation.\n\nWithin a virtualenv\n===================\n\nIt's possible that you may run into issues when performing the ``pip install -e .``\ndescribed above with a Python virtualenv active. If you're having trouble with\nPython finding installed libraries within the virtualenv, try adding the virtualenv\nsite-packages directory to your PYTHONPATH:\n\n.. code:: console\n\n   workon <your-geopyspark-virtualenv-name>\n   export PYTHONPATH=$VIRTUAL_ENV/lib/<your python version>/site-packages\n\nReplace ``<your python version`` with whatever Python version\n``virtualenvwrapper`` is set to. Once you've set PYTHONPATH, re-install\nGeoPySpark using the instructions in \"Installing for Developers\" above.\n\nRunning GeoPySpark Tests\n~~~~~~~~~~~~~~~~~~~~~~~~\n\nGeoPySpark uses the `pytest <https://docs.pytest.org/en/latest/>`_ testing\nframework to run its unittests. If you wish to run GeoPySpark's unittests,\nthen you must first clone this repository to your machine. Once complete,\ngo to the root of the library and run the following command:\n\n.. code:: console\n\n   pytest\n\nThis will then run all of the tests present in the GeoPySpark library.\n\n**Note**: The unittests require additional dependencies in order to pass fully.\n`pyproj <https://pypi.python.org/pypi/pyproj?>`_, `colortools <https://pypi.python.org/pypi/colortools/0.1.2>`_,\nand `matplotlib <https://pypi.python.org/pypi/matplotlib/2.0.2>`_  (only for >=Python3.4) are needed to\nensure that all of the tests pass.\n\nMake Targets\n============\n\n - **install** - install GeoPySpark python package locally\n - **wheel** - build python GeoPySpark wheel for distribution\n - **pyspark** - start pyspark shell with project jars\n - **build** - builds the backend jar and moves it to the jars sub-package\n - **clean** - remove the wheel, the backend jar file, and clean the\n   geotrellis-backend directory\n\nDeveloping GeoPySpark With GeoNotebook\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n**Note**: Before begining this section, it should be noted that python-mapnik,\na dependency for GeoNotebook, has been found to be difficult to install. If\nproblems are encountered during installation, a possible work around would be\nto run ``make wheel`` and then do ``docker cp`` the ``wheel`` into the\nGeoPySpark docker container and install it from there.\n\n`GeoNotebook <https://github.com/OpenGeoscience/geonotebook>`_ is a Jupyter\nnotebook extension that specializes in working with geospatial data. GeoPySpark\ncan be used with this notebook; which allows for a more interactive experience\nwhen using the library. For this section, we will be installing both tools in a\nvirtual environment. It is recommended that you start with a new environment\nbefore following this guide.\n\nBecause there's already documentation on how to install GeoPySpark in a virtual\nenvironment, we won't go over it here. As for GeoNotebook, it also has a section\non `installation <https://github.com/OpenGeoscience/geonotebook#make-a-virtualenv-install-jupyternotebook-install-geonotebook>`_\nso that will not be covered here either.\n\nOnce you've setup both GeoPySpark and GeoNotebook, all that needs to be done\nis go to where you want to save/have saved your notebooks and execute this\ncommand:\n\n.. code:: console\n\n   jupyter notebook\n\nThis will open up the jupyter hub and will allow you to work on your notebooks.\n\nIt is also possible to develop with both GeoPySpark and GeoNotebook in editable mode.\nTo do so you will need to re-install and re-register GeoNotebook with Jupyter.\n\n.. code:: console\n\n   pip uninstall geonotebook\n   git clone --branch feature/geotrellis https://github.com/geotrellis/geonotebook ~/geonotebook\n   pip install -r ~/geonotebook/prerequirements.txt\n   pip install -r ~/geonotebook/requirements.txt\n   pip install -e ~/geonotebook\n   jupyter serverextension enable --py geonotebook\n   jupyter nbextension enable --py geonotebook\n   make notebook\n\nThe default ``Geonotebook (Python 3)`` kernel will require the following environment variables to be defined:\n\n.. code:: console\n\n   export PYSPARK_PYTHON=\"/usr/local/bin/python3\"\n   export SPARK_HOME=\"/usr/local/apache-spark/2.1.1/libexec\"\n   export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.4-src.zip:${SPARK_HOME}/python/lib/pyspark.zip\"\n\nMake sure to define them to values that are correct for your system.\nThe ``make notebook`` command also makes used of ``PYSPARK_SUBMIT_ARGS`` variable defined in the ``Makefile``.\n\nGeoNotebook/GeoTrellis integration in currently in active development and not part of GeoNotebook master.\nThe latest development is on a ``feature/geotrellis`` branch at ``<https://github.com/geotrellis/geonotebook>``.\n\nSide Note For Developers\n========================\n\nAn optional (but recommended!) step for developers is to place these\ntwo lines of code at the top of your notebooks.\n\n.. code:: console\n\n   %load_ext autoreload\n   %autoreload 2\n\nThis will make it so that you don't have to leave the notebook for your changes\nto take affect. Rather, you just have to reimport the module and it will be\nupdated. However, there are a few caveats when using ``autoreload`` that can be\nread `here <http://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html#caveats>`_.\n\nUsing ``pip install -e`` in conjunction with ``autoreload`` should cover any\nchanges made, though, and will make the development experience much less\npainful.", "description_content_type": "", "docs_url": null, "download_url": "http://github.com/locationtech-labs/geopyspark", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "LICENSE", "maintainer": "", "maintainer_email": "", "name": "geopyspark", "package_url": "https://pypi.org/project/geopyspark/", "platform": "", "project_url": "https://pypi.org/project/geopyspark/", "project_urls": {"Download": "http://github.com/locationtech-labs/geopyspark"}, "release_url": "https://pypi.org/project/geopyspark/0.4.3/", "requires_dist": null, "requires_python": "", "summary": "Python bindings for GeoTrellis", "version": "0.4.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://travis-ci.org/locationtech-labs/geopyspark\" rel=\"nofollow\"><img alt=\"https://travis-ci.org/locationtech-labs/geopyspark.svg?branch=master\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f052d8e95eaf3c4886c97023ef13efd849a0a5c7/68747470733a2f2f7472617669732d63692e6f72672f6c6f636174696f6e746563682d6c6162732f67656f7079737061726b2e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://geopyspark.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"https://readthedocs.org/projects/geopyspark/badge/?version=latest\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ddedffa5223a8d655ece7d120b0affad007baaeb/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f67656f7079737061726b2f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<a href=\"https://gitter.im/geotrellis/geotrellis\" rel=\"nofollow\"><img alt=\"https://badges.gitter.im/locationtech-labs/geopyspark.png\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5c2085de7b47f2add3159dff3b4e6dd660e6eedc/68747470733a2f2f6261646765732e6769747465722e696d2f6c6f636174696f6e746563682d6c6162732f67656f7079737061726b2e706e67\"></a>\n<p>GeoPySpark is a Python bindings library for <a href=\"http://geotrellis.io\" rel=\"nofollow\">GeoTrellis</a>, a Scala\nlibrary for working with geospatial data in a distributed environment.\nBy using <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.html\" rel=\"nofollow\">PySpark</a>, GeoPySpark is\nable to provide an interface into the GeoTrellis framework.</p>\n<div id=\"links\">\n<h2>Links</h2>\n<blockquote>\n<ul>\n<li><a href=\"https://geopyspark.readthedocs.io\" rel=\"nofollow\">Documentation</a></li>\n<li><a href=\"https://gitter.im/geotrellis/geotrellis\" rel=\"nofollow\">Gitter</a></li>\n</ul>\n</blockquote>\n</div>\n<div id=\"a-quick-example\">\n<h2>A Quick Example</h2>\n<p>Here is a quick example of GeoPySpark. In the following code, we take NLCD data\nof the state of Pennsylvania from 2011, and do a masking operation on it with\na Polygon that represents an area of interest. This masked layer is then saved.</p>\n<p>If you wish to follow along with this example, you will need to download the\nNLCD data and unzip it.. Running these two commands will complete these tasks\nfor you:</p>\n<pre><span class=\"go\">curl -o /tmp/NLCD2011_LC_Pennsylvania.zip \"https://s3-us-west-2.amazonaws.com/prd-tnm/StagedProducts/NLCD/data/2011/landcover/states/NLCD2011_LC_Pennsylvania.zip?ORIG=513_SBDDG\"\nunzip -d /tmp /tmp/NLCD2011_LC_Pennsylvania.zip</span>\n</pre>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">geopyspark</span> <span class=\"k\">as</span> <span class=\"nn\">gps</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">pyspark</span> <span class=\"kn\">import</span> <span class=\"n\">SparkContext</span>\n<span class=\"kn\">from</span> <span class=\"nn\">shapely.geometry</span> <span class=\"kn\">import</span> <span class=\"n\">box</span>\n\n\n<span class=\"c1\"># Create the SparkContext</span>\n<span class=\"n\">conf</span> <span class=\"o\">=</span> <span class=\"n\">gps</span><span class=\"o\">.</span><span class=\"n\">geopyspark_conf</span><span class=\"p\">(</span><span class=\"n\">appName</span><span class=\"o\">=</span><span class=\"s2\">\"geopyspark-example\"</span><span class=\"p\">,</span> <span class=\"n\">master</span><span class=\"o\">=</span><span class=\"s2\">\"local[*]\"</span><span class=\"p\">)</span>\n<span class=\"n\">sc</span> <span class=\"o\">=</span> <span class=\"n\">SparkContext</span><span class=\"p\">(</span><span class=\"n\">conf</span><span class=\"o\">=</span><span class=\"n\">conf</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Read in the NLCD tif that has been saved locally.</span>\n<span class=\"c1\"># This tif represents the state of Pennsylvania.</span>\n<span class=\"n\">raster_layer</span> <span class=\"o\">=</span> <span class=\"n\">gps</span><span class=\"o\">.</span><span class=\"n\">geotiff</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">layer_type</span><span class=\"o\">=</span><span class=\"n\">gps</span><span class=\"o\">.</span><span class=\"n\">LayerType</span><span class=\"o\">.</span><span class=\"n\">SPATIAL</span><span class=\"p\">,</span>\n                               <span class=\"n\">uri</span><span class=\"o\">=</span><span class=\"s1\">'/tmp/NLCD2011_LC_Pennsylvania.tif'</span><span class=\"p\">,</span>\n                               <span class=\"n\">num_partitions</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Tile the rasters within the layer and reproject them to Web Mercator.</span>\n<span class=\"n\">tiled_layer</span> <span class=\"o\">=</span> <span class=\"n\">raster_layer</span><span class=\"o\">.</span><span class=\"n\">tile_to_layout</span><span class=\"p\">(</span><span class=\"n\">layout</span><span class=\"o\">=</span><span class=\"n\">gps</span><span class=\"o\">.</span><span class=\"n\">GlobalLayout</span><span class=\"p\">(),</span> <span class=\"n\">target_crs</span><span class=\"o\">=</span><span class=\"mi\">3857</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Creates a Polygon that covers roughly the north-west section of Philadelphia.</span>\n<span class=\"c1\"># This is the region that will be masked.</span>\n<span class=\"n\">area_of_interest</span> <span class=\"o\">=</span> <span class=\"n\">box</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mf\">75.229225</span><span class=\"p\">,</span> <span class=\"mf\">40.003686</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">75.107345</span><span class=\"p\">,</span> <span class=\"mf\">40.084375</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Mask the tiles within the layer with the area of interest</span>\n<span class=\"n\">masked</span> <span class=\"o\">=</span> <span class=\"n\">tiled_layer</span><span class=\"o\">.</span><span class=\"n\">mask</span><span class=\"p\">(</span><span class=\"n\">geometries</span><span class=\"o\">=</span><span class=\"n\">area_of_interest</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># We will now pyramid the masked TiledRasterLayer so that we can use it in a TMS server later.</span>\n<span class=\"n\">pyramided_mask</span> <span class=\"o\">=</span> <span class=\"n\">masked</span><span class=\"o\">.</span><span class=\"n\">pyramid</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># Save each layer of the pyramid locally so that it can be accessed at a later time.</span>\n<span class=\"k\">for</span> <span class=\"n\">pyramid</span> <span class=\"ow\">in</span> <span class=\"n\">pyramided_mask</span><span class=\"o\">.</span><span class=\"n\">levels</span><span class=\"o\">.</span><span class=\"n\">values</span><span class=\"p\">():</span>\n    <span class=\"n\">gps</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"n\">uri</span><span class=\"o\">=</span><span class=\"s1\">'file:///tmp/pa-nlcd-2011'</span><span class=\"p\">,</span>\n              <span class=\"n\">layer_name</span><span class=\"o\">=</span><span class=\"s1\">'north-west-philly'</span><span class=\"p\">,</span>\n              <span class=\"n\">tiled_raster_layer</span><span class=\"o\">=</span><span class=\"n\">pyramid</span><span class=\"p\">)</span>\n</pre>\n<p>For additional examples, check out the <a href=\"./notebook-demos\" rel=\"nofollow\">Jupyter notebook demos</a>.</p>\n</div>\n<div id=\"requirements\">\n<h2>Requirements</h2>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Requirement</th>\n<th>Version</th>\n</tr>\n</thead>\n<tbody>\n<tr><td>Java</td>\n<td>&gt;=1.8</td>\n</tr>\n<tr><td>Scala</td>\n<td>&gt;=2.11</td>\n</tr>\n<tr><td>Python</td>\n<td>3.3 - 3.6</td>\n</tr>\n<tr><td>Spark</td>\n<td>&gt;=2.1.1</td>\n</tr>\n</tbody>\n</table>\n<p>Java 8 and Scala 2.11 are needed for GeoPySpark to work, as they are required by\nGeoTrellis. In addition, Spark needs to be installed and configured with the\nenvironment variable <tt>SPARK_HOME</tt> set.</p>\n<p>You can test to see if Spark is installed properly by running the following in\nthe terminal:</p>\n<pre><span class=\"gp\">&gt;</span> <span class=\"nb\">echo</span> <span class=\"nv\">$SPARK_HOME</span>\n<span class=\"go\">/usr/local/bin/spark</span>\n</pre>\n<p>If the return is a path leading to your Spark folder, then it means that Spark\nhas been configured correctly. If <tt>SPARK_HOME</tt> is unset or empty, you\u2019ll need to add it\nto your <tt>PATH</tt> after noting where Spark is installed on your system. For example,\na MacOS installation of Spark 2.3.0 via HomeBrew would set <tt>SPARK_HOME</tt> as follows:</p>\n<pre><span class=\"c1\"># In ~/.bash_profile\n</span><span class=\"nb\">export</span> <span class=\"nv\">SPARK_HOME</span><span class=\"o\">=</span>/usr/local/Cellar/apache-spark/2.3.0/libexec/\n</pre>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>Before installing, check the above <a href=\"#requirements\" rel=\"nofollow\">Requirements</a> table to make sure that the\nrequirements are met.</p>\n<div id=\"installing-from-pip\">\n<h3>Installing From Pip</h3>\n<p>To install via <tt>pip</tt> open the terminal and run the following:</p>\n<pre><span class=\"go\">pip install geopyspark\ngeopyspark install-jar</span>\n</pre>\n<p>The first command installs the python code and the <cite>geopyspark</cite> command\nfrom PyPi. The second downloads the backend jar file, which is too large\nto be included in the pip package, and installs it to the GeoPySpark\ninstallation directory. For more information about the <tt>geopyspark</tt>\ncommand, see the <a href=\"#geopyspark-cli\" rel=\"nofollow\">GeoPySpark CLI</a> section.</p>\n</div>\n<div id=\"installing-from-source\">\n<h3>Installing From Source</h3>\n<p>If you would rather install from source, clone the GeoPySpark repo and enter it.</p>\n<pre><span class=\"go\">git clone https://github.com/locationtech-labs/geopyspark.git\ncd geopyspark\nmake install</span>\n</pre>\n<p>This will assemble the backend-end <tt>jar</tt> that contains the Scala code,\nmove it to the <tt>jars</tt> sub-package, and then runs the <tt>setup.py</tt> script.</p>\n<dl>\n<dt>Note:</dt>\n<dd>If you have altered the global behavior of <tt>sbt</tt> this install may\nnot work the way it was intended.</dd>\n</dl>\n</div>\n<div id=\"uninstalling\">\n<h3>Uninstalling</h3>\n<p>To uninstall GeoPySpark, run the following in the terminal:</p>\n<pre><span class=\"go\">pip uninstall geopyspark\nrm .local/bin/geopyspark</span>\n</pre>\n</div>\n</div>\n<div id=\"contact-and-support\">\n<h2>Contact and Support</h2>\n<p>If you need help, have questions, or like to talk to the developers (let us\nknow what you\u2019re working on!) you can contact us at:</p>\n<blockquote>\n<ul>\n<li><a href=\"https://gitter.im/geotrellis/geotrellis\" rel=\"nofollow\">Gitter</a></li>\n<li><a href=\"https://locationtech.org/mailman/listinfo/geotrellis-user\" rel=\"nofollow\">Mailing list</a></li>\n</ul>\n</blockquote>\n<p>As you may have noticed from the above links, those are links to the GeoTrellis\ngitter channel and mailing list. This is because this project is currently an\noffshoot of GeoTrellis, and we will be using their mailing list and gitter\nchannel as a means of contact. However, we will form our own if there is a need\nfor it.</p>\n</div>\n<div id=\"geopyspark-cli\">\n<h2>GeoPySpark CLI</h2>\n<p>When GeoPySpark is installed, it comes with a script which can be accessed\nfrom anywhere on you computer. This script is used to facilitate management\nof the GeoPySpark jar file that must be installed in order for GeoPySpark to\nwork correctly. Here are the available commands:</p>\n<pre><span class=\"go\">geopyspark -h, --help // return help string and exit\ngeopyspark install-jar // downloads jar file to default location, which is geopyspark install dir\ngeopyspark install-jar -p, --path [download/path] //downloads the jar file to location specified\ngeopyspark jar-path //returns the relative path of the jar file\ngeopyspark jar-path -a, --absolute //returns the absolute path of the jar file</span>\n</pre>\n<p><tt>geopyspark <span class=\"pre\">install-jar</span></tt> is only needed when installing GeoPySpark through\n<tt>pip</tt>; and it <strong>must</strong> be ran before using GeoPySpark. If no path is selected,\nthen the jar will be installed wherever GeoPySpark was installed.</p>\n<p>The second and third commands are for getting the location of the jar file.\nThese can be used regardless of installation method. However, if installed\nthrough <tt>pip</tt>, then the jar must be downloaded first or these commands\nwill not work.</p>\n</div>\n<div id=\"developing-geopyspark\">\n<h2>Developing GeoPySpark</h2>\n<div id=\"contributing\">\n<h3>Contributing</h3>\n<p>Feedback and contributions to GeoPySpark are always welcomed.\nA CLA is required for contribution, see <a href=\"docs/contributing.rst\" rel=\"nofollow\">Contributing</a> for more\ninformation.</p>\n</div>\n<div id=\"installing-for-developers\">\n<h3>Installing for Developers</h3>\n<pre><span class=\"go\">make build\npip install -e .</span>\n</pre>\n<p><tt>make build</tt> will assemble the back-end <tt>jar</tt> and move it the <tt>jars</tt>\nsub-package. The second command will install GeoPySpark in \u201ceditable\u201d mode.\nMeaning any changes to the source files will also appear in your system\ninstallation.</p>\n<div id=\"within-a-virtualenv\">\n<h4>Within a virtualenv</h4>\n<p>It\u2019s possible that you may run into issues when performing the <tt>pip install <span class=\"pre\">-e</span> .</tt>\ndescribed above with a Python virtualenv active. If you\u2019re having trouble with\nPython finding installed libraries within the virtualenv, try adding the virtualenv\nsite-packages directory to your PYTHONPATH:</p>\n<pre><span class=\"go\">workon &lt;your-geopyspark-virtualenv-name&gt;\nexport PYTHONPATH=$VIRTUAL_ENV/lib/&lt;your python version&gt;/site-packages</span>\n</pre>\n<p>Replace <tt>&lt;your python version</tt> with whatever Python version\n<tt>virtualenvwrapper</tt> is set to. Once you\u2019ve set PYTHONPATH, re-install\nGeoPySpark using the instructions in \u201cInstalling for Developers\u201d above.</p>\n</div>\n</div>\n<div id=\"running-geopyspark-tests\">\n<h3>Running GeoPySpark Tests</h3>\n<p>GeoPySpark uses the <a href=\"https://docs.pytest.org/en/latest/\" rel=\"nofollow\">pytest</a> testing\nframework to run its unittests. If you wish to run GeoPySpark\u2019s unittests,\nthen you must first clone this repository to your machine. Once complete,\ngo to the root of the library and run the following command:</p>\n<pre><span class=\"go\">pytest</span>\n</pre>\n<p>This will then run all of the tests present in the GeoPySpark library.</p>\n<p><strong>Note</strong>: The unittests require additional dependencies in order to pass fully.\n<a href=\"https://pypi.python.org/pypi/pyproj?\" rel=\"nofollow\">pyproj</a>, <a href=\"https://pypi.python.org/pypi/colortools/0.1.2\" rel=\"nofollow\">colortools</a>,\nand <a href=\"https://pypi.python.org/pypi/matplotlib/2.0.2\" rel=\"nofollow\">matplotlib</a>  (only for &gt;=Python3.4) are needed to\nensure that all of the tests pass.</p>\n<div id=\"make-targets\">\n<h4>Make Targets</h4>\n<blockquote>\n<ul>\n<li><strong>install</strong> - install GeoPySpark python package locally</li>\n<li><strong>wheel</strong> - build python GeoPySpark wheel for distribution</li>\n<li><strong>pyspark</strong> - start pyspark shell with project jars</li>\n<li><strong>build</strong> - builds the backend jar and moves it to the jars sub-package</li>\n<li><strong>clean</strong> - remove the wheel, the backend jar file, and clean the\ngeotrellis-backend directory</li>\n</ul>\n</blockquote>\n</div>\n</div>\n<div id=\"developing-geopyspark-with-geonotebook\">\n<h3>Developing GeoPySpark With GeoNotebook</h3>\n<p><strong>Note</strong>: Before begining this section, it should be noted that python-mapnik,\na dependency for GeoNotebook, has been found to be difficult to install. If\nproblems are encountered during installation, a possible work around would be\nto run <tt>make wheel</tt> and then do <tt>docker cp</tt> the <tt>wheel</tt> into the\nGeoPySpark docker container and install it from there.</p>\n<p><a href=\"https://github.com/OpenGeoscience/geonotebook\" rel=\"nofollow\">GeoNotebook</a> is a Jupyter\nnotebook extension that specializes in working with geospatial data. GeoPySpark\ncan be used with this notebook; which allows for a more interactive experience\nwhen using the library. For this section, we will be installing both tools in a\nvirtual environment. It is recommended that you start with a new environment\nbefore following this guide.</p>\n<p>Because there\u2019s already documentation on how to install GeoPySpark in a virtual\nenvironment, we won\u2019t go over it here. As for GeoNotebook, it also has a section\non <a href=\"https://github.com/OpenGeoscience/geonotebook#make-a-virtualenv-install-jupyternotebook-install-geonotebook\" rel=\"nofollow\">installation</a>\nso that will not be covered here either.</p>\n<p>Once you\u2019ve setup both GeoPySpark and GeoNotebook, all that needs to be done\nis go to where you want to save/have saved your notebooks and execute this\ncommand:</p>\n<pre><span class=\"go\">jupyter notebook</span>\n</pre>\n<p>This will open up the jupyter hub and will allow you to work on your notebooks.</p>\n<p>It is also possible to develop with both GeoPySpark and GeoNotebook in editable mode.\nTo do so you will need to re-install and re-register GeoNotebook with Jupyter.</p>\n<pre><span class=\"go\">pip uninstall geonotebook\ngit clone --branch feature/geotrellis https://github.com/geotrellis/geonotebook ~/geonotebook\npip install -r ~/geonotebook/prerequirements.txt\npip install -r ~/geonotebook/requirements.txt\npip install -e ~/geonotebook\njupyter serverextension enable --py geonotebook\njupyter nbextension enable --py geonotebook\nmake notebook</span>\n</pre>\n<p>The default <tt>Geonotebook (Python 3)</tt> kernel will require the following environment variables to be defined:</p>\n<pre><span class=\"go\">export PYSPARK_PYTHON=\"/usr/local/bin/python3\"\nexport SPARK_HOME=\"/usr/local/apache-spark/2.1.1/libexec\"\nexport PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.4-src.zip:${SPARK_HOME}/python/lib/pyspark.zip\"</span>\n</pre>\n<p>Make sure to define them to values that are correct for your system.\nThe <tt>make notebook</tt> command also makes used of <tt>PYSPARK_SUBMIT_ARGS</tt> variable defined in the <tt>Makefile</tt>.</p>\n<p>GeoNotebook/GeoTrellis integration in currently in active development and not part of GeoNotebook master.\nThe latest development is on a <tt>feature/geotrellis</tt> branch at <tt><span class=\"pre\">&lt;https://github.com/geotrellis/geonotebook&gt;</span></tt>.</p>\n<div id=\"side-note-for-developers\">\n<h4>Side Note For Developers</h4>\n<p>An optional (but recommended!) step for developers is to place these\ntwo lines of code at the top of your notebooks.</p>\n<pre><span class=\"gp\">%</span>load_ext autoreload\n<span class=\"gp\">%</span>autoreload <span class=\"m\">2</span>\n</pre>\n<p>This will make it so that you don\u2019t have to leave the notebook for your changes\nto take affect. Rather, you just have to reimport the module and it will be\nupdated. However, there are a few caveats when using <tt>autoreload</tt> that can be\nread <a href=\"http://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html#caveats\" rel=\"nofollow\">here</a>.</p>\n<p>Using <tt>pip install <span class=\"pre\">-e</span></tt> in conjunction with <tt>autoreload</tt> should cover any\nchanges made, though, and will make the development experience much less\npainful.</p>\n</div>\n</div>\n</div>\n\n          </div>"}, "last_serial": 4594564, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "50ca605618ff793899de93c30b7093a3", "sha256": "0c36c510b4838c8b94143c925869ebbeec4fbaf358fc40361fbde6e3ff437764"}, "downloads": -1, "filename": "geopyspark-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "50ca605618ff793899de93c30b7093a3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 72122, "upload_time": "2017-05-24T22:00:40", "upload_time_iso_8601": "2017-05-24T22:00:40.935321Z", "url": "https://files.pythonhosted.org/packages/49/fd/9ea6934fd215a2a3a49e980163b1a3c76c0ce7bfa629b79d2b3a07e65845/geopyspark-0.1.0-py3-none-any.whl", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "98c68ee8dedd3f0ffae61f4a361f9099", "sha256": "8df516bade83baef54b42af625b6005d1166188ad497e337922ffd507cc263ae"}, "downloads": -1, "filename": "geopyspark-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "98c68ee8dedd3f0ffae61f4a361f9099", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 109804, "upload_time": "2017-08-14T22:50:44", "upload_time_iso_8601": "2017-08-14T22:50:44.528585Z", "url": "https://files.pythonhosted.org/packages/75/56/fe0c5535e7ab2f52b611b0e06e1b85100c72b1258af8b388a705c39ebe7d/geopyspark-0.2.0-py3-none-any.whl", "yanked": false}], "0.2.0rc1": [{"comment_text": "", "digests": {"md5": "06d3a918abb0cf1697a16a18f4f3668b", "sha256": "a87e8a45cea7ea59d469c4bdd21d5b45cdc0e7e03f0f8b0ef3c7c3e75269d6b5"}, "downloads": -1, "filename": "geopyspark-0.2.0rc1-py3-none-any.whl", "has_sig": false, "md5_digest": "06d3a918abb0cf1697a16a18f4f3668b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 101022, "upload_time": "2017-07-25T16:48:05", "upload_time_iso_8601": "2017-07-25T16:48:05.988613Z", "url": "https://files.pythonhosted.org/packages/42/d8/6d55d5fa19f5e79e54b67f093e1f5b075fdbec30d16af9a944bbeb23c1fc/geopyspark-0.2.0rc1-py3-none-any.whl", "yanked": false}], "0.2.0rc2": [{"comment_text": "", "digests": {"md5": "9f9664315f4e869e3bd4c4cdd3e3666a", "sha256": "7fed3325d20be928127fb93f6f17dfe2b368f72ceffd598f3fc543acaf53f99a"}, "downloads": -1, "filename": "geopyspark-0.2.0rc2-py3-none-any.whl", "has_sig": false, "md5_digest": "9f9664315f4e869e3bd4c4cdd3e3666a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 116744, "upload_time": "2017-07-25T21:12:45", "upload_time_iso_8601": "2017-07-25T21:12:45.215428Z", "url": "https://files.pythonhosted.org/packages/e1/4c/752ea126de239edb4e2dc6cb6e7d7331cdfaa907f604291cbe2f8e6cea87/geopyspark-0.2.0rc2-py3-none-any.whl", "yanked": false}], "0.2.0rc3": [{"comment_text": "", "digests": {"md5": "29bc5109364f2ad65e3dd52a55f872b7", "sha256": "58597461609d42b7019420b962be02e0df3295649d97cfdc447907bcec21e699"}, "downloads": -1, "filename": "geopyspark-0.2.0rc3-py3-none-any.whl", "has_sig": false, "md5_digest": "29bc5109364f2ad65e3dd52a55f872b7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 101885, "upload_time": "2017-07-26T20:33:05", "upload_time_iso_8601": "2017-07-26T20:33:05.512963Z", "url": "https://files.pythonhosted.org/packages/9a/82/c080b0b08ec1a8ffdb4777c924bb8d2d6839424bdd59adab58ee34818e4e/geopyspark-0.2.0rc3-py3-none-any.whl", "yanked": false}], "0.2.0rc4": [{"comment_text": "", "digests": {"md5": "09bbd8625e1e94aeae69961261332e93", "sha256": "248f9c557144d60fae6bfabd7c3a4b98eaf258f1b51958de557df3110ef0dc24"}, "downloads": -1, "filename": "geopyspark-0.2.0rc4-py3-none-any.whl", "has_sig": false, "md5_digest": "09bbd8625e1e94aeae69961261332e93", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 106639, "upload_time": "2017-08-01T23:19:27", "upload_time_iso_8601": "2017-08-01T23:19:27.277008Z", "url": "https://files.pythonhosted.org/packages/cd/b6/cf2d600ca326763eb37d107eb5856a54c71103318283969047b3f76e2457/geopyspark-0.2.0rc4-py3-none-any.whl", "yanked": false}], "0.2.0rc5": [{"comment_text": "", "digests": {"md5": "9eaf966663a03ec45269274529677d07", "sha256": "78eedfb30d8794d08a21dd2a4857bf385d1192d45ff5149b0ac7d53534d62d95"}, "downloads": -1, "filename": "geopyspark-0.2.0rc5-py3-none-any.whl", "has_sig": false, "md5_digest": "9eaf966663a03ec45269274529677d07", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 107320, "upload_time": "2017-08-03T23:01:04", "upload_time_iso_8601": "2017-08-03T23:01:04.720767Z", "url": "https://files.pythonhosted.org/packages/bb/b2/74d75b3df2f62b9d2b1b61667ea0bdfc5638c428cd8204b4849bd5bda241/geopyspark-0.2.0rc5-py3-none-any.whl", "yanked": false}], "0.2.0rc6": [{"comment_text": "", "digests": {"md5": "5266b4c92f3eb2496d2f8761c5f438e9", "sha256": "de8eca20d7281343dafca8acefb6a7ae72f1b4acfc3e15931663715f90ded625"}, "downloads": -1, "filename": "geopyspark-0.2.0rc6-py3-none-any.whl", "has_sig": false, "md5_digest": "5266b4c92f3eb2496d2f8761c5f438e9", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 110185, "upload_time": "2017-08-11T02:18:17", "upload_time_iso_8601": "2017-08-11T02:18:17.980556Z", "url": "https://files.pythonhosted.org/packages/bb/cc/0f776ed8c3c2e33dbb20dee9838a631ab3fd481a94111d9f4cc423781262/geopyspark-0.2.0rc6-py3-none-any.whl", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "2d81586d14daf6346c590c91c3750fc2", "sha256": "5f75a66e795bdaa9541f01b92ba165dbe68d55517d6b13b4b58c4c522598d956"}, "downloads": -1, "filename": "geopyspark-0.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "2d81586d14daf6346c590c91c3750fc2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 110062, "upload_time": "2017-08-25T19:20:35", "upload_time_iso_8601": "2017-08-25T19:20:35.295690Z", "url": "https://files.pythonhosted.org/packages/d0/51/d70871badc7dbe6178237122474e250c4349c9bd3462a34074e3c5d45644/geopyspark-0.2.1-py3-none-any.whl", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "80f438828d53ccc5fadde12539babb4c", "sha256": "da3d13f08f1a5ca675f6544ca38040ee4cb809eb180d056b6c5ace7251ff1623"}, "downloads": -1, "filename": "geopyspark-0.2.2-py3-none-any.whl", "has_sig": false, "md5_digest": "80f438828d53ccc5fadde12539babb4c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 110061, "upload_time": "2017-08-25T20:10:18", "upload_time_iso_8601": "2017-08-25T20:10:18.309553Z", "url": "https://files.pythonhosted.org/packages/f6/30/c169e621794aa7ae35cab495152bf43d1f914156c98eaddcb1bc4214038b/geopyspark-0.2.2-py3-none-any.whl", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "cde1f57473d782de4f64bdfc22915a89", "sha256": "4b83a36cd29a4de973952898f2b889465305b3121195d22561e2d92cf0a1a3aa"}, "downloads": -1, "filename": "geopyspark-0.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "cde1f57473d782de4f64bdfc22915a89", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 124507, "upload_time": "2017-11-29T22:40:35", "upload_time_iso_8601": "2017-11-29T22:40:35.912535Z", "url": "https://files.pythonhosted.org/packages/ce/64/afa14fce2d809c82583bc4aa85743af729ee9f1bd85ee6d3361dcc161b5f/geopyspark-0.3.0-py3-none-any.whl", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "2499f6a9abe00a4e8fb0c2e68ab00f20", "sha256": "3e28ade393a6fe106f2cbc85b65bbc0c534772ca1aba6c4391dc2b0c3bdffe32"}, "downloads": -1, "filename": "geopyspark-0.4.0-py3-none-any.whl", "has_sig": false, "md5_digest": "2499f6a9abe00a4e8fb0c2e68ab00f20", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 90210, "upload_time": "2018-05-02T19:30:50", "upload_time_iso_8601": "2018-05-02T19:30:50.053308Z", "url": "https://files.pythonhosted.org/packages/2d/d5/51c926fe6b1ae908ca7a67f52ff4ea0a162f36b7c0f3cd2a39095c85508b/geopyspark-0.4.0-py3-none-any.whl", "yanked": false}], "0.4.1": [{"comment_text": "", "digests": {"md5": "2ba644862f4c3839080b3be053e787a6", "sha256": "e87d494dd4998fa5c7d116d9cb6cd642bbbef23fe3bdf2fe59db4ee4126b5e07"}, "downloads": -1, "filename": "geopyspark-0.4.1-py3-none-any.whl", "has_sig": false, "md5_digest": "2ba644862f4c3839080b3be053e787a6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 90236, "upload_time": "2018-05-24T16:02:01", "upload_time_iso_8601": "2018-05-24T16:02:01.903471Z", "url": "https://files.pythonhosted.org/packages/08/52/187d79db97f6f65d04b8d327d33b4023e72202441263d5d261555170d5bd/geopyspark-0.4.1-py3-none-any.whl", "yanked": false}], "0.4.2": [{"comment_text": "", "digests": {"md5": "395b49dcda9d6790d17dbe05776a5cb2", "sha256": "da3fa2df56ede96da80cc17d7cacffd0c833ccb8cd3512bde0e3b717db85e6db"}, "downloads": -1, "filename": "geopyspark-0.4.2-py3-none-any.whl", "has_sig": false, "md5_digest": "395b49dcda9d6790d17dbe05776a5cb2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 91944, "upload_time": "2018-06-04T19:16:41", "upload_time_iso_8601": "2018-06-04T19:16:41.640665Z", "url": "https://files.pythonhosted.org/packages/bb/d8/be09d591e3dc34be5370e8284513b1d91cd039e85bfa02d3d2d90cb85dab/geopyspark-0.4.2-py3-none-any.whl", "yanked": false}], "0.4.3": [{"comment_text": "", "digests": {"md5": "f98cdab68c0f8a8a47528c8b44cdc49f", "sha256": "9dc1924f26f484467b8b45624de14add23490b26798abf334cf27ee427640c73"}, "downloads": -1, "filename": "geopyspark-0.4.3-py3.5.egg", "has_sig": false, "md5_digest": "f98cdab68c0f8a8a47528c8b44cdc49f", "packagetype": "bdist_egg", "python_version": "3.5", "requires_python": null, "size": 207562, "upload_time": "2018-12-11T16:24:11", "upload_time_iso_8601": "2018-12-11T16:24:11.570199Z", "url": "https://files.pythonhosted.org/packages/9c/16/88292925a5487aa22901577ae8eeed06c2fd3ecf3c54a34a5c2437b6ae34/geopyspark-0.4.3-py3.5.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "aed4ef157f76f44f5a3a2f35a0ac1611", "sha256": "6d0f824a0c3fa71ee3fb02fe397c3e1dbbbd3653b0cea4ef37cb09a225e38e94"}, "downloads": -1, "filename": "geopyspark-0.4.3-py3-none-any.whl", "has_sig": false, "md5_digest": "aed4ef157f76f44f5a3a2f35a0ac1611", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 90998, "upload_time": "2018-12-13T14:00:36", "upload_time_iso_8601": "2018-12-13T14:00:36.736013Z", "url": "https://files.pythonhosted.org/packages/bf/7a/8b0f2e5b2ec8cb7de4b34e5f2c569ae4d81a4f6155700b5d372ac971ec8a/geopyspark-0.4.3-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "f98cdab68c0f8a8a47528c8b44cdc49f", "sha256": "9dc1924f26f484467b8b45624de14add23490b26798abf334cf27ee427640c73"}, "downloads": -1, "filename": "geopyspark-0.4.3-py3.5.egg", "has_sig": false, "md5_digest": "f98cdab68c0f8a8a47528c8b44cdc49f", "packagetype": "bdist_egg", "python_version": "3.5", "requires_python": null, "size": 207562, "upload_time": "2018-12-11T16:24:11", "upload_time_iso_8601": "2018-12-11T16:24:11.570199Z", "url": "https://files.pythonhosted.org/packages/9c/16/88292925a5487aa22901577ae8eeed06c2fd3ecf3c54a34a5c2437b6ae34/geopyspark-0.4.3-py3.5.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "aed4ef157f76f44f5a3a2f35a0ac1611", "sha256": "6d0f824a0c3fa71ee3fb02fe397c3e1dbbbd3653b0cea4ef37cb09a225e38e94"}, "downloads": -1, "filename": "geopyspark-0.4.3-py3-none-any.whl", "has_sig": false, "md5_digest": "aed4ef157f76f44f5a3a2f35a0ac1611", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 90998, "upload_time": "2018-12-13T14:00:36", "upload_time_iso_8601": "2018-12-13T14:00:36.736013Z", "url": "https://files.pythonhosted.org/packages/bf/7a/8b0f2e5b2ec8cb7de4b34e5f2c569ae4d81a4f6155700b5d372ac971ec8a/geopyspark-0.4.3-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 00:57:57 2020"}