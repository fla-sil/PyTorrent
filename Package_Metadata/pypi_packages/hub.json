{"info": {"author": "Snark AI Inc.", "author_email": "support@snark.ai", "bugtrack_url": null, "classifiers": [], "description": "[![Documentation Status](https://readthedocs.org/projects/hubdb/badge/?version=latest)](https://hubdb.readthedocs.io/en/latest/?badge=latest)\n\n<img src=\"docs/logo/hub_logo.png\" width=\"100%\"/>\n\n**Hub for machine learning to store large datasets, building data pipelines and train models at scale**\n\nHub currently supports following features and more coming soon:\n - **Hub Arrays**: scalable numpy-like arrays stored on the cloud accessible over internet as if they're local numpy arrays.\n\n# Quick Start\n\nLet's see how it works in action:\n```sh\npip3 install hub\n```\n\nCreate a large array and read/write from anywhere as if it's a local array!\n```python\n> import hub\n> datahub = hub.fs('./cache').connect()\n> bigarray = datahub.array('your_array_name', \n          shape=(10000, 10000, 3), \n          chunk=(100, 100, 1), \n          dtype='uint8')\n> bigarray[0,0,0]\n```\nInstead of `hub.fs(path)` (Local File System), you could also use `hub.s3('bucket_name', aws_access_key_id='...', aws_secret_access_key='...')` or `hub.gs('bucket_name', 'gs_cred_path.json')` or chain them together to enable caching mechanism such as `hub.s3('bucket_name').fs('./path/to/cache')`\n\n# Examples\n- [Waymo Open Dataset](https://medium.com/snarkhub/extending-snark-hub-capabilities-to-handle-waymo-open-dataset-4dc7b7d8ab35)\n- [Aptiv nuScenes](https://medium.com/snarkhub/snark-hub-is-hosting-nuscenes-dataset-for-autonomous-driving-1470ae3e1923)\n\n\n# Problems with Current Workflows\n\nMost of the time Data Scientists/ML researchers work on data management and preprocessing instead of doing modeling. Deep Learning often requires to work with large datasets. Those datasets can grow up to terabyte or even petabyte size. It is hard to manage data, version control and track. It is time consuming to download the data and link with the training or inference code. There is no easy way to access a chunk of it and possibly visualize. **Wouldn\u2019t it be more convenient to have large datasets stored & version-controlled as single numpy-like array on the cloud and have access to it from any machine at scale?**\n\nWe realized that there are a few problems related with current workflow in deep learning data management through our experience of working with deep learning companies and researchers.\n1. **Data locality**. When you have local GPU servers but store the data in a secure remote data center or on the cloud, you need to plan ahead to download specific datasets to your GPU box because it takes time. Sharing preprocessed dataset from one GPU box across your team is also slow and error-prone if there're multiple preprocessing pipelines.\n\n2. **Code dependency on local folder structure**. People use a folder structure to store images or videos. As a result, the data input pipeline has to take into consideration the raw folder structure which creates unnecessary & error-prone code dependency of the dataset folder structure.\n\n3. **Managing preprocessing pipelines**. If you want to run some preprocessing, it would be ideal to save the preprocessed images as a local cache for training.But it\u2019s usually hard to manage & version control the preprocessed images locally when there are multiple preprocessing pipelies and the dataset is very big.\n\n4. **Visualization**. It's difficult to visualize the raw data or preprocessed dataset on servers.\n\n5. **Reading a small slice of data**. Another popular way is to store in HDF5/TFRecords format and upload to a cloud bucket, but still you have to manage many chunks of HDF5/TFRecords files. If you want to read a small slice of data, it's not clear which TFRecord/HDF5 chunk you need to load. It's also inefficient to load the whole file for a small slice of data.\n\n6. **Synchronization across team**. If multiple users modify the data, there needs to be a data versioning and synchronization protocol implemented.\n\n7. **RAM management**. Whenever you want to create a numpy array you are worried if the numpy array is going to fit in the local RAM/disk limit.\n\n\n# Workflow with Hub Arrays\nSimply declare an array with the namespace inside the code and thats it. \u201cWhere and How the data is stored?\u201d is totally abstracted away from the data scientist or machine learning engineer. **You can create a numpy array up to Petabytes scale without worrying if the array will fit into RAM or local disk.** The inner workings are like this:\n1. The actual array is created on a cloud bucket (object storage) and partially cached on your local environment. The array size can easily scale to 1PB.\n2. When you read/write to the array, the package automatically synchronize the change from local to cloud bucket via internet.\n\nWe\u2019re working on simple authentication system, data management, advanced data caching & fetching, and version controls.\n\n```python\n> import hub\n> import numpy as np\n\n# Create a large array that you can read/write from anywhere.\n> datahub = hub.s3('bucket_name', aws_access_key_id='...', aws_secret_access_key='...').connect()\n> bigarray = datahub.array('your_array_name', shape=(100000, 512, 512, 3), chunk=(100, 512, 512, 3), dtype='int32')\n\n# Writing to one slice of the array. Automatically syncs to cloud.\n> image = np.random.random((512,512,3))\n> bigarray[0, :,:, :] = image\n\n# Lazy-Load an existing array from cloud without really downloading the entries\n> imagenet = datahub.open('imagenet')\n> imagenet.shape\n(1034908, 469, 387, 3)\n\n# Download the entries from cloud to local on demand.\n> imagenet[0,:,:,:].mean()\n```\n\n## Usage\n**Step 1.** Install\n```sh\npip3 install hub\n```\n\n**Step 2.** Lazy-load a public dataset, and fetch a single image with up to 50MB/s speed and plot\n```python\n> import hub\n> datahub = hub.gs('your_bucket_name', 'your_creds_path.json').connect()\n> imagenet = datahub.open('imagenet')\n> imagenet.shape\n(1034908, 469, 387, 3)\n\n> import matplotlib.pyplot as plt\n> plt.imshow(imagenet[0])\n```\n\n**Step 3.** Compute the mean and standard deviation of any chunk of the full dataset\n```python\n> imagenet[0:10,100:200,100:200].mean()\n0.132\n> imagenet[0:10,100:200,100:200].std()\n0.005\n```\n\n**Step 4.** Create your own array and access it from another machine\n```python\n# Create on one machine\n> import numpy as np\n> datahub = hub.s3('bucket_name', aws_access_key_id='...', aws_secret_access_key='...').connect()\n> mnist = datahub.array(shape=(50000,28,28,1), name='name/random_name')\n> mnist[0,:,:,:] = np.random.random((1,28,28,1))\n\n# Access it from another machine\n> mnist = datahub.open('name/random_name')\n> print(mnist[0])\n```\n\n\n## Features\n* **Data Management**: Storing large datasets with version control\n* **Collaboration**: Multiple data scientists working on the same data in sync\n* **Distribute**: Accessing from multiple machines at the same time\n* **Machine Learning**: Native integration with Numpy, Dask, PyTorch or TensorFlow.\n* **Scale**: Create as big arrays as you want\n* **Visualization**: Visualize the data without trouble\n\n## Benchmarking\n\nFor full reproducibility please refer to the [code](/test/benchmark)\n\n### Download Parallelism\n\nThe following chart shows that hub on a single machine (aws p3.2xlarge) can achieve up to 875 MB/s download speed with multithreading and multiprocessing enabled. Choosing the chunk size plays a role in reaching maximum speed up. The bellow chart shows the tradeoff using different number of threads and processes.\n\n<img src=\"test/benchmark/results/Parallel12MB.png\" width=\"650\"/>\n\n\n### Training Deep Learning Model \n\nThe following benchmark shows that streaming data through Hub package while training deep learning model is equivalent to reading data from local file system. The benchmarks have been produced on AWS using p3.2xlarge machine with V100 GPU. The data is stored on S3 within the same region. In the asynchronous data loading figure, first three models (VGG, Resnet101 and DenseNet) have no data bottleneck. Basically the processing time is greater than loading the data in the background. However for more lightweight models such as Resnet18 or SqueezeNet, training is bottlenecked on reading speed. Number of parallel workers for reading the data has been chosen to be the same. The batch size was chosen smaller for large models to fit in the GPU RAM.  \n\nTraining Deep Learning          |  Data Streaming\n:-------------------------:|:-------------------------:\n<img src=\"test/benchmark/results/Training.png\" alt=\"Training\" width=\"440\"/>  |   <img src=\"test/benchmark/results/Data%20Bottleneck.png\" width=\"440\"/>\n\n## Use Cases\n* **Aerial images**: Satellite and drone imagery\n* **Medical Images**: Volumetric images such as MRI or Xray\n* **Self-Driving Cars**: Radar, 3D LIDAR, Point Cloud, Semantic Segmentation, Video Objects\n* **Retail**: Self-checkout datasets\n* **Media**: Images, Video, Audio storage\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/snarkai/hub", "keywords": "snark-hub", "license": "", "maintainer": "", "maintainer_email": "", "name": "hub", "package_url": "https://pypi.org/project/hub/", "platform": "", "project_url": "https://pypi.org/project/hub/", "project_urls": {"Homepage": "https://github.com/snarkai/hub"}, "release_url": "https://pypi.org/project/hub/0.4.1.4/", "requires_dist": ["click (<8,>=6.7)", "pathos (==0.2.2.1)", "boto3 (<3,>=1.9.2)", "botocore (>=1.12.204)", "numpy (<2,>=1.18.1)", "tenacity (<7,>=5)", "google-cloud-storage (<2,>=1)", "pillow (<8,>=6)", "lz4 (<4,>=3)", "retrying (<2,>=1)"], "requires_python": ">=3", "summary": "Snark Hub", "version": "0.4.1.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://hubdb.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/be3e145da7b9b8277926577f53f9769aa9d06146/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f68756264622f62616467652f3f76657273696f6e3d6c6174657374\"></a></p>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9a73beda13d5d4b53e1d51fac31c46a7360cfe60/646f63732f6c6f676f2f6875625f6c6f676f2e706e67\" width=\"100%\">\n<p><strong>Hub for machine learning to store large datasets, building data pipelines and train models at scale</strong></p>\n<p>Hub currently supports following features and more coming soon:</p>\n<ul>\n<li><strong>Hub Arrays</strong>: scalable numpy-like arrays stored on the cloud accessible over internet as if they're local numpy arrays.</li>\n</ul>\n<h1>Quick Start</h1>\n<p>Let's see how it works in action:</p>\n<pre>pip3 install hub\n</pre>\n<p>Create a large array and read/write from anywhere as if it's a local array!</p>\n<pre><span class=\"o\">&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">hub</span>\n<span class=\"o\">&gt;</span> <span class=\"n\">datahub</span> <span class=\"o\">=</span> <span class=\"n\">hub</span><span class=\"o\">.</span><span class=\"n\">fs</span><span class=\"p\">(</span><span class=\"s1\">'./cache'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">connect</span><span class=\"p\">()</span>\n<span class=\"o\">&gt;</span> <span class=\"n\">bigarray</span> <span class=\"o\">=</span> <span class=\"n\">datahub</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"s1\">'your_array_name'</span><span class=\"p\">,</span> \n          <span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">10000</span><span class=\"p\">,</span> <span class=\"mi\">10000</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">),</span> \n          <span class=\"n\">chunk</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span> \n          <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s1\">'uint8'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;</span> <span class=\"n\">bigarray</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n</pre>\n<p>Instead of <code>hub.fs(path)</code> (Local File System), you could also use <code>hub.s3('bucket_name', aws_access_key_id='...', aws_secret_access_key='...')</code> or <code>hub.gs('bucket_name', 'gs_cred_path.json')</code> or chain them together to enable caching mechanism such as <code>hub.s3('bucket_name').fs('./path/to/cache')</code></p>\n<h1>Examples</h1>\n<ul>\n<li><a href=\"https://medium.com/snarkhub/extending-snark-hub-capabilities-to-handle-waymo-open-dataset-4dc7b7d8ab35\" rel=\"nofollow\">Waymo Open Dataset</a></li>\n<li><a href=\"https://medium.com/snarkhub/snark-hub-is-hosting-nuscenes-dataset-for-autonomous-driving-1470ae3e1923\" rel=\"nofollow\">Aptiv nuScenes</a></li>\n</ul>\n<h1>Problems with Current Workflows</h1>\n<p>Most of the time Data Scientists/ML researchers work on data management and preprocessing instead of doing modeling. Deep Learning often requires to work with large datasets. Those datasets can grow up to terabyte or even petabyte size. It is hard to manage data, version control and track. It is time consuming to download the data and link with the training or inference code. There is no easy way to access a chunk of it and possibly visualize. <strong>Wouldn\u2019t it be more convenient to have large datasets stored &amp; version-controlled as single numpy-like array on the cloud and have access to it from any machine at scale?</strong></p>\n<p>We realized that there are a few problems related with current workflow in deep learning data management through our experience of working with deep learning companies and researchers.</p>\n<ol>\n<li>\n<p><strong>Data locality</strong>. When you have local GPU servers but store the data in a secure remote data center or on the cloud, you need to plan ahead to download specific datasets to your GPU box because it takes time. Sharing preprocessed dataset from one GPU box across your team is also slow and error-prone if there're multiple preprocessing pipelines.</p>\n</li>\n<li>\n<p><strong>Code dependency on local folder structure</strong>. People use a folder structure to store images or videos. As a result, the data input pipeline has to take into consideration the raw folder structure which creates unnecessary &amp; error-prone code dependency of the dataset folder structure.</p>\n</li>\n<li>\n<p><strong>Managing preprocessing pipelines</strong>. If you want to run some preprocessing, it would be ideal to save the preprocessed images as a local cache for training.But it\u2019s usually hard to manage &amp; version control the preprocessed images locally when there are multiple preprocessing pipelies and the dataset is very big.</p>\n</li>\n<li>\n<p><strong>Visualization</strong>. It's difficult to visualize the raw data or preprocessed dataset on servers.</p>\n</li>\n<li>\n<p><strong>Reading a small slice of data</strong>. Another popular way is to store in HDF5/TFRecords format and upload to a cloud bucket, but still you have to manage many chunks of HDF5/TFRecords files. If you want to read a small slice of data, it's not clear which TFRecord/HDF5 chunk you need to load. It's also inefficient to load the whole file for a small slice of data.</p>\n</li>\n<li>\n<p><strong>Synchronization across team</strong>. If multiple users modify the data, there needs to be a data versioning and synchronization protocol implemented.</p>\n</li>\n<li>\n<p><strong>RAM management</strong>. Whenever you want to create a numpy array you are worried if the numpy array is going to fit in the local RAM/disk limit.</p>\n</li>\n</ol>\n<h1>Workflow with Hub Arrays</h1>\n<p>Simply declare an array with the namespace inside the code and thats it. \u201cWhere and How the data is stored?\u201d is totally abstracted away from the data scientist or machine learning engineer. <strong>You can create a numpy array up to Petabytes scale without worrying if the array will fit into RAM or local disk.</strong> The inner workings are like this:</p>\n<ol>\n<li>The actual array is created on a cloud bucket (object storage) and partially cached on your local environment. The array size can easily scale to 1PB.</li>\n<li>When you read/write to the array, the package automatically synchronize the change from local to cloud bucket via internet.</li>\n</ol>\n<p>We\u2019re working on simple authentication system, data management, advanced data caching &amp; fetching, and version controls.</p>\n<pre><span class=\"o\">&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">hub</span>\n<span class=\"o\">&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n\n<span class=\"c1\"># Create a large array that you can read/write from anywhere.</span>\n<span class=\"o\">&gt;</span> <span class=\"n\">datahub</span> <span class=\"o\">=</span> <span class=\"n\">hub</span><span class=\"o\">.</span><span class=\"n\">s3</span><span class=\"p\">(</span><span class=\"s1\">'bucket_name'</span><span class=\"p\">,</span> <span class=\"n\">aws_access_key_id</span><span class=\"o\">=</span><span class=\"s1\">'...'</span><span class=\"p\">,</span> <span class=\"n\">aws_secret_access_key</span><span class=\"o\">=</span><span class=\"s1\">'...'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">connect</span><span class=\"p\">()</span>\n<span class=\"o\">&gt;</span> <span class=\"n\">bigarray</span> <span class=\"o\">=</span> <span class=\"n\">datahub</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"s1\">'your_array_name'</span><span class=\"p\">,</span> <span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">100000</span><span class=\"p\">,</span> <span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">),</span> <span class=\"n\">chunk</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s1\">'int32'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Writing to one slice of the array. Automatically syncs to cloud.</span>\n<span class=\"o\">&gt;</span> <span class=\"n\">image</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"p\">((</span><span class=\"mi\">512</span><span class=\"p\">,</span><span class=\"mi\">512</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">))</span>\n<span class=\"o\">&gt;</span> <span class=\"n\">bigarray</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"p\">:,:,</span> <span class=\"p\">:]</span> <span class=\"o\">=</span> <span class=\"n\">image</span>\n\n<span class=\"c1\"># Lazy-Load an existing array from cloud without really downloading the entries</span>\n<span class=\"o\">&gt;</span> <span class=\"n\">imagenet</span> <span class=\"o\">=</span> <span class=\"n\">datahub</span><span class=\"o\">.</span><span class=\"n\">open</span><span class=\"p\">(</span><span class=\"s1\">'imagenet'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;</span> <span class=\"n\">imagenet</span><span class=\"o\">.</span><span class=\"n\">shape</span>\n<span class=\"p\">(</span><span class=\"mi\">1034908</span><span class=\"p\">,</span> <span class=\"mi\">469</span><span class=\"p\">,</span> <span class=\"mi\">387</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Download the entries from cloud to local on demand.</span>\n<span class=\"o\">&gt;</span> <span class=\"n\">imagenet</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,:,:,:]</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span>\n</pre>\n<h2>Usage</h2>\n<p><strong>Step 1.</strong> Install</p>\n<pre>pip3 install hub\n</pre>\n<p><strong>Step 2.</strong> Lazy-load a public dataset, and fetch a single image with up to 50MB/s speed and plot</p>\n<pre><span class=\"o\">&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">hub</span>\n<span class=\"o\">&gt;</span> <span class=\"n\">datahub</span> <span class=\"o\">=</span> <span class=\"n\">hub</span><span class=\"o\">.</span><span class=\"n\">gs</span><span class=\"p\">(</span><span class=\"s1\">'your_bucket_name'</span><span class=\"p\">,</span> <span class=\"s1\">'your_creds_path.json'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">connect</span><span class=\"p\">()</span>\n<span class=\"o\">&gt;</span> <span class=\"n\">imagenet</span> <span class=\"o\">=</span> <span class=\"n\">datahub</span><span class=\"o\">.</span><span class=\"n\">open</span><span class=\"p\">(</span><span class=\"s1\">'imagenet'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;</span> <span class=\"n\">imagenet</span><span class=\"o\">.</span><span class=\"n\">shape</span>\n<span class=\"p\">(</span><span class=\"mi\">1034908</span><span class=\"p\">,</span> <span class=\"mi\">469</span><span class=\"p\">,</span> <span class=\"mi\">387</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">)</span>\n\n<span class=\"o\">&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"k\">as</span> <span class=\"nn\">plt</span>\n<span class=\"o\">&gt;</span> <span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">imshow</span><span class=\"p\">(</span><span class=\"n\">imagenet</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n</pre>\n<p><strong>Step 3.</strong> Compute the mean and standard deviation of any chunk of the full dataset</p>\n<pre><span class=\"o\">&gt;</span> <span class=\"n\">imagenet</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">:</span><span class=\"mi\">10</span><span class=\"p\">,</span><span class=\"mi\">100</span><span class=\"p\">:</span><span class=\"mi\">200</span><span class=\"p\">,</span><span class=\"mi\">100</span><span class=\"p\">:</span><span class=\"mi\">200</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span>\n<span class=\"mf\">0.132</span>\n<span class=\"o\">&gt;</span> <span class=\"n\">imagenet</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">:</span><span class=\"mi\">10</span><span class=\"p\">,</span><span class=\"mi\">100</span><span class=\"p\">:</span><span class=\"mi\">200</span><span class=\"p\">,</span><span class=\"mi\">100</span><span class=\"p\">:</span><span class=\"mi\">200</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">std</span><span class=\"p\">()</span>\n<span class=\"mf\">0.005</span>\n</pre>\n<p><strong>Step 4.</strong> Create your own array and access it from another machine</p>\n<pre><span class=\"c1\"># Create on one machine</span>\n<span class=\"o\">&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"o\">&gt;</span> <span class=\"n\">datahub</span> <span class=\"o\">=</span> <span class=\"n\">hub</span><span class=\"o\">.</span><span class=\"n\">s3</span><span class=\"p\">(</span><span class=\"s1\">'bucket_name'</span><span class=\"p\">,</span> <span class=\"n\">aws_access_key_id</span><span class=\"o\">=</span><span class=\"s1\">'...'</span><span class=\"p\">,</span> <span class=\"n\">aws_secret_access_key</span><span class=\"o\">=</span><span class=\"s1\">'...'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">connect</span><span class=\"p\">()</span>\n<span class=\"o\">&gt;</span> <span class=\"n\">mnist</span> <span class=\"o\">=</span> <span class=\"n\">datahub</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">50000</span><span class=\"p\">,</span><span class=\"mi\">28</span><span class=\"p\">,</span><span class=\"mi\">28</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">),</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'name/random_name'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;</span> <span class=\"n\">mnist</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,:,:,:]</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">28</span><span class=\"p\">,</span><span class=\"mi\">28</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">))</span>\n\n<span class=\"c1\"># Access it from another machine</span>\n<span class=\"o\">&gt;</span> <span class=\"n\">mnist</span> <span class=\"o\">=</span> <span class=\"n\">datahub</span><span class=\"o\">.</span><span class=\"n\">open</span><span class=\"p\">(</span><span class=\"s1\">'name/random_name'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">mnist</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n</pre>\n<h2>Features</h2>\n<ul>\n<li><strong>Data Management</strong>: Storing large datasets with version control</li>\n<li><strong>Collaboration</strong>: Multiple data scientists working on the same data in sync</li>\n<li><strong>Distribute</strong>: Accessing from multiple machines at the same time</li>\n<li><strong>Machine Learning</strong>: Native integration with Numpy, Dask, PyTorch or TensorFlow.</li>\n<li><strong>Scale</strong>: Create as big arrays as you want</li>\n<li><strong>Visualization</strong>: Visualize the data without trouble</li>\n</ul>\n<h2>Benchmarking</h2>\n<p>For full reproducibility please refer to the <a href=\"/test/benchmark\" rel=\"nofollow\">code</a></p>\n<h3>Download Parallelism</h3>\n<p>The following chart shows that hub on a single machine (aws p3.2xlarge) can achieve up to 875 MB/s download speed with multithreading and multiprocessing enabled. Choosing the chunk size plays a role in reaching maximum speed up. The bellow chart shows the tradeoff using different number of threads and processes.</p>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/82f3d459c78bb402bda9f8a39f894cb85e5e14e4/746573742f62656e63686d61726b2f726573756c74732f506172616c6c656c31324d422e706e67\" width=\"650\">\n<h3>Training Deep Learning Model</h3>\n<p>The following benchmark shows that streaming data through Hub package while training deep learning model is equivalent to reading data from local file system. The benchmarks have been produced on AWS using p3.2xlarge machine with V100 GPU. The data is stored on S3 within the same region. In the asynchronous data loading figure, first three models (VGG, Resnet101 and DenseNet) have no data bottleneck. Basically the processing time is greater than loading the data in the background. However for more lightweight models such as Resnet18 or SqueezeNet, training is bottlenecked on reading speed. Number of parallel workers for reading the data has been chosen to be the same. The batch size was chosen smaller for large models to fit in the GPU RAM.</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">Training Deep Learning</th>\n<th align=\"center\">Data Streaming</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\"><img alt=\"Training\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a8ad99704ecc052117c24f818a3691a5bb8cfc36/746573742f62656e63686d61726b2f726573756c74732f547261696e696e672e706e67\" width=\"440\"></td>\n<td align=\"center\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/323028ccb6d23b17c70c0b697e5268910f9489b0/746573742f62656e63686d61726b2f726573756c74732f44617461253230426f74746c656e65636b2e706e67\" width=\"440\"></td>\n</tr></tbody></table>\n<h2>Use Cases</h2>\n<ul>\n<li><strong>Aerial images</strong>: Satellite and drone imagery</li>\n<li><strong>Medical Images</strong>: Volumetric images such as MRI or Xray</li>\n<li><strong>Self-Driving Cars</strong>: Radar, 3D LIDAR, Point Cloud, Semantic Segmentation, Video Objects</li>\n<li><strong>Retail</strong>: Self-checkout datasets</li>\n<li><strong>Media</strong>: Images, Video, Audio storage</li>\n</ul>\n\n          </div>"}, "last_serial": 7146975, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "abce2d6a8d026c4e049f559aaaf8506c", "sha256": "a7f66a2af516e5f80ab98f0f1e21c9d4e019a853e8b0bcf65498277ef0277f4d"}, "downloads": -1, "filename": "hub-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "abce2d6a8d026c4e049f559aaaf8506c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 6300, "upload_time": "2019-08-11T23:02:03", "upload_time_iso_8601": "2019-08-11T23:02:03.430466Z", "url": "https://files.pythonhosted.org/packages/e1/4a/a6f733af5e4ce47eca678a81217712db7a843a3cadda6e7e9241e5824515/hub-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5e9d1ee0c7d72ff7aeff75087aa59f90", "sha256": "71a09c8441f9258ae73c5a99114261a08d30c1f35ab40fbe3b070857c96228ab"}, "downloads": -1, "filename": "hub-0.0.1.tar.gz", "has_sig": false, "md5_digest": "5e9d1ee0c7d72ff7aeff75087aa59f90", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 5503, "upload_time": "2019-08-11T23:02:04", "upload_time_iso_8601": "2019-08-11T23:02:04.804883Z", "url": "https://files.pythonhosted.org/packages/40/ff/d344154d2afce283bd4a0c65fbdd549b4fddb19fdd6f03ff295e8b3e7fca/hub-0.0.1.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "60464483767681f55d009248d8e49959", "sha256": "28fe8f47cf51d578e30867a2dbf34a07fe3c182bca3c8d2b21d0b70777eb26b9"}, "downloads": -1, "filename": "hub-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "60464483767681f55d009248d8e49959", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 22592, "upload_time": "2019-08-15T06:30:11", "upload_time_iso_8601": "2019-08-15T06:30:11.916331Z", "url": "https://files.pythonhosted.org/packages/cd/31/4c7dfbf5f2bf22c05f81d7b9618ae5ded9274e04fc01894a99a2e3269e13/hub-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8c71efed34fc18755b4d24a914bf33fa", "sha256": "40d7cf6384e3d35680595829bd1b22a69b33bc4a21b48f120996f7d3224f209e"}, "downloads": -1, "filename": "hub-0.1.0.tar.gz", "has_sig": false, "md5_digest": "8c71efed34fc18755b4d24a914bf33fa", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15925, "upload_time": "2019-08-15T06:30:13", "upload_time_iso_8601": "2019-08-15T06:30:13.753589Z", "url": "https://files.pythonhosted.org/packages/72/d0/f0e29f499cc3953d6293387b8fe2a803865578820d4eb8fc6c18d52bc8ff/hub-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "9c60a5dd8affb2f64f33f41953379ca6", "sha256": "14e7c285421bc3dbb7a5713916dfc59c3253766f5541e4d372edf6bee0b8163c"}, "downloads": -1, "filename": "hub-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "9c60a5dd8affb2f64f33f41953379ca6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 22600, "upload_time": "2019-08-15T06:33:34", "upload_time_iso_8601": "2019-08-15T06:33:34.091359Z", "url": "https://files.pythonhosted.org/packages/86/c7/c0d817d08398bc2c0c2250c899953e11581094b00316c2dee413f9d0c9b8/hub-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c6c336f3bf97a7b9aac887226308fe0e", "sha256": "7c755985c0cad15c8f291e7e4cd04909bff0490ec7216d8a0a8037e3f7426225"}, "downloads": -1, "filename": "hub-0.1.1.tar.gz", "has_sig": false, "md5_digest": "c6c336f3bf97a7b9aac887226308fe0e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 15956, "upload_time": "2019-08-15T06:33:35", "upload_time_iso_8601": "2019-08-15T06:33:35.718828Z", "url": "https://files.pythonhosted.org/packages/7a/70/8f261464bbc810e34b468c9c82ce042ef5d394a69a20404aab33f3cbb011/hub-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "adc41ef80fa615edad36072842f9ecd0", "sha256": "49b6d57180e85264c0448e7f18a8cb63cc86ad64b2b9059f095291e422f6a5c1"}, "downloads": -1, "filename": "hub-0.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "adc41ef80fa615edad36072842f9ecd0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 22371, "upload_time": "2019-08-15T20:45:56", "upload_time_iso_8601": "2019-08-15T20:45:56.781115Z", "url": "https://files.pythonhosted.org/packages/d9/b3/1477d1e88e3ff172bf36522c8b82c053ca11abcac717e64f7539c8dda18c/hub-0.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6d70203468bc635f26bf19dbff5221a1", "sha256": "f53cd026638b7b0f09ddca69cc8b550cf1a562e4578e3cb267be76b71b5af0cb"}, "downloads": -1, "filename": "hub-0.1.2.tar.gz", "has_sig": false, "md5_digest": "6d70203468bc635f26bf19dbff5221a1", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 15787, "upload_time": "2019-08-15T20:45:58", "upload_time_iso_8601": "2019-08-15T20:45:58.502727Z", "url": "https://files.pythonhosted.org/packages/36/4e/456c6144d84c0ef604ec6886030f7b430436c97ae5e017138caf68839fbe/hub-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "a95364713dc08bfda34b20b3c45db2be", "sha256": "254dca8d5fce8d7e2f10244b3996b2d03411ca7355a3f07d2785bb0f0e48e6af"}, "downloads": -1, "filename": "hub-0.1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "a95364713dc08bfda34b20b3c45db2be", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 22387, "upload_time": "2019-08-15T21:06:41", "upload_time_iso_8601": "2019-08-15T21:06:41.239217Z", "url": "https://files.pythonhosted.org/packages/28/a8/64488aedd973f3116ea453ab40538ae081d56a74ef3dc044f02ad083edb1/hub-0.1.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "927e677afe1166c305c80540a53e01c8", "sha256": "dfec363cc77e033facd0ffc111459910eaf805db96adc42b236f86ff45c7ff6a"}, "downloads": -1, "filename": "hub-0.1.3.tar.gz", "has_sig": false, "md5_digest": "927e677afe1166c305c80540a53e01c8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 15797, "upload_time": "2019-08-15T21:06:42", "upload_time_iso_8601": "2019-08-15T21:06:42.568251Z", "url": "https://files.pythonhosted.org/packages/72/85/3c9d853c12b9b71ebb603dee1d928112543758ab9d228ade25ec94faf42b/hub-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "7b38766dcb6ed2e6106c59a7e0fb0844", "sha256": "f397366c5864dd968687bf8caff36fec6692fe7177e5113e8c1b503656e8f3c1"}, "downloads": -1, "filename": "hub-0.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "7b38766dcb6ed2e6106c59a7e0fb0844", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 24757, "upload_time": "2019-08-15T21:56:44", "upload_time_iso_8601": "2019-08-15T21:56:44.342070Z", "url": "https://files.pythonhosted.org/packages/52/72/36fea9b29d39aefabeaeb9e7f85680b467e7f6fdaf09b3e4072f67ff46e9/hub-0.1.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "911c04609cddff9072350e65480e6129", "sha256": "49649646ad13b2c74ed3829527fa48ee2cec743eb3342adc157a14354c4f9fa8"}, "downloads": -1, "filename": "hub-0.1.4.tar.gz", "has_sig": false, "md5_digest": "911c04609cddff9072350e65480e6129", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 19720, "upload_time": "2019-08-15T21:56:46", "upload_time_iso_8601": "2019-08-15T21:56:46.067794Z", "url": "https://files.pythonhosted.org/packages/17/14/f0df014acb29051fa331adaae5b2db77cc834db2d979c809072f7cc07178/hub-0.1.4.tar.gz", "yanked": false}], "0.1.5": [{"comment_text": "", "digests": {"md5": "0645233c15206f0bf77c1b8a5c0e1905", "sha256": "bf6b046bd13105fb7beda5a1e0747a03856cf8725f51631d85377df138b1996c"}, "downloads": -1, "filename": "hub-0.1.5-py3-none-any.whl", "has_sig": false, "md5_digest": "0645233c15206f0bf77c1b8a5c0e1905", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 24752, "upload_time": "2019-08-15T23:20:48", "upload_time_iso_8601": "2019-08-15T23:20:48.013102Z", "url": "https://files.pythonhosted.org/packages/1c/ea/32d37c8e410294ba0633d5b747e384d3afe72008a07ab9843a3d050f21f5/hub-0.1.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6280d1da24237e8e0c3ea5e6c69d5888", "sha256": "9170f2105b82291153e43b536aac034d4c9077431ed671bbfe45bfceec0eb01e"}, "downloads": -1, "filename": "hub-0.1.5.tar.gz", "has_sig": false, "md5_digest": "6280d1da24237e8e0c3ea5e6c69d5888", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 20287, "upload_time": "2019-08-15T23:20:49", "upload_time_iso_8601": "2019-08-15T23:20:49.709737Z", "url": "https://files.pythonhosted.org/packages/b7/1e/ae17736c4c0e0352b5ee8afcea76d6a9a703ea1833edade605809055fb1f/hub-0.1.5.tar.gz", "yanked": false}], "0.1.6": [{"comment_text": "", "digests": {"md5": "3126e342354e72b5d6f94b9b93779adf", "sha256": "2f3a866b203f4dc2cc081369887ddc7f4faee0a8eab2d69b8ac649a2d6cd1fff"}, "downloads": -1, "filename": "hub-0.1.6-py3-none-any.whl", "has_sig": false, "md5_digest": "3126e342354e72b5d6f94b9b93779adf", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 24741, "upload_time": "2019-08-16T20:44:02", "upload_time_iso_8601": "2019-08-16T20:44:02.491187Z", "url": "https://files.pythonhosted.org/packages/79/87/65cded44ef347873f890b0997cf56658e08eb438ef0df1525aa6338efce3/hub-0.1.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3ac654df27424fc61fb88c0d6a2d2780", "sha256": "1fdecaa87e5a71dcd3e02e21f0d6f59956bd2ef9941e96ec9fdc92ee93e4935b"}, "downloads": -1, "filename": "hub-0.1.6.tar.gz", "has_sig": false, "md5_digest": "3ac654df27424fc61fb88c0d6a2d2780", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 19790, "upload_time": "2019-08-16T20:44:04", "upload_time_iso_8601": "2019-08-16T20:44:04.344120Z", "url": "https://files.pythonhosted.org/packages/a2/d0/4b927e913e579d70717bed453a1bc9b3dabff5d9f8ebc2123d1747d13c19/hub-0.1.6.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "677fc7285093c720909bfd2e8df042a6", "sha256": "dd8cd05e47131a3277bfe6d7c8abd6a926151a082ebbd71f6013071295f9ca10"}, "downloads": -1, "filename": "hub-0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "677fc7285093c720909bfd2e8df042a6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 25371, "upload_time": "2019-08-23T18:00:30", "upload_time_iso_8601": "2019-08-23T18:00:30.313902Z", "url": "https://files.pythonhosted.org/packages/93/50/9e978f64214fb2a764a875412e8db707a90f053cd84358f61ac341a0b28d/hub-0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5eff038e97018b825c27fb4bfe64525a", "sha256": "f4dbcec98b4ca61a27b66f2bdc8c180c83707e6c392dc3a91eae3911f044f67c"}, "downloads": -1, "filename": "hub-0.2.tar.gz", "has_sig": false, "md5_digest": "5eff038e97018b825c27fb4bfe64525a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 21060, "upload_time": "2019-08-23T18:00:32", "upload_time_iso_8601": "2019-08-23T18:00:32.146870Z", "url": "https://files.pythonhosted.org/packages/3d/f0/adf3b5ba051bf0f541d50d994d6ad3170b0096db6bf990a00253a6679cc5/hub-0.2.tar.gz", "yanked": false}], "0.2.0.1": [{"comment_text": "", "digests": {"md5": "e156765ead49090dd146d963302f238c", "sha256": "7befaa6258613d19745592b7bdd254569cc6165d93cc282653a89582a464539a"}, "downloads": -1, "filename": "hub-0.2.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "e156765ead49090dd146d963302f238c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 28866, "upload_time": "2019-08-23T18:19:25", "upload_time_iso_8601": "2019-08-23T18:19:25.309891Z", "url": "https://files.pythonhosted.org/packages/b0/1c/7a05815bf15d82ad70ec0f9f47a1b343bbaa500641fff8b5e925f4c7492a/hub-0.2.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b023d418f617d73fad3b8af3b7f91a34", "sha256": "e6ed993c117bac960d09b783ac8b7389d6db3c0ac25b6091d4500fcdbe1373a1"}, "downloads": -1, "filename": "hub-0.2.0.1.tar.gz", "has_sig": false, "md5_digest": "b023d418f617d73fad3b8af3b7f91a34", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 23924, "upload_time": "2019-08-23T18:19:27", "upload_time_iso_8601": "2019-08-23T18:19:27.397769Z", "url": "https://files.pythonhosted.org/packages/f9/02/04dc7e0bb1683eebe3434141576b2461cb671a00bc9d64491898129929ac/hub-0.2.0.1.tar.gz", "yanked": false}], "0.2.0.3": [{"comment_text": "", "digests": {"md5": "9a1ffe3065b77f3259bdd4a2132d3330", "sha256": "f37d13372ef9c29eb44afb5e121d1034cc124faae840b547f1058a1cc57b405f"}, "downloads": -1, "filename": "hub-0.2.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "9a1ffe3065b77f3259bdd4a2132d3330", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 29458, "upload_time": "2019-08-24T17:30:36", "upload_time_iso_8601": "2019-08-24T17:30:36.828779Z", "url": "https://files.pythonhosted.org/packages/ce/d9/272ff562bc7fe57485a78fef560d5c2d38fb0bc3a52f546e7de2dbffa1fe/hub-0.2.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "70186a37adb4582e40f00545de81b677", "sha256": "a335b99f9becf7beec155a0c94877a4b98ba64fc2f9db589ace33f9ba21a2f41"}, "downloads": -1, "filename": "hub-0.2.0.3.tar.gz", "has_sig": false, "md5_digest": "70186a37adb4582e40f00545de81b677", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 24859, "upload_time": "2019-08-24T17:30:38", "upload_time_iso_8601": "2019-08-24T17:30:38.527155Z", "url": "https://files.pythonhosted.org/packages/fe/ff/743e17aab58fe29a8c925ba983e461610df30b81a6be1d25e1ac91fdbcf8/hub-0.2.0.3.tar.gz", "yanked": false}], "0.2.0.4": [{"comment_text": "", "digests": {"md5": "baca64cee77f6285494460d33f116f08", "sha256": "e1777b4c3d3dcfb4a6f9a15224f85770bad60e6545b66f010f9c49a01a2a5264"}, "downloads": -1, "filename": "hub-0.2.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "baca64cee77f6285494460d33f116f08", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 29460, "upload_time": "2019-09-06T18:14:41", "upload_time_iso_8601": "2019-09-06T18:14:41.006343Z", "url": "https://files.pythonhosted.org/packages/a6/ea/88e38bd89edc1d47f9a905458a38cf9dd8ab29b24a90869820a507481fca/hub-0.2.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "028a4e67664157d3c8a4113335ccba62", "sha256": "1973c990909581479be3128b59aeb65a2b28a840bab496dd48ef6c972e984722"}, "downloads": -1, "filename": "hub-0.2.0.4.tar.gz", "has_sig": false, "md5_digest": "028a4e67664157d3c8a4113335ccba62", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 24892, "upload_time": "2019-09-06T18:14:42", "upload_time_iso_8601": "2019-09-06T18:14:42.770780Z", "url": "https://files.pythonhosted.org/packages/16/8f/13fde76aa25c20caede12c749be9f60791e69f9eb4a651ae7c03319d4e4f/hub-0.2.0.4.tar.gz", "yanked": false}], "0.4.0.0": [{"comment_text": "", "digests": {"md5": "5b353621030aef514f7a8fe0effda4df", "sha256": "d023cfca445acf03a1e53816e0cc07ea89595942c92b8d8ab5f9623a922ac741"}, "downloads": -1, "filename": "hub-0.4.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "5b353621030aef514f7a8fe0effda4df", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 51033, "upload_time": "2020-02-21T16:11:28", "upload_time_iso_8601": "2020-02-21T16:11:28.847175Z", "url": "https://files.pythonhosted.org/packages/b1/43/5bcd0c400717dae0efbf0e8938eba1ec94c2e91cdaaf59a42496dd4d488a/hub-0.4.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "19f6aed41eb8730d11e49b29717b1a9a", "sha256": "ec4286becdfdce78e9387991041862e2920797459c54046d4b30066bc5355f2b"}, "downloads": -1, "filename": "hub-0.4.0.0.tar.gz", "has_sig": false, "md5_digest": "19f6aed41eb8730d11e49b29717b1a9a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 28859, "upload_time": "2020-02-21T16:11:30", "upload_time_iso_8601": "2020-02-21T16:11:30.278104Z", "url": "https://files.pythonhosted.org/packages/52/66/c1cd1659fb9d9a7db35130be837fd102191f4f0be24fe45e7d12524ff14a/hub-0.4.0.0.tar.gz", "yanked": false}], "0.4.0.1": [{"comment_text": "", "digests": {"md5": "0539eba5c0780ebb504fa35b299ab23f", "sha256": "124c4c68ace2264cb7c2d7280feb6dcda949ef92d61cbab175ed0f260fb16824"}, "downloads": -1, "filename": "hub-0.4.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "0539eba5c0780ebb504fa35b299ab23f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 51005, "upload_time": "2020-02-21T16:13:27", "upload_time_iso_8601": "2020-02-21T16:13:27.907565Z", "url": "https://files.pythonhosted.org/packages/dd/75/a06498d702d100214dfd7c4e7df156169326c336a0a74c9d991a02b486db/hub-0.4.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7391282df57ef562de9fa7e883f4952e", "sha256": "d4ce4cbb722aa407006c2e9e0f533bc028e53fda83f223f37074f551cf75b55d"}, "downloads": -1, "filename": "hub-0.4.0.1.tar.gz", "has_sig": false, "md5_digest": "7391282df57ef562de9fa7e883f4952e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 28842, "upload_time": "2020-02-21T16:13:29", "upload_time_iso_8601": "2020-02-21T16:13:29.754594Z", "url": "https://files.pythonhosted.org/packages/8f/82/0a11f2aefddefde2c6067281f4495c4f1900862a61db1fdc46d05f20cf3d/hub-0.4.0.1.tar.gz", "yanked": false}], "0.4.1.0": [{"comment_text": "", "digests": {"md5": "3d75e3aa65a1b932a36827c6855208ec", "sha256": "0bd170e37ef53be11afedbca5ecf928f65a33a77717fba44c4983b6f5e2bcf74"}, "downloads": -1, "filename": "hub-0.4.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "3d75e3aa65a1b932a36827c6855208ec", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 51724, "upload_time": "2020-03-09T23:47:20", "upload_time_iso_8601": "2020-03-09T23:47:20.418347Z", "url": "https://files.pythonhosted.org/packages/3f/2f/ea2954b3c5347850e33dc1d8dd1776326a0bf43a894a3ab143366a9172d1/hub-0.4.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c4fda5c4f3e1db3a696dc42ba7cbbf0f", "sha256": "c0450387acfa185a081bea864a6f28d305d88b452bcbc9b845d430a2c274c951"}, "downloads": -1, "filename": "hub-0.4.1.0.tar.gz", "has_sig": false, "md5_digest": "c4fda5c4f3e1db3a696dc42ba7cbbf0f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 29293, "upload_time": "2020-03-09T23:47:21", "upload_time_iso_8601": "2020-03-09T23:47:21.978256Z", "url": "https://files.pythonhosted.org/packages/8b/9a/bd1e3872a2e401daa1707fcd77d80ad969acd956c1256d7827f5ab422899/hub-0.4.1.0.tar.gz", "yanked": false}], "0.4.1.2": [{"comment_text": "", "digests": {"md5": "bfdaee2e02465f53a09d6e3e20c2ebd4", "sha256": "e894c0558ced6f403a4dfe82ceb0f44d50de7036066314801bc77ccbd3701f8c"}, "downloads": -1, "filename": "hub-0.4.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "bfdaee2e02465f53a09d6e3e20c2ebd4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 52098, "upload_time": "2020-03-19T00:34:06", "upload_time_iso_8601": "2020-03-19T00:34:06.477956Z", "url": "https://files.pythonhosted.org/packages/ef/12/ae2cee40433ebaaa492de0e9ffafe555790dbae1d7780829964f97be4035/hub-0.4.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c7326fa677475cba0cb7aa7184eb39dc", "sha256": "82d65886b806d239062168ab97f9a8bc2c5e49fd29a5b2388fa12f26471b8355"}, "downloads": -1, "filename": "hub-0.4.1.2.tar.gz", "has_sig": false, "md5_digest": "c7326fa677475cba0cb7aa7184eb39dc", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 29917, "upload_time": "2020-03-19T00:34:08", "upload_time_iso_8601": "2020-03-19T00:34:08.087660Z", "url": "https://files.pythonhosted.org/packages/f9/e7/59db111c251d901574d9bb19beea44914c7453296ddb80417dda75b4d1de/hub-0.4.1.2.tar.gz", "yanked": false}], "0.4.1.3": [{"comment_text": "", "digests": {"md5": "b2e5f3a268f9c87df91a6124b37bb477", "sha256": "5e22fcb64119daa5d1c408519a674e64766aa6126054b4bd9a544c56d1c0a874"}, "downloads": -1, "filename": "hub-0.4.1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "b2e5f3a268f9c87df91a6124b37bb477", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 52334, "upload_time": "2020-05-01T18:27:27", "upload_time_iso_8601": "2020-05-01T18:27:27.950791Z", "url": "https://files.pythonhosted.org/packages/ac/16/0dc4c17e3a025221e34cad1c838e6359c7cc8089d93542b59219d84ae912/hub-0.4.1.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "da1f66774767d6dc6336cf9f01b14113", "sha256": "0cac76438b1301b7923b5914ab0dc8e1a70d00b171546ad4cd9526ec6eacc5f0"}, "downloads": -1, "filename": "hub-0.4.1.3.tar.gz", "has_sig": false, "md5_digest": "da1f66774767d6dc6336cf9f01b14113", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 30813, "upload_time": "2020-05-01T18:27:29", "upload_time_iso_8601": "2020-05-01T18:27:29.190598Z", "url": "https://files.pythonhosted.org/packages/f5/d4/b08e6239d352ff9ef5a9b9cfc2f393956c18ffcc42b1a21cff6289a784f7/hub-0.4.1.3.tar.gz", "yanked": false}], "0.4.1.4": [{"comment_text": "", "digests": {"md5": "21746199555fa09a6bb14fa31f318da0", "sha256": "e50f466e760c31888f7fa1f8ba56cebf2cc736a7faab8edb045f77c60d7c588b"}, "downloads": -1, "filename": "hub-0.4.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "21746199555fa09a6bb14fa31f318da0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 52319, "upload_time": "2020-05-01T18:32:04", "upload_time_iso_8601": "2020-05-01T18:32:04.150959Z", "url": "https://files.pythonhosted.org/packages/1e/52/7cefb522b42472a2fb5de940f2ef744712647d6655460822e7371e7f7531/hub-0.4.1.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c70ba29aebd9677a5475b87db5789bf6", "sha256": "1a732be492090cb1783ee8ee95ca4668d2a81efec2617c23075fda1e2b7fa8c9"}, "downloads": -1, "filename": "hub-0.4.1.4.tar.gz", "has_sig": false, "md5_digest": "c70ba29aebd9677a5475b87db5789bf6", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 30802, "upload_time": "2020-05-01T18:32:05", "upload_time_iso_8601": "2020-05-01T18:32:05.296068Z", "url": "https://files.pythonhosted.org/packages/e5/3e/73ddf12b20e8d1055444ee96d2d448f63975c39b41a4e761b1fa8438fcad/hub-0.4.1.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "21746199555fa09a6bb14fa31f318da0", "sha256": "e50f466e760c31888f7fa1f8ba56cebf2cc736a7faab8edb045f77c60d7c588b"}, "downloads": -1, "filename": "hub-0.4.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "21746199555fa09a6bb14fa31f318da0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 52319, "upload_time": "2020-05-01T18:32:04", "upload_time_iso_8601": "2020-05-01T18:32:04.150959Z", "url": "https://files.pythonhosted.org/packages/1e/52/7cefb522b42472a2fb5de940f2ef744712647d6655460822e7371e7f7531/hub-0.4.1.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c70ba29aebd9677a5475b87db5789bf6", "sha256": "1a732be492090cb1783ee8ee95ca4668d2a81efec2617c23075fda1e2b7fa8c9"}, "downloads": -1, "filename": "hub-0.4.1.4.tar.gz", "has_sig": false, "md5_digest": "c70ba29aebd9677a5475b87db5789bf6", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 30802, "upload_time": "2020-05-01T18:32:05", "upload_time_iso_8601": "2020-05-01T18:32:05.296068Z", "url": "https://files.pythonhosted.org/packages/e5/3e/73ddf12b20e8d1055444ee96d2d448f63975c39b41a4e761b1fa8438fcad/hub-0.4.1.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:49:59 2020"}