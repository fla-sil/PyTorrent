{"info": {"author": "DSaPP Researchers", "author_email": "datascifellows@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.6", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5"], "description": "=======\ncollate\n=======\n\n\n.. image:: https://img.shields.io/pypi/v/collate.svg\n        :target: https://pypi.python.org/pypi/collate\n\n.. image:: https://travis-ci.org/dssg/collate.svg?branch=master\n        :target: https://travis-ci.org/dssg/collate\n\n.. image:: https://readthedocs.org/projects/collate/badge/?version=latest\n        :target: https://collate.readthedocs.io/en/latest/?badge=latest\n        :alt: Documentation Status\n\n.. image:: https://pyup.io/repos/github/dssg/collate/shield.svg\n     :target: https://pyup.io/repos/github/dssg/collate/\n     :alt: Updates\n\n.. image:: https://codecov.io/gh/dssg/collate/branch/master/graph/badge.svg\n    :target: https://codecov.io/gh/dssg/collate\n    :alt: Code Coverage\n\n\nAggregated feature generation made easy.\n\n\n* Free software for noncommercial use: `UChicago open source license <https://github.com/dssg/collate/blob/master/LICENSE>`_.\n* Documentation: https://collate.readthedocs.io.\n\nOverview\n========\n\nCollate allows you to easily specify and execute statements like \u201cfind the number of restaurants in a given zip code that have had food safety violations within the past year.\u201d  The real power is that it allows you to vary both the spatial and temporal windows, choosing not just zip code and one year, but a range over multiple partitions and times. Specifying features is also easier and more efficient than writing raw sql. Collate will automatically generate and execute all the required SQL scripts to aggregate the data across many groups in an efficient manner. We mainly use the results as features in machine learning models.\n\nInputs\n======\n\nTake for example `food inspections data from the City of Chicago <https://data.cityofchicago.org/Health-Human-Services/Food-Inspections/4ijn-s7e5>`_. The table looks like this:\n\n\n============= =========== ===== =============== ========== =========== ===\ninspection_id license_no  zip   inspection_date results    violations  ...\n============= =========== ===== =============== ========== =========== ===\n1966765       80273       60636 2016-10-18      No Entry               ...\n1966314       2092894     60640 2016-10-11      Pass       \u2026CORRECTED\u2026 ...\n1966286       2215628     60661 2016-10-11      Pass w/ C\u2026 \u2026HAZARDOUS\u2026 ...\n1966220       2424039     60620 2016-10-07      Pass                   ...\n============= =========== ===== =============== ========== =========== ===\n\nThere are two spatial levels in the data: the specific restaurant (by its license number) and the zip code. And there is a date.\n\nAn example of an aggregate feature is the number of failed inspections. In raw SQL this could be calculated, for each restaurant, as so::\n\n    SELECT license_no, sum((results = 'Fail')::int) as failed_sum\n    FROM food_inspections GROUP BY license_no;\n\nIn collate, this aggregated column would be defined as::\n\n    Aggregate({\"failed\": \"(results = 'Fail')::int\"}, \"sum\", {'coltype':'aggregate', 'all': {'type': 'mean'}})\n\nNote that the SQL query is split into two parts: the first argument to ``Aggregate``\nis the computation to be performed and gives it a name (as a dictionary key), and\nthe second argument is the reduction function to perform. The third argument provides\na set of rules for how to handle imputation of null values in the resulting fields.\n\nSplitting the SQL like this makes it easy to generate lots of composable features \nas the outer product of these two lists.  For example, you may also be interested \nin the proportion of inspections that resulted in a failure in addition to the \ntotal number. This is easy to specify with the average value of the `failed` \ncomputation::\n\n    Aggregate({\"failed\": \"(results = 'Fail')::int\"}, [\"sum\",\"avg\"], {'coltype':'aggregate', 'all': {'type': 'mean'}})\n\n\nAggregations in collate easily aggregate this single feature across different spatiotemporal groups, e.g.::\n\n    Aggregate({\"failed\": \"(results = 'Fail')::int\"}, [\"sum\",\"avg\"], {'coltype':'aggregate', 'all': {'type': 'mean'}})\n    st = SpacetimeAggregation([fail],\n\t                           from_obj='food_inspections',\n                               groups=['license_no','zip'],\n                               intervals={\"license_no\":[\"2 year\", \"3 year\"], \"zip\": [\"1 year\"]},\n                               dates=[\"2016-01-01\", \"2015-01-01\"],\n                               date_column=\"inspection_date\",\n                               state_table='all_restaurants',\n                               state_group='license_no',\n                               schema='test_collate')\n\nThe ``SpacetimeAggregation`` object encapsulates the ``FROM`` section of the query\n(in this case it's simply the inspections table), as well as the ``GROUP BY``\ncolumns.  Not only will this create information about the individual restaurants\n(grouping by ``license_no``), it also creates \"neighborhood\" columns that add\ninformation about the region in which the restaurant is operating (by grouping by\n``zip``). The ``state_table`` specified here should contain the comprehensive set of\n``state_group`` entities and dates for which output should be generated for them,\nregardless if they exist in the ``from_obj``.\n\nEven more powerful is the sophisticated date range partitioning that the\n``SpacetimeAggregation`` object provides.  It will create multiple queries in\norder to create the summary statistics over the past 1, 2, or 3 years, looking\nback from either Jan 1, 2015 or Jan 1 2016. Executing this set of queries with::\n\n    st.execute(engine.connect()) # with a SQLAlchemy engine object\n\nwill create four new tables in the ``test_collate`` schema. The table\n``food_inspections_license_no`` will contain four feature columns for each\nlicense that describe the total number and proportion of failures over the past\ntwo or three years, with a date column that states whether it was looking\nbefore 2016 or 2015. Similarly, a ``food_inspections_zip`` table will have two\nfeature columns for every zip code in the database, looking at the total and\naverage number of failures in that neighborhood over the year prior to the date\nin the date column. The ``food_inspections_aggregation`` table joins these results \ntogether to make it easier to look at both neighborhood and restaurant-level \neffects for any given restaurant. Finally, the ``food_inspections_aggregation_imputed``\ntable fills in null values using the imputation rules specified in the ``Aggregate``\nconstructor.\n\nImputation Rules\n================\n\nImputation rules should be specified in the form of a dictionary::\n\n    {\n        'coltype': 'aggregate',\n        'all': {'type': 'mean'},\n        'max': {'type': 'constant', 'value': 137}\n    }\n\nThe ``coltype`` key of this dictionary must be one of ``aggregate``, ``categorical``, \nor ``array_categorical`` and informs how the imputation rules are applied.\n\nThe other keys of the dictionary are the reduction functions used by the aggregate\n(such as ``sum``, ``count``, ``avg``, etc.) or ``all`` as a catch-all. Function-specific\nrules will take precedence over the catch-all rule. The values associated with these\nkeys are each a dictionary with a required ``type`` key specifying the rule type and\nother rule-specific keys.\n\nCurrently available imputation rules:\n    * ``mean``: The average value of the feature (for ``SpacetimeAggregation`` the mean is taken within-date).\n    * ``constant``: Fill with a constant value from a required ``value`` parameter.\n    * ``zero``: Fill with zero.\n    * ``zero_noflag``: Fill with zero without generating an \"imputed\" flag. This option should be used only for cases where null values are explicitly known to be zero such as absence of an entity from an events table indicating that no such event has occurred.\n    * ``null_category``: Only available for categorical features. Just flag null values with the null category column.\n    * ``binary_mode``: Only available for aggregate column types. Takes the modal value for a binary feature.\n    * ``error``: Raise an exception if any null values are encountered for this feature.\n\nOutputs\n=======\n\nThe main output of a collate aggregation is a database table with all of the aggregated features joined to a list of entities.\n\n\nTODO: sample rows from the above aggregation.\n\n\nUsage Examples\n==============\n\nMultiple quantities\n~~~~~~~~~~~~~~~~~~~\nTODO\n\nMultiple functions\n~~~~~~~~~~~~~~~~~~\nTODO\n\nTuple quantity\n~~~~~~~~~~~~~~\nTODO\n\nDate substitution\n~~~~~~~~~~~~~~~~~\nTODO\n\nCategorical counts\n~~~~~~~~~~~~~~~~~~\nTODO\n\nNaming of features\n~~~~~~~~~~~~~~~~~~\nTODO\n\nMore complicated from_obj\n~~~~~~~~~~~~~~~~~~~~~~~~~\nTODO\n\nTechnical details\n=================\n\n\n=======\nHistory\n=======\n\n0.1.0\n------------------\n\n* Initial release.\n\n\n", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/dssg/collate", "keywords": "collate", "license": "MIT license", "maintainer": "", "maintainer_email": "", "name": "collate", "package_url": "https://pypi.org/project/collate/", "platform": "", "project_url": "https://pypi.org/project/collate/", "project_urls": {"Homepage": "https://github.com/dssg/collate"}, "release_url": "https://pypi.org/project/collate/0.3.0/", "requires_dist": null, "requires_python": "", "summary": "Aggregated feature generation made easy.", "version": "0.3.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            =======<br>collate<br>=======<br><br><br>.. image:: https://img.shields.io/pypi/v/collate.svg<br>        :target: https://pypi.python.org/pypi/collate<br><br>.. image:: https://travis-ci.org/dssg/collate.svg?branch=master<br>        :target: https://travis-ci.org/dssg/collate<br><br>.. image:: https://readthedocs.org/projects/collate/badge/?version=latest<br>        :target: https://collate.readthedocs.io/en/latest/?badge=latest<br>        :alt: Documentation Status<br><br>.. image:: https://pyup.io/repos/github/dssg/collate/shield.svg<br>     :target: https://pyup.io/repos/github/dssg/collate/<br>     :alt: Updates<br><br>.. image:: https://codecov.io/gh/dssg/collate/branch/master/graph/badge.svg<br>    :target: https://codecov.io/gh/dssg/collate<br>    :alt: Code Coverage<br><br><br>Aggregated feature generation made easy.<br><br><br>* Free software for noncommercial use: `UChicago open source license &lt;https://github.com/dssg/collate/blob/master/LICENSE&gt;`_.<br>* Documentation: https://collate.readthedocs.io.<br><br>Overview<br>========<br><br>Collate allows you to easily specify and execute statements like \u201cfind the number of restaurants in a given zip code that have had food safety violations within the past year.\u201d  The real power is that it allows you to vary both the spatial and temporal windows, choosing not just zip code and one year, but a range over multiple partitions and times. Specifying features is also easier and more efficient than writing raw sql. Collate will automatically generate and execute all the required SQL scripts to aggregate the data across many groups in an efficient manner. We mainly use the results as features in machine learning models.<br><br>Inputs<br>======<br><br>Take for example `food inspections data from the City of Chicago &lt;https://data.cityofchicago.org/Health-Human-Services/Food-Inspections/4ijn-s7e5&gt;`_. The table looks like this:<br><br><br>============= =========== ===== =============== ========== =========== ===<br>inspection_id license_no  zip   inspection_date results    violations  ...<br>============= =========== ===== =============== ========== =========== ===<br>1966765       80273       60636 2016-10-18      No Entry               ...<br>1966314       2092894     60640 2016-10-11      Pass       \u2026CORRECTED\u2026 ...<br>1966286       2215628     60661 2016-10-11      Pass w/ C\u2026 \u2026HAZARDOUS\u2026 ...<br>1966220       2424039     60620 2016-10-07      Pass                   ...<br>============= =========== ===== =============== ========== =========== ===<br><br>There are two spatial levels in the data: the specific restaurant (by its license number) and the zip code. And there is a date.<br><br>An example of an aggregate feature is the number of failed inspections. In raw SQL this could be calculated, for each restaurant, as so::<br><br>    SELECT license_no, sum((results = 'Fail')::int) as failed_sum<br>    FROM food_inspections GROUP BY license_no;<br><br>In collate, this aggregated column would be defined as::<br><br>    Aggregate({\"failed\": \"(results = 'Fail')::int\"}, \"sum\", {'coltype':'aggregate', 'all': {'type': 'mean'}})<br><br>Note that the SQL query is split into two parts: the first argument to ``Aggregate``<br>is the computation to be performed and gives it a name (as a dictionary key), and<br>the second argument is the reduction function to perform. The third argument provides<br>a set of rules for how to handle imputation of null values in the resulting fields.<br><br>Splitting the SQL like this makes it easy to generate lots of composable features <br>as the outer product of these two lists.  For example, you may also be interested <br>in the proportion of inspections that resulted in a failure in addition to the <br>total number. This is easy to specify with the average value of the `failed` <br>computation::<br><br>    Aggregate({\"failed\": \"(results = 'Fail')::int\"}, [\"sum\",\"avg\"], {'coltype':'aggregate', 'all': {'type': 'mean'}})<br><br><br>Aggregations in collate easily aggregate this single feature across different spatiotemporal groups, e.g.::<br><br>    Aggregate({\"failed\": \"(results = 'Fail')::int\"}, [\"sum\",\"avg\"], {'coltype':'aggregate', 'all': {'type': 'mean'}})<br>    st = SpacetimeAggregation([fail],<br>\t                           from_obj='food_inspections',<br>                               groups=['license_no','zip'],<br>                               intervals={\"license_no\":[\"2 year\", \"3 year\"], \"zip\": [\"1 year\"]},<br>                               dates=[\"2016-01-01\", \"2015-01-01\"],<br>                               date_column=\"inspection_date\",<br>                               state_table='all_restaurants',<br>                               state_group='license_no',<br>                               schema='test_collate')<br><br>The ``SpacetimeAggregation`` object encapsulates the ``FROM`` section of the query<br>(in this case it's simply the inspections table), as well as the ``GROUP BY``<br>columns.  Not only will this create information about the individual restaurants<br>(grouping by ``license_no``), it also creates \"neighborhood\" columns that add<br>information about the region in which the restaurant is operating (by grouping by<br>``zip``). The ``state_table`` specified here should contain the comprehensive set of<br>``state_group`` entities and dates for which output should be generated for them,<br>regardless if they exist in the ``from_obj``.<br><br>Even more powerful is the sophisticated date range partitioning that the<br>``SpacetimeAggregation`` object provides.  It will create multiple queries in<br>order to create the summary statistics over the past 1, 2, or 3 years, looking<br>back from either Jan 1, 2015 or Jan 1 2016. Executing this set of queries with::<br><br>    st.execute(engine.connect()) # with a SQLAlchemy engine object<br><br>will create four new tables in the ``test_collate`` schema. The table<br>``food_inspections_license_no`` will contain four feature columns for each<br>license that describe the total number and proportion of failures over the past<br>two or three years, with a date column that states whether it was looking<br>before 2016 or 2015. Similarly, a ``food_inspections_zip`` table will have two<br>feature columns for every zip code in the database, looking at the total and<br>average number of failures in that neighborhood over the year prior to the date<br>in the date column. The ``food_inspections_aggregation`` table joins these results <br>together to make it easier to look at both neighborhood and restaurant-level <br>effects for any given restaurant. Finally, the ``food_inspections_aggregation_imputed``<br>table fills in null values using the imputation rules specified in the ``Aggregate``<br>constructor.<br><br>Imputation Rules<br>================<br><br>Imputation rules should be specified in the form of a dictionary::<br><br>    {<br>        'coltype': 'aggregate',<br>        'all': {'type': 'mean'},<br>        'max': {'type': 'constant', 'value': 137}<br>    }<br><br>The ``coltype`` key of this dictionary must be one of ``aggregate``, ``categorical``, <br>or ``array_categorical`` and informs how the imputation rules are applied.<br><br>The other keys of the dictionary are the reduction functions used by the aggregate<br>(such as ``sum``, ``count``, ``avg``, etc.) or ``all`` as a catch-all. Function-specific<br>rules will take precedence over the catch-all rule. The values associated with these<br>keys are each a dictionary with a required ``type`` key specifying the rule type and<br>other rule-specific keys.<br><br>Currently available imputation rules:<br>    * ``mean``: The average value of the feature (for ``SpacetimeAggregation`` the mean is taken within-date).<br>    * ``constant``: Fill with a constant value from a required ``value`` parameter.<br>    * ``zero``: Fill with zero.<br>    * ``zero_noflag``: Fill with zero without generating an \"imputed\" flag. This option should be used only for cases where null values are explicitly known to be zero such as absence of an entity from an events table indicating that no such event has occurred.<br>    * ``null_category``: Only available for categorical features. Just flag null values with the null category column.<br>    * ``binary_mode``: Only available for aggregate column types. Takes the modal value for a binary feature.<br>    * ``error``: Raise an exception if any null values are encountered for this feature.<br><br>Outputs<br>=======<br><br>The main output of a collate aggregation is a database table with all of the aggregated features joined to a list of entities.<br><br><br>TODO: sample rows from the above aggregation.<br><br><br>Usage Examples<br>==============<br><br>Multiple quantities<br>~~~~~~~~~~~~~~~~~~~<br>TODO<br><br>Multiple functions<br>~~~~~~~~~~~~~~~~~~<br>TODO<br><br>Tuple quantity<br>~~~~~~~~~~~~~~<br>TODO<br><br>Date substitution<br>~~~~~~~~~~~~~~~~~<br>TODO<br><br>Categorical counts<br>~~~~~~~~~~~~~~~~~~<br>TODO<br><br>Naming of features<br>~~~~~~~~~~~~~~~~~~<br>TODO<br><br>More complicated from_obj<br>~~~~~~~~~~~~~~~~~~~~~~~~~<br>TODO<br><br>Technical details<br>=================<br><br><br>=======<br>History<br>=======<br><br>0.1.0<br>------------------<br><br>* Initial release.<br><br><br>\n          </div>"}, "last_serial": 3266868, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "130c1c5109f24366d3b0d4d98d234db0", "sha256": "9092dbf17a2a96604ad82ad9bebfadfc9794193b7e608e9b944f3cfa2f711f30"}, "downloads": -1, "filename": "collate-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "130c1c5109f24366d3b0d4d98d234db0", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 9519, "upload_time": "2016-12-14T00:06:03", "upload_time_iso_8601": "2016-12-14T00:06:03.275911Z", "url": "https://files.pythonhosted.org/packages/e3/bf/57c2d275bf366934656fdc67307dc3ab5fece2a509a343d51274df1d4982/collate-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a835795c7462786c8d20a78a0b982914", "sha256": "52eb6eb3c62db70ac9cbe1649781b3691d64191ddf79ec33502be73608507ab2"}, "downloads": -1, "filename": "collate-0.1.0.tar.gz", "has_sig": false, "md5_digest": "a835795c7462786c8d20a78a0b982914", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 218564, "upload_time": "2016-12-14T00:06:05", "upload_time_iso_8601": "2016-12-14T00:06:05.863471Z", "url": "https://files.pythonhosted.org/packages/3c/8f/265fa686c2082d0f67f74f05ef8769a92f493e69e45eb6208eddca3717ce/collate-0.1.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "596502ca99466b5049cd0fb827edfc3f", "sha256": "3eafabb7526efdb79d696fd291f67cdaafc24768e933614ef06e9a082d29156b"}, "downloads": -1, "filename": "collate-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "596502ca99466b5049cd0fb827edfc3f", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 12775, "upload_time": "2017-02-26T05:26:19", "upload_time_iso_8601": "2017-02-26T05:26:19.019363Z", "url": "https://files.pythonhosted.org/packages/fd/eb/e1ba81d4d3c3097b94a5c9bbeabf1d026b9e3b66994fffe2bab66cdef444/collate-0.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0aab4a42719aac6dd0debd3b050587b6", "sha256": "e2813ea1e2b58e00ff8178351aaf08aa5134917da514d96556f80b98ae66d905"}, "downloads": -1, "filename": "collate-0.2.0.tar.gz", "has_sig": false, "md5_digest": "0aab4a42719aac6dd0debd3b050587b6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 221931, "upload_time": "2017-02-26T05:26:20", "upload_time_iso_8601": "2017-02-26T05:26:20.854180Z", "url": "https://files.pythonhosted.org/packages/61/ba/2f88b7c32ff618530a83c8d45d7fab5813a8e5bb94488535aa381a628162/collate-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "a5237fa80f5722a358f1ac45fd0d953a", "sha256": "efe2fd2bbec04d94aed29d91473d867db8e05cc67f97252a7289ee1364c00de4"}, "downloads": -1, "filename": "collate-0.2.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "a5237fa80f5722a358f1ac45fd0d953a", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 15687, "upload_time": "2017-07-24T22:42:40", "upload_time_iso_8601": "2017-07-24T22:42:40.248008Z", "url": "https://files.pythonhosted.org/packages/12/2e/dd9ced3faa230791856f2cacc1d9cb9936fc296fa4e2f5a836b4a991b267/collate-0.2.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c8a1dcacd74761c3e899d2460f1d029d", "sha256": "6fa8a9611f4962f9fdb34577fbfb33139d296a7367b574ed0ce00b2d67b3eea5"}, "downloads": -1, "filename": "collate-0.2.1.tar.gz", "has_sig": false, "md5_digest": "c8a1dcacd74761c3e899d2460f1d029d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 226399, "upload_time": "2017-07-24T22:42:42", "upload_time_iso_8601": "2017-07-24T22:42:42.300132Z", "url": "https://files.pythonhosted.org/packages/95/43/a36111a6af065079ffbae4002871040f9014d28ba348f7c4a5dd5edef9e7/collate-0.2.1.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "ab4820933b9ddadd35f1469866a611c8", "sha256": "4bffe06ef9f2413127a992c0642ee8af5757cc01d64d0990c4a41309e36a6e2a"}, "downloads": -1, "filename": "collate-0.3.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "ab4820933b9ddadd35f1469866a611c8", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 22002, "upload_time": "2017-10-20T20:31:38", "upload_time_iso_8601": "2017-10-20T20:31:38.464945Z", "url": "https://files.pythonhosted.org/packages/6c/ed/34a192b48d978e9d4b85c61c91fcf1e77b40242a00abc14fca507be9e43d/collate-0.3.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cb65fc7e36893bfc8bb94d9463cad136", "sha256": "ec29c8e657c80ed2ba93f0648528274d608a9b05f25ecb8f110bea0c737fddfd"}, "downloads": -1, "filename": "collate-0.3.0.tar.gz", "has_sig": false, "md5_digest": "cb65fc7e36893bfc8bb94d9463cad136", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 234904, "upload_time": "2017-10-20T20:31:40", "upload_time_iso_8601": "2017-10-20T20:31:40.355911Z", "url": "https://files.pythonhosted.org/packages/1c/60/e8839e4cf9777a504bafc1e9b5baf40771af175cd0b9f6b4c93482796130/collate-0.3.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ab4820933b9ddadd35f1469866a611c8", "sha256": "4bffe06ef9f2413127a992c0642ee8af5757cc01d64d0990c4a41309e36a6e2a"}, "downloads": -1, "filename": "collate-0.3.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "ab4820933b9ddadd35f1469866a611c8", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 22002, "upload_time": "2017-10-20T20:31:38", "upload_time_iso_8601": "2017-10-20T20:31:38.464945Z", "url": "https://files.pythonhosted.org/packages/6c/ed/34a192b48d978e9d4b85c61c91fcf1e77b40242a00abc14fca507be9e43d/collate-0.3.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cb65fc7e36893bfc8bb94d9463cad136", "sha256": "ec29c8e657c80ed2ba93f0648528274d608a9b05f25ecb8f110bea0c737fddfd"}, "downloads": -1, "filename": "collate-0.3.0.tar.gz", "has_sig": false, "md5_digest": "cb65fc7e36893bfc8bb94d9463cad136", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 234904, "upload_time": "2017-10-20T20:31:40", "upload_time_iso_8601": "2017-10-20T20:31:40.355911Z", "url": "https://files.pythonhosted.org/packages/1c/60/e8839e4cf9777a504bafc1e9b5baf40771af175cd0b9f6b4c93482796130/collate-0.3.0.tar.gz", "yanked": false}], "timestamp": "Thu May  7 22:18:03 2020"}