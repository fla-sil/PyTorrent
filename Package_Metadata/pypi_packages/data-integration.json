{"info": {"author": "Mara contributors", "author_email": "", "bugtrack_url": null, "classifiers": [], "description": "# Mara Data Integration\n\n[![Build Status](https://travis-ci.org/mara/data-integration.svg?branch=master)](https://travis-ci.org/mara/data-integration)\n[![PyPI - License](https://img.shields.io/pypi/l/data-integration.svg)](https://github.com/mara/data-integration/blob/master/LICENSE)\n[![PyPI version](https://badge.fury.io/py/data-integration.svg)](https://badge.fury.io/py/data-integration)\n[![Slack Status](https://img.shields.io/badge/slack-join_chat-white.svg?logo=slack&style=social)](https://communityinviter.com/apps/mara-users/public-invite)\n\n\nThis package contains a lightweight ETL framework with a focus on transparency and complexity reduction. It has a number of baked-in assumptions/ principles:\n\n- Data integration pipelines as code: pipelines, tasks and commands are created using declarative Python code.\n\n- PostgreSQL as a data processing engine.\n\n- Extensive web ui. The web browser as the main tool for inspecting, running and debugging pipelines.\n\n- GNU make semantics. Nodes depend on the completion of upstream nodes. No data dependencies or data flows.\n\n- No in-app data processing: command line tools as the main tool for interacting with databases and data.\n\n- Single machine pipeline execution based on Python's [multiprocessing](https://docs.python.org/3.6/library/multiprocessing.html). No need for distributed task queues. Easy debugging and output logging.\n\n- Cost based priority queues: nodes with higher cost (based on recorded run times) are run first.\n\n&nbsp;\n\n## Installation\n\nTo use the library directly, use pip:\n\n```\npip install data-integration\n```\n\nor\n \n```\npip install git+https://github.com/mara/data-integration.git\n```\n\nFor an example of an integration into a flask application, have a look at the [mara example project](https://github.com/mara/mara-example-project).\n\nDue to the heavy use of forking, Mara Data Integration does not run natively on Windows. If you want to run it on Windows, then please use Docker or the [Windows Subsystem for Linux](https://en.wikipedia.org/wiki/Windows_Subsystem_for_Linux). \n\n&nbsp;\n\n## Example\n\nHere is a pipeline \"demo\" consisting of three nodes that depend on each other: the task `ping_localhost`, the pipeline `sub_pipeline` and the task `sleep`:\n\n```python\nfrom data_integration.commands.bash import RunBash\nfrom data_integration.pipelines import Pipeline, Task\nfrom data_integration.ui.cli import run_pipeline, run_interactively\n\npipeline = Pipeline(\n    id='demo',\n    description='A small pipeline that demonstrates the interplay between pipelines, tasks and commands')\n\npipeline.add(Task(id='ping_localhost', description='Pings localhost',\n                  commands=[RunBash('ping -c 3 localhost')]))\n\nsub_pipeline = Pipeline(id='sub_pipeline', description='Pings a number of hosts')\n\nfor host in ['google', 'amazon', 'facebook']:\n    sub_pipeline.add(Task(id=f'ping_{host}', description=f'Pings {host}',\n                          commands=[RunBash(f'ping -c 3 {host}.com')]))\n\nsub_pipeline.add_dependency('ping_amazon', 'ping_facebook')\nsub_pipeline.add(Task(id='ping_foo', description='Pings foo',\n                      commands=[RunBash('ping foo')]), ['ping_amazon'])\n\npipeline.add(sub_pipeline, ['ping_localhost'])\n\npipeline.add(Task(id='sleep', description='Sleeps for 2 seconds',\n                  commands=[RunBash('sleep 2')]), ['sub_pipeline'])\n```\n\nTasks contain lists of commands, which do the actual work (in this case running bash commands that ping various hosts). \n\n&nbsp;\n\nIn order to run the pipeline, a PostgreSQL database needs to be configured for storing run-time information, run output and status of incremental processing: \n\n```python\nimport mara_db.auto_migration\nimport mara_db.config\nimport mara_db.dbs\n\nmara_db.config.databases \\\n    = lambda: {'mara': mara_db.dbs.PostgreSQLDB(host='localhost', user='root', database='example_etl_mara')}\n\nmara_db.auto_migration.auto_discover_models_and_migrate()\n```\n\nGiven that PostgresSQL is running and the credentials work, the output looks like this (a database with a number of tables is created):\n\n```\nCreated database \"postgresql+psycopg2://root@localhost/example_etl_mara\"\n\nCREATE TABLE data_integration_file_dependency (\n    node_path TEXT[] NOT NULL, \n    dependency_type VARCHAR NOT NULL, \n    hash VARCHAR, \n    timestamp TIMESTAMP WITHOUT TIME ZONE, \n    PRIMARY KEY (node_path, dependency_type)\n);\n\n.. more tables\n```\n\n### CLI UI\n\nThis runs a pipeline with output to stdout:\n\n```python\nfrom data_integration.ui.cli import run_pipeline\n\nrun_pipeline(pipeline)\n```\n\n![Example run cli 1](https://github.com/mara/data-integration/raw/master/docs/example-run-cli-1.gif)\n\n&nbsp;\n\nAnd this runs a single node of pipeline `sub_pipeline` together with all the nodes that it depends on:\n\n```python\nrun_pipeline(sub_pipeline, nodes=[sub_pipeline.nodes['ping_amazon']], with_upstreams=True)\n```\n\n![Example run cli 2](https://github.com/mara/data-integration/raw/master/docs/example-run-cli-2.gif)\n\n&nbsp;\n\n\nAnd finally, there is some sort of menu based on [pythondialog](http://pythondialog.sourceforge.net/) that allows to navigate and run pipelines like this:\n\n```python\nfrom data_integration.ui.cli import run_interactively\n\nrun_interactively()\n```\n\n![Example run cli 3](https://github.com/mara/data-integration/raw/master/docs/example-run-cli-3.gif)\n\n\n\n### Web UI\n\nMore importantly, this package provides an extensive web interface. It can be easily integrated into any [Flask](http://flask.pocoo.org/) based app and the [mara example project](https://github.com/mara/mara-example-project) demonstrates how to do this using [mara-app](https://github.com/mara/mara-app).\n\nFor each pipeline, there is a page that shows\n\n- a graph of all child nodes and the dependencies between them\n- a chart of the overal run time of the pipeline and it's most expensive nodes over the last 30 days (configurable)\n- a table of all the pipeline's nodes with their average run times and the resulting queuing priority\n- output and timeline for the last runs of the pipeline\n\n\n![Mara data integration web ui 1](https://github.com/mara/data-integration/raw/master/docs/mara-data-integration-web-ui-1.png)\n\nFor each task, there is a page showing \n\n- the upstreams and downstreams of the task in the pipeline\n- the run times of the task in the last 30 days\n- all commands of the task\n- output of the last runs of the task\n\n![Mara data integration web ui 2](https://github.com/mara/data-integration/raw/master/docs/mara-data-integration-web-ui-2.png)\n\n\nPipelines and tasks can be run from the web ui directly, which is probably one of the main features of this package: \n\n![Example run web ui](https://github.com/mara/data-integration/raw/master/docs/example-run-web-ui.gif)\n\n&nbsp;\n\n# Getting started\n\nDocumentation is currently work in progress. Please use the [mara example project](https://github.com/mara/mara-example-project) as a reference for getting started.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/mara/data-integration", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "data-integration", "package_url": "https://pypi.org/project/data-integration/", "platform": "", "project_url": "https://pypi.org/project/data-integration/", "project_urls": {"Homepage": "https://github.com/mara/data-integration"}, "release_url": "https://pypi.org/project/data-integration/2.8.2/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Opinionated lightweight ETL pipeline framework", "version": "2.8.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Mara Data Integration</h1>\n<p><a href=\"https://travis-ci.org/mara/data-integration\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/12075109df77e651c12d3fbd649f956a04a8ba6b/68747470733a2f2f7472617669732d63692e6f72672f6d6172612f646174612d696e746567726174696f6e2e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://github.com/mara/data-integration/blob/master/LICENSE\" rel=\"nofollow\"><img alt=\"PyPI - License\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b15c79fb7d2f629abd02e932e8385282c8a5f6e1/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f646174612d696e746567726174696f6e2e737667\"></a>\n<a href=\"https://badge.fury.io/py/data-integration\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b45cc9c9eb56ddb327f09e71bb0710b1663274bd/68747470733a2f2f62616467652e667572792e696f2f70792f646174612d696e746567726174696f6e2e737667\"></a>\n<a href=\"https://communityinviter.com/apps/mara-users/public-invite\" rel=\"nofollow\"><img alt=\"Slack Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8c01bf4f74a7c882bcfcd47e4924618eb70cfcd6/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f736c61636b2d6a6f696e5f636861742d77686974652e7376673f6c6f676f3d736c61636b267374796c653d736f6369616c\"></a></p>\n<p>This package contains a lightweight ETL framework with a focus on transparency and complexity reduction. It has a number of baked-in assumptions/ principles:</p>\n<ul>\n<li>\n<p>Data integration pipelines as code: pipelines, tasks and commands are created using declarative Python code.</p>\n</li>\n<li>\n<p>PostgreSQL as a data processing engine.</p>\n</li>\n<li>\n<p>Extensive web ui. The web browser as the main tool for inspecting, running and debugging pipelines.</p>\n</li>\n<li>\n<p>GNU make semantics. Nodes depend on the completion of upstream nodes. No data dependencies or data flows.</p>\n</li>\n<li>\n<p>No in-app data processing: command line tools as the main tool for interacting with databases and data.</p>\n</li>\n<li>\n<p>Single machine pipeline execution based on Python's <a href=\"https://docs.python.org/3.6/library/multiprocessing.html\" rel=\"nofollow\">multiprocessing</a>. No need for distributed task queues. Easy debugging and output logging.</p>\n</li>\n<li>\n<p>Cost based priority queues: nodes with higher cost (based on recorded run times) are run first.</p>\n</li>\n</ul>\n<p>\u00a0</p>\n<h2>Installation</h2>\n<p>To use the library directly, use pip:</p>\n<pre><code>pip install data-integration\n</code></pre>\n<p>or</p>\n<pre><code>pip install git+https://github.com/mara/data-integration.git\n</code></pre>\n<p>For an example of an integration into a flask application, have a look at the <a href=\"https://github.com/mara/mara-example-project\" rel=\"nofollow\">mara example project</a>.</p>\n<p>Due to the heavy use of forking, Mara Data Integration does not run natively on Windows. If you want to run it on Windows, then please use Docker or the <a href=\"https://en.wikipedia.org/wiki/Windows_Subsystem_for_Linux\" rel=\"nofollow\">Windows Subsystem for Linux</a>.</p>\n<p>\u00a0</p>\n<h2>Example</h2>\n<p>Here is a pipeline \"demo\" consisting of three nodes that depend on each other: the task <code>ping_localhost</code>, the pipeline <code>sub_pipeline</code> and the task <code>sleep</code>:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">data_integration.commands.bash</span> <span class=\"kn\">import</span> <span class=\"n\">RunBash</span>\n<span class=\"kn\">from</span> <span class=\"nn\">data_integration.pipelines</span> <span class=\"kn\">import</span> <span class=\"n\">Pipeline</span><span class=\"p\">,</span> <span class=\"n\">Task</span>\n<span class=\"kn\">from</span> <span class=\"nn\">data_integration.ui.cli</span> <span class=\"kn\">import</span> <span class=\"n\">run_pipeline</span><span class=\"p\">,</span> <span class=\"n\">run_interactively</span>\n\n<span class=\"n\">pipeline</span> <span class=\"o\">=</span> <span class=\"n\">Pipeline</span><span class=\"p\">(</span>\n    <span class=\"nb\">id</span><span class=\"o\">=</span><span class=\"s1\">'demo'</span><span class=\"p\">,</span>\n    <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s1\">'A small pipeline that demonstrates the interplay between pipelines, tasks and commands'</span><span class=\"p\">)</span>\n\n<span class=\"n\">pipeline</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">Task</span><span class=\"p\">(</span><span class=\"nb\">id</span><span class=\"o\">=</span><span class=\"s1\">'ping_localhost'</span><span class=\"p\">,</span> <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s1\">'Pings localhost'</span><span class=\"p\">,</span>\n                  <span class=\"n\">commands</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">RunBash</span><span class=\"p\">(</span><span class=\"s1\">'ping -c 3 localhost'</span><span class=\"p\">)]))</span>\n\n<span class=\"n\">sub_pipeline</span> <span class=\"o\">=</span> <span class=\"n\">Pipeline</span><span class=\"p\">(</span><span class=\"nb\">id</span><span class=\"o\">=</span><span class=\"s1\">'sub_pipeline'</span><span class=\"p\">,</span> <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s1\">'Pings a number of hosts'</span><span class=\"p\">)</span>\n\n<span class=\"k\">for</span> <span class=\"n\">host</span> <span class=\"ow\">in</span> <span class=\"p\">[</span><span class=\"s1\">'google'</span><span class=\"p\">,</span> <span class=\"s1\">'amazon'</span><span class=\"p\">,</span> <span class=\"s1\">'facebook'</span><span class=\"p\">]:</span>\n    <span class=\"n\">sub_pipeline</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">Task</span><span class=\"p\">(</span><span class=\"nb\">id</span><span class=\"o\">=</span><span class=\"sa\">f</span><span class=\"s1\">'ping_</span><span class=\"si\">{</span><span class=\"n\">host</span><span class=\"si\">}</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"sa\">f</span><span class=\"s1\">'Pings </span><span class=\"si\">{</span><span class=\"n\">host</span><span class=\"si\">}</span><span class=\"s1\">'</span><span class=\"p\">,</span>\n                          <span class=\"n\">commands</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">RunBash</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">'ping -c 3 </span><span class=\"si\">{</span><span class=\"n\">host</span><span class=\"si\">}</span><span class=\"s1\">.com'</span><span class=\"p\">)]))</span>\n\n<span class=\"n\">sub_pipeline</span><span class=\"o\">.</span><span class=\"n\">add_dependency</span><span class=\"p\">(</span><span class=\"s1\">'ping_amazon'</span><span class=\"p\">,</span> <span class=\"s1\">'ping_facebook'</span><span class=\"p\">)</span>\n<span class=\"n\">sub_pipeline</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">Task</span><span class=\"p\">(</span><span class=\"nb\">id</span><span class=\"o\">=</span><span class=\"s1\">'ping_foo'</span><span class=\"p\">,</span> <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s1\">'Pings foo'</span><span class=\"p\">,</span>\n                      <span class=\"n\">commands</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">RunBash</span><span class=\"p\">(</span><span class=\"s1\">'ping foo'</span><span class=\"p\">)]),</span> <span class=\"p\">[</span><span class=\"s1\">'ping_amazon'</span><span class=\"p\">])</span>\n\n<span class=\"n\">pipeline</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">sub_pipeline</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s1\">'ping_localhost'</span><span class=\"p\">])</span>\n\n<span class=\"n\">pipeline</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">Task</span><span class=\"p\">(</span><span class=\"nb\">id</span><span class=\"o\">=</span><span class=\"s1\">'sleep'</span><span class=\"p\">,</span> <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s1\">'Sleeps for 2 seconds'</span><span class=\"p\">,</span>\n                  <span class=\"n\">commands</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">RunBash</span><span class=\"p\">(</span><span class=\"s1\">'sleep 2'</span><span class=\"p\">)]),</span> <span class=\"p\">[</span><span class=\"s1\">'sub_pipeline'</span><span class=\"p\">])</span>\n</pre>\n<p>Tasks contain lists of commands, which do the actual work (in this case running bash commands that ping various hosts).</p>\n<p>\u00a0</p>\n<p>In order to run the pipeline, a PostgreSQL database needs to be configured for storing run-time information, run output and status of incremental processing:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">mara_db.auto_migration</span>\n<span class=\"kn\">import</span> <span class=\"nn\">mara_db.config</span>\n<span class=\"kn\">import</span> <span class=\"nn\">mara_db.dbs</span>\n\n<span class=\"n\">mara_db</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"o\">.</span><span class=\"n\">databases</span> \\\n    <span class=\"o\">=</span> <span class=\"k\">lambda</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s1\">'mara'</span><span class=\"p\">:</span> <span class=\"n\">mara_db</span><span class=\"o\">.</span><span class=\"n\">dbs</span><span class=\"o\">.</span><span class=\"n\">PostgreSQLDB</span><span class=\"p\">(</span><span class=\"n\">host</span><span class=\"o\">=</span><span class=\"s1\">'localhost'</span><span class=\"p\">,</span> <span class=\"n\">user</span><span class=\"o\">=</span><span class=\"s1\">'root'</span><span class=\"p\">,</span> <span class=\"n\">database</span><span class=\"o\">=</span><span class=\"s1\">'example_etl_mara'</span><span class=\"p\">)}</span>\n\n<span class=\"n\">mara_db</span><span class=\"o\">.</span><span class=\"n\">auto_migration</span><span class=\"o\">.</span><span class=\"n\">auto_discover_models_and_migrate</span><span class=\"p\">()</span>\n</pre>\n<p>Given that PostgresSQL is running and the credentials work, the output looks like this (a database with a number of tables is created):</p>\n<pre><code>Created database \"postgresql+psycopg2://root@localhost/example_etl_mara\"\n\nCREATE TABLE data_integration_file_dependency (\n    node_path TEXT[] NOT NULL, \n    dependency_type VARCHAR NOT NULL, \n    hash VARCHAR, \n    timestamp TIMESTAMP WITHOUT TIME ZONE, \n    PRIMARY KEY (node_path, dependency_type)\n);\n\n.. more tables\n</code></pre>\n<h3>CLI UI</h3>\n<p>This runs a pipeline with output to stdout:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">data_integration.ui.cli</span> <span class=\"kn\">import</span> <span class=\"n\">run_pipeline</span>\n\n<span class=\"n\">run_pipeline</span><span class=\"p\">(</span><span class=\"n\">pipeline</span><span class=\"p\">)</span>\n</pre>\n<p><img alt=\"Example run cli 1\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2006a02bdbd497fee530e8e05c4057c37dbc9d61/68747470733a2f2f6769746875622e636f6d2f6d6172612f646174612d696e746567726174696f6e2f7261772f6d61737465722f646f63732f6578616d706c652d72756e2d636c692d312e676966\"></p>\n<p>\u00a0</p>\n<p>And this runs a single node of pipeline <code>sub_pipeline</code> together with all the nodes that it depends on:</p>\n<pre><span class=\"n\">run_pipeline</span><span class=\"p\">(</span><span class=\"n\">sub_pipeline</span><span class=\"p\">,</span> <span class=\"n\">nodes</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">sub_pipeline</span><span class=\"o\">.</span><span class=\"n\">nodes</span><span class=\"p\">[</span><span class=\"s1\">'ping_amazon'</span><span class=\"p\">]],</span> <span class=\"n\">with_upstreams</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<p><img alt=\"Example run cli 2\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8a0891f5935cf0119233bf91b947a3d603d1e2c3/68747470733a2f2f6769746875622e636f6d2f6d6172612f646174612d696e746567726174696f6e2f7261772f6d61737465722f646f63732f6578616d706c652d72756e2d636c692d322e676966\"></p>\n<p>\u00a0</p>\n<p>And finally, there is some sort of menu based on <a href=\"http://pythondialog.sourceforge.net/\" rel=\"nofollow\">pythondialog</a> that allows to navigate and run pipelines like this:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">data_integration.ui.cli</span> <span class=\"kn\">import</span> <span class=\"n\">run_interactively</span>\n\n<span class=\"n\">run_interactively</span><span class=\"p\">()</span>\n</pre>\n<p><img alt=\"Example run cli 3\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3288510ca8e45471b23f8564193de594230d3dc8/68747470733a2f2f6769746875622e636f6d2f6d6172612f646174612d696e746567726174696f6e2f7261772f6d61737465722f646f63732f6578616d706c652d72756e2d636c692d332e676966\"></p>\n<h3>Web UI</h3>\n<p>More importantly, this package provides an extensive web interface. It can be easily integrated into any <a href=\"http://flask.pocoo.org/\" rel=\"nofollow\">Flask</a> based app and the <a href=\"https://github.com/mara/mara-example-project\" rel=\"nofollow\">mara example project</a> demonstrates how to do this using <a href=\"https://github.com/mara/mara-app\" rel=\"nofollow\">mara-app</a>.</p>\n<p>For each pipeline, there is a page that shows</p>\n<ul>\n<li>a graph of all child nodes and the dependencies between them</li>\n<li>a chart of the overal run time of the pipeline and it's most expensive nodes over the last 30 days (configurable)</li>\n<li>a table of all the pipeline's nodes with their average run times and the resulting queuing priority</li>\n<li>output and timeline for the last runs of the pipeline</li>\n</ul>\n<p><img alt=\"Mara data integration web ui 1\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f1618359198ed3c8505f32ffd2c7a8f0d8c38ee7/68747470733a2f2f6769746875622e636f6d2f6d6172612f646174612d696e746567726174696f6e2f7261772f6d61737465722f646f63732f6d6172612d646174612d696e746567726174696f6e2d7765622d75692d312e706e67\"></p>\n<p>For each task, there is a page showing</p>\n<ul>\n<li>the upstreams and downstreams of the task in the pipeline</li>\n<li>the run times of the task in the last 30 days</li>\n<li>all commands of the task</li>\n<li>output of the last runs of the task</li>\n</ul>\n<p><img alt=\"Mara data integration web ui 2\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d7ba09a259638bf74b2f9cda22e42e1fcba659fe/68747470733a2f2f6769746875622e636f6d2f6d6172612f646174612d696e746567726174696f6e2f7261772f6d61737465722f646f63732f6d6172612d646174612d696e746567726174696f6e2d7765622d75692d322e706e67\"></p>\n<p>Pipelines and tasks can be run from the web ui directly, which is probably one of the main features of this package:</p>\n<p><img alt=\"Example run web ui\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c20e2732fdb37fae34b441c40e84d518c00b56b2/68747470733a2f2f6769746875622e636f6d2f6d6172612f646174612d696e746567726174696f6e2f7261772f6d61737465722f646f63732f6578616d706c652d72756e2d7765622d75692e676966\"></p>\n<p>\u00a0</p>\n<h1>Getting started</h1>\n<p>Documentation is currently work in progress. Please use the <a href=\"https://github.com/mara/mara-example-project\" rel=\"nofollow\">mara example project</a> as a reference for getting started.</p>\n\n          </div>"}, "last_serial": 7162454, "releases": {"2.4.1": [{"comment_text": "", "digests": {"md5": "48e7b7137652d9b1130bf171ea322dbe", "sha256": "ba6696290b4218e47de683973be21ee3be293957ff76f90a3a66250d253c5994"}, "downloads": -1, "filename": "data-integration-2.4.1.tar.gz", "has_sig": false, "md5_digest": "48e7b7137652d9b1130bf171ea322dbe", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 40866, "upload_time": "2019-07-05T07:53:38", "upload_time_iso_8601": "2019-07-05T07:53:38.024294Z", "url": "https://files.pythonhosted.org/packages/e4/f6/9e4cb99a54b7b61ae8bd9aba788a1e4889aa4305f59d9dd1eecba352d418/data-integration-2.4.1.tar.gz", "yanked": false}], "2.4.2": [{"comment_text": "", "digests": {"md5": "ac64dfeeb5c6e436ccf0386249b21b07", "sha256": "774742100de37902813f36315e3e380f8cb5bf240017fac1b3794a45b7286b72"}, "downloads": -1, "filename": "data-integration-2.4.2.tar.gz", "has_sig": false, "md5_digest": "ac64dfeeb5c6e436ccf0386249b21b07", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 40897, "upload_time": "2019-07-05T08:20:27", "upload_time_iso_8601": "2019-07-05T08:20:27.405567Z", "url": "https://files.pythonhosted.org/packages/c5/54/886c0e22dd0ac6947f80b8f5909033b67803ac14029dd3c59c6c59b3a84b/data-integration-2.4.2.tar.gz", "yanked": false}], "2.5.0": [{"comment_text": "", "digests": {"md5": "c6f64971b66afc3010c360144b9c562f", "sha256": "b027245266fcaca9c4813c84ad6d99a79bc41e154f3d8682d732965fd7cb4703"}, "downloads": -1, "filename": "data-integration-2.5.0.tar.gz", "has_sig": false, "md5_digest": "c6f64971b66afc3010c360144b9c562f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 40909, "upload_time": "2019-07-07T08:21:00", "upload_time_iso_8601": "2019-07-07T08:21:00.095493Z", "url": "https://files.pythonhosted.org/packages/1a/36/24d00c9889bab2dc26850a2bba710bd2065512a6d79965ae49396792ce6a/data-integration-2.5.0.tar.gz", "yanked": false}], "2.6.0": [{"comment_text": "", "digests": {"md5": "831562a8c92e618cd5bc4011afb401de", "sha256": "fbe1537920cf2f2ea53ab679f0bb7fe0d62cb7677d8f3320b8001aa2fd9eaed2"}, "downloads": -1, "filename": "data-integration-2.6.0.tar.gz", "has_sig": false, "md5_digest": "831562a8c92e618cd5bc4011afb401de", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 41481, "upload_time": "2020-02-12T22:33:09", "upload_time_iso_8601": "2020-02-12T22:33:09.938799Z", "url": "https://files.pythonhosted.org/packages/36/67/7deb750d0843d2c6f53ab59c5fefda15b9a863d9150e665fc610a219514d/data-integration-2.6.0.tar.gz", "yanked": false}], "2.6.1": [{"comment_text": "", "digests": {"md5": "573bf099202b43e0981c78ab38e4ad47", "sha256": "6716a36e076f923569560874d0b027650722151a9101b71cef9c03698cfc72c1"}, "downloads": -1, "filename": "data-integration-2.6.1.tar.gz", "has_sig": false, "md5_digest": "573bf099202b43e0981c78ab38e4ad47", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 41795, "upload_time": "2020-02-20T16:43:15", "upload_time_iso_8601": "2020-02-20T16:43:15.419932Z", "url": "https://files.pythonhosted.org/packages/69/05/76e832009fc8c643e316150332490f08754cc00b4fddde3db4320f07a57c/data-integration-2.6.1.tar.gz", "yanked": false}], "2.7.0": [{"comment_text": "", "digests": {"md5": "9a39ec79e7dd3a5ef16a60f5ab90312f", "sha256": "ce00dbad9fa34f69f22a730f25f1cccae314e1bbf39ba35daf9c651cc8f9a802"}, "downloads": -1, "filename": "data-integration-2.7.0.tar.gz", "has_sig": false, "md5_digest": "9a39ec79e7dd3a5ef16a60f5ab90312f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 43046, "upload_time": "2020-03-05T09:37:08", "upload_time_iso_8601": "2020-03-05T09:37:08.537170Z", "url": "https://files.pythonhosted.org/packages/74/b3/adeb42c18ca89a176f6ddb612a9484f98f416146e4e2e3fa33cb9585bb2e/data-integration-2.7.0.tar.gz", "yanked": false}], "2.8.0": [{"comment_text": "", "digests": {"md5": "40954ea2cf310492ceabc317a59f16b5", "sha256": "4f668f579594140d422fe2a7f54ef2071fc9b65f40c0bea84cc51347e8b6ce52"}, "downloads": -1, "filename": "data-integration-2.8.0.tar.gz", "has_sig": false, "md5_digest": "40954ea2cf310492ceabc317a59f16b5", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 44374, "upload_time": "2020-03-25T22:07:52", "upload_time_iso_8601": "2020-03-25T22:07:52.986256Z", "url": "https://files.pythonhosted.org/packages/09/59/5503e6408a837c6c0f762511cc3ba5608f0eba8e788caaa725ca470fc3b6/data-integration-2.8.0.tar.gz", "yanked": false}], "2.8.1": [{"comment_text": "", "digests": {"md5": "7d8beaf6d6e0c3212d6bf36536579cd4", "sha256": "11b88e56b1905326865f70f25f06ff2300a16b00799108d0e65f7a215a6d8d40"}, "downloads": -1, "filename": "data-integration-2.8.1.tar.gz", "has_sig": false, "md5_digest": "7d8beaf6d6e0c3212d6bf36536579cd4", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 44623, "upload_time": "2020-04-27T10:21:56", "upload_time_iso_8601": "2020-04-27T10:21:56.333571Z", "url": "https://files.pythonhosted.org/packages/5c/db/2b53511eb2a736c57a1d1562c92d6f1049fc48631205e7bdd20657098dad/data-integration-2.8.1.tar.gz", "yanked": false}], "2.8.2": [{"comment_text": "", "digests": {"md5": "523ba5a8e97cbb8cf88cd50e1f7f1ec2", "sha256": "196b88c319e19bd45c0dc88e6b306e76b7eedb5bd24fc5afbb5374104176242d"}, "downloads": -1, "filename": "data-integration-2.8.2.tar.gz", "has_sig": false, "md5_digest": "523ba5a8e97cbb8cf88cd50e1f7f1ec2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 45008, "upload_time": "2020-05-04T09:24:24", "upload_time_iso_8601": "2020-05-04T09:24:24.333397Z", "url": "https://files.pythonhosted.org/packages/9d/16/5271f2054b91fa85d9970bbe586e503f83d8c94b509cf17460953a67dd97/data-integration-2.8.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "523ba5a8e97cbb8cf88cd50e1f7f1ec2", "sha256": "196b88c319e19bd45c0dc88e6b306e76b7eedb5bd24fc5afbb5374104176242d"}, "downloads": -1, "filename": "data-integration-2.8.2.tar.gz", "has_sig": false, "md5_digest": "523ba5a8e97cbb8cf88cd50e1f7f1ec2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 45008, "upload_time": "2020-05-04T09:24:24", "upload_time_iso_8601": "2020-05-04T09:24:24.333397Z", "url": "https://files.pythonhosted.org/packages/9d/16/5271f2054b91fa85d9970bbe586e503f83d8c94b509cf17460953a67dd97/data-integration-2.8.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:40:22 2020"}