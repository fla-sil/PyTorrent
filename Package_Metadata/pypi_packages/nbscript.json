{"info": {"author": "Richard Darst", "author_email": "", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Framework :: Jupyter", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 2", "Programming Language :: Python :: 3"], "description": "# Run Jupyter notebooks as scripts\n\nJupyter notebooks are designed almost exclusively for interactive use, but\nmany people want to use them for heavy-duty computational usage.\n`nbscript` is designed to process notebooks as scripts and provide the\nmost common script features: clear start and end, arguments (argv),\n(stdin) and stdout, and so on.\n\nWe also take the perspective of batch processing, so also have a wrapper\nthat allows you to submit notebooks as Slurm scripts (similar sbatch\nwith a Python as the interpreter).\n\nNotebooks are very good for interactive work, but for large\ncomputation interactive just isn't an efficient use of resources.  For\nother expensive resources that can't be shared (GPUs for example),\ninteractive work even for development can be a bit questionable.  A\nproper course of action would be to create proper programs to run\nseparate from notebooks... but sometimes people prefer to stay in\nnotebooks.\n\nMany other modules (see references below) try to allow notebooks to be\nrun, but we take the viewpoint that the traditional UNIX script\ninterface is good and notebooks should be made like scripts: `nbscript\nnotebook.ipynb` should behave similarly to `python notebook.py`.  This\nalso allows us to provide a logical pathway to non-notebook programs.\n\n\n\n## Quick examples of invocation\n\n`nbscript`:\n\n* `nbscript input.ipynb [argv]`: runs, prints results as asciidoc to\n  stdout.  Within the script, `from nbscript import argv` to get the\n  argv.\n\n* `nbscript --save input.ipynb`: runs, saves to `input.out.ipynb`\n\n* `nbscript --save --timestamp input.ipynb`: runs, saves to\n  `input.out.TIMESTAMP.ipynb`\n\n`snotebook`:\n\n* `snotebook [slurm opts] input.ipynb`: submits to slurm with\n  `sbatch`, using the `--save` option like you see above.  Slurm\n  output is in `input.out.ipynb.log`.\n\n* `snotebook [slurm opts] --- --timestamp input.ipynb`: like above,\n  but adds `--timestamp` option like you see above.\n\n\n\n## Usage\n\nnbscript is still in development, so not all of this functionality\nexists yet.  In general, `nbscript notebook.ipynb` should have as\nsimilar an interface as `python notebook.py`.\n\n\nRun a notebook from the command line:\n\n* `nbscript nb.ipynb arg1 arg2 ...`.  Within the notebook, you can\n  access the arguments by `import nbscript ; nbscript.argv` (these are\n  currently transferred via environment variables).  Note that `argv[0]`\n  is the notebook name if it is known, otherwise `None`.\n\n* By default, only the output of the cells is printed to stdout.\n  Options may used to save the notebook to a file in any of\n  nbconvert's supported output formats.\n\n\nYou may also run a notebook via IPython extensions:\n\n* `%nbscript nb.ipynb [arg1 arg2 ...]`.  By default the output isn't\n  substituted back in, because we couldn't do much with that.\n  Instead, it is saved to a HTML file with the output and errors.  If\n  you don't give an output name, the output is timestamped.\n\n  * Currently not implemented, use `!nbscript` instead.\n\n* `nbscript` sets the `NBSCRIPT_RUNNING` environment variable, and if\n  this is already set it won't run again.  That way, you can have a\n  notebook execute itself with the `%nbscript`magic function.\n\n\nInterface within notebooks:\n\n* `import nbscript ; nbscript.argv` is the `argv` in analogy to\n  `sys.argv`.  (json-encoded in the environment variable `NB_ARGV`).\n\n  * One would use `argparse` with `nbscript.argv`, in particularly\n    `parser.parse_args(args=nbscript.argv[1:])`.\n\n* Other environment variables: `NB_NAME` is the notebook name (note\n  that there is no way for Jupyter kernels to know the currently\n  executing notebook name, this seems to be intentional because it's a\n  protocol layer violation).\n\n* `nbscript` sets the environment variable `NBSCRIPT_RUNNING` before\n  it executes a notebook, and if this is already set then it will do\n  nothing if it tries to execute again (print an error message and\n  exit).  This is so that an notebook can `nbscript`-execute itself\n  without recursive execution.  This behavior is up for debate.\n\n\nSubmit a notebook via Slurm\n\n* `snotebook nb.ipynb arg1 arg2`.  This is similar to `sbatch\n  script.sh arg1 arg2` - it will search for `#SBATCH` lines and\n  process them (stopping the search after the first cell that has\n  any).\n\n* Similar to the `%nbscript` magic function, there is the `%snotebook`\n  magic function.\n\n\nSaving output state:\n\n* When a notebook is run non-interactively, it would be useful to save\n  the state so that the output variables can be re-loaded and played\n  with.  To do that, we should find some way to serialize the state\n  and re-load it.  It would be nice if nbscript could automate this,\n  but perhaps that makes things too fragile.\n\n* The [dill](https://pypi.org/project/dill/) module is supposed to be\n  able to serialize most Python objects (but starts failing at some\n  complex machine learning pipeline objects).  One can try to\n  serialize the state at the end of the execution.\n\n* In the future, we want to add support for automatically serializing\n  the final state after the notebook is run in parallel to the html\n  output.  This would allow one to re-load the state to continue\n  post-processing.  For now, though, we recommend you explicitly save\n  whatever is important (this is probably more reliable anyway).\n\n\n\n## See also\n\nThere are many commands to execute notebooks, but most of these do not\nsee the notebooks as a first-class script, but as an interactive thing\nwhich happens to be run.  that would have run, arguments, stdout, etc.\n\n\n* https://github.com/nteract/papermill seems to be one of the most\n  similar projects to this.  Cells are tagged as containing\n  parameters, which means that they can be overridden from the command\n  line. It still takes the view that this is mainly a notebook.\n\n* [nbconvert](https://nbconvert.readthedocs.io/en/latest/) is the\n  default way for executing notebooks.  There is no default way to\n  pass arguments and output formats are designed to look like\n  notebooks.\n\n* https://pypi.org/project/runipy/ is a pretty basic script similar to\n  `nbconvert --execute` it seems (deprecated in favor of `nbconvert\n  --execute`).\n\n* Several tools called `nbrun`, some of which are deprecated in favor\n  of `nbconvert`.\n\n* https://github.com/takluyver/nbparameterise also dynamically\n  replaces values in cells.\n\n* https://github.com/NERSC/slurm-magic is IPython magic functions for\n  interacting with Slurm.  It doesn't do anything special about the\n  notebook format.  The `%%sbatch` magic submits a cell as a Slurm\n  shell script and probably the `%srun` magic runs a command line.\n  This makes a logical companion to `nbscript` and is perhaps better\n  than an interface we might make.\n\n* and many more...\n\nAll of these accomplish the same thing but have different (a few) or\nno (most) ways of passing parameters.\n\n\n\n## Development status and maintnance\n\nCurrently this is a usable alpha - the main invocations work, but get\ntoo creative and expect problems!  There are tests to verify the\nimportant stuff works, though.\n\nMaintainer: Richard Darst, Aalto University.  Feedback and\nimprovements encouraged.\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/NordicHPC/nbscript", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "nbscript", "package_url": "https://pypi.org/project/nbscript/", "platform": "", "project_url": "https://pypi.org/project/nbscript/", "project_urls": {"Homepage": "https://github.com/NordicHPC/nbscript"}, "release_url": "https://pypi.org/project/nbscript/0.1.0/", "requires_dist": ["jupyter-client", "nbconvert", "nbformat"], "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*,", "summary": "Run Jupyter notebooks like shell scripts", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Run Jupyter notebooks as scripts</h1>\n<p>Jupyter notebooks are designed almost exclusively for interactive use, but\nmany people want to use them for heavy-duty computational usage.\n<code>nbscript</code> is designed to process notebooks as scripts and provide the\nmost common script features: clear start and end, arguments (argv),\n(stdin) and stdout, and so on.</p>\n<p>We also take the perspective of batch processing, so also have a wrapper\nthat allows you to submit notebooks as Slurm scripts (similar sbatch\nwith a Python as the interpreter).</p>\n<p>Notebooks are very good for interactive work, but for large\ncomputation interactive just isn't an efficient use of resources.  For\nother expensive resources that can't be shared (GPUs for example),\ninteractive work even for development can be a bit questionable.  A\nproper course of action would be to create proper programs to run\nseparate from notebooks... but sometimes people prefer to stay in\nnotebooks.</p>\n<p>Many other modules (see references below) try to allow notebooks to be\nrun, but we take the viewpoint that the traditional UNIX script\ninterface is good and notebooks should be made like scripts: <code>nbscript notebook.ipynb</code> should behave similarly to <code>python notebook.py</code>.  This\nalso allows us to provide a logical pathway to non-notebook programs.</p>\n<h2>Quick examples of invocation</h2>\n<p><code>nbscript</code>:</p>\n<ul>\n<li>\n<p><code>nbscript input.ipynb [argv]</code>: runs, prints results as asciidoc to\nstdout.  Within the script, <code>from nbscript import argv</code> to get the\nargv.</p>\n</li>\n<li>\n<p><code>nbscript --save input.ipynb</code>: runs, saves to <code>input.out.ipynb</code></p>\n</li>\n<li>\n<p><code>nbscript --save --timestamp input.ipynb</code>: runs, saves to\n<code>input.out.TIMESTAMP.ipynb</code></p>\n</li>\n</ul>\n<p><code>snotebook</code>:</p>\n<ul>\n<li>\n<p><code>snotebook [slurm opts] input.ipynb</code>: submits to slurm with\n<code>sbatch</code>, using the <code>--save</code> option like you see above.  Slurm\noutput is in <code>input.out.ipynb.log</code>.</p>\n</li>\n<li>\n<p><code>snotebook [slurm opts] --- --timestamp input.ipynb</code>: like above,\nbut adds <code>--timestamp</code> option like you see above.</p>\n</li>\n</ul>\n<h2>Usage</h2>\n<p>nbscript is still in development, so not all of this functionality\nexists yet.  In general, <code>nbscript notebook.ipynb</code> should have as\nsimilar an interface as <code>python notebook.py</code>.</p>\n<p>Run a notebook from the command line:</p>\n<ul>\n<li>\n<p><code>nbscript nb.ipynb arg1 arg2 ...</code>.  Within the notebook, you can\naccess the arguments by <code>import nbscript ; nbscript.argv</code> (these are\ncurrently transferred via environment variables).  Note that <code>argv[0]</code>\nis the notebook name if it is known, otherwise <code>None</code>.</p>\n</li>\n<li>\n<p>By default, only the output of the cells is printed to stdout.\nOptions may used to save the notebook to a file in any of\nnbconvert's supported output formats.</p>\n</li>\n</ul>\n<p>You may also run a notebook via IPython extensions:</p>\n<ul>\n<li>\n<p><code>%nbscript nb.ipynb [arg1 arg2 ...]</code>.  By default the output isn't\nsubstituted back in, because we couldn't do much with that.\nInstead, it is saved to a HTML file with the output and errors.  If\nyou don't give an output name, the output is timestamped.</p>\n<ul>\n<li>Currently not implemented, use <code>!nbscript</code> instead.</li>\n</ul>\n</li>\n<li>\n<p><code>nbscript</code> sets the <code>NBSCRIPT_RUNNING</code> environment variable, and if\nthis is already set it won't run again.  That way, you can have a\nnotebook execute itself with the <code>%nbscript</code>magic function.</p>\n</li>\n</ul>\n<p>Interface within notebooks:</p>\n<ul>\n<li>\n<p><code>import nbscript ; nbscript.argv</code> is the <code>argv</code> in analogy to\n<code>sys.argv</code>.  (json-encoded in the environment variable <code>NB_ARGV</code>).</p>\n<ul>\n<li>One would use <code>argparse</code> with <code>nbscript.argv</code>, in particularly\n<code>parser.parse_args(args=nbscript.argv[1:])</code>.</li>\n</ul>\n</li>\n<li>\n<p>Other environment variables: <code>NB_NAME</code> is the notebook name (note\nthat there is no way for Jupyter kernels to know the currently\nexecuting notebook name, this seems to be intentional because it's a\nprotocol layer violation).</p>\n</li>\n<li>\n<p><code>nbscript</code> sets the environment variable <code>NBSCRIPT_RUNNING</code> before\nit executes a notebook, and if this is already set then it will do\nnothing if it tries to execute again (print an error message and\nexit).  This is so that an notebook can <code>nbscript</code>-execute itself\nwithout recursive execution.  This behavior is up for debate.</p>\n</li>\n</ul>\n<p>Submit a notebook via Slurm</p>\n<ul>\n<li>\n<p><code>snotebook nb.ipynb arg1 arg2</code>.  This is similar to <code>sbatch script.sh arg1 arg2</code> - it will search for <code>#SBATCH</code> lines and\nprocess them (stopping the search after the first cell that has\nany).</p>\n</li>\n<li>\n<p>Similar to the <code>%nbscript</code> magic function, there is the <code>%snotebook</code>\nmagic function.</p>\n</li>\n</ul>\n<p>Saving output state:</p>\n<ul>\n<li>\n<p>When a notebook is run non-interactively, it would be useful to save\nthe state so that the output variables can be re-loaded and played\nwith.  To do that, we should find some way to serialize the state\nand re-load it.  It would be nice if nbscript could automate this,\nbut perhaps that makes things too fragile.</p>\n</li>\n<li>\n<p>The <a href=\"https://pypi.org/project/dill/\" rel=\"nofollow\">dill</a> module is supposed to be\nable to serialize most Python objects (but starts failing at some\ncomplex machine learning pipeline objects).  One can try to\nserialize the state at the end of the execution.</p>\n</li>\n<li>\n<p>In the future, we want to add support for automatically serializing\nthe final state after the notebook is run in parallel to the html\noutput.  This would allow one to re-load the state to continue\npost-processing.  For now, though, we recommend you explicitly save\nwhatever is important (this is probably more reliable anyway).</p>\n</li>\n</ul>\n<h2>See also</h2>\n<p>There are many commands to execute notebooks, but most of these do not\nsee the notebooks as a first-class script, but as an interactive thing\nwhich happens to be run.  that would have run, arguments, stdout, etc.</p>\n<ul>\n<li>\n<p><a href=\"https://github.com/nteract/papermill\" rel=\"nofollow\">https://github.com/nteract/papermill</a> seems to be one of the most\nsimilar projects to this.  Cells are tagged as containing\nparameters, which means that they can be overridden from the command\nline. It still takes the view that this is mainly a notebook.</p>\n</li>\n<li>\n<p><a href=\"https://nbconvert.readthedocs.io/en/latest/\" rel=\"nofollow\">nbconvert</a> is the\ndefault way for executing notebooks.  There is no default way to\npass arguments and output formats are designed to look like\nnotebooks.</p>\n</li>\n<li>\n<p><a href=\"https://pypi.org/project/runipy/\" rel=\"nofollow\">https://pypi.org/project/runipy/</a> is a pretty basic script similar to\n<code>nbconvert --execute</code> it seems (deprecated in favor of <code>nbconvert --execute</code>).</p>\n</li>\n<li>\n<p>Several tools called <code>nbrun</code>, some of which are deprecated in favor\nof <code>nbconvert</code>.</p>\n</li>\n<li>\n<p><a href=\"https://github.com/takluyver/nbparameterise\" rel=\"nofollow\">https://github.com/takluyver/nbparameterise</a> also dynamically\nreplaces values in cells.</p>\n</li>\n<li>\n<p><a href=\"https://github.com/NERSC/slurm-magic\" rel=\"nofollow\">https://github.com/NERSC/slurm-magic</a> is IPython magic functions for\ninteracting with Slurm.  It doesn't do anything special about the\nnotebook format.  The <code>%%sbatch</code> magic submits a cell as a Slurm\nshell script and probably the <code>%srun</code> magic runs a command line.\nThis makes a logical companion to <code>nbscript</code> and is perhaps better\nthan an interface we might make.</p>\n</li>\n<li>\n<p>and many more...</p>\n</li>\n</ul>\n<p>All of these accomplish the same thing but have different (a few) or\nno (most) ways of passing parameters.</p>\n<h2>Development status and maintnance</h2>\n<p>Currently this is a usable alpha - the main invocations work, but get\ntoo creative and expect problems!  There are tests to verify the\nimportant stuff works, though.</p>\n<p>Maintainer: Richard Darst, Aalto University.  Feedback and\nimprovements encouraged.</p>\n\n          </div>"}, "last_serial": 6960857, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "d960bab6dc16d23468a544249902abba", "sha256": "51d09ff4b034a427109b5394f75d7926e81a3f83c30000537202f0a974a3b1e6"}, "downloads": -1, "filename": "nbscript-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "d960bab6dc16d23468a544249902abba", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*,", "size": 12674, "upload_time": "2020-04-06T11:18:08", "upload_time_iso_8601": "2020-04-06T11:18:08.146420Z", "url": "https://files.pythonhosted.org/packages/f4/43/84fb47ef13c4d2bd91e5e90803b3e2910d3ed5352e84369407460f99ae59/nbscript-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ba07eaedd25234b90c254c3938622449", "sha256": "aa70716d07f39b3738288be9a1472c135719bff1d58a184d81ca1074c497387b"}, "downloads": -1, "filename": "nbscript-0.1.0.tar.gz", "has_sig": false, "md5_digest": "ba07eaedd25234b90c254c3938622449", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*,", "size": 13100, "upload_time": "2020-04-06T11:18:10", "upload_time_iso_8601": "2020-04-06T11:18:10.285986Z", "url": "https://files.pythonhosted.org/packages/c7/31/a224b89b40a4f43e36a063b558d710459e1e9f7c09c9e6ddb45a3d892ee5/nbscript-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "d960bab6dc16d23468a544249902abba", "sha256": "51d09ff4b034a427109b5394f75d7926e81a3f83c30000537202f0a974a3b1e6"}, "downloads": -1, "filename": "nbscript-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "d960bab6dc16d23468a544249902abba", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*,", "size": 12674, "upload_time": "2020-04-06T11:18:08", "upload_time_iso_8601": "2020-04-06T11:18:08.146420Z", "url": "https://files.pythonhosted.org/packages/f4/43/84fb47ef13c4d2bd91e5e90803b3e2910d3ed5352e84369407460f99ae59/nbscript-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ba07eaedd25234b90c254c3938622449", "sha256": "aa70716d07f39b3738288be9a1472c135719bff1d58a184d81ca1074c497387b"}, "downloads": -1, "filename": "nbscript-0.1.0.tar.gz", "has_sig": false, "md5_digest": "ba07eaedd25234b90c254c3938622449", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*,", "size": 13100, "upload_time": "2020-04-06T11:18:10", "upload_time_iso_8601": "2020-04-06T11:18:10.285986Z", "url": "https://files.pythonhosted.org/packages/c7/31/a224b89b40a4f43e36a063b558d710459e1e9f7c09c9e6ddb45a3d892ee5/nbscript-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:46:52 2020"}