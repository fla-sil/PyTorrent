{"info": {"author": "Michel Blancard", "author_email": "UNKNOWN", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3"], "description": "# weakscraper\nHTML scraper with templates\n\n## Description\n\nMost HTML pages are generated using templates. Why not use templates too for scraping HTML pages? As for a template language, let's use HTML plus a few keywords. That way, the workflow with `weakscraper` is the following :\n* Get the source of a HTML page you want to scrap.\n* Using a few keywords, edit the HTML to select which information is of interest and which parts to discard.\n* If complicated processing is required, write additional callbacks.\n* Run `weakscraper` on the template and on the HTML.\n\n\n## Pros\n* Observes the [rule of least power](https://en.wikipedia.org/wiki/Rule_of_least_power). A declarative language helps to focus on *what* to keep. *How* the information is scrapped is the job of the library.\n\n## Cons\n\n## Examples\n\n## How it works ?\n\n## License\n\nMIT (http://www.opensource.org/licenses/mit-license.php)", "description_content_type": null, "docs_url": null, "download_url": null, "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/michelbl/weakscraper", "keywords": "parser scraper HTML template", "license": "MIT", "maintainer": null, "maintainer_email": null, "name": "weakscraper", "package_url": "https://pypi.org/project/weakscraper/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/weakscraper/", "project_urls": {"Homepage": "https://github.com/michelbl/weakscraper"}, "release_url": "https://pypi.org/project/weakscraper/0.0.1/", "requires_dist": null, "requires_python": null, "summary": "HTML scraper with templates", "version": "0.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p># weakscraper\nHTML scraper with templates</p>\n<p>## Description</p>\n<p>Most HTML pages are generated using templates. Why not use templates too for scraping HTML pages? As for a template language, let\u2019s use HTML plus a few keywords. That way, the workflow with <cite>weakscraper</cite> is the following :\n* Get the source of a HTML page you want to scrap.\n* Using a few keywords, edit the HTML to select which information is of interest and which parts to discard.\n* If complicated processing is required, write additional callbacks.\n* Run <cite>weakscraper</cite> on the template and on the HTML.</p>\n<p>## Pros\n* Observes the [rule of least power](<a href=\"https://en.wikipedia.org/wiki/Rule_of_least_power\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Rule_of_least_power</a>). A declarative language helps to focus on <em>what</em> to keep. <em>How</em> the information is scrapped is the job of the library.</p>\n<p>## Cons</p>\n<p>## Examples</p>\n<p>## How it works ?</p>\n<p>## License</p>\n<p>MIT (<a href=\"http://www.opensource.org/licenses/mit-license.php\" rel=\"nofollow\">http://www.opensource.org/licenses/mit-license.php</a>)</p>\n\n          </div>"}, "last_serial": 2031932, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "3845eb4aaec6594ff8e360ef2ed235a4", "sha256": "6288e9dfbc5213b4ab814452b1b1f8c30dc1bba03702b26fac3680416c9850a3"}, "downloads": -1, "filename": "weakscraper-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "3845eb4aaec6594ff8e360ef2ed235a4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 14038, "upload_time": "2016-03-28T16:08:49", "upload_time_iso_8601": "2016-03-28T16:08:49.786747Z", "url": "https://files.pythonhosted.org/packages/80/a5/756fc5e3568bbcd8bd705b2e377a2da9ac95b0be7c405021cbdb2cfa704a/weakscraper-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "75509108173ea9f40d11ec9ca2aa2ef7", "sha256": "4a3d7950c73bbed6b38da9cbb2eccabc262bfd18d9a6203b7b50a3bcc5a03eb9"}, "downloads": -1, "filename": "weakscraper-0.0.1.tar.gz", "has_sig": false, "md5_digest": "75509108173ea9f40d11ec9ca2aa2ef7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7365, "upload_time": "2016-03-28T16:09:21", "upload_time_iso_8601": "2016-03-28T16:09:21.288846Z", "url": "https://files.pythonhosted.org/packages/82/c6/3862484d2da7723d2dacaa5d173bb40bddc59bd0ac0c434e7e2ca1dab67c/weakscraper-0.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "3845eb4aaec6594ff8e360ef2ed235a4", "sha256": "6288e9dfbc5213b4ab814452b1b1f8c30dc1bba03702b26fac3680416c9850a3"}, "downloads": -1, "filename": "weakscraper-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "3845eb4aaec6594ff8e360ef2ed235a4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 14038, "upload_time": "2016-03-28T16:08:49", "upload_time_iso_8601": "2016-03-28T16:08:49.786747Z", "url": "https://files.pythonhosted.org/packages/80/a5/756fc5e3568bbcd8bd705b2e377a2da9ac95b0be7c405021cbdb2cfa704a/weakscraper-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "75509108173ea9f40d11ec9ca2aa2ef7", "sha256": "4a3d7950c73bbed6b38da9cbb2eccabc262bfd18d9a6203b7b50a3bcc5a03eb9"}, "downloads": -1, "filename": "weakscraper-0.0.1.tar.gz", "has_sig": false, "md5_digest": "75509108173ea9f40d11ec9ca2aa2ef7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7365, "upload_time": "2016-03-28T16:09:21", "upload_time_iso_8601": "2016-03-28T16:09:21.288846Z", "url": "https://files.pythonhosted.org/packages/82/c6/3862484d2da7723d2dacaa5d173bb40bddc59bd0ac0c434e7e2ca1dab67c/weakscraper-0.0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:31:37 2020"}