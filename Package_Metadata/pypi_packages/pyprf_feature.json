{"info": {"author": "Marian Schneider, Ingo Marquardt", "author_email": "marian.schneider@maastrichtuniversity.nl", "bugtrack_url": null, "classifiers": [], "description": "|DOI|\n\npyprf_feature\n=============\n\nA free & open source package for finding best-fitting population\nreceptive field (PRF) models and feature weights for fMRI data.\n\nIf you are only interested in the spatial properties of the population\nreceptive fields, not preferred features, check out the `pyprf\npackage <https://github.com/ingo-m/pypRF>`__.\n\nInstallation\n------------\n\nFor installation, follow these steps:\n\n0. (Optional) Create conda environment\n\n.. code:: bash\n\n    conda create -n env_pyprf_feature python=2.7\n    source activate env_pyprf_feature\n    conda install pip\n\n1. Clone repository\n\n.. code:: bash\n\n    git clone https://github.com/MSchnei/pyprf_feature.git\n\n2. Install numpy, e.g.\u00a0by running:\n\n.. code:: bash\n\n    pip install numpy\n\n3. Install pyprf_feature with pip\n\n.. code:: bash\n\n    pip install /path/to/cloned/pyprf_feature\n\nDependencies\n------------\n\n`**Python 2.7** <https://www.python.org/download/releases/2.7/>`__\n\n+----------------------------------------+----------------+\n| Package                                | Tested version |\n+========================================+================+\n| `NumPy <http://www.numpy.org/>`__      | 1.11.1         |\n+----------------------------------------+----------------+\n| `SciPy <http://www.scipy.org/>`__      | 0.18.0         |\n+----------------------------------------+----------------+\n| `NiBabel <http://nipy.org/nibabel/>`__ | 2.0.2          |\n+----------------------------------------+----------------+\n\nHow to use\n----------\n\n1. Present stimuli and record fMRI data\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe PsychoPy scripts in the Stimulation folder can be used for\npresenting appropriate visual stimuli.\n\n2. Prepare spatial and temporal information for experiment as arrays\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n1. Run prepro_get_spat_info.py in the prepro folder to obtain an array\n   with the spatial information of the experiment. This should result in\n   a 3d numpy array with shape [pixel x pixel x nr of spatial aperture\n   conditions] that represents images of the spatial apertures stacked\n   on top of each other.\n\n2. Run prepro_get_temp_info.py in the prepro folder to obtain an array\n   with the temporal information of the experiment. This should result\n   in a 2d numpy array with shape [nr of volumes across all runs x 4].\n   The first column represents unique identifiers of spatial aperture\n   conditions. The second column represents onset times and the third\n   durations (both in s).The fourth column represents unique feature\n   identifiers.\n\n3. Prepare the input data\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe input data should be motion-corrected, high-pass filtered and\n(optionally) distortion-corrected. If desired, spatial as well as\ntemporal smoothing can be applied. The PrePro folder contains some\nauxiliary scripts to perform some of these functions.\n\n4. Adjust the csv file\n~~~~~~~~~~~~~~~~~~~~~~\n\nAdjust the information in the config_default.csv file in the Analysis\nfolder, such that the provided information is correct. It is recommended\nto make a specific copy of the csv file for every subject.\n\n5. Run pyprf_feature\n~~~~~~~~~~~~~~~~~~~~\n\nOpen a terminal and run\n\n::\n\n    pyprf_feature -config path/to/custom_config.csv\n\nReferences\n----------\n\nThis application is based on the following work:\n\n-  Dumoulin, S. O., & Wandell, B. A. (2008). Population receptive field\n   estimates in human visual cortex. NeuroImage, 39(2), 647\u2013660.\n   https://doi.org/10.1016/j.neuroimage.2007.09.034\n\n-  Nishimoto, S., Vu, A. T., Naselaris, T., Benjamini, Y., Yu, B., &\n   Gallant, J. L. (2011). Report Reconstructing Visual Experiences from\n   Brain Activity Evoked by Natural Movies, 1641\u20131646.\n   https://doi.org/10.1016/j.cub.2011.08.031\n\n-  St-Yves, G., & Naselaris, T. (2017). The feature-weighted receptive\n   field: An interpretable encoding model for complex feature spaces.\n   NeuroImage, (June), 1\u201315.\n   https://doi.org/10.1016/j.neuroimage.2017.06.035\n\nLicense\n-------\n\nThe project is licensed under `GNU General Public License Version\n3 <http://www.gnu.org/licenses/gpl.html>`__.\n\n.. |DOI| image:: https://zenodo.org/badge/78625137.svg\n   :target: https://zenodo.org/badge/latestdoi/78625137\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/MSchnei/pyprf_feature", "keywords": "pRF", "license": "GNU General Public License Version 3", "maintainer": "", "maintainer_email": "", "name": "pyprf_feature", "package_url": "https://pypi.org/project/pyprf_feature/", "platform": "", "project_url": "https://pypi.org/project/pyprf_feature/", "project_urls": {"Homepage": "https://github.com/MSchnei/pyprf_feature"}, "release_url": "https://pypi.org/project/pyprf_feature/1.1.3/", "requires_dist": null, "requires_python": "", "summary": "A free & open source package for finding best-fitting                     population receptive field (PRF) models and feature                     weights for fMRI data.", "version": "1.1.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://zenodo.org/badge/latestdoi/78625137\" rel=\"nofollow\"><img alt=\"DOI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9618e18ee05ea993eefafeac809fa59bd372afd8/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f37383632353133372e737667\"></a></p>\n<div id=\"pyprf-feature\">\n<h2>pyprf_feature</h2>\n<p>A free &amp; open source package for finding best-fitting population\nreceptive field (PRF) models and feature weights for fMRI data.</p>\n<p>If you are only interested in the spatial properties of the population\nreceptive fields, not preferred features, check out the <a href=\"https://github.com/ingo-m/pypRF\" rel=\"nofollow\">pyprf\npackage</a>.</p>\n<div id=\"installation\">\n<h3>Installation</h3>\n<p>For installation, follow these steps:</p>\n<ol>\n<li>(Optional) Create conda environment</li>\n</ol>\n<pre>conda create -n env_pyprf_feature <span class=\"nv\">python</span><span class=\"o\">=</span><span class=\"m\">2</span>.7\n<span class=\"nb\">source</span> activate env_pyprf_feature\nconda install pip\n</pre>\n<ol>\n<li>Clone repository</li>\n</ol>\n<pre>git clone https://github.com/MSchnei/pyprf_feature.git\n</pre>\n<ol>\n<li>Install numpy, e.g.\u00a0by running:</li>\n</ol>\n<pre>pip install numpy\n</pre>\n<ol>\n<li>Install pyprf_feature with pip</li>\n</ol>\n<pre>pip install /path/to/cloned/pyprf_feature\n</pre>\n</div>\n<div id=\"dependencies\">\n<h3>Dependencies</h3>\n<p><a href=\"https://www.python.org/download/releases/2.7/\" rel=\"nofollow\">**Python 2.7**</a></p>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Package</th>\n<th>Tested version</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><a href=\"http://www.numpy.org/\" rel=\"nofollow\">NumPy</a></td>\n<td>1.11.1</td>\n</tr>\n<tr><td><a href=\"http://www.scipy.org/\" rel=\"nofollow\">SciPy</a></td>\n<td>0.18.0</td>\n</tr>\n<tr><td><a href=\"http://nipy.org/nibabel/\" rel=\"nofollow\">NiBabel</a></td>\n<td>2.0.2</td>\n</tr>\n</tbody>\n</table>\n</div>\n<div id=\"how-to-use\">\n<h3>How to use</h3>\n<div id=\"present-stimuli-and-record-fmri-data\">\n<h4>1. Present stimuli and record fMRI data</h4>\n<p>The PsychoPy scripts in the Stimulation folder can be used for\npresenting appropriate visual stimuli.</p>\n</div>\n<div id=\"prepare-spatial-and-temporal-information-for-experiment-as-arrays\">\n<h4>2. Prepare spatial and temporal information for experiment as arrays</h4>\n<ol>\n<li>Run prepro_get_spat_info.py in the prepro folder to obtain an array\nwith the spatial information of the experiment. This should result in\na 3d numpy array with shape [pixel x pixel x nr of spatial aperture\nconditions] that represents images of the spatial apertures stacked\non top of each other.</li>\n<li>Run prepro_get_temp_info.py in the prepro folder to obtain an array\nwith the temporal information of the experiment. This should result\nin a 2d numpy array with shape [nr of volumes across all runs x 4].\nThe first column represents unique identifiers of spatial aperture\nconditions. The second column represents onset times and the third\ndurations (both in s).The fourth column represents unique feature\nidentifiers.</li>\n</ol>\n</div>\n<div id=\"prepare-the-input-data\">\n<h4>3. Prepare the input data</h4>\n<p>The input data should be motion-corrected, high-pass filtered and\n(optionally) distortion-corrected. If desired, spatial as well as\ntemporal smoothing can be applied. The PrePro folder contains some\nauxiliary scripts to perform some of these functions.</p>\n</div>\n<div id=\"adjust-the-csv-file\">\n<h4>4. Adjust the csv file</h4>\n<p>Adjust the information in the config_default.csv file in the Analysis\nfolder, such that the provided information is correct. It is recommended\nto make a specific copy of the csv file for every subject.</p>\n</div>\n<div id=\"run-pyprf-feature\">\n<h4>5. Run pyprf_feature</h4>\n<p>Open a terminal and run</p>\n<pre>pyprf_feature -config path/to/custom_config.csv\n</pre>\n</div>\n</div>\n<div id=\"references\">\n<h3>References</h3>\n<p>This application is based on the following work:</p>\n<ul>\n<li>Dumoulin, S. O., &amp; Wandell, B. A. (2008). Population receptive field\nestimates in human visual cortex. NeuroImage, 39(2), 647\u2013660.\n<a href=\"https://doi.org/10.1016/j.neuroimage.2007.09.034\" rel=\"nofollow\">https://doi.org/10.1016/j.neuroimage.2007.09.034</a></li>\n<li>Nishimoto, S., Vu, A. T., Naselaris, T., Benjamini, Y., Yu, B., &amp;\nGallant, J. L. (2011). Report Reconstructing Visual Experiences from\nBrain Activity Evoked by Natural Movies, 1641\u20131646.\n<a href=\"https://doi.org/10.1016/j.cub.2011.08.031\" rel=\"nofollow\">https://doi.org/10.1016/j.cub.2011.08.031</a></li>\n<li>St-Yves, G., &amp; Naselaris, T. (2017). The feature-weighted receptive\nfield: An interpretable encoding model for complex feature spaces.\nNeuroImage, (June), 1\u201315.\n<a href=\"https://doi.org/10.1016/j.neuroimage.2017.06.035\" rel=\"nofollow\">https://doi.org/10.1016/j.neuroimage.2017.06.035</a></li>\n</ul>\n</div>\n<div id=\"license\">\n<h3>License</h3>\n<p>The project is licensed under <a href=\"http://www.gnu.org/licenses/gpl.html\" rel=\"nofollow\">GNU General Public License Version\n3</a>.</p>\n</div>\n</div>\n\n          </div>"}, "last_serial": 4921408, "releases": {"1.1.0": [{"comment_text": "", "digests": {"md5": "a9a2a83554bc347448e8a72fe1a490e0", "sha256": "9179bb1aa94a2c40eb97ace662a391492e7b002abfdf3b3c05d17ffe8f140da7"}, "downloads": -1, "filename": "pyprf_feature-1.1.0.tar.gz", "has_sig": false, "md5_digest": "a9a2a83554bc347448e8a72fe1a490e0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 51051, "upload_time": "2018-10-27T11:14:17", "upload_time_iso_8601": "2018-10-27T11:14:17.340703Z", "url": "https://files.pythonhosted.org/packages/55/f0/0bf51aad6971361b70ed54cecf121b7e3a8b40901b603893536e7b8923ee/pyprf_feature-1.1.0.tar.gz", "yanked": false}], "1.1.1": [{"comment_text": "", "digests": {"md5": "2538591db6e313f13bd210c229289cfd", "sha256": "67c97e9e8c28c95e4862df50cefdd5c4d52d9a1f3bd61dfb7305cbcd3dc9aad3"}, "downloads": -1, "filename": "pyprf_feature-1.1.1.tar.gz", "has_sig": false, "md5_digest": "2538591db6e313f13bd210c229289cfd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 53844, "upload_time": "2018-11-20T12:35:27", "upload_time_iso_8601": "2018-11-20T12:35:27.807513Z", "url": "https://files.pythonhosted.org/packages/2d/1a/b61b6609cbf986b2d2cdd2475d1d29a77fcb006ac408a69abafca19b312c/pyprf_feature-1.1.1.tar.gz", "yanked": false}], "1.1.2": [{"comment_text": "", "digests": {"md5": "1e00c07b48c2a9ca89e0733c67abec65", "sha256": "a4cc9ab26eeb97e15131fa6c267429c780140d8c0102269a270b1c6a6050c45d"}, "downloads": -1, "filename": "pyprf_feature-1.1.2.tar.gz", "has_sig": false, "md5_digest": "1e00c07b48c2a9ca89e0733c67abec65", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 53980, "upload_time": "2018-12-06T16:04:58", "upload_time_iso_8601": "2018-12-06T16:04:58.232483Z", "url": "https://files.pythonhosted.org/packages/4f/b7/e548a1c03d7cec22083c41f0efc3fe1deb98e2629593cb4b9da46eaa4321/pyprf_feature-1.1.2.tar.gz", "yanked": false}], "1.1.3": [{"comment_text": "", "digests": {"md5": "1f35ee69c3c2ea49d2d98f18b127d2e1", "sha256": "e14adcd90c081ca3d024a402a69262cdce42ed2d73395995088528d3c59836bf"}, "downloads": -1, "filename": "pyprf_feature-1.1.3.tar.gz", "has_sig": false, "md5_digest": "1f35ee69c3c2ea49d2d98f18b127d2e1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 56755, "upload_time": "2019-03-10T14:26:24", "upload_time_iso_8601": "2019-03-10T14:26:24.222170Z", "url": "https://files.pythonhosted.org/packages/7c/f4/718da4e68b350f81e5b918b201f23219f55e45977c2315027c7c30d92923/pyprf_feature-1.1.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "1f35ee69c3c2ea49d2d98f18b127d2e1", "sha256": "e14adcd90c081ca3d024a402a69262cdce42ed2d73395995088528d3c59836bf"}, "downloads": -1, "filename": "pyprf_feature-1.1.3.tar.gz", "has_sig": false, "md5_digest": "1f35ee69c3c2ea49d2d98f18b127d2e1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 56755, "upload_time": "2019-03-10T14:26:24", "upload_time_iso_8601": "2019-03-10T14:26:24.222170Z", "url": "https://files.pythonhosted.org/packages/7c/f4/718da4e68b350f81e5b918b201f23219f55e45977c2315027c7c30d92923/pyprf_feature-1.1.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:59:09 2020"}