{"info": {"author": "Trevor Barron", "author_email": "barron.trevor@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Education", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "===============================\nRLFlow\n===============================\n\n\n.. image:: https://img.shields.io/pypi/v/rlflow.svg\n        :target: https://pypi.python.org/pypi/rlflow\n\n.. image:: https://img.shields.io/travis/tpbarron/rlflow.svg\n        :target: https://travis-ci.org/tpbarron/rlflow\n\n.. image:: https://readthedocs.org/projects/rlflow/badge/?version=latest\n        :target: https://rlflow.readthedocs.io/en/latest/?badge=latest\n        :alt: Documentation Status\n\n.. image:: https://pyup.io/repos/github/tpbarron/rlflow/shield.svg\n     :target: https://pyup.io/repos/github/tpbarron/rlflow/\n     :alt: Updates\n\n\nA framework for learning about and experimenting with reinforcement learning algorithms.\nIt is built on top of TensorFlow and `TFLearn <http://tflearn.org/>`_  and is interfaces\nwith the OpenAI gym (universe should work, too). It aims to be as modular as possible so\nthat new algorithms and ideas can easily be tested. I started it to gain a better\nunderstanding of core RL algorithms and maybe it can be useful for others as well.\n\n\nFeatures\n--------\n\nAlgorithms (future algorithms italicized):\n\n  - MDP algorithms\n\n      + Value iteration\n      + Policy iteration\n\n  - Temporal Difference Learning\n\n      + SARSA\n      + Deep Q-Learning\n      + *Policy gradient Q-learning*\n\n  - Gradient algorithms\n\n      + Vanilla policy gradient\n      + *Deterministic policy gradient*\n      + *Natural policy gradient*\n\n  - Gradient-Free algorithms\n\n      + *Cross entropy method*\n\nFunction approximators (defined by TFLearn model):\n\n  - Linear\n  - Neural network\n  - *RBF*\n\nWorks with any OpenAI gym environment.\n\n\nFuture Enhancements\n-------------------\n\n* Improved TensorBoard logging\n* Improved model snapshotting to include exploration states, memories, etc.\n* Any suggestions?\n\n\nFixes\n------------------\n* Errors / warnings on TensorFlow session save\n\n\nLicense\n------------------\n\n* Free software: MIT license\n* Documentation: https://rlflow.readthedocs.io.\n\n\n=======\nHistory\n=======\n\n0.1.2/3 (2016-17-15)\n------------------\n\n* Improving meta data and fixing __init__ scripts to load subpackages properly\n\n\n0.1.0 (2016-16-15)\n------------------\n\n* First release on PyPI.", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/tpbarron/rlflow", "keywords": "FLFlow,TFLearn,TensorFlow,Deep Learning,Reinforcement Learning,Machine Learning,Neural Networks", "license": "MIT license", "maintainer": "", "maintainer_email": "", "name": "rlflow", "package_url": "https://pypi.org/project/rlflow/", "platform": "", "project_url": "https://pypi.org/project/rlflow/", "project_urls": {"Homepage": "https://github.com/tpbarron/rlflow"}, "release_url": "https://pypi.org/project/rlflow/0.1.3/", "requires_dist": null, "requires_python": "", "summary": "A framework for learning about and experimenting with reinforcement learning algorithms", "version": "0.1.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            ===============================<br>RLFlow<br>===============================<br><br><br>.. image:: https://img.shields.io/pypi/v/rlflow.svg<br>        :target: https://pypi.python.org/pypi/rlflow<br><br>.. image:: https://img.shields.io/travis/tpbarron/rlflow.svg<br>        :target: https://travis-ci.org/tpbarron/rlflow<br><br>.. image:: https://readthedocs.org/projects/rlflow/badge/?version=latest<br>        :target: https://rlflow.readthedocs.io/en/latest/?badge=latest<br>        :alt: Documentation Status<br><br>.. image:: https://pyup.io/repos/github/tpbarron/rlflow/shield.svg<br>     :target: https://pyup.io/repos/github/tpbarron/rlflow/<br>     :alt: Updates<br><br><br>A framework for learning about and experimenting with reinforcement learning algorithms.<br>It is built on top of TensorFlow and `TFLearn &lt;http://tflearn.org/&gt;`_  and is interfaces<br>with the OpenAI gym (universe should work, too). It aims to be as modular as possible so<br>that new algorithms and ideas can easily be tested. I started it to gain a better<br>understanding of core RL algorithms and maybe it can be useful for others as well.<br><br><br>Features<br>--------<br><br>Algorithms (future algorithms italicized):<br><br>  - MDP algorithms<br><br>      + Value iteration<br>      + Policy iteration<br><br>  - Temporal Difference Learning<br><br>      + SARSA<br>      + Deep Q-Learning<br>      + *Policy gradient Q-learning*<br><br>  - Gradient algorithms<br><br>      + Vanilla policy gradient<br>      + *Deterministic policy gradient*<br>      + *Natural policy gradient*<br><br>  - Gradient-Free algorithms<br><br>      + *Cross entropy method*<br><br>Function approximators (defined by TFLearn model):<br><br>  - Linear<br>  - Neural network<br>  - *RBF*<br><br>Works with any OpenAI gym environment.<br><br><br>Future Enhancements<br>-------------------<br><br>* Improved TensorBoard logging<br>* Improved model snapshotting to include exploration states, memories, etc.<br>* Any suggestions?<br><br><br>Fixes<br>------------------<br>* Errors / warnings on TensorFlow session save<br><br><br>License<br>------------------<br><br>* Free software: MIT license<br>* Documentation: https://rlflow.readthedocs.io.<br><br><br>=======<br>History<br>=======<br><br>0.1.2/3 (2016-17-15)<br>------------------<br><br>* Improving meta data and fixing __init__ scripts to load subpackages properly<br><br><br>0.1.0 (2016-16-15)<br>------------------<br><br>* First release on PyPI.\n          </div>"}, "last_serial": 2525221, "releases": {"0.1.2": [{"comment_text": "", "digests": {"md5": "fd6feba71a49057447d210118a4402cc", "sha256": "49fbfb114e9733d650ad05f2b226336bc6910370ffac7604a81971fcc4c3d48d"}, "downloads": -1, "filename": "rlflow-0.1.2.tar.gz", "has_sig": false, "md5_digest": "fd6feba71a49057447d210118a4402cc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12526, "upload_time": "2016-12-17T16:57:49", "upload_time_iso_8601": "2016-12-17T16:57:49.191864Z", "url": "https://files.pythonhosted.org/packages/53/ce/ab6b9427feadb28f2ed0b52af7d473cd60eaa338455a5ecc3c84ec5889c3/rlflow-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "d1d7263ed792abc3f6937a16c09091b6", "sha256": "b9a0aec4a60505ba3ec2301825887aa91959e527c117a16654e68e4c27635a04"}, "downloads": -1, "filename": "rlflow-0.1.3.tar.gz", "has_sig": false, "md5_digest": "d1d7263ed792abc3f6937a16c09091b6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 26954, "upload_time": "2016-12-17T20:57:06", "upload_time_iso_8601": "2016-12-17T20:57:06.851202Z", "url": "https://files.pythonhosted.org/packages/a8/1e/8e0c81d207578a3fd0ee30c3781ffda800768ed8ca097f2ab3a9f93e8974/rlflow-0.1.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "d1d7263ed792abc3f6937a16c09091b6", "sha256": "b9a0aec4a60505ba3ec2301825887aa91959e527c117a16654e68e4c27635a04"}, "downloads": -1, "filename": "rlflow-0.1.3.tar.gz", "has_sig": false, "md5_digest": "d1d7263ed792abc3f6937a16c09091b6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 26954, "upload_time": "2016-12-17T20:57:06", "upload_time_iso_8601": "2016-12-17T20:57:06.851202Z", "url": "https://files.pythonhosted.org/packages/a8/1e/8e0c81d207578a3fd0ee30c3781ffda800768ed8ca097f2ab3a9f93e8974/rlflow-0.1.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:02:17 2020"}