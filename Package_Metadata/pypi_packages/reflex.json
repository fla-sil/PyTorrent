{"info": {"author": "Talin", "author_email": "viridia@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "License :: OSI Approved :: GNU General Public License (GPL)", "License :: OSI Approved :: Python Software Foundation License", "Operating System :: OS Independent", "Programming Language :: Python", "Topic :: Software Development :: Compilers", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "Reflex: A lightweight lexical scanner library.\n\nReflex supports regular expressions, rule actions, multiple scanner states,\ntracking of line/column numbers, and customizable token classes.\n\nReflex is not a \"scanner generator\" in the sense of generating source code.\nInstead, it generates a scanner object dynamically based on the set of\ninput rules sepecified. The rules themselves are ordinary python regular\nexpressions, combined with rule actions which are simply python functions.\n\nExample use:\n\n    # Create a scanner. The \"start\" parameter specifies the name of the\n    # starting state. Note: The state argument can be any hashable python\n    # type.\n    scanner = reflex.scanner( \"start\" )\n    \n    # Add some rules.\n    # The whitespace rule has no actions, so whitespace will be skipped\n    scanner.rule( \"\\s+\" )\n    \n    # Rules for identifiers and numbers.\n    TOKEN_IDENT = 1\n    TOKEN_NUMBER = 2\n    scanner.rule( \"[a-zA-Z_][\\w_]*\", token=TOKEN_IDENT )\n    scanner.rule( \"0x[\\da-fA-F]+|\\d+\", token=TOKEN_NUMBER )\n    \n    # The \"string\" rule kicks us into the string state\n    TOKEN_STRING = 3\n    scanner.rule( \"\\\"\", tostate=\"string\" )\n\n    # Define the string state. \"string_escape\" and \"string_chars\" are\n    # action functions which handle the parsed charaxcters and escape\n    # sequences and append them to a buffer. Once a quotation mark\n    # is encountered, we set the token type to be TOKEN_STRING\n    # and return to the start state.\n    scanner.state( \"string\" )\n    scanner.rule( \"\\\"\", tostate=\"start\", token=TOKEN_STRING )\n    scanner.rule( \"\\\\\\\\.\", string_escape )\n    scanner.rule( \"[^\\\"\\\\\\\\]+\", string_text )\n\nInvoking the scanner: The scanner can be called as a function which\ntakes a reference to a stream (such as a file object) which iterates\nover input lines. The \"context\" argument is for application use,\nThe result is an iterator which produces a series of tokens.\nThe same scanner can be used to parse multiple input files, by\ncreating a new stream for each file.\n\n    # Return an instance of the scanner.\n    token_iter = scanner( istream, context )\n\nGetting the tokens. Here is a simple example of looping through the\ninput tokens. A real-world use would most likely involve comparing\nvs. the type of the current token.\n\n    # token.id is the token type (the same as the token= argument in the rule)\n    # token.value is the actual characters that make up the token.\n    # token.line is the line number on which the token was encountered.\n    # token.pos is the column number of the first character of the token.\n    for token in token_iter:\n        print token.id, token.value, token.line, token.pos\n     \nAction functions are python functions which take a single argument, which\nis the token stream instance.\n\n    # Action function to handle striing text.\n    # Appends the value of the current token to the string data\n    def string_text( token_stream ):\n        string_data += scanner.token.value\n        \nThe token_stream object has a number of interesting and usable attributes:\n\n    states:  dictionary of scanner states\n    state:   the current state\n    stream:  the input line stream\n    context: the context pointer that was passed to the scanner\n    token:   the current token\n    line:    the line number of the current parse position\n    pos:     the column number of the current parse position\n    \nNote - reflex currently has a limit of 99 rules for each state. (That is\nthe maximum number of capturing groups allowed in a python regular expression.)", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://viridia.org/python-projects/", "keywords": null, "license": "Choice of GPL or Python license", "maintainer": null, "maintainer_email": null, "name": "reflex", "package_url": "https://pypi.org/project/reflex/", "platform": "Any", "project_url": "https://pypi.org/project/reflex/", "project_urls": {"Download": "UNKNOWN", "Homepage": "http://viridia.org/python-projects/"}, "release_url": "https://pypi.org/project/reflex/0.1/", "requires_dist": null, "requires_python": null, "summary": "A lightweight regex-based lexical scanner library.", "version": "0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            Reflex: A lightweight lexical scanner library.<br><br>Reflex supports regular expressions, rule actions, multiple scanner states,<br>tracking of line/column numbers, and customizable token classes.<br><br>Reflex is not a \"scanner generator\" in the sense of generating source code.<br>Instead, it generates a scanner object dynamically based on the set of<br>input rules sepecified. The rules themselves are ordinary python regular<br>expressions, combined with rule actions which are simply python functions.<br><br>Example use:<br><br>    # Create a scanner. The \"start\" parameter specifies the name of the<br>    # starting state. Note: The state argument can be any hashable python<br>    # type.<br>    scanner = reflex.scanner( \"start\" )<br>    <br>    # Add some rules.<br>    # The whitespace rule has no actions, so whitespace will be skipped<br>    scanner.rule( \"\\s+\" )<br>    <br>    # Rules for identifiers and numbers.<br>    TOKEN_IDENT = 1<br>    TOKEN_NUMBER = 2<br>    scanner.rule( \"[a-zA-Z_][\\w_]*\", token=TOKEN_IDENT )<br>    scanner.rule( \"0x[\\da-fA-F]+|\\d+\", token=TOKEN_NUMBER )<br>    <br>    # The \"string\" rule kicks us into the string state<br>    TOKEN_STRING = 3<br>    scanner.rule( \"\\\"\", tostate=\"string\" )<br><br>    # Define the string state. \"string_escape\" and \"string_chars\" are<br>    # action functions which handle the parsed charaxcters and escape<br>    # sequences and append them to a buffer. Once a quotation mark<br>    # is encountered, we set the token type to be TOKEN_STRING<br>    # and return to the start state.<br>    scanner.state( \"string\" )<br>    scanner.rule( \"\\\"\", tostate=\"start\", token=TOKEN_STRING )<br>    scanner.rule( \"\\\\\\\\.\", string_escape )<br>    scanner.rule( \"[^\\\"\\\\\\\\]+\", string_text )<br><br>Invoking the scanner: The scanner can be called as a function which<br>takes a reference to a stream (such as a file object) which iterates<br>over input lines. The \"context\" argument is for application use,<br>The result is an iterator which produces a series of tokens.<br>The same scanner can be used to parse multiple input files, by<br>creating a new stream for each file.<br><br>    # Return an instance of the scanner.<br>    token_iter = scanner( istream, context )<br><br>Getting the tokens. Here is a simple example of looping through the<br>input tokens. A real-world use would most likely involve comparing<br>vs. the type of the current token.<br><br>    # token.id is the token type (the same as the token= argument in the rule)<br>    # token.value is the actual characters that make up the token.<br>    # token.line is the line number on which the token was encountered.<br>    # token.pos is the column number of the first character of the token.<br>    for token in token_iter:<br>        print token.id, token.value, token.line, token.pos<br>     <br>Action functions are python functions which take a single argument, which<br>is the token stream instance.<br><br>    # Action function to handle striing text.<br>    # Appends the value of the current token to the string data<br>    def string_text( token_stream ):<br>        string_data += scanner.token.value<br>        <br>The token_stream object has a number of interesting and usable attributes:<br><br>    states:  dictionary of scanner states<br>    state:   the current state<br>    stream:  the input line stream<br>    context: the context pointer that was passed to the scanner<br>    token:   the current token<br>    line:    the line number of the current parse position<br>    pos:     the column number of the current parse position<br>    <br>Note - reflex currently has a limit of 99 rules for each state. (That is<br>the maximum number of capturing groups allowed in a python regular expression.)\n          </div>"}, "last_serial": 798743, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "41cc5a1aad0bc681a344cc7f226326b1", "sha256": "06b416026c8b13c640c288ebc3231552b5fe9a34e93e46849c3926fb4dc63f19"}, "downloads": -1, "filename": "reflex-0.1-py2.4.egg", "has_sig": false, "md5_digest": "41cc5a1aad0bc681a344cc7f226326b1", "packagetype": "bdist_egg", "python_version": "2.4", "requires_python": null, "size": 9627, "upload_time": "2005-12-26T00:52:47", "upload_time_iso_8601": "2005-12-26T00:52:47Z", "url": "https://files.pythonhosted.org/packages/07/6a/ca347fe694018b15c6ec9dc6920921991f89929effd0b68255e68dd4df30/reflex-0.1-py2.4.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "3aeac3459faf9dc2aa32707b099a2e0a", "sha256": "7fb7e090c938c0956e701d9d2541818f95ec99db23767e553a497e5652a06cb7"}, "downloads": -1, "filename": "reflex-0.1.tar.gz", "has_sig": false, "md5_digest": "3aeac3459faf9dc2aa32707b099a2e0a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4861, "upload_time": "2005-12-26T00:52:46", "upload_time_iso_8601": "2005-12-26T00:52:46Z", "url": "https://files.pythonhosted.org/packages/8e/e3/c325e16e335ab2760194c951d0a4289f6ed70f54529753a43618e24a02fa/reflex-0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "41cc5a1aad0bc681a344cc7f226326b1", "sha256": "06b416026c8b13c640c288ebc3231552b5fe9a34e93e46849c3926fb4dc63f19"}, "downloads": -1, "filename": "reflex-0.1-py2.4.egg", "has_sig": false, "md5_digest": "41cc5a1aad0bc681a344cc7f226326b1", "packagetype": "bdist_egg", "python_version": "2.4", "requires_python": null, "size": 9627, "upload_time": "2005-12-26T00:52:47", "upload_time_iso_8601": "2005-12-26T00:52:47Z", "url": "https://files.pythonhosted.org/packages/07/6a/ca347fe694018b15c6ec9dc6920921991f89929effd0b68255e68dd4df30/reflex-0.1-py2.4.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "3aeac3459faf9dc2aa32707b099a2e0a", "sha256": "7fb7e090c938c0956e701d9d2541818f95ec99db23767e553a497e5652a06cb7"}, "downloads": -1, "filename": "reflex-0.1.tar.gz", "has_sig": false, "md5_digest": "3aeac3459faf9dc2aa32707b099a2e0a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4861, "upload_time": "2005-12-26T00:52:46", "upload_time_iso_8601": "2005-12-26T00:52:46Z", "url": "https://files.pythonhosted.org/packages/8e/e3/c325e16e335ab2760194c951d0a4289f6ed70f54529753a43618e24a02fa/reflex-0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:05:24 2020"}