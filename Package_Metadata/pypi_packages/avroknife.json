{"info": {"author": "Mateusz Kobos, Pawel Szostek", "author_email": "mkobos@icm.edu.pl", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Environment :: Console", "Intended Audience :: Developers", "License :: OSI Approved :: Apache Software License", "Operating System :: POSIX :: Linux", "Programming Language :: Python", "Programming Language :: Python :: 2.7", "Topic :: Scientific/Engineering :: Information Analysis"], "description": "About\n=====\n\n|Build Status|\n\nThis project provides a command-line utility for browsing and simple\nmanipulation of Avro-based files.\n\n`Apache Avro <http://avro.apache.org/>`__ is a serialization format\ninvented to be a language-independent way of communication between\n`Hadoop <http://hadoop.apache.org/>`__ data processing tasks. Hadoop\ntasks produce output that, on an abstract level, can be regarded as a\nlist of objects of the same type. In practice, when using Avro format,\nthis list is represented in the file system as a directory containing\nmany Avro-formatted files where each file has the same schema. We call\nthis directory the **Avro data store**.\n\n``avroknife`` allows for browsing and simple manipulation of Avro data\nstores. It was inspired by Avro library's own tool called ``avro-tools``\nwhich is distributed with that library as a ``*.jar`` file. Apart from\ndifferences in particular functionalities, the main philosophical\ndifference between these two is that ``avroknife`` operates on whole\nAvro data store while ``avro-tools`` operates on individual Avro files.\n\nFeatures\n========\n\n-  Accesses Avro data stores placed in the local file system as well as\n   in the Hadoop Distributed File System (HDFS).\n\n   -  Note that in order to access HDFS, you need to have ``pydoop``\n      Python package installed.\n\n-  Provides the following execution modes (run ``avroknife -h`` for\n   details):\n\n   -  prints out schema of data store,\n   -  dumps data store as JSON,\n   -  dumps selected records from data store as a new data store,\n   -  dumps a field from selected records to file system or to stdout,\n   -  prints number of records inside a data store.\n\n-  Allows for simple selection of the records to be accessed based on\n   combination of the following constraints:\n\n   -  index range of the records,\n   -  limit set on number of returned records,\n   -  value of a field.\n\nUsage examples\n==============\n\nLet's assume that we have an Avro data store available as\n``/user/$USER/example_data_store`` directory in HDFS:\n\n::\n\n    $ hadoop fs -ls example_data_store\n    Found 4 items\n    -rw-r--r--   1 mafju supergroup        408 2014-09-18 11:36 /user/mafju/example_data_store/part-m-00000.avro\n    -rw-r--r--   1 mafju supergroup        449 2014-09-18 11:36 /user/mafju/example_data_store/part-m-00001.avro\n    -rw-r--r--   1 mafju supergroup        364 2014-09-18 11:36 /user/mafju/example_data_store/part-m-00002.avro\n    -rw-r--r--   1 mafju supergroup        429 2014-09-18 11:36 /user/mafju/example_data_store/part-m-00003.avro\n\nFirst, let's check the schema of the data store\n\n::\n\n    $ avroknife getschema example_data_store\n    {\n        \"namespace\": \"avroknife.test.data\", \n        \"type\": \"record\", \n        \"name\": \"User\", \n        \"fields\": [\n            {\n                \"type\": \"int\", \n                \"name\": \"position\"\n            }, \n            {\n                \"type\": \"string\", \n                \"name\": \"name\"\n            }, \n            {\n                \"type\": [\n                    \"int\", \n                    \"null\"\n                ], \n                \"name\": \"favorite_number\"\n            }, \n            {\n                \"type\": [\n                    \"string\", \n                    \"null\"\n                ], \n                \"name\": \"favorite_color\"\n            }, \n            {\n                \"type\": [\n                    \"bytes\", \n                    \"null\"\n                ], \n                \"name\": \"secret\"\n            }\n        ]\n    }\n\nThen, let's list all its records:\n\n::\n\n    $ avroknife tojson example_data_store\n    {\"position\": 0, \"name\": \"Alyssa\", \"favorite_number\": 256, \"favorite_color\": null, \"secret\": null}\n    {\"position\": 1, \"name\": \"Ben\", \"favorite_number\": 4, \"favorite_color\": \"red\", \"secret\": null}\n    {\"position\": 2, \"name\": \"Alyssa2\", \"favorite_number\": 512, \"favorite_color\": null, \"secret\": null}\n    {\"position\": 3, \"name\": \"Ben2\", \"favorite_number\": 8, \"favorite_color\": \"blue\", \"secret\": \"MDk4NzY1NDMyMQ==\"}\n    {\"position\": 4, \"name\": \"Ben3\", \"favorite_number\": 2, \"favorite_color\": \"green\", \"secret\": \"MTIzNDVhYmNk\"}\n    {\"position\": 5, \"name\": \"Alyssa3\", \"favorite_number\": 16, \"favorite_color\": null, \"secret\": null}\n    {\"position\": 6, \"name\": \"Mallet\", \"favorite_number\": null, \"favorite_color\": \"blue\", \"secret\": \"YXNkZmdm\"}\n    {\"position\": 7, \"name\": \"Mikel\", \"favorite_number\": null, \"favorite_color\": \"\", \"secret\": null}\n\nNow, let's select the records where the ``favorite_color`` attribute is\nequal ``blue`` and the index of the record is 5 of larger:\n\n::\n\n    $ avroknife tojson --select favorite_color=\"blue\" --index 5- example_data_store\n    {\"position\": 6, \"name\": \"Mallet\", \"favorite_number\": null, \"favorite_color\": \"blue\", \"secret\": \"YXNkZmdm\"}\n\nNext, let's extract value of the ``name`` attribute for all records\nwhere the ``favorite_color`` attribute is equal ``blue``:\n\n::\n\n    $ avroknife extract --value_field name --select favorite_color=\"blue\" example_data_store\n    Ben2\n    Mallet\n\nNote that if the data store was placed in the local file system, you\nwould have to prefix its path with ``local:``, e.g.\n\n::\n\n    $ avroknife tojson local:example_data_store\n\nThat's it. Run ``avroknife -h`` to find out more about other modes and\noptions of ``avroknife``.\n\nInstallation\n============\n\nThe project is available in the PyPI repository, so in oder to install\nit, you need to do\n\n::\n\n    sudo pip install avroknife\n\n**If you want to access HDFS**, ``pydoop`` Python library needs to be\ninstalled in the system. You can follow the description on `Pydoop's\ndocumentation page <http://crs4.github.io/pydoop/installation.html>`__\nin order to proceed with its installation. On Ubuntu 14.04, installing\nPydoop boils down to the following steps:\n\n-  Install Hadoop. If you want to install it on a single node in a\n   so-called pseudo-distributed mode, I recommend to use the Cloudera\n   Hadoop distribution. This can be done by following Cloudera's\n   `step-by-step\n   guide <http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/latest/CDH4-Quick-Start/cdh4qs_topic_3_2.html>`__.\n   Apart from the ``hadoop-0.20-conf-pseudo`` package from the Cloudera\n   repository that is mentioned in the guide, you also have to install\n   ``hadoop-client`` package.\n-  Make sure that Java JDK is installed correctly. This can be done by\n   executing the following steps.\n\n   -  Make sure that Java JDK is installed. This can be done by\n      installing ``openjdk-7-jdk`` package, i.e.,\n      ``sudo apt-get install openjdk-7-jdk``.\n   -  Make sure that the ``JAVA_HOME`` environment variable is set\n      properly. This can be done by adding line\n      ``export JAVA_HOME=\"/usr/lib/jvm/default-java\"`` in\n      ``/etc/profile.d/my_env_vars.sh`` file.\n\n-  Install the following Ubuntu packages: ``python-dev``,\n   ``libssl-dev``, i.e., ``sudo apt-get install python-dev libssl-dev``.\n-  Install the Pydoop package through ``pip``, i.e.,\n   ``sudo -i pip install pydoop``.\n\nTroubleshooting\n===============\n\nOn my system (Ubuntu 14.04) with my installation of Hadoop (CDH 4.7.0),\nthe following message was printed on stderr every time that I accessed\nHDFS:\n\n::\n\n    SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n    SLF4J: Defaulting to no-operation (NOP) logger implementation\n    SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details\n\nIt turned out that among the jars loaded by the ``pydoop`` library, the\n``slf4j`` jar was missing (the symbolic link to it was broken). In order\nto amend this problem I\n\n-  removed the broken symbolic link with\n   ``sudo rm /usr/lib/hadoop/client/slf4j-log4j12.jar``\n-  created a correct symbolic link with\n   ``sudo ln -s /usr/share/java/slf4j-log4j12.jar /usr/lib/hadoop/client/slf4j-log4j12.jar``\n   (you need to have the ``libslf4j-java`` package installed in order to\n   have the target jar file present).\n\nHistory\n=======\n\nThe initial version of ``avroknife`` was created in March 2013. The\nscript has been used by the developers of the Information Inference\nService in the\n`OpenAIREplus <http://cordis.europa.eu/project/rcn/100079_en.html>`__\nproject.\n\nLicense\n=======\n\nThe code is licensed under Apache License, Version 2.0\n\n.. |Build Status| image:: https://travis-ci.org/CeON/avroknife.png?branch=master\n   :target: https://travis-ci.org/CeON/avroknife", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/CeON/avroknife", "keywords": "Avro,browsing,manipulation", "license": "Apache License, Version 2.0", "maintainer": null, "maintainer_email": null, "name": "avroknife", "package_url": "https://pypi.org/project/avroknife/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/avroknife/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/CeON/avroknife"}, "release_url": "https://pypi.org/project/avroknife/1.0.5/", "requires_dist": null, "requires_python": null, "summary": "Utility for browsing and simple manipulation of Avro-based files", "version": "1.0.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"about\">\n<h2>About</h2>\n<p><a href=\"https://travis-ci.org/CeON/avroknife\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/dab6814939a7091b896f7b5fd5e18db500b71cc9/68747470733a2f2f7472617669732d63692e6f72672f43654f4e2f6176726f6b6e6966652e706e673f6272616e63683d6d6173746572\"></a></p>\n<p>This project provides a command-line utility for browsing and simple\nmanipulation of Avro-based files.</p>\n<p><a href=\"http://avro.apache.org/\" rel=\"nofollow\">Apache Avro</a> is a serialization format\ninvented to be a language-independent way of communication between\n<a href=\"http://hadoop.apache.org/\" rel=\"nofollow\">Hadoop</a> data processing tasks. Hadoop\ntasks produce output that, on an abstract level, can be regarded as a\nlist of objects of the same type. In practice, when using Avro format,\nthis list is represented in the file system as a directory containing\nmany Avro-formatted files where each file has the same schema. We call\nthis directory the <strong>Avro data store</strong>.</p>\n<p><tt>avroknife</tt> allows for browsing and simple manipulation of Avro data\nstores. It was inspired by Avro library\u2019s own tool called <tt><span class=\"pre\">avro-tools</span></tt>\nwhich is distributed with that library as a <tt>*.jar</tt> file. Apart from\ndifferences in particular functionalities, the main philosophical\ndifference between these two is that <tt>avroknife</tt> operates on whole\nAvro data store while <tt><span class=\"pre\">avro-tools</span></tt> operates on individual Avro files.</p>\n</div>\n<div id=\"features\">\n<h2>Features</h2>\n<ul>\n<li>Accesses Avro data stores placed in the local file system as well as\nin the Hadoop Distributed File System (HDFS).<ul>\n<li>Note that in order to access HDFS, you need to have <tt>pydoop</tt>\nPython package installed.</li>\n</ul>\n</li>\n<li>Provides the following execution modes (run <tt>avroknife <span class=\"pre\">-h</span></tt> for\ndetails):<ul>\n<li>prints out schema of data store,</li>\n<li>dumps data store as JSON,</li>\n<li>dumps selected records from data store as a new data store,</li>\n<li>dumps a field from selected records to file system or to stdout,</li>\n<li>prints number of records inside a data store.</li>\n</ul>\n</li>\n<li>Allows for simple selection of the records to be accessed based on\ncombination of the following constraints:<ul>\n<li>index range of the records,</li>\n<li>limit set on number of returned records,</li>\n<li>value of a field.</li>\n</ul>\n</li>\n</ul>\n</div>\n<div id=\"usage-examples\">\n<h2>Usage examples</h2>\n<p>Let\u2019s assume that we have an Avro data store available as\n<tt><span class=\"pre\">/user/$USER/example_data_store</span></tt> directory in HDFS:</p>\n<pre>$ hadoop fs -ls example_data_store\nFound 4 items\n-rw-r--r--   1 mafju supergroup        408 2014-09-18 11:36 /user/mafju/example_data_store/part-m-00000.avro\n-rw-r--r--   1 mafju supergroup        449 2014-09-18 11:36 /user/mafju/example_data_store/part-m-00001.avro\n-rw-r--r--   1 mafju supergroup        364 2014-09-18 11:36 /user/mafju/example_data_store/part-m-00002.avro\n-rw-r--r--   1 mafju supergroup        429 2014-09-18 11:36 /user/mafju/example_data_store/part-m-00003.avro\n</pre>\n<p>First, let\u2019s check the schema of the data store</p>\n<pre>$ avroknife getschema example_data_store\n{\n    \"namespace\": \"avroknife.test.data\",\n    \"type\": \"record\",\n    \"name\": \"User\",\n    \"fields\": [\n        {\n            \"type\": \"int\",\n            \"name\": \"position\"\n        },\n        {\n            \"type\": \"string\",\n            \"name\": \"name\"\n        },\n        {\n            \"type\": [\n                \"int\",\n                \"null\"\n            ],\n            \"name\": \"favorite_number\"\n        },\n        {\n            \"type\": [\n                \"string\",\n                \"null\"\n            ],\n            \"name\": \"favorite_color\"\n        },\n        {\n            \"type\": [\n                \"bytes\",\n                \"null\"\n            ],\n            \"name\": \"secret\"\n        }\n    ]\n}\n</pre>\n<p>Then, let\u2019s list all its records:</p>\n<pre>$ avroknife tojson example_data_store\n{\"position\": 0, \"name\": \"Alyssa\", \"favorite_number\": 256, \"favorite_color\": null, \"secret\": null}\n{\"position\": 1, \"name\": \"Ben\", \"favorite_number\": 4, \"favorite_color\": \"red\", \"secret\": null}\n{\"position\": 2, \"name\": \"Alyssa2\", \"favorite_number\": 512, \"favorite_color\": null, \"secret\": null}\n{\"position\": 3, \"name\": \"Ben2\", \"favorite_number\": 8, \"favorite_color\": \"blue\", \"secret\": \"MDk4NzY1NDMyMQ==\"}\n{\"position\": 4, \"name\": \"Ben3\", \"favorite_number\": 2, \"favorite_color\": \"green\", \"secret\": \"MTIzNDVhYmNk\"}\n{\"position\": 5, \"name\": \"Alyssa3\", \"favorite_number\": 16, \"favorite_color\": null, \"secret\": null}\n{\"position\": 6, \"name\": \"Mallet\", \"favorite_number\": null, \"favorite_color\": \"blue\", \"secret\": \"YXNkZmdm\"}\n{\"position\": 7, \"name\": \"Mikel\", \"favorite_number\": null, \"favorite_color\": \"\", \"secret\": null}\n</pre>\n<p>Now, let\u2019s select the records where the <tt>favorite_color</tt> attribute is\nequal <tt>blue</tt> and the index of the record is 5 of larger:</p>\n<pre>$ avroknife tojson --select favorite_color=\"blue\" --index 5- example_data_store\n{\"position\": 6, \"name\": \"Mallet\", \"favorite_number\": null, \"favorite_color\": \"blue\", \"secret\": \"YXNkZmdm\"}\n</pre>\n<p>Next, let\u2019s extract value of the <tt>name</tt> attribute for all records\nwhere the <tt>favorite_color</tt> attribute is equal <tt>blue</tt>:</p>\n<pre>$ avroknife extract --value_field name --select favorite_color=\"blue\" example_data_store\nBen2\nMallet\n</pre>\n<p>Note that if the data store was placed in the local file system, you\nwould have to prefix its path with <tt>local:</tt>, e.g.</p>\n<pre>$ avroknife tojson local:example_data_store\n</pre>\n<p>That\u2019s it. Run <tt>avroknife <span class=\"pre\">-h</span></tt> to find out more about other modes and\noptions of <tt>avroknife</tt>.</p>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>The project is available in the PyPI repository, so in oder to install\nit, you need to do</p>\n<pre>sudo pip install avroknife\n</pre>\n<p><strong>If you want to access HDFS</strong>, <tt>pydoop</tt> Python library needs to be\ninstalled in the system. You can follow the description on <a href=\"http://crs4.github.io/pydoop/installation.html\" rel=\"nofollow\">Pydoop\u2019s\ndocumentation page</a>\nin order to proceed with its installation. On Ubuntu 14.04, installing\nPydoop boils down to the following steps:</p>\n<ul>\n<li>Install Hadoop. If you want to install it on a single node in a\nso-called pseudo-distributed mode, I recommend to use the Cloudera\nHadoop distribution. This can be done by following Cloudera\u2019s\n<a href=\"http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/latest/CDH4-Quick-Start/cdh4qs_topic_3_2.html\" rel=\"nofollow\">step-by-step\nguide</a>.\nApart from the <tt><span class=\"pre\">hadoop-0.20-conf-pseudo</span></tt> package from the Cloudera\nrepository that is mentioned in the guide, you also have to install\n<tt><span class=\"pre\">hadoop-client</span></tt> package.</li>\n<li>Make sure that Java JDK is installed correctly. This can be done by\nexecuting the following steps.<ul>\n<li>Make sure that Java JDK is installed. This can be done by\ninstalling <tt><span class=\"pre\">openjdk-7-jdk</span></tt> package, i.e.,\n<tt>sudo <span class=\"pre\">apt-get</span> install <span class=\"pre\">openjdk-7-jdk</span></tt>.</li>\n<li>Make sure that the <tt>JAVA_HOME</tt> environment variable is set\nproperly. This can be done by adding line\n<tt>export <span class=\"pre\">JAVA_HOME=\"/usr/lib/jvm/default-java\"</span></tt> in\n<tt>/etc/profile.d/my_env_vars.sh</tt> file.</li>\n</ul>\n</li>\n<li>Install the following Ubuntu packages: <tt><span class=\"pre\">python-dev</span></tt>,\n<tt><span class=\"pre\">libssl-dev</span></tt>, i.e., <tt>sudo <span class=\"pre\">apt-get</span> install <span class=\"pre\">python-dev</span> <span class=\"pre\">libssl-dev</span></tt>.</li>\n<li>Install the Pydoop package through <tt>pip</tt>, i.e.,\n<tt>sudo <span class=\"pre\">-i</span> pip install pydoop</tt>.</li>\n</ul>\n</div>\n<div id=\"troubleshooting\">\n<h2>Troubleshooting</h2>\n<p>On my system (Ubuntu 14.04) with my installation of Hadoop (CDH 4.7.0),\nthe following message was printed on stderr every time that I accessed\nHDFS:</p>\n<pre>SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\nSLF4J: Defaulting to no-operation (NOP) logger implementation\nSLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details\n</pre>\n<p>It turned out that among the jars loaded by the <tt>pydoop</tt> library, the\n<tt>slf4j</tt> jar was missing (the symbolic link to it was broken). In order\nto amend this problem I</p>\n<ul>\n<li>removed the broken symbolic link with\n<tt>sudo rm <span class=\"pre\">/usr/lib/hadoop/client/slf4j-log4j12.jar</span></tt></li>\n<li>created a correct symbolic link with\n<tt>sudo ln <span class=\"pre\">-s</span> <span class=\"pre\">/usr/share/java/slf4j-log4j12.jar</span> <span class=\"pre\">/usr/lib/hadoop/client/slf4j-log4j12.jar</span></tt>\n(you need to have the <tt><span class=\"pre\">libslf4j-java</span></tt> package installed in order to\nhave the target jar file present).</li>\n</ul>\n</div>\n<div id=\"history\">\n<h2>History</h2>\n<p>The initial version of <tt>avroknife</tt> was created in March 2013. The\nscript has been used by the developers of the Information Inference\nService in the\n<a href=\"http://cordis.europa.eu/project/rcn/100079_en.html\" rel=\"nofollow\">OpenAIREplus</a>\nproject.</p>\n</div>\n<div id=\"license\">\n<h2>License</h2>\n<p>The code is licensed under Apache License, Version 2.0</p>\n</div>\n\n          </div>"}, "last_serial": 1715300, "releases": {"0.9": [{"comment_text": "", "digests": {"md5": "246c13d11ae4ed9949dfb209e052133c", "sha256": "c1c29d0737e41d9b505cc5c0d93718ba9b6d35b41cda30f80b888894e944791d"}, "downloads": -1, "filename": "avroknife-0.9-py2.7.egg", "has_sig": false, "md5_digest": "246c13d11ae4ed9949dfb209e052133c", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": null, "size": 55063, "upload_time": "2014-09-23T13:02:55", "upload_time_iso_8601": "2014-09-23T13:02:55.686334Z", "url": "https://files.pythonhosted.org/packages/bf/f9/9ab5b48e1423df5229da7a1f56e9083cd761e524ee2182ac3d923b63ce5f/avroknife-0.9-py2.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "5ee66f07263c0c67367ae4f325dc71f5", "sha256": "b118d9ce5821a87fabb090328614e9856b243fcc4fb3bedab388148ce1baa4a6"}, "downloads": -1, "filename": "avroknife-0.9-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "5ee66f07263c0c67367ae4f325dc71f5", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 34895, "upload_time": "2014-09-23T13:02:59", "upload_time_iso_8601": "2014-09-23T13:02:59.184606Z", "url": "https://files.pythonhosted.org/packages/30/2d/db6235c2e1b2a8af529c7e4090e239ca0aa77a5e1451aa16f9244f581c5c/avroknife-0.9-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "30c379aa24c5acf237bb2cb76c6b0e1f", "sha256": "4db851a17f518bd677ef4875e26704004669d2f9d24ffb5cf13ff8bd6c4a8a83"}, "downloads": -1, "filename": "avroknife-0.9.tar.gz", "has_sig": false, "md5_digest": "30c379aa24c5acf237bb2cb76c6b0e1f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28862, "upload_time": "2014-09-23T13:02:53", "upload_time_iso_8601": "2014-09-23T13:02:53.694455Z", "url": "https://files.pythonhosted.org/packages/6a/14/d52e49e43e6eec1c89daefc45feb4d3dfefe5245293fc207f0107fe106e7/avroknife-0.9.tar.gz", "yanked": false}], "0.9.3": [{"comment_text": "", "digests": {"md5": "2471641df113e48e0c526fa8e97fb47c", "sha256": "df052051614f492047440ec56aa8134b3ac7f775bf6cbd0506fcd783ac6d11a0"}, "downloads": -1, "filename": "avroknife-0.9.3-py2.7.egg", "has_sig": false, "md5_digest": "2471641df113e48e0c526fa8e97fb47c", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": null, "size": 54968, "upload_time": "2014-09-23T15:10:28", "upload_time_iso_8601": "2014-09-23T15:10:28.052796Z", "url": "https://files.pythonhosted.org/packages/b0/28/c4f4930fe1fc7c03feb99ec43df18542784878e5881d231e068533b6997e/avroknife-0.9.3-py2.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "aa000f9b61ce62120c99dee7284a08e9", "sha256": "c7e4a5097f4864e9d8e230ef9e4dc8374b05c59662a01b28b6984d7b678228a5"}, "downloads": -1, "filename": "avroknife-0.9.3-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "aa000f9b61ce62120c99dee7284a08e9", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 60198, "upload_time": "2014-09-23T15:10:31", "upload_time_iso_8601": "2014-09-23T15:10:31.199660Z", "url": "https://files.pythonhosted.org/packages/7c/14/cfdb0732d40ce0e61066be6079f237f7bb76d5e3b8ece4bb31beb51667fc/avroknife-0.9.3-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "be138ef22c34ea1eaadf65f939c8180b", "sha256": "56e71a9dbaa7650a10f7383e33713825a744193d7afa766fa0203ba751db65cf"}, "downloads": -1, "filename": "avroknife-0.9.3.tar.gz", "has_sig": false, "md5_digest": "be138ef22c34ea1eaadf65f939c8180b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 48597, "upload_time": "2014-09-23T15:10:24", "upload_time_iso_8601": "2014-09-23T15:10:24.570318Z", "url": "https://files.pythonhosted.org/packages/f4/41/e5d7b12cfa85175b75e375d109ee652d0dfc7355cfdbd09674ef8ff883e8/avroknife-0.9.3.tar.gz", "yanked": false}], "1.0": [{"comment_text": "", "digests": {"md5": "836e50e056c46d9336c026c8a5fac546", "sha256": "51b51911d9fd18104e7289fe98d45abc3729868c70113c3914a67975364c83df"}, "downloads": -1, "filename": "avroknife-1.0-py2.7.egg", "has_sig": false, "md5_digest": "836e50e056c46d9336c026c8a5fac546", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": null, "size": 60185, "upload_time": "2015-01-18T02:07:13", "upload_time_iso_8601": "2015-01-18T02:07:13.479342Z", "url": "https://files.pythonhosted.org/packages/47/1c/9f29eeec53e8884a1d8670580c19792ca93d1ca16885c147a797b02d656a/avroknife-1.0-py2.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "61d5b67b3340041766410d65c209d01e", "sha256": "75aabe9a9dabb4aa51b8e277c3d025a2f042b18af96171474ebe4ff330ffaa8c"}, "downloads": -1, "filename": "avroknife-1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "61d5b67b3340041766410d65c209d01e", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 65417, "upload_time": "2015-01-18T02:07:16", "upload_time_iso_8601": "2015-01-18T02:07:16.056596Z", "url": "https://files.pythonhosted.org/packages/a9/c9/0c8dadd56d5e048c391f30b60d012924fca7f4bb296ea639310ec719e5a5/avroknife-1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "94f6aae6b5dd137b9d6cd8c4bc033a87", "sha256": "3e177f76a3c02a5c7e5dff726354e04b8aa46df3fd0d4a07b95434c62db0a428"}, "downloads": -1, "filename": "avroknife-1.0.tar.gz", "has_sig": false, "md5_digest": "94f6aae6b5dd137b9d6cd8c4bc033a87", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 53022, "upload_time": "2015-01-18T02:07:08", "upload_time_iso_8601": "2015-01-18T02:07:08.259079Z", "url": "https://files.pythonhosted.org/packages/29/12/728acef8df7637718f14aa8980303d2f2cfdaf37aa476135732766d715cf/avroknife-1.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "d5430d0214d23e9d2109938a73a48a50", "sha256": "a0050e428bd6dcacaa4ac38f13de77cd9e321bdf97689244b28efe4c83071f25"}, "downloads": -1, "filename": "avroknife-1.0.1-py2.7.egg", "has_sig": false, "md5_digest": "d5430d0214d23e9d2109938a73a48a50", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": null, "size": 60197, "upload_time": "2015-01-18T02:19:04", "upload_time_iso_8601": "2015-01-18T02:19:04.683879Z", "url": "https://files.pythonhosted.org/packages/24/09/cce70a5bc0d1e0c2cd2ec31628771cd1412a4a5d6bb805d15284259ead70/avroknife-1.0.1-py2.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "8de0564203acb952a19d045e4914990d", "sha256": "09c7b8737fa233b635c208d852d43ea5da5adca791acef0896f9d6dff2894b65"}, "downloads": -1, "filename": "avroknife-1.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "8de0564203acb952a19d045e4914990d", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 65474, "upload_time": "2015-01-18T02:19:08", "upload_time_iso_8601": "2015-01-18T02:19:08.280880Z", "url": "https://files.pythonhosted.org/packages/40/1d/560cdc9f9ee5d69416c5fd19a2f7031331593f142e165eeb3a2a5d05f797/avroknife-1.0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "060ccead74a3bed69f9d64eab44aa7cb", "sha256": "e77384594f8785b2305f3abd39616499435352730b4574d81cb2aa7b2db69cb3"}, "downloads": -1, "filename": "avroknife-1.0.1.tar.gz", "has_sig": false, "md5_digest": "060ccead74a3bed69f9d64eab44aa7cb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 53039, "upload_time": "2015-01-18T02:19:02", "upload_time_iso_8601": "2015-01-18T02:19:02.101387Z", "url": "https://files.pythonhosted.org/packages/40/71/9084f0c73175600838dc5eae5c40a9cc649d801ff96ae894a0781daf67fa/avroknife-1.0.1.tar.gz", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "b72be03c46295fb99292a28ccefd3cf2", "sha256": "51ce59c449f98c6cfa33ddf1d0b832cdaa0732eb81fc7eca1ca140cfb5b7350f"}, "downloads": -1, "filename": "avroknife-1.0.3-py2.7.egg", "has_sig": false, "md5_digest": "b72be03c46295fb99292a28ccefd3cf2", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": null, "size": 59803, "upload_time": "2015-03-10T18:29:36", "upload_time_iso_8601": "2015-03-10T18:29:36.743226Z", "url": "https://files.pythonhosted.org/packages/2e/81/29831d42e0b5596a72fa86f2edd470cf3f288c2d49beb97aa4421bf1f078/avroknife-1.0.3-py2.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "bac621cdb7f3533e40be559b3a6197ee", "sha256": "c3bee33daf85546bbb82227b09f5db55ee1918d7bfd8465dc219ee0a7825883c"}, "downloads": -1, "filename": "avroknife-1.0.3-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "bac621cdb7f3533e40be559b3a6197ee", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 65196, "upload_time": "2015-03-10T18:29:40", "upload_time_iso_8601": "2015-03-10T18:29:40.594579Z", "url": "https://files.pythonhosted.org/packages/0b/0a/ccfedaa7b8814fbd35b2c1e0eb0aaedeab25f0e2ec75ac64a0c4d3605cc4/avroknife-1.0.3-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "380a48091f3f65df60e40dcab1739c55", "sha256": "2c94a4ce92d107a3054c0241ed15681e07da31b966656524ff8131c7a8d9e3f8"}, "downloads": -1, "filename": "avroknife-1.0.3.tar.gz", "has_sig": false, "md5_digest": "380a48091f3f65df60e40dcab1739c55", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 52903, "upload_time": "2015-03-10T18:29:33", "upload_time_iso_8601": "2015-03-10T18:29:33.400621Z", "url": "https://files.pythonhosted.org/packages/1b/e1/97bd5ffc666262d740bc75ecadb9da71c56172f7bb891167b5f02d5b425d/avroknife-1.0.3.tar.gz", "yanked": false}], "1.0.4": [{"comment_text": "", "digests": {"md5": "2a9d585f96bb1bdfb5a3e51b7396d0dc", "sha256": "a32a8ae10476ef39e30b3564f7532396c35273e9f44d6d7071e7149de4435b91"}, "downloads": -1, "filename": "avroknife-1.0.4-py2.7.egg", "has_sig": false, "md5_digest": "2a9d585f96bb1bdfb5a3e51b7396d0dc", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": null, "size": 65994, "upload_time": "2015-03-19T16:06:27", "upload_time_iso_8601": "2015-03-19T16:06:27.656502Z", "url": "https://files.pythonhosted.org/packages/8e/da/604c0aa44d93c02713362b24d8e46f7bcf9cfb2e2f4c139e93ef0dcf7f72/avroknife-1.0.4-py2.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "38b5854ff4b5a080debc273d15047059", "sha256": "504372d664d461911212193def29a10cf690039e54fb0ab91e16687066143641"}, "downloads": -1, "filename": "avroknife-1.0.4-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "38b5854ff4b5a080debc273d15047059", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 71498, "upload_time": "2015-03-19T16:06:30", "upload_time_iso_8601": "2015-03-19T16:06:30.914630Z", "url": "https://files.pythonhosted.org/packages/ff/4c/f0b77609b4c7c1c025f6b82de79bb1d56a8b26d59dc6cd1fe30fa2c8bdd2/avroknife-1.0.4-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "383e4ae32ddcfdf8cc4540f45177eb29", "sha256": "b0ed1c011c89322c81fa2d6946c90c718fc5aef7def6a4dff932a878070df50c"}, "downloads": -1, "filename": "avroknife-1.0.4.tar.gz", "has_sig": false, "md5_digest": "383e4ae32ddcfdf8cc4540f45177eb29", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 59184, "upload_time": "2015-03-19T16:06:24", "upload_time_iso_8601": "2015-03-19T16:06:24.333334Z", "url": "https://files.pythonhosted.org/packages/bd/4e/f6ff348d78821d18926b4905045fcb976181e6ff45edcc9d2bb9a4acb784/avroknife-1.0.4.tar.gz", "yanked": false}], "1.0.5": [{"comment_text": "", "digests": {"md5": "fec49851d6eb3311cd54fb7d982456db", "sha256": "689d9fdc236a47e268d74171fb387a8401a77b1f44328708c44ec30c77a08a41"}, "downloads": -1, "filename": "avroknife-1.0.5-py2.7.egg", "has_sig": false, "md5_digest": "fec49851d6eb3311cd54fb7d982456db", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": null, "size": 60436, "upload_time": "2015-09-09T13:12:41", "upload_time_iso_8601": "2015-09-09T13:12:41.597369Z", "url": "https://files.pythonhosted.org/packages/b2/56/07583b294fc6333392367a58d8653756309bb8f9d2058475abfcfe7150a0/avroknife-1.0.5-py2.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "1c74decfd4acdb5923c3fdec0fc9e392", "sha256": "bd3c2390c19a32e1b9912913e8254f14b3917731cd2fef48f46fd84e5576fde6"}, "downloads": -1, "filename": "avroknife-1.0.5-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "1c74decfd4acdb5923c3fdec0fc9e392", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 65853, "upload_time": "2015-09-09T13:12:48", "upload_time_iso_8601": "2015-09-09T13:12:48.159315Z", "url": "https://files.pythonhosted.org/packages/f2/3c/ffb2b8243ab04d6a6e0ac93ecf61bbe250aa665368c4f1880466ab268887/avroknife-1.0.5-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3f018c55d40836bd32265ed8de6a62f3", "sha256": "80f05e3e553218c87cdee0111258e9eda1ae5d1d55bd81aa44f09bbdda386244"}, "downloads": -1, "filename": "avroknife-1.0.5.tar.gz", "has_sig": false, "md5_digest": "3f018c55d40836bd32265ed8de6a62f3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 54900, "upload_time": "2015-09-09T13:12:36", "upload_time_iso_8601": "2015-09-09T13:12:36.331895Z", "url": "https://files.pythonhosted.org/packages/f8/c7/8242b46854adfbb1150d13d7823102960bc311bee9b82a591bace0c7de48/avroknife-1.0.5.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "fec49851d6eb3311cd54fb7d982456db", "sha256": "689d9fdc236a47e268d74171fb387a8401a77b1f44328708c44ec30c77a08a41"}, "downloads": -1, "filename": "avroknife-1.0.5-py2.7.egg", "has_sig": false, "md5_digest": "fec49851d6eb3311cd54fb7d982456db", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": null, "size": 60436, "upload_time": "2015-09-09T13:12:41", "upload_time_iso_8601": "2015-09-09T13:12:41.597369Z", "url": "https://files.pythonhosted.org/packages/b2/56/07583b294fc6333392367a58d8653756309bb8f9d2058475abfcfe7150a0/avroknife-1.0.5-py2.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "1c74decfd4acdb5923c3fdec0fc9e392", "sha256": "bd3c2390c19a32e1b9912913e8254f14b3917731cd2fef48f46fd84e5576fde6"}, "downloads": -1, "filename": "avroknife-1.0.5-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "1c74decfd4acdb5923c3fdec0fc9e392", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 65853, "upload_time": "2015-09-09T13:12:48", "upload_time_iso_8601": "2015-09-09T13:12:48.159315Z", "url": "https://files.pythonhosted.org/packages/f2/3c/ffb2b8243ab04d6a6e0ac93ecf61bbe250aa665368c4f1880466ab268887/avroknife-1.0.5-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3f018c55d40836bd32265ed8de6a62f3", "sha256": "80f05e3e553218c87cdee0111258e9eda1ae5d1d55bd81aa44f09bbdda386244"}, "downloads": -1, "filename": "avroknife-1.0.5.tar.gz", "has_sig": false, "md5_digest": "3f018c55d40836bd32265ed8de6a62f3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 54900, "upload_time": "2015-09-09T13:12:36", "upload_time_iso_8601": "2015-09-09T13:12:36.331895Z", "url": "https://files.pythonhosted.org/packages/f8/c7/8242b46854adfbb1150d13d7823102960bc311bee9b82a591bace0c7de48/avroknife-1.0.5.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:16:02 2020"}