{"info": {"author": "Monte M. Goode", "author_email": "MMGoode@lbl.gov", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Environment :: Console", "Intended Audience :: Developers", "Intended Audience :: Telecommunications Industry", "License :: OSI Approved :: BSD License", "Operating System :: POSIX", "Programming Language :: Python :: 2", "Topic :: Internet", "Topic :: Software Development :: Libraries", "Topic :: System :: Networking"], "description": "*****************************************************************\nClient libraries and programs for esmond: ESnet Monitoring Daemon\n*****************************************************************\n\n==================================\nClient programs for perfSONAR data\n==================================\n\nesmond-ps-get-endpoints\n=======================\n\nA discovery tool to quickly see what tests have been stored in an esmond\nperfSONAR archive. Give a list of tests in MA with the following sample\ninformation:\n\n::\n\n    source: anl-owamp.es.net\n    destination: lsvn-owamp.es.net\n    measurement_agent: anl-owamp.es.net\n    tool_name: bwctl/tracepath,traceroute\n    event_type: packet-trace, failures, path-mtu\n\n\nesmond-ps-get-metadata\n======================\n\nSimilar to get-endpoints, but this will fetch the actual metadata test data\nfrom an esmond perfSONAR archive.  By default it will show the measurements\nthat are common to all tests:\n\n::\n\n    source\n    destination\n    measurement_agent\n    input_source\n    input_destination\n    tool_name\n\nIncluding the --metadata-extended will also show the per-test measurements.\nThis option can not be used with the CSV output option.\n\nSample default output:\n\n::\n\n    source: perfsonar-latency-v4.esc.qmul.ac.uk\n    destination: anl-owamp.es.net\n    measurement_agent: anl-owamp.es.net\n    input_source: perfsonar-latency.esc.qmul.ac.uk\n    input_destination: anl-owamp.es.net\n    tool_name: powstream\n\n\nSample output with the --metadata-extended flag:\n\n::\n\n    source: perfsonar-latency-v4.esc.qmul.ac.uk\n    destination: anl-owamp.es.net\n    measurement_agent: anl-owamp.es.net\n    input_source: perfsonar-latency.esc.qmul.ac.uk\n    input_destination: anl-owamp.es.net\n    tool_name: powstream\n    ip_transport_protocol: udp\n    sample_bucket_width: 0.0001\n    sample_size: 600\n    subject_type: point-to-point\n    time_duration: 60\n    time_interval: 0\n    time_probe_interval: 0.1\n\n\nesmond-ps-get\n=============\n\nTool to pull smaller, more focused sets of data from a perfSONAR MA. This\nrequires a source/dest pair as well as a specific event type. Intended to\nbe more of a \"quick look\" at some data.  To gather more/larger amounts\nof data, esmond-ps-get-bulk is intended for that.\n\nesmond-ps-get-bulk\n==================\n\nTool to pull non-trivial amounts of data from a perfSONAR esmond archive.\n\nIterates through the metadata matching the user query and makes incremental\ndata requests from the archive so as not to overwhelm the data store. When\nall of the data for a given event type associated with a given metadata\nhas been gathered, it will be written to disc in either json or csv format,\nwith the format:\n\n::\n\n    <source>_<dest>_<event_type>_<start_time>_<end_time>.csv|.json\n\n\nSo one would end up with a set of output files that look like this:\n\n::\n\n    perfsonar.ascr.doe.gov_anl-owamp.es.net_failures_2015-03-15_2015-04-02.csv\n    perfsonar.ascr.doe.gov_anl-owamp.es.net_histogram-owdelay_2015-03-15_2015-04-02.csv\n    perfsonar.ascr.doe.gov_anl-owamp.es.net_histogram-ttl_2015-03-15_2015-04-02.csv\n    perfsonar.ascr.doe.gov_anl-owamp.es.net_packet-count-lost_2015-03-15_2015-04-02.csv\n    perfsonar.ascr.doe.gov_anl-owamp.es.net_packet-count-sent_2015-03-15_2015-04-02.csv\n    perfsonar.ascr.doe.gov_anl-owamp.es.net_packet-duplicates_2015-03-15_2015-04-02.csv\n    perfsonar.ascr.doe.gov_anl-owamp.es.net_packet-loss-rate_2015-03-15_2015-04-02.csv\n    perfsonar.ascr.doe.gov_anl-owamp.es.net_time-error-estimates_2015-03-15_2015-04-02.csv\n\n\nAfter the file for the metadata/event-type has been written, it will continue\nto the next event-type or metadata as appropriate.  The \"human readable\"\noutput format is not available in this program.\n\nWhile designed to not murder an MA with massive data queries, this command can\nreturn a lot of data, so it is recommended to limit the scope of your query\nby source, dest, event-type, etc.\n\nGeneral esmond-ps perfSONAR client usage\n========================================\n\nCore and/or required args\n-------------------------\n\nThese args are common to all clients.  See the --help flag to get a\ncomplete list of options.\n\n--url\n~~~~~\n\nRequired on all programs. Just the base protocol://host:port is required. When\nquerying a default perfSONAR install, it is not necessary to include the URI\nas well.  For example given a MA access URL of:\n\n::\n\n    http://albq-owamp-v6.es.net:8085/esmond/perfsonar/archive\n\n\nIt is only necessary to provide:\n\n::\n\n    --url http://albq-owamp-v6.es.net:8085\n\n--src and --dest\n~~~~~~~~~~~~~~~~\n\nSource and destination for the tests.  Both are required for some of the\nclients.  This is input as raw IP addresses.\n\n--start-time and --end-time\n~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nIf these args are not included, it will default to grabbing data from the\nprevious 24 hours.  Arg input is parsed by the Python dateutil library\nwhich will preform pretty intelligent guesses about incoming date formats.\nIt will understand structured things like ISO datetime formats, and more\norganic ones like \"January 1 2015\" - if a time is not given, will default\n00:00 am, etc.\n\nSee: https://dateutil.readthedocs.org/en/latest/examples.html#parse-examples\nTo see the variety of date formats that it will accept.\n\n--event-type\n~~~~~~~~~~~~\n\nRequires a valid measurement event type.  The command line arg --list-events\ncan be used to give a list of valid event types.\n\nSometimes required.\n\nAdditional filtering args\n-------------------------\n\nThere are additional args that can be used to filter results as well:\n\n::\n\n    --agent\n    --tool\n    --summary-type\n    --summary-window\n\n\nThese should be fairly self-explanatory.\n\n--filter\n~~~~~~~~\n\nAn additional power user filter that takes the format:\n\n::\n\n    --filter key:value\n\n\nThis will add filters to the query string that goes to the MA. This\noption can be used more than once to add multiple filters to the\nquery string, invalid filters will be ignored.\n\nOutput\n------\n\n--output-format\n~~~~~~~~~~~~~~~\n\nSelect the desired output format from the choices 'human,' 'json' and\n'csv.' Default is human readable for viewing in a terminal.  The human\nand csv options are not allowed in all circumstances.\n\n--output-directory\n~~~~~~~~~~~~~~~~~~\n\nRequired by esmond-ps-get-bulk - specifies a directory to write output\nfiles to.  Will default to the current working directory.\n\n--ip\n~~~~\n\nBy default in the output, IP addresses (source, dest, agent, etc) will be\nconverted to a human readable fully qualified domain name. Using the -ip\nflag will stop this conversion and display all hostnames as raw IP addresses.\n\nExample perfSONAR command line client usage\n===========================================\n\nesmond-ps-get-endpoints examples\n--------------------------------\n\nGet a list of all tests over the last 24 hours available in a given MA, show\nsrc/dest as raw ip addresses:\n\n::\n\n    esmond-ps-get-endpoints --url http://nettest.lbl.gov/ --ip\n\nFind all the powstream test data in a given MA since the beginning of the year:\n\n::\n\n    esmond-ps-get-endpoints --url http://nettest.lbl.gov/ --ip --start-time 'January 1' --tool powstream\n\nesmond-ps-get-metadata examples\n-------------------------------\n\nShow all test metadata for a given destination over the last 24 hours,\ndisplayed in CSV format:\n\n::\n\n    esmond-ps-get-metadata --url http://nettest.lbl.gov/ --dest 198.129.254.62 --output-format csv\n\nShow more detailed metadata information from an MA for all bwctl/iperf3\ntests involving a particular source since the beginning of the year,\nshowing extended test metadata like test duration, interval, etc\nas a list of json objects:\n\n::\n\n    esmond-ps-get-metadata --url http://nettest.lbl.gov/ --tool bwctl/iperf3 --src 198.124.238.130 --metadata-extended --output-format json --start-time 'Jan 1'\n\nesmond-ps-get examples\n----------------------\n\nRetrieve the past 24 hours of packet trace data for a src/dest pair:\n\n::\n\n    esmond-ps-get --url http://nettest.lbl.gov/ --src  131.243.24.11 --dest 198.129.254.62 --event-type packet-trace\n\nGet throughput data starting at the beginning of the month (presuming the\nmonth is April) for a src/dest pair:\n\n::\n\n    esmond-ps-get --url http://nettest.lbl.gov/ --src  131.243.24.11 --dest 198.129.254.114 --event-type throughput --start-time 'April 1'\n\nesmond-ps-get-bulk examples\n---------------------------\n\nPull all failures event-type information from an MA since the beginning\nof the year and write out to current working directory as a set of json\nfiles:\n\n::\n\n    esmond-ps-get-bulk --url http://anl-owamp.es.net:8085  --event-type failures --start-time 'January 1' --output-format json\n\n\nPull all data associated with a given source from the past 24 hours and write\nto a custom directory in CSV format:\n\n::\n\n    esmond-ps-get-bulk --url http://anl-owamp.es.net:8085  --src 192.73.213.28 --output-format csv -D ~/Desktop/tmp\n\n\nPull data for all event types measured by the powstream tool since the start\nof March and write to a custom directory in json format:\n\n::\n\n    esmond-ps-get-bulk --url http://anl-owamp.es.net:8085  --tool powstream --start-time 'March 1' --output-format json -D ~/Desktop/tmp\n\n\nPull all the data in an MA for the past 24 hours and output to current working\ndirectory in json format:\n\n::\n\n    esmond-ps-get-bulk --url http://nettest.lbl.gov/ --output-format json\n\n======================================\nEsmond perfSONAR data loading programs\n======================================\n\nThere are also client programs for writing data to an MA. This requires that the\nuser have write access to the esmond instance.\n\nCore and/or required args\n=========================\n\nThe following args are required/generally needed by all programs that write\ndata to an MA.\n\n--user and --key\n----------------\n\nBoth of these args are required. It is the username and api key string that\nwas generated on the MA to allow access to it.\n\n--url\n-----\n\nThe url of the MA. Format http://example.com:80 where http or https can be the\nprefix. Just host and port information, no uri information. Defaults to\nhttp://localhost:8080.\n\n--script_alias\n--------------\n\nUsed when the REST API has been deployed under Apache using a ScriptAlias\ndirective/prefix. This would commonly be set to 'esmond' since the canned\nCentOS deployments use script alias of /esmond to allow other things to\nrun on the webserver (ie: so the REST API is not the root of the webserver).\nThe default value is '/' - which will not perform any prefixing.\n\nesmond-ps-load-gridftp\n======================\n\nUtility to parse and load GridFTP data.\n\nThis will read the default gridftp logs, process the \"Transfer stats\" entries,\nand upload the results to the pS esmond backend as metadata and either\nthroughput or failures event types. This has been expanded (using the --json\nflag) to read the new json formatted gridftp logs that contain additional\nevent types like retransmits, iostat, etc.\n\nThe basic use case would that this script be run from cron periodically\nover the day to parse and load data from the gridftp logs into an esmond\nbackend.  The scanning code will write out the contents of the record that\nwas last loaded as a python pickle file to disc.  This state file is used\nto pick up from the point the last processing pass got to.\n\nBasic usage: the following arguments are required for baseline operation:\n\n::\n\n    esmond-ps-load-gridftp -f ~/Desktop/gridftp.log -U http://localhost:8000 -u mgoode -k api_key_for_mgoode\n\nIn addition to the flags outlined above, required args\n------------------------------------------------------\n\n--file\n~~~~~~\n\nThe path to the logfile to process.  The code will normalize the path,\nso relative paths are fine.  No default.\n\nCommonly used args\n------------------\n\n--json\n~~~~~~\n\nSpecifies that the log indicate by the --file flag is the json-formatted\nGridFTP files.\n\n--pickle\n~~~~~~~~\n\nThe path to the pickle file the scanning code uses to store the \"state\"\nof the last record that has been processed.  Code uses this to know where\nto pick up on subsequent scans.  This defaults to ./load_grid_ftp.pickle\nor ./load_grid_ftp.json.pickle as appropriate - will probably want to\nchange this to a fully qualified path somewhere.\n\n--dont_write\n~~~~~~~~~~~~\n\nSuppresses writing the pickle state file out when the file has been scanned.\nThis would be used when manually/etc processing one or more log files where\nit is desired to just parse the contents of an entire static (ie: no longer\nbeing written to) file.  Defaults to False - use this flag to suppress\nwriting the state file.\n\n--log_dir\n~~~~~~~~~\n\nCan be used to specify a directory to write a log from the program to.\nIf this is not set (the default), then log output will go to stdout.\n\nOptional content selection args\n-------------------------------\n\nThe gridftp logs contain information on the user, the file being sent and\nthe volume being written to.  Since these might be considered to be sensitive\ndata, this information is not sent to the backend by default.  The following\nflags can be set to send that information if desired:\n\n::\n\n    -F (--file_attr): send gridftp-file/value of FILE\n    -N (--name_attr): send gridftp-user/value of USER (name)\n    -V (--volume_attr): send gridftp-volume/value of VOLUME\n\nOther/development args\n----------------------\n\n--single\n~~~~~~~~\n\nWill process a single value starting at the last record sent and stop.\nThis is mostly used for development/testing to \"step through\" a file\nrecord by record.  It will set the pickle state file to the single\nrecord sent before exiting.\n\nRunning from cron and dealing with rotated logs\n-----------------------------------------------\n\nWhen running from cron the script should be run with the required arguments\nenumerated above and set the --pickle arg to a fully qualified path, and\nthe --file arg should point to the logfile.  It can be run at whatever\nfrequency the user desires as the code will pick up from the last record\nthat was processed.  When running from cron, the --log_dir arg should\nbe set so the logging output is written to a file rather than sent to\nstdout.\n\nLog rotation interfere with this if the code has not finished scanning\na log before it is rotated and renamed.  If the code is run on the \"fresh\"\nlog, it will not find the last record that was processed.   To deal with\nthis, this script should also be kicked off using the \"prerotate\" hook\nthat logrotated provides.\n\nWhen running this as a prerotate job, the -D (--delete_state) flag should\nalso be used.  This will delete the pickle state file when the scan is\ndone with the log before it is rotated.  The state file is deleted so that\nwhen the next cron job runs on the new \"fresh\" log, it will just start\nscaning from the beginning and not try to search for a record that it\nwon't find.\n\nAlternately if the user doesn't need the data to be periodically loaded,\none could opt to exclusively run this as a logrotated/prerotate job such\nthat the entire log is processed in one throw before it is rotated.  In that\ncase the --dont_write flag should be used.\n\nesmond-ps-pipe\n==============\n\nUtility to take json-formatted output from bwctl (--parsable flag) and\nload the data into an esmond MA.\n\nCurrently supported tool types:\n\n* iperf3\n\nUsage\n-----\n\nPrimarily relies on the required command line args (--user, --key, etc)\noutlined above and piped input from the bwctl command:\n\n::\n\n    bwctl -c lbl-pt1.es.net -s llnl-pt1.es.net -T iperf3 --parsable --verbose |& esmond-ps-pipe --user mgoode --key api_key_for_mgoode\n\nThe primary thing (other than using a -T <tool> that is supported) is that bwctl\n**must** be run with both the --parsable flag (which generates the json output)\n**and also** the --verbose flag. esmond-ps-pipe pulls important metadata from\nthe --verbose output, and uses it to identify the json part of the output.\n\nIf the program is unable to extract the necessary metadata and a valid json\npayload from the piped input, it will log a fatal error and exit.\n\nShell redirection\n-----------------\nNote the \"**|&**\" that redirects the output from bwctl to esmond-ps-pipe - both stdout and stderr need to be piped to esmond-ps-pipe. That should work on Csh and current versions of Bash. This may vary from shell to shell - for example, older versions of Bash might need to use \"**2>&1 |**\" or something similar. The short of it is, the shell-specific way to redirect both stdout and stderr from bwctl is necessary.\n\nIf an error that looks something like this is generated:\n\n::\n\n    ts=2015-10-20 11:37:24,881 event=id_and_extract.error id=1445366244 could not extract tool_name\n    ts=2015-10-20 11:37:24,881 event=id_and_extract.error id=1445366244 could not extract input_source\n    ts=2015-10-20 11:37:24,881 event=id_and_extract.error id=1445366244 could not extract input_destination\n    ts=2015-10-20 11:37:24,881 event=main.fatal id=1445366244 could not extract metadata and valid json from input\n    ts=2015-10-20 11:37:24,882 event=main.fatal id=1445366244 exiting\n\nIt is likely that the redirection is not being executed properly because tool_name, input_source and input_destination are all read from the bwctl headers that are being written to stderr.\n\nOptional args\n-------------\n\n--log_dir\n~~~~~~~~~\n\nLike esmond-ps-load-gridftp, this takes a --log_dir arg which specifies the\ndirectory that logging output should be written to. If not specified, logging\noutput will got to stdout.\n\nEvent types\n-----------\n\niperf3\n~~~~~~\n\nThe following event types are extracted (as appropriate RE: TCP, UDP, streams,\netc) from the iperf3 data:\n\n::\n\n    throughput\n    throughput-subintervals\n    packet-retransmits-subintervals\n    streams-packet-retransmits\n    streams-packet-retransmits-subintervals\n    streams-throughput\n    streams-throughput-subintervals\n    packet-retransmits\n    packet-count-lost\n    packet-count-sent\n    packet-loss-rate\n\n\n\n=======================================\nAPI Client Libraries for perfSONAR data\n=======================================\n\nThe pS data can be queried, retrieved and posted to the esmond/cassandra backend\nvia a REST interface.  This is streamlined by the following libraries::\n\n    esmond.api.client.perfsonar.query\n    esmond.api.client.perfsonar.post\n\nInitializing the query interface\n================================\n\nThe query libarary has two main \"top level\" classes: ApiFilters and ApiConnect.\nApiFilters lets the user, through a series of properties, set the primary query\ncriteria like time ranges, source, destination, etc.  The following criteria\nproperties can be set::\n\n    destination\n    input_destination\n    input_source\n    measurement_agent\n    source\n    tool_name\n    time\n    time_start\n    time_end\n    time_range\n    verbose (for debugging/extended output)\n\nAfter the query criteria have been set in the ApiFilters object, that is passed\nto the ApiConnect object as one of the args.\n\nThe ApiConnect object takes the url of the REST interface as an argument, along\nwith the filters object, and optional username and api_key arguments if the user\nis accessing restricted functionality of the REST interface (non-public data,\ngetting around throttling restrictions, etc).\n\nA complete example of setting this up::\n\n    from esmond.api.client.perfsonar.query import ApiConnect, ApiFilters\n\n    filters = ApiFilters()\n\n    filters.verbose = True\n    filters.time_start = time.time() - 3600\n    filters.time_end = time.time()\n    filters.source = '198.129.254.30'\n    filters.tool_name = 'bwctl/iperf3'\n\n    conn = ApiConnect('http://localhost:8000/', filters)\n\nNOTE: the default perfSONAR/esmond deployments use a WSGIScriptAlias of /esmond\nprefixing the URI - this is set in Apache.  The client libraries default to\nusing this.  But if one is doing development against the django runserver dev\nserver, or if this has been set up differently, then the optional kwarg\n\"script_alias\" will need to be set as well.  Against the dev server, it can\nbe set to script_alias=None since the Apache directive is not in place.\n\nRetrieving the data\n===================\n\nThe basic design of the returned data is a hierarchy of encapsulation objects\nthat return additioanl objects objects, etc.  All of the returned objects\nhave informative __repr__ methods defined, that might help when doing\ninitial development.\n\nThe top level call to the ApiConnect object is get_metadata().  This is an\niterator that will return a series of Metadata objects matching the criteria\ngiven in the ApiFilters object.  At the top level, the Metadata object exposes\na series of properties giving additional information about the returned\nmetadata.  Example of this::\n\n    for md in conn.get_metadata():\n        print md # debug info in __repr__\n        print md.destination\n        print md.ip_packet_interval\n        ...\n\nThe following top-level properties are exposed by the Metadata object::\n\n    destination\n    event_types (a list of event type names - more on this)\n    input_destination\n    input_source\n    ip_packet_interval\n    measurement_agent\n    metadata_key\n    sample_bucket_width\n    source\n    subject_type\n    time_duration\n    tool_name\n    uri\n\nThe next in the data object hierarchy is fetching the event types that are\nassociated with the metadata.  This can be done by either using an interator\nto access all of the event types::\n\n    for et in md.get_all_event_types():\n        print et.event_type\n        ...\n\nor fetching a single one by name::\n\n    et = md.get_event_type('histogram-owdelay')\n\nThe top-level property \"event_types\" will return a list of valid event types\nthat can be passed as the argument to get_event_type.\n\nThe EventType objects expose the following top-level properties::\n\n    base_uri\n    event_type\n    data_type\n    summaries (a list of associated summaries - more on this)\n\nThe the actual underlying data are retrieved from the EventType objects by a call to the get_data() method, which returns a DataPayload object::\n\n    dpay = et.get_data()\n\nThe DataPayload object expose the following top-level properties::\n\n    data_type\n    data\n\nThe data_type property returns the underlying data_type in the payload, and\nthe data property returns a list of DataPoint or DataHistogram objects as\nis appropriate.  Both the DataPoint and DataHistogram objects expose the\nfollowing properties::\n\n    ts (measurement timestamp as a UTC python datetime object)\n    val (the measurement or hisogram dict)\n    ts_epoch (the ts object expressed as UNIX time)\n\nPutting it all together, to iterate throught all of the returned data::\n\n    for et in md.get_all_event_types():\n        dpay = et.get_data()\n        print dpay.data_type\n        for dp in dpay.data:\n            print dp.ts, dp.val\n\nSome event types have aggregated summaries associated with them.  Retrieving\nthe summaries from an EventType object is very similar to pulling event types\nfrom a Metadata object.  The following properties/methods are analogous to the\nones that exist in the Metadata object::\n\n    summaries\n\nThis returns a list of two-element tuples: (summary-type, summary-window). The\nwindow is the time duration of the aggregation rollups.\n\nThe summary data can be retrieved by either using an iterator::\n\n    for summ in et.get_all_summaries():\n        ...\n\nOr a single type can be fetched::\n\n    summ = et.get_summary(summary-type, summary-window)\n\nLike with the EventType object, the underlying data can be retrieved by\ncalling get_data() to get a DataPayload object and call the data property\non that to get a list of DataPoint objects.\n\nWriting data to pS esmond/backend\n=================================\n\nThe REST interface also supports adding metadata, event types and data if\nthe user is properly authenticated using a username and api_key that has\nbeen generated by the admin of the system.  The following are presented as\nan ordered process, but any single step of this can be done independently.\nThe functionality for POSTing date can be found in the following libarary::\n\n    from esmond.api.client.perfsonar.post import MetadataPost, \\\n        EventTypePost, EventTypeBulkPost\n\nFirst one needs to create a new metadata entry - this is accomplished\nusing the MetadataPost object.  It is initialized with a REST url,\nusername, api_key and a series of associated data - most required, a few\noptional (the commented key/val pairs in the arg dict are optional)::\n\n    args = {\n        \"subject_type\": \"point-to-point\",\n        \"source\": \"10.10.0.1\",\n        \"destination\": \"10.10.0.2\",\n        \"tool_name\": \"bwctl/iperf3\",\n        \"measurement_agent\": \"10.10.0.2\",\n        \"input_source\": \"host1\",\n        \"input_destination\": \"host2\",\n        # \"time_duration\": 30,\n        # \"ip_transport_protocol\": \"tcp\"\n    }\n\n    mp = MetadataPost('http://localhost:8000/', username='pS_user',\n        api_key='api-key-generated-by-auth-database', **args)\n\nThis will create the basic data associated with this metadata.  Then add\nthe event types and summaries associated with this metadata and post the\nnew information::\n\n    mp.add_event_type('throughput')\n    mp.add_event_type('time-error-estimates')\n    mp.add_event_type('histogram-ttl')\n    mp.add_event_type('packet-loss-rate')\n    mp.add_summary_type('packet-count-sent', 'aggregation', [3600, 86400])\n\n    new_meta = mp.post_metadata()\n\nThis writes the metadata information to the back end and returns the\nassociated \"read only\" Metadata object that was covered in the previous\nsection.  This is mostly necessary to get the newly generated metadata_key\nproperty, it will be needed for other operations.\n\nNext data can be added to the assocaited event types - the process is similar\nfor both numeric and histogram data.  Intialize an EventTypePost object\nsimilarly to the MetadataPost object, but also using the appropriate\nmetadata_key and event_type to add the data to::\n\n    et = EventTypePost('http://localhost:8000/', username='pS_user',\n        api_key='api-key-generated-by-auth-database',\n        metadata_key=new_meta.metadata_key,\n        event_type='throughput')\n\nDiscrete data points can be added the process is similar for both numeric\ndata and histogram data - first arg is an integer timestamp in seconds and\nthe second is the value - and post it::\n\n    et.add_data_point(1397075053, 23)\n    et.add_data_point(1397075113, 55)\n\n    (or in the case of histograms)\n\n    et.add_data_point(1397075053, {28: 33})\n    et.add_data_point(1397075113, {9: 12})\n\n    et.post_data()\n\nIt is also possible to bulk post data for a variety of event types associated\nwith a single metadata using the EventTypeBulkPost interface.  Intialize in\na similar fashion minus the event_type arg::\n\n    etb = EventTypeBulkPost('http://localhost:8000/', username='pS_user',\n            api_key='api-key-generated-by-auth-database',\n            metadata_key=new_meta.metadata_key)\n\nAdd a mix of data points specified by event type and post::\n\n    etb.add_data_point('time-error-estimates', 1397075053, 23)\n    etb.add_data_point('packet-loss-rate', 1397075053,\n        {'numerator': 11, 'denominator': 33})\n\n    etb.add_data_point('time-error-estimates', 1397075113, 55)\n    etb.add_data_point('packet-loss-rate', 1397075113,\n        {'numerator': 5, 'denominator': 8})\n\n    etb.post_data()\n\nNOTE: as noted in the previous section, the optional script_alias kwarg works\nthe same way with the POST interface.\n\n\n\n\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://software.es.net/esmond/", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "esmond-client", "package_url": "https://pypi.org/project/esmond-client/", "platform": "", "project_url": "https://pypi.org/project/esmond-client/", "project_urls": {"Homepage": "http://software.es.net/esmond/"}, "release_url": "https://pypi.org/project/esmond-client/4.2.1/", "requires_dist": ["python-dateutil", "requests"], "requires_python": "", "summary": "API client libraries and command line tools for the ESnet Monitoring Daemon (esmond).", "version": "4.2.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"client-programs-for-perfsonar-data\">\n<h2>Client programs for perfSONAR data</h2>\n<div id=\"esmond-ps-get-endpoints\">\n<h3>esmond-ps-get-endpoints</h3>\n<p>A discovery tool to quickly see what tests have been stored in an esmond\nperfSONAR archive. Give a list of tests in MA with the following sample\ninformation:</p>\n<pre>source: anl-owamp.es.net\ndestination: lsvn-owamp.es.net\nmeasurement_agent: anl-owamp.es.net\ntool_name: bwctl/tracepath,traceroute\nevent_type: packet-trace, failures, path-mtu\n</pre>\n</div>\n<div id=\"esmond-ps-get-metadata\">\n<h3>esmond-ps-get-metadata</h3>\n<p>Similar to get-endpoints, but this will fetch the actual metadata test data\nfrom an esmond perfSONAR archive.  By default it will show the measurements\nthat are common to all tests:</p>\n<pre>source\ndestination\nmeasurement_agent\ninput_source\ninput_destination\ntool_name\n</pre>\n<p>Including the \u2013metadata-extended will also show the per-test measurements.\nThis option can not be used with the CSV output option.</p>\n<p>Sample default output:</p>\n<pre>source: perfsonar-latency-v4.esc.qmul.ac.uk\ndestination: anl-owamp.es.net\nmeasurement_agent: anl-owamp.es.net\ninput_source: perfsonar-latency.esc.qmul.ac.uk\ninput_destination: anl-owamp.es.net\ntool_name: powstream\n</pre>\n<p>Sample output with the \u2013metadata-extended flag:</p>\n<pre>source: perfsonar-latency-v4.esc.qmul.ac.uk\ndestination: anl-owamp.es.net\nmeasurement_agent: anl-owamp.es.net\ninput_source: perfsonar-latency.esc.qmul.ac.uk\ninput_destination: anl-owamp.es.net\ntool_name: powstream\nip_transport_protocol: udp\nsample_bucket_width: 0.0001\nsample_size: 600\nsubject_type: point-to-point\ntime_duration: 60\ntime_interval: 0\ntime_probe_interval: 0.1\n</pre>\n</div>\n<div id=\"esmond-ps-get\">\n<h3>esmond-ps-get</h3>\n<p>Tool to pull smaller, more focused sets of data from a perfSONAR MA. This\nrequires a source/dest pair as well as a specific event type. Intended to\nbe more of a \u201cquick look\u201d at some data.  To gather more/larger amounts\nof data, esmond-ps-get-bulk is intended for that.</p>\n</div>\n<div id=\"esmond-ps-get-bulk\">\n<h3>esmond-ps-get-bulk</h3>\n<p>Tool to pull non-trivial amounts of data from a perfSONAR esmond archive.</p>\n<p>Iterates through the metadata matching the user query and makes incremental\ndata requests from the archive so as not to overwhelm the data store. When\nall of the data for a given event type associated with a given metadata\nhas been gathered, it will be written to disc in either json or csv format,\nwith the format:</p>\n<pre>&lt;source&gt;_&lt;dest&gt;_&lt;event_type&gt;_&lt;start_time&gt;_&lt;end_time&gt;.csv|.json\n</pre>\n<p>So one would end up with a set of output files that look like this:</p>\n<pre>perfsonar.ascr.doe.gov_anl-owamp.es.net_failures_2015-03-15_2015-04-02.csv\nperfsonar.ascr.doe.gov_anl-owamp.es.net_histogram-owdelay_2015-03-15_2015-04-02.csv\nperfsonar.ascr.doe.gov_anl-owamp.es.net_histogram-ttl_2015-03-15_2015-04-02.csv\nperfsonar.ascr.doe.gov_anl-owamp.es.net_packet-count-lost_2015-03-15_2015-04-02.csv\nperfsonar.ascr.doe.gov_anl-owamp.es.net_packet-count-sent_2015-03-15_2015-04-02.csv\nperfsonar.ascr.doe.gov_anl-owamp.es.net_packet-duplicates_2015-03-15_2015-04-02.csv\nperfsonar.ascr.doe.gov_anl-owamp.es.net_packet-loss-rate_2015-03-15_2015-04-02.csv\nperfsonar.ascr.doe.gov_anl-owamp.es.net_time-error-estimates_2015-03-15_2015-04-02.csv\n</pre>\n<p>After the file for the metadata/event-type has been written, it will continue\nto the next event-type or metadata as appropriate.  The \u201chuman readable\u201d\noutput format is not available in this program.</p>\n<p>While designed to not murder an MA with massive data queries, this command can\nreturn a lot of data, so it is recommended to limit the scope of your query\nby source, dest, event-type, etc.</p>\n</div>\n<div id=\"general-esmond-ps-perfsonar-client-usage\">\n<h3>General esmond-ps perfSONAR client usage</h3>\n<div id=\"core-and-or-required-args\">\n<h4>Core and/or required args</h4>\n<p>These args are common to all clients.  See the \u2013help flag to get a\ncomplete list of options.</p>\n<div id=\"url\">\n<h5>\u2013url</h5>\n<p>Required on all programs. Just the base protocol://host:port is required. When\nquerying a default perfSONAR install, it is not necessary to include the URI\nas well.  For example given a MA access URL of:</p>\n<pre>http://albq-owamp-v6.es.net:8085/esmond/perfsonar/archive\n</pre>\n<p>It is only necessary to provide:</p>\n<pre>--url http://albq-owamp-v6.es.net:8085\n</pre>\n</div>\n<div id=\"src-and-dest\">\n<h5>\u2013src and \u2013dest</h5>\n<p>Source and destination for the tests.  Both are required for some of the\nclients.  This is input as raw IP addresses.</p>\n</div>\n<div id=\"start-time-and-end-time\">\n<h5>\u2013start-time and \u2013end-time</h5>\n<p>If these args are not included, it will default to grabbing data from the\nprevious 24 hours.  Arg input is parsed by the Python dateutil library\nwhich will preform pretty intelligent guesses about incoming date formats.\nIt will understand structured things like ISO datetime formats, and more\norganic ones like \u201cJanuary 1 2015\u201d - if a time is not given, will default\n00:00 am, etc.</p>\n<p>See: <a href=\"https://dateutil.readthedocs.org/en/latest/examples.html#parse-examples\" rel=\"nofollow\">https://dateutil.readthedocs.org/en/latest/examples.html#parse-examples</a>\nTo see the variety of date formats that it will accept.</p>\n</div>\n<div id=\"event-type\">\n<h5>\u2013event-type</h5>\n<p>Requires a valid measurement event type.  The command line arg \u2013list-events\ncan be used to give a list of valid event types.</p>\n<p>Sometimes required.</p>\n</div>\n</div>\n<div id=\"additional-filtering-args\">\n<h4>Additional filtering args</h4>\n<p>There are additional args that can be used to filter results as well:</p>\n<pre>--agent\n--tool\n--summary-type\n--summary-window\n</pre>\n<p>These should be fairly self-explanatory.</p>\n<div id=\"filter\">\n<h5>\u2013filter</h5>\n<p>An additional power user filter that takes the format:</p>\n<pre>--filter key:value\n</pre>\n<p>This will add filters to the query string that goes to the MA. This\noption can be used more than once to add multiple filters to the\nquery string, invalid filters will be ignored.</p>\n</div>\n</div>\n<div id=\"output\">\n<h4>Output</h4>\n<div id=\"output-format\">\n<h5>\u2013output-format</h5>\n<p>Select the desired output format from the choices \u2018human,\u2019 \u2018json\u2019 and\n\u2018csv.\u2019 Default is human readable for viewing in a terminal.  The human\nand csv options are not allowed in all circumstances.</p>\n</div>\n<div id=\"output-directory\">\n<h5>\u2013output-directory</h5>\n<p>Required by esmond-ps-get-bulk - specifies a directory to write output\nfiles to.  Will default to the current working directory.</p>\n</div>\n<div id=\"ip\">\n<h5>\u2013ip</h5>\n<p>By default in the output, IP addresses (source, dest, agent, etc) will be\nconverted to a human readable fully qualified domain name. Using the -ip\nflag will stop this conversion and display all hostnames as raw IP addresses.</p>\n</div>\n</div>\n</div>\n<div id=\"example-perfsonar-command-line-client-usage\">\n<h3>Example perfSONAR command line client usage</h3>\n<div id=\"esmond-ps-get-endpoints-examples\">\n<h4>esmond-ps-get-endpoints examples</h4>\n<p>Get a list of all tests over the last 24 hours available in a given MA, show\nsrc/dest as raw ip addresses:</p>\n<pre>esmond-ps-get-endpoints --url http://nettest.lbl.gov/ --ip\n</pre>\n<p>Find all the powstream test data in a given MA since the beginning of the year:</p>\n<pre>esmond-ps-get-endpoints --url http://nettest.lbl.gov/ --ip --start-time 'January 1' --tool powstream\n</pre>\n</div>\n<div id=\"esmond-ps-get-metadata-examples\">\n<h4>esmond-ps-get-metadata examples</h4>\n<p>Show all test metadata for a given destination over the last 24 hours,\ndisplayed in CSV format:</p>\n<pre>esmond-ps-get-metadata --url http://nettest.lbl.gov/ --dest 198.129.254.62 --output-format csv\n</pre>\n<p>Show more detailed metadata information from an MA for all bwctl/iperf3\ntests involving a particular source since the beginning of the year,\nshowing extended test metadata like test duration, interval, etc\nas a list of json objects:</p>\n<pre>esmond-ps-get-metadata --url http://nettest.lbl.gov/ --tool bwctl/iperf3 --src 198.124.238.130 --metadata-extended --output-format json --start-time 'Jan 1'\n</pre>\n</div>\n<div id=\"esmond-ps-get-examples\">\n<h4>esmond-ps-get examples</h4>\n<p>Retrieve the past 24 hours of packet trace data for a src/dest pair:</p>\n<pre>esmond-ps-get --url http://nettest.lbl.gov/ --src  131.243.24.11 --dest 198.129.254.62 --event-type packet-trace\n</pre>\n<p>Get throughput data starting at the beginning of the month (presuming the\nmonth is April) for a src/dest pair:</p>\n<pre>esmond-ps-get --url http://nettest.lbl.gov/ --src  131.243.24.11 --dest 198.129.254.114 --event-type throughput --start-time 'April 1'\n</pre>\n</div>\n<div id=\"esmond-ps-get-bulk-examples\">\n<h4>esmond-ps-get-bulk examples</h4>\n<p>Pull all failures event-type information from an MA since the beginning\nof the year and write out to current working directory as a set of json\nfiles:</p>\n<pre>esmond-ps-get-bulk --url http://anl-owamp.es.net:8085  --event-type failures --start-time 'January 1' --output-format json\n</pre>\n<p>Pull all data associated with a given source from the past 24 hours and write\nto a custom directory in CSV format:</p>\n<pre>esmond-ps-get-bulk --url http://anl-owamp.es.net:8085  --src 192.73.213.28 --output-format csv -D ~/Desktop/tmp\n</pre>\n<p>Pull data for all event types measured by the powstream tool since the start\nof March and write to a custom directory in json format:</p>\n<pre>esmond-ps-get-bulk --url http://anl-owamp.es.net:8085  --tool powstream --start-time 'March 1' --output-format json -D ~/Desktop/tmp\n</pre>\n<p>Pull all the data in an MA for the past 24 hours and output to current working\ndirectory in json format:</p>\n<pre>esmond-ps-get-bulk --url http://nettest.lbl.gov/ --output-format json\n</pre>\n</div>\n</div>\n</div>\n<div id=\"esmond-perfsonar-data-loading-programs\">\n<h2>Esmond perfSONAR data loading programs</h2>\n<p>There are also client programs for writing data to an MA. This requires that the\nuser have write access to the esmond instance.</p>\n<div id=\"id1\">\n<h3>Core and/or required args</h3>\n<p>The following args are required/generally needed by all programs that write\ndata to an MA.</p>\n<div id=\"user-and-key\">\n<h4>\u2013user and \u2013key</h4>\n<p>Both of these args are required. It is the username and api key string that\nwas generated on the MA to allow access to it.</p>\n</div>\n<div id=\"id2\">\n<h4>\u2013url</h4>\n<p>The url of the MA. Format <a href=\"http://example.com:80\" rel=\"nofollow\">http://example.com:80</a> where http or https can be the\nprefix. Just host and port information, no uri information. Defaults to\n<a href=\"http://localhost:8080\" rel=\"nofollow\">http://localhost:8080</a>.</p>\n</div>\n<div id=\"script-alias\">\n<h4>\u2013script_alias</h4>\n<p>Used when the REST API has been deployed under Apache using a ScriptAlias\ndirective/prefix. This would commonly be set to \u2018esmond\u2019 since the canned\nCentOS deployments use script alias of /esmond to allow other things to\nrun on the webserver (ie: so the REST API is not the root of the webserver).\nThe default value is \u2018/\u2019 - which will not perform any prefixing.</p>\n</div>\n</div>\n<div id=\"esmond-ps-load-gridftp\">\n<h3>esmond-ps-load-gridftp</h3>\n<p>Utility to parse and load GridFTP data.</p>\n<p>This will read the default gridftp logs, process the \u201cTransfer stats\u201d entries,\nand upload the results to the pS esmond backend as metadata and either\nthroughput or failures event types. This has been expanded (using the \u2013json\nflag) to read the new json formatted gridftp logs that contain additional\nevent types like retransmits, iostat, etc.</p>\n<p>The basic use case would that this script be run from cron periodically\nover the day to parse and load data from the gridftp logs into an esmond\nbackend.  The scanning code will write out the contents of the record that\nwas last loaded as a python pickle file to disc.  This state file is used\nto pick up from the point the last processing pass got to.</p>\n<p>Basic usage: the following arguments are required for baseline operation:</p>\n<pre>esmond-ps-load-gridftp -f ~/Desktop/gridftp.log -U http://localhost:8000 -u mgoode -k api_key_for_mgoode\n</pre>\n<div id=\"in-addition-to-the-flags-outlined-above-required-args\">\n<h4>In addition to the flags outlined above, required args</h4>\n<h4 id=\"file\"><span class=\"section-subtitle\">\u2013file</span></h4>\n<p>The path to the logfile to process.  The code will normalize the path,\nso relative paths are fine.  No default.</p>\n</div>\n<div id=\"commonly-used-args\">\n<h4>Commonly used args</h4>\n<div id=\"json\">\n<h5>\u2013json</h5>\n<p>Specifies that the log indicate by the \u2013file flag is the json-formatted\nGridFTP files.</p>\n</div>\n<div id=\"pickle\">\n<h5>\u2013pickle</h5>\n<p>The path to the pickle file the scanning code uses to store the \u201cstate\u201d\nof the last record that has been processed.  Code uses this to know where\nto pick up on subsequent scans.  This defaults to ./load_grid_ftp.pickle\nor ./load_grid_ftp.json.pickle as appropriate - will probably want to\nchange this to a fully qualified path somewhere.</p>\n</div>\n<div id=\"dont-write\">\n<h5>\u2013dont_write</h5>\n<p>Suppresses writing the pickle state file out when the file has been scanned.\nThis would be used when manually/etc processing one or more log files where\nit is desired to just parse the contents of an entire static (ie: no longer\nbeing written to) file.  Defaults to False - use this flag to suppress\nwriting the state file.</p>\n</div>\n<div id=\"log-dir\">\n<h5>\u2013log_dir</h5>\n<p>Can be used to specify a directory to write a log from the program to.\nIf this is not set (the default), then log output will go to stdout.</p>\n</div>\n</div>\n<div id=\"optional-content-selection-args\">\n<h4>Optional content selection args</h4>\n<p>The gridftp logs contain information on the user, the file being sent and\nthe volume being written to.  Since these might be considered to be sensitive\ndata, this information is not sent to the backend by default.  The following\nflags can be set to send that information if desired:</p>\n<pre>-F (--file_attr): send gridftp-file/value of FILE\n-N (--name_attr): send gridftp-user/value of USER (name)\n-V (--volume_attr): send gridftp-volume/value of VOLUME\n</pre>\n</div>\n<div id=\"other-development-args\">\n<h4>Other/development args</h4>\n<h4 id=\"single\"><span class=\"section-subtitle\">\u2013single</span></h4>\n<p>Will process a single value starting at the last record sent and stop.\nThis is mostly used for development/testing to \u201cstep through\u201d a file\nrecord by record.  It will set the pickle state file to the single\nrecord sent before exiting.</p>\n</div>\n<div id=\"running-from-cron-and-dealing-with-rotated-logs\">\n<h4>Running from cron and dealing with rotated logs</h4>\n<p>When running from cron the script should be run with the required arguments\nenumerated above and set the \u2013pickle arg to a fully qualified path, and\nthe \u2013file arg should point to the logfile.  It can be run at whatever\nfrequency the user desires as the code will pick up from the last record\nthat was processed.  When running from cron, the \u2013log_dir arg should\nbe set so the logging output is written to a file rather than sent to\nstdout.</p>\n<p>Log rotation interfere with this if the code has not finished scanning\na log before it is rotated and renamed.  If the code is run on the \u201cfresh\u201d\nlog, it will not find the last record that was processed.   To deal with\nthis, this script should also be kicked off using the \u201cprerotate\u201d hook\nthat logrotated provides.</p>\n<p>When running this as a prerotate job, the -D (\u2013delete_state) flag should\nalso be used.  This will delete the pickle state file when the scan is\ndone with the log before it is rotated.  The state file is deleted so that\nwhen the next cron job runs on the new \u201cfresh\u201d log, it will just start\nscaning from the beginning and not try to search for a record that it\nwon\u2019t find.</p>\n<p>Alternately if the user doesn\u2019t need the data to be periodically loaded,\none could opt to exclusively run this as a logrotated/prerotate job such\nthat the entire log is processed in one throw before it is rotated.  In that\ncase the \u2013dont_write flag should be used.</p>\n</div>\n</div>\n<div id=\"esmond-ps-pipe\">\n<h3>esmond-ps-pipe</h3>\n<p>Utility to take json-formatted output from bwctl (\u2013parsable flag) and\nload the data into an esmond MA.</p>\n<p>Currently supported tool types:</p>\n<ul>\n<li>iperf3</li>\n</ul>\n<div id=\"usage\">\n<h4>Usage</h4>\n<p>Primarily relies on the required command line args (\u2013user, \u2013key, etc)\noutlined above and piped input from the bwctl command:</p>\n<pre>bwctl -c lbl-pt1.es.net -s llnl-pt1.es.net -T iperf3 --parsable --verbose |&amp; esmond-ps-pipe --user mgoode --key api_key_for_mgoode\n</pre>\n<p>The primary thing (other than using a -T &lt;tool&gt; that is supported) is that bwctl\n<strong>must</strong> be run with both the \u2013parsable flag (which generates the json output)\n<strong>and also</strong> the \u2013verbose flag. esmond-ps-pipe pulls important metadata from\nthe \u2013verbose output, and uses it to identify the json part of the output.</p>\n<p>If the program is unable to extract the necessary metadata and a valid json\npayload from the piped input, it will log a fatal error and exit.</p>\n</div>\n<div id=\"shell-redirection\">\n<h4>Shell redirection</h4>\n<p>Note the \u201c<strong>|&amp;</strong>\u201d that redirects the output from bwctl to esmond-ps-pipe - both stdout and stderr need to be piped to esmond-ps-pipe. That should work on Csh and current versions of Bash. This may vary from shell to shell - for example, older versions of Bash might need to use \u201c<strong>2&gt;&amp;1 |</strong>\u201d or something similar. The short of it is, the shell-specific way to redirect both stdout and stderr from bwctl is necessary.</p>\n<p>If an error that looks something like this is generated:</p>\n<pre>ts=2015-10-20 11:37:24,881 event=id_and_extract.error id=1445366244 could not extract tool_name\nts=2015-10-20 11:37:24,881 event=id_and_extract.error id=1445366244 could not extract input_source\nts=2015-10-20 11:37:24,881 event=id_and_extract.error id=1445366244 could not extract input_destination\nts=2015-10-20 11:37:24,881 event=main.fatal id=1445366244 could not extract metadata and valid json from input\nts=2015-10-20 11:37:24,882 event=main.fatal id=1445366244 exiting\n</pre>\n<p>It is likely that the redirection is not being executed properly because tool_name, input_source and input_destination are all read from the bwctl headers that are being written to stderr.</p>\n</div>\n<div id=\"optional-args\">\n<h4>Optional args</h4>\n<h4 id=\"id3\"><span class=\"section-subtitle\">\u2013log_dir</span></h4>\n<p>Like esmond-ps-load-gridftp, this takes a \u2013log_dir arg which specifies the\ndirectory that logging output should be written to. If not specified, logging\noutput will got to stdout.</p>\n</div>\n<div id=\"event-types\">\n<h4>Event types</h4>\n<h4 id=\"iperf3\"><span class=\"section-subtitle\">iperf3</span></h4>\n<p>The following event types are extracted (as appropriate RE: TCP, UDP, streams,\netc) from the iperf3 data:</p>\n<pre>throughput\nthroughput-subintervals\npacket-retransmits-subintervals\nstreams-packet-retransmits\nstreams-packet-retransmits-subintervals\nstreams-throughput\nstreams-throughput-subintervals\npacket-retransmits\npacket-count-lost\npacket-count-sent\npacket-loss-rate\n</pre>\n</div>\n</div>\n</div>\n<div id=\"api-client-libraries-for-perfsonar-data\">\n<h2>API Client Libraries for perfSONAR data</h2>\n<p>The pS data can be queried, retrieved and posted to the esmond/cassandra backend\nvia a REST interface.  This is streamlined by the following libraries:</p>\n<pre>esmond.api.client.perfsonar.query\nesmond.api.client.perfsonar.post\n</pre>\n<div id=\"initializing-the-query-interface\">\n<h3>Initializing the query interface</h3>\n<p>The query libarary has two main \u201ctop level\u201d classes: ApiFilters and ApiConnect.\nApiFilters lets the user, through a series of properties, set the primary query\ncriteria like time ranges, source, destination, etc.  The following criteria\nproperties can be set:</p>\n<pre>destination\ninput_destination\ninput_source\nmeasurement_agent\nsource\ntool_name\ntime\ntime_start\ntime_end\ntime_range\nverbose (for debugging/extended output)\n</pre>\n<p>After the query criteria have been set in the ApiFilters object, that is passed\nto the ApiConnect object as one of the args.</p>\n<p>The ApiConnect object takes the url of the REST interface as an argument, along\nwith the filters object, and optional username and api_key arguments if the user\nis accessing restricted functionality of the REST interface (non-public data,\ngetting around throttling restrictions, etc).</p>\n<p>A complete example of setting this up:</p>\n<pre>from esmond.api.client.perfsonar.query import ApiConnect, ApiFilters\n\nfilters = ApiFilters()\n\nfilters.verbose = True\nfilters.time_start = time.time() - 3600\nfilters.time_end = time.time()\nfilters.source = '198.129.254.30'\nfilters.tool_name = 'bwctl/iperf3'\n\nconn = ApiConnect('http://localhost:8000/', filters)\n</pre>\n<p>NOTE: the default perfSONAR/esmond deployments use a WSGIScriptAlias of /esmond\nprefixing the URI - this is set in Apache.  The client libraries default to\nusing this.  But if one is doing development against the django runserver dev\nserver, or if this has been set up differently, then the optional kwarg\n\u201cscript_alias\u201d will need to be set as well.  Against the dev server, it can\nbe set to script_alias=None since the Apache directive is not in place.</p>\n</div>\n<div id=\"retrieving-the-data\">\n<h3>Retrieving the data</h3>\n<p>The basic design of the returned data is a hierarchy of encapsulation objects\nthat return additioanl objects objects, etc.  All of the returned objects\nhave informative __repr__ methods defined, that might help when doing\ninitial development.</p>\n<p>The top level call to the ApiConnect object is get_metadata().  This is an\niterator that will return a series of Metadata objects matching the criteria\ngiven in the ApiFilters object.  At the top level, the Metadata object exposes\na series of properties giving additional information about the returned\nmetadata.  Example of this:</p>\n<pre>for md in conn.get_metadata():\n    print md # debug info in __repr__\n    print md.destination\n    print md.ip_packet_interval\n    ...\n</pre>\n<p>The following top-level properties are exposed by the Metadata object:</p>\n<pre>destination\nevent_types (a list of event type names - more on this)\ninput_destination\ninput_source\nip_packet_interval\nmeasurement_agent\nmetadata_key\nsample_bucket_width\nsource\nsubject_type\ntime_duration\ntool_name\nuri\n</pre>\n<p>The next in the data object hierarchy is fetching the event types that are\nassociated with the metadata.  This can be done by either using an interator\nto access all of the event types:</p>\n<pre>for et in md.get_all_event_types():\n    print et.event_type\n    ...\n</pre>\n<p>or fetching a single one by name:</p>\n<pre>et = md.get_event_type('histogram-owdelay')\n</pre>\n<p>The top-level property \u201cevent_types\u201d will return a list of valid event types\nthat can be passed as the argument to get_event_type.</p>\n<p>The EventType objects expose the following top-level properties:</p>\n<pre>base_uri\nevent_type\ndata_type\nsummaries (a list of associated summaries - more on this)\n</pre>\n<p>The the actual underlying data are retrieved from the EventType objects by a call to the get_data() method, which returns a DataPayload object:</p>\n<pre>dpay = et.get_data()\n</pre>\n<p>The DataPayload object expose the following top-level properties:</p>\n<pre>data_type\ndata\n</pre>\n<p>The data_type property returns the underlying data_type in the payload, and\nthe data property returns a list of DataPoint or DataHistogram objects as\nis appropriate.  Both the DataPoint and DataHistogram objects expose the\nfollowing properties:</p>\n<pre>ts (measurement timestamp as a UTC python datetime object)\nval (the measurement or hisogram dict)\nts_epoch (the ts object expressed as UNIX time)\n</pre>\n<p>Putting it all together, to iterate throught all of the returned data:</p>\n<pre>for et in md.get_all_event_types():\n    dpay = et.get_data()\n    print dpay.data_type\n    for dp in dpay.data:\n        print dp.ts, dp.val\n</pre>\n<p>Some event types have aggregated summaries associated with them.  Retrieving\nthe summaries from an EventType object is very similar to pulling event types\nfrom a Metadata object.  The following properties/methods are analogous to the\nones that exist in the Metadata object:</p>\n<pre>summaries\n</pre>\n<p>This returns a list of two-element tuples: (summary-type, summary-window). The\nwindow is the time duration of the aggregation rollups.</p>\n<p>The summary data can be retrieved by either using an iterator:</p>\n<pre>for summ in et.get_all_summaries():\n    ...\n</pre>\n<p>Or a single type can be fetched:</p>\n<pre>summ = et.get_summary(summary-type, summary-window)\n</pre>\n<p>Like with the EventType object, the underlying data can be retrieved by\ncalling get_data() to get a DataPayload object and call the data property\non that to get a list of DataPoint objects.</p>\n</div>\n<div id=\"writing-data-to-ps-esmond-backend\">\n<h3>Writing data to pS esmond/backend</h3>\n<p>The REST interface also supports adding metadata, event types and data if\nthe user is properly authenticated using a username and api_key that has\nbeen generated by the admin of the system.  The following are presented as\nan ordered process, but any single step of this can be done independently.\nThe functionality for POSTing date can be found in the following libarary:</p>\n<pre>from esmond.api.client.perfsonar.post import MetadataPost, \\\n    EventTypePost, EventTypeBulkPost\n</pre>\n<p>First one needs to create a new metadata entry - this is accomplished\nusing the MetadataPost object.  It is initialized with a REST url,\nusername, api_key and a series of associated data - most required, a few\noptional (the commented key/val pairs in the arg dict are optional):</p>\n<pre>args = {\n    \"subject_type\": \"point-to-point\",\n    \"source\": \"10.10.0.1\",\n    \"destination\": \"10.10.0.2\",\n    \"tool_name\": \"bwctl/iperf3\",\n    \"measurement_agent\": \"10.10.0.2\",\n    \"input_source\": \"host1\",\n    \"input_destination\": \"host2\",\n    # \"time_duration\": 30,\n    # \"ip_transport_protocol\": \"tcp\"\n}\n\nmp = MetadataPost('http://localhost:8000/', username='pS_user',\n    api_key='api-key-generated-by-auth-database', **args)\n</pre>\n<p>This will create the basic data associated with this metadata.  Then add\nthe event types and summaries associated with this metadata and post the\nnew information:</p>\n<pre>mp.add_event_type('throughput')\nmp.add_event_type('time-error-estimates')\nmp.add_event_type('histogram-ttl')\nmp.add_event_type('packet-loss-rate')\nmp.add_summary_type('packet-count-sent', 'aggregation', [3600, 86400])\n\nnew_meta = mp.post_metadata()\n</pre>\n<p>This writes the metadata information to the back end and returns the\nassociated \u201cread only\u201d Metadata object that was covered in the previous\nsection.  This is mostly necessary to get the newly generated metadata_key\nproperty, it will be needed for other operations.</p>\n<p>Next data can be added to the assocaited event types - the process is similar\nfor both numeric and histogram data.  Intialize an EventTypePost object\nsimilarly to the MetadataPost object, but also using the appropriate\nmetadata_key and event_type to add the data to:</p>\n<pre>et = EventTypePost('http://localhost:8000/', username='pS_user',\n    api_key='api-key-generated-by-auth-database',\n    metadata_key=new_meta.metadata_key,\n    event_type='throughput')\n</pre>\n<p>Discrete data points can be added the process is similar for both numeric\ndata and histogram data - first arg is an integer timestamp in seconds and\nthe second is the value - and post it:</p>\n<pre>et.add_data_point(1397075053, 23)\net.add_data_point(1397075113, 55)\n\n(or in the case of histograms)\n\net.add_data_point(1397075053, {28: 33})\net.add_data_point(1397075113, {9: 12})\n\net.post_data()\n</pre>\n<p>It is also possible to bulk post data for a variety of event types associated\nwith a single metadata using the EventTypeBulkPost interface.  Intialize in\na similar fashion minus the event_type arg:</p>\n<pre>etb = EventTypeBulkPost('http://localhost:8000/', username='pS_user',\n        api_key='api-key-generated-by-auth-database',\n        metadata_key=new_meta.metadata_key)\n</pre>\n<p>Add a mix of data points specified by event type and post:</p>\n<pre>etb.add_data_point('time-error-estimates', 1397075053, 23)\netb.add_data_point('packet-loss-rate', 1397075053,\n    {'numerator': 11, 'denominator': 33})\n\netb.add_data_point('time-error-estimates', 1397075113, 55)\netb.add_data_point('packet-loss-rate', 1397075113,\n    {'numerator': 5, 'denominator': 8})\n\netb.post_data()\n</pre>\n<p>NOTE: as noted in the previous section, the optional script_alias kwarg works\nthe same way with the POST interface.</p>\n</div>\n</div>\n\n          </div>"}, "last_serial": 5313274, "releases": {"1.0": [{"comment_text": "", "digests": {"md5": "a70dd5ea06a2dedf91d2e7735932c959", "sha256": "589ef6daf29447d14ca31440e7ab3e66a0380b91a3b7228eabe99b2abb525a41"}, "downloads": -1, "filename": "esmond_client-1.0-py2-none-any.whl", "has_sig": false, "md5_digest": "a70dd5ea06a2dedf91d2e7735932c959", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 15874, "upload_time": "2014-06-11T21:44:24", "upload_time_iso_8601": "2014-06-11T21:44:24.030994Z", "url": "https://files.pythonhosted.org/packages/3f/75/b34323fc1ac6763b3eb8872d90d57160e98fcd572c04d5005486df3ee37a/esmond_client-1.0-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "16107940b38bbe4abe44a42bded2034d", "sha256": "08670bb1a06a90880c4ac64f4b78d2ee925e14520485df6baddeef92b183ff3c"}, "downloads": -1, "filename": "esmond_client-1.0.tar.gz", "has_sig": false, "md5_digest": "16107940b38bbe4abe44a42bded2034d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12790, "upload_time": "2014-06-11T21:44:21", "upload_time_iso_8601": "2014-06-11T21:44:21.391233Z", "url": "https://files.pythonhosted.org/packages/f1/6f/deb701251546d0caade7eb2f3317eb69cceafcf97ba45e3d8ace7c2afc51/esmond_client-1.0.tar.gz", "yanked": false}], "1.1": [{"comment_text": "", "digests": {"md5": "ad6a24919bacdb066158ea03df6f8d0f", "sha256": "52347a27d5939cc186ca0e5723f8470c5e15af08a6533a763afa7b5302e6233d"}, "downloads": -1, "filename": "esmond_client-1.1.tar.gz", "has_sig": false, "md5_digest": "ad6a24919bacdb066158ea03df6f8d0f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18604, "upload_time": "2014-09-25T20:28:42", "upload_time_iso_8601": "2014-09-25T20:28:42.156626Z", "url": "https://files.pythonhosted.org/packages/77/2f/1e147742cd9d7bda467f200a0b6fe467dfddce81cb3a35d1fcc86088bf65/esmond_client-1.1.tar.gz", "yanked": false}], "1.2": [{"comment_text": "", "digests": {"md5": "8268c8e34e0ea2f78a61be35c9dd0c6d", "sha256": "cec274668a5631f91828daceb5edcc7e303fa62cdac96a2aa7e061310200a08d"}, "downloads": -1, "filename": "esmond_client-1.2.tar.gz", "has_sig": false, "md5_digest": "8268c8e34e0ea2f78a61be35c9dd0c6d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 19117, "upload_time": "2015-02-23T20:36:53", "upload_time_iso_8601": "2015-02-23T20:36:53.473750Z", "url": "https://files.pythonhosted.org/packages/75/43/09d4840eb44ff1ca0fab59b669cc6b9bd1bfe504d88f7bbca990e0492340/esmond_client-1.2.tar.gz", "yanked": false}], "1.3": [{"comment_text": "", "digests": {"md5": "2cf23011332b5aa168283b0ffcc2d971", "sha256": "4dd66beefbfeed468cf5add3e16fa8bf0b691cd159a7578fd76d497993699370"}, "downloads": -1, "filename": "esmond_client-1.3.tar.gz", "has_sig": false, "md5_digest": "2cf23011332b5aa168283b0ffcc2d971", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 36246, "upload_time": "2015-04-15T22:59:47", "upload_time_iso_8601": "2015-04-15T22:59:47.293115Z", "url": "https://files.pythonhosted.org/packages/21/f6/31559c0362ba351531d26b593a433127641c34d51a845fa35105ab82541c/esmond_client-1.3.tar.gz", "yanked": false}], "1.4": [], "1.5": [{"comment_text": "", "digests": {"md5": "fe5afabf6604ac2353b5075d8d79f258", "sha256": "b4301a72f6cf9157efe741499dee711d4fe58e2a002512252a4c328fa0f8534e"}, "downloads": -1, "filename": "esmond_client-1.5.tar.gz", "has_sig": false, "md5_digest": "fe5afabf6604ac2353b5075d8d79f258", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 41498, "upload_time": "2015-09-02T18:51:08", "upload_time_iso_8601": "2015-09-02T18:51:08.025858Z", "url": "https://files.pythonhosted.org/packages/c7/8d/03c2a09d2422a1aeef055a931dd2bfe87531ec4ad3023ed4fd3aae0ae441/esmond_client-1.5.tar.gz", "yanked": false}], "1.6": [{"comment_text": "", "digests": {"md5": "6849cc8c39379f2957770e35ffa6c3e4", "sha256": "20684640b81fa9be2dc5a4ea5bcaf733d0090068bd6588718b02b09c7f252600"}, "downloads": -1, "filename": "esmond_client-1.6.tar.gz", "has_sig": false, "md5_digest": "6849cc8c39379f2957770e35ffa6c3e4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 59494, "upload_time": "2015-10-26T18:39:14", "upload_time_iso_8601": "2015-10-26T18:39:14.099861Z", "url": "https://files.pythonhosted.org/packages/95/65/b9083a67e94ad1971ff6d5baff7d8f96b4d03060954f2f835ca48b3b04c8/esmond_client-1.6.tar.gz", "yanked": false}], "2.0": [{"comment_text": "", "digests": {"md5": "3b44a807abc2c8be8776ac80a12ff1ef", "sha256": "3a7f92f2a70da6ec75a041b2d23229a3a957bcb4298a7539e55d90cc2590baf0"}, "downloads": -1, "filename": "esmond_client-2.0.tar.gz", "has_sig": false, "md5_digest": "3b44a807abc2c8be8776ac80a12ff1ef", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 63211, "upload_time": "2016-03-03T14:49:20", "upload_time_iso_8601": "2016-03-03T14:49:20.161927Z", "url": "https://files.pythonhosted.org/packages/4c/fb/49bb2ef971b05690815e0a7e36afa9204f9a06b01610906b6c7f67bda43c/esmond_client-2.0.tar.gz", "yanked": false}], "4.2.1": [{"comment_text": "", "digests": {"md5": "552dc53f28c7f250fefb37ea777a408b", "sha256": "8778971fb83a4a0e6e2a055b9f652b78ed0f9671baf0c023ea55823a23442439"}, "downloads": -1, "filename": "esmond_client-4.2.1-py2-none-any.whl", "has_sig": false, "md5_digest": "552dc53f28c7f250fefb37ea777a408b", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 69188, "upload_time": "2019-05-24T15:31:48", "upload_time_iso_8601": "2019-05-24T15:31:48.499004Z", "url": "https://files.pythonhosted.org/packages/cc/83/677ff9026be1a50be3235a0c305a127b669681de6b39e42007e9cd5f5724/esmond_client-4.2.1-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3dda3063aa216f04829bb12060eae9bf", "sha256": "5095e714c686dc4031f7f18909472f51e2bdfd83b027ff9ee7428aabdf2d08fd"}, "downloads": -1, "filename": "esmond_client-4.2.1.tar.gz", "has_sig": false, "md5_digest": "3dda3063aa216f04829bb12060eae9bf", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 68144, "upload_time": "2019-05-24T15:31:49", "upload_time_iso_8601": "2019-05-24T15:31:49.927312Z", "url": "https://files.pythonhosted.org/packages/c3/c6/c262d9ec005e5f86b00defdb4ae30a38a6493a87459999117c7b043738d7/esmond_client-4.2.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "552dc53f28c7f250fefb37ea777a408b", "sha256": "8778971fb83a4a0e6e2a055b9f652b78ed0f9671baf0c023ea55823a23442439"}, "downloads": -1, "filename": "esmond_client-4.2.1-py2-none-any.whl", "has_sig": false, "md5_digest": "552dc53f28c7f250fefb37ea777a408b", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 69188, "upload_time": "2019-05-24T15:31:48", "upload_time_iso_8601": "2019-05-24T15:31:48.499004Z", "url": "https://files.pythonhosted.org/packages/cc/83/677ff9026be1a50be3235a0c305a127b669681de6b39e42007e9cd5f5724/esmond_client-4.2.1-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3dda3063aa216f04829bb12060eae9bf", "sha256": "5095e714c686dc4031f7f18909472f51e2bdfd83b027ff9ee7428aabdf2d08fd"}, "downloads": -1, "filename": "esmond_client-4.2.1.tar.gz", "has_sig": false, "md5_digest": "3dda3063aa216f04829bb12060eae9bf", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 68144, "upload_time": "2019-05-24T15:31:49", "upload_time_iso_8601": "2019-05-24T15:31:49.927312Z", "url": "https://files.pythonhosted.org/packages/c3/c6/c262d9ec005e5f86b00defdb4ae30a38a6493a87459999117c7b043738d7/esmond_client-4.2.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:45:39 2020"}