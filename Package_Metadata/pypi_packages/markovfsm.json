{"info": {"author": "Vladimir Ignatev", "author_email": "ya.na.pochte@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: CC0 1.0 Universal (CC0 1.0) Public Domain Dedication", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.6", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.2", "Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Scientific/Engineering :: Information Analysis", "Topic :: Software Development :: Libraries"], "description": "# Markov Chain and Finite-State Stochastic Machine\n\nThis package implements functionality for analyzing stochastic (or random)\nfinite state (Markov) processes.\n\nIt can build a Markov chain from the states of the process.\n\nAlso the package provides non-deterministic FSM (finite-state machine)\nfunctionality for evaluating of Markov chains. You can easily build \na probabilistic automaton from the Markov chain.\n\nOne more feature is an integration with amazing [Graphviz](http://www.graphviz.org/) tool.\n`markovfsm` plots a state transitions graph of Markov model for you.\n\n# Installation\nAs usual, `pip install markovfsm`\n\nNo special prerequisites required, expect the Graphviz, if you want to use plotting features.\nIn such case, you have to install Graphviz and [`graphviz` PyPI package](https://pypi.org/project/graphviz/).\n\n# Usage examples\n## Coin flipping\nLet's start with the simplest Markov process - a flipping of perfect coin.\nLet '0' state be 'tails' and '1' state correspond to 'heads'.\n\nWe define a random function (`coin()`), once being evaluated, returns the next state of the process.\n\nLet's create a `Chain` object and perform big enough count of experiments:\n```python\nfrom random import random\nfrom graphviz import Digraph\n\nfrom markovfsm import Chain\nfrom markovfsm.plot import transitions_to_graph\n\n\ndef coin():               # random process: the perfect coin flipping\n    return 1 if random() > 0.5 else 0\n\nchain = Chain(2, coin())  # create an empty Markov chain with 2 states\n\nfor i in range(1000000):  # let the Markov chain build state transition matrix\n    chain.learn(coin())   # based on 1000000 of coin flips\n```\nLet's plot a graph of state transitions.\n```python\ng = Digraph(format='svg', engine='dot',\n            graph_attr={'pad': '0.1', 'nodesep': '0.4', 'ranksep': '1.0'},\n            node_attr={'fontname': 'Helvetica'},\n            edge_attr={'fontsize': '8.0', 'fontname': 'Helvetica'})\n\ntransitions_to_graph(g, chain.transition_matrix(),\n                     lambda s: \"tails\" if s == 0 else \"heads\")\n\ng.render('./graph')       # this will output ``graph.svg`` (SVG graphics)\n                          # and ``graph`` (DOT language) files\n```\n\n## Rigged dice\nAnother illustrative example is the process of rolling a rigged dice.\nWe use beta distribution to emulate non-perfect dice.\n\nThe remaining part of the code almost the same.\n```python\n#!coding:utf-8\n\nfrom random import betavariate\nfrom graphviz import Digraph\n\nfrom markovfsm import Chain\nfrom markovfsm.plot import transitions_to_graph\n\n\ndef rigged_dice():\n    return int((betavariate(0.5, 0.7) * 6))\n\nchain = Chain(6, rigged_dice())\n\n# roll dice many times to build Markov chain for this process\nfor i in range(100000):\n    chain.learn(rigged_dice())\n```\n\nAnd then let's plot states transitions.\n```python\ndef state_mapping(state):\n    if state == 0: return u'\u2680'\n    if state == 1: return u'\u2681'\n    if state == 2: return u'\u2682'\n    if state == 3: return u'\u2683'\n    if state == 4: return u'\u2684'\n    if state == 5: return u'\u2685'\n\ng = Digraph(format='svg', engine='dot',\n            graph_attr={'pad': '0.1', 'nodesep': '0.15', 'ranksep': '0.5'},\n            edge_attr={'fontsize': '6.0', 'fontname':'Helvetica'})\n\ntransitions_to_graph(g, chain.transition_matrix(), state_mapping)\ng.render('./graph')\n```\n\n# Probabilistic finite-state machine\nFinite-state machine (FSM, or state machine) is a model of computation.\nThe machine can be in exactly one of finite number of states.\nProbabilistic automaton is a FSM where transitions between states are probabilistic.\nUnlike normal FSM, requiring only a graph of possible transitions between states,\nprobabilistic automaton adds probability of every transition.\n```python\nfrom random import random\n\n# build Markov chain with 2 states, init with random state\nchain = Chain(2, 0 if random() > 0.5 else 1)\n\n# flip coin many times and build Markov chain for this process\n# let 0 be heads and 1 tails\nfor i in range(1000000):\n    chain.learn(0 if random() > 0.5 else 1)\n\n# get transition matrix\n#   It should look like:\n#\n#    P = | 0.5 0.5 |\n#        | 0.5 0.5 |\n#\nP = chain.transition_matrix()\n\nprint \"%s %s\" % (P[0][0], P[0][1])\nprint \"%s %s\" % (P[1][0], P[1][1])\n\n# get probabilities of transition from state 0 to other states (0 and 1)\n# actually, the line in the transition matrix\nprint chain.get_transitions_probs(0)\n\n# let's make a FSM with stochastic properties equal to described by Markov chain\n# use rnd() as a random numbers generator, and 0 (heads) as initial state\nfsm = FSM(chain, 0)\n\nfsm.next()  # will change the state of automaton randomly in a such way that\n            # the statistics of such transition will be equal to Markov process\n            # statistics\n```\n\n# API\n`chain.transition_matrix()` will return transition matrix: a matrix N x N,\nwhere N is the number of states, where each i-row correspond to the state of the process\nand each j-element in the row contains the probability of transition to state ``j``\nfrom the state ``i``.\n\n`chain.learn(state)` will learn Markov chain from new `state` transition\n\n`FSM(chain, initial_state)` - object, representing probabilistic automaton,\nbuilt from `chain` in state `initial_state`\n\n\n# License\nMIT License. Creative Commons CC0.\n\n\nNews\n====\n\n0.2\n---\n\n*Release date: 25-Mar-2019*\n\n* Updated usage information and added illustrations\n* Better documentation\n\n\n0.1\n---\n\n*Release date: 20-Dec-2017*\n\n* Initial release", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/vladignatyev/markovfsm", "keywords": "markov chain random process probability stochastic automata finite-state machine fsm", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "markovfsm", "package_url": "https://pypi.org/project/markovfsm/", "platform": "", "project_url": "https://pypi.org/project/markovfsm/", "project_urls": {"Homepage": "https://github.com/vladignatyev/markovfsm"}, "release_url": "https://pypi.org/project/markovfsm/0.2/", "requires_dist": null, "requires_python": "", "summary": "Markov Chain generator from random process data", "version": "0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            # Markov Chain and Finite-State Stochastic Machine<br><br>This package implements functionality for analyzing stochastic (or random)<br>finite state (Markov) processes.<br><br>It can build a Markov chain from the states of the process.<br><br>Also the package provides non-deterministic FSM (finite-state machine)<br>functionality for evaluating of Markov chains. You can easily build <br>a probabilistic automaton from the Markov chain.<br><br>One more feature is an integration with amazing [Graphviz](http://www.graphviz.org/) tool.<br>`markovfsm` plots a state transitions graph of Markov model for you.<br><br># Installation<br>As usual, `pip install markovfsm`<br><br>No special prerequisites required, expect the Graphviz, if you want to use plotting features.<br>In such case, you have to install Graphviz and [`graphviz` PyPI package](https://pypi.org/project/graphviz/).<br><br># Usage examples<br>## Coin flipping<br>Let's start with the simplest Markov process - a flipping of perfect coin.<br>Let '0' state be 'tails' and '1' state correspond to 'heads'.<br><br>We define a random function (`coin()`), once being evaluated, returns the next state of the process.<br><br>Let's create a `Chain` object and perform big enough count of experiments:<br>```python<br>from random import random<br>from graphviz import Digraph<br><br>from markovfsm import Chain<br>from markovfsm.plot import transitions_to_graph<br><br><br>def coin():               # random process: the perfect coin flipping<br>    return 1 if random() &gt; 0.5 else 0<br><br>chain = Chain(2, coin())  # create an empty Markov chain with 2 states<br><br>for i in range(1000000):  # let the Markov chain build state transition matrix<br>    chain.learn(coin())   # based on 1000000 of coin flips<br>```<br>Let's plot a graph of state transitions.<br>```python<br>g = Digraph(format='svg', engine='dot',<br>            graph_attr={'pad': '0.1', 'nodesep': '0.4', 'ranksep': '1.0'},<br>            node_attr={'fontname': 'Helvetica'},<br>            edge_attr={'fontsize': '8.0', 'fontname': 'Helvetica'})<br><br>transitions_to_graph(g, chain.transition_matrix(),<br>                     lambda s: \"tails\" if s == 0 else \"heads\")<br><br>g.render('./graph')       # this will output ``graph.svg`` (SVG graphics)<br>                          # and ``graph`` (DOT language) files<br>```<br><br>## Rigged dice<br>Another illustrative example is the process of rolling a rigged dice.<br>We use beta distribution to emulate non-perfect dice.<br><br>The remaining part of the code almost the same.<br>```python<br>#!coding:utf-8<br><br>from random import betavariate<br>from graphviz import Digraph<br><br>from markovfsm import Chain<br>from markovfsm.plot import transitions_to_graph<br><br><br>def rigged_dice():<br>    return int((betavariate(0.5, 0.7) * 6))<br><br>chain = Chain(6, rigged_dice())<br><br># roll dice many times to build Markov chain for this process<br>for i in range(100000):<br>    chain.learn(rigged_dice())<br>```<br><br>And then let's plot states transitions.<br>```python<br>def state_mapping(state):<br>    if state == 0: return u'\u2680'<br>    if state == 1: return u'\u2681'<br>    if state == 2: return u'\u2682'<br>    if state == 3: return u'\u2683'<br>    if state == 4: return u'\u2684'<br>    if state == 5: return u'\u2685'<br><br>g = Digraph(format='svg', engine='dot',<br>            graph_attr={'pad': '0.1', 'nodesep': '0.15', 'ranksep': '0.5'},<br>            edge_attr={'fontsize': '6.0', 'fontname':'Helvetica'})<br><br>transitions_to_graph(g, chain.transition_matrix(), state_mapping)<br>g.render('./graph')<br>```<br><br># Probabilistic finite-state machine<br>Finite-state machine (FSM, or state machine) is a model of computation.<br>The machine can be in exactly one of finite number of states.<br>Probabilistic automaton is a FSM where transitions between states are probabilistic.<br>Unlike normal FSM, requiring only a graph of possible transitions between states,<br>probabilistic automaton adds probability of every transition.<br>```python<br>from random import random<br><br># build Markov chain with 2 states, init with random state<br>chain = Chain(2, 0 if random() &gt; 0.5 else 1)<br><br># flip coin many times and build Markov chain for this process<br># let 0 be heads and 1 tails<br>for i in range(1000000):<br>    chain.learn(0 if random() &gt; 0.5 else 1)<br><br># get transition matrix<br>#   It should look like:<br>#<br>#    P = | 0.5 0.5 |<br>#        | 0.5 0.5 |<br>#<br>P = chain.transition_matrix()<br><br>print \"%s %s\" % (P[0][0], P[0][1])<br>print \"%s %s\" % (P[1][0], P[1][1])<br><br># get probabilities of transition from state 0 to other states (0 and 1)<br># actually, the line in the transition matrix<br>print chain.get_transitions_probs(0)<br><br># let's make a FSM with stochastic properties equal to described by Markov chain<br># use rnd() as a random numbers generator, and 0 (heads) as initial state<br>fsm = FSM(chain, 0)<br><br>fsm.next()  # will change the state of automaton randomly in a such way that<br>            # the statistics of such transition will be equal to Markov process<br>            # statistics<br>```<br><br># API<br>`chain.transition_matrix()` will return transition matrix: a matrix N x N,<br>where N is the number of states, where each i-row correspond to the state of the process<br>and each j-element in the row contains the probability of transition to state ``j``<br>from the state ``i``.<br><br>`chain.learn(state)` will learn Markov chain from new `state` transition<br><br>`FSM(chain, initial_state)` - object, representing probabilistic automaton,<br>built from `chain` in state `initial_state`<br><br><br># License<br>MIT License. Creative Commons CC0.<br><br><br>News<br>====<br><br>0.2<br>---<br><br>*Release date: 25-Mar-2019*<br><br>* Updated usage information and added illustrations<br>* Better documentation<br><br><br>0.1<br>---<br><br>*Release date: 20-Dec-2017*<br><br>* Initial release\n          </div>"}, "last_serial": 4982232, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "f0c796d5a3c84bf932d13f972bb938ce", "sha256": "84b6dbcdaa7e63c676f577e58e3c8b3303c3607e93466ed81ce313d02a0c9852"}, "downloads": -1, "filename": "markovfsm-0.1.tar.gz", "has_sig": false, "md5_digest": "f0c796d5a3c84bf932d13f972bb938ce", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5270, "upload_time": "2017-12-19T23:58:35", "upload_time_iso_8601": "2017-12-19T23:58:35.196282Z", "url": "https://files.pythonhosted.org/packages/ae/42/031174a2db7afbca2f955f7d24bfb0e9b742703041b9aa22a723b1d76261/markovfsm-0.1.tar.gz", "yanked": false}], "0.1a": [{"comment_text": "", "digests": {"md5": "55a4819e2642de8d738accd7dfaf13a1", "sha256": "9fda512b67a4f510d4c6dd88f667025d29ccfc2cf8128801d5b76d8958b506ee"}, "downloads": -1, "filename": "markovfsm-0.1a.tar.gz", "has_sig": false, "md5_digest": "55a4819e2642de8d738accd7dfaf13a1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5285, "upload_time": "2017-12-20T00:01:56", "upload_time_iso_8601": "2017-12-20T00:01:56.535277Z", "url": "https://files.pythonhosted.org/packages/09/93/cd709e86c192ef2bcf7cd35b004b999e62c3db8efa69efa65495aee1acc7/markovfsm-0.1a.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "fbe71052894116b531de14a072e9d761", "sha256": "fdf539273a30a1802bac7c08765cd8504669411fe04a4dd7de05ff2408b3100d"}, "downloads": -1, "filename": "markovfsm-0.2.tar.gz", "has_sig": false, "md5_digest": "fbe71052894116b531de14a072e9d761", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5325, "upload_time": "2019-03-25T12:33:11", "upload_time_iso_8601": "2019-03-25T12:33:11.103686Z", "url": "https://files.pythonhosted.org/packages/d5/ba/22303ebb1fcceab0f649ae9489beab8a11cf582aa24063748aae3a2f4b04/markovfsm-0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "fbe71052894116b531de14a072e9d761", "sha256": "fdf539273a30a1802bac7c08765cd8504669411fe04a4dd7de05ff2408b3100d"}, "downloads": -1, "filename": "markovfsm-0.2.tar.gz", "has_sig": false, "md5_digest": "fbe71052894116b531de14a072e9d761", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5325, "upload_time": "2019-03-25T12:33:11", "upload_time_iso_8601": "2019-03-25T12:33:11.103686Z", "url": "https://files.pythonhosted.org/packages/d5/ba/22303ebb1fcceab0f649ae9489beab8a11cf582aa24063748aae3a2f4b04/markovfsm-0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:57:41 2020"}