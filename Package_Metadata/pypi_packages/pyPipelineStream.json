{"info": {"author": "daniyall", "author_email": "daniyal.l@outlook.com", "bugtrack_url": null, "classifiers": [], "description": "A pipelining framework for Python. Developers can create nodes and chain them together to create pipelines. \n\nClasses that extend ```Node``` must implement ```run``` method that will be called whenever new data is available.  \n\nA simple example\n\n```python\nfrom pyPipelining import Node, Pipeline\n\nclass Generate(Node):\n    def setup(self):\n        self.pos = 0\n\n    def run(self, data):\n        if self.pos < self.size:\n            self.emit(self.pos)\n            self.pos = self.pos + 1\n        else:\n            self.close()\n\nclass Square(Node):\n    def run(self, data):\n        self.emit(data**2)\n\n\npipeline = Pipeline(Generate(\"gen\", size=10) | Square(\"square\"))\nprint(pipeline)\npipeline.run()\n```\n\nNodes can also specify a batch size that dictates how much data should be pushed to the node.\nFor example, building on the previous example. In this case ```batch_size``` is specified in the nodes ```setup``` method. Alternatively, it can be set when creating the node (ex. ```Printer(\"print\", batch_size=5)```)\n\n```python\nclass Printer(Node):\n    def setup(self):\n        self.batch_size = Node.BATCH_SIZE_ALL\n\n    def run(self, data):\n        print(data)\n\npipeline = Pipeline(Generate(\"gen\", size=10) | Square(\"square\") | Printer(\"print\"))\nprint(pipeline)\npipeline.run()\n```", "description_content_type": null, "docs_url": null, "download_url": "https://github.com/daniyall/pyPipelining/archive/0.2.0.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/daniyall/pyPipelining", "keywords": "data-science,pipelining,stream-processing,data-analysis", "license": "LICENSE.txt", "maintainer": "", "maintainer_email": "", "name": "pyPipelineStream", "package_url": "https://pypi.org/project/pyPipelineStream/", "platform": "", "project_url": "https://pypi.org/project/pyPipelineStream/", "project_urls": {"Download": "https://github.com/daniyall/pyPipelining/archive/0.2.0.tar.gz", "Homepage": "https://github.com/daniyall/pyPipelining"}, "release_url": "https://pypi.org/project/pyPipelineStream/0.2.0/", "requires_dist": null, "requires_python": "", "summary": "A pipelining framework designed for data analysis but can be useful to other applications", "version": "0.2.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            A pipelining framework for Python. Developers can create nodes and chain them together to create pipelines. <br><br>Classes that extend ```Node``` must implement ```run``` method that will be called whenever new data is available.  <br><br>A simple example<br><br>```python<br>from pyPipelining import Node, Pipeline<br><br>class Generate(Node):<br>    def setup(self):<br>        self.pos = 0<br><br>    def run(self, data):<br>        if self.pos &lt; self.size:<br>            self.emit(self.pos)<br>            self.pos = self.pos + 1<br>        else:<br>            self.close()<br><br>class Square(Node):<br>    def run(self, data):<br>        self.emit(data**2)<br><br><br>pipeline = Pipeline(Generate(\"gen\", size=10) | Square(\"square\"))<br>print(pipeline)<br>pipeline.run()<br>```<br><br>Nodes can also specify a batch size that dictates how much data should be pushed to the node.<br>For example, building on the previous example. In this case ```batch_size``` is specified in the nodes ```setup``` method. Alternatively, it can be set when creating the node (ex. ```Printer(\"print\", batch_size=5)```)<br><br>```python<br>class Printer(Node):<br>    def setup(self):<br>        self.batch_size = Node.BATCH_SIZE_ALL<br><br>    def run(self, data):<br>        print(data)<br><br>pipeline = Pipeline(Generate(\"gen\", size=10) | Square(\"square\") | Printer(\"print\"))<br>print(pipeline)<br>pipeline.run()<br>```\n          </div>"}, "last_serial": 3469411, "releases": {"0.2.0": [{"comment_text": "", "digests": {"md5": "d884607eb6cb7b6af721cf150ffe030f", "sha256": "cc4e78a2daca2575457a16794adf872421bfa6a9572e4066b4490bae3feb6072"}, "downloads": -1, "filename": "pyPipelineStream-0.2.0.tar.gz", "has_sig": false, "md5_digest": "d884607eb6cb7b6af721cf150ffe030f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2870, "upload_time": "2018-01-07T19:59:18", "upload_time_iso_8601": "2018-01-07T19:59:18.522831Z", "url": "https://files.pythonhosted.org/packages/11/28/f56f0e1025e7cbceca320d2b1727cdf0bbbb57c9a66f2ef1f426bdbe0f1c/pyPipelineStream-0.2.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "d884607eb6cb7b6af721cf150ffe030f", "sha256": "cc4e78a2daca2575457a16794adf872421bfa6a9572e4066b4490bae3feb6072"}, "downloads": -1, "filename": "pyPipelineStream-0.2.0.tar.gz", "has_sig": false, "md5_digest": "d884607eb6cb7b6af721cf150ffe030f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2870, "upload_time": "2018-01-07T19:59:18", "upload_time_iso_8601": "2018-01-07T19:59:18.522831Z", "url": "https://files.pythonhosted.org/packages/11/28/f56f0e1025e7cbceca320d2b1727cdf0bbbb57c9a66f2ef1f426bdbe0f1c/pyPipelineStream-0.2.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:59:30 2020"}