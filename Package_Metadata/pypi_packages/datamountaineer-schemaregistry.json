{"info": {"author": "DataMountaineer", "author_email": "andrew@datamountaineer.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "License :: OSI Approved :: Apache Software License", "Operating System :: OS Independent", "Programming Language :: Python", "Topic :: Software Development :: Libraries"], "description": "[![Build Status](https://travis-ci.org/datamountaineer/python-serializers.svg?branch=master)](https://travis-ci.org/datamountaineer/python-serializers)\n[![PyPI](https://img.shields.io/badge/PyPi-0.3-blue.svg)](https://pypi.python.org/pypi/datamountaineer-schemaregistry/0.3)\n\n# Python Schema Registry Client and Serializers/Deserializers\n\nA Python client used to interact with [Confluent](http://confluent.io/)'s\n[schema registry](https://github.com/confluentinc/schema-registry).  Supports Python 3.5.  This also works within a virtual env.\n\nThe API is heavily based off of the existing Java API of [Confluent schema registry](https://github.com/confluentinc/schema-registry).\n\nThe serializers/deserializers use [fastavro](https://github.com/tebeka/fastavro) for reading and writing by default.\nWhen one does not want to use `fastavro`, it can be disabled by providing `fast_avro=False` to the `MessageSerializer` constructor and Apache Avro's `avro` package will be used instead.\n\n# Installation\n\nRun `python setup.py install` from the source root.\n\nor via pip\n\n```\npip3 install datamountaineer-schemaregistry \n```\n\n# Example Usage\n\nSetup\n\n```python\nfrom datamountaineer.schemaregistry.client import SchemaRegistryClient\nfrom datamountaineer.schemaregistry.serializers import MessageSerializer, Util\n\n# Initialize the client\nclient = SchemaRegistryClient(url='http://registry.host')\n```\n\nSchema operations\n\n```python\n# register a schema for a subject\nschema_id = client.register('my_subject', avro_schema)\n\n# fetch a schema by ID\navro_schema = client.get_by_id(schema_id)\n\n# get the latest schema info for a subject\nschema_id,avro_schema,schema_version = client.get_latest_schema('my_subject')\n\n# get the version of a schema\nschema_version = client.get_version('my_subject', avro_schema)\n\n# Compatibility tests\nis_compatible = client.test_compatibility('my_subject', another_schema)\n\n# One of NONE, FULL, FORWARD, BACKWARD\nnew_level = client.update_compatibility('NONE','my_subject')\ncurrent_level = client.get_compatibility('my_subject')\n```\n\nEncoding to write back to Kafka. Encoding by id is the most efficent as it avoids an extra trip to the Schema Registry to\nlookup the schema id.\n\n```python\n# Message operations\n\n# encode a record to put onto kafka\nserializer = MessageSerializer(client)\n\n#build your avro\nrecord = get_obj_to_put_into_kafka()\n\n# use the schema id directly\nencoded = serializer.encode_record_with_schema_id(schema_id, record)\n```\n\nEncode by schema only.\n\n```python\n# use an existing schema and topic\n# this will register the schema to the right subject based\n# on the topic name and then serialize\nencoded = serializer.encode_record_with_schema('my_topic', avro_schema, record)\n```\n\nReading messages\n\n```python\n# decode a message from kafka\nmessage = get_message_from_kafka()\ndecoded_object = serializer.decode_message(message)\n```\n# Release Notes\n\n**0.3**\n* Testing, setup, and import improvements from PR #4\n\n# Testing\n\n```\npip3 install pytest mock\npy.test -s -rxs -v\n```\n\n\n\n# License\n\nThe project is licensed under the Apache 2 license.", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/datamountaineer/python-serializers", "keywords": "datamountaineer schema registry schemaregistry confluent avro", "license": "Apache 2.0", "maintainer": null, "maintainer_email": null, "name": "datamountaineer-schemaregistry", "package_url": "https://pypi.org/project/datamountaineer-schemaregistry/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/datamountaineer-schemaregistry/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/datamountaineer/python-serializers"}, "release_url": "https://pypi.org/project/datamountaineer-schemaregistry/0.3/", "requires_dist": null, "requires_python": null, "summary": "DataMountaineer Python 3 Confluent Schema Registry Client", "version": "0.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            [![Build Status](https://travis-ci.org/datamountaineer/python-serializers.svg?branch=master)](https://travis-ci.org/datamountaineer/python-serializers)<br>[![PyPI](https://img.shields.io/badge/PyPi-0.3-blue.svg)](https://pypi.python.org/pypi/datamountaineer-schemaregistry/0.3)<br><br># Python Schema Registry Client and Serializers/Deserializers<br><br>A Python client used to interact with [Confluent](http://confluent.io/)'s<br>[schema registry](https://github.com/confluentinc/schema-registry).  Supports Python 3.5.  This also works within a virtual env.<br><br>The API is heavily based off of the existing Java API of [Confluent schema registry](https://github.com/confluentinc/schema-registry).<br><br>The serializers/deserializers use [fastavro](https://github.com/tebeka/fastavro) for reading and writing by default.<br>When one does not want to use `fastavro`, it can be disabled by providing `fast_avro=False` to the `MessageSerializer` constructor and Apache Avro's `avro` package will be used instead.<br><br># Installation<br><br>Run `python setup.py install` from the source root.<br><br>or via pip<br><br>```<br>pip3 install datamountaineer-schemaregistry <br>```<br><br># Example Usage<br><br>Setup<br><br>```python<br>from datamountaineer.schemaregistry.client import SchemaRegistryClient<br>from datamountaineer.schemaregistry.serializers import MessageSerializer, Util<br><br># Initialize the client<br>client = SchemaRegistryClient(url='http://registry.host')<br>```<br><br>Schema operations<br><br>```python<br># register a schema for a subject<br>schema_id = client.register('my_subject', avro_schema)<br><br># fetch a schema by ID<br>avro_schema = client.get_by_id(schema_id)<br><br># get the latest schema info for a subject<br>schema_id,avro_schema,schema_version = client.get_latest_schema('my_subject')<br><br># get the version of a schema<br>schema_version = client.get_version('my_subject', avro_schema)<br><br># Compatibility tests<br>is_compatible = client.test_compatibility('my_subject', another_schema)<br><br># One of NONE, FULL, FORWARD, BACKWARD<br>new_level = client.update_compatibility('NONE','my_subject')<br>current_level = client.get_compatibility('my_subject')<br>```<br><br>Encoding to write back to Kafka. Encoding by id is the most efficent as it avoids an extra trip to the Schema Registry to<br>lookup the schema id.<br><br>```python<br># Message operations<br><br># encode a record to put onto kafka<br>serializer = MessageSerializer(client)<br><br>#build your avro<br>record = get_obj_to_put_into_kafka()<br><br># use the schema id directly<br>encoded = serializer.encode_record_with_schema_id(schema_id, record)<br>```<br><br>Encode by schema only.<br><br>```python<br># use an existing schema and topic<br># this will register the schema to the right subject based<br># on the topic name and then serialize<br>encoded = serializer.encode_record_with_schema('my_topic', avro_schema, record)<br>```<br><br>Reading messages<br><br>```python<br># decode a message from kafka<br>message = get_message_from_kafka()<br>decoded_object = serializer.decode_message(message)<br>```<br># Release Notes<br><br>**0.3**<br>* Testing, setup, and import improvements from PR #4<br><br># Testing<br><br>```<br>pip3 install pytest mock<br>py.test -s -rxs -v<br>```<br><br><br><br># License<br><br>The project is licensed under the Apache 2 license.\n          </div>"}, "last_serial": 2466450, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "8e739ab4dc5acaba720c9fef78e31c98", "sha256": "d88059ba052fb8b2117a951b749cda4b776656abf9c0d03a69f5f4a4d20de2e7"}, "downloads": -1, "filename": "datamountaineer-schemaregistry-0.1.tar.gz", "has_sig": false, "md5_digest": "8e739ab4dc5acaba720c9fef78e31c98", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7332, "upload_time": "2016-08-24T20:22:35", "upload_time_iso_8601": "2016-08-24T20:22:35.665836Z", "url": "https://files.pythonhosted.org/packages/2a/4a/c82ab858086afde4751dc056f9f87b52a182908ce49a4f0945eac79c5b07/datamountaineer-schemaregistry-0.1.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "ee47bb5e58103c3d4661f3ce114862bb", "sha256": "f8e9098ac4390248261578dbd452791054da17fffb1a787673a7dce75a893b96"}, "downloads": -1, "filename": "datamountaineer-schemaregistry-0.2.tar.gz", "has_sig": false, "md5_digest": "ee47bb5e58103c3d4661f3ce114862bb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6740, "upload_time": "2016-09-02T09:32:14", "upload_time_iso_8601": "2016-09-02T09:32:14.060276Z", "url": "https://files.pythonhosted.org/packages/51/dc/d10eac50a1a3eb71e04c2929b29e79cea5aee9a1462a3cf00e77188d2e08/datamountaineer-schemaregistry-0.2.tar.gz", "yanked": false}], "0.3": [{"comment_text": "", "digests": {"md5": "5e2e5bab34ffbbda662ae7909672e334", "sha256": "15ac3c28499322f3d68454f276d4b64745b835fddd78919f1210ff44f8d48345"}, "downloads": -1, "filename": "datamountaineer-schemaregistry-0.3.tar.gz", "has_sig": false, "md5_digest": "5e2e5bab34ffbbda662ae7909672e334", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10487, "upload_time": "2016-11-17T14:38:28", "upload_time_iso_8601": "2016-11-17T14:38:28.123346Z", "url": "https://files.pythonhosted.org/packages/67/8c/9a7f76c012b42933fb221959bb015589623c9fe8db707800d9a9524a84e3/datamountaineer-schemaregistry-0.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "5e2e5bab34ffbbda662ae7909672e334", "sha256": "15ac3c28499322f3d68454f276d4b64745b835fddd78919f1210ff44f8d48345"}, "downloads": -1, "filename": "datamountaineer-schemaregistry-0.3.tar.gz", "has_sig": false, "md5_digest": "5e2e5bab34ffbbda662ae7909672e334", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10487, "upload_time": "2016-11-17T14:38:28", "upload_time_iso_8601": "2016-11-17T14:38:28.123346Z", "url": "https://files.pythonhosted.org/packages/67/8c/9a7f76c012b42933fb221959bb015589623c9fe8db707800d9a9524a84e3/datamountaineer-schemaregistry-0.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:40:19 2020"}