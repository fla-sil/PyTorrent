{"info": {"author": "Jeremy Howard", "author_email": "info@fast.ai", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Intended Audience :: Developers", "License :: OSI Approved :: Apache Software License", "Natural Language :: English", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "[![Build Status](https://dev.azure.com/fastdotai/fastai/_apis/build/status/fastai.fastai)](https://dev.azure.com/fastdotai/fastai/_build/latest?definitionId=1)\n[![pypi fastai version](https://img.shields.io/pypi/v/fastai.svg)](https://pypi.python.org/pypi/fastai)\n[![Conda fastai version](https://img.shields.io/conda/v/fastai/fastai.svg)](https://anaconda.org/fastai/fastai)\n\n[![Anaconda-Server Badge](https://anaconda.org/fastai/fastai/badges/platforms.svg)](https://anaconda.org/fastai/fastai)\n[![fastai python compatibility](https://img.shields.io/pypi/pyversions/fastai.svg)](https://pypi.python.org/pypi/fastai)\n[![fastai license](https://img.shields.io/pypi/l/fastai.svg)](https://pypi.python.org/pypi/fastai)\n\n# fastai\n\nThe fastai library simplifies training fast and accurate neural nets using modern best practices. See the [fastai website](https://docs.fast.ai) to get started. The library is based on research into deep learning best practices undertaken at [fast.ai](http://www.fast.ai), and includes \\\"out of the box\\\" support for [`vision`](https://docs.fast.ai/vision.html#vision), [`text`](https://docs.fast.ai/text.html#text), [`tabular`](https://docs.fast.ai/tabular.html#tabular), and [`collab`](https://docs.fast.ai/collab.html#collab) (collaborative filtering) models. For brief examples, see the [examples](https://github.com/fastai/fastai/tree/master/examples) folder; detailed examples are provided in the full [documentation](https://docs.fast.ai/). For instance, here's how to train an MNIST model using [resnet18](https://arxiv.org/abs/1512.03385) (from the [vision example](https://github.com/fastai/fastai/blob/master/examples/vision.ipynb)):\n\n```python\nuntar_data(MNIST_PATH)\ndata = image_data_from_folder(MNIST_PATH)\nlearn = cnn_learner(data, tvm.resnet18, metrics=accuracy)\nlearn.fit(1)\n```\n\n## Note for [course.fast.ai](http://course.fast.ai) students\n\nThis document is written for `fastai v1`, which we use for the current, third version of part 1 of the [course.fast.ai](http://course.fast.ai) deep learning course. If you're following along with a course at [course18.fast.ai](http://course18.fast.ai)&mdash;that is, part 2 of the deep learning course, or the machine learning course (which aren't yet updated for v1)&mdash;you need to use `fastai 0.7`;  please follow the installation instructions [here](https://forums.fast.ai/t/fastai-v0-install-issues-thread/24652).\n\n*Note: If you want to dive deep into fastai, Jeremy Howard, its lead developer, will be showing internals and advanced features in [Deep Learning Part II](https://www.usfca.edu/data-institute/certificates/deep-learning-part-two) at the University of San Francisco from March 18th, 2018.*\n\n## Installation\n\n**NB:** *fastai v1 currently supports Linux only, and requires **PyTorch v1** and **Python 3.6** or later. Windows support is at an experimental stage: it should work fine but we haven't thoroughly tested it. Since Macs don't currently have good Nvidia GPU support, we do not currently prioritize Mac development.*\n\n`fastai-1.x` can be installed with either `conda` or `pip` package managers and also from source. At the moment you can't just run *install*, since you first need to get the correct `pytorch` version installed - thus to get `fastai-1.x` installed choose one of the installation recipes below using your favorite python package manager. Note that **PyTorch v1** and **Python 3.6** are the minimal version requirements.\n\nIt's highly recommended you install `fastai` and its dependencies in a virtual environment ([`conda`](https://conda.io/docs/user-guide/tasks/manage-environments.html) or others), so that you don't interfere with system-wide python packages. It's not that you must, but if you experience problems with any dependency packages, please consider using a fresh virtual environment just for `fastai`.\n\nStarting with pytorch-1.x you no longer need to install a special pytorch-cpu version. Instead use the normal pytorch and it works with and without GPU. But [you can install the cpu build too](https://docs.fast.ai/install.html#cpu-build).\n\nIf you experience installation problems, please read about [installation issues](https://github.com/fastai/fastai/blob/master/README.md#installation-issues).\n\nIf you are planning on using `fastai` in the jupyter notebook environment, make sure to also install the corresponding [packages](https://docs.fast.ai/install.html#jupyter-notebook-dependencies).\n\nMore advanced installation issues, such as installing only partial dependencies are covered in a dedicated [installation doc](https://docs.fast.ai/install.html).\n\n### Conda Install\n\n```bash\nconda install -c pytorch -c fastai fastai\n```\n\nThis will install the `pytorch` build with the latest `cudatoolkit` version. If you need a higher or lower `CUDA XX` build (e.g. CUDA 9.0), following the instructions [here](https://pytorch.org/get-started/locally/), to install the desired `pytorch` build.\n\nNote that JPEG decoding can be a bottleneck, particularly if you have a fast GPU. You can optionally install an optimized JPEG decoder as follows (Linux):\n\n```bash\nconda uninstall --force jpeg libtiff -y\nconda install -c conda-forge libjpeg-turbo\nCC=\"cc -mavx2\" pip install --no-cache-dir -U --force-reinstall --no-binary :all: --compile pillow-simd\n```\nIf you only care about faster JPEG decompression, it can be `pillow` or `pillow-simd` in the last command above, the latter speeds up other image processing operations. For the full story see [Pillow-SIMD](https://docs.fast.ai/performance.html#faster-image-processing).\n\n### PyPI Install\n\n```bash\npip install fastai\n```\n\nBy default pip will install the latest `pytorch` with the latest `cudatoolkit`. If your hardware doesn't support the latest `cudatoolkit`, follow the instructions [here](https://pytorch.org/get-started/locally/), to install a `pytorch` build that fits your hardware.\n\n### Bug Fix Install\n\nIf a bug fix was made in git and you can't wait till a new release is made, you can install the bleeding edge version of `fastai` with:\n\n```\npip install git+https://github.com/fastai/fastai.git\n```\n\n### Developer Install\n\nThe following instructions will result in a [pip editable install](https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs), so that you can `git pull` at any time and your environment will automatically get the updates:\n\n```bash\ngit clone https://github.com/fastai/fastai\ncd fastai\ntools/run-after-git-clone\npip install -e \".[dev]\"\n```\n\nNext, you can test that the build works by starting the jupyter notebook:\n\n```bash\njupyter notebook\n```\nand executing an example notebook. For example load `examples/tabular.ipynb` and run it.\n\nPlease refer to [CONTRIBUTING.md](https://github.com/fastai/fastai/blob/master/CONTRIBUTING.md) and [Notes For Developers](https://docs.fast.ai/dev/develop.html) for more details on how to contribute to the `fastai` project.\n\n\n\n\n### Building From Source\n\nIf for any reason you can't use the prepackaged packages and have to build from source, this section is for you.\n\n1. To build `pytorch` from source follow the [complete instructions](https://github.com/pytorch/pytorch#from-source). Remember to first install CUDA, CuDNN, and other required libraries as suggested - everything will be very slow without those libraries built into `pytorch`.\n\n2. Next, you will also need to build `torchvision` from source:\n\n   ```bash\n   git clone https://github.com/pytorch/vision\n   cd vision\n   python setup.py install\n   ```\n\n3. When both `pytorch` and `torchvision` are installed, first test that you can load each of these libraries:\n\n   ```bash\n   import torch\n   import torchvision\n   ```\n\n   to validate that they were installed correctly\n\n   Finally, proceed with `fastai` installation as normal, either through prepackaged pip or conda builds or installing from source (\"the developer install\") as explained in the sections above.\n\n\n\n## Installation Issues\n\nIf the installation process fails, first make sure [your system is supported](https://github.com/fastai/fastai/blob/master/README.md#is-my-system-supported). And if the problem is still not addressed, please refer to the [troubleshooting document](https://docs.fast.ai/troubleshoot.html).\n\nIf you encounter installation problems with conda, make sure you have the latest `conda` client (`conda install` will do an update too):\n```bash\nconda install conda\n```\n\n### Is My System Supported?\n\n1. Python: You need to have python 3.6 or higher\n\n2. CPU or GPU\n\n   The `pytorch` binary package comes with its own CUDA, CuDNN, NCCL, MKL, and other libraries so you don't have to install system-wide NVIDIA's CUDA and related libraries if you don't need them for something else. If you have them installed already it doesn't matter which NVIDIA's CUDA version library you have installed system-wide. Your system could have CUDA 9.0 libraries, and you can still use `pytorch` build with CUDA 10.0 libraries without any problem, since the `pytorch` binary package is self-contained.\n\n   The only requirement is that you have installed and configured the NVIDIA driver correctly. Usually you can test that by running `nvidia-smi`. While it's possible that this application is not available on your system, it's very likely that if it doesn't work, than your don't have your NVIDIA drivers configured properly. And remember that a reboot is always required after installing NVIDIA drivers.\n\n3. Operating System:\n\n   Since fastai-1.0 relies on pytorch-1.0, you need to be able to install pytorch-1.0 first.\n\n   As of this moment pytorch.org's 1.0 version supports:\n\n    | Platform | GPU    | CPU    |\n    |----------|--------|--------|\n    | linux    | binary | binary |\n    | mac      | source | binary |\n    | windows  | binary | binary |\n\n   Legend: `binary` = can be installed directly, `source` = needs to be built from source.\n\n   If there is no `pytorch` preview conda or pip package available for your system, you may still be able to [build it from source](https://pytorch.org/get-started/locally/).\n\n4. How do you know which pytorch cuda version build to choose?\n\n   It depends on the version of the installed NVIDIA driver. Here are the requirements for CUDA versions supported by pre-built `pytorch` releases:\n\n    | CUDA Toolkit | NVIDIA (Linux x86_64) |\n    |--------------|-----------------------|\n    | CUDA 10.0    | >= 410.00             |\n    | CUDA 9.0     | >= 384.81             |\n    | CUDA 8.0     | >= 367.48             |\n\n   So if your NVIDIA driver is less than 384, then you can only use CUDA 8.0. Of course, you can upgrade your drivers to more recent ones if your card supports it.\n\n   You can find a complete table with all variations [here](https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html).\n\n   If you use NVIDIA driver 410+, you most likely want to install the `cudatoolkit=10.0` pytorch variant, via:\n   ```bash\n   conda install -c pytorch pytorch cudatoolkit=10.0\n   ```\n   or if you need a lower version, use one of:\n   ```bash\n   conda install -c pytorch pytorch cudatoolkit=8.0\n   conda install -c pytorch pytorch cudatoolkit=9.0\n   ```\n   For other options refer to the complete list of [the available pytorch variants](https://pytorch.org/get-started/locally/).\n\n## Updates\n\nIn order to update your environment, simply install `fastai` in exactly the same way you did the initial installation.\n\nTop level files `environment.yml` and `environment-cpu.yml` belong to the old fastai (0.7). `conda env update` is no longer the way to update your `fastai-1.x` environment. These files remain because the fastai course-v2 video instructions rely on this setup. Eventually, once fastai course-v3 p1 and p2 will be completed, they will probably be moved to where they belong - under `old/`.\n\n## Contribution guidelines\n\nIf you want to contribute to `fastai`, be sure to review the [contribution guidelines](https://github.com/fastai/fastai/blob/master/CONTRIBUTING.md). This project adheres to fastai's [code of conduct](https://github.com/fastai/fastai/blob/master/CODE-OF-CONDUCT.md). By participating, you are expected to uphold this code.\n\nWe use GitHub issues for tracking requests and bugs, so please see [fastai forum](https://forums.fast.ai/) for general questions and discussion.\n\nThe fastai project strives to abide by generally accepted best practices in open-source software development:\n\n## History\n\nA detailed history of changes can be found [here](https://github.com/fastai/fastai/blob/master/CHANGES.md).\n\n## Copyright\n\nCopyright 2017 onwards, fast.ai, Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this project's files except in compliance with the License. A copy of the License is provided in the LICENSE file in this repository.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/H4dr1en/fastai/archive/v0.5-alpha.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/H4dr1en/fastai", "keywords": "fastai,deep learning,machine learning", "license": "Apache Software License 2.0", "maintainer": "", "maintainer_email": "", "name": "fastai-bottleneck-1-1-1", "package_url": "https://pypi.org/project/fastai-bottleneck-1-1-1/", "platform": "", "project_url": "https://pypi.org/project/fastai-bottleneck-1-1-1/", "project_urls": {"Download": "https://github.com/H4dr1en/fastai/archive/v0.5-alpha.tar.gz", "Homepage": "https://github.com/H4dr1en/fastai"}, "release_url": "https://pypi.org/project/fastai-bottleneck-1-1-1/0.5a0/", "requires_dist": null, "requires_python": ">=3.6", "summary": "This is not the official fastai package.", "version": "0.5a0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://dev.azure.com/fastdotai/fastai/_build/latest?definitionId=1\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d7fd9978b3b9338bd8306010240178a3b6fdf9bc/68747470733a2f2f6465762e617a7572652e636f6d2f66617374646f7461692f6661737461692f5f617069732f6275696c642f7374617475732f6661737461692e666173746169\"></a>\n<a href=\"https://pypi.python.org/pypi/fastai\" rel=\"nofollow\"><img alt=\"pypi fastai version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/26d07987bbc3673724cd93774654345906a79af4/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6661737461692e737667\"></a>\n<a href=\"https://anaconda.org/fastai/fastai\" rel=\"nofollow\"><img alt=\"Conda fastai version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8db121ba4c127098c65659f8dafa4126582295e3/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f762f6661737461692f6661737461692e737667\"></a></p>\n<p><a href=\"https://anaconda.org/fastai/fastai\" rel=\"nofollow\"><img alt=\"Anaconda-Server Badge\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e48fd46d01a94c80e38abeb5d50aef92d59ad3c9/68747470733a2f2f616e61636f6e64612e6f72672f6661737461692f6661737461692f6261646765732f706c6174666f726d732e737667\"></a>\n<a href=\"https://pypi.python.org/pypi/fastai\" rel=\"nofollow\"><img alt=\"fastai python compatibility\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/db74c54f5410a0308d215f725e3002719dbde979/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f6661737461692e737667\"></a>\n<a href=\"https://pypi.python.org/pypi/fastai\" rel=\"nofollow\"><img alt=\"fastai license\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d03e179543e86c87f98d260a4e84fb49ba3f0d88/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f6661737461692e737667\"></a></p>\n<h1>fastai</h1>\n<p>The fastai library simplifies training fast and accurate neural nets using modern best practices. See the <a href=\"https://docs.fast.ai\" rel=\"nofollow\">fastai website</a> to get started. The library is based on research into deep learning best practices undertaken at <a href=\"http://www.fast.ai\" rel=\"nofollow\">fast.ai</a>, and includes \"out of the box\" support for <a href=\"https://docs.fast.ai/vision.html#vision\" rel=\"nofollow\"><code>vision</code></a>, <a href=\"https://docs.fast.ai/text.html#text\" rel=\"nofollow\"><code>text</code></a>, <a href=\"https://docs.fast.ai/tabular.html#tabular\" rel=\"nofollow\"><code>tabular</code></a>, and <a href=\"https://docs.fast.ai/collab.html#collab\" rel=\"nofollow\"><code>collab</code></a> (collaborative filtering) models. For brief examples, see the <a href=\"https://github.com/fastai/fastai/tree/master/examples\" rel=\"nofollow\">examples</a> folder; detailed examples are provided in the full <a href=\"https://docs.fast.ai/\" rel=\"nofollow\">documentation</a>. For instance, here's how to train an MNIST model using <a href=\"https://arxiv.org/abs/1512.03385\" rel=\"nofollow\">resnet18</a> (from the <a href=\"https://github.com/fastai/fastai/blob/master/examples/vision.ipynb\" rel=\"nofollow\">vision example</a>):</p>\n<pre><span class=\"n\">untar_data</span><span class=\"p\">(</span><span class=\"n\">MNIST_PATH</span><span class=\"p\">)</span>\n<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">image_data_from_folder</span><span class=\"p\">(</span><span class=\"n\">MNIST_PATH</span><span class=\"p\">)</span>\n<span class=\"n\">learn</span> <span class=\"o\">=</span> <span class=\"n\">cnn_learner</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">tvm</span><span class=\"o\">.</span><span class=\"n\">resnet18</span><span class=\"p\">,</span> <span class=\"n\">metrics</span><span class=\"o\">=</span><span class=\"n\">accuracy</span><span class=\"p\">)</span>\n<span class=\"n\">learn</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</pre>\n<h2>Note for <a href=\"http://course.fast.ai\" rel=\"nofollow\">course.fast.ai</a> students</h2>\n<p>This document is written for <code>fastai v1</code>, which we use for the current, third version of part 1 of the <a href=\"http://course.fast.ai\" rel=\"nofollow\">course.fast.ai</a> deep learning course. If you're following along with a course at <a href=\"http://course18.fast.ai\" rel=\"nofollow\">course18.fast.ai</a>\u2014that is, part 2 of the deep learning course, or the machine learning course (which aren't yet updated for v1)\u2014you need to use <code>fastai 0.7</code>;  please follow the installation instructions <a href=\"https://forums.fast.ai/t/fastai-v0-install-issues-thread/24652\" rel=\"nofollow\">here</a>.</p>\n<p><em>Note: If you want to dive deep into fastai, Jeremy Howard, its lead developer, will be showing internals and advanced features in <a href=\"https://www.usfca.edu/data-institute/certificates/deep-learning-part-two\" rel=\"nofollow\">Deep Learning Part II</a> at the University of San Francisco from March 18th, 2018.</em></p>\n<h2>Installation</h2>\n<p><strong>NB:</strong> <em>fastai v1 currently supports Linux only, and requires <strong>PyTorch v1</strong> and <strong>Python 3.6</strong> or later. Windows support is at an experimental stage: it should work fine but we haven't thoroughly tested it. Since Macs don't currently have good Nvidia GPU support, we do not currently prioritize Mac development.</em></p>\n<p><code>fastai-1.x</code> can be installed with either <code>conda</code> or <code>pip</code> package managers and also from source. At the moment you can't just run <em>install</em>, since you first need to get the correct <code>pytorch</code> version installed - thus to get <code>fastai-1.x</code> installed choose one of the installation recipes below using your favorite python package manager. Note that <strong>PyTorch v1</strong> and <strong>Python 3.6</strong> are the minimal version requirements.</p>\n<p>It's highly recommended you install <code>fastai</code> and its dependencies in a virtual environment (<a href=\"https://conda.io/docs/user-guide/tasks/manage-environments.html\" rel=\"nofollow\"><code>conda</code></a> or others), so that you don't interfere with system-wide python packages. It's not that you must, but if you experience problems with any dependency packages, please consider using a fresh virtual environment just for <code>fastai</code>.</p>\n<p>Starting with pytorch-1.x you no longer need to install a special pytorch-cpu version. Instead use the normal pytorch and it works with and without GPU. But <a href=\"https://docs.fast.ai/install.html#cpu-build\" rel=\"nofollow\">you can install the cpu build too</a>.</p>\n<p>If you experience installation problems, please read about <a href=\"https://github.com/fastai/fastai/blob/master/README.md#installation-issues\" rel=\"nofollow\">installation issues</a>.</p>\n<p>If you are planning on using <code>fastai</code> in the jupyter notebook environment, make sure to also install the corresponding <a href=\"https://docs.fast.ai/install.html#jupyter-notebook-dependencies\" rel=\"nofollow\">packages</a>.</p>\n<p>More advanced installation issues, such as installing only partial dependencies are covered in a dedicated <a href=\"https://docs.fast.ai/install.html\" rel=\"nofollow\">installation doc</a>.</p>\n<h3>Conda Install</h3>\n<pre>conda install -c pytorch -c fastai fastai\n</pre>\n<p>This will install the <code>pytorch</code> build with the latest <code>cudatoolkit</code> version. If you need a higher or lower <code>CUDA XX</code> build (e.g. CUDA 9.0), following the instructions <a href=\"https://pytorch.org/get-started/locally/\" rel=\"nofollow\">here</a>, to install the desired <code>pytorch</code> build.</p>\n<p>Note that JPEG decoding can be a bottleneck, particularly if you have a fast GPU. You can optionally install an optimized JPEG decoder as follows (Linux):</p>\n<pre>conda uninstall --force jpeg libtiff -y\nconda install -c conda-forge libjpeg-turbo\n<span class=\"nv\">CC</span><span class=\"o\">=</span><span class=\"s2\">\"cc -mavx2\"</span> pip install --no-cache-dir -U --force-reinstall --no-binary :all: --compile pillow-simd\n</pre>\n<p>If you only care about faster JPEG decompression, it can be <code>pillow</code> or <code>pillow-simd</code> in the last command above, the latter speeds up other image processing operations. For the full story see <a href=\"https://docs.fast.ai/performance.html#faster-image-processing\" rel=\"nofollow\">Pillow-SIMD</a>.</p>\n<h3>PyPI Install</h3>\n<pre>pip install fastai\n</pre>\n<p>By default pip will install the latest <code>pytorch</code> with the latest <code>cudatoolkit</code>. If your hardware doesn't support the latest <code>cudatoolkit</code>, follow the instructions <a href=\"https://pytorch.org/get-started/locally/\" rel=\"nofollow\">here</a>, to install a <code>pytorch</code> build that fits your hardware.</p>\n<h3>Bug Fix Install</h3>\n<p>If a bug fix was made in git and you can't wait till a new release is made, you can install the bleeding edge version of <code>fastai</code> with:</p>\n<pre><code>pip install git+https://github.com/fastai/fastai.git\n</code></pre>\n<h3>Developer Install</h3>\n<p>The following instructions will result in a <a href=\"https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs\" rel=\"nofollow\">pip editable install</a>, so that you can <code>git pull</code> at any time and your environment will automatically get the updates:</p>\n<pre>git clone https://github.com/fastai/fastai\n<span class=\"nb\">cd</span> fastai\ntools/run-after-git-clone\npip install -e <span class=\"s2\">\".[dev]\"</span>\n</pre>\n<p>Next, you can test that the build works by starting the jupyter notebook:</p>\n<pre>jupyter notebook\n</pre>\n<p>and executing an example notebook. For example load <code>examples/tabular.ipynb</code> and run it.</p>\n<p>Please refer to <a href=\"https://github.com/fastai/fastai/blob/master/CONTRIBUTING.md\" rel=\"nofollow\">CONTRIBUTING.md</a> and <a href=\"https://docs.fast.ai/dev/develop.html\" rel=\"nofollow\">Notes For Developers</a> for more details on how to contribute to the <code>fastai</code> project.</p>\n<h3>Building From Source</h3>\n<p>If for any reason you can't use the prepackaged packages and have to build from source, this section is for you.</p>\n<ol>\n<li>\n<p>To build <code>pytorch</code> from source follow the <a href=\"https://github.com/pytorch/pytorch#from-source\" rel=\"nofollow\">complete instructions</a>. Remember to first install CUDA, CuDNN, and other required libraries as suggested - everything will be very slow without those libraries built into <code>pytorch</code>.</p>\n</li>\n<li>\n<p>Next, you will also need to build <code>torchvision</code> from source:</p>\n<pre>git clone https://github.com/pytorch/vision\n<span class=\"nb\">cd</span> vision\npython setup.py install\n</pre>\n</li>\n<li>\n<p>When both <code>pytorch</code> and <code>torchvision</code> are installed, first test that you can load each of these libraries:</p>\n<pre>import torch\nimport torchvision\n</pre>\n<p>to validate that they were installed correctly</p>\n<p>Finally, proceed with <code>fastai</code> installation as normal, either through prepackaged pip or conda builds or installing from source (\"the developer install\") as explained in the sections above.</p>\n</li>\n</ol>\n<h2>Installation Issues</h2>\n<p>If the installation process fails, first make sure <a href=\"https://github.com/fastai/fastai/blob/master/README.md#is-my-system-supported\" rel=\"nofollow\">your system is supported</a>. And if the problem is still not addressed, please refer to the <a href=\"https://docs.fast.ai/troubleshoot.html\" rel=\"nofollow\">troubleshooting document</a>.</p>\n<p>If you encounter installation problems with conda, make sure you have the latest <code>conda</code> client (<code>conda install</code> will do an update too):</p>\n<pre>conda install conda\n</pre>\n<h3>Is My System Supported?</h3>\n<ol>\n<li>\n<p>Python: You need to have python 3.6 or higher</p>\n</li>\n<li>\n<p>CPU or GPU</p>\n<p>The <code>pytorch</code> binary package comes with its own CUDA, CuDNN, NCCL, MKL, and other libraries so you don't have to install system-wide NVIDIA's CUDA and related libraries if you don't need them for something else. If you have them installed already it doesn't matter which NVIDIA's CUDA version library you have installed system-wide. Your system could have CUDA 9.0 libraries, and you can still use <code>pytorch</code> build with CUDA 10.0 libraries without any problem, since the <code>pytorch</code> binary package is self-contained.</p>\n<p>The only requirement is that you have installed and configured the NVIDIA driver correctly. Usually you can test that by running <code>nvidia-smi</code>. While it's possible that this application is not available on your system, it's very likely that if it doesn't work, than your don't have your NVIDIA drivers configured properly. And remember that a reboot is always required after installing NVIDIA drivers.</p>\n</li>\n<li>\n<p>Operating System:</p>\n<p>Since fastai-1.0 relies on pytorch-1.0, you need to be able to install pytorch-1.0 first.</p>\n<p>As of this moment pytorch.org's 1.0 version supports:</p>\n<table>\n<thead>\n<tr>\n<th>Platform</th>\n<th>GPU</th>\n<th>CPU</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>linux</td>\n<td>binary</td>\n<td>binary</td>\n</tr>\n<tr>\n<td>mac</td>\n<td>source</td>\n<td>binary</td>\n</tr>\n<tr>\n<td>windows</td>\n<td>binary</td>\n<td>binary</td>\n</tr></tbody></table>\n<p>Legend: <code>binary</code> = can be installed directly, <code>source</code> = needs to be built from source.</p>\n<p>If there is no <code>pytorch</code> preview conda or pip package available for your system, you may still be able to <a href=\"https://pytorch.org/get-started/locally/\" rel=\"nofollow\">build it from source</a>.</p>\n</li>\n<li>\n<p>How do you know which pytorch cuda version build to choose?</p>\n<p>It depends on the version of the installed NVIDIA driver. Here are the requirements for CUDA versions supported by pre-built <code>pytorch</code> releases:</p>\n<table>\n<thead>\n<tr>\n<th>CUDA Toolkit</th>\n<th>NVIDIA (Linux x86_64)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CUDA 10.0</td>\n<td>&gt;= 410.00</td>\n</tr>\n<tr>\n<td>CUDA 9.0</td>\n<td>&gt;= 384.81</td>\n</tr>\n<tr>\n<td>CUDA 8.0</td>\n<td>&gt;= 367.48</td>\n</tr></tbody></table>\n<p>So if your NVIDIA driver is less than 384, then you can only use CUDA 8.0. Of course, you can upgrade your drivers to more recent ones if your card supports it.</p>\n<p>You can find a complete table with all variations <a href=\"https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html\" rel=\"nofollow\">here</a>.</p>\n<p>If you use NVIDIA driver 410+, you most likely want to install the <code>cudatoolkit=10.0</code> pytorch variant, via:</p>\n<pre>conda install -c pytorch pytorch <span class=\"nv\">cudatoolkit</span><span class=\"o\">=</span><span class=\"m\">10</span>.0\n</pre>\n<p>or if you need a lower version, use one of:</p>\n<pre>conda install -c pytorch pytorch <span class=\"nv\">cudatoolkit</span><span class=\"o\">=</span><span class=\"m\">8</span>.0\nconda install -c pytorch pytorch <span class=\"nv\">cudatoolkit</span><span class=\"o\">=</span><span class=\"m\">9</span>.0\n</pre>\n<p>For other options refer to the complete list of <a href=\"https://pytorch.org/get-started/locally/\" rel=\"nofollow\">the available pytorch variants</a>.</p>\n</li>\n</ol>\n<h2>Updates</h2>\n<p>In order to update your environment, simply install <code>fastai</code> in exactly the same way you did the initial installation.</p>\n<p>Top level files <code>environment.yml</code> and <code>environment-cpu.yml</code> belong to the old fastai (0.7). <code>conda env update</code> is no longer the way to update your <code>fastai-1.x</code> environment. These files remain because the fastai course-v2 video instructions rely on this setup. Eventually, once fastai course-v3 p1 and p2 will be completed, they will probably be moved to where they belong - under <code>old/</code>.</p>\n<h2>Contribution guidelines</h2>\n<p>If you want to contribute to <code>fastai</code>, be sure to review the <a href=\"https://github.com/fastai/fastai/blob/master/CONTRIBUTING.md\" rel=\"nofollow\">contribution guidelines</a>. This project adheres to fastai's <a href=\"https://github.com/fastai/fastai/blob/master/CODE-OF-CONDUCT.md\" rel=\"nofollow\">code of conduct</a>. By participating, you are expected to uphold this code.</p>\n<p>We use GitHub issues for tracking requests and bugs, so please see <a href=\"https://forums.fast.ai/\" rel=\"nofollow\">fastai forum</a> for general questions and discussion.</p>\n<p>The fastai project strives to abide by generally accepted best practices in open-source software development:</p>\n<h2>History</h2>\n<p>A detailed history of changes can be found <a href=\"https://github.com/fastai/fastai/blob/master/CHANGES.md\" rel=\"nofollow\">here</a>.</p>\n<h2>Copyright</h2>\n<p>Copyright 2017 onwards, fast.ai, Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this project's files except in compliance with the License. A copy of the License is provided in the LICENSE file in this repository.</p>\n\n          </div>"}, "last_serial": 4981122, "releases": {"0.3a0": [{"comment_text": "", "digests": {"md5": "4cc4888bccbb40acdffe84f049670a53", "sha256": "44e2bd283fb6e5b01f030509446edbfeabf234d239b73bfb9a990015b99cab18"}, "downloads": -1, "filename": "fastai_bottleneck_1-1-1-0.3a0.tar.gz", "has_sig": false, "md5_digest": "4cc4888bccbb40acdffe84f049670a53", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 2883960, "upload_time": "2019-03-25T06:52:20", "upload_time_iso_8601": "2019-03-25T06:52:20.948040Z", "url": "https://files.pythonhosted.org/packages/30/af/32b39250b62e65bd8825fd8783986db5494f467712aacafc5fb4f27ac370/fastai_bottleneck_1-1-1-0.3a0.tar.gz", "yanked": false}], "0.5a0": [{"comment_text": "", "digests": {"md5": "bb4cb4c086805f3a66582c427ba6de5d", "sha256": "ba60eb17c0d779cfa8780585be15caecea3243b36140d53057f8a24ecfbff465"}, "downloads": -1, "filename": "fastai_bottleneck_1-1-1-0.5a0.tar.gz", "has_sig": false, "md5_digest": "bb4cb4c086805f3a66582c427ba6de5d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 2883993, "upload_time": "2019-03-25T07:06:43", "upload_time_iso_8601": "2019-03-25T07:06:43.496365Z", "url": "https://files.pythonhosted.org/packages/fb/c8/fc472624cc0f70839f211961d09f82020b14332792e140b7fd6fcd808bb0/fastai_bottleneck_1-1-1-0.5a0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "bb4cb4c086805f3a66582c427ba6de5d", "sha256": "ba60eb17c0d779cfa8780585be15caecea3243b36140d53057f8a24ecfbff465"}, "downloads": -1, "filename": "fastai_bottleneck_1-1-1-0.5a0.tar.gz", "has_sig": false, "md5_digest": "bb4cb4c086805f3a66582c427ba6de5d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 2883993, "upload_time": "2019-03-25T07:06:43", "upload_time_iso_8601": "2019-03-25T07:06:43.496365Z", "url": "https://files.pythonhosted.org/packages/fb/c8/fc472624cc0f70839f211961d09f82020b14332792e140b7fd6fcd808bb0/fastai_bottleneck_1-1-1-0.5a0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:43:41 2020"}