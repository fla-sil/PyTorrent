{"info": {"author": "Nick Kunz", "author_email": "nick.kunz@me.com", "bugtrack_url": null, "classifiers": ["Intended Audience :: Science/Research", "License :: OSI Approved :: GNU General Public License v3 (GPLv3)", "Programming Language :: Python :: 3", "Topic :: Scientific/Engineering", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Scientific/Engineering :: Mathematics"], "description": "<div align=\"center\">\n  <img src=\"https://github.com/nickkunz/nestedhyperboost/blob/master/media/images/nestedhyperboost_banner.png\">\n</div>\n\n## Nested Cross-Validation for Bayesian Optimized Gradient Boosting\n[![PyPI version](https://badge.fury.io/py/nestedhyperboost.svg)](https://badge.fury.io/py/nestedhyperboost)\n[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)\n[![Build Status](https://travis-ci.com/nickkunz/nestedhyperboost.svg?branch=master)](https://travis-ci.com/nickkunz/nestedhyperboost)\n[![Codacy Badge](https://api.codacy.com/project/badge/Grade/8d3b4a3d156c4c7f9c62ac540782efd6)](https://app.codacy.com/manual/nickkunz/nestedhyperboost?utm_source=github.com&utm_medium=referral&utm_content=nickkunz/nestedhyperboost&utm_campaign=Badge_Grade_Dashboard)\n![GitHub last commit](https://img.shields.io/github/last-commit/nickkunz/nestedhyperboost)\n\n## Description\nA Python implementation that unifies Nested K-Fold Cross-Validation, Bayesian Hyperparameter Optimization, and Gradient Boosting. Designed for rapid prototyping on small to mid-sized data sets (can be manipulated within memory). Quickly obtains high quality prediction results by abstracting away tedious hyperparameter tuning and implementation details in favor of usability and implementation speed. Bayesian Hyperparamter Optimization utilizes Tree Parzen Estimation (TPE) from the <a href=\"https://github.com/hyperopt/hyperopt\">Hyperopt</a> package. Gradient Boosting can be conducted one of three ways. Select between <a href=\"https://github.com/dmlc/xgboost\">XGBoost</a>, <a href=\"https://github.com/microsoft/LightGBM\">LightGBM</a>, or <a href=\"https://github.com/catboost/catboost\">CatBoost</a>. <a href=\"https://github.com/dmlc/xgboost\">XGBoost</a> is applied using traditional Gradient Tree Boosting (GTB). <a href=\"https://github.com/microsoft/LightGBM\">LightGBM</a> is applied using its novel Gradient Based One Sided Sampling (GOSS). <a href=\"https://github.com/catboost/catboost\">CatBoost</a> is applied usings its novel Ordered Boosting. NestedHyperBoost can be applied to regression, multi-class classification, and binary classification problems.\n\n## Features\n1. Consistent syntax across all Gradient Boosting methods.\n2. Supported Gradient Boosting methods: <a href=\"https://github.com/dmlc/xgboost\">XGBoost</a>, <a href=\"https://github.com/microsoft/LightGBM\">LightGBM</a>, <a href=\"https://github.com/catboost/catboost\">CatBoost</a>.\n3. Returns custom object that includes common performance metrics and plots.\n4. Developed for readability, maintainability, and future improvement.\n\n## Requirements\n1. Python 3\n2. NumPy\n3. Pandas\n4. MatPlotLib\n5. Scikit-Learn\n6. Hyperopt\n7. XGBoost\n8. LightGBM\n9. CatBoost\n\n## Installation\n```python\n## install pypi release\npip install nestedhyperboost\n\n## install developer version\npip install git+https://github.com/nickkunz/nestedhyperboost.git\n```\n\n## Usage\n```python\n## load libraries\nfrom nestedhyperboost import xgboost\nfrom sklearn import datasets\nimport pandas\n\n## load data\ndata_sklearn = datasets.load_iris()\ndata = pandas.DataFrame(data_sklearn.data, columns = data_sklearn.feature_names)\ndata['target'] = pandas.Series(data_sklearn.target)\n\n## conduct nestedhyperboost\nresults = xgboost.xgb_ncv_classifier(\n    data = data,\n    y = 'target',\n    k_inner = 5,\n    k_outer = 5,\n    n_evals = 10\n)\n\n## preview results\nresults.accu_mean()\nresults.conf_mtrx()\nresults.prfs_mean()\n\n## preview plots\nresults.feat_plot()\n\n## model and params\nmodel = results.model\nparams = results.params\n```\n\n## License\n\u00a9 Nick Kunz, 2019. Licensed under the General Public License v3.0 (GPLv3).\n\n## Contributions\nNestedHyperBoost is open for improvements and maintenance. Your help is valued to make the package better for everyone.\n\n## References\nBergstra, J., Bardenet, R., Bengio, Y., Kegl, B. (2011). Algorithms for Hyper-Parameter Optimization. https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf.\n\nBergstra, J., Yamins, D., Cox, D. D. (2013). Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures. \nProceedings of the 30th International Conference on International Conference on Machine Learning. 28:I115\u2013I123. \nhttp://proceedings.mlr.press/v28/bergstra13.pdf.\n\nChen, T., Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 785\u2013794.\nhttps://www.kdd.org/kdd2016/papers/files/rfp0697-chenAemb.pdf.\n\nKe, G., Meng, Q., Finley, T., et al. (2017). LightGBM: A Highly Efficient Gradient Boosting Decision Tree. Proceedings of the 31st International Conference on Neural Information Processing Systems. 3146-3154. https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf.\n\nProkhorenkova, L., Gusev, G., Vorobev, A., et al. (2018). CatBoost: Unbiased Boosting with Categorical Features. Proceedings of the 32nd International Conference on Neural Information Processing Systems. 6639\u20136649.\nhttp://learningsys.org/nips17/assets/papers/paper_11.pdf.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/nickkunz/nestedhyperboost", "keywords": "nested cross-validation,bayesian optimization,gradient boosting,xgboost,lightgbm,catboost", "license": "", "maintainer": "", "maintainer_email": "", "name": "nestedhyperboost", "package_url": "https://pypi.org/project/nestedhyperboost/", "platform": "", "project_url": "https://pypi.org/project/nestedhyperboost/", "project_urls": {"Homepage": "https://github.com/nickkunz/nestedhyperboost"}, "release_url": "https://pypi.org/project/nestedhyperboost/0.0.3/", "requires_dist": ["numpy", "pandas", "matplotlib", "sklearn", "hyperopt", "xgboost", "lightgbm", "catboost"], "requires_python": "", "summary": "A wrapper for conducting Nested Cross-Validation with Bayesian Hyper-Parameter Optimized Gradient Boosting", "version": "0.0.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div>\n  <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9ad01357d299dfbd2ef5d50272790e4df32beb0f/68747470733a2f2f6769746875622e636f6d2f6e69636b6b756e7a2f6e65737465646879706572626f6f73742f626c6f622f6d61737465722f6d656469612f696d616765732f6e65737465646879706572626f6f73745f62616e6e65722e706e67\">\n</div>\n<h2>Nested Cross-Validation for Bayesian Optimized Gradient Boosting</h2>\n<p><a href=\"https://badge.fury.io/py/nestedhyperboost\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fd21f0755d62244b1c2cb7cd02a6999e58c34edc/68747470733a2f2f62616467652e667572792e696f2f70792f6e65737465646879706572626f6f73742e737667\"></a>\n<a href=\"https://www.gnu.org/licenses/gpl-3.0\" rel=\"nofollow\"><img alt=\"License: GPL v3\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8de17537dd1659a5a076ce547de301e27c839e67/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d47504c76332d626c75652e737667\"></a>\n<a href=\"https://travis-ci.com/nickkunz/nestedhyperboost\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0539d101563576431f485fbb3b68fc912d52568f/68747470733a2f2f7472617669732d63692e636f6d2f6e69636b6b756e7a2f6e65737465646879706572626f6f73742e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://app.codacy.com/manual/nickkunz/nestedhyperboost?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=nickkunz/nestedhyperboost&amp;utm_campaign=Badge_Grade_Dashboard\" rel=\"nofollow\"><img alt=\"Codacy Badge\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8ba279f1f18739b3289e02c81a6d151b870d3a02/68747470733a2f2f6170692e636f646163792e636f6d2f70726f6a6563742f62616467652f47726164652f3864336234613364313536633463376639633632616335343037383265666436\"></a>\n<img alt=\"GitHub last commit\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/74315497f068dbade59c11bebd2ba400b06ffb26/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6173742d636f6d6d69742f6e69636b6b756e7a2f6e65737465646879706572626f6f7374\"></p>\n<h2>Description</h2>\n<p>A Python implementation that unifies Nested K-Fold Cross-Validation, Bayesian Hyperparameter Optimization, and Gradient Boosting. Designed for rapid prototyping on small to mid-sized data sets (can be manipulated within memory). Quickly obtains high quality prediction results by abstracting away tedious hyperparameter tuning and implementation details in favor of usability and implementation speed. Bayesian Hyperparamter Optimization utilizes Tree Parzen Estimation (TPE) from the <a href=\"https://github.com/hyperopt/hyperopt\" rel=\"nofollow\">Hyperopt</a> package. Gradient Boosting can be conducted one of three ways. Select between <a href=\"https://github.com/dmlc/xgboost\" rel=\"nofollow\">XGBoost</a>, <a href=\"https://github.com/microsoft/LightGBM\" rel=\"nofollow\">LightGBM</a>, or <a href=\"https://github.com/catboost/catboost\" rel=\"nofollow\">CatBoost</a>. <a href=\"https://github.com/dmlc/xgboost\" rel=\"nofollow\">XGBoost</a> is applied using traditional Gradient Tree Boosting (GTB). <a href=\"https://github.com/microsoft/LightGBM\" rel=\"nofollow\">LightGBM</a> is applied using its novel Gradient Based One Sided Sampling (GOSS). <a href=\"https://github.com/catboost/catboost\" rel=\"nofollow\">CatBoost</a> is applied usings its novel Ordered Boosting. NestedHyperBoost can be applied to regression, multi-class classification, and binary classification problems.</p>\n<h2>Features</h2>\n<ol>\n<li>Consistent syntax across all Gradient Boosting methods.</li>\n<li>Supported Gradient Boosting methods: <a href=\"https://github.com/dmlc/xgboost\" rel=\"nofollow\">XGBoost</a>, <a href=\"https://github.com/microsoft/LightGBM\" rel=\"nofollow\">LightGBM</a>, <a href=\"https://github.com/catboost/catboost\" rel=\"nofollow\">CatBoost</a>.</li>\n<li>Returns custom object that includes common performance metrics and plots.</li>\n<li>Developed for readability, maintainability, and future improvement.</li>\n</ol>\n<h2>Requirements</h2>\n<ol>\n<li>Python 3</li>\n<li>NumPy</li>\n<li>Pandas</li>\n<li>MatPlotLib</li>\n<li>Scikit-Learn</li>\n<li>Hyperopt</li>\n<li>XGBoost</li>\n<li>LightGBM</li>\n<li>CatBoost</li>\n</ol>\n<h2>Installation</h2>\n<pre><span class=\"c1\">## install pypi release</span>\n<span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">nestedhyperboost</span>\n\n<span class=\"c1\">## install developer version</span>\n<span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">git</span><span class=\"o\">+</span><span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">github</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">nickkunz</span><span class=\"o\">/</span><span class=\"n\">nestedhyperboost</span><span class=\"o\">.</span><span class=\"n\">git</span>\n</pre>\n<h2>Usage</h2>\n<pre><span class=\"c1\">## load libraries</span>\n<span class=\"kn\">from</span> <span class=\"nn\">nestedhyperboost</span> <span class=\"kn\">import</span> <span class=\"n\">xgboost</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn</span> <span class=\"kn\">import</span> <span class=\"n\">datasets</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pandas</span>\n\n<span class=\"c1\">## load data</span>\n<span class=\"n\">data_sklearn</span> <span class=\"o\">=</span> <span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">load_iris</span><span class=\"p\">()</span>\n<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">(</span><span class=\"n\">data_sklearn</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">columns</span> <span class=\"o\">=</span> <span class=\"n\">data_sklearn</span><span class=\"o\">.</span><span class=\"n\">feature_names</span><span class=\"p\">)</span>\n<span class=\"n\">data</span><span class=\"p\">[</span><span class=\"s1\">'target'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">Series</span><span class=\"p\">(</span><span class=\"n\">data_sklearn</span><span class=\"o\">.</span><span class=\"n\">target</span><span class=\"p\">)</span>\n\n<span class=\"c1\">## conduct nestedhyperboost</span>\n<span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">xgboost</span><span class=\"o\">.</span><span class=\"n\">xgb_ncv_classifier</span><span class=\"p\">(</span>\n    <span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">,</span>\n    <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"s1\">'target'</span><span class=\"p\">,</span>\n    <span class=\"n\">k_inner</span> <span class=\"o\">=</span> <span class=\"mi\">5</span><span class=\"p\">,</span>\n    <span class=\"n\">k_outer</span> <span class=\"o\">=</span> <span class=\"mi\">5</span><span class=\"p\">,</span>\n    <span class=\"n\">n_evals</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\">## preview results</span>\n<span class=\"n\">results</span><span class=\"o\">.</span><span class=\"n\">accu_mean</span><span class=\"p\">()</span>\n<span class=\"n\">results</span><span class=\"o\">.</span><span class=\"n\">conf_mtrx</span><span class=\"p\">()</span>\n<span class=\"n\">results</span><span class=\"o\">.</span><span class=\"n\">prfs_mean</span><span class=\"p\">()</span>\n\n<span class=\"c1\">## preview plots</span>\n<span class=\"n\">results</span><span class=\"o\">.</span><span class=\"n\">feat_plot</span><span class=\"p\">()</span>\n\n<span class=\"c1\">## model and params</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">results</span><span class=\"o\">.</span><span class=\"n\">model</span>\n<span class=\"n\">params</span> <span class=\"o\">=</span> <span class=\"n\">results</span><span class=\"o\">.</span><span class=\"n\">params</span>\n</pre>\n<h2>License</h2>\n<p>\u00a9 Nick Kunz, 2019. Licensed under the General Public License v3.0 (GPLv3).</p>\n<h2>Contributions</h2>\n<p>NestedHyperBoost is open for improvements and maintenance. Your help is valued to make the package better for everyone.</p>\n<h2>References</h2>\n<p>Bergstra, J., Bardenet, R., Bengio, Y., Kegl, B. (2011). Algorithms for Hyper-Parameter Optimization. <a href=\"https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf\" rel=\"nofollow\">https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf</a>.</p>\n<p>Bergstra, J., Yamins, D., Cox, D. D. (2013). Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures.\nProceedings of the 30th International Conference on International Conference on Machine Learning. 28:I115\u2013I123.\n<a href=\"http://proceedings.mlr.press/v28/bergstra13.pdf\" rel=\"nofollow\">http://proceedings.mlr.press/v28/bergstra13.pdf</a>.</p>\n<p>Chen, T., Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 785\u2013794.\n<a href=\"https://www.kdd.org/kdd2016/papers/files/rfp0697-chenAemb.pdf\" rel=\"nofollow\">https://www.kdd.org/kdd2016/papers/files/rfp0697-chenAemb.pdf</a>.</p>\n<p>Ke, G., Meng, Q., Finley, T., et al. (2017). LightGBM: A Highly Efficient Gradient Boosting Decision Tree. Proceedings of the 31st International Conference on Neural Information Processing Systems. 3146-3154. <a href=\"https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf\" rel=\"nofollow\">https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf</a>.</p>\n<p>Prokhorenkova, L., Gusev, G., Vorobev, A., et al. (2018). CatBoost: Unbiased Boosting with Categorical Features. Proceedings of the 32nd International Conference on Neural Information Processing Systems. 6639\u20136649.\n<a href=\"http://learningsys.org/nips17/assets/papers/paper_11.pdf\" rel=\"nofollow\">http://learningsys.org/nips17/assets/papers/paper_11.pdf</a>.</p>\n\n          </div>"}, "last_serial": 6958853, "releases": {"0.0.2": [{"comment_text": "", "digests": {"md5": "424a1d5af554c5e2b2799516c7f16c86", "sha256": "6dea898ab4e056131feb62106e26cb27c9db237bcb5b4af8f1d9a22e19ee2b39"}, "downloads": -1, "filename": "nestedhyperboost-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "424a1d5af554c5e2b2799516c7f16c86", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 32046, "upload_time": "2020-03-23T04:08:34", "upload_time_iso_8601": "2020-03-23T04:08:34.949537Z", "url": "https://files.pythonhosted.org/packages/d0/41/0829c5acb4ec01dee098bd783e5c1b0f7ed6e43d5817c638c8816933b060/nestedhyperboost-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "948423afb5b215caf90ce737abaa1179", "sha256": "01def4bc60683218c585f98577882154a73e74b58c5c93a8fc847470502df7b5"}, "downloads": -1, "filename": "nestedhyperboost-0.0.2.tar.gz", "has_sig": false, "md5_digest": "948423afb5b215caf90ce737abaa1179", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 25452, "upload_time": "2020-03-23T04:08:37", "upload_time_iso_8601": "2020-03-23T04:08:37.196227Z", "url": "https://files.pythonhosted.org/packages/53/cd/7d104f53a2779cc9c246de4617f70f4b41cc8ce7847511006765664b78ea/nestedhyperboost-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "f45fa43a8ac37b9bf28598ab51d51e27", "sha256": "8af9a9b8dd542d0744e6448ad725f59e8946b7f850a17a0b43288659d92e9601"}, "downloads": -1, "filename": "nestedhyperboost-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "f45fa43a8ac37b9bf28598ab51d51e27", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 30933, "upload_time": "2020-04-06T02:54:10", "upload_time_iso_8601": "2020-04-06T02:54:10.886315Z", "url": "https://files.pythonhosted.org/packages/5e/70/f158a8649d218a2e781a0dc1915c4c0aa2b10f47738713e5692b9fb3bf76/nestedhyperboost-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "947eba1247cd392c7fb923e8e9d201fb", "sha256": "2820ee7469489bf5f2d80d4913437b2759b346a68439e77d005b71118092544b"}, "downloads": -1, "filename": "nestedhyperboost-0.0.3.tar.gz", "has_sig": false, "md5_digest": "947eba1247cd392c7fb923e8e9d201fb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 25335, "upload_time": "2020-04-06T02:54:12", "upload_time_iso_8601": "2020-04-06T02:54:12.357676Z", "url": "https://files.pythonhosted.org/packages/40/07/a205a257ed3477699813db8d5f9be5d9a66b34c2fce02862da09de05ab24/nestedhyperboost-0.0.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "f45fa43a8ac37b9bf28598ab51d51e27", "sha256": "8af9a9b8dd542d0744e6448ad725f59e8946b7f850a17a0b43288659d92e9601"}, "downloads": -1, "filename": "nestedhyperboost-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "f45fa43a8ac37b9bf28598ab51d51e27", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 30933, "upload_time": "2020-04-06T02:54:10", "upload_time_iso_8601": "2020-04-06T02:54:10.886315Z", "url": "https://files.pythonhosted.org/packages/5e/70/f158a8649d218a2e781a0dc1915c4c0aa2b10f47738713e5692b9fb3bf76/nestedhyperboost-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "947eba1247cd392c7fb923e8e9d201fb", "sha256": "2820ee7469489bf5f2d80d4913437b2759b346a68439e77d005b71118092544b"}, "downloads": -1, "filename": "nestedhyperboost-0.0.3.tar.gz", "has_sig": false, "md5_digest": "947eba1247cd392c7fb923e8e9d201fb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 25335, "upload_time": "2020-04-06T02:54:12", "upload_time_iso_8601": "2020-04-06T02:54:12.357676Z", "url": "https://files.pythonhosted.org/packages/40/07/a205a257ed3477699813db8d5f9be5d9a66b34c2fce02862da09de05ab24/nestedhyperboost-0.0.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:46:23 2020"}