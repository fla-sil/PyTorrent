{"info": {"author": "System Research Group, Microsoft Research Asia", "author_email": "mmdnn_feedback@microsoft.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 2", "Programming Language :: Python :: 3", "Topic :: Scientific/Engineering :: Mathematics", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "# ![MMdnn](https://ndqzpq.dm2304.livefilestore.com/y4mF9ON1vKrSy0ew9dM3Fw6KAvLzQza2nL9JiMSIfgfKLbqJPvuxwOC2VIur_Ycz4TvVpkibMkvKXrX-N9QOkyh0AaUW4qhWDak8cyM0UoLLxc57apyhfDaxflLlZrGqiJgzn1ztsxiaZMzglaIMhoo8kjPuZ5-vY7yoWXqJuhC1BDHOwgNPwIgzpxV1H4k1oQzmewThpAJ_w_fUHzianZtMw?width=35&height=35&cropmode=none) MMdnn\n\n[![PyPi Version](https://img.shields.io/pypi/v/mmdnn.svg)](https://pypi.org/project/mmdnn/)\n[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)\n[![Linux](https://travis-ci.org/Microsoft/MMdnn.svg?branch=master)](https://travis-ci.org/Microsoft/MMdnn)\n\nMMdnn is a comprehensive and cross-framework tool to convert, visualize and diagnose deep learning (DL) models.\nThe \"MM\" stands for model management, and \"dnn\" is the acronym of deep neural network.\n\nMajor features include:\n\n- <a href=\"#conversion\">**Model Conversion**</a>\n\n  - We implement a universal converter to convert DL models between frameworks, which means you can train a model with one framework and deploy it with another.\n\n- **Model Retraining**\n\n  - During the model conversion, we generate some code snippets to simplify later retraining or inference.\n\n- **Model Search & Visualization**\n\n  - We provide a [model collection](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/models/README.md) to help you find some popular models.\n  - We provide a <a href=\"#visualization\">model visualizer</a> to display the network architecture more intuitively.\n\n- **Model Deployment**\n\n  - We provide some guidelines to help you deploy DL models to another hardware platform.\n    - [Android](https://github.com/Microsoft/MMdnn/wiki/Deploy-your-TensorFlow-Lite-Model-in-Android)\n    - [Serving](https://github.com/Microsoft/MMdnn/wiki/Tensorflow-Serving-Via-Docker)\n\n  - We provide a guide to help you accelerate inference with TensorRT.\n    - [TensorRT](https://github.com/Microsoft/MMdnn/wiki/Using-TensorRT-to-Accelerate-Inference)\n\n\n## Related Projects\n\nTargeting at openness and advancing state-of-art technology, [Microsoft Research (MSR)](https://www.microsoft.com/en-us/research/group/systems-and-networking-research-group-asia/) and [Microsoft Software Technology Center (STC)](https://www.microsoft.com/en-us/ard/company/introduction.aspx) had also released few other open source projects:\n\n* [OpenPAI](https://github.com/Microsoft/pai) : an open source platform that provides complete AI model training and resource management capabilities, it is easy to extend and supports on-premise, cloud and hybrid environments in various scale.\n* [FrameworkController](https://github.com/Microsoft/frameworkcontroller) : an open source general-purpose Kubernetes Pod Controller that orchestrate all kinds of applications on Kubernetes by a single controller.\n* [NNI](https://github.com/Microsoft/nni) : a lightweight but powerful toolkit to help users automate Feature Engineering, Neural Architecture Search, Hyperparameter Tuning and Model Compression.\n* [NeuronBlocks](https://github.com/Microsoft/NeuronBlocks) : an NLP deep learning modeling toolkit that helps engineers to build DNN models like playing Lego. The main goal of this toolkit is to minimize developing cost for NLP deep neural network model building, including both training and inference stages.\n* [SPTAG](https://github.com/Microsoft/SPTAG) : Space Partition Tree And Graph (SPTAG) is an open source library for large scale vector approximate nearest neighbor search scenario.\n\nWe encourage researchers, developers and students to leverage these projects to boost their AI / Deep Learning productivity.\n\n## Installation\n\n### Install manually\n\nYou can get a stable version of MMdnn by\n\n```bash\npip install mmdnn\n```\nAnd make sure to have [Python](https://www.python.org/) installed\nor you can try the newest version by\n\n```bash\npip install -U git+https://github.com/Microsoft/MMdnn.git@master\n```\n\n### Install with docker image\n\nMMdnn provides a docker image, which packages MMdnn and Deep Learning frameworks that we support as well as other dependencies.\nYou can easily try the image with the following steps:\n\n1. Install Docker Community Edition(CE)\n\n    [_Learn more about how to install docker_](https://github.com/Microsoft/MMdnn/blob/master/docs/InstallDockerCE.md)\n\n1. Pull MMdnn docker image\n    ```bash\n    docker pull mmdnn/mmdnn:cpu.small\n    ```\n\n1. Run image in an interactive mode\n\n    ```bash\n    docker run -it mmdnn/mmdnn:cpu.small\n    ```\n\n## Features\n\n### <a name=\"conversion\">Model Conversion</a>\n\nAcross the industry and academia, there are a number of existing frameworks available for developers and researchers to design a model, where each framework has its own network structure definition and saving model format. The gaps between frameworks impede the inter-operation of the models.\n\n<img src=\"https://raw.githubusercontent.com/Microsoft/MMdnn/master/docs/supported.jpg\" width=\"633\" >\n\nWe provide a model converter to help developers convert models between frameworks through an intermediate representation format.\n\n#### Support frameworks\n\n> [Note] You can click the links to get detailed README of each framework.\n\n- [Caffe](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/caffe/README.md)\n- [Microsoft Cognitive Toolkit (CNTK)](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/cntk/README.md)\n- [CoreML](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/coreml/README.md)\n- [Keras](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/keras/README.md)\n- [MXNet](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/mxnet/README.md)\n- [ONNX](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/onnx/README.md) (Destination only)\n- [PyTorch](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/pytorch/README.md)\n- [TensorFlow](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/tensorflow/README.md) (Experimental) (We highly recommend you read the README of TensorFlow first)\n- [DarkNet](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/darknet/README.md) (Source only, Experiment)\n\n#### Tested models\n\nThe model conversion between currently supported frameworks is tested on some **ImageNet** models.\n\nModels | Caffe | Keras | TensorFlow | CNTK | MXNet | PyTorch  | CoreML | ONNX\n:-----:|:-----:|:-----:|:----------:|:----:|:-----:|:--------:|:------:|:-----:|\n[VGG 19](https://arxiv.org/abs/1409.1556.pdf) | \u221a | \u221a | \u221a | \u221a | \u221a | \u221a | \u221a | \u221a\n[Inception V1](https://arxiv.org/abs/1409.4842v1) | \u221a | \u221a | \u221a | \u221a | \u221a | \u221a | \u221a | \u221a\n[Inception V3](https://arxiv.org/abs/1512.00567)  | \u221a | \u221a | \u221a | \u221a | \u221a | \u221a | \u221a | \u221a\n[Inception V4](https://arxiv.org/abs/1512.00567)  | \u221a | \u221a | \u221a | o | \u221a | \u221a | \u221a | \u221a\n[ResNet V1](https://arxiv.org/abs/1512.03385)                               |   \u00d7   |   \u221a   |     \u221a      |   o  |   \u221a   |    \u221a | \u221a | \u221a\n[ResNet V2](https://arxiv.org/abs/1603.05027)                               |   \u221a   |   \u221a   |     \u221a      |   \u221a  |   \u221a   | \u221a | \u221a | \u221a\n[MobileNet V1](https://arxiv.org/pdf/1704.04861.pdf)                        |   \u00d7   |   \u221a   |     \u221a      |   o  |   \u221a   |    \u221a       | \u221a | \u221a | \u221a\n[MobileNet V2](https://arxiv.org/pdf/1704.04861.pdf)                        |   \u00d7   |   \u221a   |     \u221a      |   o  |   \u221a   |    \u221a       | \u221a | \u221a | \u221a\n[Xception](https://arxiv.org/pdf/1610.02357.pdf)                            |   \u221a   |   \u221a   |     \u221a      |   o  |   \u00d7   |    \u221a | \u221a | \u221a | \u221a\n[SqueezeNet](https://arxiv.org/pdf/1602.07360)                              |   \u221a   |   \u221a   |     \u221a      |   \u221a  |   \u221a   |    \u221a | \u221a | \u221a | \u221a\n[DenseNet](https://arxiv.org/abs/1608.06993)                                |   \u221a   |   \u221a   |     \u221a      |   \u221a  |   \u221a   |    \u221a       | \u221a | \u221a\n[NASNet](https://arxiv.org/abs/1707.07012)                                  |   x   |   \u221a   |     \u221a      |   o  |   \u221a   | \u221a | \u221a | x\n[ResNext](https://arxiv.org/abs/1611.05431)                                 |   \u221a   |   \u221a   |     \u221a      |   \u221a  |   \u221a   | \u221a | \u221a | \u221a | \u221a | \u221a\n[voc FCN](https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf) |       |       |     \u221a      |   \u221a  |       |\nYolo3                                                                       |       |   \u221a   |            |   \u221a  |\n\n#### Usage\n\nOne command to achieve the conversion. Using TensorFlow **ResNet V2 152** to PyTorch as our example.\n\n```bash\n$ mmdownload -f tensorflow -n resnet_v2_152 -o ./\n$ mmconvert -sf tensorflow -in imagenet_resnet_v2_152.ckpt.meta -iw imagenet_resnet_v2_152.ckpt --dstNodeName MMdnn_Output -df pytorch -om tf_resnet_to_pth.pth\n```\n\nDone.\n\n#### On-going frameworks\n\n- Torch7 (help wanted)\n- Chainer (help wanted)\n\n#### On-going Models\n\n- Face Detection\n- Semantic Segmentation\n- Image Style Transfer\n- Object Detection\n- RNN\n\n---\n\n### <a name=\"visualization\">Model Visualization</a>\n\nYou can use the [MMdnn model visualizer](http://vis.mmdnn.com/) and submit your IR json file to visualize your model.  In order to run the commands below, you will need to install [requests](https://anaconda.org/anaconda/requests), [keras](https://anaconda.org/anaconda/keras), and [TensorFlow](https://anaconda.org/anaconda/tensorflow) using your favorite package manager.\n\nUse the [Keras \"inception_v3\" model](https://github.com/fchollet/deep-learning-models) as an example again.\n\n1. Download the pre-trained models\n\n```bash\n$ mmdownload -f keras -n inception_v3\n```\n\n2. Convert the pre-trained model files into an intermediate representation\n\n```bash\n$ mmtoir -f keras -w imagenet_inception_v3.h5 -o keras_inception_v3\n```\n\n3. Open the [MMdnn model visualizer](http://mmdnn.eastasia.cloudapp.azure.com:8080/) and choose file *keras_inception_v3.json*\n\n![vismmdnn](docs/vismmdnn.png)\n\n---\n\n## Examples\n\n### Official Tutorial\n\n- [Keras \"inception V3\" to CNTK](https://github.com/Microsoft/MMdnn/blob/master/docs/keras2cntk.md) and [related issue](https://github.com/Microsoft/MMdnn/issues/19)\n\n- [TensorFlow slim model \"ResNet V2 152\" to PyTorch](https://github.com/Microsoft/MMdnn/blob/master/docs/tf2pytorch.md)\n\n- [Mxnet model \"LResNet50E-IR\" to TensorFlow](https://github.com/Microsoft/MMdnn/issues/85) and [related issue](https://github.com/Microsoft/MMdnn/issues/135)\n\n### Users' Examples\n\n- [MXNet \"ResNet-152-11k\" to PyTorch](https://github.com/Microsoft/MMdnn/issues/6)\n\n- [Another Example of MXNet \"ResNet-152-11k\" to PyTorch](https://blog.paperspace.com/convert-full-imagenet-pre-trained-model-from-mxnet-to-pytorch/)\n\n- [MXNet \"ResNeXt\" to Keras](https://github.com/Microsoft/MMdnn/issues/58)\n\n- [TensorFlow \"ResNet-101\" to PyTorch](https://github.com/Microsoft/MMdnn/issues/22)\n\n- [TensorFlow \"mnist mlp model\" to CNTK](https://github.com/Microsoft/MMdnn/issues/11)\n\n- [TensorFlow \"Inception_v3\" to MXNet](https://github.com/Microsoft/MMdnn/issues/30)\n\n- [Caffe \"voc-fcn\" to TensorFlow](https://github.com/Microsoft/MMdnn/issues/29)\n\n- [Caffe \"AlexNet\" to TensorFlow](https://github.com/Microsoft/MMdnn/issues/10)\n\n- [Caffe \"inception_v4\" to TensorFlow](https://github.com/Microsoft/MMdnn/issues/26)\n\n- [Caffe \"VGG16_SOD\" to TensorFlow](https://github.com/Microsoft/MMdnn/issues/27)\n\n- [Caffe \"SqueezeNet v1.1\" to CNTK](https://github.com/Microsoft/MMdnn/issues/48)\n\n---\n\n## Contributing\n\nMost contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n### Intermediate Representation\n\nThe intermediate representation stores the **network architecture** in **protobuf binary** and **pre-trained weights** in **NumPy** native format.\n\n> [Note!] Currently the IR weights data is in NHWC (channel last) format.\n\nDetails are in [ops.txt](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/common/IR/ops.pbtxt) and [graph.proto](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/common/IR/graph.proto). New operators and any comments are welcome.\n\n### Frameworks\n\nWe are working on other frameworks conversion and visualization, such as PyTorch, CoreML and so on. We're investigating more RNN related operators. Any contributions and suggestions are welcome! Details in [Contribution Guideline](https://github.com/Microsoft/MMdnn/wiki/Contribution-Guideline).\n\n## Authors\n\nYu Liu (Peking University): Project Developer & Maintainer\n\nCheng CHEN (Microsoft Research Asia): Caffe, CNTK, CoreML Emitter, Keras, MXNet, TensorFlow\n\nJiahao YAO (Peking University): CoreML, MXNet Emitter, PyTorch Parser; HomePage\n\nRu ZHANG (Chinese Academy of Sciences): CoreML Emitter, DarkNet Parser, Keras, TensorFlow frozen graph Parser; Yolo and SSD models; Tests\n\nYuhao ZHOU (Shanghai Jiao Tong University): MXNet\n\nTingting QIN (Microsoft Research Asia): Caffe Emitter\n\nTong ZHAN (Microsoft): ONNX Emitter\n\nQianwen WANG (Hong Kong University of Science and Technology): Visualization\n\n## Acknowledgements\n\nThanks to [Saumitro Dasgupta](https://github.com/ethereon), the initial code of *caffe -> IR converting* is references to his project [caffe-tensorflow](https://github.com/ethereon/caffe-tensorflow).\n\n## License\nLicensed under the [MIT](LICENSE) license.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Microsoft/MMdnn", "keywords": "deep learning model converter visualization", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "mmdnn", "package_url": "https://pypi.org/project/mmdnn/", "platform": "", "project_url": "https://pypi.org/project/mmdnn/", "project_urls": {"Homepage": "https://github.com/Microsoft/MMdnn"}, "release_url": "https://pypi.org/project/mmdnn/0.3.0/", "requires_dist": ["numpy (>=1.15.0)", "protobuf (>=3.6.0)", "six (>=1.10.0)", "pillow (>=6.2.1)"], "requires_python": "", "summary": "Deep learning model converter, visualization and editor.", "version": "0.3.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1><img alt=\"MMdnn\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c731168371e3cc9e9f7456368a68289ead46e248/68747470733a2f2f6e64717a70712e646d323330342e6c69766566696c6573746f72652e636f6d2f79346d46394f4e31764b72537930657739644d334677364b41764c7a517a61326e4c394a694d53496667664b4c62714a50767578774f4332564975725f59637a34547656706b69624d6b764b5872582d4e39514f6b796830416155573471685744616b3863794d30556f4c4c786335376170796866446178666c4c6c5a724771694a677a6e317a74737869615a4d7a676c61494d686f6f386b6a50755a352d765937796f5758714a756843314244484f77674e507749677a7078563148346b316f517a6d6577546870414a5f775f6655487a69616e5a744d773f77696474683d3335266865696768743d33352663726f706d6f64653d6e6f6e65\"> MMdnn</h1>\n<p><a href=\"https://pypi.org/project/mmdnn/\" rel=\"nofollow\"><img alt=\"PyPi Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f8e9bbebd6f40a5253e265f5339d4a5175bfb943/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6d6d646e6e2e737667\"></a>\n<a href=\"LICENSE\" rel=\"nofollow\"><img alt=\"License\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c88fab50b4a1dc0cd91faeb7ba5654d56e380260/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75652e737667\"></a>\n<a href=\"https://travis-ci.org/Microsoft/MMdnn\" rel=\"nofollow\"><img alt=\"Linux\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2c95a4cf54043a3ccea1e237a212764d2c57cee9/68747470733a2f2f7472617669732d63692e6f72672f4d6963726f736f66742f4d4d646e6e2e7376673f6272616e63683d6d6173746572\"></a></p>\n<p>MMdnn is a comprehensive and cross-framework tool to convert, visualize and diagnose deep learning (DL) models.\nThe \"MM\" stands for model management, and \"dnn\" is the acronym of deep neural network.</p>\n<p>Major features include:</p>\n<ul>\n<li>\n<p><a href=\"#conversion\" rel=\"nofollow\"><strong>Model Conversion</strong></a></p>\n<ul>\n<li>We implement a universal converter to convert DL models between frameworks, which means you can train a model with one framework and deploy it with another.</li>\n</ul>\n</li>\n<li>\n<p><strong>Model Retraining</strong></p>\n<ul>\n<li>During the model conversion, we generate some code snippets to simplify later retraining or inference.</li>\n</ul>\n</li>\n<li>\n<p><strong>Model Search &amp; Visualization</strong></p>\n<ul>\n<li>We provide a <a href=\"https://github.com/Microsoft/MMdnn/blob/master/mmdnn/models/README.md\" rel=\"nofollow\">model collection</a> to help you find some popular models.</li>\n<li>We provide a <a href=\"#visualization\" rel=\"nofollow\">model visualizer</a> to display the network architecture more intuitively.</li>\n</ul>\n</li>\n<li>\n<p><strong>Model Deployment</strong></p>\n<ul>\n<li>\n<p>We provide some guidelines to help you deploy DL models to another hardware platform.</p>\n<ul>\n<li><a href=\"https://github.com/Microsoft/MMdnn/wiki/Deploy-your-TensorFlow-Lite-Model-in-Android\" rel=\"nofollow\">Android</a></li>\n<li><a href=\"https://github.com/Microsoft/MMdnn/wiki/Tensorflow-Serving-Via-Docker\" rel=\"nofollow\">Serving</a></li>\n</ul>\n</li>\n<li>\n<p>We provide a guide to help you accelerate inference with TensorRT.</p>\n<ul>\n<li><a href=\"https://github.com/Microsoft/MMdnn/wiki/Using-TensorRT-to-Accelerate-Inference\" rel=\"nofollow\">TensorRT</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2>Related Projects</h2>\n<p>Targeting at openness and advancing state-of-art technology, <a href=\"https://www.microsoft.com/en-us/research/group/systems-and-networking-research-group-asia/\" rel=\"nofollow\">Microsoft Research (MSR)</a> and <a href=\"https://www.microsoft.com/en-us/ard/company/introduction.aspx\" rel=\"nofollow\">Microsoft Software Technology Center (STC)</a> had also released few other open source projects:</p>\n<ul>\n<li><a href=\"https://github.com/Microsoft/pai\" rel=\"nofollow\">OpenPAI</a> : an open source platform that provides complete AI model training and resource management capabilities, it is easy to extend and supports on-premise, cloud and hybrid environments in various scale.</li>\n<li><a href=\"https://github.com/Microsoft/frameworkcontroller\" rel=\"nofollow\">FrameworkController</a> : an open source general-purpose Kubernetes Pod Controller that orchestrate all kinds of applications on Kubernetes by a single controller.</li>\n<li><a href=\"https://github.com/Microsoft/nni\" rel=\"nofollow\">NNI</a> : a lightweight but powerful toolkit to help users automate Feature Engineering, Neural Architecture Search, Hyperparameter Tuning and Model Compression.</li>\n<li><a href=\"https://github.com/Microsoft/NeuronBlocks\" rel=\"nofollow\">NeuronBlocks</a> : an NLP deep learning modeling toolkit that helps engineers to build DNN models like playing Lego. The main goal of this toolkit is to minimize developing cost for NLP deep neural network model building, including both training and inference stages.</li>\n<li><a href=\"https://github.com/Microsoft/SPTAG\" rel=\"nofollow\">SPTAG</a> : Space Partition Tree And Graph (SPTAG) is an open source library for large scale vector approximate nearest neighbor search scenario.</li>\n</ul>\n<p>We encourage researchers, developers and students to leverage these projects to boost their AI / Deep Learning productivity.</p>\n<h2>Installation</h2>\n<h3>Install manually</h3>\n<p>You can get a stable version of MMdnn by</p>\n<pre>pip install mmdnn\n</pre>\n<p>And make sure to have <a href=\"https://www.python.org/\" rel=\"nofollow\">Python</a> installed\nor you can try the newest version by</p>\n<pre>pip install -U git+https://github.com/Microsoft/MMdnn.git@master\n</pre>\n<h3>Install with docker image</h3>\n<p>MMdnn provides a docker image, which packages MMdnn and Deep Learning frameworks that we support as well as other dependencies.\nYou can easily try the image with the following steps:</p>\n<ol>\n<li>\n<p>Install Docker Community Edition(CE)</p>\n<p><a href=\"https://github.com/Microsoft/MMdnn/blob/master/docs/InstallDockerCE.md\" rel=\"nofollow\"><em>Learn more about how to install docker</em></a></p>\n</li>\n<li>\n<p>Pull MMdnn docker image</p>\n<pre>docker pull mmdnn/mmdnn:cpu.small\n</pre>\n</li>\n<li>\n<p>Run image in an interactive mode</p>\n<pre>docker run -it mmdnn/mmdnn:cpu.small\n</pre>\n</li>\n</ol>\n<h2>Features</h2>\n<h3><a>Model Conversion</a></h3>\n<p>Across the industry and academia, there are a number of existing frameworks available for developers and researchers to design a model, where each framework has its own network structure definition and saving model format. The gaps between frameworks impede the inter-operation of the models.</p>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/318b02b119efb2a464d856ca3c5252de34787325/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f4d6963726f736f66742f4d4d646e6e2f6d61737465722f646f63732f737570706f727465642e6a7067\" width=\"633\">\n<p>We provide a model converter to help developers convert models between frameworks through an intermediate representation format.</p>\n<h4>Support frameworks</h4>\n<blockquote>\n<p>[Note] You can click the links to get detailed README of each framework.</p>\n</blockquote>\n<ul>\n<li><a href=\"https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/caffe/README.md\" rel=\"nofollow\">Caffe</a></li>\n<li><a href=\"https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/cntk/README.md\" rel=\"nofollow\">Microsoft Cognitive Toolkit (CNTK)</a></li>\n<li><a href=\"https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/coreml/README.md\" rel=\"nofollow\">CoreML</a></li>\n<li><a href=\"https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/keras/README.md\" rel=\"nofollow\">Keras</a></li>\n<li><a href=\"https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/mxnet/README.md\" rel=\"nofollow\">MXNet</a></li>\n<li><a href=\"https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/onnx/README.md\" rel=\"nofollow\">ONNX</a> (Destination only)</li>\n<li><a href=\"https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/pytorch/README.md\" rel=\"nofollow\">PyTorch</a></li>\n<li><a href=\"https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/tensorflow/README.md\" rel=\"nofollow\">TensorFlow</a> (Experimental) (We highly recommend you read the README of TensorFlow first)</li>\n<li><a href=\"https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/darknet/README.md\" rel=\"nofollow\">DarkNet</a> (Source only, Experiment)</li>\n</ul>\n<h4>Tested models</h4>\n<p>The model conversion between currently supported frameworks is tested on some <strong>ImageNet</strong> models.</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">Models</th>\n<th align=\"center\">Caffe</th>\n<th align=\"center\">Keras</th>\n<th align=\"center\">TensorFlow</th>\n<th align=\"center\">CNTK</th>\n<th align=\"center\">MXNet</th>\n<th align=\"center\">PyTorch</th>\n<th align=\"center\">CoreML</th>\n<th align=\"center\">ONNX</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\"><a href=\"https://arxiv.org/abs/1409.1556.pdf\" rel=\"nofollow\">VGG 19</a></td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n</tr>\n<tr>\n<td align=\"center\"><a href=\"https://arxiv.org/abs/1409.4842v1\" rel=\"nofollow\">Inception V1</a></td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n</tr>\n<tr>\n<td align=\"center\"><a href=\"https://arxiv.org/abs/1512.00567\" rel=\"nofollow\">Inception V3</a></td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n</tr>\n<tr>\n<td align=\"center\"><a href=\"https://arxiv.org/abs/1512.00567\" rel=\"nofollow\">Inception V4</a></td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">o</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n</tr>\n<tr>\n<td align=\"center\"><a href=\"https://arxiv.org/abs/1512.03385\" rel=\"nofollow\">ResNet V1</a></td>\n<td align=\"center\">\u00d7</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">o</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n</tr>\n<tr>\n<td align=\"center\"><a href=\"https://arxiv.org/abs/1603.05027\" rel=\"nofollow\">ResNet V2</a></td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n</tr>\n<tr>\n<td align=\"center\"><a href=\"https://arxiv.org/pdf/1704.04861.pdf\" rel=\"nofollow\">MobileNet V1</a></td>\n<td align=\"center\">\u00d7</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">o</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n</tr>\n<tr>\n<td align=\"center\"><a href=\"https://arxiv.org/pdf/1704.04861.pdf\" rel=\"nofollow\">MobileNet V2</a></td>\n<td align=\"center\">\u00d7</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">o</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n</tr>\n<tr>\n<td align=\"center\"><a href=\"https://arxiv.org/pdf/1610.02357.pdf\" rel=\"nofollow\">Xception</a></td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">o</td>\n<td align=\"center\">\u00d7</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n</tr>\n<tr>\n<td align=\"center\"><a href=\"https://arxiv.org/pdf/1602.07360\" rel=\"nofollow\">SqueezeNet</a></td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n</tr>\n<tr>\n<td align=\"center\"><a href=\"https://arxiv.org/abs/1608.06993\" rel=\"nofollow\">DenseNet</a></td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n</tr>\n<tr>\n<td align=\"center\"><a href=\"https://arxiv.org/abs/1707.07012\" rel=\"nofollow\">NASNet</a></td>\n<td align=\"center\">x</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">o</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">x</td>\n</tr>\n<tr>\n<td align=\"center\"><a href=\"https://arxiv.org/abs/1611.05431\" rel=\"nofollow\">ResNext</a></td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n</tr>\n<tr>\n<td align=\"center\"><a href=\"https://people.eecs.berkeley.edu/%7Ejonlong/long_shelhamer_fcn.pdf\" rel=\"nofollow\">voc FCN</a></td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td align=\"center\">Yolo3</td>\n<td align=\"center\"></td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\"></td>\n<td align=\"center\">\u221a</td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n</tr></tbody></table>\n<h4>Usage</h4>\n<p>One command to achieve the conversion. Using TensorFlow <strong>ResNet V2 152</strong> to PyTorch as our example.</p>\n<pre>$ mmdownload -f tensorflow -n resnet_v2_152 -o ./\n$ mmconvert -sf tensorflow -in imagenet_resnet_v2_152.ckpt.meta -iw imagenet_resnet_v2_152.ckpt --dstNodeName MMdnn_Output -df pytorch -om tf_resnet_to_pth.pth\n</pre>\n<p>Done.</p>\n<h4>On-going frameworks</h4>\n<ul>\n<li>Torch7 (help wanted)</li>\n<li>Chainer (help wanted)</li>\n</ul>\n<h4>On-going Models</h4>\n<ul>\n<li>Face Detection</li>\n<li>Semantic Segmentation</li>\n<li>Image Style Transfer</li>\n<li>Object Detection</li>\n<li>RNN</li>\n</ul>\n<hr>\n<h3><a>Model Visualization</a></h3>\n<p>You can use the <a href=\"http://vis.mmdnn.com/\" rel=\"nofollow\">MMdnn model visualizer</a> and submit your IR json file to visualize your model.  In order to run the commands below, you will need to install <a href=\"https://anaconda.org/anaconda/requests\" rel=\"nofollow\">requests</a>, <a href=\"https://anaconda.org/anaconda/keras\" rel=\"nofollow\">keras</a>, and <a href=\"https://anaconda.org/anaconda/tensorflow\" rel=\"nofollow\">TensorFlow</a> using your favorite package manager.</p>\n<p>Use the <a href=\"https://github.com/fchollet/deep-learning-models\" rel=\"nofollow\">Keras \"inception_v3\" model</a> as an example again.</p>\n<ol>\n<li>Download the pre-trained models</li>\n</ol>\n<pre>$ mmdownload -f keras -n inception_v3\n</pre>\n<ol>\n<li>Convert the pre-trained model files into an intermediate representation</li>\n</ol>\n<pre>$ mmtoir -f keras -w imagenet_inception_v3.h5 -o keras_inception_v3\n</pre>\n<ol>\n<li>Open the <a href=\"http://mmdnn.eastasia.cloudapp.azure.com:8080/\" rel=\"nofollow\">MMdnn model visualizer</a> and choose file <em>keras_inception_v3.json</em></li>\n</ol>\n<p><img alt=\"vismmdnn\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/016a8beab6761c28b1dce6f658b482f65d6f3b74/646f63732f7669736d6d646e6e2e706e67\"></p>\n<hr>\n<h2>Examples</h2>\n<h3>Official Tutorial</h3>\n<ul>\n<li>\n<p><a href=\"https://github.com/Microsoft/MMdnn/blob/master/docs/keras2cntk.md\" rel=\"nofollow\">Keras \"inception V3\" to CNTK</a> and <a href=\"https://github.com/Microsoft/MMdnn/issues/19\" rel=\"nofollow\">related issue</a></p>\n</li>\n<li>\n<p><a href=\"https://github.com/Microsoft/MMdnn/blob/master/docs/tf2pytorch.md\" rel=\"nofollow\">TensorFlow slim model \"ResNet V2 152\" to PyTorch</a></p>\n</li>\n<li>\n<p><a href=\"https://github.com/Microsoft/MMdnn/issues/85\" rel=\"nofollow\">Mxnet model \"LResNet50E-IR\" to TensorFlow</a> and <a href=\"https://github.com/Microsoft/MMdnn/issues/135\" rel=\"nofollow\">related issue</a></p>\n</li>\n</ul>\n<h3>Users' Examples</h3>\n<ul>\n<li>\n<p><a href=\"https://github.com/Microsoft/MMdnn/issues/6\" rel=\"nofollow\">MXNet \"ResNet-152-11k\" to PyTorch</a></p>\n</li>\n<li>\n<p><a href=\"https://blog.paperspace.com/convert-full-imagenet-pre-trained-model-from-mxnet-to-pytorch/\" rel=\"nofollow\">Another Example of MXNet \"ResNet-152-11k\" to PyTorch</a></p>\n</li>\n<li>\n<p><a href=\"https://github.com/Microsoft/MMdnn/issues/58\" rel=\"nofollow\">MXNet \"ResNeXt\" to Keras</a></p>\n</li>\n<li>\n<p><a href=\"https://github.com/Microsoft/MMdnn/issues/22\" rel=\"nofollow\">TensorFlow \"ResNet-101\" to PyTorch</a></p>\n</li>\n<li>\n<p><a href=\"https://github.com/Microsoft/MMdnn/issues/11\" rel=\"nofollow\">TensorFlow \"mnist mlp model\" to CNTK</a></p>\n</li>\n<li>\n<p><a href=\"https://github.com/Microsoft/MMdnn/issues/30\" rel=\"nofollow\">TensorFlow \"Inception_v3\" to MXNet</a></p>\n</li>\n<li>\n<p><a href=\"https://github.com/Microsoft/MMdnn/issues/29\" rel=\"nofollow\">Caffe \"voc-fcn\" to TensorFlow</a></p>\n</li>\n<li>\n<p><a href=\"https://github.com/Microsoft/MMdnn/issues/10\" rel=\"nofollow\">Caffe \"AlexNet\" to TensorFlow</a></p>\n</li>\n<li>\n<p><a href=\"https://github.com/Microsoft/MMdnn/issues/26\" rel=\"nofollow\">Caffe \"inception_v4\" to TensorFlow</a></p>\n</li>\n<li>\n<p><a href=\"https://github.com/Microsoft/MMdnn/issues/27\" rel=\"nofollow\">Caffe \"VGG16_SOD\" to TensorFlow</a></p>\n</li>\n<li>\n<p><a href=\"https://github.com/Microsoft/MMdnn/issues/48\" rel=\"nofollow\">Caffe \"SqueezeNet v1.1\" to CNTK</a></p>\n</li>\n</ul>\n<hr>\n<h2>Contributing</h2>\n<p>Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to and actually do, grant us\nthe rights to use your contribution. For details, visit <a href=\"https://cla.microsoft.com\" rel=\"nofollow\">https://cla.microsoft.com</a>.</p>\n<p>When you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.</p>\n<p>This project has adopted the <a href=\"https://opensource.microsoft.com/codeofconduct/\" rel=\"nofollow\">Microsoft Open Source Code of Conduct</a>.\nFor more information see the <a href=\"https://opensource.microsoft.com/codeofconduct/faq/\" rel=\"nofollow\">Code of Conduct FAQ</a> or\ncontact <a href=\"mailto:opencode@microsoft.com\">opencode@microsoft.com</a> with any additional questions or comments.</p>\n<h3>Intermediate Representation</h3>\n<p>The intermediate representation stores the <strong>network architecture</strong> in <strong>protobuf binary</strong> and <strong>pre-trained weights</strong> in <strong>NumPy</strong> native format.</p>\n<blockquote>\n<p>[Note!] Currently the IR weights data is in NHWC (channel last) format.</p>\n</blockquote>\n<p>Details are in <a href=\"https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/common/IR/ops.pbtxt\" rel=\"nofollow\">ops.txt</a> and <a href=\"https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/common/IR/graph.proto\" rel=\"nofollow\">graph.proto</a>. New operators and any comments are welcome.</p>\n<h3>Frameworks</h3>\n<p>We are working on other frameworks conversion and visualization, such as PyTorch, CoreML and so on. We're investigating more RNN related operators. Any contributions and suggestions are welcome! Details in <a href=\"https://github.com/Microsoft/MMdnn/wiki/Contribution-Guideline\" rel=\"nofollow\">Contribution Guideline</a>.</p>\n<h2>Authors</h2>\n<p>Yu Liu (Peking University): Project Developer &amp; Maintainer</p>\n<p>Cheng CHEN (Microsoft Research Asia): Caffe, CNTK, CoreML Emitter, Keras, MXNet, TensorFlow</p>\n<p>Jiahao YAO (Peking University): CoreML, MXNet Emitter, PyTorch Parser; HomePage</p>\n<p>Ru ZHANG (Chinese Academy of Sciences): CoreML Emitter, DarkNet Parser, Keras, TensorFlow frozen graph Parser; Yolo and SSD models; Tests</p>\n<p>Yuhao ZHOU (Shanghai Jiao Tong University): MXNet</p>\n<p>Tingting QIN (Microsoft Research Asia): Caffe Emitter</p>\n<p>Tong ZHAN (Microsoft): ONNX Emitter</p>\n<p>Qianwen WANG (Hong Kong University of Science and Technology): Visualization</p>\n<h2>Acknowledgements</h2>\n<p>Thanks to <a href=\"https://github.com/ethereon\" rel=\"nofollow\">Saumitro Dasgupta</a>, the initial code of <em>caffe -&gt; IR converting</em> is references to his project <a href=\"https://github.com/ethereon/caffe-tensorflow\" rel=\"nofollow\">caffe-tensorflow</a>.</p>\n<h2>License</h2>\n<p>Licensed under the <a href=\"LICENSE\" rel=\"nofollow\">MIT</a> license.</p>\n\n          </div>"}, "last_serial": 7154969, "releases": {"0.1.5": [{"comment_text": "", "digests": {"md5": "8da02daa32aa40ec92c32dc58ff63067", "sha256": "50d4aaf4b592bfdc3cac82bb02aeedf1e66565231e83be99b0cd4ae76948cb66"}, "downloads": -1, "filename": "mmdnn-0.1.5-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "8da02daa32aa40ec92c32dc58ff63067", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 209142, "upload_time": "2018-04-10T13:23:39", "upload_time_iso_8601": "2018-04-10T13:23:39.475418Z", "url": "https://files.pythonhosted.org/packages/54/96/9147077bdce25102c721de81d61de1fab29a0dee3cc91f8170f7d4548061/mmdnn-0.1.5-py2.py3-none-any.whl", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "e681d79e3909449d81d3680e1d0e1087", "sha256": "db63fd3253c7a93e93f376eff30529ffce5ef88e32cb316dc7fffbb60a11e33a"}, "downloads": -1, "filename": "mmdnn-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e681d79e3909449d81d3680e1d0e1087", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 246313, "upload_time": "2018-05-15T08:48:32", "upload_time_iso_8601": "2018-05-15T08:48:32.240376Z", "url": "https://files.pythonhosted.org/packages/f3/4f/20f0c72d3e34c985cf8063aa35113fe4047c2352eee6474c39dae55e8a8f/mmdnn-0.2.0-py2.py3-none-any.whl", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "26f111a534d302f62bb6c3df2450db21", "sha256": "279f411edded9216ad0eace48d7ed0762f9614142e94a7211ee18d0577f94c1b"}, "downloads": -1, "filename": "mmdnn-0.2.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "26f111a534d302f62bb6c3df2450db21", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 249495, "upload_time": "2018-05-22T09:15:27", "upload_time_iso_8601": "2018-05-22T09:15:27.468577Z", "url": "https://files.pythonhosted.org/packages/d1/1b/fd65b54598c284947d6e561d4c843f719654654491cd015a7b5efc3991bc/mmdnn-0.2.1-py2.py3-none-any.whl", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "0b8961f6faca34b96ab25a54f4f8d5d8", "sha256": "f564f7f28531479a177f28595f0d19aa0721f5864e3f9aa6dbece73664cb2f5f"}, "downloads": -1, "filename": "mmdnn-0.2.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "0b8961f6faca34b96ab25a54f4f8d5d8", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 266269, "upload_time": "2018-06-11T09:16:25", "upload_time_iso_8601": "2018-06-11T09:16:25.064365Z", "url": "https://files.pythonhosted.org/packages/1a/06/0b65c2574eea2c0fece070e16d34152d523c9fcb163607639a20a313269b/mmdnn-0.2.2-py2.py3-none-any.whl", "yanked": false}], "0.2.3": [{"comment_text": "", "digests": {"md5": "9c90be9c6ca52c98e663adbad608af1b", "sha256": "62c37362ce50a56b1292b73debca29295195ce0b20cda3457e87fdbc9544e617"}, "downloads": -1, "filename": "mmdnn-0.2.3-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "9c90be9c6ca52c98e663adbad608af1b", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 284008, "upload_time": "2018-07-21T02:50:09", "upload_time_iso_8601": "2018-07-21T02:50:09.773743Z", "url": "https://files.pythonhosted.org/packages/3e/e1/e7389325a160f9134b53b9d3813a074109ba33ba1838ddec24fe8eb7c973/mmdnn-0.2.3-py2.py3-none-any.whl", "yanked": false}], "0.2.4": [{"comment_text": "", "digests": {"md5": "07e7176e139e4d3c153d76f5e42ca9c1", "sha256": "16eabad531b49bb10cb12961638daa453917336122a72f77b01981a9c118fdee"}, "downloads": -1, "filename": "mmdnn-0.2.4-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "07e7176e139e4d3c153d76f5e42ca9c1", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 316706, "upload_time": "2019-03-03T04:26:53", "upload_time_iso_8601": "2019-03-03T04:26:53.394271Z", "url": "https://files.pythonhosted.org/packages/ce/98/57bfb7de7a99106765433a78690ff089ae564d0a37fba871adf136c3f00b/mmdnn-0.2.4-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a659599534646667883346c944a8687f", "sha256": "67a4d157aae2eaf5377c2a41f81465b93489d15077bb9d795d3c3a75f6b3539b"}, "downloads": -1, "filename": "mmdnn-0.2.4.tar.gz", "has_sig": false, "md5_digest": "a659599534646667883346c944a8687f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 237909, "upload_time": "2019-03-03T04:26:55", "upload_time_iso_8601": "2019-03-03T04:26:55.294783Z", "url": "https://files.pythonhosted.org/packages/b6/28/d0b2d32c1f33018592f829531f2b880f86b303fdb9b9d52ded50238736ad/mmdnn-0.2.4.tar.gz", "yanked": false}], "0.2.5": [{"comment_text": "", "digests": {"md5": "d4d84e98e071dc37acd531ec598e1299", "sha256": "c8f7105e46e112a6b313eabda2cccd50a053afb90240233f30f3cb0e5a33ff24"}, "downloads": -1, "filename": "mmdnn-0.2.5-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "d4d84e98e071dc37acd531ec598e1299", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 317326, "upload_time": "2019-04-16T03:48:04", "upload_time_iso_8601": "2019-04-16T03:48:04.755260Z", "url": "https://files.pythonhosted.org/packages/a5/20/1fb6420b806c546392c045f98ff3d0ede51011db2b56f9552a18a1b31506/mmdnn-0.2.5-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6c024653e8952e8b64b7dea548f964cc", "sha256": "cc37036c2c103c7296bf03aaa00acc258cbef301e3663b168b86fd4b9b2be09c"}, "downloads": -1, "filename": "mmdnn-0.2.5.tar.gz", "has_sig": false, "md5_digest": "6c024653e8952e8b64b7dea548f964cc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 238436, "upload_time": "2019-04-16T03:48:06", "upload_time_iso_8601": "2019-04-16T03:48:06.663310Z", "url": "https://files.pythonhosted.org/packages/26/30/cb8b4e8809b2c64163e74838cccd1684bd834437fb1c85aad986e177a3aa/mmdnn-0.2.5.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "508f3e386039366b2274cb41ba6f66d5", "sha256": "f79cc1c2d4654385b8169e3b1326d9ee4820126f805028904e8635d410139245"}, "downloads": -1, "filename": "mmdnn-0.3.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "508f3e386039366b2274cb41ba6f66d5", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 320200, "upload_time": "2020-05-03T05:52:31", "upload_time_iso_8601": "2020-05-03T05:52:31.121704Z", "url": "https://files.pythonhosted.org/packages/67/0a/ad7fa4d13ab5c29505097929fc4c99faac750982ab5c94532ccf2a796df6/mmdnn-0.3.0-py2.py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "508f3e386039366b2274cb41ba6f66d5", "sha256": "f79cc1c2d4654385b8169e3b1326d9ee4820126f805028904e8635d410139245"}, "downloads": -1, "filename": "mmdnn-0.3.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "508f3e386039366b2274cb41ba6f66d5", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 320200, "upload_time": "2020-05-03T05:52:31", "upload_time_iso_8601": "2020-05-03T05:52:31.121704Z", "url": "https://files.pythonhosted.org/packages/67/0a/ad7fa4d13ab5c29505097929fc4c99faac750982ab5c94532ccf2a796df6/mmdnn-0.3.0-py2.py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 00:53:16 2020"}