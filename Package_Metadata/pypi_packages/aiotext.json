{"info": {"author": "Eric Wiener", "author_email": "ericwiener3@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# All-in-one Text Cleaner\nThis package was created to speed up the process of cleaning text for natural language processing and machine learning. The package does the following:\n- Converts all text to lowercase\n- Expands contractions using [pycontractions](https://pypi.org/project/pycontractions/) trained on the glove-twitter-100 word2vec training set (optional)\n- Removes text in brackets. Matches \"()\",\"[]\", or \"{}\" (optional)\n- Combines concatenations (turns \"georgetown-louisville\" into \"georgetown louisville\" or \"georgetownlousivelle\"). Matches all types of hyphens.\n- Splits sentences on punctuation using algorithm defined in [this stackoverflow post](https://stackoverflow.com/a/31505798/6942666).\n- Tokenizes sentences.\n- Lemmatizes tokens using NLTK WordNetLemmatizer and a lookup table between Penn Bank tags and Word Net.\n\n## Installation\n```\n$ pip3 install aiotext\n$ pip3 install git+https://github.com/EricWiener/pycontractions\n```\nPlease note that pycontractions is specified as a dependency and will download from PyPi and work, but the branch I linked to above has multiple improvements.\n\n\n## Usage:\n### Options:\n| Option                 | Default                    | Description                                                                                                                                                                                    |\n|------------------------|----------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| expand_contractions    | True                      | If true, contractions will be expanded (it's -> it is). This takes a long time. Especially the first time you run it.                                                                          |\n| strip_text_in_brackets | False                      | If true removes text in brackets. If false the brackets will be removed, but text inside will remain.                                                                                          |\n| combine_concatenations | False                      | If false replaces hyphen with space (george-louis -> george louis). If true just removes hyphen (george-louis -> georgelouis).                                                                 |\n| w2v_path               | None                       | Path to word2vec binary.                                                                                                                                                                       |\n| api_key                | \"word2vec-google-news-300\" | w2v_path will be given preference over api_key. If no valid binary is found at the path, the api will download the key specified. If no key is specified, the Google News vector will be used. |\n\n\n```python\nfrom aiotext import Cleaner\n\ntext = \"Call me Ishmael. Some years ago\u2014never mind how long precisely\u2014having \"\ntext += \"little or no money in my purse, and nothing particular to interest me \"\ntext += \"on shore, I thought I would sail about a little and see the watery part \"\ntext += \"of the world. It is a way I have of driving off the spleen and \"\ntext += \"regulating the circulation.\"\n\n# Initialize cleaner\ncleaner = Cleaner(expand_contractions=True)\n\nassert cleaner.clean(text) == [\n['call', 'me', 'ishmael'],\n['some', 'year', 'ago', 'never', 'mind', 'how', 'long', 'precisely', 'have', 'little', 'or', 'no', 'money', 'in', 'my', 'purse', 'and', 'nothing', 'particular',\n    'to', 'interest', 'me', 'on', 'shore', 'i', 'think', 'i', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world'],\n['it', 'be', 'a', 'way', 'i', 'have', 'of', 'drive', 'off',\n    'the', 'spleen', 'and', 'regulate', 'the', 'circulation'],\n]\n```\n\n# Notes\n- Please note you might have to manually quit and reattempt to run the program the first time you run it if it gets stuck after downloading the contractions dataset.\n- Wordnet is used to lemmatize based on the parts of speech given by Penn Bank. Since Wordnet is limited in the number of options (eg. no pronouns), some words will not be processed. This is done to preserve the root word. For instance, \"us\" Wordnet will convert \"us\" to \"u\". In order to avoid this, \"us\" will not be passed into the lemmatizer.\n- You may need to run the following if `wordnet` or `punkt` is not found\n```python\npython3\n>> import nltk\n>> nltk.download('wordnet')\n>> nltk.download('punkt')\n```\n\n## Change log\n- 1.0.0: Initial release\n- 1.0.1: Corrected handling of sentences without punctuation and brackets\n- 1.0.2: Added modified contraction expander download. Also made changes to solve [issue](https://github.com/nltk/nltk/issues/2269) with NLTK lemmatizer.\n- 1.0.3: Added options for specifying word2vec model to use for contraction expansion\n- 1.0.4: Minor syntax error\n- 1.0.5: Changed passing of arguments, updated README, improved tokenization, and changed order of parsing to tag POS before cleaning text.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/EricWiener/aiotext", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "aiotext", "package_url": "https://pypi.org/project/aiotext/", "platform": "", "project_url": "https://pypi.org/project/aiotext/", "project_urls": {"Homepage": "https://github.com/EricWiener/aiotext"}, "release_url": "https://pypi.org/project/aiotext/1.0.6/", "requires_dist": ["scikit-learn", "pycontractions", "nltk"], "requires_python": "", "summary": "All in one text processor and cleaner.", "version": "1.0.6", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>All-in-one Text Cleaner</h1>\n<p>This package was created to speed up the process of cleaning text for natural language processing and machine learning. The package does the following:</p>\n<ul>\n<li>Converts all text to lowercase</li>\n<li>Expands contractions using <a href=\"https://pypi.org/project/pycontractions/\" rel=\"nofollow\">pycontractions</a> trained on the glove-twitter-100 word2vec training set (optional)</li>\n<li>Removes text in brackets. Matches \"()\",\"[]\", or \"{}\" (optional)</li>\n<li>Combines concatenations (turns \"georgetown-louisville\" into \"georgetown louisville\" or \"georgetownlousivelle\"). Matches all types of hyphens.</li>\n<li>Splits sentences on punctuation using algorithm defined in <a href=\"https://stackoverflow.com/a/31505798/6942666\" rel=\"nofollow\">this stackoverflow post</a>.</li>\n<li>Tokenizes sentences.</li>\n<li>Lemmatizes tokens using NLTK WordNetLemmatizer and a lookup table between Penn Bank tags and Word Net.</li>\n</ul>\n<h2>Installation</h2>\n<pre><code>$ pip3 install aiotext\n$ pip3 install git+https://github.com/EricWiener/pycontractions\n</code></pre>\n<p>Please note that pycontractions is specified as a dependency and will download from PyPi and work, but the branch I linked to above has multiple improvements.</p>\n<h2>Usage:</h2>\n<h3>Options:</h3>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Default</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>expand_contractions</td>\n<td>True</td>\n<td>If true, contractions will be expanded (it's -&gt; it is). This takes a long time. Especially the first time you run it.</td>\n</tr>\n<tr>\n<td>strip_text_in_brackets</td>\n<td>False</td>\n<td>If true removes text in brackets. If false the brackets will be removed, but text inside will remain.</td>\n</tr>\n<tr>\n<td>combine_concatenations</td>\n<td>False</td>\n<td>If false replaces hyphen with space (george-louis -&gt; george louis). If true just removes hyphen (george-louis -&gt; georgelouis).</td>\n</tr>\n<tr>\n<td>w2v_path</td>\n<td>None</td>\n<td>Path to word2vec binary.</td>\n</tr>\n<tr>\n<td>api_key</td>\n<td>\"word2vec-google-news-300\"</td>\n<td>w2v_path will be given preference over api_key. If no valid binary is found at the path, the api will download the key specified. If no key is specified, the Google News vector will be used.</td>\n</tr></tbody></table>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">aiotext</span> <span class=\"kn\">import</span> <span class=\"n\">Cleaner</span>\n\n<span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"s2\">\"Call me Ishmael. Some years ago\u2014never mind how long precisely\u2014having \"</span>\n<span class=\"n\">text</span> <span class=\"o\">+=</span> <span class=\"s2\">\"little or no money in my purse, and nothing particular to interest me \"</span>\n<span class=\"n\">text</span> <span class=\"o\">+=</span> <span class=\"s2\">\"on shore, I thought I would sail about a little and see the watery part \"</span>\n<span class=\"n\">text</span> <span class=\"o\">+=</span> <span class=\"s2\">\"of the world. It is a way I have of driving off the spleen and \"</span>\n<span class=\"n\">text</span> <span class=\"o\">+=</span> <span class=\"s2\">\"regulating the circulation.\"</span>\n\n<span class=\"c1\"># Initialize cleaner</span>\n<span class=\"n\">cleaner</span> <span class=\"o\">=</span> <span class=\"n\">Cleaner</span><span class=\"p\">(</span><span class=\"n\">expand_contractions</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n<span class=\"k\">assert</span> <span class=\"n\">cleaner</span><span class=\"o\">.</span><span class=\"n\">clean</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"p\">[</span>\n<span class=\"p\">[</span><span class=\"s1\">'call'</span><span class=\"p\">,</span> <span class=\"s1\">'me'</span><span class=\"p\">,</span> <span class=\"s1\">'ishmael'</span><span class=\"p\">],</span>\n<span class=\"p\">[</span><span class=\"s1\">'some'</span><span class=\"p\">,</span> <span class=\"s1\">'year'</span><span class=\"p\">,</span> <span class=\"s1\">'ago'</span><span class=\"p\">,</span> <span class=\"s1\">'never'</span><span class=\"p\">,</span> <span class=\"s1\">'mind'</span><span class=\"p\">,</span> <span class=\"s1\">'how'</span><span class=\"p\">,</span> <span class=\"s1\">'long'</span><span class=\"p\">,</span> <span class=\"s1\">'precisely'</span><span class=\"p\">,</span> <span class=\"s1\">'have'</span><span class=\"p\">,</span> <span class=\"s1\">'little'</span><span class=\"p\">,</span> <span class=\"s1\">'or'</span><span class=\"p\">,</span> <span class=\"s1\">'no'</span><span class=\"p\">,</span> <span class=\"s1\">'money'</span><span class=\"p\">,</span> <span class=\"s1\">'in'</span><span class=\"p\">,</span> <span class=\"s1\">'my'</span><span class=\"p\">,</span> <span class=\"s1\">'purse'</span><span class=\"p\">,</span> <span class=\"s1\">'and'</span><span class=\"p\">,</span> <span class=\"s1\">'nothing'</span><span class=\"p\">,</span> <span class=\"s1\">'particular'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'to'</span><span class=\"p\">,</span> <span class=\"s1\">'interest'</span><span class=\"p\">,</span> <span class=\"s1\">'me'</span><span class=\"p\">,</span> <span class=\"s1\">'on'</span><span class=\"p\">,</span> <span class=\"s1\">'shore'</span><span class=\"p\">,</span> <span class=\"s1\">'i'</span><span class=\"p\">,</span> <span class=\"s1\">'think'</span><span class=\"p\">,</span> <span class=\"s1\">'i'</span><span class=\"p\">,</span> <span class=\"s1\">'would'</span><span class=\"p\">,</span> <span class=\"s1\">'sail'</span><span class=\"p\">,</span> <span class=\"s1\">'about'</span><span class=\"p\">,</span> <span class=\"s1\">'a'</span><span class=\"p\">,</span> <span class=\"s1\">'little'</span><span class=\"p\">,</span> <span class=\"s1\">'and'</span><span class=\"p\">,</span> <span class=\"s1\">'see'</span><span class=\"p\">,</span> <span class=\"s1\">'the'</span><span class=\"p\">,</span> <span class=\"s1\">'watery'</span><span class=\"p\">,</span> <span class=\"s1\">'part'</span><span class=\"p\">,</span> <span class=\"s1\">'of'</span><span class=\"p\">,</span> <span class=\"s1\">'the'</span><span class=\"p\">,</span> <span class=\"s1\">'world'</span><span class=\"p\">],</span>\n<span class=\"p\">[</span><span class=\"s1\">'it'</span><span class=\"p\">,</span> <span class=\"s1\">'be'</span><span class=\"p\">,</span> <span class=\"s1\">'a'</span><span class=\"p\">,</span> <span class=\"s1\">'way'</span><span class=\"p\">,</span> <span class=\"s1\">'i'</span><span class=\"p\">,</span> <span class=\"s1\">'have'</span><span class=\"p\">,</span> <span class=\"s1\">'of'</span><span class=\"p\">,</span> <span class=\"s1\">'drive'</span><span class=\"p\">,</span> <span class=\"s1\">'off'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'the'</span><span class=\"p\">,</span> <span class=\"s1\">'spleen'</span><span class=\"p\">,</span> <span class=\"s1\">'and'</span><span class=\"p\">,</span> <span class=\"s1\">'regulate'</span><span class=\"p\">,</span> <span class=\"s1\">'the'</span><span class=\"p\">,</span> <span class=\"s1\">'circulation'</span><span class=\"p\">],</span>\n<span class=\"p\">]</span>\n</pre>\n<h1>Notes</h1>\n<ul>\n<li>Please note you might have to manually quit and reattempt to run the program the first time you run it if it gets stuck after downloading the contractions dataset.</li>\n<li>Wordnet is used to lemmatize based on the parts of speech given by Penn Bank. Since Wordnet is limited in the number of options (eg. no pronouns), some words will not be processed. This is done to preserve the root word. For instance, \"us\" Wordnet will convert \"us\" to \"u\". In order to avoid this, \"us\" will not be passed into the lemmatizer.</li>\n<li>You may need to run the following if <code>wordnet</code> or <code>punkt</code> is not found</li>\n</ul>\n<pre><span class=\"n\">python3</span>\n<span class=\"o\">&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">nltk</span>\n<span class=\"o\">&gt;&gt;</span> <span class=\"n\">nltk</span><span class=\"o\">.</span><span class=\"n\">download</span><span class=\"p\">(</span><span class=\"s1\">'wordnet'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;</span> <span class=\"n\">nltk</span><span class=\"o\">.</span><span class=\"n\">download</span><span class=\"p\">(</span><span class=\"s1\">'punkt'</span><span class=\"p\">)</span>\n</pre>\n<h2>Change log</h2>\n<ul>\n<li>1.0.0: Initial release</li>\n<li>1.0.1: Corrected handling of sentences without punctuation and brackets</li>\n<li>1.0.2: Added modified contraction expander download. Also made changes to solve <a href=\"https://github.com/nltk/nltk/issues/2269\" rel=\"nofollow\">issue</a> with NLTK lemmatizer.</li>\n<li>1.0.3: Added options for specifying word2vec model to use for contraction expansion</li>\n<li>1.0.4: Minor syntax error</li>\n<li>1.0.5: Changed passing of arguments, updated README, improved tokenization, and changed order of parsing to tag POS before cleaning text.</li>\n</ul>\n\n          </div>"}, "last_serial": 5842340, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "fd334d0f3f18a2f3814c1af0818f1f70", "sha256": "79976d70aac3107a7a7c1b482f14d1f66582c17732a46c5412ada0eb17c7cf89"}, "downloads": -1, "filename": "aiotext-1.0.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "fd334d0f3f18a2f3814c1af0818f1f70", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 9245, "upload_time": "2019-04-17T19:39:57", "upload_time_iso_8601": "2019-04-17T19:39:57.774537Z", "url": "https://files.pythonhosted.org/packages/f1/38/a7524e6d7b2cc4af2be68b7a746bc586d2bb1ce5991c9b13d6ca129595c6/aiotext-1.0.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6bdc29f1d9743e5c715f04ace5d3ee11", "sha256": "662cfe439c3ac571e20324d652cee16bbd2352ad22e0feaeab3ff50498a4ba41"}, "downloads": -1, "filename": "aiotext-1.0.0.tar.gz", "has_sig": false, "md5_digest": "6bdc29f1d9743e5c715f04ace5d3ee11", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7232, "upload_time": "2019-04-17T19:39:59", "upload_time_iso_8601": "2019-04-17T19:39:59.957559Z", "url": "https://files.pythonhosted.org/packages/be/70/911e9ef8cfee880f447d18c53282820c20902a1f13471c5246f75ab2f2ab/aiotext-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "dae28592deb30cfd8278afc417140fd3", "sha256": "311b8fa43b93901576e4f503bea46e830a261ab9ca5679bb72c60347a8e5d19c"}, "downloads": -1, "filename": "aiotext-1.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "dae28592deb30cfd8278afc417140fd3", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 9659, "upload_time": "2019-04-17T22:45:13", "upload_time_iso_8601": "2019-04-17T22:45:13.014235Z", "url": "https://files.pythonhosted.org/packages/37/e7/2212254c46b258f9beb8e82110dd769e921caf426db12a90c3757293e75b/aiotext-1.0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3194f4e040b492781617ce4a1a08d82a", "sha256": "58ac44afb2de871ad61b621cbce20a10e4367b91ff806f022bd295482ac88be6"}, "downloads": -1, "filename": "aiotext-1.0.1.tar.gz", "has_sig": false, "md5_digest": "3194f4e040b492781617ce4a1a08d82a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7683, "upload_time": "2019-04-17T22:45:14", "upload_time_iso_8601": "2019-04-17T22:45:14.842921Z", "url": "https://files.pythonhosted.org/packages/fc/8d/3e924f63d0d98c7903fad5fff016c85a0150b85f2c70ca4dd9239a5e2a68/aiotext-1.0.1.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "f2195ae3371b765a5ffba0da2253263b", "sha256": "02bff566a8452fd380279325f66da9ec98260ee5e19d0d82b48cf639d5d6dd11"}, "downloads": -1, "filename": "aiotext-1.0.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "f2195ae3371b765a5ffba0da2253263b", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 9850, "upload_time": "2019-04-18T03:23:52", "upload_time_iso_8601": "2019-04-18T03:23:52.067755Z", "url": "https://files.pythonhosted.org/packages/50/41/55d8f1c3560d59173ec3f7955b618be78a441cc626e84b6551036e66a195/aiotext-1.0.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ec9fc4dc6ef7762f74d1ce1b4f0aa62c", "sha256": "5c51b535d8904c14709af250680b024fa62a1e696249cc1f8005d4e8d7effda3"}, "downloads": -1, "filename": "aiotext-1.0.2.tar.gz", "has_sig": false, "md5_digest": "ec9fc4dc6ef7762f74d1ce1b4f0aa62c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7879, "upload_time": "2019-04-18T03:23:54", "upload_time_iso_8601": "2019-04-18T03:23:54.824520Z", "url": "https://files.pythonhosted.org/packages/01/57/b974b3fd24ef7432949b51a0761ab8fff69497993d6b75d7aa69c1cecd38/aiotext-1.0.2.tar.gz", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "5c1a4e63d483dd04a0982430e0cfc61b", "sha256": "1de9e50164f5a6370fecfe556be2be277c5a756dd645c2b4a71854d38cadaa17"}, "downloads": -1, "filename": "aiotext-1.0.3-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "5c1a4e63d483dd04a0982430e0cfc61b", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 10013, "upload_time": "2019-04-18T14:17:29", "upload_time_iso_8601": "2019-04-18T14:17:29.797187Z", "url": "https://files.pythonhosted.org/packages/c3/b2/8a74f4157bd2edcb0a588bd129202fb30b2d926f5c8ec14b392cbfa9b1ad/aiotext-1.0.3-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f9b902a47f75cbb14ddf00118a8270bc", "sha256": "4ffc63bfa6eb43cea5b791f81eec0334df0310a6817e754d2363b7ba12dee1bd"}, "downloads": -1, "filename": "aiotext-1.0.3.tar.gz", "has_sig": false, "md5_digest": "f9b902a47f75cbb14ddf00118a8270bc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8035, "upload_time": "2019-04-18T14:17:32", "upload_time_iso_8601": "2019-04-18T14:17:32.589250Z", "url": "https://files.pythonhosted.org/packages/45/ea/b82029b3ce8b14e9336172b601349f7069ba6e7233179a27b2a03ec2de84/aiotext-1.0.3.tar.gz", "yanked": false}], "1.0.4": [{"comment_text": "", "digests": {"md5": "d06a06e34e3bf98b2ec5df6e182f8203", "sha256": "b042a1708b216453a93068afd6d9a46df356299fdd540da131c59385912c704f"}, "downloads": -1, "filename": "aiotext-1.0.4-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "d06a06e34e3bf98b2ec5df6e182f8203", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 10007, "upload_time": "2019-04-18T14:21:50", "upload_time_iso_8601": "2019-04-18T14:21:50.338475Z", "url": "https://files.pythonhosted.org/packages/d0/75/dcbcc254e355b7388b061feb99dad74a2d466750632348ce641751aacda9/aiotext-1.0.4-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f3c4673ade638e023e8655caf4422131", "sha256": "da432f7775aad301e9fb98c89f988155404f10c9784e3802381d37acd0f06e63"}, "downloads": -1, "filename": "aiotext-1.0.4.tar.gz", "has_sig": false, "md5_digest": "f3c4673ade638e023e8655caf4422131", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8025, "upload_time": "2019-04-18T14:21:53", "upload_time_iso_8601": "2019-04-18T14:21:53.780192Z", "url": "https://files.pythonhosted.org/packages/24/ca/9812450f7042f6aaa9fddf26680be43c4dca0e66655d30df230de38fd772/aiotext-1.0.4.tar.gz", "yanked": false}], "1.0.5": [{"comment_text": "", "digests": {"md5": "fcdfc701f265f2659c61044cdcda8723", "sha256": "a2907cb3529b27e243cd242748affd4bf2fc9dff139850a61007aef429b2e2a4"}, "downloads": -1, "filename": "aiotext-1.0.5-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "fcdfc701f265f2659c61044cdcda8723", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 9315, "upload_time": "2019-04-18T17:16:07", "upload_time_iso_8601": "2019-04-18T17:16:07.931477Z", "url": "https://files.pythonhosted.org/packages/52/45/0ba589ce4d077af121cad34af7f9660f7d780b2afc215245440c9e4970a4/aiotext-1.0.5-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9f51d12c7ef29548ef34a89ea2108c50", "sha256": "e4369a5733033a07e6583b6469e818e0a6a11d2e2f425616e6631fdca63b84dd"}, "downloads": -1, "filename": "aiotext-1.0.5.tar.gz", "has_sig": false, "md5_digest": "9f51d12c7ef29548ef34a89ea2108c50", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7600, "upload_time": "2019-04-18T17:16:10", "upload_time_iso_8601": "2019-04-18T17:16:10.039705Z", "url": "https://files.pythonhosted.org/packages/d7/ce/590b4171bbb57474721df93c4ad7f60fdaff86583271ba4efbc2b828e043/aiotext-1.0.5.tar.gz", "yanked": false}], "1.0.6": [{"comment_text": "", "digests": {"md5": "72b1429c39a11406584ee56152280fb3", "sha256": "0126d382913c419e166a5d184c5d4b8465f533c5090c996bf91ed4e776667146"}, "downloads": -1, "filename": "aiotext-1.0.6-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "72b1429c39a11406584ee56152280fb3", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 9403, "upload_time": "2019-09-17T15:35:59", "upload_time_iso_8601": "2019-09-17T15:35:59.322608Z", "url": "https://files.pythonhosted.org/packages/e8/e4/d463a3cc81e5687a34e2b80e15daff52fbee53293c1b2c5cf525e937cbcc/aiotext-1.0.6-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "92497cd2ffec4a6c274b436004743417", "sha256": "c650d54f3261ea8d522b169768ace8ae47c5679f0cd073c25dc03c51e5cc51fd"}, "downloads": -1, "filename": "aiotext-1.0.6.tar.gz", "has_sig": false, "md5_digest": "92497cd2ffec4a6c274b436004743417", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7680, "upload_time": "2019-09-17T15:36:01", "upload_time_iso_8601": "2019-09-17T15:36:01.728350Z", "url": "https://files.pythonhosted.org/packages/86/39/17be2687b8604c5aecbd137f39716880a9c7639160f4364d45a12233e7df/aiotext-1.0.6.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "72b1429c39a11406584ee56152280fb3", "sha256": "0126d382913c419e166a5d184c5d4b8465f533c5090c996bf91ed4e776667146"}, "downloads": -1, "filename": "aiotext-1.0.6-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "72b1429c39a11406584ee56152280fb3", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 9403, "upload_time": "2019-09-17T15:35:59", "upload_time_iso_8601": "2019-09-17T15:35:59.322608Z", "url": "https://files.pythonhosted.org/packages/e8/e4/d463a3cc81e5687a34e2b80e15daff52fbee53293c1b2c5cf525e937cbcc/aiotext-1.0.6-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "92497cd2ffec4a6c274b436004743417", "sha256": "c650d54f3261ea8d522b169768ace8ae47c5679f0cd073c25dc03c51e5cc51fd"}, "downloads": -1, "filename": "aiotext-1.0.6.tar.gz", "has_sig": false, "md5_digest": "92497cd2ffec4a6c274b436004743417", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7680, "upload_time": "2019-09-17T15:36:01", "upload_time_iso_8601": "2019-09-17T15:36:01.728350Z", "url": "https://files.pythonhosted.org/packages/86/39/17be2687b8604c5aecbd137f39716880a9c7639160f4364d45a12233e7df/aiotext-1.0.6.tar.gz", "yanked": false}], "timestamp": "Thu May  7 16:20:42 2020"}