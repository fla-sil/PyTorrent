{"info": {"author": "Edward Newell", "author_email": "edward.newell@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# Fast Sampling from Categorical Distributions on the GPU using PyTorch\n\nCurrently, the `pytorch.distributions.Categorical` is a bit slow if you\nneed to draw a large number of samples from a static categorical distribution.\nAlso, you are limited to having no more than 2^24 different outcomes.\n\nThe \n[\"alias method\"](http://cgi.cs.mcgill.ca/~enewel3/posts/alias-method/index.html)\nlet's you sample very quickly from distributions with large support, and this\nimplementation in PyTorch let's you have more than 2^24 outcomes.\n\nI needed this for rapid generation of word embeddings in\n[hilbert](https://github.com/enewe101/hilbert).\n\n# Install\n\n``pip install pytorch-categorical``\n\n# Use\n\n    import pytorch_categorical\n\timport torch\n\n\tnum_outcomes = int(1e6)\n    probs = torch.random(num_outcomes)\n\tprobs /= probs.sum()\n\n\tsampler = pytorch_categorical.Categorical(probs)\n\n\tnum_samples = int(1e6)\n\tsamples = sampler.sample((num_samples,))\n\nThe constructor also takes a `dtype` and a `device` if you want to specify \nthem.  By default\n\n# Posterity\nAt the time I made this, there was an open issue to incorporate a more rapid\nsampler based on the alias method, but nothing was released yet.  Hopefully\nthat will get into a release soon!  For now, use this!\n\n# Tested.  It's Correct and Fast.\nI've backed this by a few simple tests, including a benchmark against torch.\nThis implementation takes about 175X longer to construct a sampler with one\nmillion outcomes, but after this up-front cost, it yields (draws of ten\nthousand) samples about 3000X faster (with greater advantage the more samples\nthat are eventually drawn).  So the main usecase is when you have to draw many\nsamples from a stable distribution.\n\nRun the correctness and benchmark tests: ``python test.py``.\n\nEnjoy!", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/enewe101/pytorch-categorical", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "pytorch-categorical", "package_url": "https://pypi.org/project/pytorch-categorical/", "platform": "", "project_url": "https://pypi.org/project/pytorch-categorical/", "project_urls": {"Homepage": "https://github.com/enewe101/pytorch-categorical"}, "release_url": "https://pypi.org/project/pytorch-categorical/0.0.3/", "requires_dist": null, "requires_python": "", "summary": "Draw a large number of samples from a categorical distribution with large support on the GPU using Pytorch.", "version": "0.0.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Fast Sampling from Categorical Distributions on the GPU using PyTorch</h1>\n<p>Currently, the <code>pytorch.distributions.Categorical</code> is a bit slow if you\nneed to draw a large number of samples from a static categorical distribution.\nAlso, you are limited to having no more than 2^24 different outcomes.</p>\n<p>The\n<a href=\"http://cgi.cs.mcgill.ca/%7Eenewel3/posts/alias-method/index.html\" rel=\"nofollow\">\"alias method\"</a>\nlet's you sample very quickly from distributions with large support, and this\nimplementation in PyTorch let's you have more than 2^24 outcomes.</p>\n<p>I needed this for rapid generation of word embeddings in\n<a href=\"https://github.com/enewe101/hilbert\" rel=\"nofollow\">hilbert</a>.</p>\n<h1>Install</h1>\n<p><code>pip install pytorch-categorical</code></p>\n<h1>Use</h1>\n<pre><code>import pytorch_categorical\nimport torch\n\nnum_outcomes = int(1e6)\nprobs = torch.random(num_outcomes)\nprobs /= probs.sum()\n\nsampler = pytorch_categorical.Categorical(probs)\n\nnum_samples = int(1e6)\nsamples = sampler.sample((num_samples,))\n</code></pre>\n<p>The constructor also takes a <code>dtype</code> and a <code>device</code> if you want to specify\nthem.  By default</p>\n<h1>Posterity</h1>\n<p>At the time I made this, there was an open issue to incorporate a more rapid\nsampler based on the alias method, but nothing was released yet.  Hopefully\nthat will get into a release soon!  For now, use this!</p>\n<h1>Tested.  It's Correct and Fast.</h1>\n<p>I've backed this by a few simple tests, including a benchmark against torch.\nThis implementation takes about 175X longer to construct a sampler with one\nmillion outcomes, but after this up-front cost, it yields (draws of ten\nthousand) samples about 3000X faster (with greater advantage the more samples\nthat are eventually drawn).  So the main usecase is when you have to draw many\nsamples from a stable distribution.</p>\n<p>Run the correctness and benchmark tests: <code>python test.py</code>.</p>\n<p>Enjoy!</p>\n\n          </div>"}, "last_serial": 5105350, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "8e4851e01c259a5f130c877f43f622f0", "sha256": "df34d1efddae20e26869a713e6b4c5f013f7a48e3af31050351206098f7c57c1"}, "downloads": -1, "filename": "pytorch-categorical-0.0.1.tar.gz", "has_sig": false, "md5_digest": "8e4851e01c259a5f130c877f43f622f0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3675, "upload_time": "2019-04-03T21:49:09", "upload_time_iso_8601": "2019-04-03T21:49:09.532641Z", "url": "https://files.pythonhosted.org/packages/4d/7e/71e0ba8e8375b1380bbaddbd00ca3f040098f62402e2fc04f331c4582ab3/pytorch-categorical-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "679e7cd7b16c2959b9e6124eeb6f9eb4", "sha256": "eb53ab0512f7a9dc0f1d274da016e0c66b5c51960ff3add6ba193be873c0c676"}, "downloads": -1, "filename": "pytorch-categorical-0.0.2.tar.gz", "has_sig": false, "md5_digest": "679e7cd7b16c2959b9e6124eeb6f9eb4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4208, "upload_time": "2019-04-04T04:49:35", "upload_time_iso_8601": "2019-04-04T04:49:35.985835Z", "url": "https://files.pythonhosted.org/packages/ee/e4/666a00a92c7968c236f69ba80fb15961b3a10b0414e6ca6611a9b5a3466d/pytorch-categorical-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "82176550a53d5c2f6cae3700b680fd09", "sha256": "d71c6d93da62cab4d2bd57d1ea58105ba1354bf14e85a9b94ca4e9c506bf93cb"}, "downloads": -1, "filename": "pytorch-categorical-0.0.3.tar.gz", "has_sig": false, "md5_digest": "82176550a53d5c2f6cae3700b680fd09", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4340, "upload_time": "2019-04-05T19:38:58", "upload_time_iso_8601": "2019-04-05T19:38:58.903958Z", "url": "https://files.pythonhosted.org/packages/b0/b8/8b82b5c66bef1fdfd8b6c5241fc175cf5e9d9ac33fec7aebeb8dda796177/pytorch-categorical-0.0.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "82176550a53d5c2f6cae3700b680fd09", "sha256": "d71c6d93da62cab4d2bd57d1ea58105ba1354bf14e85a9b94ca4e9c506bf93cb"}, "downloads": -1, "filename": "pytorch-categorical-0.0.3.tar.gz", "has_sig": false, "md5_digest": "82176550a53d5c2f6cae3700b680fd09", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4340, "upload_time": "2019-04-05T19:38:58", "upload_time_iso_8601": "2019-04-05T19:38:58.903958Z", "url": "https://files.pythonhosted.org/packages/b0/b8/8b82b5c66bef1fdfd8b6c5241fc175cf5e9d9ac33fec7aebeb8dda796177/pytorch-categorical-0.0.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:14:00 2020"}