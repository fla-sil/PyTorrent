{"info": {"author": "Scofield", "author_email": "2387813033@qq.com", "bugtrack_url": null, "classifiers": ["Framework :: Scrapy", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.4"], "description": "scrapyscript allows you to invoke one or more spiders from a script, have them all run in parallel, and get the results back as a single list.  No scrapy project, no boilerplate, no hassle.", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/aox-lei/scrapy-script", "keywords": "scrapy", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "scrapy_script", "package_url": "https://pypi.org/project/scrapy_script/", "platform": "", "project_url": "https://pypi.org/project/scrapy_script/", "project_urls": {"Homepage": "https://github.com/aox-lei/scrapy-script"}, "release_url": "https://pypi.org/project/scrapy_script/1.0.1/", "requires_dist": null, "requires_python": "", "summary": "Run a Scrapy spider programmatically from a script or a Celery task - no project required.", "version": "1.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>scrapyscript allows you to invoke one or more spiders from a script, have them all run in parallel, and get the results back as a single list.  No scrapy project, no boilerplate, no hassle.</p>\n\n          </div>"}, "last_serial": 6078574, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "fef0f949b6c227ca824f8c87d968a172", "sha256": "ae5f148da038f5cfe7e11afc5003f34699be73ba047b63a9b5ca3c4e40e4c932"}, "downloads": -1, "filename": "scrapy_script-1.0.0.tar.gz", "has_sig": false, "md5_digest": "fef0f949b6c227ca824f8c87d968a172", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4659, "upload_time": "2019-11-05T01:45:09", "upload_time_iso_8601": "2019-11-05T01:45:09.007747Z", "url": "https://files.pythonhosted.org/packages/5c/fa/4142c78fa8244dee1573bca3dc817877f59bca0b2fcea44d0b27cd49875f/scrapy_script-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "44ae5578568adc2258af7f8987d41c9e", "sha256": "d6ca849eb78a5789b5d6f656820564e903df3a6ba88b36f389e5db63fa8d83a7"}, "downloads": -1, "filename": "scrapy_script-1.0.1.tar.gz", "has_sig": false, "md5_digest": "44ae5578568adc2258af7f8987d41c9e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4669, "upload_time": "2019-11-05T01:52:57", "upload_time_iso_8601": "2019-11-05T01:52:57.546928Z", "url": "https://files.pythonhosted.org/packages/e8/7e/07e032b6fefdb93e8d3c169d582024a068967f5c2a9e2baa9924d8684b75/scrapy_script-1.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "44ae5578568adc2258af7f8987d41c9e", "sha256": "d6ca849eb78a5789b5d6f656820564e903df3a6ba88b36f389e5db63fa8d83a7"}, "downloads": -1, "filename": "scrapy_script-1.0.1.tar.gz", "has_sig": false, "md5_digest": "44ae5578568adc2258af7f8987d41c9e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4669, "upload_time": "2019-11-05T01:52:57", "upload_time_iso_8601": "2019-11-05T01:52:57.546928Z", "url": "https://files.pythonhosted.org/packages/e8/7e/07e032b6fefdb93e8d3c169d582024a068967f5c2a9e2baa9924d8684b75/scrapy_script-1.0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:56:41 2020"}