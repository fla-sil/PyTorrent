{"info": {"author": "Jo\u00e3o Ribeiro", "author_email": "jmribeiro77209@gmail.com", "bugtrack_url": null, "classifiers": ["Programming Language :: Python :: 3"], "description": "# YAAF: Yet Another Agents Framework\n\n_A minimalistic reinforcement learning framework._\n\n## Installation \n\n      $ pip install yaaf                               # Install YAAF\n      $ pip install gym[atari]                         # Install OpenAI Gym's Atari environments\n      $ git clone https://github.com/jmribeiro/yaaf    # Clone the repo for the examples and tutorials\n      $ cd yaaf/examples                               \n      $ python 0_space_invaders_random_agent.py        # Run example\n\n- **Rapid Prototyping**: Setting up an agent on an environment can easily be done with a few lines of code:\n\n      # Setup the Environment\n      environment = OpenAIGymEnvironment(name=\"SpaceInvaders-v0\", render=True)\n\n      # Setup the Agent\n      agent = RandomAgent(environment.action_space)\n\n      # Run the agent on the environment for 5 episodes\n      runner = EpisodeRunners(agent, environment, episodes=5)\n      runner.run()\n      environment.close()\n\n- **Simplicity**\n\n    **States**: Tensors/Numpy arrays with a given shape;\n\n    **Actions**: Integers if a discrete action space, Floats if a continuous action space;\n\n    **Timesteps**: Named tuples in shape of (state, action, reward, next_, is_terminal, info)\n\n    **Agents**: Objects capable of execution actions when given a state. If trainable, capable of learning when given a timestep \n\n    **Environments**: Objects which evolve over time, where agents can execute actions;\n\n    **Runners**: Objects that interact an actor (agent or policy) on an environment, notifying a list of observers at every timestep;\n\n    **Metrics**: Objects that evaluate an agent's or policy's performance on a given run. Passed as observables to the Runners.\n\n    **Presenters** (TODO): Objects that display an agent's performance on a given run. Used to make plots and compare agents.\n\n- **Result Reproducibility**:\n\n    After creating and evaluating an agent on a given environment, it is possible to persistently save the agent to disk, allowing programmers to load up pre-trained agents and compare them in different scenarios.\n\n    **Implemented Agents**:\n\n    - DQN (https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf)\n    - QNetwork (http://ml.informatik.uni-freiburg.de/former/_media/publications/rieecml05.pdf)\n    - QLearning (https://link.springer.com/content/pdf/10.1007%2FBF00992698.pdf)\n    - SARSA\n\n    **Planned Agents**:\n\n    - [TODO] DDQN (https://arxiv.org/abs/1509.06461)\n    - [TODO] A3C (https://arxiv.org/pdf/1602.01783.pdf)\n    - [TODO] GA3C (https://arxiv.org/pdf/1611.06256.pdf)\n    - [TODO] DDPG (https://arxiv.org/pdf/1509.02971.pdf)\n    - [TODO] PPO (https://arxiv.org/abs/1707.06347)\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://github.com/jmribeiro/yaaf", "keywords": "Autonomous Agents,Reinforcement Learning", "license": "Apache 2.0", "maintainer": "", "maintainer_email": "", "name": "yaaf", "package_url": "https://pypi.org/project/yaaf/", "platform": "", "project_url": "https://pypi.org/project/yaaf/", "project_urls": {"Homepage": "http://github.com/jmribeiro/yaaf"}, "release_url": "https://pypi.org/project/yaaf/0.0.2/", "requires_dist": ["gym", "keras", "numpy", "scipy", "pyyaml", "tensorflow"], "requires_python": "", "summary": "YAAF: Yet Another Agents Framework", "version": "0.0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>YAAF: Yet Another Agents Framework</h1>\n<p><em>A minimalistic reinforcement learning framework.</em></p>\n<h2>Installation</h2>\n<pre><code>  $ pip install yaaf                               # Install YAAF\n  $ pip install gym[atari]                         # Install OpenAI Gym's Atari environments\n  $ git clone https://github.com/jmribeiro/yaaf    # Clone the repo for the examples and tutorials\n  $ cd yaaf/examples                               \n  $ python 0_space_invaders_random_agent.py        # Run example\n</code></pre>\n<ul>\n<li>\n<p><strong>Rapid Prototyping</strong>: Setting up an agent on an environment can easily be done with a few lines of code:</p>\n<pre><code># Setup the Environment\nenvironment = OpenAIGymEnvironment(name=\"SpaceInvaders-v0\", render=True)\n\n# Setup the Agent\nagent = RandomAgent(environment.action_space)\n\n# Run the agent on the environment for 5 episodes\nrunner = EpisodeRunners(agent, environment, episodes=5)\nrunner.run()\nenvironment.close()\n</code></pre>\n</li>\n<li>\n<p><strong>Simplicity</strong></p>\n<p><strong>States</strong>: Tensors/Numpy arrays with a given shape;</p>\n<p><strong>Actions</strong>: Integers if a discrete action space, Floats if a continuous action space;</p>\n<p><strong>Timesteps</strong>: Named tuples in shape of (state, action, reward, next_, is_terminal, info)</p>\n<p><strong>Agents</strong>: Objects capable of execution actions when given a state. If trainable, capable of learning when given a timestep</p>\n<p><strong>Environments</strong>: Objects which evolve over time, where agents can execute actions;</p>\n<p><strong>Runners</strong>: Objects that interact an actor (agent or policy) on an environment, notifying a list of observers at every timestep;</p>\n<p><strong>Metrics</strong>: Objects that evaluate an agent's or policy's performance on a given run. Passed as observables to the Runners.</p>\n<p><strong>Presenters</strong> (TODO): Objects that display an agent's performance on a given run. Used to make plots and compare agents.</p>\n</li>\n<li>\n<p><strong>Result Reproducibility</strong>:</p>\n<p>After creating and evaluating an agent on a given environment, it is possible to persistently save the agent to disk, allowing programmers to load up pre-trained agents and compare them in different scenarios.</p>\n<p><strong>Implemented Agents</strong>:</p>\n<ul>\n<li>DQN (<a href=\"https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf\" rel=\"nofollow\">https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf</a>)</li>\n<li>QNetwork (<a href=\"http://ml.informatik.uni-freiburg.de/former/_media/publications/rieecml05.pdf\" rel=\"nofollow\">http://ml.informatik.uni-freiburg.de/former/_media/publications/rieecml05.pdf</a>)</li>\n<li>QLearning (<a href=\"https://link.springer.com/content/pdf/10.1007%2FBF00992698.pdf\" rel=\"nofollow\">https://link.springer.com/content/pdf/10.1007%2FBF00992698.pdf</a>)</li>\n<li>SARSA</li>\n</ul>\n<p><strong>Planned Agents</strong>:</p>\n<ul>\n<li>[TODO] DDQN (<a href=\"https://arxiv.org/abs/1509.06461\" rel=\"nofollow\">https://arxiv.org/abs/1509.06461</a>)</li>\n<li>[TODO] A3C (<a href=\"https://arxiv.org/pdf/1602.01783.pdf\" rel=\"nofollow\">https://arxiv.org/pdf/1602.01783.pdf</a>)</li>\n<li>[TODO] GA3C (<a href=\"https://arxiv.org/pdf/1611.06256.pdf\" rel=\"nofollow\">https://arxiv.org/pdf/1611.06256.pdf</a>)</li>\n<li>[TODO] DDPG (<a href=\"https://arxiv.org/pdf/1509.02971.pdf\" rel=\"nofollow\">https://arxiv.org/pdf/1509.02971.pdf</a>)</li>\n<li>[TODO] PPO (<a href=\"https://arxiv.org/abs/1707.06347\" rel=\"nofollow\">https://arxiv.org/abs/1707.06347</a>)</li>\n</ul>\n</li>\n</ul>\n\n          </div>"}, "last_serial": 5346941, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "d6140c146b2ae12e4efc00c9c582605a", "sha256": "7c66c7ae1e6992635dbd3eb181f63eddea30f954cb732e8fa50aca405f7af395"}, "downloads": -1, "filename": "yaaf-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "d6140c146b2ae12e4efc00c9c582605a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 25087, "upload_time": "2019-06-01T17:43:22", "upload_time_iso_8601": "2019-06-01T17:43:22.047913Z", "url": "https://files.pythonhosted.org/packages/14/23/6062d61a260a214709bb230ccc873153ee4dfde5ff40b3cc7901459e2f88/yaaf-0.0.1-py3-none-any.whl", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "fcea87e141b5a38cf1a30f83cfa7d06c", "sha256": "ca7f8df9c6d83bd205e113883d71f9427c6ea4ca2eeaf0610af120134d8796c4"}, "downloads": -1, "filename": "yaaf-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "fcea87e141b5a38cf1a30f83cfa7d06c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 25091, "upload_time": "2019-06-01T17:43:23", "upload_time_iso_8601": "2019-06-01T17:43:23.667009Z", "url": "https://files.pythonhosted.org/packages/88/51/6ee32bd9672312b3ba6600d1c60883bf50c9f53a4773707ebf41c95d33d6/yaaf-0.0.2-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "fcea87e141b5a38cf1a30f83cfa7d06c", "sha256": "ca7f8df9c6d83bd205e113883d71f9427c6ea4ca2eeaf0610af120134d8796c4"}, "downloads": -1, "filename": "yaaf-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "fcea87e141b5a38cf1a30f83cfa7d06c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 25091, "upload_time": "2019-06-01T17:43:23", "upload_time_iso_8601": "2019-06-01T17:43:23.667009Z", "url": "https://files.pythonhosted.org/packages/88/51/6ee32bd9672312b3ba6600d1c60883bf50c9f53a4773707ebf41c95d33d6/yaaf-0.0.2-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 03:23:53 2020"}