{"info": {"author": "Michael J.T. O'Kelly", "author_email": "mokelly@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Operating System :: Unix", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4"], "description": "##############\nWabbit Wappa\n##############\n\n.. image:: https://travis-ci.org/mokelly/wabbit_wappa.svg?branch=master\n    :target: https://travis-ci.org/mokelly/wabbit_wappa\n\n**Wabbit Wappa** is a full-featured Python wrapper for the lightning fast `Vowpal Wabbit <https://github.com/JohnLangford/vowpal_wabbit/wiki>`_ (\"VW\") \nmachine learning utility.  Wabbit Wappa makes it easier to use VW's powerful features while abstracting away its idiosyncratic syntax and interface.\n\n.. contents:: :local:\n\n****************\nFeatures\n****************\n\n* Complete Pythonic wrapper for the Vowpal Wabbit training and test syntax\n* Online training and testing, with no need to restart VW or reload the trained model to go between them\n* Save the trained model on the fly\n\n****************\nGetting Started\n****************\n\nIf you're unfamiliar with Vowpal Wabbit, this documentation is no substitute for \nthe `detailed tutorials <https://github.com/JohnLangford/vowpal_wabbit/wiki/Tutorial>`_\nat the VW wiki.  You'll eventually need to read those to understand VW's advanced features.\n\nInstallation\n===============\n\nYou have three installation options, depending on your comfort with compiling and installing the VW utility.\n\n**If you already have Vowpal Wabbit installed**::\n\n    pip install wabbit_wappa\n\n**If you still need to install VW (currently version 7.7) and its dependencies**:\n\nStart by cloning the WW repository::\n\n    git clone https://github.com/mokelly/wabbit_wappa.git\n    cd wabbit_wappa\n\nThen run the included install script (which more or less follows the VW instructions)::\n\n    scripts/vw-install.sh\n    export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib;\n    python setup.py install\n\n(The \"export\" line should be added to your .profile if you don't want to run it every time you use Vowpal Wabbit.)\n\n**If you want a virtual machine with everything all set up for you:**\n    \n*Windows users, this is your only option at present*\n\nFirst install the virtual machine manager `Vagrant <http://www.vagrantup.com/>`_ along with your favorite virtualization system (such as `VirtualBox <https://www.virtualbox.org/>`_).\nThen from the Wabbit Wappa source directory type::\n\n    vagrant up\n\nThis will launch an Ubuntu VM and provision it with VW and WW, completely automatically!  Once that's all complete, just SSH to your new VM with::\n\n    vagrant ssh\n    \nTesting\n---------\n\nMake sure everything is installed and configured correctly by running the tests::\n\n    py.test\n\nUsage Example\n===============\n\nLet's walk through an example of using Wabbit Wappa.  We will teach VW to recognize\ncapitalized characters.\n(You can find the whole script at ``examples/capitalization_demo.py``.)\n\nStart a default VW process in Logistic Regression mode::\n\n    >>> from wabbit_wappa import *\n    >>> vw = VW(loss_function='logistic')\n    >>> print vw.command\n    vw --save_resume --quiet --loss_function logistic --predictions /dev/stdout\n\nBehind the scenes, Wabbit Wappa generates a command line including default parameters critical\nto interaction with this wrapper.  VW is immediately run as a subprocess.\n\nNow train the logistic model by sending 10 labeled examples to the VW learner::\n\n    for i in range(10):\n        label, features = get_example()  # Random example; see capitalization_demo.py\n        vw.send_example(label, features=features)\n\nFrom examples like these::\n\n    Label -1: ['z', 'x', 'n', 'F', 'C', 'B', 'f', 'p', 'O'] is mostly lowercase\n    Label -1: ['S', 'u', 'e', 'K', 'f', 'w', 'l', 'C', 'd'] is mostly lowercase\n    Label -1: ['g', 'v', 'q', 'z', 'x', 'B', 'T', 'p', 'M'] is mostly lowercase\n    Label 1: ['j', 'i', 'k', 'D', 'm', 'N', 'Q', 'Z', 'L'] is mostly uppercase\n    Label 1: ['B', 'U', 'V', 'R', 'i', 'h', 'T', 'A', 'v'] is mostly uppercase\n    Label 1: ['Y', 'u', 'R', 'K', 's', 'X', 'g', 'M', 'j'] is mostly uppercase\n    Label -1: ['t', 'L', 'a', 'g', 'D', 'E', 'f', 'G', 'u'] is mostly lowercase\n    Label 1: ['F', 'W', 'y', 'i', 'U', 'E', 'X', 'r', 'e'] is mostly uppercase\n    Label -1: ['s', 'e', 'h', 'U', 'J', 'C', 'j', 'P', 'b'] is mostly lowercase\n    Label 1: ['A', 'k', 'H', 'G', 'a', 'b', 'w', 'Q', 'V'] is mostly uppercase\n\nVW begins to find the pattern: a +1 label if the capital letters outnumber the\nlowercase, and -1 otherwise.\n\nHow well trained is our model?  Let's run 100 tests on new random examples::\n\n    for i in range(num_tests):\n        label, features = get_example()\n        # Give the features to the model, witholding the label\n        response = vw.get_prediction(features)\n        prediction = response.prediction\n        # Test whether the floating-point prediction is in the right direction\n        if cmp(prediction, 0) == label:\n            num_good_tests += 1\n\n(For logistic regression, a ``prediction`` value greater than zero representa\na label of +1; that is why ``cmp(prediction, 0)`` is used.)\n\n    >>> print \"Correctly predicted\", num_good_tests, \"out of\", num_tests\n    Correctly predicted 60 out of 100\n\nWe can go on training, without restarting the process.  Let's train on 1,000 more examples::\n\n    for i in range(1000):\n        label, features = get_example()\n        vw.send_example(label, features=features)\n\nNow how good are our predictions?\n\n    Correctly predicted 98 out of 100\n\nWe can save the model to disk at any point in the process::\n\n    filename = 'capitalization.saved.model'\n    vw.save_model(filename)\n\nand reload our model using the 'i' argument::\n\n    >>> vw2 = VW(loss_function='logistic', i=filename)\n    >>> print vw2.command\n    vw -i capitalization.saved.model --save_resume --quiet --loss_function logistic --predictions /dev/stdout\n\nThe ``vw2`` model will now give just the same predictions that ``vw`` would have; and the default ``save_resume=True`` parameter\nmeans we can continue training from where we left off.\n\nTo shut down the VW subprocess before your program exits, call ``vw.close()``.\n\n\n****************\nDocumentation\n****************\n\nNamespaces\n===============\n\nThe most important Vowpal Wabbit feature not discussed above is namespaces.  VW\nuses namespaces to divide features into groups, which is used for some of its\nadvanced features.  Without discussing in detail *why* you would use them,\nhere's *how* to use namespaces in Wabbit Wappa.\n\nTo reproduce an example from this `Vowpal Wabbit tutorial <https://github.com/JohnLangford/vowpal_wabbit/wiki/v6.1_tutorial.pdf>`_::\n\n    namespace1 = Namespace('excuses', 0.1, [('the', 0.01), 'dog', 'ate', 'my', 'homework'])\n    namespace2 = Namespace('teacher', features='male white Bagnell AI ate breakfast'.split())\n\nThese namespaces can then be used as examples in training and prediction::\n\n    vw.send_example(response=1.,\n                    importance=.5,\n                    tag=\"example_39\",\n                    namespaces=[namespace1, namespace2])\n    response = vw.get_prediction(namespaces=[namespace1, namespace2])\n    prediction = response.prediction\n\nAlternatively, Namespaces can be queued up to be used automatically in the next\nexample or prediction sent to the VW subprocess::\n\n    vw.add_namespace(namespace1)\n    vw.add_namespace(namespace2)\n    vw.send_example(response=-1., importance=.5, tag=\"example_39\")\n\nor::\n\n    vw.add_namespace('excuses', 0.1, [('the', 0.01), 'dog', 'ate', 'my', 'homework'])\n    vw.add_namespace('teacher', features='male white Bagnell AI ate breakfast'.split())\n    response = vw.get_prediction()\n    prediction = response.prediction\n\nTokens in Vowpal Wabbit may not contain the space character, ``:`` or ``|``.  By default,\nWabbit Wappa will detect and escape these characters::\n\n    >>> namespace = Namespace('Metric Features', 3.28, [('hei|ght', 1.5), ('len:gth', 2.0)])\n    >>> print namespace.to_string()\n    Metric\\_Features:3.28 hei\\\\ght:1.5 len\\;gth:2.0\n\nIf you wish, you can get the raw VW input lines and pass them to the subprocess directly::\n\n    vw.add_namespace(namespace1)\n    vw.add_namespace(namespace2)\n    raw_line = vw.make_line(response=1., importance=.5, tag=\"example_39\")\n    vw.send_line(raw_line)\n\n    >>> print raw_line\n    1.0 0.5 'example_39|excuses:0.1 the:0.01 dog ate my homework |teacher male white Bagnell AI ate breakfast\n\n\nVW Options\n===============\n\nIn the ``VW()`` constructor, each named argument corresponds\nto a Vowpal Wabbit option.  Single character keys are mapped to single-dash options;\ne.g. ``b=20`` yields ``-b 20``.  Multiple character keys map to double-dash options:\n``quiet=True`` yields ``--quiet``.\n\nBoolean values are interpreted as flags: present if True, absent if False (or not given).\nAll non-boolean values are treated as option arguments, as in the `-b` example above.\n\nIf an option argument is a list, that option is repeated multiple times;\ne.g. ``q=['ab', 'bc']`` yields ``-q ab -q bc``.\n\nRun ``vw -h`` from your terminal for a listing of most options.\n\nNote that Wabbit Wappa makes no attempt to validate the inputs or\nensure they are compatible with its functionality.  For instance, changing the\ndefault ``predictions='/dev/stdout'`` will probably make that ``VW()`` instance\nnon-functional.\n\nActive Learning\n=================\n\nActive Learning is an approach to training somewhere between supervised and unsupervised.\nWhen getting labeled data is very expensive (such as when users must be solicited for\ntheir preferences), an Active Learning approach assigns an \"importance\" value to each\nunlabeled example, so that only the most critical labels need be acquired.\n\nVowpal Wabbit's `Active Learning <https://github.com/JohnLangford/vowpal_wabbit/wiki/active_learning.pdf>`_\ninterface requires you to start a VW instance in server mode and communicate with it\nvia a socket.  Wabbit Wappa abstracts all that away, providing the same interface for both\nregular and Active learning::\n\n    vw = VW(loss_function='logistic', active_mode=True, active_mellowness=0.1)\n    response = vw.get_prediction(features)\n    if response.importance >= 1.:\n        label = get_expensive_label(features)\n        vw.send_example(label, features=features)\n\nSee ``examples/active_learning_demo.py`` for a fully worked example.\n\n\nAPI Documentation\n===================\n\nFor complete explanation of all parameters, refer to the docstrings::\n\n    import wabbit_wappa\n    help(wabbit_wappa)\n\n\n\n\n\n\n\n****************\nHistory\n****************\n\n0.0.1 (2014-03-31)\n=====================\n\n* First release on GitHub\n\n0.0.2 (2014-04-07)\n=====================\n\n* Good unit test coverage\n* Full documentation, instructions and demo\n* Added command line builder with Pythonic interface\n\n0.1.2 (2014-04-09)\n=====================\n\n* Now installable using pip\n* Updated VW version to 7.6\n* Tweaked line detection to speed up process communication\n\n0.2.0 (2014-04-13)\n=====================\n\n* Active Learning interface, with documentation and example script\n* Minor performance boosts\n* **Backwards-incompatible change:** ``get_prediction()`` now returns a ``VWResult`` object, with the predicted value accessible as ``result.prediction``.\n  \n0.3.0 (2014-10-16)\n======================\n\n* Python 3 compatibility (thanks `Antti Haapala <https://github.com/ztane>`_!)\n* Much faster line buffering (50% overall speed improvement) (thanks `Antti Haapala <https://github.com/ztane>`_!)\n* Updated VW version to 7.7\n* Updated Ubuntu in VM to Trusty\n* Travis integration", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/mokelly/wabbit_wappa", "keywords": "wabbit_wappa", "license": "MIT", "maintainer": null, "maintainer_email": null, "name": "wabbit_wappa", "package_url": "https://pypi.org/project/wabbit_wappa/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/wabbit_wappa/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/mokelly/wabbit_wappa"}, "release_url": "https://pypi.org/project/wabbit_wappa/0.3.0/", "requires_dist": null, "requires_python": null, "summary": "Wabbit Wappa is a full-featured Python wrapper for the Vowpal Wabbit machine learning utility.", "version": "0.3.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://travis-ci.org/mokelly/wabbit_wappa\" rel=\"nofollow\"><img alt=\"https://travis-ci.org/mokelly/wabbit_wappa.svg?branch=master\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b2ce5d39f71076da0339b437b903769a149ab45b/68747470733a2f2f7472617669732d63692e6f72672f6d6f6b656c6c792f7761626269745f77617070612e7376673f6272616e63683d6d6173746572\"></a>\n<p><strong>Wabbit Wappa</strong> is a full-featured Python wrapper for the lightning fast <a href=\"https://github.com/JohnLangford/vowpal_wabbit/wiki\" rel=\"nofollow\">Vowpal Wabbit</a> (\u201cVW\u201d)\nmachine learning utility.  Wabbit Wappa makes it easier to use VW\u2019s powerful features while abstracting away its idiosyncratic syntax and interface.</p>\n<div id=\"contents\">\n<ul>\n<li><a href=\"#features\" id=\"id8\" rel=\"nofollow\">Features</a></li>\n<li><a href=\"#getting-started\" id=\"id9\" rel=\"nofollow\">Getting Started</a><ul>\n<li><a href=\"#installation\" id=\"id10\" rel=\"nofollow\">Installation</a><ul>\n<li><a href=\"#testing\" id=\"id11\" rel=\"nofollow\">Testing</a></li>\n</ul>\n</li>\n<li><a href=\"#usage-example\" id=\"id12\" rel=\"nofollow\">Usage Example</a></li>\n</ul>\n</li>\n<li><a href=\"#documentation\" id=\"id13\" rel=\"nofollow\">Documentation</a><ul>\n<li><a href=\"#namespaces\" id=\"id14\" rel=\"nofollow\">Namespaces</a></li>\n<li><a href=\"#vw-options\" id=\"id15\" rel=\"nofollow\">VW Options</a></li>\n<li><a href=\"#active-learning\" id=\"id16\" rel=\"nofollow\">Active Learning</a></li>\n<li><a href=\"#api-documentation\" id=\"id17\" rel=\"nofollow\">API Documentation</a></li>\n</ul>\n</li>\n<li><a href=\"#history\" id=\"id18\" rel=\"nofollow\">History</a><ul>\n<li><a href=\"#id2\" id=\"id19\" rel=\"nofollow\">0.0.1 (2014-03-31)</a></li>\n<li><a href=\"#id3\" id=\"id20\" rel=\"nofollow\">0.0.2 (2014-04-07)</a></li>\n<li><a href=\"#id4\" id=\"id21\" rel=\"nofollow\">0.1.2 (2014-04-09)</a></li>\n<li><a href=\"#id5\" id=\"id22\" rel=\"nofollow\">0.2.0 (2014-04-13)</a></li>\n<li><a href=\"#id6\" id=\"id23\" rel=\"nofollow\">0.3.0 (2014-10-16)</a></li>\n</ul>\n</li>\n</ul>\n</div>\n<div id=\"features\">\n<h2><a href=\"#id8\" rel=\"nofollow\">Features</a></h2>\n<ul>\n<li>Complete Pythonic wrapper for the Vowpal Wabbit training and test syntax</li>\n<li>Online training and testing, with no need to restart VW or reload the trained model to go between them</li>\n<li>Save the trained model on the fly</li>\n</ul>\n</div>\n<div id=\"getting-started\">\n<h2><a href=\"#id9\" rel=\"nofollow\">Getting Started</a></h2>\n<p>If you\u2019re unfamiliar with Vowpal Wabbit, this documentation is no substitute for\nthe <a href=\"https://github.com/JohnLangford/vowpal_wabbit/wiki/Tutorial\" rel=\"nofollow\">detailed tutorials</a>\nat the VW wiki.  You\u2019ll eventually need to read those to understand VW\u2019s advanced features.</p>\n<div id=\"installation\">\n<h3><a href=\"#id10\" rel=\"nofollow\">Installation</a></h3>\n<p>You have three installation options, depending on your comfort with compiling and installing the VW utility.</p>\n<p><strong>If you already have Vowpal Wabbit installed</strong>:</p>\n<pre>pip install wabbit_wappa\n</pre>\n<p><strong>If you still need to install VW (currently version 7.7) and its dependencies</strong>:</p>\n<p>Start by cloning the WW repository:</p>\n<pre>git clone https://github.com/mokelly/wabbit_wappa.git\ncd wabbit_wappa\n</pre>\n<p>Then run the included install script (which more or less follows the VW instructions):</p>\n<pre>scripts/vw-install.sh\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib;\npython setup.py install\n</pre>\n<p>(The \u201cexport\u201d line should be added to your .profile if you don\u2019t want to run it every time you use Vowpal Wabbit.)</p>\n<p><strong>If you want a virtual machine with everything all set up for you:</strong></p>\n<p><em>Windows users, this is your only option at present</em></p>\n<p>First install the virtual machine manager <a href=\"http://www.vagrantup.com/\" rel=\"nofollow\">Vagrant</a> along with your favorite virtualization system (such as <a href=\"https://www.virtualbox.org/\" rel=\"nofollow\">VirtualBox</a>).\nThen from the Wabbit Wappa source directory type:</p>\n<pre>vagrant up\n</pre>\n<p>This will launch an Ubuntu VM and provision it with VW and WW, completely automatically!  Once that\u2019s all complete, just SSH to your new VM with:</p>\n<pre>vagrant ssh\n</pre>\n<div id=\"testing\">\n<h4><a href=\"#id11\" rel=\"nofollow\">Testing</a></h4>\n<p>Make sure everything is installed and configured correctly by running the tests:</p>\n<pre>py.test\n</pre>\n</div>\n</div>\n<div id=\"usage-example\">\n<h3><a href=\"#id12\" rel=\"nofollow\">Usage Example</a></h3>\n<p>Let\u2019s walk through an example of using Wabbit Wappa.  We will teach VW to recognize\ncapitalized characters.\n(You can find the whole script at <tt>examples/capitalization_demo.py</tt>.)</p>\n<p>Start a default VW process in Logistic Regression mode:</p>\n<pre>&gt;&gt;&gt; from wabbit_wappa import *\n&gt;&gt;&gt; vw = VW(loss_function='logistic')\n&gt;&gt;&gt; print vw.command\nvw --save_resume --quiet --loss_function logistic --predictions /dev/stdout\n</pre>\n<p>Behind the scenes, Wabbit Wappa generates a command line including default parameters critical\nto interaction with this wrapper.  VW is immediately run as a subprocess.</p>\n<p>Now train the logistic model by sending 10 labeled examples to the VW learner:</p>\n<pre>for i in range(10):\n    label, features = get_example()  # Random example; see capitalization_demo.py\n    vw.send_example(label, features=features)\n</pre>\n<p>From examples like these:</p>\n<pre>Label -1: ['z', 'x', 'n', 'F', 'C', 'B', 'f', 'p', 'O'] is mostly lowercase\nLabel -1: ['S', 'u', 'e', 'K', 'f', 'w', 'l', 'C', 'd'] is mostly lowercase\nLabel -1: ['g', 'v', 'q', 'z', 'x', 'B', 'T', 'p', 'M'] is mostly lowercase\nLabel 1: ['j', 'i', 'k', 'D', 'm', 'N', 'Q', 'Z', 'L'] is mostly uppercase\nLabel 1: ['B', 'U', 'V', 'R', 'i', 'h', 'T', 'A', 'v'] is mostly uppercase\nLabel 1: ['Y', 'u', 'R', 'K', 's', 'X', 'g', 'M', 'j'] is mostly uppercase\nLabel -1: ['t', 'L', 'a', 'g', 'D', 'E', 'f', 'G', 'u'] is mostly lowercase\nLabel 1: ['F', 'W', 'y', 'i', 'U', 'E', 'X', 'r', 'e'] is mostly uppercase\nLabel -1: ['s', 'e', 'h', 'U', 'J', 'C', 'j', 'P', 'b'] is mostly lowercase\nLabel 1: ['A', 'k', 'H', 'G', 'a', 'b', 'w', 'Q', 'V'] is mostly uppercase\n</pre>\n<p>VW begins to find the pattern: a +1 label if the capital letters outnumber the\nlowercase, and -1 otherwise.</p>\n<p>How well trained is our model?  Let\u2019s run 100 tests on new random examples:</p>\n<pre>for i in range(num_tests):\n    label, features = get_example()\n    # Give the features to the model, witholding the label\n    response = vw.get_prediction(features)\n    prediction = response.prediction\n    # Test whether the floating-point prediction is in the right direction\n    if cmp(prediction, 0) == label:\n        num_good_tests += 1\n</pre>\n<p>(For logistic regression, a <tt>prediction</tt> value greater than zero representa\na label of +1; that is why <tt>cmp(prediction, 0)</tt> is used.)</p>\n<blockquote>\n<pre>&gt;&gt;&gt; print \"Correctly predicted\", num_good_tests, \"out of\", num_tests\nCorrectly predicted 60 out of 100\n</pre>\n</blockquote>\n<p>We can go on training, without restarting the process.  Let\u2019s train on 1,000 more examples:</p>\n<pre>for i in range(1000):\n    label, features = get_example()\n    vw.send_example(label, features=features)\n</pre>\n<p>Now how good are our predictions?</p>\n<blockquote>\nCorrectly predicted 98 out of 100</blockquote>\n<p>We can save the model to disk at any point in the process:</p>\n<pre>filename = 'capitalization.saved.model'\nvw.save_model(filename)\n</pre>\n<p>and reload our model using the \u2018i\u2019 argument:</p>\n<pre>&gt;&gt;&gt; vw2 = VW(loss_function='logistic', i=filename)\n&gt;&gt;&gt; print vw2.command\nvw -i capitalization.saved.model --save_resume --quiet --loss_function logistic --predictions /dev/stdout\n</pre>\n<p>The <tt>vw2</tt> model will now give just the same predictions that <tt>vw</tt> would have; and the default <tt>save_resume=True</tt> parameter\nmeans we can continue training from where we left off.</p>\n<p>To shut down the VW subprocess before your program exits, call <tt>vw.close()</tt>.</p>\n</div>\n</div>\n<div id=\"documentation\">\n<h2><a href=\"#id13\" rel=\"nofollow\">Documentation</a></h2>\n<div id=\"namespaces\">\n<h3><a href=\"#id14\" rel=\"nofollow\">Namespaces</a></h3>\n<p>The most important Vowpal Wabbit feature not discussed above is namespaces.  VW\nuses namespaces to divide features into groups, which is used for some of its\nadvanced features.  Without discussing in detail <em>why</em> you would use them,\nhere\u2019s <em>how</em> to use namespaces in Wabbit Wappa.</p>\n<p>To reproduce an example from this <a href=\"https://github.com/JohnLangford/vowpal_wabbit/wiki/v6.1_tutorial.pdf\" rel=\"nofollow\">Vowpal Wabbit tutorial</a>:</p>\n<pre>namespace1 = Namespace('excuses', 0.1, [('the', 0.01), 'dog', 'ate', 'my', 'homework'])\nnamespace2 = Namespace('teacher', features='male white Bagnell AI ate breakfast'.split())\n</pre>\n<p>These namespaces can then be used as examples in training and prediction:</p>\n<pre>vw.send_example(response=1.,\n                importance=.5,\n                tag=\"example_39\",\n                namespaces=[namespace1, namespace2])\nresponse = vw.get_prediction(namespaces=[namespace1, namespace2])\nprediction = response.prediction\n</pre>\n<p>Alternatively, Namespaces can be queued up to be used automatically in the next\nexample or prediction sent to the VW subprocess:</p>\n<pre>vw.add_namespace(namespace1)\nvw.add_namespace(namespace2)\nvw.send_example(response=-1., importance=.5, tag=\"example_39\")\n</pre>\n<p>or:</p>\n<pre>vw.add_namespace('excuses', 0.1, [('the', 0.01), 'dog', 'ate', 'my', 'homework'])\nvw.add_namespace('teacher', features='male white Bagnell AI ate breakfast'.split())\nresponse = vw.get_prediction()\nprediction = response.prediction\n</pre>\n<p>Tokens in Vowpal Wabbit may not contain the space character, <tt>:</tt> or <tt>|</tt>.  By default,\nWabbit Wappa will detect and escape these characters:</p>\n<pre>&gt;&gt;&gt; namespace = Namespace('Metric Features', 3.28, [('hei|ght', 1.5), ('len:gth', 2.0)])\n&gt;&gt;&gt; print namespace.to_string()\nMetric\\_Features:3.28 hei\\\\ght:1.5 len\\;gth:2.0\n</pre>\n<p>If you wish, you can get the raw VW input lines and pass them to the subprocess directly:</p>\n<pre>vw.add_namespace(namespace1)\nvw.add_namespace(namespace2)\nraw_line = vw.make_line(response=1., importance=.5, tag=\"example_39\")\nvw.send_line(raw_line)\n\n&gt;&gt;&gt; print raw_line\n1.0 0.5 'example_39|excuses:0.1 the:0.01 dog ate my homework |teacher male white Bagnell AI ate breakfast\n</pre>\n</div>\n<div id=\"vw-options\">\n<h3><a href=\"#id15\" rel=\"nofollow\">VW Options</a></h3>\n<p>In the <tt>VW()</tt> constructor, each named argument corresponds\nto a Vowpal Wabbit option.  Single character keys are mapped to single-dash options;\ne.g. <tt>b=20</tt> yields <tt><span class=\"pre\">-b</span> 20</tt>.  Multiple character keys map to double-dash options:\n<tt>quiet=True</tt> yields <tt><span class=\"pre\">--quiet</span></tt>.</p>\n<p>Boolean values are interpreted as flags: present if True, absent if False (or not given).\nAll non-boolean values are treated as option arguments, as in the <cite>-b</cite> example above.</p>\n<p>If an option argument is a list, that option is repeated multiple times;\ne.g. <tt><span class=\"pre\">q=['ab',</span> 'bc']</tt> yields <tt><span class=\"pre\">-q</span> ab <span class=\"pre\">-q</span> bc</tt>.</p>\n<p>Run <tt>vw <span class=\"pre\">-h</span></tt> from your terminal for a listing of most options.</p>\n<p>Note that Wabbit Wappa makes no attempt to validate the inputs or\nensure they are compatible with its functionality.  For instance, changing the\ndefault <tt><span class=\"pre\">predictions='/dev/stdout'</span></tt> will probably make that <tt>VW()</tt> instance\nnon-functional.</p>\n</div>\n<div id=\"active-learning\">\n<h3><a href=\"#id16\" rel=\"nofollow\">Active Learning</a></h3>\n<p>Active Learning is an approach to training somewhere between supervised and unsupervised.\nWhen getting labeled data is very expensive (such as when users must be solicited for\ntheir preferences), an Active Learning approach assigns an \u201cimportance\u201d value to each\nunlabeled example, so that only the most critical labels need be acquired.</p>\n<p>Vowpal Wabbit\u2019s <a href=\"https://github.com/JohnLangford/vowpal_wabbit/wiki/active_learning.pdf\" rel=\"nofollow\">Active Learning</a>\ninterface requires you to start a VW instance in server mode and communicate with it\nvia a socket.  Wabbit Wappa abstracts all that away, providing the same interface for both\nregular and Active learning:</p>\n<pre>vw = VW(loss_function='logistic', active_mode=True, active_mellowness=0.1)\nresponse = vw.get_prediction(features)\nif response.importance &gt;= 1.:\n    label = get_expensive_label(features)\n    vw.send_example(label, features=features)\n</pre>\n<p>See <tt>examples/active_learning_demo.py</tt> for a fully worked example.</p>\n</div>\n<div id=\"api-documentation\">\n<h3><a href=\"#id17\" rel=\"nofollow\">API Documentation</a></h3>\n<p>For complete explanation of all parameters, refer to the docstrings:</p>\n<pre>import wabbit_wappa\nhelp(wabbit_wappa)\n</pre>\n</div>\n</div>\n<div id=\"history\">\n<h2><a href=\"#id18\" rel=\"nofollow\">History</a></h2>\n<div id=\"id2\">\n<h3><a href=\"#id19\" rel=\"nofollow\">0.0.1 (2014-03-31)</a></h3>\n<ul>\n<li>First release on GitHub</li>\n</ul>\n</div>\n<div id=\"id3\">\n<h3><a href=\"#id20\" rel=\"nofollow\">0.0.2 (2014-04-07)</a></h3>\n<ul>\n<li>Good unit test coverage</li>\n<li>Full documentation, instructions and demo</li>\n<li>Added command line builder with Pythonic interface</li>\n</ul>\n</div>\n<div id=\"id4\">\n<h3><a href=\"#id21\" rel=\"nofollow\">0.1.2 (2014-04-09)</a></h3>\n<ul>\n<li>Now installable using pip</li>\n<li>Updated VW version to 7.6</li>\n<li>Tweaked line detection to speed up process communication</li>\n</ul>\n</div>\n<div id=\"id5\">\n<h3><a href=\"#id22\" rel=\"nofollow\">0.2.0 (2014-04-13)</a></h3>\n<ul>\n<li>Active Learning interface, with documentation and example script</li>\n<li>Minor performance boosts</li>\n<li><strong>Backwards-incompatible change:</strong> <tt>get_prediction()</tt> now returns a <tt>VWResult</tt> object, with the predicted value accessible as <tt>result.prediction</tt>.</li>\n</ul>\n</div>\n<div id=\"id6\">\n<h3><a href=\"#id23\" rel=\"nofollow\">0.3.0 (2014-10-16)</a></h3>\n<ul>\n<li>Python 3 compatibility (thanks <a href=\"https://github.com/ztane\" rel=\"nofollow\">Antti Haapala</a>!)</li>\n<li>Much faster line buffering (50% overall speed improvement) (thanks <a href=\"https://github.com/ztane\" rel=\"nofollow\">Antti Haapala</a>!)</li>\n<li>Updated VW version to 7.7</li>\n<li>Updated Ubuntu in VM to Trusty</li>\n<li>Travis integration</li>\n</ul>\n</div>\n</div>\n\n          </div>"}, "last_serial": 1276098, "releases": {"0.1.2": [{"comment_text": "", "digests": {"md5": "ae67050e9ddc1c184de9e3c4cccbfe85", "sha256": "5183f70bb45256d92575be9ba710b4028d55eddf523b1cf63558f660b5e801d2"}, "downloads": -1, "filename": "wabbit_wappa-0.1.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "ae67050e9ddc1c184de9e3c4cccbfe85", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 14988, "upload_time": "2014-04-09T15:45:23", "upload_time_iso_8601": "2014-04-09T15:45:23.867775Z", "url": "https://files.pythonhosted.org/packages/f3/d4/1498249e7e15653386e152b76bd40f49c98216b5d45ee731f0177660e54d/wabbit_wappa-0.1.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d42b9ef0bfa3a2d8eb5010c160fd3e04", "sha256": "99b1f4a280813f4ba1ab01ce07451025bafec2916fe04ff6235abffe938ee42a"}, "downloads": -1, "filename": "wabbit_wappa-0.1.2.tar.gz", "has_sig": false, "md5_digest": "d42b9ef0bfa3a2d8eb5010c160fd3e04", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 19357, "upload_time": "2014-04-09T15:45:00", "upload_time_iso_8601": "2014-04-09T15:45:00.814232Z", "url": "https://files.pythonhosted.org/packages/50/72/37c19e3737f964ad38c3e1ad00d1788ef0f9381d85ea625cf1b0baa87c25/wabbit_wappa-0.1.2.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "5c0a050337f3ec081db5bab09e240b34", "sha256": "c2058aeae65121725f3901a5b102033bcd911661bfdef1ec1a51eb1984d62ef0"}, "downloads": -1, "filename": "wabbit_wappa-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "5c0a050337f3ec081db5bab09e240b34", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 18448, "upload_time": "2014-04-13T13:47:53", "upload_time_iso_8601": "2014-04-13T13:47:53.023573Z", "url": "https://files.pythonhosted.org/packages/3d/81/852995e3bfc504ffbbd1e73eb0ebdd6bca740257ed8f1fe36abc5028fbb3/wabbit_wappa-0.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7ab6b40d7151d5893ce65c0a0e859c8f", "sha256": "29881f8095468f2ea01454fbb29db79484a37a63dcd3f753e14af38b489c0c4d"}, "downloads": -1, "filename": "wabbit_wappa-0.2.0.tar.gz", "has_sig": false, "md5_digest": "7ab6b40d7151d5893ce65c0a0e859c8f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22419, "upload_time": "2014-04-13T13:47:43", "upload_time_iso_8601": "2014-04-13T13:47:43.495207Z", "url": "https://files.pythonhosted.org/packages/7a/5b/91de32cd4e0e48f4df6af468b24dcf32fec6ae3d49fda87786bed574dd0d/wabbit_wappa-0.2.0.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "75a78933e2d8f276ddd545c9ccfe53a3", "sha256": "c03d34a04852e065237cdc0362731f5d34d561a55dd006a36e4f6eb79f4bd720"}, "downloads": -1, "filename": "wabbit_wappa-0.3.0.tar.gz", "has_sig": false, "md5_digest": "75a78933e2d8f276ddd545c9ccfe53a3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23001, "upload_time": "2014-10-20T05:27:41", "upload_time_iso_8601": "2014-10-20T05:27:41.799691Z", "url": "https://files.pythonhosted.org/packages/3c/19/91a846c5f82a951a849413683a7acec4c5037a75c5b29bdad09fa1e4a47e/wabbit_wappa-0.3.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "75a78933e2d8f276ddd545c9ccfe53a3", "sha256": "c03d34a04852e065237cdc0362731f5d34d561a55dd006a36e4f6eb79f4bd720"}, "downloads": -1, "filename": "wabbit_wappa-0.3.0.tar.gz", "has_sig": false, "md5_digest": "75a78933e2d8f276ddd545c9ccfe53a3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23001, "upload_time": "2014-10-20T05:27:41", "upload_time_iso_8601": "2014-10-20T05:27:41.799691Z", "url": "https://files.pythonhosted.org/packages/3c/19/91a846c5f82a951a849413683a7acec4c5037a75c5b29bdad09fa1e4a47e/wabbit_wappa-0.3.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:33:22 2020"}