{"info": {"author": "Yasufumi Taniguchi", "author_email": "yasufumi.taniguchi@gmail.com", "bugtrack_url": null, "classifiers": ["Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8"], "description": "# PyTorch Pipeline: Simple ETL Pipeline for PyTorch\n\nPyTorch Pipeline is a simple ETL framework for PyTorch.\nIt is an alternative to [tf.data](https://www.tensorflow.org/api_docs/python/tf/data) in TensorFlow\n\n\n# Requirements\n\n- Python 3.6+\n- PyTorch 1.2+\n\n\n# Installation\n\nTo install PyTorch Pipeline:\n\n```bash\npip install pytorch_pipeilne\n```\n\n\n# Basic Usage\n\n```py\nimport pytorch_pipeilne as pp\n\nd = pp.TextDataset('/path/to/your/text')\nd.shuffle(buffer_size=100).batch(batch_size=10).first()\n```\n\n# Usage with PyTorch\n\n```py\nfrom torch.utils.data import DataLoader\nimport pytorch_pipeilne as pp\n\n\nd = pp.Dataset(range(1_000)).parallel().shuffle(100).batch(10)\nloader = DataLoader(d, num_workers=4, collate_fn=lambda x: x)\nfor x in loader:\n    ...\n```\n\n# Usage with LineFlow\n\nYou can use PyTorch Pipeline with pre-defined datasets in [LineFlow](https://github.com/tofunlp/lineflow):\n\n```py\nfrom torch.utils.data import DataLoader\nfrom lineflow.datasets.wikitext import cached_get_wikitext\nimport pytorch_pipeilne as pp\n\ndataset = cached_get_wikitext('wikitext-2')\n# Preprocessing dataset\ntrain_data = pp.Dataset(dataset['train']) \\\n    .flat_map(lambda x: x.split() + ['<eos>']) \\\n    .window(35) \\\n    .parallel() \\\n    .shuffle(64 * 100) \\\n    .batch(64)\n\n# Iterating dataset\nloader = DataLoader(train_data, num_workers=4, collate_fn=lambda x: x)\nfor x in loader:\n    ...\n```", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/yasufumy/pytorch-pipeline", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "pytorch-pipeline", "package_url": "https://pypi.org/project/pytorch-pipeline/", "platform": "", "project_url": "https://pypi.org/project/pytorch-pipeline/", "project_urls": {"Homepage": "https://github.com/yasufumy/pytorch-pipeline"}, "release_url": "https://pypi.org/project/pytorch-pipeline/0.0.1/", "requires_dist": null, "requires_python": "", "summary": "Simple ETL Pipeline for PyTorch", "version": "0.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>PyTorch Pipeline: Simple ETL Pipeline for PyTorch</h1>\n<p>PyTorch Pipeline is a simple ETL framework for PyTorch.\nIt is an alternative to <a href=\"https://www.tensorflow.org/api_docs/python/tf/data\" rel=\"nofollow\">tf.data</a> in TensorFlow</p>\n<h1>Requirements</h1>\n<ul>\n<li>Python 3.6+</li>\n<li>PyTorch 1.2+</li>\n</ul>\n<h1>Installation</h1>\n<p>To install PyTorch Pipeline:</p>\n<pre>pip install pytorch_pipeilne\n</pre>\n<h1>Basic Usage</h1>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">pytorch_pipeilne</span> <span class=\"k\">as</span> <span class=\"nn\">pp</span>\n\n<span class=\"n\">d</span> <span class=\"o\">=</span> <span class=\"n\">pp</span><span class=\"o\">.</span><span class=\"n\">TextDataset</span><span class=\"p\">(</span><span class=\"s1\">'/path/to/your/text'</span><span class=\"p\">)</span>\n<span class=\"n\">d</span><span class=\"o\">.</span><span class=\"n\">shuffle</span><span class=\"p\">(</span><span class=\"n\">buffer_size</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">batch</span><span class=\"p\">(</span><span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">first</span><span class=\"p\">()</span>\n</pre>\n<h1>Usage with PyTorch</h1>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torch.utils.data</span> <span class=\"kn\">import</span> <span class=\"n\">DataLoader</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pytorch_pipeilne</span> <span class=\"k\">as</span> <span class=\"nn\">pp</span>\n\n\n<span class=\"n\">d</span> <span class=\"o\">=</span> <span class=\"n\">pp</span><span class=\"o\">.</span><span class=\"n\">Dataset</span><span class=\"p\">(</span><span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">1_000</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">parallel</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">shuffle</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">batch</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n<span class=\"n\">loader</span> <span class=\"o\">=</span> <span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">,</span> <span class=\"n\">num_workers</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">collate_fn</span><span class=\"o\">=</span><span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">x</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">x</span> <span class=\"ow\">in</span> <span class=\"n\">loader</span><span class=\"p\">:</span>\n    <span class=\"o\">...</span>\n</pre>\n<h1>Usage with LineFlow</h1>\n<p>You can use PyTorch Pipeline with pre-defined datasets in <a href=\"https://github.com/tofunlp/lineflow\" rel=\"nofollow\">LineFlow</a>:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torch.utils.data</span> <span class=\"kn\">import</span> <span class=\"n\">DataLoader</span>\n<span class=\"kn\">from</span> <span class=\"nn\">lineflow.datasets.wikitext</span> <span class=\"kn\">import</span> <span class=\"n\">cached_get_wikitext</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pytorch_pipeilne</span> <span class=\"k\">as</span> <span class=\"nn\">pp</span>\n\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">cached_get_wikitext</span><span class=\"p\">(</span><span class=\"s1\">'wikitext-2'</span><span class=\"p\">)</span>\n<span class=\"c1\"># Preprocessing dataset</span>\n<span class=\"n\">train_data</span> <span class=\"o\">=</span> <span class=\"n\">pp</span><span class=\"o\">.</span><span class=\"n\">Dataset</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"p\">[</span><span class=\"s1\">'train'</span><span class=\"p\">])</span> \\\n    <span class=\"o\">.</span><span class=\"n\">flat_map</span><span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">()</span> <span class=\"o\">+</span> <span class=\"p\">[</span><span class=\"s1\">'&lt;eos&gt;'</span><span class=\"p\">])</span> \\\n    <span class=\"o\">.</span><span class=\"n\">window</span><span class=\"p\">(</span><span class=\"mi\">35</span><span class=\"p\">)</span> \\\n    <span class=\"o\">.</span><span class=\"n\">parallel</span><span class=\"p\">()</span> \\\n    <span class=\"o\">.</span><span class=\"n\">shuffle</span><span class=\"p\">(</span><span class=\"mi\">64</span> <span class=\"o\">*</span> <span class=\"mi\">100</span><span class=\"p\">)</span> \\\n    <span class=\"o\">.</span><span class=\"n\">batch</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Iterating dataset</span>\n<span class=\"n\">loader</span> <span class=\"o\">=</span> <span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"n\">train_data</span><span class=\"p\">,</span> <span class=\"n\">num_workers</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">collate_fn</span><span class=\"o\">=</span><span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">x</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">x</span> <span class=\"ow\">in</span> <span class=\"n\">loader</span><span class=\"p\">:</span>\n    <span class=\"o\">...</span>\n</pre>\n\n          </div>"}, "last_serial": 6485023, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "95526c1bd0a7d5e5d789140a66b21781", "sha256": "8c0c421aaf73cb279d5891d3e89f4527fbe144c5d1ee4f6967d4616a9f90a4a2"}, "downloads": -1, "filename": "pytorch-pipeline-0.0.1.tar.gz", "has_sig": false, "md5_digest": "95526c1bd0a7d5e5d789140a66b21781", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14409, "upload_time": "2020-01-20T06:39:22", "upload_time_iso_8601": "2020-01-20T06:39:22.923826Z", "url": "https://files.pythonhosted.org/packages/3d/bd/4d2d422bdbba7836008ff35bec0b4682d6fd865db0991154d4dcb67862d4/pytorch-pipeline-0.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "95526c1bd0a7d5e5d789140a66b21781", "sha256": "8c0c421aaf73cb279d5891d3e89f4527fbe144c5d1ee4f6967d4616a9f90a4a2"}, "downloads": -1, "filename": "pytorch-pipeline-0.0.1.tar.gz", "has_sig": false, "md5_digest": "95526c1bd0a7d5e5d789140a66b21781", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14409, "upload_time": "2020-01-20T06:39:22", "upload_time_iso_8601": "2020-01-20T06:39:22.923826Z", "url": "https://files.pythonhosted.org/packages/3d/bd/4d2d422bdbba7836008ff35bec0b4682d6fd865db0991154d4dcb67862d4/pytorch-pipeline-0.0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:13:46 2020"}