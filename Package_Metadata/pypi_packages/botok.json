{"info": {"author": "Esukhia development team", "author_email": "esukhiadev@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved :: Apache Software License", "Natural Language :: Tibetan", "Operating System :: OS Independent", "Programming Language :: Python :: 3", "Topic :: Text Processing :: Linguistic"], "description": "# botok \u2013 Python Tibetan Tokenizer\n[![Build Status](https://travis-ci.org/Esukhia/botok.svg?branch=master)](https://travis-ci.org/Esukhia/botok)  [![Coverage Status](https://coveralls.io/repos/github/Esukhia/botok/badge.svg?branch=master)](https://coveralls.io/github/Esukhia/botok?branch=master) ![GitHub release](https://img.shields.io/github/release/Esukhia/botok.svg) [![CodeFactor](https://www.codefactor.io/repository/github/esukhia/botok/badge)](https://www.codefactor.io/repository/github/esukhia/botok) [![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://black.readthedocs.io/en/stable/)\n\n\n## Overview\n\nbotok tokenizes Tibetan text into words.\n\n### Basic usage\n\n#### Getting started\nRequires to have Python3 installed.\n\n    pip3 install botok\n\n```python\n>>> from botok import Text\n\n>>> # input is a multi-line input string\n>>> in_str = \"\"\"\u0f63\u0f7a \u0f42\u0f66\u0f0d \u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b\u0f58\u0f50\u0f60\u0f72\u0f0b \u0f06 \u0f64\u0f72\u0f0b\u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b  tr \n... \u0f56\u0f51\u0f7a\u0f0b\u0f0b\u0f63\u0f7a \u0f42\u0f66\u0f0d \u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b\u0f56\u0f51\u0f7a\u0f0b\u0f63\u0f7a\u0f42\u0f66\u0f0b\u0f21\u0f22\u0f23\u0f40\u0f40\u0f0d \n... \u0f58\u0f50\u0f60\u0f72\u0f0b\u0f62\u0f92\u0fb1\u0f0b\u0f58\u0f5a\u0f7c\u0f62\u0f0b\u0f42\u0f53\u0f66\u0f0b\u0f54\u0f60\u0f72\u0f0b\u0f49\u0f66\u0f0b\u0f46\u0f74\u0f0b\u0f60\u0f50\u0f74\u0f44\u0f0b\u0f0d\u0f0d \u0f0d\u0f0d\u0f58\u0f41\u0f60\u0f0d\"\"\"\n\n\n### STEP1: instanciating Text\n\n>>> # A. on a string\n>>> t = Text(in_str)\n\n>>> # B. on a file\n... # note all following operations can be applied to files in this way.\n>>> from pathlib import Path\n>>> in_file = Path.cwd() / 'test.txt'\n\n>>> # file content:\n>>> in_file.read_text()\n'\u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b\u0f56\u0f51\u0f7a\u0f0b\u0f63\u0f7a\u0f42\u0f66\u0f0d\u0f0d\\n'\n\n>>> t = Text(in_file)\n>>> t.tokenize_chunks_plaintext\n\n>>> # checking an output file has been written:\n... # BOM is added by default so that notepad in Windows doesn't scramble the line breaks\n>>> out_file = Path.cwd() / 'test_pybo.txt'\n>>> out_file.read_text()\n'\\ufeff\u0f56\u0f40\u0fb2\u0f0b \u0f64\u0f72\u0f66\u0f0b \u0f56\u0f51\u0f7a\u0f0b \u0f63\u0f7a\u0f42\u0f66 \u0f0d\u0f0d'\n\n### STEP2: properties will perform actions on the input string:\n### note: original spaces are replaced by underscores.\n\n>>> # OUTPUT1: chunks are meaningful groups of chars from the input string.\n... # see how punctuations, numerals, non-bo and syllables are all neatly grouped.\n>>> t.tokenize_chunks_plaintext\n'\u0f63\u0f7a_\u0f42\u0f66 \u0f0d_ \u0f56\u0f40\u0fb2\u0f0b \u0f64\u0f72\u0f66\u0f0b \u0f58\u0f50\u0f60\u0f72\u0f0b _\u0f06_ \u0f64\u0f72\u0f0b \u0f56\u0f40\u0fb2\u0f0b \u0f64\u0f72\u0f66\u0f0b__ tr_\\n \u0f56\u0f51\u0f7a\u0f0b\u0f0b \u0f63\u0f7a_\u0f42\u0f66 \u0f0d_ \u0f56\u0f40\u0fb2\u0f0b \u0f64\u0f72\u0f66\u0f0b \u0f56\u0f51\u0f7a\u0f0b \u0f63\u0f7a\u0f42\u0f66\u0f0b \u0f21\u0f22\u0f23 \u0f40\u0f40 \u0f0d_\\n \u0f58\u0f50\u0f60\u0f72\u0f0b \u0f62\u0f92\u0fb1\u0f0b \u0f58\u0f5a\u0f7c\u0f62\u0f0b \u0f42\u0f53\u0f66\u0f0b \u0f54\u0f60\u0f72\u0f0b \u0f49\u0f66\u0f0b \u0f46\u0f74\u0f0b \u0f60\u0f50\u0f74\u0f44\u0f0b \u0f0d\u0f0d_\u0f0d\u0f0d \u0f58\u0f41\u0f60 \u0f0d'\n\n>>> # OUTPUT2: could as well be acheived by in_str.split(' ')\n>>> t.tokenize_on_spaces\n'\u0f63\u0f7a \u0f42\u0f66\u0f0d \u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b\u0f58\u0f50\u0f60\u0f72\u0f0b \u0f06 \u0f64\u0f72\u0f0b\u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b tr \u0f56\u0f51\u0f7a\u0f0b\u0f0b\u0f63\u0f7a \u0f42\u0f66\u0f0d \u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b\u0f56\u0f51\u0f7a\u0f0b\u0f63\u0f7a\u0f42\u0f66\u0f0b\u0f21\u0f22\u0f23\u0f40\u0f40\u0f0d \u0f58\u0f50\u0f60\u0f72\u0f0b\u0f62\u0f92\u0fb1\u0f0b\u0f58\u0f5a\u0f7c\u0f62\u0f0b\u0f42\u0f53\u0f66\u0f0b\u0f54\u0f60\u0f72\u0f0b\u0f49\u0f66\u0f0b\u0f46\u0f74\u0f0b\u0f60\u0f50\u0f74\u0f44\u0f0b\u0f0d\u0f0d \u0f0d\u0f0d\u0f58\u0f41\u0f60\u0f0d'\n\n>>> # OUTPUT3: segments in words.\n... # see how \u0f56\u0f51\u0f7a\u0f0b\u0f0b\u0f63\u0f7a_\u0f42\u0f66 was still recognized as a single word, even with the space and the double tsek.\n... # the affixed particles are separated from the hosting word: \u0f58\u0f50 \u0f60\u0f72\u0f0b \u0f62\u0f92\u0fb1\u0f0b\u0f58\u0f5a\u0f7c \u0f62\u0f0b \u0f42\u0f53\u0f66\u0f0b\u0f54 \u0f60\u0f72\u0f0b \u0f49 \u0f66\u0f0b\n>>> t.tokenize_words_raw_text\nLoading Trie... (2s.)\n'\u0f63\u0f7a_\u0f42\u0f66 \u0f0d_ \u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b \u0f58\u0f50 \u0f60\u0f72\u0f0b _\u0f06_ \u0f64\u0f72\u0f0b \u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b_ tr_ \u0f56\u0f51\u0f7a\u0f0b\u0f0b\u0f63\u0f7a_\u0f42\u0f66 \u0f0d_ \u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b \u0f56\u0f51\u0f7a\u0f0b\u0f63\u0f7a\u0f42\u0f66\u0f0b \u0f21\u0f22\u0f23 \u0f40\u0f40 \u0f0d_ \u0f58\u0f50 \u0f60\u0f72\u0f0b \u0f62\u0f92\u0fb1\u0f0b\u0f58\u0f5a\u0f7c \u0f62\u0f0b \u0f42\u0f53\u0f66\u0f0b\u0f54 \u0f60\u0f72\u0f0b \u0f49 \u0f66\u0f0b \u0f46\u0f74\u0f0b \u0f60\u0f50\u0f74\u0f44\u0f0b \u0f0d\u0f0d_\u0f0d\u0f0d \u0f58\u0f41\u0f60 \u0f0d'\n>>> t.tokenize_words_raw_lines\n'\u0f63\u0f7a_\u0f42\u0f66 \u0f0d_ \u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b \u0f58\u0f50 \u0f60\u0f72\u0f0b _\u0f06_ \u0f64\u0f72\u0f0b \u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b__ tr_\\n \u0f56\u0f51\u0f7a\u0f0b\u0f0b\u0f63\u0f7a_\u0f42\u0f66 \u0f0d_ \u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b \u0f56\u0f51\u0f7a\u0f0b\u0f63\u0f7a\u0f42\u0f66\u0f0b \u0f21\u0f22\u0f23 \u0f40\u0f40 \u0f0d_\\n \u0f58\u0f50 \u0f60\u0f72\u0f0b \u0f62\u0f92\u0fb1\u0f0b\u0f58\u0f5a\u0f7c \u0f62\u0f0b \u0f42\u0f53\u0f66\u0f0b\u0f54 \u0f60\u0f72\u0f0b \u0f49 \u0f66\u0f0b \u0f46\u0f74\u0f0b \u0f60\u0f50\u0f74\u0f44\u0f0b \u0f0d\u0f0d_\u0f0d\u0f0d \u0f58\u0f41\u0f60 \u0f0d'\n\n>>> # OUTPUT4: segments in words, then calculates the number of occurences of each word found\n... # by default, it counts in_str's substrings in the output, which is why we have \u0f56\u0f51\u0f7a\u0f0b\u0f0b\u0f63\u0f7a \u0f42\u0f66\t1, \u0f56\u0f51\u0f7a\u0f0b\u0f63\u0f7a\u0f42\u0f66\u0f0b\t1\n... # this behaviour can easily be modified to take into account the words that pybo recognized instead (see advanced usage)\n>>> print(t.list_word_types)\n\u0f60\u0f72\u0f0b\t3\n\u0f0d \t2\n\u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b\t2\n\u0f58\u0f50\t2\n\u0f63\u0f7a \u0f42\u0f66\t1\n \u0f06 \t1\n\u0f64\u0f72\u0f0b\t1\n\u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b  \t1\ntr \\n\t1\n\u0f56\u0f51\u0f7a\u0f0b\u0f0b\u0f63\u0f7a \u0f42\u0f66\t1\n\u0f56\u0f51\u0f7a\u0f0b\u0f63\u0f7a\u0f42\u0f66\u0f0b\t1\n\u0f21\u0f22\u0f23\t1\n\u0f40\u0f40\t1\n\u0f0d \\n\t1\n\u0f62\u0f92\u0fb1\u0f0b\u0f58\u0f5a\u0f7c\t1\n\u0f62\u0f0b\t1\n\u0f42\u0f53\u0f66\u0f0b\u0f54\t1\n\u0f49\t1\n\u0f66\u0f0b\t1\n\u0f46\u0f74\u0f0b\t1\n\u0f60\u0f50\u0f74\u0f44\u0f0b\t1\n\u0f0d\u0f0d \u0f0d\u0f0d\t1\n\u0f58\u0f41\u0f60\t1\n\u0f0d\t1\n```\n\n## Acknowledgements\n\n**botok** is an open source library for Tibetan NLP.\n\nWe are always open to cooperation in introducing new features, tool integrations and testing solutions.\n\nMany thanks to the companies and organizations who have supported botok's development, especially:\n\n* [Khyentse Foundation](https://khyentsefoundation.org) for contributing USD22,000 to kickstart the project \n* The [Barom/Esukhia canon project](http://www.barom.org) for sponsoring training data curation\n* [BDRC](https://tbrc.org) for contributing 2 staff for 6 months for data curation\n\n## Maintainance\n\nBuild the source dist:\n\n```\nrm -rf dist/\npython3 setup.py clean sdist\n```\n\nand upload on twine (version >= `1.11.0`) with:\n\n```\ntwine upload dist/*\n```\n\n## License\n\nThe Python code is Copyright (C) 2019 Esukhia, provided under [Apache 2](LICENSE). \n\ncontributors:\n * [Drupchen](https://github.com/drupchen)\n * [\u00c9lie Roux](https://github.com/eroux)\n * [Ngawang Trinley](https://github.com/ngawangtrinley)\n * [Mikko Kotila](https://github.com/mikkokotila)\n * [Thubten Rinzin](https://github.com/thubtenrigzin)\n\n * [Tenzin](https://github.com/10zinten)\n * Joyce Mackzenzie for reworking the logo", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Esukhia/botok", "keywords": "nlp computational_linguistics tibetan tokenizer token", "license": "Apache2", "maintainer": "", "maintainer_email": "", "name": "botok", "package_url": "https://pypi.org/project/botok/", "platform": "", "project_url": "https://pypi.org/project/botok/", "project_urls": {"Homepage": "https://github.com/Esukhia/botok", "Source": "https://github.com/Esukhia/botok", "Tracker": "https://github.com/Esukhia/botok/issues"}, "release_url": "https://pypi.org/project/botok/0.7.5/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Tibetan Word Tokenizer", "version": "0.7.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>botok \u2013 Python Tibetan Tokenizer</h1>\n<p><a href=\"https://travis-ci.org/Esukhia/botok\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/48e45247e515200e754e3b795f2abf715426eac1/68747470733a2f2f7472617669732d63692e6f72672f4573756b6869612f626f746f6b2e7376673f6272616e63683d6d6173746572\"></a>  <a href=\"https://coveralls.io/github/Esukhia/botok?branch=master\" rel=\"nofollow\"><img alt=\"Coverage Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/30e51e11017a81a12647b7528d0564504faf2edb/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f4573756b6869612f626f746f6b2f62616467652e7376673f6272616e63683d6d6173746572\"></a> <img alt=\"GitHub release\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/73ba2d4279ec265a2b1f012d721b060855415f97/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f4573756b6869612f626f746f6b2e737667\"> <a href=\"https://www.codefactor.io/repository/github/esukhia/botok\" rel=\"nofollow\"><img alt=\"CodeFactor\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f73e33cc3feea67f26f20ba7743e3df44071f8ca/68747470733a2f2f7777772e636f6465666163746f722e696f2f7265706f7369746f72792f6769746875622f6573756b6869612f626f746f6b2f6261646765\"></a> <a href=\"https://black.readthedocs.io/en/stable/\" rel=\"nofollow\"><img alt=\"Code style: black\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fbfdc7754183ecf079bc71ddeabaf88f6cbc5c00/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667\"></a></p>\n<h2>Overview</h2>\n<p>botok tokenizes Tibetan text into words.</p>\n<h3>Basic usage</h3>\n<h4>Getting started</h4>\n<p>Requires to have Python3 installed.</p>\n<pre><code>pip3 install botok\n</code></pre>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">botok</span> <span class=\"kn\">import</span> <span class=\"n\">Text</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"c1\"># input is a multi-line input string</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">in_str</span> <span class=\"o\">=</span> <span class=\"s2\">\"\"\"\u0f63\u0f7a \u0f42\u0f66\u0f0d \u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b\u0f58\u0f50\u0f60\u0f72\u0f0b \u0f06 \u0f64\u0f72\u0f0b\u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b  tr </span>\n<span class=\"s2\">... \u0f56\u0f51\u0f7a\u0f0b\u0f0b\u0f63\u0f7a \u0f42\u0f66\u0f0d \u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b\u0f56\u0f51\u0f7a\u0f0b\u0f63\u0f7a\u0f42\u0f66\u0f0b\u0f21\u0f22\u0f23\u0f40\u0f40\u0f0d </span>\n<span class=\"s2\">... \u0f58\u0f50\u0f60\u0f72\u0f0b\u0f62\u0f92\u0fb1\u0f0b\u0f58\u0f5a\u0f7c\u0f62\u0f0b\u0f42\u0f53\u0f66\u0f0b\u0f54\u0f60\u0f72\u0f0b\u0f49\u0f66\u0f0b\u0f46\u0f74\u0f0b\u0f60\u0f50\u0f74\u0f44\u0f0b\u0f0d\u0f0d \u0f0d\u0f0d\u0f58\u0f41\u0f60\u0f0d\"\"\"</span>\n\n\n<span class=\"c1\">### STEP1: instanciating Text</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"c1\"># A. on a string</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">t</span> <span class=\"o\">=</span> <span class=\"n\">Text</span><span class=\"p\">(</span><span class=\"n\">in_str</span><span class=\"p\">)</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"c1\"># B. on a file</span>\n<span class=\"o\">...</span> <span class=\"c1\"># note all following operations can be applied to files in this way.</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">pathlib</span> <span class=\"kn\">import</span> <span class=\"n\">Path</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">in_file</span> <span class=\"o\">=</span> <span class=\"n\">Path</span><span class=\"o\">.</span><span class=\"n\">cwd</span><span class=\"p\">()</span> <span class=\"o\">/</span> <span class=\"s1\">'test.txt'</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"c1\"># file content:</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">in_file</span><span class=\"o\">.</span><span class=\"n\">read_text</span><span class=\"p\">()</span>\n<span class=\"s1\">'\u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b\u0f56\u0f51\u0f7a\u0f0b\u0f63\u0f7a\u0f42\u0f66\u0f0d\u0f0d</span><span class=\"se\">\\n</span><span class=\"s1\">'</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">t</span> <span class=\"o\">=</span> <span class=\"n\">Text</span><span class=\"p\">(</span><span class=\"n\">in_file</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">t</span><span class=\"o\">.</span><span class=\"n\">tokenize_chunks_plaintext</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"c1\"># checking an output file has been written:</span>\n<span class=\"o\">...</span> <span class=\"c1\"># BOM is added by default so that notepad in Windows doesn't scramble the line breaks</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">out_file</span> <span class=\"o\">=</span> <span class=\"n\">Path</span><span class=\"o\">.</span><span class=\"n\">cwd</span><span class=\"p\">()</span> <span class=\"o\">/</span> <span class=\"s1\">'test_pybo.txt'</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">out_file</span><span class=\"o\">.</span><span class=\"n\">read_text</span><span class=\"p\">()</span>\n<span class=\"s1\">'</span><span class=\"se\">\\ufeff</span><span class=\"s1\">\u0f56\u0f40\u0fb2\u0f0b \u0f64\u0f72\u0f66\u0f0b \u0f56\u0f51\u0f7a\u0f0b \u0f63\u0f7a\u0f42\u0f66 \u0f0d\u0f0d'</span>\n\n<span class=\"c1\">### STEP2: properties will perform actions on the input string:</span>\n<span class=\"c1\">### note: original spaces are replaced by underscores.</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"c1\"># OUTPUT1: chunks are meaningful groups of chars from the input string.</span>\n<span class=\"o\">...</span> <span class=\"c1\"># see how punctuations, numerals, non-bo and syllables are all neatly grouped.</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">t</span><span class=\"o\">.</span><span class=\"n\">tokenize_chunks_plaintext</span>\n<span class=\"s1\">'\u0f63\u0f7a_\u0f42\u0f66 \u0f0d_ \u0f56\u0f40\u0fb2\u0f0b \u0f64\u0f72\u0f66\u0f0b \u0f58\u0f50\u0f60\u0f72\u0f0b _\u0f06_ \u0f64\u0f72\u0f0b \u0f56\u0f40\u0fb2\u0f0b \u0f64\u0f72\u0f66\u0f0b__ tr_</span><span class=\"se\">\\n</span><span class=\"s1\"> \u0f56\u0f51\u0f7a\u0f0b\u0f0b \u0f63\u0f7a_\u0f42\u0f66 \u0f0d_ \u0f56\u0f40\u0fb2\u0f0b \u0f64\u0f72\u0f66\u0f0b \u0f56\u0f51\u0f7a\u0f0b \u0f63\u0f7a\u0f42\u0f66\u0f0b \u0f21\u0f22\u0f23 \u0f40\u0f40 \u0f0d_</span><span class=\"se\">\\n</span><span class=\"s1\"> \u0f58\u0f50\u0f60\u0f72\u0f0b \u0f62\u0f92\u0fb1\u0f0b \u0f58\u0f5a\u0f7c\u0f62\u0f0b \u0f42\u0f53\u0f66\u0f0b \u0f54\u0f60\u0f72\u0f0b \u0f49\u0f66\u0f0b \u0f46\u0f74\u0f0b \u0f60\u0f50\u0f74\u0f44\u0f0b \u0f0d\u0f0d_\u0f0d\u0f0d \u0f58\u0f41\u0f60 \u0f0d'</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"c1\"># OUTPUT2: could as well be acheived by in_str.split(' ')</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">t</span><span class=\"o\">.</span><span class=\"n\">tokenize_on_spaces</span>\n<span class=\"s1\">'\u0f63\u0f7a \u0f42\u0f66\u0f0d \u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b\u0f58\u0f50\u0f60\u0f72\u0f0b \u0f06 \u0f64\u0f72\u0f0b\u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b tr \u0f56\u0f51\u0f7a\u0f0b\u0f0b\u0f63\u0f7a \u0f42\u0f66\u0f0d \u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b\u0f56\u0f51\u0f7a\u0f0b\u0f63\u0f7a\u0f42\u0f66\u0f0b\u0f21\u0f22\u0f23\u0f40\u0f40\u0f0d \u0f58\u0f50\u0f60\u0f72\u0f0b\u0f62\u0f92\u0fb1\u0f0b\u0f58\u0f5a\u0f7c\u0f62\u0f0b\u0f42\u0f53\u0f66\u0f0b\u0f54\u0f60\u0f72\u0f0b\u0f49\u0f66\u0f0b\u0f46\u0f74\u0f0b\u0f60\u0f50\u0f74\u0f44\u0f0b\u0f0d\u0f0d \u0f0d\u0f0d\u0f58\u0f41\u0f60\u0f0d'</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"c1\"># OUTPUT3: segments in words.</span>\n<span class=\"o\">...</span> <span class=\"c1\"># see how \u0f56\u0f51\u0f7a\u0f0b\u0f0b\u0f63\u0f7a_\u0f42\u0f66 was still recognized as a single word, even with the space and the double tsek.</span>\n<span class=\"o\">...</span> <span class=\"c1\"># the affixed particles are separated from the hosting word: \u0f58\u0f50 \u0f60\u0f72\u0f0b \u0f62\u0f92\u0fb1\u0f0b\u0f58\u0f5a\u0f7c \u0f62\u0f0b \u0f42\u0f53\u0f66\u0f0b\u0f54 \u0f60\u0f72\u0f0b \u0f49 \u0f66\u0f0b</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">t</span><span class=\"o\">.</span><span class=\"n\">tokenize_words_raw_text</span>\n<span class=\"n\">Loading</span> <span class=\"n\">Trie</span><span class=\"o\">...</span> <span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"n\">s</span><span class=\"o\">.</span><span class=\"p\">)</span>\n<span class=\"s1\">'\u0f63\u0f7a_\u0f42\u0f66 \u0f0d_ \u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b \u0f58\u0f50 \u0f60\u0f72\u0f0b _\u0f06_ \u0f64\u0f72\u0f0b \u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b_ tr_ \u0f56\u0f51\u0f7a\u0f0b\u0f0b\u0f63\u0f7a_\u0f42\u0f66 \u0f0d_ \u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b \u0f56\u0f51\u0f7a\u0f0b\u0f63\u0f7a\u0f42\u0f66\u0f0b \u0f21\u0f22\u0f23 \u0f40\u0f40 \u0f0d_ \u0f58\u0f50 \u0f60\u0f72\u0f0b \u0f62\u0f92\u0fb1\u0f0b\u0f58\u0f5a\u0f7c \u0f62\u0f0b \u0f42\u0f53\u0f66\u0f0b\u0f54 \u0f60\u0f72\u0f0b \u0f49 \u0f66\u0f0b \u0f46\u0f74\u0f0b \u0f60\u0f50\u0f74\u0f44\u0f0b \u0f0d\u0f0d_\u0f0d\u0f0d \u0f58\u0f41\u0f60 \u0f0d'</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">t</span><span class=\"o\">.</span><span class=\"n\">tokenize_words_raw_lines</span>\n<span class=\"s1\">'\u0f63\u0f7a_\u0f42\u0f66 \u0f0d_ \u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b \u0f58\u0f50 \u0f60\u0f72\u0f0b _\u0f06_ \u0f64\u0f72\u0f0b \u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b__ tr_</span><span class=\"se\">\\n</span><span class=\"s1\"> \u0f56\u0f51\u0f7a\u0f0b\u0f0b\u0f63\u0f7a_\u0f42\u0f66 \u0f0d_ \u0f56\u0f40\u0fb2\u0f0b\u0f64\u0f72\u0f66\u0f0b \u0f56\u0f51\u0f7a\u0f0b\u0f63\u0f7a\u0f42\u0f66\u0f0b \u0f21\u0f22\u0f23 \u0f40\u0f40 \u0f0d_</span><span class=\"se\">\\n</span><span class=\"s1\"> \u0f58\u0f50 \u0f60\u0f72\u0f0b \u0f62\u0f92\u0fb1\u0f0b\u0f58\u0f5a\u0f7c \u0f62\u0f0b \u0f42\u0f53\u0f66\u0f0b\u0f54 \u0f60\u0f72\u0f0b \u0f49 \u0f66\u0f0b \u0f46\u0f74\u0f0b \u0f60\u0f50\u0f74\u0f44\u0f0b \u0f0d\u0f0d_\u0f0d\u0f0d \u0f58\u0f41\u0f60 \u0f0d'</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"c1\"># OUTPUT4: segments in words, then calculates the number of occurences of each word found</span>\n<span class=\"o\">...</span> <span class=\"c1\"># by default, it counts in_str's substrings in the output, which is why we have \u0f56\u0f51\u0f7a\u0f0b\u0f0b\u0f63\u0f7a \u0f42\u0f66\t1, \u0f56\u0f51\u0f7a\u0f0b\u0f63\u0f7a\u0f42\u0f66\u0f0b\t1</span>\n<span class=\"o\">...</span> <span class=\"c1\"># this behaviour can easily be modified to take into account the words that pybo recognized instead (see advanced usage)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">t</span><span class=\"o\">.</span><span class=\"n\">list_word_types</span><span class=\"p\">)</span>\n<span class=\"n\">\u0f60\u0f72</span><span class=\"err\">\u0f0b</span>\t<span class=\"mi\">3</span>\n<span class=\"err\">\u0f0d</span> \t<span class=\"mi\">2</span>\n<span class=\"n\">\u0f56\u0f40\u0fb2</span><span class=\"err\">\u0f0b</span><span class=\"n\">\u0f64\u0f72\u0f66</span><span class=\"err\">\u0f0b</span>\t<span class=\"mi\">2</span>\n<span class=\"n\">\u0f58\u0f50</span>\t<span class=\"mi\">2</span>\n<span class=\"n\">\u0f63\u0f7a</span> <span class=\"n\">\u0f42\u0f66</span>\t<span class=\"mi\">1</span>\n <span class=\"err\">\u0f06</span> \t<span class=\"mi\">1</span>\n<span class=\"n\">\u0f64\u0f72</span><span class=\"err\">\u0f0b</span>\t<span class=\"mi\">1</span>\n<span class=\"n\">\u0f56\u0f40\u0fb2</span><span class=\"err\">\u0f0b</span><span class=\"n\">\u0f64\u0f72\u0f66</span><span class=\"err\">\u0f0b</span>  \t<span class=\"mi\">1</span>\n<span class=\"n\">tr</span> \\<span class=\"n\">n</span>\t<span class=\"mi\">1</span>\n<span class=\"n\">\u0f56\u0f51\u0f7a</span><span class=\"err\">\u0f0b\u0f0b</span><span class=\"n\">\u0f63\u0f7a</span> <span class=\"n\">\u0f42\u0f66</span>\t<span class=\"mi\">1</span>\n<span class=\"n\">\u0f56\u0f51\u0f7a</span><span class=\"err\">\u0f0b</span><span class=\"n\">\u0f63\u0f7a\u0f42\u0f66</span><span class=\"err\">\u0f0b</span>\t<span class=\"mi\">1</span>\n<span class=\"mi\">\u0f21\u0f22\u0f23</span>\t<span class=\"mi\">1</span>\n<span class=\"n\">\u0f40\u0f40</span>\t<span class=\"mi\">1</span>\n<span class=\"err\">\u0f0d</span> \\<span class=\"n\">n</span>\t<span class=\"mi\">1</span>\n<span class=\"n\">\u0f62\u0f92\u0fb1</span><span class=\"err\">\u0f0b</span><span class=\"n\">\u0f58\u0f5a\u0f7c</span>\t<span class=\"mi\">1</span>\n<span class=\"n\">\u0f62</span><span class=\"err\">\u0f0b</span>\t<span class=\"mi\">1</span>\n<span class=\"n\">\u0f42\u0f53\u0f66</span><span class=\"err\">\u0f0b</span><span class=\"n\">\u0f54</span>\t<span class=\"mi\">1</span>\n<span class=\"n\">\u0f49</span>\t<span class=\"mi\">1</span>\n<span class=\"n\">\u0f66</span><span class=\"err\">\u0f0b</span>\t<span class=\"mi\">1</span>\n<span class=\"n\">\u0f46\u0f74</span><span class=\"err\">\u0f0b</span>\t<span class=\"mi\">1</span>\n<span class=\"n\">\u0f60\u0f50\u0f74\u0f44</span><span class=\"err\">\u0f0b</span>\t<span class=\"mi\">1</span>\n<span class=\"err\">\u0f0d\u0f0d</span> <span class=\"err\">\u0f0d\u0f0d</span>\t<span class=\"mi\">1</span>\n<span class=\"n\">\u0f58\u0f41\u0f60</span>\t<span class=\"mi\">1</span>\n<span class=\"err\">\u0f0d</span>\t<span class=\"mi\">1</span>\n</pre>\n<h2>Acknowledgements</h2>\n<p><strong>botok</strong> is an open source library for Tibetan NLP.</p>\n<p>We are always open to cooperation in introducing new features, tool integrations and testing solutions.</p>\n<p>Many thanks to the companies and organizations who have supported botok's development, especially:</p>\n<ul>\n<li><a href=\"https://khyentsefoundation.org\" rel=\"nofollow\">Khyentse Foundation</a> for contributing USD22,000 to kickstart the project</li>\n<li>The <a href=\"http://www.barom.org\" rel=\"nofollow\">Barom/Esukhia canon project</a> for sponsoring training data curation</li>\n<li><a href=\"https://tbrc.org\" rel=\"nofollow\">BDRC</a> for contributing 2 staff for 6 months for data curation</li>\n</ul>\n<h2>Maintainance</h2>\n<p>Build the source dist:</p>\n<pre><code>rm -rf dist/\npython3 setup.py clean sdist\n</code></pre>\n<p>and upload on twine (version &gt;= <code>1.11.0</code>) with:</p>\n<pre><code>twine upload dist/*\n</code></pre>\n<h2>License</h2>\n<p>The Python code is Copyright (C) 2019 Esukhia, provided under <a href=\"LICENSE\" rel=\"nofollow\">Apache 2</a>.</p>\n<p>contributors:</p>\n<ul>\n<li>\n<p><a href=\"https://github.com/drupchen\" rel=\"nofollow\">Drupchen</a></p>\n</li>\n<li>\n<p><a href=\"https://github.com/eroux\" rel=\"nofollow\">\u00c9lie Roux</a></p>\n</li>\n<li>\n<p><a href=\"https://github.com/ngawangtrinley\" rel=\"nofollow\">Ngawang Trinley</a></p>\n</li>\n<li>\n<p><a href=\"https://github.com/mikkokotila\" rel=\"nofollow\">Mikko Kotila</a></p>\n</li>\n<li>\n<p><a href=\"https://github.com/thubtenrigzin\" rel=\"nofollow\">Thubten Rinzin</a></p>\n</li>\n<li>\n<p><a href=\"https://github.com/10zinten\" rel=\"nofollow\">Tenzin</a></p>\n</li>\n<li>\n<p>Joyce Mackzenzie for reworking the logo</p>\n</li>\n</ul>\n\n          </div>"}, "last_serial": 6376210, "releases": {"0.6.10": [{"comment_text": "", "digests": {"md5": "d5c7b7ec502fb0519c9cdf53989c1b43", "sha256": "4d2dcdf09c2f17392dd4224ad20bed2c5ea23f335267304971effe2ce3b9425d"}, "downloads": -1, "filename": "botok-0.6.10.tar.gz", "has_sig": false, "md5_digest": "d5c7b7ec502fb0519c9cdf53989c1b43", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 1094226, "upload_time": "2019-09-12T20:06:11", "upload_time_iso_8601": "2019-09-12T20:06:11.145597Z", "url": "https://files.pythonhosted.org/packages/e7/36/8063c19f5ece7f76a2192348f086c93fc1bea23b3541b62db9e95eed6e9b/botok-0.6.10.tar.gz", "yanked": false}], "0.6.11": [{"comment_text": "", "digests": {"md5": "babd20af63a0a3c8ea3e7632dac223ce", "sha256": "08582549ffa9775180ef3f32b839a9d7679c7730e30f7f80a3eea8ab5a7dac23"}, "downloads": -1, "filename": "botok-0.6.11.tar.gz", "has_sig": false, "md5_digest": "babd20af63a0a3c8ea3e7632dac223ce", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 1094995, "upload_time": "2019-10-04T21:48:16", "upload_time_iso_8601": "2019-10-04T21:48:16.653406Z", "url": "https://files.pythonhosted.org/packages/87/eb/7d4ada02c5b5644c9433e819ff90a6fb0bd8fb3bcb73c142428c2fdffb92/botok-0.6.11.tar.gz", "yanked": false}], "0.6.12": [{"comment_text": "", "digests": {"md5": "314bc84aa814ab5d70694aba3c4d619f", "sha256": "80fb3513f2a3e9a09dc4c926e28fddeb6e3256488a6ee40222d62e978298f613"}, "downloads": -1, "filename": "botok-0.6.12.tar.gz", "has_sig": false, "md5_digest": "314bc84aa814ab5d70694aba3c4d619f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 1094935, "upload_time": "2019-10-07T13:35:43", "upload_time_iso_8601": "2019-10-07T13:35:43.039853Z", "url": "https://files.pythonhosted.org/packages/fd/74/7e557557893e1b2ae0cfd7407477af9509f1c97646f6aac43d7acbcda5f3/botok-0.6.12.tar.gz", "yanked": false}], "0.6.13": [{"comment_text": "", "digests": {"md5": "2cb95ed11761443a65dd2806ebcdb3ae", "sha256": "60d0d4047ec870450d7d934324a45ab89e568728a6700888371e3d207f55d028"}, "downloads": -1, "filename": "botok-0.6.13.tar.gz", "has_sig": false, "md5_digest": "2cb95ed11761443a65dd2806ebcdb3ae", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 1096233, "upload_time": "2019-11-01T07:19:18", "upload_time_iso_8601": "2019-11-01T07:19:18.520176Z", "url": "https://files.pythonhosted.org/packages/1d/3d/614b90c2c1845c433b09cd1c9eab28840793527bc154c59374d01315cd85/botok-0.6.13.tar.gz", "yanked": false}], "0.6.14": [{"comment_text": "", "digests": {"md5": "0205c1120ab1ef0b598ff7ee51dc4f3c", "sha256": "4ee92f091d8db1a242701f63fec98cbf835cb8db609e08de0db4f48102972d5b"}, "downloads": -1, "filename": "botok-0.6.14.tar.gz", "has_sig": false, "md5_digest": "0205c1120ab1ef0b598ff7ee51dc4f3c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 1096927, "upload_time": "2019-11-05T11:49:53", "upload_time_iso_8601": "2019-11-05T11:49:53.660529Z", "url": "https://files.pythonhosted.org/packages/75/95/f96be7eca87361bf71018d2dbe065f28a9754b43f23be7130aaedf7b6fba/botok-0.6.14.tar.gz", "yanked": false}], "0.6.15": [{"comment_text": "", "digests": {"md5": "56f899bcde32e29aa2be8ef109a273a8", "sha256": "6844f4124afe71548b0f2c5a3a232092ea454fecd0df9c9a06e8fceb420ba442"}, "downloads": -1, "filename": "botok-0.6.15.tar.gz", "has_sig": false, "md5_digest": "56f899bcde32e29aa2be8ef109a273a8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 1095772, "upload_time": "2019-11-06T17:35:40", "upload_time_iso_8601": "2019-11-06T17:35:40.953109Z", "url": "https://files.pythonhosted.org/packages/ee/c0/8270b11daafb1b9612fc747e6187d043ddf31b50644584e7f071061a70e4/botok-0.6.15.tar.gz", "yanked": false}], "0.6.16": [{"comment_text": "", "digests": {"md5": "705fe40620d41fd5572cfdf12ae0d001", "sha256": "b43181ecd103a40a9c38cedbc88a968138f11736492686896175c95a7d6b407c"}, "downloads": -1, "filename": "botok-0.6.16.tar.gz", "has_sig": false, "md5_digest": "705fe40620d41fd5572cfdf12ae0d001", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 1095992, "upload_time": "2019-11-07T14:27:56", "upload_time_iso_8601": "2019-11-07T14:27:56.226786Z", "url": "https://files.pythonhosted.org/packages/a6/0b/42cf1601f65123d12810bf5485e6e25fd2ffc2f72d73c0aa7ccfd8293ac1/botok-0.6.16.tar.gz", "yanked": false}], "0.6.17": [{"comment_text": "", "digests": {"md5": "0f95c5802ae766ed01c854795220e649", "sha256": "5ceaa988b60a44266ff70e2f45b4da78342bb2dcee6086278acdcbec27e93fdd"}, "downloads": -1, "filename": "botok-0.6.17.tar.gz", "has_sig": false, "md5_digest": "0f95c5802ae766ed01c854795220e649", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 1096000, "upload_time": "2019-11-07T20:10:32", "upload_time_iso_8601": "2019-11-07T20:10:32.304712Z", "url": "https://files.pythonhosted.org/packages/e8/59/8cbc5d7382bf31cf69db9a23855749d63b17b9febfe62873c8c447734723/botok-0.6.17.tar.gz", "yanked": false}], "0.6.18": [{"comment_text": "", "digests": {"md5": "69c581b87ab7f0c24e6253100c741d08", "sha256": "8e0424ed9809b52561aee0166cc76372f0616fad41d87a8e2743cabf862661be"}, "downloads": -1, "filename": "botok-0.6.18.tar.gz", "has_sig": false, "md5_digest": "69c581b87ab7f0c24e6253100c741d08", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 1096720, "upload_time": "2019-11-21T09:01:10", "upload_time_iso_8601": "2019-11-21T09:01:10.943599Z", "url": "https://files.pythonhosted.org/packages/47/f9/30199b6c2e459a39c5cd119cfcd6bd74796f833e89adb13a03ea777012d1/botok-0.6.18.tar.gz", "yanked": false}], "0.6.9": [{"comment_text": "", "digests": {"md5": "e49970c9d2ec431cf33cf1af4e0badfa", "sha256": "d8b2c6ad17163a2258c3cca687b2b032a3a588b4fe61881a9fdd64cec2051fcb"}, "downloads": -1, "filename": "botok-0.6.9.tar.gz", "has_sig": false, "md5_digest": "e49970c9d2ec431cf33cf1af4e0badfa", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 1094373, "upload_time": "2019-09-01T22:19:22", "upload_time_iso_8601": "2019-09-01T22:19:22.710623Z", "url": "https://files.pythonhosted.org/packages/0b/b2/c6539b4b163b4f1360961d04bba2341a37c09d5b09113bcdae9d5a953fab/botok-0.6.9.tar.gz", "yanked": false}], "0.7.0": [{"comment_text": "", "digests": {"md5": "00b191f2948afa976f85b6eaf52826c0", "sha256": "c5a221c4cba414c1d0b4a8e5cc19e821433ada8861c4b1f762bab0a59f8341b1"}, "downloads": -1, "filename": "botok-0.7.0.tar.gz", "has_sig": false, "md5_digest": "00b191f2948afa976f85b6eaf52826c0", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 230102, "upload_time": "2019-12-10T10:55:33", "upload_time_iso_8601": "2019-12-10T10:55:33.697519Z", "url": "https://files.pythonhosted.org/packages/08/4b/733c1063725dbcf283b3f91880efb687cf36a8be96b33878de307e07bf74/botok-0.7.0.tar.gz", "yanked": false}], "0.7.1": [{"comment_text": "", "digests": {"md5": "7c22f199fd88f7c3dc02a06acb8f14eb", "sha256": "ba5ac4022aa764f73564c6dc6c5aa3171c0d780b3b90297bf78fa2541adc82d4"}, "downloads": -1, "filename": "botok-0.7.1.tar.gz", "has_sig": false, "md5_digest": "7c22f199fd88f7c3dc02a06acb8f14eb", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 52821, "upload_time": "2019-12-11T20:30:48", "upload_time_iso_8601": "2019-12-11T20:30:48.851960Z", "url": "https://files.pythonhosted.org/packages/90/83/435e849b2d3976f126b622e1b7f404544661ddb68968fc0cc1a6a693c26f/botok-0.7.1.tar.gz", "yanked": false}], "0.7.2": [{"comment_text": "", "digests": {"md5": "5532c747c8375b4af6a69f83f4d853a9", "sha256": "7c3950552ba15f0a546a3bf800eafa3e6850379afc20cbd694b556bdb0772066"}, "downloads": -1, "filename": "botok-0.7.2.tar.gz", "has_sig": false, "md5_digest": "5532c747c8375b4af6a69f83f4d853a9", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 52815, "upload_time": "2019-12-12T10:54:45", "upload_time_iso_8601": "2019-12-12T10:54:45.484517Z", "url": "https://files.pythonhosted.org/packages/da/af/a6c0c24fb64cd3e429c0eed1fc5ccc766991c58c8cb9c9ef98ab330c0388/botok-0.7.2.tar.gz", "yanked": false}], "0.7.3": [{"comment_text": "", "digests": {"md5": "a5960d2ea45a1778822f3a72da00bef9", "sha256": "7aecb59b0e94ccd39b925eeddc36e1e243a5ac87714b26f5bfeedcfa80363988"}, "downloads": -1, "filename": "botok-0.7.3.tar.gz", "has_sig": false, "md5_digest": "a5960d2ea45a1778822f3a72da00bef9", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 52832, "upload_time": "2019-12-12T11:11:17", "upload_time_iso_8601": "2019-12-12T11:11:17.867537Z", "url": "https://files.pythonhosted.org/packages/18/ea/c6646c6be52ecf83700b68c355af3dc82ffbe6a224e679acc2d155e6fae3/botok-0.7.3.tar.gz", "yanked": false}], "0.7.4": [{"comment_text": "", "digests": {"md5": "8533a081a74c18a0a3f62a7cc3c366d4", "sha256": "38c3131341910cc84a087a1181e79fc30ed640e29276376cfd860ab1869308bb"}, "downloads": -1, "filename": "botok-0.7.4.tar.gz", "has_sig": false, "md5_digest": "8533a081a74c18a0a3f62a7cc3c366d4", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 52957, "upload_time": "2019-12-15T02:28:09", "upload_time_iso_8601": "2019-12-15T02:28:09.436347Z", "url": "https://files.pythonhosted.org/packages/c6/33/31a1cbfa22d6880432243eb738f5d11990ea9326d7dfecaeeda9a6c85281/botok-0.7.4.tar.gz", "yanked": false}], "0.7.5": [{"comment_text": "", "digests": {"md5": "ef52f62f56505405db9044a0d59687fc", "sha256": "8489f64ac209ee73f50e9382e05bc596d6de8ec66f3df9609f1da8839ca2ff54"}, "downloads": -1, "filename": "botok-0.7.5.tar.gz", "has_sig": false, "md5_digest": "ef52f62f56505405db9044a0d59687fc", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 50241, "upload_time": "2019-12-30T18:02:24", "upload_time_iso_8601": "2019-12-30T18:02:24.185620Z", "url": "https://files.pythonhosted.org/packages/81/44/1da0de82d94f51cc66d02e3d7105f6033580cbc61e29fdf1cbcce2d8db4e/botok-0.7.5.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ef52f62f56505405db9044a0d59687fc", "sha256": "8489f64ac209ee73f50e9382e05bc596d6de8ec66f3df9609f1da8839ca2ff54"}, "downloads": -1, "filename": "botok-0.7.5.tar.gz", "has_sig": false, "md5_digest": "ef52f62f56505405db9044a0d59687fc", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 50241, "upload_time": "2019-12-30T18:02:24", "upload_time_iso_8601": "2019-12-30T18:02:24.185620Z", "url": "https://files.pythonhosted.org/packages/81/44/1da0de82d94f51cc66d02e3d7105f6033580cbc61e29fdf1cbcce2d8db4e/botok-0.7.5.tar.gz", "yanked": false}], "timestamp": "Thu May  7 22:36:35 2020"}