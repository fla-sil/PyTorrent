{"info": {"author": "eterna2", "author_email": "eterna2@hotmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "Intended Audience :: Developers", "Natural Language :: English", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "# e2fyi-pyspark\n\n[![PyPI version](https://badge.fury.io/py/e2fyi-pyspark.svg)](https://badge.fury.io/py/e2fyi-pyspark)\n[![Build Status](https://travis-ci.org/e2fyi/pyspark-utils.svg?branch=master)](https://travis-ci.org/e2fyi/pyspark-utils)\n[![Coverage Status](https://coveralls.io/repos/github/e2fyi/pyspark-utils/badge.svg?branch=master)](https://coveralls.io/github/e2fyi/pyspark-utils?branch=master)\n[![Documentation Status](https://readthedocs.org/projects/e2fyi-pyspark/badge/?version=latest)](https://e2fyi-pyspark.readthedocs.io/en/latest/?badge=latest)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![Downloads](https://pepy.tech/badge/e2fyi-pyspark)](https://pepy.tech/project/e2fyi-pyspark)\n\n`e2fyi-pyspark` is an `e2fyi` namespaced python package with `pyspark` subpackage\n(i.e. `e2fyi.pyspark`) which holds a collections of useful functions for common\nbut painful pyspark tasks.\n\nAPI documentation can be found at [https://e2fyi-pyspark.readthedocs.io/en/latest/](https://e2fyi-pyspark.readthedocs.io/en/latest/).\n\nChange logs are available in [CHANGELOG.md](./CHANGELOG.md).\n\n> - Python 3.6 and above\n> - Licensed under [Apache-2.0](./LICENSE).\n\n## Quickstart\n\n```bash\npip install e2fyi-pyspark\n```\n\n### Infer schema for unknown json strings inside a pyspark dataframe\n\n`e2fyi.pyspark.schema.infer_schema_from_rows` is a util function to infer the\nschema of unknown json strings inside a pyspark dataframe - i.e. so that the\nschema can be subsequently used to parse the json string into a typed data\nstructure in the dataframe\n(see [`pyspark.sql.functions.from_json`](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.from_json)).\n\n```py\nimport pyspark\nfrom e2fyi.pyspark.schema import infer_schema_from_rows\n\n# get spark session\nspark = pyspark.sql.SparkSession.builder.getOrCreate()\n# load a parquet (assume the parquet has a column \"json_str\", which\n# contains a json str with unknown schema)\ndf = spark.read.parquet(\"s3://some-bucket/some-file.parquet\")\n# get 10% of the rows as sample (w/o replacement)\nsample_rows = df.select(\"json_str\").sample(False, 0.01).collect()\n# infer the schema for json str in col \"json_str\" based on the sample rows\n# NOTE: this is run locally (not in spark)\nschema = infer_schema_from_rows(sample_rows, col=\"json_str\")\n# add a new column \"data\" which is the parsed json string with a inferred schema\ndf = df.withColumn(\"data\", pyspark.sql.functions.from_json(\"json_str\", schema))\n# should have a column \"data\" with a proper schema\ndf.printSchema()\n```", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/e2fyi/pyspark-utils", "keywords": "util pyspark", "license": "", "maintainer": "", "maintainer_email": "", "name": "e2fyi-pyspark", "package_url": "https://pypi.org/project/e2fyi-pyspark/", "platform": "", "project_url": "https://pypi.org/project/e2fyi-pyspark/", "project_urls": {"Homepage": "https://github.com/e2fyi/pyspark-utils"}, "release_url": "https://pypi.org/project/e2fyi-pyspark/0.1.0a1/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Productivity functions for common but painful pyspark tasks.", "version": "0.1.0a1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>e2fyi-pyspark</h1>\n<p><a href=\"https://badge.fury.io/py/e2fyi-pyspark\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/06bff8bacff6c174d0d4c4be78237e1c9916737f/68747470733a2f2f62616467652e667572792e696f2f70792f65326679692d7079737061726b2e737667\"></a>\n<a href=\"https://travis-ci.org/e2fyi/pyspark-utils\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/67d74a9da893001060def7a28d092fd2b05f8968/68747470733a2f2f7472617669732d63692e6f72672f65326679692f7079737061726b2d7574696c732e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://coveralls.io/github/e2fyi/pyspark-utils?branch=master\" rel=\"nofollow\"><img alt=\"Coverage Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8aaa4ea324d0987b03e13f0a626afe0717e9f7ea/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f65326679692f7079737061726b2d7574696c732f62616467652e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://e2fyi-pyspark.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fb08670c71f27b8ebac771db71f831f6b18791fd/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f65326679692d7079737061726b2f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<a href=\"https://github.com/psf/black\" rel=\"nofollow\"><img alt=\"Code style: black\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fbfdc7754183ecf079bc71ddeabaf88f6cbc5c00/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667\"></a>\n<a href=\"https://pepy.tech/project/e2fyi-pyspark\" rel=\"nofollow\"><img alt=\"Downloads\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/365a646f94257aa6e8ca4ed8410069da8025beb4/68747470733a2f2f706570792e746563682f62616467652f65326679692d7079737061726b\"></a></p>\n<p><code>e2fyi-pyspark</code> is an <code>e2fyi</code> namespaced python package with <code>pyspark</code> subpackage\n(i.e. <code>e2fyi.pyspark</code>) which holds a collections of useful functions for common\nbut painful pyspark tasks.</p>\n<p>API documentation can be found at <a href=\"https://e2fyi-pyspark.readthedocs.io/en/latest/\" rel=\"nofollow\">https://e2fyi-pyspark.readthedocs.io/en/latest/</a>.</p>\n<p>Change logs are available in <a href=\"./CHANGELOG.md\" rel=\"nofollow\">CHANGELOG.md</a>.</p>\n<blockquote>\n<ul>\n<li>Python 3.6 and above</li>\n<li>Licensed under <a href=\"./LICENSE\" rel=\"nofollow\">Apache-2.0</a>.</li>\n</ul>\n</blockquote>\n<h2>Quickstart</h2>\n<pre>pip install e2fyi-pyspark\n</pre>\n<h3>Infer schema for unknown json strings inside a pyspark dataframe</h3>\n<p><code>e2fyi.pyspark.schema.infer_schema_from_rows</code> is a util function to infer the\nschema of unknown json strings inside a pyspark dataframe - i.e. so that the\nschema can be subsequently used to parse the json string into a typed data\nstructure in the dataframe\n(see <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.from_json\" rel=\"nofollow\"><code>pyspark.sql.functions.from_json</code></a>).</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">pyspark</span>\n<span class=\"kn\">from</span> <span class=\"nn\">e2fyi.pyspark.schema</span> <span class=\"kn\">import</span> <span class=\"n\">infer_schema_from_rows</span>\n\n<span class=\"c1\"># get spark session</span>\n<span class=\"n\">spark</span> <span class=\"o\">=</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">SparkSession</span><span class=\"o\">.</span><span class=\"n\">builder</span><span class=\"o\">.</span><span class=\"n\">getOrCreate</span><span class=\"p\">()</span>\n<span class=\"c1\"># load a parquet (assume the parquet has a column \"json_str\", which</span>\n<span class=\"c1\"># contains a json str with unknown schema)</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">spark</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"o\">.</span><span class=\"n\">parquet</span><span class=\"p\">(</span><span class=\"s2\">\"s3://some-bucket/some-file.parquet\"</span><span class=\"p\">)</span>\n<span class=\"c1\"># get 10% of the rows as sample (w/o replacement)</span>\n<span class=\"n\">sample_rows</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">select</span><span class=\"p\">(</span><span class=\"s2\">\"json_str\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"mf\">0.01</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">collect</span><span class=\"p\">()</span>\n<span class=\"c1\"># infer the schema for json str in col \"json_str\" based on the sample rows</span>\n<span class=\"c1\"># NOTE: this is run locally (not in spark)</span>\n<span class=\"n\">schema</span> <span class=\"o\">=</span> <span class=\"n\">infer_schema_from_rows</span><span class=\"p\">(</span><span class=\"n\">sample_rows</span><span class=\"p\">,</span> <span class=\"n\">col</span><span class=\"o\">=</span><span class=\"s2\">\"json_str\"</span><span class=\"p\">)</span>\n<span class=\"c1\"># add a new column \"data\" which is the parsed json string with a inferred schema</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">withColumn</span><span class=\"p\">(</span><span class=\"s2\">\"data\"</span><span class=\"p\">,</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">functions</span><span class=\"o\">.</span><span class=\"n\">from_json</span><span class=\"p\">(</span><span class=\"s2\">\"json_str\"</span><span class=\"p\">,</span> <span class=\"n\">schema</span><span class=\"p\">))</span>\n<span class=\"c1\"># should have a column \"data\" with a proper schema</span>\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">printSchema</span><span class=\"p\">()</span>\n</pre>\n\n          </div>"}, "last_serial": 6365002, "releases": {"0.1.0a1": [{"comment_text": "", "digests": {"md5": "65c80f24e5e9bfb246fbf1faf1e191e4", "sha256": "5803e03f99958c919d80296bb5924e0370dea959ac4fdfdb76d6a5d182197087"}, "downloads": -1, "filename": "e2fyi-pyspark-0.1.0a1.tar.gz", "has_sig": false, "md5_digest": "65c80f24e5e9bfb246fbf1faf1e191e4", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 8845, "upload_time": "2019-12-27T11:21:07", "upload_time_iso_8601": "2019-12-27T11:21:07.869797Z", "url": "https://files.pythonhosted.org/packages/9d/af/0377f641477d3cf1f259e30626e7ac05e7ddf3cef6c4490a8f82e83de205/e2fyi-pyspark-0.1.0a1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "65c80f24e5e9bfb246fbf1faf1e191e4", "sha256": "5803e03f99958c919d80296bb5924e0370dea959ac4fdfdb76d6a5d182197087"}, "downloads": -1, "filename": "e2fyi-pyspark-0.1.0a1.tar.gz", "has_sig": false, "md5_digest": "65c80f24e5e9bfb246fbf1faf1e191e4", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 8845, "upload_time": "2019-12-27T11:21:07", "upload_time_iso_8601": "2019-12-27T11:21:07.869797Z", "url": "https://files.pythonhosted.org/packages/9d/af/0377f641477d3cf1f259e30626e7ac05e7ddf3cef6c4490a8f82e83de205/e2fyi-pyspark-0.1.0a1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:48:35 2020"}