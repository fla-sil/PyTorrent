{"info": {"author": "Anand B Pillai", "author_email": "abpillai@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Environment :: Console", "Environment :: Web Environment", "Intended Audience :: Developers", "Intended Audience :: End Users/Desktop", "License :: OSI Approved :: GNU General Public License (GPL)", "Operating System :: OS Independent", "Programming Language :: Python", "Topic :: Internet :: WWW/HTTP :: Indexing/Search", "Topic :: Software Development :: Libraries :: Python Modules", "Topic :: Software Development :: Testing :: Traffic Generation", "Topic :: Text Processing :: Indexing"], "description": "HarvestMan is a modular, extensible and flexible web crawler program cum framework written in pure Python. HarvestMan? can be used to download files from websites according to a number of customized rules and constraints. It can be used to find information from websites matching keywords or regular expressions.", "description_content_type": null, "docs_url": null, "download_url": null, "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://code.google.com/p/harvestman-crawler/", "keywords": "crawler spider web-crawler web-bot robot data-mining python", "license": "GPLv2", "maintainer": "Lukasz Szybalski", "maintainer_email": "szybalski@gmail.com", "name": "HarvestMan", "package_url": "https://pypi.org/project/HarvestMan/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/HarvestMan/", "project_urls": {"Homepage": "http://code.google.com/p/harvestman-crawler/"}, "release_url": "https://pypi.org/project/HarvestMan/2.0.4betadev-r169/", "requires_dist": null, "requires_python": null, "summary": "HarvestMan is a web crawler application and framework.", "version": "2.0.4betadev-r169", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>HarvestMan is a modular, extensible and flexible web crawler program cum framework written in pure Python. HarvestMan? can be used to download files from websites according to a number of customized rules and constraints. It can be used to find information from websites matching keywords or regular expressions.</p>\n\n          </div>"}, "last_serial": 75641, "releases": {"1.4.6 final": [], "2.0.4betadev-r169": []}, "urls": [], "timestamp": "Fri May  8 00:52:24 2020"}