{"info": {"author": "Kyle Lawlor", "author_email": "klawlor419@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "Programming Language :: Python :: 3"], "description": "Evalkit API Client Library\n==========================\n\n[Overview](#overview)\n[Testing](#testing)\n[Documentation](#documentation)\n[Installation](#installation)\n[Usage](#usage)\n[Contributing](#contributing)\n[References](#references)\n\nOverview\n--------\n\nThis is a library for making requests to an EvaluationKit API.\n\nTesting\n-------\n\nThis project is tested with [tox](https://tox.readthedocs.io/en/latest/).\n\nRun the tox command to run checks and unit tests:\n```\n$ tox\n```\n\nBy default, this project's tox runs:\n\n * [flake8](http://flake8.pycqa.org/en/latest/)\n * [mypy](https://github.com/python/mypy)\n * [pytest](https://docs.pytest.org/en/latest/)\n\nTo create test coverage reports:\n```\n$ tox -e cov\n```\n\nDeployment\n----------\n\nDeployment to pypi is done with tox:\n```\n$ tox -e deploy\n```\nMake sure to bump the version in setup.py before deploying.\n\nDocumentation\n-------------\n\nThis project has Sphinx documentation at the following url:\nhttps://lcary.github.io/canvas-lms-tools/\n\nThe EvaluationKit API documentation is also very useful:\n\n\nInstallation\n------------\n\nTo install, use pip:\n\n    pip install evalkit_api_client\n\nOr clone the repo:\n\n    git clone https://github.com/lcary/canvas-lms-tools.git\n    cd canvas-lms-tools/evalkit_api_client\n    python setup.py install\n\nUsage\n-----\n\nAdding the client as a dependency in your project's `requirements.txt`\nfile is the intended way to use the client.\n\n#### REPL Example\n\n```\n$ python\n>>> from evalkit_api_client.v1_client import EvalKitAPIv1\n>>> url = 'https://sub-account.evaluationkit.com/api/v1'\n>>> token = 'xxxxxxxxxxxxxxxxxxxTHISxISxNOTxAxREALxTOKENxxxxxxxxxxxxxxxxxxxxx'\n>>> api = EvalKitAPIv1(url, token)\n>>> projects = api.get_projects().json()\n>>> len(projects.json())  # number of projects in sub-account\n>>> for p in projects.['resultList']:\n...     print(p['id'], p['title'])\n...\n49400 Test Evaluation A\n57600 Test Eval B\n```\n\n#### Script Example\n\nThis very simple example requires a few environment variables. The\nAPI URL and token should be something like:\n```\nEVALKIT_API_URL=https://sub-account.evaluationkit.com/api/v1\nEVALKIT_API_TOKEN=xxxxxxxxxxxxxxxxxxxTHISxISxNOTxAxREALxTOKENxxxxxxxxxxxxxxxxxxxxx\n```\n\nThe recommended approach is to use a config file with limited read\npermissions instead of environment variables, but bear with me here.\n\nOnce installed in your project via pip, use as follows:\n\n```python\nfrom os import environ\nfrom pprint import pprint\n\nfrom evalkit_api_client.v1_client import EvalKitAPIv1\n\nurl = environ.get('EVALKIT_API_URL')\ntoken = environ.get('EVALKIT_API_TOKEN')\n\napi = EvalKitAPIv1(url, token)\nprojects = api.get_projects()\n\nprint(projects.json())\n```\n\n#### EvalKitAPIv1\n\nThis library is meant to be imported into your code. The `EvalKitAPIv1` client\nobject requires a `api_url` argument and a `api_token` argument. The `api_url`\nshould likely be defined in a configuration file, and should be the full API\nURL without the endpoint, e.g. `https://sub.evaluationkit.com/api/v1/`. The `api_token`\nshould similarly be defined in a config file, and is the token generated for\na given subaccount in EvaluationKit.\n\nRefer to the client interface [documentation](#documentation) for more information.\n\nContributing\n------------\n\n#### Building Wheels\n\nBuilding the wheel:\n\n    python setup.py bdist_wheel\n\n#### Installing Wheels\n\nHow to install the client for testing:\n\n    pip uninstall evalkit_api_client || echo \"Already uninstalled.\"\n    pip install --no-index --find-links=dist evalkit_api_client\n\nAlternatively, install by specifying the full or relative path to the `.whl` file:\n\n    pip install --no-index /path/to/canvas-lms-tools/evalkit_api_client/dist/evalkit_api_client-<version>-py2.py3-none-any.whl\n\n(You may need to `pip install wheel` first if you are installing from another\nproject. Consult [stack overflow](https://stackoverflow.com/questions/28002897/wheel-file-installation)\nfor more help.)\n\n#### Sphinx Docs\n\nCreating the docs:\n\n    cd docs\n    pip install -r requirements.txt\n    pip install evalkit_api_client\n    make html\n    open build/html/index.html\n\nDeploying the docs to GitHub pages:\n\n    git checkout master\n    git pull\n    git branch -D gh-pages\n    git checkout -b gh-pages\n    rm -rf ./*\n    touch .nojekyll\n    git checkout master evalkit_api_client/docs/\n    < build the docs as above >\n    mv evalkit_api_client/docs/build/html/* ./\n    rm -rf evalkit_api_client\n    git add -A\n    git commit\n    git push -f origin gh-pages\n\nFor more info see the [GitHub Pages documentation](https://pages.github.com/),\nthe [Sphinx docs](http://www.sphinx-doc.org/en/master/contents.html),\nor the following [script docs](http://www.willmcginnis.com/2016/02/29/automating-documentation-workflow-with-sphinx-and-github-pages/).\n\nReferences\n----------\n\nThis project was originally created with the following \"cookiecutter\" tool:\nhttps://github.com/wdm0006/cookiecutter-pipproject\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "https://github.com/lcary/canvas-lms-tools/archive/0.0.1a1", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/lcary/canvas-lms-tools", "keywords": "", "license": "Apache", "maintainer": "", "maintainer_email": "", "name": "evalkit-api-client", "package_url": "https://pypi.org/project/evalkit-api-client/", "platform": "", "project_url": "https://pypi.org/project/evalkit-api-client/", "project_urls": {"Download": "https://github.com/lcary/canvas-lms-tools/archive/0.0.1a1", "Homepage": "https://github.com/lcary/canvas-lms-tools"}, "release_url": "https://pypi.org/project/evalkit-api-client/0.0.1a1/", "requires_dist": ["requests (==2.19.1)"], "requires_python": "", "summary": "This is a library for making requests to a EvaluationKIT API.", "version": "0.0.1a1", "yanked": false, "html_description": "<div class=\"project-description\">\n            Evalkit API Client Library<br>==========================<br><br>[Overview](#overview)<br>[Testing](#testing)<br>[Documentation](#documentation)<br>[Installation](#installation)<br>[Usage](#usage)<br>[Contributing](#contributing)<br>[References](#references)<br><br>Overview<br>--------<br><br>This is a library for making requests to an EvaluationKit API.<br><br>Testing<br>-------<br><br>This project is tested with [tox](https://tox.readthedocs.io/en/latest/).<br><br>Run the tox command to run checks and unit tests:<br>```<br>$ tox<br>```<br><br>By default, this project's tox runs:<br><br> * [flake8](http://flake8.pycqa.org/en/latest/)<br> * [mypy](https://github.com/python/mypy)<br> * [pytest](https://docs.pytest.org/en/latest/)<br><br>To create test coverage reports:<br>```<br>$ tox -e cov<br>```<br><br>Deployment<br>----------<br><br>Deployment to pypi is done with tox:<br>```<br>$ tox -e deploy<br>```<br>Make sure to bump the version in setup.py before deploying.<br><br>Documentation<br>-------------<br><br>This project has Sphinx documentation at the following url:<br>https://lcary.github.io/canvas-lms-tools/<br><br>The EvaluationKit API documentation is also very useful:<br><br><br>Installation<br>------------<br><br>To install, use pip:<br><br>    pip install evalkit_api_client<br><br>Or clone the repo:<br><br>    git clone https://github.com/lcary/canvas-lms-tools.git<br>    cd canvas-lms-tools/evalkit_api_client<br>    python setup.py install<br><br>Usage<br>-----<br><br>Adding the client as a dependency in your project's `requirements.txt`<br>file is the intended way to use the client.<br><br>#### REPL Example<br><br>```<br>$ python<br>&gt;&gt;&gt; from evalkit_api_client.v1_client import EvalKitAPIv1<br>&gt;&gt;&gt; url = 'https://sub-account.evaluationkit.com/api/v1'<br>&gt;&gt;&gt; token = 'xxxxxxxxxxxxxxxxxxxTHISxISxNOTxAxREALxTOKENxxxxxxxxxxxxxxxxxxxxx'<br>&gt;&gt;&gt; api = EvalKitAPIv1(url, token)<br>&gt;&gt;&gt; projects = api.get_projects().json()<br>&gt;&gt;&gt; len(projects.json())  # number of projects in sub-account<br>&gt;&gt;&gt; for p in projects.['resultList']:<br>...     print(p['id'], p['title'])<br>...<br>49400 Test Evaluation A<br>57600 Test Eval B<br>```<br><br>#### Script Example<br><br>This very simple example requires a few environment variables. The<br>API URL and token should be something like:<br>```<br>EVALKIT_API_URL=https://sub-account.evaluationkit.com/api/v1<br>EVALKIT_API_TOKEN=xxxxxxxxxxxxxxxxxxxTHISxISxNOTxAxREALxTOKENxxxxxxxxxxxxxxxxxxxxx<br>```<br><br>The recommended approach is to use a config file with limited read<br>permissions instead of environment variables, but bear with me here.<br><br>Once installed in your project via pip, use as follows:<br><br>```python<br>from os import environ<br>from pprint import pprint<br><br>from evalkit_api_client.v1_client import EvalKitAPIv1<br><br>url = environ.get('EVALKIT_API_URL')<br>token = environ.get('EVALKIT_API_TOKEN')<br><br>api = EvalKitAPIv1(url, token)<br>projects = api.get_projects()<br><br>print(projects.json())<br>```<br><br>#### EvalKitAPIv1<br><br>This library is meant to be imported into your code. The `EvalKitAPIv1` client<br>object requires a `api_url` argument and a `api_token` argument. The `api_url`<br>should likely be defined in a configuration file, and should be the full API<br>URL without the endpoint, e.g. `https://sub.evaluationkit.com/api/v1/`. The `api_token`<br>should similarly be defined in a config file, and is the token generated for<br>a given subaccount in EvaluationKit.<br><br>Refer to the client interface [documentation](#documentation) for more information.<br><br>Contributing<br>------------<br><br>#### Building Wheels<br><br>Building the wheel:<br><br>    python setup.py bdist_wheel<br><br>#### Installing Wheels<br><br>How to install the client for testing:<br><br>    pip uninstall evalkit_api_client || echo \"Already uninstalled.\"<br>    pip install --no-index --find-links=dist evalkit_api_client<br><br>Alternatively, install by specifying the full or relative path to the `.whl` file:<br><br>    pip install --no-index /path/to/canvas-lms-tools/evalkit_api_client/dist/evalkit_api_client-&lt;version&gt;-py2.py3-none-any.whl<br><br>(You may need to `pip install wheel` first if you are installing from another<br>project. Consult [stack overflow](https://stackoverflow.com/questions/28002897/wheel-file-installation)<br>for more help.)<br><br>#### Sphinx Docs<br><br>Creating the docs:<br><br>    cd docs<br>    pip install -r requirements.txt<br>    pip install evalkit_api_client<br>    make html<br>    open build/html/index.html<br><br>Deploying the docs to GitHub pages:<br><br>    git checkout master<br>    git pull<br>    git branch -D gh-pages<br>    git checkout -b gh-pages<br>    rm -rf ./*<br>    touch .nojekyll<br>    git checkout master evalkit_api_client/docs/<br>    &lt; build the docs as above &gt;<br>    mv evalkit_api_client/docs/build/html/* ./<br>    rm -rf evalkit_api_client<br>    git add -A<br>    git commit<br>    git push -f origin gh-pages<br><br>For more info see the [GitHub Pages documentation](https://pages.github.com/),<br>the [Sphinx docs](http://www.sphinx-doc.org/en/master/contents.html),<br>or the following [script docs](http://www.willmcginnis.com/2016/02/29/automating-documentation-workflow-with-sphinx-and-github-pages/).<br><br>References<br>----------<br><br>This project was originally created with the following \"cookiecutter\" tool:<br>https://github.com/wdm0006/cookiecutter-pipproject<br><br><br>\n          </div>"}, "last_serial": 4074631, "releases": {"0.0.1a0": [{"comment_text": "", "digests": {"md5": "41ecc18efb37e7901461cd48f6650d1e", "sha256": "68918d02a6470f020af234af68bdebe3741a823d1075d21a706a6dd756e9a4b6"}, "downloads": -1, "filename": "evalkit_api_client-0.0.1a0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "41ecc18efb37e7901461cd48f6650d1e", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 6570, "upload_time": "2018-06-26T18:18:02", "upload_time_iso_8601": "2018-06-26T18:18:02.552593Z", "url": "https://files.pythonhosted.org/packages/e0/72/b02108f6b28c40043d6ddc157288d8d81e63af448e097af6da787bcb5c52/evalkit_api_client-0.0.1a0-py2.py3-none-any.whl", "yanked": false}], "0.0.1a1": [{"comment_text": "", "digests": {"md5": "7902a5e5497beef42dbb95bc69bab442", "sha256": "08084919425a6cc364092de3206d5c6bf53aab0c272734180bcb8f2e20a20e61"}, "downloads": -1, "filename": "evalkit_api_client-0.0.1a1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "7902a5e5497beef42dbb95bc69bab442", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 6549, "upload_time": "2018-07-17T17:19:16", "upload_time_iso_8601": "2018-07-17T17:19:16.220015Z", "url": "https://files.pythonhosted.org/packages/db/fa/e08f6b5b41534172b882b766125f7e60a0e4852f67d3671af48dda0e24c0/evalkit_api_client-0.0.1a1-py2.py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "7902a5e5497beef42dbb95bc69bab442", "sha256": "08084919425a6cc364092de3206d5c6bf53aab0c272734180bcb8f2e20a20e61"}, "downloads": -1, "filename": "evalkit_api_client-0.0.1a1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "7902a5e5497beef42dbb95bc69bab442", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 6549, "upload_time": "2018-07-17T17:19:16", "upload_time_iso_8601": "2018-07-17T17:19:16.220015Z", "url": "https://files.pythonhosted.org/packages/db/fa/e08f6b5b41534172b882b766125f7e60a0e4852f67d3671af48dda0e24c0/evalkit_api_client-0.0.1a1-py2.py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 00:45:17 2020"}