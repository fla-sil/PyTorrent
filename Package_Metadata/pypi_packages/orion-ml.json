{"info": {"author": "MIT Data To AI Lab", "author_email": "dailabmit@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "<p align=\"left\">\n<img width=15% src=\"https://dai.lids.mit.edu/wp-content/uploads/2018/06/Logo_DAI_highres.png\" alt=\u201cDAI-Lab\u201d />\n<i>An open source project from Data to AI Lab at MIT.</i>\n</p>\n\n<p align=\"left\">\n<img width=20% src=\"https://dai.lids.mit.edu/wp-content/uploads/2018/08/orion.png\" alt=\u201cOrion\u201d />\n</p>\n\n[![Development Status](https://img.shields.io/badge/Development%20Status-2%20--%20Pre--Alpha-yellow)](https://pypi.org/search/?c=Development+Status+%3A%3A+2+-+Pre-Alpha)\n[![CircleCI](https://circleci.com/gh/D3-AI/Orion.svg?style=shield)](https://circleci.com/gh/D3-AI/Orion)\n[![Travis CI Shield](https://travis-ci.org/D3-AI/Orion.svg?branch=master)](https://travis-ci.org/D3-AI/Orion)\n\n# Orion\n\nOrion is a machine learning library built for telemetry data generated by satellites.\n\n* License: [MIT](https://github.com/D3-AI/Orion/blob/master/LICENSE)\n* Development Status: [Pre-Alpha](https://pypi.org/search/?c=Development+Status+%3A%3A+2+-+Pre-Alpha)\n* Homepage: https://github.com/D3-AI/Orion\n\n# Overview\n\nOrion is a machine learning library built for telemetry data generated by Satellites.\n\nWith this data, our interest is to develop techniques to:\n\n* identify rare patterns and flag them for expert review.\n* predict outcomes ahead of time.\n\nThe library makes use of a number of *automated machine learning* tools developed under\n[\"The human data interaction project\"](https://github.com/HDI-Project) within the\n[Data to AI Lab at MIT](https://dai.lids.mit.edu/).\n\nWith the ready availability of *automated machine learning* tools, the focus is on:\n\n* domain expert interaction with the machine learning system;\n* learning from minimal labels;\n* explainability of model outputs;\n* model audit;\n* scalability;\n\n## Table of Contents\n\n* [I. Data Format](#data-format)\n   * [I.1 Input](#input)\n   * [I.2 Output](#output)\n   * [I.2 Dataset we use in this library](#dataset-we-use-in-this-library)\n* [II. Orion Pipelines](#orion-pipelines)\n   * [II.1 Current Available Pipelines](#current-available-pipelines)\n   * [II.2 Leaderboard](#leaderboard)\n* [III. Getting Started](#getting-started)\n   * [III.1 Requirements](#requirements)\n   * [III.2 Install](#install)\n* [IV. Quickstart](#quickstart)\n* [V. Database](#database)\n\n# Data Format\n\n## Input\n\n**Orion Pipelines** work on time Series that are provided as a single table of telemetry\nobservations with two columns:\n\n* `timestamp`: an INTEGER or FLOAT column with the time of the observation in\n  [Unix Time Format](https://en.wikipedia.org/wiki/Unix_time)\n* `value`: an INTEGER or FLOAT column with the observed value at the indicated timestamp\n\nThis is an example of such table:\n\n|  timestamp |     value |\n|------------|-----------|\n| 1222819200 | -0.366358 |\n| 1222840800 | -0.394107 |\n| 1222862400 |  0.403624 |\n| 1222884000 | -0.362759 |\n| 1222905600 | -0.370746 |\n\n## Output\n\nThe output of the **Orion Pipelines** is another table that contains the detected anomalous\nintervals and that has at least two columns:\n\n* `start`: timestamp where the anomalous interval starts\n* `end`: timestamp where the anomalous interval ends\n\nOptionally, a third column called `score` can be included with a value that represents the\nseverity of the detected anomaly.\n\nAn example of such a table is:\n\n|      start |        end |    score |\n|------------|------------|----------|\n| 1222970400 | 1222992000 | 0.572643 |\n| 1223013600 | 1223035200 | 0.572643 |\n\n## Dataset we use in this library\n\nFor development, evaluation of pipelines, we include a dataset which includes several satellite\ntelemetry signals already formatted as expected by the Orion Pipelines.\n\nThis formatted dataset can be browsed and downloaded directly from the\n[d3-ai-orion AWS S3 Bucket](https://d3-ai-orion.s3.amazonaws.com/index.html).\n\nThis dataset is adapted from the one used for the experiments in the\n[Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding paper](https://arxiv.org/abs/1802.04431).\n[Original source data is available for download here](https://s3-us-west-2.amazonaws.com/telemanom/data.zip).\nWe thank NASA for making this data available for public use.\n\n# Orion Pipelines\n\nThe main component in the Orion project are the **Orion Pipelines**, which consist of\n[MLBlocks Pipelines](https://hdi-project.github.io/MLBlocks/advanced_usage/pipelines.html)\nspecialized in detecting anomalies in time series.\n\nAs ``MLPipeline`` instances, **Orion Pipelines**:\n\n* consist of a list of one or more [MLPrimitives](https://hdi-project.github.io/MLPrimitives/)\n* can be *fitted* on some data and later on used to *predict* anomalies on more data\n* can be *scored* by comparing their predictions with some known anomalies\n* have *hyperparameters* that can be *tuned* to improve their anomaly detection performance\n* can be stored as a JSON file that includes all the primitives that compose them, as well as\n  other required configuration options.\n\n## Current Available Pipelines\n\nIn the **Orion Project**, the pipelines are included as **JSON** files, which can be found\ninside the [orion/pipelines](orion/pipelines) folder.\n\nThis is the list of pipelines available so far, which will grow over time:\n\n| name | location | description |\n|------|----------|-------------|\n| Dummy | [orion/pipelines/dummy.json](orion/pipelines/dummy.json) | Dummy Pipeline to showcase the input and output format and the usage of sample primitives |\n| LSTM Dynamic Threshold | [orion/pipelines/lstm_dynamic_threshold.json](orion/pipelines/lstm_dynamic_threshold.json) | LSTM Based pipeline inspired by the [Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding paper](https://arxiv.org/abs/1802.04431) |\n| Mean 24h LSTM | [orion/pipelines/mean_24h_lstm.json](orion/pipelines/mean_24h_lstm.json) | LSTM Based pipeline with 24h mean aggregation preprocessing |\n| Median 24h LSTM | [orion/pipelines/median_24h_lstm.json](orion/pipelines/median_24h_lstm.json) | LSTM Based pipeline with 24h median aggregation preprocessing |\n| Sum 24h LSTM | [orion/pipelines/sum_24h_lstm.json](orion/pipelines/sum_24h_lstm.json) | LSTM Based pipeline with 24h sum aggregation preprocessing |\n| Skew 24h LSTM | [orion/pipelines/skew_24h_lstm.json](orion/pipelines/skew_24h_lstm.json) | LSTM Based pipeline with 24h skew aggregation preprocessing |\n| CycleGAN | [orion/pipelines/cyclegan.json](orion/pipelines/cyclegan.json) | CycleGAN Based pipeline |\n| ARIMA | [orion/pipelines/arima.json](orion/pipelines/arima.json) | ARIMA Based pipeline |\n\n## Leaderboard\n\nIn this repository we maintain this up-to-date leaderboard with the current scoring of the\npipelines according to the benchmarking procedure explained in the [benchmark documentation](\nBENCHMARK.md).\n\n| pipeline                  |   accuracy |        f1 |   precision |     recall |\n|---------------------------|------------|-----------|-------------|------------|\n| CycleGAN                  |   0.781147 | 0.137234  |   0.147674  | 0.18173    |\n| LSTM Dynamic Thresholding |   0.832052 | 0.125999  |   0.178968  | 0.151298   |\n| Dummy                     |   0.818975 | 0.108436  |   0.13994   | 0.133865   |\n| Mean 24h LSTM             |   0.667412 | 0.0420656 |   0.0775713 | 0.0456106  |\n| Sum 24h LSTM              |   0.685844 | 0.0417817 |   0.066248  | 0.033882   |\n| ARIMA                     |   0.510343 | 0.038821  |   0.0604475 | 0.0377441  |\n| Median 24h LSTM           |   0.673667 | 0.0237867 |   0.0604165 | 0.0178578  |\n| Skew 24h LSTM             |   0.369548 | 0.01142   |   0.0213837 | 0.00902504 |\n\n# Getting Started\n\n## Requirements\n\n### Python\n\n**Orion** has been developed and runs on [Python 3.6](https://www.python.org/downloads/release/python-360/).\n\nAlso, although it is not strictly required, the usage of a [virtualenv](https://virtualenv.pypa.io/en/latest/)\nis highly recommended in order to avoid interfering with other software installed in the system\nwhere you are trying to run **Orion**.\n\n### MongoDB\n\nIn order to be fully operational, **Orion** requires having access to a\n[MongoDB](https://www.mongodb.com/) database running version **3.6** or higher.\n\n## Install\n\nThe easiest and recommended way to install **Orion** is using [pip](https://pip.pypa.io/en/stable/):\n\n```bash\npip install orion-ml\n```\n\nThis will pull and install the latest stable release from [PyPi](https://pypi.org/).\n\nIf you want to install from source or contribute to the project please read the\n[Contributing Guide](https://sdv-dev.github.io/Copulas/contributing.html#get-started).\n\n### Docker\n\nEven thought it's not mandatory to use it, **Orion** comes with the possibility to be\ndistributed and run as a docker image, making its usage in offline systems easier.\n\nFor more details please read the [Docker Usage Documentation](DOCKER.md).\n\n# Quickstart\n\nIn the following steps we will show a short guide about how to run one of the **Orion Pipelines**\non one of the signals from the **Demo Dataset**.\n\n## 1. Load the data\n\nIn the first step we will load the **S-1** signal from the **Demo Dataset**.\n\nWe will do so in two parts, train and test, as we will use the first part to fit the\npipeline and the second one to evaluate its performance.\n\nTo do so, we need to import the `orion.data.load_signal` function and call it twice passing\nthe `'S-1-train'` and `'S-1-test'` names.\n\n```python3\nfrom orion.data import load_signal\n\ntrain = load_signal('S-1-train')\ntest = load_signal('S-1-test')\n```\n\nThe output will be a table in the format described above:\n\n```\n    timestamp     value\n0  1222819200 -0.366359\n1  1222840800 -0.394108\n2  1222862400  0.403625\n3  1222884000 -0.362759\n4  1222905600 -0.370746\n```\n\n## 2. Detect anomalies using a pipeline\n\nOnce we have the data, let us try to use the LSTM pipeline to analyze it and search for anomalies.\n\nIn order to do so, we will have import the `orion.analysis.analyze` function and pass it\nthe train and test dataframes and the name of the pipeline that we want to use:\n\n```python3\nfrom orion.analysis import analyze\n\nanomalies = analyze(\n    pipeline='lstm_dynamic_threshold',\n    train=train,\n    test=test\n)\n```\n\n**NOTE:** Depending on your system and the exact versions that you might have installed\nsome *WARNINGS* may be printed. These can be safely ignored as they do not interfere\nwith the proper behavior of the pipeline.\n\nThe output of the previous command will be a ``pandas.DataFrame`` containing a table in the\nOutput format described above:\n\n```\n        start         end     score\n0  1394323200  1399701600  0.673494\n```\n\n## 3. Evaluate performance\n\nIn this next step we will load some already known anomalous intervals and evaluate how\ngood our anomaly detection was by comparing those with our detected intervals.\n\nFor this, we will first load the known anomalies for the signal that we are using:\n\n```python3\nfrom orion.data import load_anomalies\n\nknown_anomalies = load_anomalies('S-1')\n```\n\nThe output will be a table in the same format as the `anomalies` one.\n\n```\n        start         end\n0  1392768000  1402423200\n```\n\nAfterwards, we pass the ground truth, the detected anomalies and the original test data\nto the `orion.metrics.accuracy_score` and `orion.metrics.f1_score` functions in order\nto compute a score that indicates how good our anomaly detection was:\n\n```python3\nfrom orion.metrics import accuracy_score, f1_score\n\naccuracy_score(known_anomalies, anomalies, test)  # -> 0.972987721691678\n\nf1_score(known_anomalies, anomalies, test)  # -> 0.7155172413793103\n```\n\n# Database\n\n**Orion** comes ready to use a MongoDB Database to easily register and explore:\n\n* Multiple Datasets based on signals from one or more satellites.\n* Multiple Pipelines, including historical Pipeline versions.\n* Pipeline executions on the registered Datasets, including any environment details required to\n  later on reproduce the results.\n* Pipeline execution results and detected events.\n* Comments about the detected events.\n\nThis, among other things, allows:\n\n* Providing visibility about the system usage.\n* Keeping track of the evolution of the registered pipelines and their performance over multiple datasets.\n* Visualizing and browsing the detected events by the pipelines using a web application.\n* Collecting comments from multiple domain experts about the detected events to be able to later\n  on curate the pipelines based on their knowledge.\n* Reproducing previous executions in identical environments to replicate the obtained results.\n* Detecting and keeping a history of system failures for later investigation.\n\nThe complete **Database schema and usage instructions** can be found in the\n[database documentation](DATABASE.md)\n\n\nHistory\n=======\n\n## 0.1.0 - 2020-04-23\n\nFirst Orion release to PyPI: https://pypi.org/project/orion-ml/\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/D3-AI/Orion", "keywords": "orion", "license": "MIT license", "maintainer": "", "maintainer_email": "", "name": "orion-ml", "package_url": "https://pypi.org/project/orion-ml/", "platform": "", "project_url": "https://pypi.org/project/orion-ml/", "project_urls": {"Homepage": "https://github.com/D3-AI/Orion"}, "release_url": "https://pypi.org/project/orion-ml/0.1.0/", "requires_dist": ["baytune (<0.3,>=0.2.3)", "mlblocks (<0.4,>=0.3.0)", "mlprimitives (<0.3,>=0.2.2)", "mongoengine (<0.17,>=0.16.3)", "numpy (<1.17,>=1.15.4)", "pandas (<0.25,>=0.23.4)", "pymongo (<4,>=3.7.2)", "scikit-learn (<0.21,>=0.20.1)", "tabulate (<0.9,>=0.8.3)", "pip (>=9.0.1) ; extra == 'dev'", "bumpversion (<0.6,>=0.5.3) ; extra == 'dev'", "watchdog (<0.11,>=0.8.3) ; extra == 'dev'", "m2r (<0.3,>=0.2.0) ; extra == 'dev'", "nbsphinx (<0.7,>=0.5.0) ; extra == 'dev'", "Sphinx (<3,>=1.7.1) ; extra == 'dev'", "sphinx-rtd-theme (<0.5,>=0.2.4) ; extra == 'dev'", "autodocsumm (<1,>=0.1.10) ; extra == 'dev'", "flake8 (<4,>=3.7.7) ; extra == 'dev'", "isort (<5,>=4.3.4) ; extra == 'dev'", "autoflake (<2,>=1.2) ; extra == 'dev'", "autopep8 (<2,>=1.4.3) ; extra == 'dev'", "twine (<4,>=1.10.0) ; extra == 'dev'", "wheel (>=0.30.0) ; extra == 'dev'", "coverage (<6,>=4.5.1) ; extra == 'dev'", "tox (<4,>=2.9.1) ; extra == 'dev'", "doc8 (<0.9,==0.8.0) ; extra == 'dev'", "pydocstyle (<4,==3.0.0) ; extra == 'dev'", "pytest (>=3.4.2) ; extra == 'dev'", "pytest-cov (>=2.6.0) ; extra == 'dev'", "pytest (>=3.4.2) ; extra == 'test'", "pytest-cov (>=2.6.0) ; extra == 'test'"], "requires_python": ">=3.6", "summary": "Orion is a machine learning library built for data generated by satellites.", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p align=\"left\">\n<img alt=\"\u201cDAI-Lab\u201d\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/80df0970db0e9e95cce463bc9fa595caf90dd1c7/68747470733a2f2f6461692e6c6964732e6d69742e6564752f77702d636f6e74656e742f75706c6f6164732f323031382f30362f4c6f676f5f4441495f686967687265732e706e67\" width=\"15%\">\n<i>An open source project from Data to AI Lab at MIT.</i>\n</p>\n<p align=\"left\">\n<img alt=\"\u201cOrion\u201d\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/39b9c92e22534b6569ba216d9e7103884c33c9e3/68747470733a2f2f6461692e6c6964732e6d69742e6564752f77702d636f6e74656e742f75706c6f6164732f323031382f30382f6f72696f6e2e706e67\" width=\"20%\">\n</p>\n<p><a href=\"https://pypi.org/search/?c=Development+Status+%3A%3A+2+-+Pre-Alpha\" rel=\"nofollow\"><img alt=\"Development Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/127dddfac365abf943ba0c998fa192a73323a022/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446576656c6f706d656e742532305374617475732d322532302d2d2532305072652d2d416c7068612d79656c6c6f77\"></a>\n<a href=\"https://circleci.com/gh/D3-AI/Orion\" rel=\"nofollow\"><img alt=\"CircleCI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/43301b205a4656ac9f923814e0701c4725d285fc/68747470733a2f2f636972636c6563692e636f6d2f67682f44332d41492f4f72696f6e2e7376673f7374796c653d736869656c64\"></a>\n<a href=\"https://travis-ci.org/D3-AI/Orion\" rel=\"nofollow\"><img alt=\"Travis CI Shield\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f6d4894dbf343675e3eb02ef16ef33598ccfa48a/68747470733a2f2f7472617669732d63692e6f72672f44332d41492f4f72696f6e2e7376673f6272616e63683d6d6173746572\"></a></p>\n<h1>Orion</h1>\n<p>Orion is a machine learning library built for telemetry data generated by satellites.</p>\n<ul>\n<li>License: <a href=\"https://github.com/D3-AI/Orion/blob/master/LICENSE\" rel=\"nofollow\">MIT</a></li>\n<li>Development Status: <a href=\"https://pypi.org/search/?c=Development+Status+%3A%3A+2+-+Pre-Alpha\" rel=\"nofollow\">Pre-Alpha</a></li>\n<li>Homepage: <a href=\"https://github.com/D3-AI/Orion\" rel=\"nofollow\">https://github.com/D3-AI/Orion</a></li>\n</ul>\n<h1>Overview</h1>\n<p>Orion is a machine learning library built for telemetry data generated by Satellites.</p>\n<p>With this data, our interest is to develop techniques to:</p>\n<ul>\n<li>identify rare patterns and flag them for expert review.</li>\n<li>predict outcomes ahead of time.</li>\n</ul>\n<p>The library makes use of a number of <em>automated machine learning</em> tools developed under\n<a href=\"https://github.com/HDI-Project\" rel=\"nofollow\">\"The human data interaction project\"</a> within the\n<a href=\"https://dai.lids.mit.edu/\" rel=\"nofollow\">Data to AI Lab at MIT</a>.</p>\n<p>With the ready availability of <em>automated machine learning</em> tools, the focus is on:</p>\n<ul>\n<li>domain expert interaction with the machine learning system;</li>\n<li>learning from minimal labels;</li>\n<li>explainability of model outputs;</li>\n<li>model audit;</li>\n<li>scalability;</li>\n</ul>\n<h2>Table of Contents</h2>\n<ul>\n<li><a href=\"#data-format\" rel=\"nofollow\">I. Data Format</a>\n<ul>\n<li><a href=\"#input\" rel=\"nofollow\">I.1 Input</a></li>\n<li><a href=\"#output\" rel=\"nofollow\">I.2 Output</a></li>\n<li><a href=\"#dataset-we-use-in-this-library\" rel=\"nofollow\">I.2 Dataset we use in this library</a></li>\n</ul>\n</li>\n<li><a href=\"#orion-pipelines\" rel=\"nofollow\">II. Orion Pipelines</a>\n<ul>\n<li><a href=\"#current-available-pipelines\" rel=\"nofollow\">II.1 Current Available Pipelines</a></li>\n<li><a href=\"#leaderboard\" rel=\"nofollow\">II.2 Leaderboard</a></li>\n</ul>\n</li>\n<li><a href=\"#getting-started\" rel=\"nofollow\">III. Getting Started</a>\n<ul>\n<li><a href=\"#requirements\" rel=\"nofollow\">III.1 Requirements</a></li>\n<li><a href=\"#install\" rel=\"nofollow\">III.2 Install</a></li>\n</ul>\n</li>\n<li><a href=\"#quickstart\" rel=\"nofollow\">IV. Quickstart</a></li>\n<li><a href=\"#database\" rel=\"nofollow\">V. Database</a></li>\n</ul>\n<h1>Data Format</h1>\n<h2>Input</h2>\n<p><strong>Orion Pipelines</strong> work on time Series that are provided as a single table of telemetry\nobservations with two columns:</p>\n<ul>\n<li><code>timestamp</code>: an INTEGER or FLOAT column with the time of the observation in\n<a href=\"https://en.wikipedia.org/wiki/Unix_time\" rel=\"nofollow\">Unix Time Format</a></li>\n<li><code>value</code>: an INTEGER or FLOAT column with the observed value at the indicated timestamp</li>\n</ul>\n<p>This is an example of such table:</p>\n<table>\n<thead>\n<tr>\n<th>timestamp</th>\n<th>value</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1222819200</td>\n<td>-0.366358</td>\n</tr>\n<tr>\n<td>1222840800</td>\n<td>-0.394107</td>\n</tr>\n<tr>\n<td>1222862400</td>\n<td>0.403624</td>\n</tr>\n<tr>\n<td>1222884000</td>\n<td>-0.362759</td>\n</tr>\n<tr>\n<td>1222905600</td>\n<td>-0.370746</td>\n</tr></tbody></table>\n<h2>Output</h2>\n<p>The output of the <strong>Orion Pipelines</strong> is another table that contains the detected anomalous\nintervals and that has at least two columns:</p>\n<ul>\n<li><code>start</code>: timestamp where the anomalous interval starts</li>\n<li><code>end</code>: timestamp where the anomalous interval ends</li>\n</ul>\n<p>Optionally, a third column called <code>score</code> can be included with a value that represents the\nseverity of the detected anomaly.</p>\n<p>An example of such a table is:</p>\n<table>\n<thead>\n<tr>\n<th>start</th>\n<th>end</th>\n<th>score</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1222970400</td>\n<td>1222992000</td>\n<td>0.572643</td>\n</tr>\n<tr>\n<td>1223013600</td>\n<td>1223035200</td>\n<td>0.572643</td>\n</tr></tbody></table>\n<h2>Dataset we use in this library</h2>\n<p>For development, evaluation of pipelines, we include a dataset which includes several satellite\ntelemetry signals already formatted as expected by the Orion Pipelines.</p>\n<p>This formatted dataset can be browsed and downloaded directly from the\n<a href=\"https://d3-ai-orion.s3.amazonaws.com/index.html\" rel=\"nofollow\">d3-ai-orion AWS S3 Bucket</a>.</p>\n<p>This dataset is adapted from the one used for the experiments in the\n<a href=\"https://arxiv.org/abs/1802.04431\" rel=\"nofollow\">Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding paper</a>.\n<a href=\"https://s3-us-west-2.amazonaws.com/telemanom/data.zip\" rel=\"nofollow\">Original source data is available for download here</a>.\nWe thank NASA for making this data available for public use.</p>\n<h1>Orion Pipelines</h1>\n<p>The main component in the Orion project are the <strong>Orion Pipelines</strong>, which consist of\n<a href=\"https://hdi-project.github.io/MLBlocks/advanced_usage/pipelines.html\" rel=\"nofollow\">MLBlocks Pipelines</a>\nspecialized in detecting anomalies in time series.</p>\n<p>As <code>MLPipeline</code> instances, <strong>Orion Pipelines</strong>:</p>\n<ul>\n<li>consist of a list of one or more <a href=\"https://hdi-project.github.io/MLPrimitives/\" rel=\"nofollow\">MLPrimitives</a></li>\n<li>can be <em>fitted</em> on some data and later on used to <em>predict</em> anomalies on more data</li>\n<li>can be <em>scored</em> by comparing their predictions with some known anomalies</li>\n<li>have <em>hyperparameters</em> that can be <em>tuned</em> to improve their anomaly detection performance</li>\n<li>can be stored as a JSON file that includes all the primitives that compose them, as well as\nother required configuration options.</li>\n</ul>\n<h2>Current Available Pipelines</h2>\n<p>In the <strong>Orion Project</strong>, the pipelines are included as <strong>JSON</strong> files, which can be found\ninside the <a href=\"orion/pipelines\" rel=\"nofollow\">orion/pipelines</a> folder.</p>\n<p>This is the list of pipelines available so far, which will grow over time:</p>\n<table>\n<thead>\n<tr>\n<th>name</th>\n<th>location</th>\n<th>description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Dummy</td>\n<td><a href=\"orion/pipelines/dummy.json\" rel=\"nofollow\">orion/pipelines/dummy.json</a></td>\n<td>Dummy Pipeline to showcase the input and output format and the usage of sample primitives</td>\n</tr>\n<tr>\n<td>LSTM Dynamic Threshold</td>\n<td><a href=\"orion/pipelines/lstm_dynamic_threshold.json\" rel=\"nofollow\">orion/pipelines/lstm_dynamic_threshold.json</a></td>\n<td>LSTM Based pipeline inspired by the <a href=\"https://arxiv.org/abs/1802.04431\" rel=\"nofollow\">Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding paper</a></td>\n</tr>\n<tr>\n<td>Mean 24h LSTM</td>\n<td><a href=\"orion/pipelines/mean_24h_lstm.json\" rel=\"nofollow\">orion/pipelines/mean_24h_lstm.json</a></td>\n<td>LSTM Based pipeline with 24h mean aggregation preprocessing</td>\n</tr>\n<tr>\n<td>Median 24h LSTM</td>\n<td><a href=\"orion/pipelines/median_24h_lstm.json\" rel=\"nofollow\">orion/pipelines/median_24h_lstm.json</a></td>\n<td>LSTM Based pipeline with 24h median aggregation preprocessing</td>\n</tr>\n<tr>\n<td>Sum 24h LSTM</td>\n<td><a href=\"orion/pipelines/sum_24h_lstm.json\" rel=\"nofollow\">orion/pipelines/sum_24h_lstm.json</a></td>\n<td>LSTM Based pipeline with 24h sum aggregation preprocessing</td>\n</tr>\n<tr>\n<td>Skew 24h LSTM</td>\n<td><a href=\"orion/pipelines/skew_24h_lstm.json\" rel=\"nofollow\">orion/pipelines/skew_24h_lstm.json</a></td>\n<td>LSTM Based pipeline with 24h skew aggregation preprocessing</td>\n</tr>\n<tr>\n<td>CycleGAN</td>\n<td><a href=\"orion/pipelines/cyclegan.json\" rel=\"nofollow\">orion/pipelines/cyclegan.json</a></td>\n<td>CycleGAN Based pipeline</td>\n</tr>\n<tr>\n<td>ARIMA</td>\n<td><a href=\"orion/pipelines/arima.json\" rel=\"nofollow\">orion/pipelines/arima.json</a></td>\n<td>ARIMA Based pipeline</td>\n</tr></tbody></table>\n<h2>Leaderboard</h2>\n<p>In this repository we maintain this up-to-date leaderboard with the current scoring of the\npipelines according to the benchmarking procedure explained in the <a href=\"BENCHMARK.md\" rel=\"nofollow\">benchmark documentation</a>.</p>\n<table>\n<thead>\n<tr>\n<th>pipeline</th>\n<th>accuracy</th>\n<th>f1</th>\n<th>precision</th>\n<th>recall</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CycleGAN</td>\n<td>0.781147</td>\n<td>0.137234</td>\n<td>0.147674</td>\n<td>0.18173</td>\n</tr>\n<tr>\n<td>LSTM Dynamic Thresholding</td>\n<td>0.832052</td>\n<td>0.125999</td>\n<td>0.178968</td>\n<td>0.151298</td>\n</tr>\n<tr>\n<td>Dummy</td>\n<td>0.818975</td>\n<td>0.108436</td>\n<td>0.13994</td>\n<td>0.133865</td>\n</tr>\n<tr>\n<td>Mean 24h LSTM</td>\n<td>0.667412</td>\n<td>0.0420656</td>\n<td>0.0775713</td>\n<td>0.0456106</td>\n</tr>\n<tr>\n<td>Sum 24h LSTM</td>\n<td>0.685844</td>\n<td>0.0417817</td>\n<td>0.066248</td>\n<td>0.033882</td>\n</tr>\n<tr>\n<td>ARIMA</td>\n<td>0.510343</td>\n<td>0.038821</td>\n<td>0.0604475</td>\n<td>0.0377441</td>\n</tr>\n<tr>\n<td>Median 24h LSTM</td>\n<td>0.673667</td>\n<td>0.0237867</td>\n<td>0.0604165</td>\n<td>0.0178578</td>\n</tr>\n<tr>\n<td>Skew 24h LSTM</td>\n<td>0.369548</td>\n<td>0.01142</td>\n<td>0.0213837</td>\n<td>0.00902504</td>\n</tr></tbody></table>\n<h1>Getting Started</h1>\n<h2>Requirements</h2>\n<h3>Python</h3>\n<p><strong>Orion</strong> has been developed and runs on <a href=\"https://www.python.org/downloads/release/python-360/\" rel=\"nofollow\">Python 3.6</a>.</p>\n<p>Also, although it is not strictly required, the usage of a <a href=\"https://virtualenv.pypa.io/en/latest/\" rel=\"nofollow\">virtualenv</a>\nis highly recommended in order to avoid interfering with other software installed in the system\nwhere you are trying to run <strong>Orion</strong>.</p>\n<h3>MongoDB</h3>\n<p>In order to be fully operational, <strong>Orion</strong> requires having access to a\n<a href=\"https://www.mongodb.com/\" rel=\"nofollow\">MongoDB</a> database running version <strong>3.6</strong> or higher.</p>\n<h2>Install</h2>\n<p>The easiest and recommended way to install <strong>Orion</strong> is using <a href=\"https://pip.pypa.io/en/stable/\" rel=\"nofollow\">pip</a>:</p>\n<pre>pip install orion-ml\n</pre>\n<p>This will pull and install the latest stable release from <a href=\"https://pypi.org/\" rel=\"nofollow\">PyPi</a>.</p>\n<p>If you want to install from source or contribute to the project please read the\n<a href=\"https://sdv-dev.github.io/Copulas/contributing.html#get-started\" rel=\"nofollow\">Contributing Guide</a>.</p>\n<h3>Docker</h3>\n<p>Even thought it's not mandatory to use it, <strong>Orion</strong> comes with the possibility to be\ndistributed and run as a docker image, making its usage in offline systems easier.</p>\n<p>For more details please read the <a href=\"DOCKER.md\" rel=\"nofollow\">Docker Usage Documentation</a>.</p>\n<h1>Quickstart</h1>\n<p>In the following steps we will show a short guide about how to run one of the <strong>Orion Pipelines</strong>\non one of the signals from the <strong>Demo Dataset</strong>.</p>\n<h2>1. Load the data</h2>\n<p>In the first step we will load the <strong>S-1</strong> signal from the <strong>Demo Dataset</strong>.</p>\n<p>We will do so in two parts, train and test, as we will use the first part to fit the\npipeline and the second one to evaluate its performance.</p>\n<p>To do so, we need to import the <code>orion.data.load_signal</code> function and call it twice passing\nthe <code>'S-1-train'</code> and <code>'S-1-test'</code> names.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">orion.data</span> <span class=\"kn\">import</span> <span class=\"n\">load_signal</span>\n\n<span class=\"n\">train</span> <span class=\"o\">=</span> <span class=\"n\">load_signal</span><span class=\"p\">(</span><span class=\"s1\">'S-1-train'</span><span class=\"p\">)</span>\n<span class=\"n\">test</span> <span class=\"o\">=</span> <span class=\"n\">load_signal</span><span class=\"p\">(</span><span class=\"s1\">'S-1-test'</span><span class=\"p\">)</span>\n</pre>\n<p>The output will be a table in the format described above:</p>\n<pre><code>    timestamp     value\n0  1222819200 -0.366359\n1  1222840800 -0.394108\n2  1222862400  0.403625\n3  1222884000 -0.362759\n4  1222905600 -0.370746\n</code></pre>\n<h2>2. Detect anomalies using a pipeline</h2>\n<p>Once we have the data, let us try to use the LSTM pipeline to analyze it and search for anomalies.</p>\n<p>In order to do so, we will have import the <code>orion.analysis.analyze</code> function and pass it\nthe train and test dataframes and the name of the pipeline that we want to use:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">orion.analysis</span> <span class=\"kn\">import</span> <span class=\"n\">analyze</span>\n\n<span class=\"n\">anomalies</span> <span class=\"o\">=</span> <span class=\"n\">analyze</span><span class=\"p\">(</span>\n    <span class=\"n\">pipeline</span><span class=\"o\">=</span><span class=\"s1\">'lstm_dynamic_threshold'</span><span class=\"p\">,</span>\n    <span class=\"n\">train</span><span class=\"o\">=</span><span class=\"n\">train</span><span class=\"p\">,</span>\n    <span class=\"n\">test</span><span class=\"o\">=</span><span class=\"n\">test</span>\n<span class=\"p\">)</span>\n</pre>\n<p><strong>NOTE:</strong> Depending on your system and the exact versions that you might have installed\nsome <em>WARNINGS</em> may be printed. These can be safely ignored as they do not interfere\nwith the proper behavior of the pipeline.</p>\n<p>The output of the previous command will be a <code>pandas.DataFrame</code> containing a table in the\nOutput format described above:</p>\n<pre><code>        start         end     score\n0  1394323200  1399701600  0.673494\n</code></pre>\n<h2>3. Evaluate performance</h2>\n<p>In this next step we will load some already known anomalous intervals and evaluate how\ngood our anomaly detection was by comparing those with our detected intervals.</p>\n<p>For this, we will first load the known anomalies for the signal that we are using:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">orion.data</span> <span class=\"kn\">import</span> <span class=\"n\">load_anomalies</span>\n\n<span class=\"n\">known_anomalies</span> <span class=\"o\">=</span> <span class=\"n\">load_anomalies</span><span class=\"p\">(</span><span class=\"s1\">'S-1'</span><span class=\"p\">)</span>\n</pre>\n<p>The output will be a table in the same format as the <code>anomalies</code> one.</p>\n<pre><code>        start         end\n0  1392768000  1402423200\n</code></pre>\n<p>Afterwards, we pass the ground truth, the detected anomalies and the original test data\nto the <code>orion.metrics.accuracy_score</code> and <code>orion.metrics.f1_score</code> functions in order\nto compute a score that indicates how good our anomaly detection was:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">orion.metrics</span> <span class=\"kn\">import</span> <span class=\"n\">accuracy_score</span><span class=\"p\">,</span> <span class=\"n\">f1_score</span>\n\n<span class=\"n\">accuracy_score</span><span class=\"p\">(</span><span class=\"n\">known_anomalies</span><span class=\"p\">,</span> <span class=\"n\">anomalies</span><span class=\"p\">,</span> <span class=\"n\">test</span><span class=\"p\">)</span>  <span class=\"c1\"># -&gt; 0.972987721691678</span>\n\n<span class=\"n\">f1_score</span><span class=\"p\">(</span><span class=\"n\">known_anomalies</span><span class=\"p\">,</span> <span class=\"n\">anomalies</span><span class=\"p\">,</span> <span class=\"n\">test</span><span class=\"p\">)</span>  <span class=\"c1\"># -&gt; 0.7155172413793103</span>\n</pre>\n<h1>Database</h1>\n<p><strong>Orion</strong> comes ready to use a MongoDB Database to easily register and explore:</p>\n<ul>\n<li>Multiple Datasets based on signals from one or more satellites.</li>\n<li>Multiple Pipelines, including historical Pipeline versions.</li>\n<li>Pipeline executions on the registered Datasets, including any environment details required to\nlater on reproduce the results.</li>\n<li>Pipeline execution results and detected events.</li>\n<li>Comments about the detected events.</li>\n</ul>\n<p>This, among other things, allows:</p>\n<ul>\n<li>Providing visibility about the system usage.</li>\n<li>Keeping track of the evolution of the registered pipelines and their performance over multiple datasets.</li>\n<li>Visualizing and browsing the detected events by the pipelines using a web application.</li>\n<li>Collecting comments from multiple domain experts about the detected events to be able to later\non curate the pipelines based on their knowledge.</li>\n<li>Reproducing previous executions in identical environments to replicate the obtained results.</li>\n<li>Detecting and keeping a history of system failures for later investigation.</li>\n</ul>\n<p>The complete <strong>Database schema and usage instructions</strong> can be found in the\n<a href=\"DATABASE.md\" rel=\"nofollow\">database documentation</a></p>\n<h1>History</h1>\n<h2>0.1.0 - 2020-04-23</h2>\n<p>First Orion release to PyPI: <a href=\"https://pypi.org/project/orion-ml/\" rel=\"nofollow\">https://pypi.org/project/orion-ml/</a></p>\n\n          </div>"}, "last_serial": 7186737, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "ea249222c34c80f27334657c642c46b5", "sha256": "c3b1661e6a49936aa01c70270e5baf6bce8e6f6ca2329bf80d05464b450c2011"}, "downloads": -1, "filename": "orion_ml-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "ea249222c34c80f27334657c642c46b5", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6", "size": 38438, "upload_time": "2020-04-23T16:53:12", "upload_time_iso_8601": "2020-04-23T16:53:12.030315Z", "url": "https://files.pythonhosted.org/packages/46/aa/ed64753445c5eeb99544ec8f8dd6a09238892f051002fa6cd644077272bf/orion_ml-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3d7f9a66baf83b770557df2ad56cc71d", "sha256": "41040fdf0b722ef6e9eeec3b7f0a5070ac817c98d16ba4f6975a9cebdb8af000"}, "downloads": -1, "filename": "orion-ml-0.1.0.tar.gz", "has_sig": false, "md5_digest": "3d7f9a66baf83b770557df2ad56cc71d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 161725, "upload_time": "2020-04-23T16:53:16", "upload_time_iso_8601": "2020-04-23T16:53:16.073771Z", "url": "https://files.pythonhosted.org/packages/12/e3/2008426302f58ed57ffbb3320b4a253155decc2c7516d7e60900dca6f53e/orion-ml-0.1.0.tar.gz", "yanked": false}], "0.1.0.dev0": [{"comment_text": "", "digests": {"md5": "c32fbd4510b18e51f94fcded2e1712f2", "sha256": "5559425d06396f21077b0a34c394df0bf800a56dc757fd3e26f7003528d06ba4"}, "downloads": -1, "filename": "orion_ml-0.1.0.dev0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "c32fbd4510b18e51f94fcded2e1712f2", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6", "size": 38493, "upload_time": "2020-04-23T16:49:56", "upload_time_iso_8601": "2020-04-23T16:49:56.596439Z", "url": "https://files.pythonhosted.org/packages/c4/6a/94d42021da70da225616ec97c0f2ec5b89ca91fe1d641614cfa9bc86d865/orion_ml-0.1.0.dev0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2b551ad883b2e0e1e4cde96e2944be4a", "sha256": "b074178463396edc883879d9a4505178af7d1d70c5cab351841187540b5b3730"}, "downloads": -1, "filename": "orion-ml-0.1.0.dev0.tar.gz", "has_sig": false, "md5_digest": "2b551ad883b2e0e1e4cde96e2944be4a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 161648, "upload_time": "2020-04-23T16:50:01", "upload_time_iso_8601": "2020-04-23T16:50:01.547175Z", "url": "https://files.pythonhosted.org/packages/ae/cd/8dd7b1c866b429ab7810a63f74f12bbc21825f1b50772178eb8bb59c1a59/orion-ml-0.1.0.dev0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ea249222c34c80f27334657c642c46b5", "sha256": "c3b1661e6a49936aa01c70270e5baf6bce8e6f6ca2329bf80d05464b450c2011"}, "downloads": -1, "filename": "orion_ml-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "ea249222c34c80f27334657c642c46b5", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6", "size": 38438, "upload_time": "2020-04-23T16:53:12", "upload_time_iso_8601": "2020-04-23T16:53:12.030315Z", "url": "https://files.pythonhosted.org/packages/46/aa/ed64753445c5eeb99544ec8f8dd6a09238892f051002fa6cd644077272bf/orion_ml-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3d7f9a66baf83b770557df2ad56cc71d", "sha256": "41040fdf0b722ef6e9eeec3b7f0a5070ac817c98d16ba4f6975a9cebdb8af000"}, "downloads": -1, "filename": "orion-ml-0.1.0.tar.gz", "has_sig": false, "md5_digest": "3d7f9a66baf83b770557df2ad56cc71d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 161725, "upload_time": "2020-04-23T16:53:16", "upload_time_iso_8601": "2020-04-23T16:53:16.073771Z", "url": "https://files.pythonhosted.org/packages/12/e3/2008426302f58ed57ffbb3320b4a253155decc2c7516d7e60900dca6f53e/orion-ml-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:01:35 2020"}