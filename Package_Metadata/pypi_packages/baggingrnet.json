{"info": {"author": "Lianfa Li", "author_email": "lspatial@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "baggingrnet: Library for Bagging of Deep Residual Neural Networks\n================\n\n### Introduction\n\nThis package provides The python Library for Bagging of Deep Residual Neural Networks (baggingrnet). Current version just supports the KERAS package of deep learning and will extend to the others in the future. The following functionaity is provoded in this package: \\* model multBagging: Major class to parallel bagging of autoencoder-based deep residual networks. You can setup its aruments for optimal effects. See the class and its member functions' help for details.\nresAutoencoder: Major class of the base model of autoencoder-based deep residual network. See the specifics for its details. ensPrediction: Major class to ensemble predictions and optional evaluation for independent test.\n\\* util pmetrics: main metrics including rsquare and rmse etc.\n\n-   data data: function to access two sample datas to test and demonstrate parallel training and predictions of multiple models by bagging. simData: function to simulate the dataset for a test.\n\n### Installation of the package\n\n1.  You can directly install this package using the following command for the latest version:\n\n          pip install baggingrnet  \n\n2.  You can also clone the repository and then install:\n\n         git clone --recursive https://github.com/lspatial/baggingrnet.git\n         pip install ./setup.py install \n\n### Modeling Framework\n\nThe modeling is based on bagging of the encoding-decoding antoencoder based deep residual multilayer percepton (MLP). Residual connections were used from the encoding to decoding layers to improve the learning efficiency and use of bagging is to achieve the stable and improved ensemble predictions, with uncertainty metric (standard deviation). <img  align=\"center\" src=\"https://raw.githubusercontent.com/lspatial/baggingrnet/master/figs/framework.jpg\"  style=\"zoom:50%\"  hspace=\"2\"/>\n\nThe relevant paper will be published and will update here once published.\n\n### Example 1: Regression of Simulated Data\n\nThe dataset is simulated using the following formula: <img  align=\"center\" src=\"https://raw.githubusercontent.com/lspatial/baggingrnet/master/figs/simform.png\"  hspace=\"2\"/>\n\neach covariate defined as:\n*x*<sub>1</sub>\u2004\u223c\u2004*U*(1,\u2006100),*x*<sub>2</sub>\u2004\u223c\u2004*U*(0,\u2006100),*x*<sub>3</sub>\u2004\u223c\u2004*U*(1,\u200610),*x*<sub>4</sub>\u2004\u223c\u2004*U*(1,\u2006100),*x*<sub>5</sub>\u2004\u223c\u2004*U*(9,\u2006100),*x*<sub>6</sub>\u2004\u223c\u2004*U*(1,\u20061009),*x*<sub>7</sub>\u2004\u223c\u2004*U*(5,\u2006300),*x*<sub>8</sub>\u00a0*U*(6\u2004\u223c\u2004200)\n This example is to illustrate how to use bagging class to train a model and compare the results by the models with and without use of residual connections in the models.\n\n###### 1) Load the dataset:\n\n``` python\nfrom baggingrnet.data import data\n\nsim_train=data('sim_train')\nsim_train['gindex']=np.array([i for i in range(sim_train.shape[0])])\n```\n\n``` r\nknitr::kable(py$sim_train[c(1:5),], format = \"html\")\n```\n\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left;\">\n</th>\n<th style=\"text-align:right;\">\nx1\n</th>\n<th style=\"text-align:right;\">\nx2\n</th>\n<th style=\"text-align:right;\">\nx3\n</th>\n<th style=\"text-align:right;\">\nx4\n</th>\n<th style=\"text-align:right;\">\nx5\n</th>\n<th style=\"text-align:right;\">\nx6\n</th>\n<th style=\"text-align:right;\">\nx7\n</th>\n<th style=\"text-align:right;\">\nx8\n</th>\n<th style=\"text-align:right;\">\ny\n</th>\n<th style=\"text-align:right;\">\ngindex\n</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left;\">\n9842\n</td>\n<td style=\"text-align:right;\">\n69.59893\n</td>\n<td style=\"text-align:right;\">\n6.368696\n</td>\n<td style=\"text-align:right;\">\n5.950720\n</td>\n<td style=\"text-align:right;\">\n97.97698\n</td>\n<td style=\"text-align:right;\">\n81.77670\n</td>\n<td style=\"text-align:right;\">\n38.12578\n</td>\n<td style=\"text-align:right;\">\n38.71023\n</td>\n<td style=\"text-align:right;\">\n124.90578\n</td>\n<td style=\"text-align:right;\">\n168.7697448\n</td>\n<td style=\"text-align:right;\">\n0\n</td>\n</tr>\n<tr>\n<td style=\"text-align:left;\">\n2513\n</td>\n<td style=\"text-align:right;\">\n88.83580\n</td>\n<td style=\"text-align:right;\">\n47.619385\n</td>\n<td style=\"text-align:right;\">\n8.107348\n</td>\n<td style=\"text-align:right;\">\n23.95389\n</td>\n<td style=\"text-align:right;\">\n41.00300\n</td>\n<td style=\"text-align:right;\">\n256.75319\n</td>\n<td style=\"text-align:right;\">\n203.75759\n</td>\n<td style=\"text-align:right;\">\n146.79040\n</td>\n<td style=\"text-align:right;\">\n184.8472212\n</td>\n<td style=\"text-align:right;\">\n1\n</td>\n</tr>\n<tr>\n<td style=\"text-align:left;\">\n9116\n</td>\n<td style=\"text-align:right;\">\n65.32664\n</td>\n<td style=\"text-align:right;\">\n49.473679\n</td>\n<td style=\"text-align:right;\">\n5.982418\n</td>\n<td style=\"text-align:right;\">\n75.99401\n</td>\n<td style=\"text-align:right;\">\n80.56275\n</td>\n<td style=\"text-align:right;\">\n849.48435\n</td>\n<td style=\"text-align:right;\">\n204.52137\n</td>\n<td style=\"text-align:right;\">\n161.61705\n</td>\n<td style=\"text-align:right;\">\n-444.5390646\n</td>\n<td style=\"text-align:right;\">\n2\n</td>\n</tr>\n<tr>\n<td style=\"text-align:left;\">\n2673\n</td>\n<td style=\"text-align:right;\">\n21.72827\n</td>\n<td style=\"text-align:right;\">\n64.946680\n</td>\n<td style=\"text-align:right;\">\n2.592348\n</td>\n<td style=\"text-align:right;\">\n70.32067\n</td>\n<td style=\"text-align:right;\">\n42.27824\n</td>\n<td style=\"text-align:right;\">\n387.42060\n</td>\n<td style=\"text-align:right;\">\n13.15852\n</td>\n<td style=\"text-align:right;\">\n88.47877\n</td>\n<td style=\"text-align:right;\">\n-166.3553631\n</td>\n<td style=\"text-align:right;\">\n3\n</td>\n</tr>\n<tr>\n<td style=\"text-align:left;\">\n5607\n</td>\n<td style=\"text-align:right;\">\n69.45317\n</td>\n<td style=\"text-align:right;\">\n18.811648\n</td>\n<td style=\"text-align:right;\">\n5.624373\n</td>\n<td style=\"text-align:right;\">\n39.81835\n</td>\n<td style=\"text-align:right;\">\n84.80446\n</td>\n<td style=\"text-align:right;\">\n333.43811\n</td>\n<td style=\"text-align:right;\">\n89.22591\n</td>\n<td style=\"text-align:right;\">\n77.25155\n</td>\n<td style=\"text-align:right;\">\n-0.5405426\n</td>\n<td style=\"text-align:right;\">\n4\n</td>\n</tr>\n</tbody>\n</table>\n###### 2) Set bagging path, list of predictor names, get the bagging class instance and input data:\n\n``` python\n# Load the major class for parallel bagging training\nfrom baggingrnet.model.bagging import  multBagging  \n\nfeasList = ['x'+str(i) for i in range(1,9)] #List of the covariates used in training \ntarget='y' # Name of the target variable \nbagpath='/tmp/sim_bagging/res' # Path used to \nchkpath(bagpath)\nmbag=multBagging(bagpath)\nmbag.getInputSample(sim_train, feasList,None,'gindex',target)\n```\n\n###### 3) Define the arguments of a model and append it to the list of modeling duties:\n\n``` python\nname = str(0) # model name as unique identifier \nnodes = [32,16,8,4] # List of number of nodes for the encoding and coding layers, adjustable optionally; \nminibatch = 512 # Size for mini batch \nisresidual = True # Whether to use residual connections in the model \nnepoch = 200 #Number of epoches \nsampling_fea = False # Whether to bootstrap the predictors/features \nnoutput = 1 # Number of the output node \nislog=False # Whether to make the log transformation \n# The following is to add the model's arguments to the list of duties. \nmbag.addTask(name,noutput,sampling_fea, nepoch, nodes, minibatch, isresidual,islog)\n```\n\n###### 4) Initiate the training:\n\n``` python\nmbag.startMProcess(1)\n```\n\nHere, just one core is used for one model.\n\n###### 5) Prediction using the trained models and optional evaluation of the trained model:\n\n``` python\nfrom baggingrnet.model.baggingpre import  ensPrediction\n# Load the test dataset \nsim_test=data('sim_test')\nsim_test['gindex']=np.array([i for i in range(sim_test.shape[0])]) # Generate the unique id for merging the predicitons of multiple models \n# Setup the path and target variable  \nprepath=\"/tmp/sim_bagging/res_pre\"\nchkpath(prepath)\n#Load the prdiction class\nmbagpre=ensPrediction(bagpath,prepath)\n#Load the test data \nmbagpre.getInputSample(sim_test, feasList,'gindex')\n#Start to make predictions for multiple trained models. \nmbagpre.startMProcess(1)\n#Obtain the ensemble predictions from those of multiple models and optional evaluation of the models. \nmbagpre.aggPredict(isval=True,tfld='y')\n```\n\nThe above five steps illustrate the process of loading data, training, testing, and predicting. To compare with the results of residual models, the following code is to get the results for the non-residual models.\n\n``` python\nmbag.removeTask(name)\nbagpath='/tmp/sim_bagging/nores'\nchkpath(bagpath)\nmbag_nores=multBagging(bagpath)\nmbag_nores.getInputSample(sim_train, feasList,None,'gindex','y')\nisresidual = False  # This is to set no use of residual connections in the models. \nmbag_nores.addTask(name,noutput,sampling_fea, nepoch, nodes, minibatch, isresidual,islog)\nmbag_nores.startMProcess(1) \nprepath=\"/tmp/sim_bagging/nores_pre\"\nchkpath(prepath)\nmbagpre=ensPrediction(bagpath,prepath)\nmbagpre.getInputSample(sim_test, feasList,'gindex')\nmbagpre.startMProcess(1)\nmbagpre.aggPredict(isval=True,tfld='y')\n```\n\nThe comparison of the training/learning curves for residual and non-residual models:\n\n![](https://raw.githubusercontent.com/lspatial/baggingrnet/master/README_files/figure-markdown_github/unnamed-chunk-10-1.png)\n\nThe comparison of the independent test for residual and non-residual models: performance (R2 and RMSE)\n\n    ## [1] \"non residual model   r2: 0.78, rmse: 150.17\"\n\n    ## [1] \"residual model   r2: 0.91, rmse: 98.37\"\n\n    ## [1] \"Residual model improved R2 by 12.48%, compared with non-residual model\"\n\n    ## [1] \"Residual model decreased rmse by -51.8, compared with non-residual model\"\n\nThe scatter comparison of residual vs. non-residual models for the independent test:\n\n![](https://raw.githubusercontent.com/lspatial/baggingrnet/master/README_files/figure-markdown_github/unnamed-chunk-12-1.png)\n\n### Example 2: Spatiotemporal Estimation of PM<sub>2.5</sub>\n\nThis dataset is the real dataset of the 2015 PM<sub>2.5</sub> and the relevant covariates for the Beijing-Tianjin-Tangshan area. Due to data security reason, it has been added with small Gaussian noise.\n\n<img  align=\"center\" src=\"https://raw.githubusercontent.com/lspatial/baggingrnet/master/figs/studyregion.png\"  style=\"zoom:65%\"  hspace=\"2\"/>\n\n###### 1) Load input data:\n\nHere the PM<sub>2.5</sub> dataset is used to test the proposed methods.\n\n``` python\nfrom baggingrnet.data import data\npm25_train=data('pm2.5_train')\npm25_train['gindex']=np.array([i for i in range(pm25_train.shape[0])])\n```\n\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left;\">\n</th>\n<th style=\"text-align:left;\">\nsites\n</th>\n<th style=\"text-align:left;\">\nsite\\_name\n</th>\n<th style=\"text-align:left;\">\ncity\n</th>\n<th style=\"text-align:right;\">\nlon\n</th>\n<th style=\"text-align:right;\">\nlat\n</th>\n<th style=\"text-align:right;\">\npm25\\_davg\n</th>\n<th style=\"text-align:right;\">\nele\n</th>\n<th style=\"text-align:right;\">\nprs\n</th>\n<th style=\"text-align:right;\">\ntem\n</th>\n<th style=\"text-align:right;\">\nrhu\n</th>\n<th style=\"text-align:right;\">\nwin\n</th>\n<th style=\"text-align:right;\">\naod\n</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left;\">\n23123\n</td>\n<td style=\"text-align:left;\">\n1010A\n</td>\n<td style=\"text-align:left;\">\n\u660c\u5e73\u9547\n</td>\n<td style=\"text-align:left;\">\n\u5317\u4eac\n</td>\n<td style=\"text-align:right;\">\n116.2300\n</td>\n<td style=\"text-align:right;\">\n40.1952\n</td>\n<td style=\"text-align:right;\">\n6.80000\n</td>\n<td style=\"text-align:right;\">\n57.0\n</td>\n<td style=\"text-align:right;\">\n1007.709\n</td>\n<td style=\"text-align:right;\">\n20.0859852\n</td>\n<td style=\"text-align:right;\">\n0.7609952\n</td>\n<td style=\"text-align:right;\">\n17.39427\n</td>\n<td style=\"text-align:right;\">\n0.2877372\n</td>\n</tr>\n<tr>\n<td style=\"text-align:left;\">\n1339\n</td>\n<td style=\"text-align:left;\">\n1014A\n</td>\n<td style=\"text-align:left;\">\n\u5357\u53e3\u8def\n</td>\n<td style=\"text-align:left;\">\n\u5929\u6d25\n</td>\n<td style=\"text-align:right;\">\n117.1930\n</td>\n<td style=\"text-align:right;\">\n39.1730\n</td>\n<td style=\"text-align:right;\">\n84.59091\n</td>\n<td style=\"text-align:right;\">\n8.5\n</td>\n<td style=\"text-align:right;\">\n1021.859\n</td>\n<td style=\"text-align:right;\">\n-0.2894622\n</td>\n<td style=\"text-align:right;\">\n0.6565141\n</td>\n<td style=\"text-align:right;\">\n40.61296\n</td>\n<td style=\"text-align:right;\">\n0.2245625\n</td>\n</tr>\n<tr>\n<td style=\"text-align:left;\">\n11843\n</td>\n<td style=\"text-align:left;\">\n1062A\n</td>\n<td style=\"text-align:left;\">\n\u94c1\u8def\n</td>\n<td style=\"text-align:left;\">\n\u627f\u5fb7\n</td>\n<td style=\"text-align:right;\">\n117.9664\n</td>\n<td style=\"text-align:right;\">\n40.9161\n</td>\n<td style=\"text-align:right;\">\n21.27273\n</td>\n<td style=\"text-align:right;\">\n362.0\n</td>\n<td style=\"text-align:right;\">\n969.876\n</td>\n<td style=\"text-align:right;\">\n15.3092365\n</td>\n<td style=\"text-align:right;\">\n0.5288071\n</td>\n<td style=\"text-align:right;\">\n16.61683\n</td>\n<td style=\"text-align:right;\">\n0.4272831\n</td>\n</tr>\n<tr>\n<td style=\"text-align:left;\">\n9373\n</td>\n<td style=\"text-align:left;\">\n\u6986\u57a1\n</td>\n<td style=\"text-align:left;\">\n\u4eac\u5357\u6986\u57a1\uff0c\u4eac\u5357\u533a\u57df\u70b9\n</td>\n<td style=\"text-align:left;\">\n\u5317\u4eac\n</td>\n<td style=\"text-align:right;\">\n116.3000\n</td>\n<td style=\"text-align:right;\">\n39.5200\n</td>\n<td style=\"text-align:right;\">\n12.08696\n</td>\n<td style=\"text-align:right;\">\n18.0\n</td>\n<td style=\"text-align:right;\">\n1013.116\n</td>\n<td style=\"text-align:right;\">\n14.0085974\n</td>\n<td style=\"text-align:right;\">\n0.8100768\n</td>\n<td style=\"text-align:right;\">\n39.46079\n</td>\n<td style=\"text-align:right;\">\n0.5075859\n</td>\n</tr>\n<tr>\n<td style=\"text-align:left;\">\n19596\n</td>\n<td style=\"text-align:left;\">\n1069A\n</td>\n<td style=\"text-align:left;\">\n\u73af\u5883\u76d1\u6d4b\u76d1\u7406\u4e2d\u5fc3\n</td>\n<td style=\"text-align:left;\">\n\u5eca\u574a\n</td>\n<td style=\"text-align:right;\">\n116.7150\n</td>\n<td style=\"text-align:right;\">\n39.5571\n</td>\n<td style=\"text-align:right;\">\n64.20833\n</td>\n<td style=\"text-align:right;\">\n35.0\n</td>\n<td style=\"text-align:right;\">\n1005.249\n</td>\n<td style=\"text-align:right;\">\n24.4960499\n</td>\n<td style=\"text-align:right;\">\n0.8604047\n</td>\n<td style=\"text-align:right;\">\n14.01048\n</td>\n<td style=\"text-align:right;\">\n1.5149391\n</td>\n</tr>\n</tbody>\n</table>\n###### 2) Set bagging path, list of predictor names, get the bagging class instance and input data:\n\n``` python\nfrom baggingrnet.model.bagging import  multBagging\nimport random as r \nfeasList = ['lat', 'lon', 'ele', 'prs', 'tem', 'rhu', 'win', 'pblh_re', 'pre_re', 'o3_re', 'aod', 'merra2_re', 'haod',\n         'shaod', 'jd','lat2','lon2','latlon']\ntarget='pm25_avg_log'\nbagpath='/tmp/baggingpm25_2/res'\nchkpath(bagpath)\nmbag=multBagging(bagpath)\n```\n\n    ## initializing ...\n\n``` python\nmbag.getInputSample(pm25_train, feasList,None,'gindex',target)\n```\n\n    ## (29475, 31)\n\n###### 3) Define the arguments of multiple models (here 100 models) and append them to the list of modeling duties:\n\n``` python\nimport random as r \nfor i in range(1,81):\n    name = str(i)\n    nodes = [128 + r.randint(-5,5),128+ r.randint(-5,5),96,64,32,12]\n    minibatch = 2560+r.randint(-5,5)\n    isresidual = False\n    nepoch = 120\n    sampling_fea = False\n    noutput = 1\n    islog=True\n    mbag.addTask(name,noutput,sampling_fea, nepoch, nodes, minibatch, isresidual,islog)\n    \n```\n\n###### 4) Initiate the training:\n\nInitiate the parallel programs using 10 cores\n\n``` python\nmbag.startMProcess(10)\n```\n\n###### 5) Prediction using the trained models and optional evaluation of the trained model:\n\n``` python\nfrom baggingrnet.model.baggingpre import  ensPrediction\nprepath=\"/tmp/baggingpm25_2p/res\"\nchkpath(prepath)\nmbagpre=ensPrediction(bagpath,prepath)\nmbagpre.getInputSample(pm25_test, feasList,'gindex')\nmbagpre.startMProcess(10)\nmbagpre.aggPredict(isval=True,tfld='pm25_davg')\n```\n\nFinally, the following results were obtaned.\n\nThe results are shown as the following:\n\n###### 1) Typical learning curves of non-residual vs. residual models are shown as the following:\n\n![](https://raw.githubusercontent.com/lspatial/baggingrnet/master/README_files/figure-markdown_github/unnamed-chunk-19-1.png)\n\n###### 2) Mean performance (R2 and RMSE) of the predictions of multiple non-residual vs residual models for the independent dataset :\n\n![](https://raw.githubusercontent.com/lspatial/baggingrnet/master/README_files/figure-markdown_github/unnamed-chunk-20-1.png)\n\n###### 3) Performance (R2 and RMSE) of the ensembled predictions based on multiple models for the independent dataset:\n\n    ## [1] \"non residual model   r2: 0.88, rmse: 23.55\"\n\n    ## [1] \"residual model   r2: 0.91, rmse: 20.35\"\n\n    ## [1] \"Residual model improved R2 by 2.97%, compared with non-residual model\"\n\n    ## [1] \"Residual model decreased rmse by -3.2, compared with non-residual model\"\n\n###### 4) Scatter plots for the ensemble predictions of non-residual vs residual models:\n\n![](https://raw.githubusercontent.com/lspatial/baggingrnet/master/README_files/figure-markdown_github/unnamed-chunk-22-1.png)\n\n###### 5) Comparison of ensemble predictions vs. predictions of single models:\n\nStatistics of the performance for the predictions of multiple models and ensemble predictions are made. The following shows R<sup>2</sup> and RMSE, barplots and scatter plots.\n\nPerformance digits:\n\n    ## [1] \"Ensemble predictions: R2=0.91, RMSE=20.35\"\n\n    ## [1] \"Mean performance of predictions of multiple single models: R2=0.86, RMSE=26.07\"\n\n    ## [1] \"Ensemble predictions averagely improved the single predictions by 6% for R2, and reduced -5.72ug/m3 for RMSE\"\n\nThe boxplot shows considerable improvement by bagging (6% in R<sup>2</sup> and -5.72 *\u03bc*g/m<sup>3</sup>), in comparison with single models.\n\n![](https://raw.githubusercontent.com/lspatial/baggingrnet/master/README_files/figure-markdown_github/unnamed-chunk-24-1.png)\n\nThe following shows the scatter plots of observed PM<sub>2.5</sub> vs. ensemble predictions/residuals:\n\n![](https://raw.githubusercontent.com/lspatial/baggingrnet/master/README_files/figure-markdown_github/unnamed-chunk-25-1.png)\n\n### Contact\n\nFor this library and its relevant complete applications, welcome to contact Dr. Lianfa Li. Email: <lspatial@gmail.com> or  <lilf@lreis.ac.cn>", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "baggingrnet", "package_url": "https://pypi.org/project/baggingrnet/", "platform": "", "project_url": "https://pypi.org/project/baggingrnet/", "project_urls": null, "release_url": "https://pypi.org/project/baggingrnet/0.0.12/", "requires_dist": null, "requires_python": "", "summary": "Library for Bagging of Deep Residual Neural Networks", "version": "0.0.12", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>baggingrnet: Library for Bagging of Deep Residual Neural Networks</h1>\n<h3>Introduction</h3>\n<p>This package provides The python Library for Bagging of Deep Residual Neural Networks (baggingrnet). Current version just supports the KERAS package of deep learning and will extend to the others in the future. The following functionaity is provoded in this package: * model multBagging: Major class to parallel bagging of autoencoder-based deep residual networks. You can setup its aruments for optimal effects. See the class and its member functions' help for details.\nresAutoencoder: Major class of the base model of autoencoder-based deep residual network. See the specifics for its details. ensPrediction: Major class to ensemble predictions and optional evaluation for independent test.\n* util pmetrics: main metrics including rsquare and rmse etc.</p>\n<ul>\n<li>data data: function to access two sample datas to test and demonstrate parallel training and predictions of multiple models by bagging. simData: function to simulate the dataset for a test.</li>\n</ul>\n<h3>Installation of the package</h3>\n<ol>\n<li>\n<p>You can directly install this package using the following command for the latest version:</p>\n<pre><code>  pip install baggingrnet  \n</code></pre>\n</li>\n<li>\n<p>You can also clone the repository and then install:</p>\n<pre><code> git clone --recursive https://github.com/lspatial/baggingrnet.git\n pip install ./setup.py install \n</code></pre>\n</li>\n</ol>\n<h3>Modeling Framework</h3>\n<p>The modeling is based on bagging of the encoding-decoding antoencoder based deep residual multilayer percepton (MLP). Residual connections were used from the encoding to decoding layers to improve the learning efficiency and use of bagging is to achieve the stable and improved ensemble predictions, with uncertainty metric (standard deviation). <img align=\"center\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/7a3c3da543a43d3aae855107f3e742e21f0d95a0/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6c7370617469616c2f62616767696e67726e65742f6d61737465722f666967732f6672616d65776f726b2e6a7067\"></p>\n<p>The relevant paper will be published and will update here once published.</p>\n<h3>Example 1: Regression of Simulated Data</h3>\n<p>The dataset is simulated using the following formula: <img align=\"center\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ff83f6ed2967957e0a380948912f007185eeb041/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6c7370617469616c2f62616767696e67726e65742f6d61737465722f666967732f73696d666f726d2e706e67\"></p>\n<p>each covariate defined as:\n<em>x</em><sub>1</sub>\u2004\u223c\u2004<em>U</em>(1,\u2006100),<em>x</em><sub>2</sub>\u2004\u223c\u2004<em>U</em>(0,\u2006100),<em>x</em><sub>3</sub>\u2004\u223c\u2004<em>U</em>(1,\u200610),<em>x</em><sub>4</sub>\u2004\u223c\u2004<em>U</em>(1,\u2006100),<em>x</em><sub>5</sub>\u2004\u223c\u2004<em>U</em>(9,\u2006100),<em>x</em><sub>6</sub>\u2004\u223c\u2004<em>U</em>(1,\u20061009),<em>x</em><sub>7</sub>\u2004\u223c\u2004<em>U</em>(5,\u2006300),<em>x</em><sub>8</sub>\u00a0<em>U</em>(6\u2004\u223c\u2004200)\nThis example is to illustrate how to use bagging class to train a model and compare the results by the models with and without use of residual connections in the models.</p>\n<h6>1) Load the dataset:</h6>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">baggingrnet.data</span> <span class=\"kn\">import</span> <span class=\"n\">data</span>\n\n<span class=\"n\">sim_train</span><span class=\"o\">=</span><span class=\"n\">data</span><span class=\"p\">(</span><span class=\"s1\">'sim_train'</span><span class=\"p\">)</span>\n<span class=\"n\">sim_train</span><span class=\"p\">[</span><span class=\"s1\">'gindex'</span><span class=\"p\">]</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"n\">i</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">sim_train</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])])</span>\n</pre>\n<pre><span class=\"n\">knitr</span><span class=\"o\">::</span><span class=\"nf\">kable</span><span class=\"p\">(</span><span class=\"n\">py</span><span class=\"o\">$</span><span class=\"n\">sim_train</span><span class=\"p\">[</span><span class=\"nf\">c</span><span class=\"p\">(</span><span class=\"m\">1</span><span class=\"o\">:</span><span class=\"m\">5</span><span class=\"p\">),],</span> <span class=\"n\">format</span> <span class=\"o\">=</span> <span class=\"s\">\"html\"</span><span class=\"p\">)</span>\n</pre>\n<table>\n<thead>\n<tr>\n<th>\n</th>\n<th>\nx1\n</th>\n<th>\nx2\n</th>\n<th>\nx3\n</th>\n<th>\nx4\n</th>\n<th>\nx5\n</th>\n<th>\nx6\n</th>\n<th>\nx7\n</th>\n<th>\nx8\n</th>\n<th>\ny\n</th>\n<th>\ngindex\n</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>\n9842\n</td>\n<td>\n69.59893\n</td>\n<td>\n6.368696\n</td>\n<td>\n5.950720\n</td>\n<td>\n97.97698\n</td>\n<td>\n81.77670\n</td>\n<td>\n38.12578\n</td>\n<td>\n38.71023\n</td>\n<td>\n124.90578\n</td>\n<td>\n168.7697448\n</td>\n<td>\n0\n</td>\n</tr>\n<tr>\n<td>\n2513\n</td>\n<td>\n88.83580\n</td>\n<td>\n47.619385\n</td>\n<td>\n8.107348\n</td>\n<td>\n23.95389\n</td>\n<td>\n41.00300\n</td>\n<td>\n256.75319\n</td>\n<td>\n203.75759\n</td>\n<td>\n146.79040\n</td>\n<td>\n184.8472212\n</td>\n<td>\n1\n</td>\n</tr>\n<tr>\n<td>\n9116\n</td>\n<td>\n65.32664\n</td>\n<td>\n49.473679\n</td>\n<td>\n5.982418\n</td>\n<td>\n75.99401\n</td>\n<td>\n80.56275\n</td>\n<td>\n849.48435\n</td>\n<td>\n204.52137\n</td>\n<td>\n161.61705\n</td>\n<td>\n-444.5390646\n</td>\n<td>\n2\n</td>\n</tr>\n<tr>\n<td>\n2673\n</td>\n<td>\n21.72827\n</td>\n<td>\n64.946680\n</td>\n<td>\n2.592348\n</td>\n<td>\n70.32067\n</td>\n<td>\n42.27824\n</td>\n<td>\n387.42060\n</td>\n<td>\n13.15852\n</td>\n<td>\n88.47877\n</td>\n<td>\n-166.3553631\n</td>\n<td>\n3\n</td>\n</tr>\n<tr>\n<td>\n5607\n</td>\n<td>\n69.45317\n</td>\n<td>\n18.811648\n</td>\n<td>\n5.624373\n</td>\n<td>\n39.81835\n</td>\n<td>\n84.80446\n</td>\n<td>\n333.43811\n</td>\n<td>\n89.22591\n</td>\n<td>\n77.25155\n</td>\n<td>\n-0.5405426\n</td>\n<td>\n4\n</td>\n</tr>\n</tbody>\n</table>\n###### 2) Set bagging path, list of predictor names, get the bagging class instance and input data:\n<pre><span class=\"c1\"># Load the major class for parallel bagging training</span>\n<span class=\"kn\">from</span> <span class=\"nn\">baggingrnet.model.bagging</span> <span class=\"kn\">import</span>  <span class=\"n\">multBagging</span>  \n\n<span class=\"n\">feasList</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'x'</span><span class=\"o\">+</span><span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">9</span><span class=\"p\">)]</span> <span class=\"c1\">#List of the covariates used in training </span>\n<span class=\"n\">target</span><span class=\"o\">=</span><span class=\"s1\">'y'</span> <span class=\"c1\"># Name of the target variable </span>\n<span class=\"n\">bagpath</span><span class=\"o\">=</span><span class=\"s1\">'/tmp/sim_bagging/res'</span> <span class=\"c1\"># Path used to </span>\n<span class=\"n\">chkpath</span><span class=\"p\">(</span><span class=\"n\">bagpath</span><span class=\"p\">)</span>\n<span class=\"n\">mbag</span><span class=\"o\">=</span><span class=\"n\">multBagging</span><span class=\"p\">(</span><span class=\"n\">bagpath</span><span class=\"p\">)</span>\n<span class=\"n\">mbag</span><span class=\"o\">.</span><span class=\"n\">getInputSample</span><span class=\"p\">(</span><span class=\"n\">sim_train</span><span class=\"p\">,</span> <span class=\"n\">feasList</span><span class=\"p\">,</span><span class=\"kc\">None</span><span class=\"p\">,</span><span class=\"s1\">'gindex'</span><span class=\"p\">,</span><span class=\"n\">target</span><span class=\"p\">)</span>\n</pre>\n<h6>3) Define the arguments of a model and append it to the list of modeling duties:</h6>\n<pre><span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span> <span class=\"c1\"># model name as unique identifier </span>\n<span class=\"n\">nodes</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">32</span><span class=\"p\">,</span><span class=\"mi\">16</span><span class=\"p\">,</span><span class=\"mi\">8</span><span class=\"p\">,</span><span class=\"mi\">4</span><span class=\"p\">]</span> <span class=\"c1\"># List of number of nodes for the encoding and coding layers, adjustable optionally; </span>\n<span class=\"n\">minibatch</span> <span class=\"o\">=</span> <span class=\"mi\">512</span> <span class=\"c1\"># Size for mini batch </span>\n<span class=\"n\">isresidual</span> <span class=\"o\">=</span> <span class=\"kc\">True</span> <span class=\"c1\"># Whether to use residual connections in the model </span>\n<span class=\"n\">nepoch</span> <span class=\"o\">=</span> <span class=\"mi\">200</span> <span class=\"c1\">#Number of epoches </span>\n<span class=\"n\">sampling_fea</span> <span class=\"o\">=</span> <span class=\"kc\">False</span> <span class=\"c1\"># Whether to bootstrap the predictors/features </span>\n<span class=\"n\">noutput</span> <span class=\"o\">=</span> <span class=\"mi\">1</span> <span class=\"c1\"># Number of the output node </span>\n<span class=\"n\">islog</span><span class=\"o\">=</span><span class=\"kc\">False</span> <span class=\"c1\"># Whether to make the log transformation </span>\n<span class=\"c1\"># The following is to add the model's arguments to the list of duties. </span>\n<span class=\"n\">mbag</span><span class=\"o\">.</span><span class=\"n\">addTask</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"p\">,</span><span class=\"n\">noutput</span><span class=\"p\">,</span><span class=\"n\">sampling_fea</span><span class=\"p\">,</span> <span class=\"n\">nepoch</span><span class=\"p\">,</span> <span class=\"n\">nodes</span><span class=\"p\">,</span> <span class=\"n\">minibatch</span><span class=\"p\">,</span> <span class=\"n\">isresidual</span><span class=\"p\">,</span><span class=\"n\">islog</span><span class=\"p\">)</span>\n</pre>\n<h6>4) Initiate the training:</h6>\n<pre><span class=\"n\">mbag</span><span class=\"o\">.</span><span class=\"n\">startMProcess</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</pre>\n<p>Here, just one core is used for one model.</p>\n<h6>5) Prediction using the trained models and optional evaluation of the trained model:</h6>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">baggingrnet.model.baggingpre</span> <span class=\"kn\">import</span>  <span class=\"n\">ensPrediction</span>\n<span class=\"c1\"># Load the test dataset </span>\n<span class=\"n\">sim_test</span><span class=\"o\">=</span><span class=\"n\">data</span><span class=\"p\">(</span><span class=\"s1\">'sim_test'</span><span class=\"p\">)</span>\n<span class=\"n\">sim_test</span><span class=\"p\">[</span><span class=\"s1\">'gindex'</span><span class=\"p\">]</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"n\">i</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">sim_test</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])])</span> <span class=\"c1\"># Generate the unique id for merging the predicitons of multiple models </span>\n<span class=\"c1\"># Setup the path and target variable  </span>\n<span class=\"n\">prepath</span><span class=\"o\">=</span><span class=\"s2\">\"/tmp/sim_bagging/res_pre\"</span>\n<span class=\"n\">chkpath</span><span class=\"p\">(</span><span class=\"n\">prepath</span><span class=\"p\">)</span>\n<span class=\"c1\">#Load the prdiction class</span>\n<span class=\"n\">mbagpre</span><span class=\"o\">=</span><span class=\"n\">ensPrediction</span><span class=\"p\">(</span><span class=\"n\">bagpath</span><span class=\"p\">,</span><span class=\"n\">prepath</span><span class=\"p\">)</span>\n<span class=\"c1\">#Load the test data </span>\n<span class=\"n\">mbagpre</span><span class=\"o\">.</span><span class=\"n\">getInputSample</span><span class=\"p\">(</span><span class=\"n\">sim_test</span><span class=\"p\">,</span> <span class=\"n\">feasList</span><span class=\"p\">,</span><span class=\"s1\">'gindex'</span><span class=\"p\">)</span>\n<span class=\"c1\">#Start to make predictions for multiple trained models. </span>\n<span class=\"n\">mbagpre</span><span class=\"o\">.</span><span class=\"n\">startMProcess</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"c1\">#Obtain the ensemble predictions from those of multiple models and optional evaluation of the models. </span>\n<span class=\"n\">mbagpre</span><span class=\"o\">.</span><span class=\"n\">aggPredict</span><span class=\"p\">(</span><span class=\"n\">isval</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span><span class=\"n\">tfld</span><span class=\"o\">=</span><span class=\"s1\">'y'</span><span class=\"p\">)</span>\n</pre>\n<p>The above five steps illustrate the process of loading data, training, testing, and predicting. To compare with the results of residual models, the following code is to get the results for the non-residual models.</p>\n<pre><span class=\"n\">mbag</span><span class=\"o\">.</span><span class=\"n\">removeTask</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"p\">)</span>\n<span class=\"n\">bagpath</span><span class=\"o\">=</span><span class=\"s1\">'/tmp/sim_bagging/nores'</span>\n<span class=\"n\">chkpath</span><span class=\"p\">(</span><span class=\"n\">bagpath</span><span class=\"p\">)</span>\n<span class=\"n\">mbag_nores</span><span class=\"o\">=</span><span class=\"n\">multBagging</span><span class=\"p\">(</span><span class=\"n\">bagpath</span><span class=\"p\">)</span>\n<span class=\"n\">mbag_nores</span><span class=\"o\">.</span><span class=\"n\">getInputSample</span><span class=\"p\">(</span><span class=\"n\">sim_train</span><span class=\"p\">,</span> <span class=\"n\">feasList</span><span class=\"p\">,</span><span class=\"kc\">None</span><span class=\"p\">,</span><span class=\"s1\">'gindex'</span><span class=\"p\">,</span><span class=\"s1\">'y'</span><span class=\"p\">)</span>\n<span class=\"n\">isresidual</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>  <span class=\"c1\"># This is to set no use of residual connections in the models. </span>\n<span class=\"n\">mbag_nores</span><span class=\"o\">.</span><span class=\"n\">addTask</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"p\">,</span><span class=\"n\">noutput</span><span class=\"p\">,</span><span class=\"n\">sampling_fea</span><span class=\"p\">,</span> <span class=\"n\">nepoch</span><span class=\"p\">,</span> <span class=\"n\">nodes</span><span class=\"p\">,</span> <span class=\"n\">minibatch</span><span class=\"p\">,</span> <span class=\"n\">isresidual</span><span class=\"p\">,</span><span class=\"n\">islog</span><span class=\"p\">)</span>\n<span class=\"n\">mbag_nores</span><span class=\"o\">.</span><span class=\"n\">startMProcess</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span> \n<span class=\"n\">prepath</span><span class=\"o\">=</span><span class=\"s2\">\"/tmp/sim_bagging/nores_pre\"</span>\n<span class=\"n\">chkpath</span><span class=\"p\">(</span><span class=\"n\">prepath</span><span class=\"p\">)</span>\n<span class=\"n\">mbagpre</span><span class=\"o\">=</span><span class=\"n\">ensPrediction</span><span class=\"p\">(</span><span class=\"n\">bagpath</span><span class=\"p\">,</span><span class=\"n\">prepath</span><span class=\"p\">)</span>\n<span class=\"n\">mbagpre</span><span class=\"o\">.</span><span class=\"n\">getInputSample</span><span class=\"p\">(</span><span class=\"n\">sim_test</span><span class=\"p\">,</span> <span class=\"n\">feasList</span><span class=\"p\">,</span><span class=\"s1\">'gindex'</span><span class=\"p\">)</span>\n<span class=\"n\">mbagpre</span><span class=\"o\">.</span><span class=\"n\">startMProcess</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"n\">mbagpre</span><span class=\"o\">.</span><span class=\"n\">aggPredict</span><span class=\"p\">(</span><span class=\"n\">isval</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span><span class=\"n\">tfld</span><span class=\"o\">=</span><span class=\"s1\">'y'</span><span class=\"p\">)</span>\n</pre>\n<p>The comparison of the training/learning curves for residual and non-residual models:</p>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/466269b38679675018f7ca7627d2d8d4b9c1b07d/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6c7370617469616c2f62616767696e67726e65742f6d61737465722f524541444d455f66696c65732f6669677572652d6d61726b646f776e5f6769746875622f756e6e616d65642d6368756e6b2d31302d312e706e67\"></p>\n<p>The comparison of the independent test for residual and non-residual models: performance (R2 and RMSE)</p>\n<pre><code>## [1] \"non residual model   r2: 0.78, rmse: 150.17\"\n\n## [1] \"residual model   r2: 0.91, rmse: 98.37\"\n\n## [1] \"Residual model improved R2 by 12.48%, compared with non-residual model\"\n\n## [1] \"Residual model decreased rmse by -51.8, compared with non-residual model\"\n</code></pre>\n<p>The scatter comparison of residual vs. non-residual models for the independent test:</p>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c4696ec1198753b55ef9448b879436326d51250b/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6c7370617469616c2f62616767696e67726e65742f6d61737465722f524541444d455f66696c65732f6669677572652d6d61726b646f776e5f6769746875622f756e6e616d65642d6368756e6b2d31322d312e706e67\"></p>\n<h3>Example 2: Spatiotemporal Estimation of PM<sub>2.5</sub></h3>\n<p>This dataset is the real dataset of the 2015 PM<sub>2.5</sub> and the relevant covariates for the Beijing-Tianjin-Tangshan area. Due to data security reason, it has been added with small Gaussian noise.</p>\n<img align=\"center\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/524b2f1be72b7baa1d1fcb0b07f796c0bd14e537/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6c7370617469616c2f62616767696e67726e65742f6d61737465722f666967732f7374756479726567696f6e2e706e67\">\n<h6>1) Load input data:</h6>\n<p>Here the PM<sub>2.5</sub> dataset is used to test the proposed methods.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">baggingrnet.data</span> <span class=\"kn\">import</span> <span class=\"n\">data</span>\n<span class=\"n\">pm25_train</span><span class=\"o\">=</span><span class=\"n\">data</span><span class=\"p\">(</span><span class=\"s1\">'pm2.5_train'</span><span class=\"p\">)</span>\n<span class=\"n\">pm25_train</span><span class=\"p\">[</span><span class=\"s1\">'gindex'</span><span class=\"p\">]</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"n\">i</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">pm25_train</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])])</span>\n</pre>\n<table>\n<thead>\n<tr>\n<th>\n</th>\n<th>\nsites\n</th>\n<th>\nsite\\_name\n</th>\n<th>\ncity\n</th>\n<th>\nlon\n</th>\n<th>\nlat\n</th>\n<th>\npm25\\_davg\n</th>\n<th>\nele\n</th>\n<th>\nprs\n</th>\n<th>\ntem\n</th>\n<th>\nrhu\n</th>\n<th>\nwin\n</th>\n<th>\naod\n</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>\n23123\n</td>\n<td>\n1010A\n</td>\n<td>\n\u660c\u5e73\u9547\n</td>\n<td>\n\u5317\u4eac\n</td>\n<td>\n116.2300\n</td>\n<td>\n40.1952\n</td>\n<td>\n6.80000\n</td>\n<td>\n57.0\n</td>\n<td>\n1007.709\n</td>\n<td>\n20.0859852\n</td>\n<td>\n0.7609952\n</td>\n<td>\n17.39427\n</td>\n<td>\n0.2877372\n</td>\n</tr>\n<tr>\n<td>\n1339\n</td>\n<td>\n1014A\n</td>\n<td>\n\u5357\u53e3\u8def\n</td>\n<td>\n\u5929\u6d25\n</td>\n<td>\n117.1930\n</td>\n<td>\n39.1730\n</td>\n<td>\n84.59091\n</td>\n<td>\n8.5\n</td>\n<td>\n1021.859\n</td>\n<td>\n-0.2894622\n</td>\n<td>\n0.6565141\n</td>\n<td>\n40.61296\n</td>\n<td>\n0.2245625\n</td>\n</tr>\n<tr>\n<td>\n11843\n</td>\n<td>\n1062A\n</td>\n<td>\n\u94c1\u8def\n</td>\n<td>\n\u627f\u5fb7\n</td>\n<td>\n117.9664\n</td>\n<td>\n40.9161\n</td>\n<td>\n21.27273\n</td>\n<td>\n362.0\n</td>\n<td>\n969.876\n</td>\n<td>\n15.3092365\n</td>\n<td>\n0.5288071\n</td>\n<td>\n16.61683\n</td>\n<td>\n0.4272831\n</td>\n</tr>\n<tr>\n<td>\n9373\n</td>\n<td>\n\u6986\u57a1\n</td>\n<td>\n\u4eac\u5357\u6986\u57a1\uff0c\u4eac\u5357\u533a\u57df\u70b9\n</td>\n<td>\n\u5317\u4eac\n</td>\n<td>\n116.3000\n</td>\n<td>\n39.5200\n</td>\n<td>\n12.08696\n</td>\n<td>\n18.0\n</td>\n<td>\n1013.116\n</td>\n<td>\n14.0085974\n</td>\n<td>\n0.8100768\n</td>\n<td>\n39.46079\n</td>\n<td>\n0.5075859\n</td>\n</tr>\n<tr>\n<td>\n19596\n</td>\n<td>\n1069A\n</td>\n<td>\n\u73af\u5883\u76d1\u6d4b\u76d1\u7406\u4e2d\u5fc3\n</td>\n<td>\n\u5eca\u574a\n</td>\n<td>\n116.7150\n</td>\n<td>\n39.5571\n</td>\n<td>\n64.20833\n</td>\n<td>\n35.0\n</td>\n<td>\n1005.249\n</td>\n<td>\n24.4960499\n</td>\n<td>\n0.8604047\n</td>\n<td>\n14.01048\n</td>\n<td>\n1.5149391\n</td>\n</tr>\n</tbody>\n</table>\n###### 2) Set bagging path, list of predictor names, get the bagging class instance and input data:\n<pre><span class=\"kn\">from</span> <span class=\"nn\">baggingrnet.model.bagging</span> <span class=\"kn\">import</span>  <span class=\"n\">multBagging</span>\n<span class=\"kn\">import</span> <span class=\"nn\">random</span> <span class=\"k\">as</span> <span class=\"nn\">r</span> \n<span class=\"n\">feasList</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'lat'</span><span class=\"p\">,</span> <span class=\"s1\">'lon'</span><span class=\"p\">,</span> <span class=\"s1\">'ele'</span><span class=\"p\">,</span> <span class=\"s1\">'prs'</span><span class=\"p\">,</span> <span class=\"s1\">'tem'</span><span class=\"p\">,</span> <span class=\"s1\">'rhu'</span><span class=\"p\">,</span> <span class=\"s1\">'win'</span><span class=\"p\">,</span> <span class=\"s1\">'pblh_re'</span><span class=\"p\">,</span> <span class=\"s1\">'pre_re'</span><span class=\"p\">,</span> <span class=\"s1\">'o3_re'</span><span class=\"p\">,</span> <span class=\"s1\">'aod'</span><span class=\"p\">,</span> <span class=\"s1\">'merra2_re'</span><span class=\"p\">,</span> <span class=\"s1\">'haod'</span><span class=\"p\">,</span>\n         <span class=\"s1\">'shaod'</span><span class=\"p\">,</span> <span class=\"s1\">'jd'</span><span class=\"p\">,</span><span class=\"s1\">'lat2'</span><span class=\"p\">,</span><span class=\"s1\">'lon2'</span><span class=\"p\">,</span><span class=\"s1\">'latlon'</span><span class=\"p\">]</span>\n<span class=\"n\">target</span><span class=\"o\">=</span><span class=\"s1\">'pm25_avg_log'</span>\n<span class=\"n\">bagpath</span><span class=\"o\">=</span><span class=\"s1\">'/tmp/baggingpm25_2/res'</span>\n<span class=\"n\">chkpath</span><span class=\"p\">(</span><span class=\"n\">bagpath</span><span class=\"p\">)</span>\n<span class=\"n\">mbag</span><span class=\"o\">=</span><span class=\"n\">multBagging</span><span class=\"p\">(</span><span class=\"n\">bagpath</span><span class=\"p\">)</span>\n</pre>\n<pre><code>## initializing ...\n</code></pre>\n<pre><span class=\"n\">mbag</span><span class=\"o\">.</span><span class=\"n\">getInputSample</span><span class=\"p\">(</span><span class=\"n\">pm25_train</span><span class=\"p\">,</span> <span class=\"n\">feasList</span><span class=\"p\">,</span><span class=\"kc\">None</span><span class=\"p\">,</span><span class=\"s1\">'gindex'</span><span class=\"p\">,</span><span class=\"n\">target</span><span class=\"p\">)</span>\n</pre>\n<pre><code>## (29475, 31)\n</code></pre>\n<h6>3) Define the arguments of multiple models (here 100 models) and append them to the list of modeling duties:</h6>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">random</span> <span class=\"k\">as</span> <span class=\"nn\">r</span> \n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">81</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">)</span>\n    <span class=\"n\">nodes</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">128</span> <span class=\"o\">+</span> <span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">),</span><span class=\"mi\">128</span><span class=\"o\">+</span> <span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">),</span><span class=\"mi\">96</span><span class=\"p\">,</span><span class=\"mi\">64</span><span class=\"p\">,</span><span class=\"mi\">32</span><span class=\"p\">,</span><span class=\"mi\">12</span><span class=\"p\">]</span>\n    <span class=\"n\">minibatch</span> <span class=\"o\">=</span> <span class=\"mi\">2560</span><span class=\"o\">+</span><span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n    <span class=\"n\">isresidual</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>\n    <span class=\"n\">nepoch</span> <span class=\"o\">=</span> <span class=\"mi\">120</span>\n    <span class=\"n\">sampling_fea</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>\n    <span class=\"n\">noutput</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>\n    <span class=\"n\">islog</span><span class=\"o\">=</span><span class=\"kc\">True</span>\n    <span class=\"n\">mbag</span><span class=\"o\">.</span><span class=\"n\">addTask</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"p\">,</span><span class=\"n\">noutput</span><span class=\"p\">,</span><span class=\"n\">sampling_fea</span><span class=\"p\">,</span> <span class=\"n\">nepoch</span><span class=\"p\">,</span> <span class=\"n\">nodes</span><span class=\"p\">,</span> <span class=\"n\">minibatch</span><span class=\"p\">,</span> <span class=\"n\">isresidual</span><span class=\"p\">,</span><span class=\"n\">islog</span><span class=\"p\">)</span>\n    \n</pre>\n<h6>4) Initiate the training:</h6>\n<p>Initiate the parallel programs using 10 cores</p>\n<pre><span class=\"n\">mbag</span><span class=\"o\">.</span><span class=\"n\">startMProcess</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n</pre>\n<h6>5) Prediction using the trained models and optional evaluation of the trained model:</h6>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">baggingrnet.model.baggingpre</span> <span class=\"kn\">import</span>  <span class=\"n\">ensPrediction</span>\n<span class=\"n\">prepath</span><span class=\"o\">=</span><span class=\"s2\">\"/tmp/baggingpm25_2p/res\"</span>\n<span class=\"n\">chkpath</span><span class=\"p\">(</span><span class=\"n\">prepath</span><span class=\"p\">)</span>\n<span class=\"n\">mbagpre</span><span class=\"o\">=</span><span class=\"n\">ensPrediction</span><span class=\"p\">(</span><span class=\"n\">bagpath</span><span class=\"p\">,</span><span class=\"n\">prepath</span><span class=\"p\">)</span>\n<span class=\"n\">mbagpre</span><span class=\"o\">.</span><span class=\"n\">getInputSample</span><span class=\"p\">(</span><span class=\"n\">pm25_test</span><span class=\"p\">,</span> <span class=\"n\">feasList</span><span class=\"p\">,</span><span class=\"s1\">'gindex'</span><span class=\"p\">)</span>\n<span class=\"n\">mbagpre</span><span class=\"o\">.</span><span class=\"n\">startMProcess</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n<span class=\"n\">mbagpre</span><span class=\"o\">.</span><span class=\"n\">aggPredict</span><span class=\"p\">(</span><span class=\"n\">isval</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span><span class=\"n\">tfld</span><span class=\"o\">=</span><span class=\"s1\">'pm25_davg'</span><span class=\"p\">)</span>\n</pre>\n<p>Finally, the following results were obtaned.</p>\n<p>The results are shown as the following:</p>\n<h6>1) Typical learning curves of non-residual vs. residual models are shown as the following:</h6>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/23eb39353c1154c7afa95ae124542a1fbcdb5add/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6c7370617469616c2f62616767696e67726e65742f6d61737465722f524541444d455f66696c65732f6669677572652d6d61726b646f776e5f6769746875622f756e6e616d65642d6368756e6b2d31392d312e706e67\"></p>\n<h6>2) Mean performance (R2 and RMSE) of the predictions of multiple non-residual vs residual models for the independent dataset :</h6>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8e6b98275c6693f0329a4cd8e148396aa20f0dec/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6c7370617469616c2f62616767696e67726e65742f6d61737465722f524541444d455f66696c65732f6669677572652d6d61726b646f776e5f6769746875622f756e6e616d65642d6368756e6b2d32302d312e706e67\"></p>\n<h6>3) Performance (R2 and RMSE) of the ensembled predictions based on multiple models for the independent dataset:</h6>\n<pre><code>## [1] \"non residual model   r2: 0.88, rmse: 23.55\"\n\n## [1] \"residual model   r2: 0.91, rmse: 20.35\"\n\n## [1] \"Residual model improved R2 by 2.97%, compared with non-residual model\"\n\n## [1] \"Residual model decreased rmse by -3.2, compared with non-residual model\"\n</code></pre>\n<h6>4) Scatter plots for the ensemble predictions of non-residual vs residual models:</h6>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b5f043b760539216bffb22a7685e8bf42edf63dd/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6c7370617469616c2f62616767696e67726e65742f6d61737465722f524541444d455f66696c65732f6669677572652d6d61726b646f776e5f6769746875622f756e6e616d65642d6368756e6b2d32322d312e706e67\"></p>\n<h6>5) Comparison of ensemble predictions vs. predictions of single models:</h6>\n<p>Statistics of the performance for the predictions of multiple models and ensemble predictions are made. The following shows R<sup>2</sup> and RMSE, barplots and scatter plots.</p>\n<p>Performance digits:</p>\n<pre><code>## [1] \"Ensemble predictions: R2=0.91, RMSE=20.35\"\n\n## [1] \"Mean performance of predictions of multiple single models: R2=0.86, RMSE=26.07\"\n\n## [1] \"Ensemble predictions averagely improved the single predictions by 6% for R2, and reduced -5.72ug/m3 for RMSE\"\n</code></pre>\n<p>The boxplot shows considerable improvement by bagging (6% in R<sup>2</sup> and -5.72 <em>\u03bc</em>g/m<sup>3</sup>), in comparison with single models.</p>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/35eb5c2a425a8d47c7f77109c30639015367113f/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6c7370617469616c2f62616767696e67726e65742f6d61737465722f524541444d455f66696c65732f6669677572652d6d61726b646f776e5f6769746875622f756e6e616d65642d6368756e6b2d32342d312e706e67\"></p>\n<p>The following shows the scatter plots of observed PM<sub>2.5</sub> vs. ensemble predictions/residuals:</p>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4ecd6543382dd22f6f839ca8cc1ff0ee89691533/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6c7370617469616c2f62616767696e67726e65742f6d61737465722f524541444d455f66696c65732f6669677572652d6d61726b646f776e5f6769746875622f756e6e616d65642d6368756e6b2d32352d312e706e67\"></p>\n<h3>Contact</h3>\n<p>For this library and its relevant complete applications, welcome to contact Dr. Lianfa Li. Email: <a href=\"mailto:lspatial@gmail.com\">lspatial@gmail.com</a> or  <a href=\"mailto:lilf@lreis.ac.cn\">lilf@lreis.ac.cn</a></p>\n\n          </div>"}, "last_serial": 5660568, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "8b3593123b5028fa90778a1b46f83ce9", "sha256": "cc502c5761ad6ae238aaa0dcdb2bfbd55c12cc58086286756f904d205b7248cc"}, "downloads": -1, "filename": "baggingrnet-0.0.1.tar.gz", "has_sig": false, "md5_digest": "8b3593123b5028fa90778a1b46f83ce9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6144588, "upload_time": "2019-08-10T06:25:55", "upload_time_iso_8601": "2019-08-10T06:25:55.137829Z", "url": "https://files.pythonhosted.org/packages/1a/43/ee6bf2bd7969f3c8bf1aeab8dfb6397ce8e3cdb877751bee31fa700d221a/baggingrnet-0.0.1.tar.gz", "yanked": false}], "0.0.10": [{"comment_text": "", "digests": {"md5": "a6fdb397c9ac03cbdaf638cc3378b170", "sha256": "fb78798747c4f14bbb1b6bbca03b9eb3b30ed7c8260a5d311d47ef36f956e1d3"}, "downloads": -1, "filename": "baggingrnet-0.0.10.tar.gz", "has_sig": false, "md5_digest": "a6fdb397c9ac03cbdaf638cc3378b170", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6142894, "upload_time": "2019-08-10T22:05:11", "upload_time_iso_8601": "2019-08-10T22:05:11.830973Z", "url": "https://files.pythonhosted.org/packages/3a/c0/54705e01d0d3abd67a0eeb7d93542d541140820c0aaef1295845cd01ac87/baggingrnet-0.0.10.tar.gz", "yanked": false}], "0.0.11": [{"comment_text": "", "digests": {"md5": "3d70afe3dc7629a72edf3ade672a28d1", "sha256": "4207af787e46ae448d56696a711f584773b50ba12991407387869dfd4a715825"}, "downloads": -1, "filename": "baggingrnet-0.0.11.tar.gz", "has_sig": false, "md5_digest": "3d70afe3dc7629a72edf3ade672a28d1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6142815, "upload_time": "2019-08-10T22:29:37", "upload_time_iso_8601": "2019-08-10T22:29:37.571031Z", "url": "https://files.pythonhosted.org/packages/f1/df/6e36d9632cc6001f579c231a1c1a3314144b9f59b192b7e3ae102cf2c478/baggingrnet-0.0.11.tar.gz", "yanked": false}], "0.0.12": [{"comment_text": "", "digests": {"md5": "4c4bba735cccbeb4f0d369de752bf1ec", "sha256": "7b50a114558e494dce63a047120b90c610b7d88adb71529397419ba0f759130b"}, "downloads": -1, "filename": "baggingrnet-0.0.12.tar.gz", "has_sig": false, "md5_digest": "4c4bba735cccbeb4f0d369de752bf1ec", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6142805, "upload_time": "2019-08-10T23:42:54", "upload_time_iso_8601": "2019-08-10T23:42:54.566207Z", "url": "https://files.pythonhosted.org/packages/25/e7/0de1749d6dfd19cadd61b3435cb10cccc66d2ac39a4d573bfe3018aa3860/baggingrnet-0.0.12.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "52ca953efd495e35c680a7050589f0da", "sha256": "42ecd1c908f948c7f6d229d8bfe12b69499d3ff8450d1cd9d5935e35e8102602"}, "downloads": -1, "filename": "baggingrnet-0.0.2.tar.gz", "has_sig": false, "md5_digest": "52ca953efd495e35c680a7050589f0da", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6144677, "upload_time": "2019-08-10T06:31:54", "upload_time_iso_8601": "2019-08-10T06:31:54.244934Z", "url": "https://files.pythonhosted.org/packages/18/e0/73de411fbb3cafedadea141c825d4d2f0fe3aafbeca33a002dd936fe2fb3/baggingrnet-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "c07c1196fa5681dbd321e0c1474b3608", "sha256": "a799a2376ecca8c977b28d474e5bcf64ac8002471fc7bf3dc090e36e3bcaa5b9"}, "downloads": -1, "filename": "baggingrnet-0.0.3.tar.gz", "has_sig": false, "md5_digest": "c07c1196fa5681dbd321e0c1474b3608", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6144624, "upload_time": "2019-08-10T06:38:32", "upload_time_iso_8601": "2019-08-10T06:38:32.550275Z", "url": "https://files.pythonhosted.org/packages/40/e3/45d9a4e2a7a0e632004b793c0980ca6c2226c00c8ba6e7e7a4033a55d420/baggingrnet-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "c8f5f7dcce35554059682bb7239893a7", "sha256": "e4bf3e2688750f90591607cb355dd51419316bf1aaf76b5a692276486cb26356"}, "downloads": -1, "filename": "baggingrnet-0.0.4.tar.gz", "has_sig": false, "md5_digest": "c8f5f7dcce35554059682bb7239893a7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6144692, "upload_time": "2019-08-10T06:51:26", "upload_time_iso_8601": "2019-08-10T06:51:26.241511Z", "url": "https://files.pythonhosted.org/packages/08/78/e348b5d4b66a59d1985fbd0fed1fb6a3c463e73d30118f50c52c775b76e0/baggingrnet-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "a2b4bcfc3ba5c2908da8e70f74feaf61", "sha256": "cbbcf73f42e06950c643a247103030743cc06c56302b7e51e6a8564585d93683"}, "downloads": -1, "filename": "baggingrnet-0.0.5.tar.gz", "has_sig": false, "md5_digest": "a2b4bcfc3ba5c2908da8e70f74feaf61", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6144696, "upload_time": "2019-08-10T06:54:45", "upload_time_iso_8601": "2019-08-10T06:54:45.849194Z", "url": "https://files.pythonhosted.org/packages/e3/dd/e4735bd3abfa6b32ced88bb09e092b3753f336475c94d10b4bcb79c668fe/baggingrnet-0.0.5.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "a70163f2a15b459d54bc1f7fa4beb565", "sha256": "901aa49f812c13098812452e35c034af1c7974a906c0afeda2bbadbc0882796e"}, "downloads": -1, "filename": "baggingrnet-0.0.6.tar.gz", "has_sig": false, "md5_digest": "a70163f2a15b459d54bc1f7fa4beb565", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6142050, "upload_time": "2019-08-10T07:01:25", "upload_time_iso_8601": "2019-08-10T07:01:25.341996Z", "url": "https://files.pythonhosted.org/packages/9a/49/b2fcc655dc13b1e8d76b378f7e46ba4539f24024b9f514fb2cb0d779025d/baggingrnet-0.0.6.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "7e63fcbb4ae592852be280fcb40e11f4", "sha256": "51c6f6169af4c655fc39fe4dd346852c6fb585d7024e01f126a85c0551b22980"}, "downloads": -1, "filename": "baggingrnet-0.0.7.tar.gz", "has_sig": false, "md5_digest": "7e63fcbb4ae592852be280fcb40e11f4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6142813, "upload_time": "2019-08-10T21:25:43", "upload_time_iso_8601": "2019-08-10T21:25:43.363285Z", "url": "https://files.pythonhosted.org/packages/d1/da/3017d0f14e3e4eac4f24c127d9ec37f53fa78509bbe3b9567091a08c9f04/baggingrnet-0.0.7.tar.gz", "yanked": false}], "0.0.8": [{"comment_text": "", "digests": {"md5": "8acf5b38e8266e8ada715cf1d6782373", "sha256": "c13c2f7580a079c50f1aa4a34d3c4cd73280fb142c9db80b4adf84f48cb59f1a"}, "downloads": -1, "filename": "baggingrnet-0.0.8.tar.gz", "has_sig": false, "md5_digest": "8acf5b38e8266e8ada715cf1d6782373", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6142853, "upload_time": "2019-08-10T21:30:34", "upload_time_iso_8601": "2019-08-10T21:30:34.079012Z", "url": "https://files.pythonhosted.org/packages/67/b7/d220c2aa6c73cc3aea40fecf2cbce6b0016b955816f72d17b29896676f55/baggingrnet-0.0.8.tar.gz", "yanked": false}], "0.0.9": [{"comment_text": "", "digests": {"md5": "ea46681770939f9735e2ca9fda89d91e", "sha256": "ace0849c95f28703ab9594dc62aacc194a76775d4e09ca532be8d0171ef13ff8"}, "downloads": -1, "filename": "baggingrnet-0.0.9.tar.gz", "has_sig": false, "md5_digest": "ea46681770939f9735e2ca9fda89d91e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6142844, "upload_time": "2019-08-10T21:36:09", "upload_time_iso_8601": "2019-08-10T21:36:09.158138Z", "url": "https://files.pythonhosted.org/packages/ec/7a/fc15699c2c9f0f6af78723ce82f3b135c86165101a07dc7fe2e18959a779/baggingrnet-0.0.9.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "4c4bba735cccbeb4f0d369de752bf1ec", "sha256": "7b50a114558e494dce63a047120b90c610b7d88adb71529397419ba0f759130b"}, "downloads": -1, "filename": "baggingrnet-0.0.12.tar.gz", "has_sig": false, "md5_digest": "4c4bba735cccbeb4f0d369de752bf1ec", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6142805, "upload_time": "2019-08-10T23:42:54", "upload_time_iso_8601": "2019-08-10T23:42:54.566207Z", "url": "https://files.pythonhosted.org/packages/25/e7/0de1749d6dfd19cadd61b3435cb10cccc66d2ac39a4d573bfe3018aa3860/baggingrnet-0.0.12.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:15:04 2020"}