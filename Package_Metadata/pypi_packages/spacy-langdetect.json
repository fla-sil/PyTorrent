{"info": {"author": "Abhijit Balaji", "author_email": "balaabhijit5@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# spacy-langdetect\nFully customizable language detection pipeline for [spaCy](https://github.com/explosion/spaCy)\n\n## Installation\n`pip install spacy-langdetect`\n\n## NOTE:\nRequires spaCy >= 2.0. This dependency is removed in `pip install spacy-langdetect` so that it can be used with `nightly` versions also\n\n## Basic usage\nOut of the box, under the hood it uses [langdetect](https://github.com/Mimino666/langdetect) to detect languages on spaCy's Doc and Span objects.\n\n```python\nimport spacy\nfrom spacy_langdetect import LanguageDetector\nnlp = spacy.load(\"en\")\nnlp.add_pipe(LanguageDetector(), name=\"language_detector\", last=True)\ntext = \"This is English text. Er lebt mit seinen Eltern und seiner Schwester in Berlin. Yo me divierto todos los d\u00edas en el parque. Je m'appelle Ang\u00e9lica Summer, j'ai 12 ans et je suis canadienne.\"\ndoc = nlp(text)\n# document level language detection. Think of it like average language of document!\nprint(doc._.language)\n# sentence level language detection\nfor i, sent in enumerate(doc.sents):\n    print(sent, sent._.language)\n```\n\n## Using your own language detector\nSuppose you are not happy with the accuracy of the out of the box language detector or you have your own language detector which you want to use with spaCy pipeline. How do you do it? That's where the `language_detection_function` argument comes in. The function takes in a Spacy Doc or Span object and can return any python object which is stored in `doc._.language` and `span._.language`. For example, let's say you want to use [googletrans](https://pypi.org/project/googletrans/) as your language detection module:\n\n```python\nimport spacy\nfrom spacy.tokens import Doc, Span\nfrom spacy_langdetect import LanguageDetector\n# install using pip install googletrans\nfrom googletrans import Translator\nnlp = spacy.load(\"en\")\n\ndef custom_detection_function(spacy_object):\n    # custom detection function should take a Spacy Doc or a\n    assert isinstance(spacy_object, Doc) or isinstance(\n        spacy_object, Span), \"spacy_object must be a spacy Doc or Span object but it is a {}\".format(type(spacy_object))\n    detection = Translator().detect(spacy_object.text)\n    return {'language':detection.lang, 'score':detection.confidence}\n\nnlp.add_pipe(LanguageDetector(language_detection_function=custom_detection_function), name=\"language_detector\", last=True)\ntext = \"This is English text. Er lebt mit seinen Eltern und seiner Schwester in Berlin. Yo me divierto todos los d\u00edas en el parque. Je m'appelle Ang\u00e9lica Summer, j'ai 12 ans et je suis canadienne.\"\ndoc = nlp(text)\n# document level language detection. Think of it like average language of document!\nprint(doc._.language)\n# sentence level language detection\nfor i, sent in enumerate(doc.sents):\n    print(sent, sent._.language)\n```\nSimilarly you can also use [pycld2](https://pypi.org/project/pycld2/) and other language detectors with spaCy\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Abhijit-2592/spacy-langdetect", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "spacy-langdetect", "package_url": "https://pypi.org/project/spacy-langdetect/", "platform": "", "project_url": "https://pypi.org/project/spacy-langdetect/", "project_urls": {"Homepage": "https://github.com/Abhijit-2592/spacy-langdetect"}, "release_url": "https://pypi.org/project/spacy-langdetect/0.1.2/", "requires_dist": ["pytest", "langdetect (==1.0.7)"], "requires_python": "", "summary": "Fully customizable language detection pipeline for spaCy", "version": "0.1.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>spacy-langdetect</h1>\n<p>Fully customizable language detection pipeline for <a href=\"https://github.com/explosion/spaCy\" rel=\"nofollow\">spaCy</a></p>\n<h2>Installation</h2>\n<p><code>pip install spacy-langdetect</code></p>\n<h2>NOTE:</h2>\n<p>Requires spaCy &gt;= 2.0. This dependency is removed in <code>pip install spacy-langdetect</code> so that it can be used with <code>nightly</code> versions also</p>\n<h2>Basic usage</h2>\n<p>Out of the box, under the hood it uses <a href=\"https://github.com/Mimino666/langdetect\" rel=\"nofollow\">langdetect</a> to detect languages on spaCy's Doc and Span objects.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">spacy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">spacy_langdetect</span> <span class=\"kn\">import</span> <span class=\"n\">LanguageDetector</span>\n<span class=\"n\">nlp</span> <span class=\"o\">=</span> <span class=\"n\">spacy</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s2\">\"en\"</span><span class=\"p\">)</span>\n<span class=\"n\">nlp</span><span class=\"o\">.</span><span class=\"n\">add_pipe</span><span class=\"p\">(</span><span class=\"n\">LanguageDetector</span><span class=\"p\">(),</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">\"language_detector\"</span><span class=\"p\">,</span> <span class=\"n\">last</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"s2\">\"This is English text. Er lebt mit seinen Eltern und seiner Schwester in Berlin. Yo me divierto todos los d\u00edas en el parque. Je m'appelle Ang\u00e9lica Summer, j'ai 12 ans et je suis canadienne.\"</span>\n<span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"n\">nlp</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">)</span>\n<span class=\"c1\"># document level language detection. Think of it like average language of document!</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">doc</span><span class=\"o\">.</span><span class=\"n\">_</span><span class=\"o\">.</span><span class=\"n\">language</span><span class=\"p\">)</span>\n<span class=\"c1\"># sentence level language detection</span>\n<span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">sent</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">doc</span><span class=\"o\">.</span><span class=\"n\">sents</span><span class=\"p\">):</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">sent</span><span class=\"p\">,</span> <span class=\"n\">sent</span><span class=\"o\">.</span><span class=\"n\">_</span><span class=\"o\">.</span><span class=\"n\">language</span><span class=\"p\">)</span>\n</pre>\n<h2>Using your own language detector</h2>\n<p>Suppose you are not happy with the accuracy of the out of the box language detector or you have your own language detector which you want to use with spaCy pipeline. How do you do it? That's where the <code>language_detection_function</code> argument comes in. The function takes in a Spacy Doc or Span object and can return any python object which is stored in <code>doc._.language</code> and <code>span._.language</code>. For example, let's say you want to use <a href=\"https://pypi.org/project/googletrans/\" rel=\"nofollow\">googletrans</a> as your language detection module:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">spacy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">spacy.tokens</span> <span class=\"kn\">import</span> <span class=\"n\">Doc</span><span class=\"p\">,</span> <span class=\"n\">Span</span>\n<span class=\"kn\">from</span> <span class=\"nn\">spacy_langdetect</span> <span class=\"kn\">import</span> <span class=\"n\">LanguageDetector</span>\n<span class=\"c1\"># install using pip install googletrans</span>\n<span class=\"kn\">from</span> <span class=\"nn\">googletrans</span> <span class=\"kn\">import</span> <span class=\"n\">Translator</span>\n<span class=\"n\">nlp</span> <span class=\"o\">=</span> <span class=\"n\">spacy</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s2\">\"en\"</span><span class=\"p\">)</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">custom_detection_function</span><span class=\"p\">(</span><span class=\"n\">spacy_object</span><span class=\"p\">):</span>\n    <span class=\"c1\"># custom detection function should take a Spacy Doc or a</span>\n    <span class=\"k\">assert</span> <span class=\"nb\">isinstance</span><span class=\"p\">(</span><span class=\"n\">spacy_object</span><span class=\"p\">,</span> <span class=\"n\">Doc</span><span class=\"p\">)</span> <span class=\"ow\">or</span> <span class=\"nb\">isinstance</span><span class=\"p\">(</span>\n        <span class=\"n\">spacy_object</span><span class=\"p\">,</span> <span class=\"n\">Span</span><span class=\"p\">),</span> <span class=\"s2\">\"spacy_object must be a spacy Doc or Span object but it is a </span><span class=\"si\">{}</span><span class=\"s2\">\"</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"nb\">type</span><span class=\"p\">(</span><span class=\"n\">spacy_object</span><span class=\"p\">))</span>\n    <span class=\"n\">detection</span> <span class=\"o\">=</span> <span class=\"n\">Translator</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">detect</span><span class=\"p\">(</span><span class=\"n\">spacy_object</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"p\">{</span><span class=\"s1\">'language'</span><span class=\"p\">:</span><span class=\"n\">detection</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"p\">,</span> <span class=\"s1\">'score'</span><span class=\"p\">:</span><span class=\"n\">detection</span><span class=\"o\">.</span><span class=\"n\">confidence</span><span class=\"p\">}</span>\n\n<span class=\"n\">nlp</span><span class=\"o\">.</span><span class=\"n\">add_pipe</span><span class=\"p\">(</span><span class=\"n\">LanguageDetector</span><span class=\"p\">(</span><span class=\"n\">language_detection_function</span><span class=\"o\">=</span><span class=\"n\">custom_detection_function</span><span class=\"p\">),</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">\"language_detector\"</span><span class=\"p\">,</span> <span class=\"n\">last</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"s2\">\"This is English text. Er lebt mit seinen Eltern und seiner Schwester in Berlin. Yo me divierto todos los d\u00edas en el parque. Je m'appelle Ang\u00e9lica Summer, j'ai 12 ans et je suis canadienne.\"</span>\n<span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"n\">nlp</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">)</span>\n<span class=\"c1\"># document level language detection. Think of it like average language of document!</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">doc</span><span class=\"o\">.</span><span class=\"n\">_</span><span class=\"o\">.</span><span class=\"n\">language</span><span class=\"p\">)</span>\n<span class=\"c1\"># sentence level language detection</span>\n<span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">sent</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">doc</span><span class=\"o\">.</span><span class=\"n\">sents</span><span class=\"p\">):</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">sent</span><span class=\"p\">,</span> <span class=\"n\">sent</span><span class=\"o\">.</span><span class=\"n\">_</span><span class=\"o\">.</span><span class=\"n\">language</span><span class=\"p\">)</span>\n</pre>\n<p>Similarly you can also use <a href=\"https://pypi.org/project/pycld2/\" rel=\"nofollow\">pycld2</a> and other language detectors with spaCy</p>\n\n          </div>"}, "last_serial": 5215583, "releases": {"0.1.1": [{"comment_text": "", "digests": {"md5": "cbb950e2a0a66573b06e635bc7712699", "sha256": "731d90e422b2237efedbec5a9f1abab18bc185b51588fff07f61a48238281a95"}, "downloads": -1, "filename": "spacy_langdetect-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "cbb950e2a0a66573b06e635bc7712699", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6059, "upload_time": "2019-02-12T14:34:27", "upload_time_iso_8601": "2019-02-12T14:34:27.848163Z", "url": "https://files.pythonhosted.org/packages/46/4c/3fdf892237cbcbd6b9ff30aedc4fb5f8a804a94ec7933b16126306fff5eb/spacy_langdetect-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e5ad4d684d601b13a70961512fe2dc67", "sha256": "1a2a5d4f3d2861f5cd0e3fe4eb041f26d4579416de00a28e5f76392544dcb0d9"}, "downloads": -1, "filename": "spacy-langdetect-0.1.1.tar.gz", "has_sig": false, "md5_digest": "e5ad4d684d601b13a70961512fe2dc67", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3038, "upload_time": "2019-02-12T14:34:29", "upload_time_iso_8601": "2019-02-12T14:34:29.291603Z", "url": "https://files.pythonhosted.org/packages/b9/d5/146d41f4008b6d1d6abe0479630bb74bf5c04d73fe501138c0cc8ea4eddf/spacy-langdetect-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "42ec70afe4e200cf0110b341c117b803", "sha256": "fb77878fb2445933cb6db836fc20a0d712fa685e1bd7e3b6a447d0556e54ebde"}, "downloads": -1, "filename": "spacy_langdetect-0.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "42ec70afe4e200cf0110b341c117b803", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 5012, "upload_time": "2019-05-02T06:47:23", "upload_time_iso_8601": "2019-05-02T06:47:23.473604Z", "url": "https://files.pythonhosted.org/packages/29/70/72dad19abe81ca8e85ff951da170915211d42d705a001d7e353af349a704/spacy_langdetect-0.1.2-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "42ec70afe4e200cf0110b341c117b803", "sha256": "fb77878fb2445933cb6db836fc20a0d712fa685e1bd7e3b6a447d0556e54ebde"}, "downloads": -1, "filename": "spacy_langdetect-0.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "42ec70afe4e200cf0110b341c117b803", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 5012, "upload_time": "2019-05-02T06:47:23", "upload_time_iso_8601": "2019-05-02T06:47:23.473604Z", "url": "https://files.pythonhosted.org/packages/29/70/72dad19abe81ca8e85ff951da170915211d42d705a001d7e353af349a704/spacy_langdetect-0.1.2-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 03:06:05 2020"}