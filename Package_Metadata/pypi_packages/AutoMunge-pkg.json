{"info": {"author": "Nicholas Teague", "author_email": "pitg888@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: GNU General Public License v3 (GPLv3)", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# Automunge Package\n# \nAutomunge is a tool for automating the final steps of data wrangling of\nstructured (tabular) data prior to the application of machine learning.\nThe automunge(.) function takes as input structured training data intended \nto train a machine learning model with any corresponding labels if available \nincluded in the set, and also if available consistently formatted test data \nthat can then be used to generate predictions from that trained model. When \nfed pandas dataframes or numpy arrays for these sets the function returns a \nseries of transformed numpy arrays or pandas dataframes per a selection which \nare numerically encoded and suitable for the direct application of machine \nlearning algorithms. A user has an option between default feature engineering \nbased on inferred properties of the data with feature transformations such as \nz score normalization, standard deviation bins for numerical sets, box-cox \npower law transform for all positive numerical sets, one-hot encoding for \ncategorical sets, and more (full documentation below), assigning specific \ncolumn feature engineering methods using a built in library of feature \nengineering transformations, or alternatively the passing of user-defined \ncustom transformation functions incorporating simple data structures such as \nto allow custom methods to each column while still making use of all of the \nbuilt-in features of the tool (such as ML infill, feature importance, \ndimensionality reduction, and most importantly the simplest way for the \nconsistent processing of subsequently available data using just a single \nfunction call of the postmunge(.) function). Missing data points in the sets \nare also available to be addressed by either assigning distinct methods to \neach column or alternatively by the automated \"ML infill\" method which \npredicts infill using machine learning models trained on the rest of the set \nin a fully generalized and automated fashion. automunge(.) returns a python \ndictionary which can be used as an input along with a subsequent test data \nset to the function postmunge(.) for  consistent processing of test data \nwhich wasn't available for the initial address.\n\nIn addition to it's use for feature engineering transformations, automunge(.) \nalso can serve an evaluatory purpose by way of a feature importance evaluation \nthrough the derivation of two metrics which provide an indication for the \nimportance of original and derived features towards the accuracy of a \npredictive model.\n\nIf elected, a user can also use the tool to perform a dimensionality reduction \nvia principle component analysis (a type of entity embedding via unsupervised \nlearning) of the data sets with the automunge(.) function or consistently for \nsubsequently available data with the postmunge(.) function.\n\nAutoMunge is now available for free pip install for your open source\npython data-wrangling\n\n```\npip install AutoMunge-pkg\n```\n\n```\n#or to upgrade (we currently roll out upgrades pretty frequently)\npip install AutoMunge-pkg --upgrade\n```\n\nOnce installed, run this in a local session to initialize:\n\n```\nfrom AutoMunge_pkg import AutoMunge\nam = AutoMunge.AutoMunge()\n```\n\nWhere eg for train/test set processing run:\n\n```\ntrain, trainID, labels, \\\nvalidation1, validationID1, validationlabels1, \\\nvalidation2, validationID2, validationlabels2, \\\ntest, testID, testlabels, \\\ntestlabelsencoding_dict, finalcolumns_train, finalcolumns_test, \\\nfeatureimportance, postprocess_dict \\\n= am.automunge(df_train, df_test, etc)\n```\n\nor for subsequent consistant processing of test data, using the\ndictionary returned from original application of automunge(.), run:\n\n```\ntest, testID, testlabels, \\\nlabelsencoding_dict, finalcolumns_test \\ =\nam.postmunge(postprocess_dict, df_test)\n```\n\nI find it helpful to pass these functions with the full range of arguments\nincluded for reference, thus a user may simply copy and past this form.\n\n```\n#for automunge(.) function on original train and test data\n\ntrain, trainID, labels, \\\nvalidation1, validationID1, validationlabels1, \\\nvalidation2, validationID2, validationlabels2, \\\ntest, testID, testlabels, \\\nlabelsencoding_dict, finalcolumns_train, finalcolumns_test, \\\nfeatureimportance, postprocess_dict = \\\nam.automunge(df_train, df_test = False, labels_column = False, trainID_column = False, \\\n            testID_column = False, valpercent1=0.0, valpercent2 = 0.0, floatprecision = 32, \\\n            shuffletrain = False, TrainLabelFreqLevel = False, powertransform = False, \\\n            binstransform = False, MLinfill = False, infilliterate=1, randomseed = 42, \\\n            numbercategoryheuristic = 15, pandasoutput = True, NArw_marker = True, \\\n            featureselection = False, featurepct = 1.0, featuremetric = .02, \\\n            featuremethod = 'default', PCAn_components = None, PCAexcl = [], \\\n            ML_cmnd = {'MLinfill_type':'default', \\\n                       'MLinfill_cmnd':{'RandomForestClassifier':{}, 'RandomForestRegressor':{}}, \\\n                       'PCA_type':'default', \\\n                       'PCA_cmnd':{}}, \\\n       \t    assigncat = {'mnmx':[], 'mnm2':[], 'mnm3':[], 'mnm4':[], 'mnm5':[], 'mnm6':[], \\\n\t\t         'nmbr':[], 'nbr2':[], 'nbr3':[], 'MADn':[], 'MAD2':[], 'MAD3':[], \\\n\t\t     \t 'bins':[], 'bint':[], \\\n\t\t         'bxcx':[], 'bxc2':[], 'bxc3':[], 'bxc4':[], \\\n\t\t         'log0':[], 'log1':[], 'pwrs':[], \\\n\t\t         'bnry':[], 'text':[], '1010':[], 'or10':[], 'om10':[], \\\n\t\t         'ordl':[], 'ord2':[], 'ord3':[], 'ord4':[], 'mmor':[], \\\n\t\t         'date':[], 'dat2':[], 'dat6':[], 'wkdy':[], 'bshr':[], 'hldy':[], \\\n\t\t         'yea2':[], 'mnt2':[], 'mnt6':[], 'day2':[], 'day5':[], \\\n\t\t         'hrs2':[], 'hrs4':[], 'min2':[], 'min4':[], 'scn2':[], \\\n\t\t         'excl':[], 'exc2':[], 'exc3':[], 'null':[], 'eval':[]}, \\\n            assigninfill = {'stdrdinfill':[], 'MLinfill':[], 'zeroinfill':[], 'oneinfill':[], \\\n                            'adjinfill':[], 'meaninfill':[], 'medianinfill':[], 'modeinfill':[]}, \\\n            transformdict = {}, processdict = {}, \\\n            printstatus = True)\n\n```\n\nPlease remember to save the automunge(.) returned object postprocess_dict \nsuch as using pickle library, which can then be later passed to the postmunge(.) \nfunction to consistently process subsequently available data.\n\n```\n#for postmunge(.) function on subsequently available test data\n#using the postprocess_dict object returned from original automunge(.) application\n\ntest, testID, testlabels, \\\nlabelsencoding_dict, finalcolumns_test = \\\nam.postmunge(postprocess_dict, df_test, testID_column = False, \\\n             labelscolumn = False, pandasoutput=True, printstatus = True, \\\n             TrainLabelFreqLevel = False, featureeval = False)\n```\n\n\nThe functions depend on pandas dataframe formatted train and test data\nor numpy arrays with consistent order of columns. The functions return \nnumpy arrays or pandas dataframes numerically encoded and normalized such \nas to make them suitable for direct application to a machine learning model \nin the framework of a user's choice, including sets for the various activities\nof a generic machine learning project such as training, hyperparameter tuning\nvalidation (validation1), final  validation (validation2), or data intended \nfor use in generation of predictions from the trained model (test set). The\nfunctions also return a few other sets such as labels, column headers,\nID sets, and etc if elected - a full list of returned arrays is below.\n\nWhen left to automation, the function works by inferring a category of \ndata based on properties of each column to select the type of processing \nfunction to apply, for example whether a column is a numerical, categorical,\nbinary, or time-series set. Alternately, a user can pass column header IDs to \nassign specific processing functions to distinct columns - which processing functions\nmay be pulled from the internal library of transformations or alternately user\ndefined. Normalization parameters from the initial automunge application are\nsaved to a returned dictionary for subsequent consistent processing of test data\nthat wasn't available at initial address with the postmunge(.) function. \n\nThe feature engineering transformations are recorded with a series of suffixes \nappended to the column header title in the returned sets, for example the \napplication of z-score normalization returns a column with header origname + _ + nmbr. \nThe function allows feature engineering methods for the training data, test data,\nand any column designated for labels if included with the sets.\n\nIn automation, for numerical data, the functions generate a series of derived\ntransformations resulting in multiple child columns. For numerical data, if the\npowertransform option is selected distribution properties are evaluated for \npotential application of z-score normalization, min-max scaling, power law transform \nvia box-cox method, or mean absolute deviation scaling. Otherwise numerical data \ndefaults to z-score, with z-score normalization options for standard\ndeviation bins for values in range <-2, -2-1, -10, 01, 12, >2 from the\nmean. For numerical sets with all positive values the functions also optionally can \nreturn a power-law transformed set using the box-cox method, along with\na corresponding set with z-score normalization applied. For time-series\ndata the model segregates the data by time-scale (year, month, day,\nhour, minute, second) and returns a set for each with z-score\nnormalization applied. For binary categorical data the functions\nreturn a single column with 1/0 designation. For multimodal categorical\ndata the functions return one-hot encoded sets using the naming\nconvention origname + _ + category. (I believe this automation of the\none-hot encoding method to be a particularily useful feature of the\ntool.) For all cases the functions generate a supplemental column (NArw)\nwith a boolean identifier for cells that were subject to infill due to\nmissing or improperly formatted data. (Please note that I don't\nconsider the current methods of numerical set distribution evaluation very \nsophisticated and have some work to do here). \n\nThe functions also include a method we call 'ML infill' which if elected\npredicts infill for missing values in both the train and test sets using\nmachine learning models trained on the rest of the set in a fuly\ngeneralized and automated fashion. The ML infill works by initially\napplying infill using traditional methods such as mean for a numerical\nset, most common value for a binary set, and a boolean identifier for\ncategorical. The functions then generate a column specific set of\ntraining data, labels, and feature sets for the derivation of infill.\nThe column's trained model is included in the outputted dictionary for\napplication of the same model in the postmunge function. Alternately, a\nuser can pass column headers to assign different infill methods to distinct \ncolumns.\n\nThe automunge(.) function also includes a method for feature importance \nevaluation, in which metrics are derived to measure the impact to predictive \naccuracy of original source columns as well as relative importance of \nderived columns using a permutation importance method. Permutation importance \nmethod was inspired by a fast.ai lecture and more information can be found in \nthe paper \"Beware Default Random Forest Importances\" by Terrence Parr, Kerem \nTurgutlu, Christopher Csiszar, and Jeremy Howard. This method currently makes \nuse of Scikit-Learns Random Forest predictors.\n\nThe function also includes a method we call 'LabelFreqLevel' which\nif elected applies multiples of the feature sets associated with each\nlabel category in the returned training data so as to enable\noversampling of those labels which may be underrepresented in the\ntraining data. This method is available for categorical labels or also\nfor numerical labels when the label processing includes standard deviation\nbins. This method is expected to improve downstream model\naccuracy for training data with uneven distribution of labels. For more\non the class imbalance problem see \"A systematic study of the class imbalance \nproblem in convolutional neural networks\" - Buda, Maki, Mazurowski.\n\nThe function also can perform dimensionality reduction of the sets via \nprinciple component analysis (PCA). The function automatically performs a \ntransformation when the number of features is more than 50% of the number\nof observations in the train set (this is a somewhat arbitrary heuristic).\nAlternately, the user can pass a desired number of features and their \npreference of type and parameters between linear PCA, Sparse PCA, or Kernel \nPCA - all currently implemented in Scikit-Learn.\n\nThe application of the automunge and postmunge functions requires the\nassignment of the function to a series of named sets. We suggest using\nconsistent naming convention as follows:\n\n```\ntrain, trainID, labels, \\\nvalidation1, validationID1, validationlabels1, \\\nvalidation2, validationID2, validationlabels2, \\ \ntest, testID, testlabels, \\\nlabelsencoding_dict, finalcolumns_train, finalcolumns_test, \\\nfeatureimportance, postprocess_dict \\\n= am.automunge(df_train, ...)\n```\n\nThe full set of arguments available to be passed are given here, with\nexplanations provided below: \n\n```\ntrain, trainID, labels, \\\nvalidation1, validationID1, validationlabels1, \\\nvalidation2, validationID2, validationlabels2, \\\ntest, testID, testlabels, \\\nlabelsencoding_dict, finalcolumns_train, finalcolumns_test, \\\nfeatureimportance, postprocess_dict = \\\nam.automunge(df_train, df_test = False, labels_column = False, trainID_column = False, \\\n            testID_column = False, valpercent1=0.0, valpercent2 = 0.0, floatprecision = 32, \\\n            shuffletrain = False, TrainLabelFreqLevel = False, powertransform = False, \\\n            binstransform = False, MLinfill = False, infilliterate=1, randomseed = 42, \\\n            numbercategoryheuristic = 15, pandasoutput = True, NArw_marker = True, \\\n            featureselection = False, featurepct = 1.0, featuremetric = .02, \\\n            featuremethod = 'default', PCAn_components = None, PCAexcl = [], \\\n            ML_cmnd = {'MLinfill_type':'default', \\\n                       'MLinfill_cmnd':{'RandomForestClassifier':{}, 'RandomForestRegressor':{}}, \\\n                       'PCA_type':'default', \\\n                       'PCA_cmnd':{}}, \\\n       \t    assigncat = {'mnmx':[], 'mnm2':[], 'mnm3':[], 'mnm4':[], 'mnm5':[], 'mnm6':[], \\\n\t\t         'nmbr':[], 'nbr2':[], 'nbr3':[], 'MADn':[], 'MAD2':[], 'MAD3':[], \\\n\t\t     \t 'bins':[], 'bint':[], \\\n\t\t         'bxcx':[], 'bxc2':[], 'bxc3':[], 'bxc4':[], \\\n\t\t         'log0':[], 'log1':[], 'pwrs':[], \\\n\t\t         'bnry':[], 'text':[], '1010':[], 'or10':[], 'om10':[], \\\n\t\t         'ordl':[], 'ord2':[], 'ord3':[], 'ord4':[], 'mmor':[], \\\n\t\t         'date':[], 'dat2':[], 'dat6':[], 'wkdy':[], 'bshr':[], 'hldy':[], \\\n\t\t         'yea2':[], 'mnt2':[], 'mnt6':[], 'day2':[], 'day5':[], \\\n\t\t         'hrs2':[], 'hrs4':[], 'min2':[], 'min4':[], 'scn2':[], \\\n\t\t         'excl':[], 'exc2':[], 'exc3':[], 'null':[], 'eval':[]}, \\\n            assigninfill = {'stdrdinfill':[], 'MLinfill':[], 'zeroinfill':[], 'oneinfill':[], \\\n                            'adjinfill':[], 'meaninfill':[], 'medianinfill':[], 'modeinfill':[]}, \\\n            transformdict = {}, processdict = {}, \\\n            printstatus = True)\n```\n\nOr for the postmunge function:\n\n```\n#for postmunge(.) function on subsequentlky available test data\n#using the postprocess_dict object returned from original automunge(.) application\n\ntest, testID, testlabels, \\\nlabelsencoding_dict, finalcolumns_test = \\\n```\n\nWith the full set of arguments available to be passed as:\n\n```\nam.postmunge(postprocess_dict, df_test, testID_column = False, \\\n             labelscolumn = False, pandasoutput=True, printstatus = True, \\\n             TrainLabelFreqLevel = False):\n```\n\nNote that the only required argument to the automunge function is the\ntrain set dataframe, the other arguments all have default values if\nnothing is passed. The postmunge function requires as minimum the\npostprocess_dict object (a python dictionary returned from the application of\nautomunge) and a dataframe test set consistently formatted as those sets\nthat were originally applied to automunge.\n\n...\n\nHere now are descriptions for the returned sets from automunge, which\nwill be followed by descriptions of the arguments which can be passed to\nthe function, followed by similar treatment for postmunge returned sets\nand arguments.\n\n...\n\n## automunge returned sets:\n\n* train: a numerically encoded set of data intended to be used to train a\ndownstream machine learning model in the framework of a user's choice\n\n* trainID: the set of ID values corresponding to the train set if a ID\ncolumn(s) was passed to the function. This set may be useful if the shuffle\noption was applied.\n\n* labels: a set of numerically encoded labels corresponding to the\ntrain set if a label column was passed. Note that the function\nassumes the label column is originally included in the train set. Note\nthat if the labels set is a single column a returned numpy array is \nflattened (e.g. [[1,2,3]] converted to [1,2,3] )\n\n* validation1: a set of training data carved out from the train set\nthat is intended for use in hyperparameter tuning of a downstream model.\n\n* validationID1: the set of ID values coresponding to the validation1\nset\n\n* validationlabels1: the set of labels coresponding to the validation1\nset\n\n* validation2: the set of training data carved out from the train set\nthat is intended for the final validation of a downstream model (this\nset should not be applied extensively for hyperparameter tuning).\n\n* validationID2: the set of ID values coresponding to the validation2\nset.\n\n* validationlabels2: the set of labels coresponding to the validation2\nset\n\n* test: the set of features, consistently encoded and normalized as the\ntraining data, that can be used to generate predictions from a\ndownstream model trained with train. Note that if no test data is\navailable during initial address this processing will take place in the\npostmunge(.) function. \n\n* testID: the set of ID values coresponding to the test set.\n\n* testlabels: a set of numerically encoded labels corresponding to the\ntest set if a label column was passed. Note that the function\nassumes the label column is originally included in the train set.\n\n* labelsencoding_dict: a dictionary that can be used to reverse encode\npredictions that were generated from a downstream model (such as to\nconvert a one-hot encoded set back to a single categorical set).\n\n* finalcolumns_train: a list of the column headers corresponding to the\ntraining data. Note that the inclusion of suffix appenders is used to\nidentify which feature engineering transformations were applied to each\ncolumn.\n\n* finalcolumns_test: a list of the column headers corresponding to the\ntest data. Note that the inclusion of suffix appenders is used to\nidentify which feature engineering transformations were applied to each\ncolumn. Note that this list should match the one preceeding.\n\n* featureimportance: a dictionary containing summary of feature importance\nranking and metrics for each of the derived sets. Note that the metric\nvalue provides an indication of the importance of the original source\ncolumn such that larger value suggests greater importance, and the metric2 \nvalue provides an indication of the relative importance of columns derived\nfrom the original source column such that smaller metric2 value suggests \ngreater relative importance. One can print the values here such as with\nthis code:\n\n```\n#to inspect values returned in featureimportance object one could run\nfor keys,values in featureimportance.items():\n    print(keys)\n    print('metric = ', values['metric'])\n    print('metric2 = ', values['metric2'])\n    print()\n```\n\n\n* postprocess_dict: a returned python dictionary that includes\nnormalization parameters and trained machine learning models used to\ngenerate consistent processing of test data that wasn't available at\ninitial address of automunge. It is recommended that this dictionary be\nsaved on each application used to train a downstream model so that it may\nbe passed to postmunge(.) to consistently process subsequently available\ntest data.\n\n...\n\n## automunge(.) passed arguments\n\n```\nam.automunge(df_train, df_test = False, labels_column = False, trainID_column = False, \\\n            testID_column = False, valpercent1=0.0, valpercent2 = 0.0, floatprecision = 32, \\\n            shuffletrain = False, TrainLabelFreqLevel = False, powertransform = False, \\\n            binstransform = False, MLinfill = False, infilliterate=1, randomseed = 42, \\\n            numbercategoryheuristic = 15, pandasoutput = True, NArw_marker = True, \\\n            featureselection = False, featurepct = 1.0, featuremetric = .02, \\\n            featuremethod = 'default', PCAn_components = None, PCAexcl = [], \\\n            ML_cmnd = {'MLinfill_type':'default', \\\n                       'MLinfill_cmnd':{'RandomForestClassifier':{}, 'RandomForestRegressor':{}}, \\\n                       'PCA_type':'default', \\\n                       'PCA_cmnd':{}}, \\\n       \t    assigncat = {'mnmx':[], 'mnm2':[], 'mnm3':[], 'mnm4':[], 'mnm5':[], 'mnm6':[], \\\n\t\t         'nmbr':[], 'nbr2':[], 'nbr3':[], 'MADn':[], 'MAD2':[], 'MAD3':[], \\\n\t\t     \t 'bins':[], 'bint':[], \\\n\t\t         'bxcx':[], 'bxc2':[], 'bxc3':[], 'bxc4':[], \\\n\t\t         'log0':[], 'log1':[], 'pwrs':[], \\\n\t\t         'bnry':[], 'text':[], '1010':[], 'or10':[], 'om10':[], \\\n\t\t         'ordl':[], 'ord2':[], 'ord3':[], 'ord4':[], 'mmor':[], \\\n\t\t         'date':[], 'dat2':[], 'dat6':[], 'wkdy':[], 'bshr':[], 'hldy':[], \\\n\t\t         'yea2':[], 'mnt2':[], 'mnt6':[], 'day2':[], 'day5':[], \\\n\t\t         'hrs2':[], 'hrs4':[], 'min2':[], 'min4':[], 'scn2':[], \\\n\t\t         'excl':[], 'exc2':[], 'exc3':[], 'null':[], 'eval':[]}, \\\n            assigninfill = {'stdrdinfill':[], 'MLinfill':[], 'zeroinfill':[], 'oneinfill':[], \\\n                            'adjinfill':[], 'meaninfill':[], 'medianinfill':[], 'modeinfill':[]}, \\\n            transformdict = {}, processdict = {}, \\\n            printstatus = True)\n```\n\n* df_train: a pandas dataframe or numpy array containing a structured \ndataset intended for use to subsequently train a machine learning model. \nThe set at a minimum should be 'tidy' meaning a single column per feature \nand a single row per observation. If desired the set may include a row ID\ncolumn and a column intended to be used as labels for a downstream\ntraining operation. The tool supports the inclusion of non-index-range \ncolumn as index or multicolumn index (requires named index columns). Such \nindex types are added to the returned \"ID\" sets which are consistently \nshuffled and partitioned as the train and test sets. \n\n* df_test: a pandas dataframe or numpy array containing a structured \ndataset intended for use to generate predictions from a downstream machine \nlearning model trained from the automunge returned sets. The set must be \nconsistantly formated as the train set with consistent column labels and/or\norder of columns. (This set may optionally contain a labels column if one \nwas included in the train set although it's inclusion is not required). If \ndesired the set may include a row ID column or a column intended for use as \nlabels. A user may pass False if this set not available. The tool supports \nthe inclusion of non-index-range column as index or multicolumn index \n(requires named index columns). Such index types are added to the returned \n\"ID\" sets which are consistently shuffled and partitioned as the train and \ntest sets.\n\n* labels_column: a string of the column title for the column from the\ndf_train set intended for use as labels in training a downstream machine\nlearning model. The function defaults to False for cases where the\ntraining set does not include a label column. An integer column index may \nalso be passed such as if the source dataset was numpy array.\n\n* trainID_column: a string of the column title for the column from the\ndf_train set intended for use as a row identifier value (such as could\nbe sequential numbers for instance). The function defaults to False for\ncases where the training set does not include an ID column. A user can \nalso pass a list of string columns titles such as to carve out multiple\ncolumns to be excluded from processing but consistently partitioned. An \ninteger column index or list of integer column indexes may also be passed \nsuch as if the source dataset was numpy array.\n\n* testID_column: a string of the column title for the column from the\ndf_test set intended for use as a row identifier value (such as could be\nsequential numbers for instance). The function defaults to False for\ncases where the training set does not include an ID column. A user can \nalso pass a list of string columns titles such as to carve out multiple\ncolumns to be excluded from processing but consistently partitioned. An \ninteger column index or list of integer column indexes may also be passed \nsuch as if the source dataset was numpy array.\n\n* valpercent1: a float value between 0 and 1 which designates the percent\nof the training data which will be set aside for the first validation\nset (generally used for hyperparameter tuning of a downstream model).\nThis value defaults to 0. (Previously the default here was set at 0.20 but \nthat is fairly an arbitrary value and a user may wish to deviate for \ndifferent size sets. Note that this value may be set to 0 if no validation \nset is needed (such as may be the case for k-means validation).)\n\n* valpercent2: a float value between 0 and 1 which designates the percent\nof the training data which will be set aside for the second validation\nset (generally used for final validation of a model prior to release).\nThis value defaults to 0. (Previously the default was set at 0.10 but that \nis fairly an arbitrary value and a user may wish to deviate for different \nsize sets.)\n\n* floatprecision: an integer with acceptable values of 16/32/64 designating\nthe memory precision for returned float values. (A tradeoff between memory\nusage and floating point precision, smaller for smaller footprint.)\n\n* shuffletrain: a boolean identifier (True/False) which indicates if the\nrows in df_train will be shuffled prior to carving out the validation\nsets. Note that if this value is set to False then the validation sets\nwill be pulled from the bottom x% sequential rows of the dataframe.\n(Where x% is the sum of validation ratios.) Note that if this value is\nset to False although the validations will be pulled from sequential\nrows, the split between validaiton1 and validation2 sets will be\nrandomized. This value defaults to False.\n\n* TrainLabelFreqLevel: a boolean identifier (True/False) which indicates\nif the TrainLabelFreqLevel method will be applied to oversample training\ndata associated with underrepresented labels. The method adds multiples\nto training data rows for those labels with lower frequency resulting in\nan (approximately) levelized frequency. This defaults to False. Note that\nthis feature may be applied to numerical label sets if the processing\napplied to the set includes standard deviation bins.\n\n* powertransform: a boolean identifier (True/False) which indicates if an\nevaluation will be performed of distribution properties to select between\nbox-cox, z-score, min-max scaling, or mean absolute deviaiton scaling \nnormalization. Note that after application of box-cox transform child columns \nare generated for a subsequent z-score normalization as well as a set of bins\nassociated with number of standard deviations from the mean. Please note that\nI don't consider the current means of distribution property evaluation very\nsophisticated and we will continue to refine this method with further research\ngoing forward. This defaults to False.\n\n* binstransform: a boolean identifier (True/False) which indicates if the\nnumerical sets will receive bin processing such as to generate child\ncolumns with boolean identifiers for number of standard deviations from\nthe mean, with groups for values <-2, -2-1, -10, 01, 12, and >2 . Note\nthat the bins and bint transformations are the same, only difference is\nthat the bint transform assumes the column has already been normalized\nwhile the bins transform does not. This value defaults to False.\n\n* MLinfill: a boolean identifier (True/False) which indicates if the ML\ninfill method will be applied as a default to predict infill for missing \nor improperly formatted data using machine learning models trained on the\nrest of the set. This defaults to False.\n\n* infilliterate: an integer indicating how many applications of the ML\ninfill processing are to be performed for purposes of predicting infill.\nThe assumption is that for sets with high frequency of missing values\nthat multiple applications of ML infill may improve accuracy although\nnote this is not an extensively tested hypothesis. This defaults to 1.\n\n* randomseed: a postitive integer used as a seed for randomness in data\nset shuffling, ML infill, and fearture importance  algorithms. This \ndefaults to 42, a nice round number.\n\n* forcetocategoricalcolumns: a list of string identifiers of column titles\nfor those columns which are to be treated as categorical to allow\none-hot encoding. This may be useful e.g. for numerically encoded\ncategorical sets such as like zip codes or phone numbers or something\nwhich would otherwise be evaluated as numerical and subject to\nnormalization. *update this aregument no longer supported, a user can\ninstead assign distinct methods to each column with assigncat per below, \nsuch as assigning a column to category 'text' for categorical.\n\n* numbercategoryheuristic: an integer used as a heuristic. When a \ncategorical set has more unique values than this heuristic, it defaults \nto categorical treatment via ordinal processing. This defaults to 15.\n\n* pandasoutput: a selector for format of returned sets. Defaults to False\nfor returned Numpy arrays. If set to True returns pandas dataframes\n(note that index is not preserved in the train/validation split, an ID\ncolumn may be passed for index identification).\n\n* NArw_marker: a boolean identifier (True/False) which indicates if the\nreturned sets will include columns with markers for rows subject to \ninfill (columns with suffix 'NArw'). This value defaults to True.\n\n* featureselection: a boolean identifier telling the function whether to\nperform a feature importance evaluation. If selected automunge will\nreturn a summary of feature importance findings in the featureimportance\nreturned dictionary. This also activates the trimming of derived sets\nthat did not meet the importance threshold if [featurepct < 1.0 and \nfeaturemethod = 'pct'] or if [fesaturemetric > 0.0 and featuremethod = \n'metric']. Note this defaults to False because it cannot operate without\na designated label column in the train set. Note that the user-specified\nsize of validationratios if passed are used in this method.\n\n* featurepct: the percentage of derived sets that are kept in the output\nbased on the feature importance evaluation. Note that NArw columns are\nexcluded from the trimming for now (the inclusion of NArws in trimming\nwill likely be included in a future expansion). This item only used if\nfeaturemethod passed as 'pct' (the default).\n\n* featuremetric: the feature importance metric below which derived sets\nare trimmed from the output. Note that this item only used if\nfeaturemethod passed as 'metric'.\n\n* featuremethod: can be passed as either 'pct' or 'metric' to select which\nfeature importance method is used for trimming the derived sets. Or can pass\nas 'default' for ignoring the featurepct/featuremetric parameters or can \npass as 'report' to return the featureimportance results with no further\nprocessing (other returned sets are empty).\n\n* PCAn_components: a user can pass an integer to define the number of PCA\nderived features for purposes of dimensionality reduction, such integer to \nbe less than the otherwise returned number of sets. Function will default \nto kernel PCA for all non-negative sets or otherwise Sparse PCA. Also if\nthis values passed as a float <1.0 then linear PCA will be applied such \nthat the returned number of sets are the minimum number that can reproduce\nthat percent of the variance. Note this can also be passed in conjunction \nwith assigned PCA type or parameters in the ML_cmnd object.\n\n* PCAexcl: a list of column headers for columns that are to be excluded from\nany application of PCA\n\n* ML_cmnd: \n\n```\nML_cmnd = {'MLinfill_type':'default', \\\n           'MLinfill_cmnd':{'RandomForestClassifier':{}, 'RandomForestRegressor':{}}, \\\n           'PCA_type':'default', \\\n           'PCA_cmnd':{}}, \\\n```\nThe ML_cmnd allows a user to pass parameters to the predictive algorithms\nused for ML infill and feature importance evaluation. Currently the only\noption for 'MLinfill_type' is default which uses Scikit-Learn's Random \nForest implementation, the intent is to add other options in a future extension.\nFor example, a user wishing to pass a custom parameter of max_depth for to the \nRandom Forest algorithms could pass:\n_\n```\nML_cmnd = {'MLinfill_type':'default', \\\n           'MLinfill_cmnd':{'RandomForestClassifier':{'max_depth':4}, \\\n                            'RandomForestRegressor':{'max_depth':4}}, \\\n           'PCA_type':'default', \\\n           'PCA_cmnd':{}}, \\\n\n#(note that currently unable to pass RF parameters to criterion and n_jobs)\n```\nA user can also assign specific methods for PCA transforms. Current PCA_types\nsupported include 'PCA', 'SparsePCA', and 'KernelPCA', all via Scikit-Learn.\nNote that the n_components are passed seperately with the PCAn_components \nargument noted above. A user can also pass parameters to the PCA functions\nthrough the PCA_cmnd, for example one could pass a kernel type for KernelPCA\nas:\n```\nML_cmnd = {'MLinfill_type':'default', \\\n           'MLinfill_cmnd':{'RandomForestClassifier':{}, \\\n                            'RandomForestRegressor':{}}, \\\n           'PCA_type':'KernelPCA', \\\n           'PCA_cmnd':{'kernel':'sigmoid'}}, \\\n\n#Also note that SparsePCA currenlty doesn't have available\n#n_jobs or normalize_components, and similarily KernelPCA \n#doesn't have available n_jobs.\n```\nNote that the PCA is currently defaulted to active for cases where the \ntrain set number of features is >0.50 the number of rows. A user can \nchange this ratio by passing 'PCA_cmnd':{'col_row_ratio':0.22}} for \ninstance. Also a user can simply turn off default PCA transforms by \npassing 'PCA_cmnd':{'PCA_type':'off'}. A user can also exclude returned\nboolean (0/1) columns from any PCA application by passing \n'PCA_cmnd':{'bool_PCA_excl':True}\nor exclude returned boolean and ordinal columns from PCA application by\n'PCA_cmnd':{'bool_ordl_PCAexcl':True}\nsuch as could potentially result in memory savings.\n\n\n* assigncat:\n\n```\n#Here are the current trasnformation options built into our library, which\n#we are continuing to build out. A user may also define their own.\n\n    assigncat = {'mnmx':[], 'mnm2':[], 'mnm3':[], 'mnm4':[], 'mnm5':[], 'mnm6':[], \\\n\t\t 'nmbr':[], 'nbr2':[], 'nbr3':[], 'MADn':[], 'MAD2':[], 'MAD3':[], \\\n\t\t 'bins':[], 'bint':[], \\\n\t\t 'bxcx':[], 'bxc2':[], 'bxc3':[], 'bxc4':[], \\\n\t\t 'log0':[], 'log1':[], 'pwrs':[], \\\n\t\t 'bnry':[], 'text':[], '1010':[], 'or10':[], 'om10':[], \\\n\t\t 'ordl':[], 'ord2':[], 'ord3':[], 'ord4':[], 'mmor':[], \\\n\t\t 'date':[], 'dat2':[], 'dat6':[], 'wkdy':[], 'bshr':[], 'hldy':[], \\\n\t\t 'yea2':[], 'mnt2':[], 'mnt6':[], 'day2':[], 'day5':[], \\\n\t\t 'hrs2':[], 'hrs4':[], 'min2':[], 'min4':[], 'scn2':[], \\\n\t\t 'excl':[], 'exc2':[], 'exc3':[], 'null':[], 'eval':[]}\n```         \n\nA user may add column identifier strings to each\nof these lists to designate this specific processing approach. Note that\nthis processing category will serve as the \"root\" of the tree of\ntransforms as defined in the transformdict. Note that additional\ncategories may be passed if defined in the passed transformdict and\nprocessdict. An example of usage here could be if a user wanted to only\nprocess numerical columns 'nmbrcolumn1' and 'nmbrcolumn2' with z-score\nnormalization instead of the full range of numerical derivations they\ncould pass assigncat = {'nbr2':['nmbrcolumn1'], ...}. We'll provide \ndetails on each of the built-in library of transformations below.\n\n* assigninfill \n```\n#Here are the current infill options built into our library, which\n#we are continuing to build out.\nassigninfill = {'stdrdinfill':[], 'MLinfill':[], 'zeroinfill':[], 'oneinfill':[], \\\n                'adjinfill':[], 'meaninfill':[], 'medianinfill':[], 'modeinfill':[]}, \\\n```\nA user may add column identifier strings to each of these lists to \ndesignate the column-specific infill approach for missing or\nimproperly formated values. Note that this infill category defaults to\nMLinfill if nothing assigned and the MLinfill argument to automunge is\nset to True. stdrdinfill means: mean for numeric sets, most common for \nbinary, and new column boolean for categorical. zeroinfill means inserting \nthe integer 0 to missing cells. oneinfill means inserting the integer 1.\nadjinfill means passing the value from the preceding row to missing cells. \nmeaninfill means inserting the mean derived from the train set to numeric \ncolumns. medianinfill means inserting the median derived from the train \nset to numeric columns. (Note currently boolean columns derived from \nnumeric are not supported for mean/median and for those cases default to \nthose infill from stdrdinfill.) modeinfill means inserting the most common\ncvalue for a set, note that modeinfill supports one-hot encoded sets.\n\n* transformdict: allows a user to pass a custom tree of transformations.\nNote that a user may define their own 4 character string \"root\"\nidentifiers for a series of processing steps using the categories \nof processing already defibned in our library and then assign columns \nin assigncat, or for custom processing functions this method should \nbe combined with processdict which is only slightly more complex. \nFor example, a user wishing to define a new set of transformations \nfor numerical series 'newt' that combines NArows, min-max, box-cox, z-score, \nand standard deviation bins could do so by passing a trasnformdict as:\n```\ntransformdict =  {'newt' : {'parents' : ['bxc4'], \\\n                            'siblings': [], \\\n                            'auntsuncles' : ['mnmx'], \\\n                            'cousins' : ['NArw'], \\\n                            'children' : [], \\\n                            'niecesnephews' : [], \\\n                            'coworkers' : [], \\\n                            'friends' : []}}\n\n#Where since bxc4 is passed as a parent, this will result in pulling\n#ofspring keys from the bxcx family tree, which has a nbr2 key as children.\n\n#from automunge library:\n    transform_dict.update({'bxc4' : {'parents' : ['bxcx'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : [], \\\n                                     'cousins' : ['NArw'], \\\n                                     'children' : ['nbr2'], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n#note that 'nmbr' is passed as a children primitize meaning if nbr2 key\n#has any offspring those will be produced as well.\n\n\n```\nBasically here 'newt' is the key and when passed to one of the family primitives\nthe corresponding process function is applied, and if it is passed to a family\nprimitive with downstream offspring then those offspring keys are pulled from\nthat key's family tree. For example, here mnmx is passed as an auntsuncles which\nmeans the mnmx processing function is applied with no downstream offspring. The\nbxcx key is passed as a parent which means the bxcx trasnform is applied coupled\nwith any downstream transforms from the bxcx key family tree, which we also show.\nNote the family primitives tree of transformations can be summarized as:\n```\n'parents' :           upstream / first generation / replaces column / with offspring\n'siblings':           upstream / first generation / supplements column / with offspring\n'auntsuncles' :       upstream / first generation / replaces column / no offspring\n'cousins' :           upstream / first generation / supplements column / no offspring\n'children' :          downstream parents / offspring generations / replaces column / with offspring\n'niecesnephews' :     downstream siblings / offspring generations / supplements column / with offspring\n'coworkers' :         downstream auntsuncles / offspring generations / replaces column / no offspring\n'friends' :           downstream cousins / offspring generations / supplements column / no offspring\n```\nNote that when we define a new transform such as 'newt' above, we also need \nto define a corresponding processdict entry for the new category, which we \ndemonstrate here:\n\n\n* processdict: allows a user to define their own processing functions \ncorresponding to new transformdict keys. We'll describe the entries here:\n```\n#for example \nprocessdict =  {'newt' : {'dualprocess' : None, \\\n\t\t\t  'singleprocess' : None, \\\n\t\t\t  'postprocess' : None, \\\n        \t          'NArowtype' : 'numeric', \\\n      \t\t          'MLinfilltype' : 'numeric', \\\n           \t\t  'labelctgy' : 'mnmx'}}\n\n#A user should pass either a pair of processing functions to both \n#dualprocess and postprocess, or alternatively just a single processing\n#function to singleprocess, and pass None to those not used.\n#For now, if just using the category as a root key and not as a family primitive, \n#can simply pass None to all the processing slots. We'll demonstrate their \n#composition and data structures for custom processing functions later in this \n#document.\n\n#dualprocess: for passing a processing function in which normalization \n#             parameters are derived from properties of the training set\n#             and jointly process the train set and if available test set\n\n#singleprocess: for passing a processing function in which no normalization\n#               parameters are needed from the train set to process the\n#               test set, such that train and test sets processed seperately\n\n#postprocess: for passing a processing function in which normalization \n#             parameters originally derived from the train set are applied\n#             to seperately process a test set\n\n#NArowtype: can be entries of either 'numeric', 'justNaN', or 'exclude' where\n#\t\t\t'numeric' refers to columns where non-numeric entries are subject\n#\t\t\t\t\t  to infill\n#\t\t\t'justNaN' refers to columns where only NaN entries are subject\n#\t\t\t          to infill\n#\t\t\t'exclude' refers to columns where no infill will be performed\n\n#MLinfilltype: can be entries of 'numeric', 'singlct', 'multirt', 'exclude'\n#              'multisp', 'exclude', or 'label' where\n#\t\t\t   'numeric' refers to columns where predictive algorithms treat\n#\t\t\t   as a regression for numeric sets\n#\t\t\t   'singlect' refers to columns where category gives a single\n#\t\t\t   column where predictive algorithms treat as a boolean classifier\n#\t\t\t   'multirt' refers to category returning multiple columns where \n#\t\t\t   predictive algorithms treat as a multi modal classifier\n#\t\t\t   'exclude' refers to categories excluded from predcitive address\n#\t\t\t   'multisp' tbh I think this is just a duplicate of multirt, a\n#\t\t\t   future update may strike this one\n#\t\t\t   'label' refers to categories specifically intended for label\n#\t\t\t   processing\n\n```\n\n* printstatus: user can pass True/False indicating whether the function will print \nstatus of processing during operation. Defaults to True.\n\nOk well we'll demonstrate further below how to build custom processing functions,\nfor now this just gives you sufficient tools to build sets of processing using\nthe built in sets in the library.\n\n...\n\n# postmunge\n\nThe postmunge(.) function is intended to consistently process subsequently available\nand consistently formatted test data with just a single function call. It requires \npassing the postprocess_dict object returned from the original application of automunge \nand that the passed test data have consistent column header labeling as the original \ntrain set.\n\n```\n\n#for postmunge(.) function on subsequently available test data\n#using the postprocess_dict object returned from original automunge(.) application\n\n#Remember to initialize automunge\nfrom AutoMunge_pkg import AutoMunge\nam = AutoMunge.AutoMunge()\n\n\n#Then we can run postmunge function as:\n\ntest, testID, testlabels, \\\nlabelsencoding_dict, finalcolumns_test = \\\nam.postmunge(postprocess_dict, df_test, testID_column = False, \\\n             labelscolumn = False, pandasoutput=True, printstatus = True, \\\n             TrainLabelFreqLevel = False, featureeval = False):\n```\n\n\n\n## postmunge(.) returned sets:\nHere now are descriptions for the returned sets from postmunge, which\nwill be followed by descriptions of the arguments which can be passed to\nthe function. \n\n* test: the set of features, consistently encoded and normalized as the\ntraining data, that can be used to generate predictions from a model\ntrained with the np_train set from automunge.\n\n* testID: the set of ID values coresponding to the test set.\n\n* testlabels: a set of numerically encoded labels corresponding to the\ntest set if a label column was passed. Note that the function\nassumes the label column is originally included in the train set. Note\nthat if the labels set is a single column a returned numpy array is \nflattened (e.g. [[1,2,3]] converted to [1,2,3] )\n\n* labelsencoding_dict: this is the same labelsencoding_dict returned from\nautomunge, it's used in case one wants to reverse encode predicted labels\n\n* finalcolumns_test: a list of the column headers corresponding to the\ntest data. Note that the inclusion of suffix appenders is used to\nidentify which feature engineering transformations were applied to each\ncolumn. Note that this list should match the one from automunge.\n\n...\n\n\n## postmunge(.) passed arguments\n\n```\n\n#for postmunge(.) function on subsequently available test data\n#using the postprocess_dict object returned from original automunge(.) application\n\n#Remember to initialize automunge\nfrom AutoMunge_pkg import AutoMunge\nam = AutoMunge.AutoMunge()\n\n\n#Then we can run postmunge function as:\n\ntest, testID, testlabels, \\\nlabelsencoding_dict, finalcolumns_test = \\\nam.postmunge(postprocess_dict, df_test, testID_column = False, \\\n             labelscolumn = False, pandasoutput=True, printstatus = True, \\\n             TrainLabelFreqLevel = False, featureeval = False)\n```\n\n* postprocess_dict: this is the dictionary returned from the initial\napplication of automunge which included normalization parameters to\nfacilitate consistent processing of test data to the original processing\nof the train set. This requires a user to remember to download the\ndictionary at the original application of automunge, otherwise if this\ndictionary is not available a user can feed this subsequent test data to\nthe automunge along with the original train data exactly as was used in\nthe original automunge call.\n\n* df_test: a pandas dataframe or numpy array containing a structured \ndataset intended for use to generate predictions from a machine learning \nmodel trained from the automunge returned sets. The set must be consistantly \nformated as the train set with consistent order of columns and if labels are\nincluded consistent labels. If desired the set may include an ID column. The \ntool supports the inclusion of non-index-range column as index or multicolumn \nindex (requires named index columns). Such index types are added to the \nreturned \"ID\" sets which are consistently shuffled and partitioned as the \ntrain and test sets.\n\n* testID_column: a string of the column title for the column from the\ndf_test set intended for use as a row identifier value (such as could be\nsequential numbers for instance). The function defaults to False for\ncases where the training set does not include an ID column. A user can \nalso pass a list of string columns titles such as to carve out multiple\ncolumns to be excluded from processing but consistently partitioned. An \ninteger column index or list of integer column indexes may also be passed \nsuch as if the source dataset was numpy array.\n\n* labelscolumn: default to False indicates that a labels column is not \nincluded in the test set passed to postmunge. A user can either pass\nTrue or the string ID of the labels column, noting that it is a requirement\nthat the labels column header string must be consistent with that from\nthe original train set. An integer column index may also be passed such\nas if the source dataset was numpy array.\n\n* pandasoutput: a selector for format of returned sets. Defaults to False\nfor returned Numpy arrays. If set to True returns pandas dataframes\n(note that index is not preserved, an ID column may be passed for index\nidentification).\n\n* printstatus: user can pass True/False indicating whether the function \nwill print status of processing during operation. Defaults to True.\n\n* TrainLabelFreqLevel: a boolean identifier (True/False) which indicates\nif the TrainLabelFreqLevel method will be applied to oversample test\ndata associated with underrepresented labels. The method adds multiples\nto test data rows for those labels with lower frequency resulting in\nan (approximately) levelized frequency. This defaults to False. Note that\nthis feature may be applied to numerical label sets if the processing\napplied to the set includes standard deviation bins.\n\n* featureeval: a boolean identifier (True/False) to activate a feature\nimportance evaluation, comparable to one performed in automunge but based\non the test set passed to postmunge. Currently the results report is not\nreturned as an object, the results are printed in the output (for backward\ncompatibility).\n\n...\n\n## Library of Transformations\n\nAutomunge has a built in library of transformations that can be passed for\nspecific columns with assigncat. A column if left unassigned will defer to\nthe automated default methods.  For example, a user can pass a min-max\nscaling method to a specific column 'col1' with: \n```\nassigncat = {'mnmx':['col1']}\n```\nWhen a user assigns a column to a specific category, that category is treated\nas the root category for the tree of transformations. Each key has an \nassociated transformation function, and that transformation function is only\napplied if the root key is also found in the tree of family primitives. The\ntree of family primitives, as introduced earlier, applies first the first\ngeneration transforms of greatgrandparents and grandparents specific to the \noriginal root key, and then any transforms for keys found in upstream primitives\ni.e. parents/siblings/auntsuncles/cousins. If a transform is applied for a \nprimitive that includes downstream offspring, such as parents/\nsiblings, then the family tree for that key with offspring is inspected to determine\ndownstream offspring categories, for example if we have a parents key of 'mnmx',\nthen any children/niecesnephews/coworkers/friends in the 'mnmx' family tree will\nbe applied as parents/siblings/auntsuncles/cousins, respectively. Note that the\ndesignation for supplements/replaces refers purely to the question of whether the\ncolumn to which the trasnform is being applied is kept in place or removed. Please\nnote that it is a quirck of the function that no original column can be left in \nplace without the application of some transformation such as to allow the building\nof the apppripriate data structures, thus at least one replacement primitive must\nalways be included. If a user does wish to leave a column in place unaltered, they \ncan simply assign that column to the 'excl' root category.\n\nNow we'll start here by listing again the family tree primitives for those root \ncategories built into the automunge library. After that we'll give a quick \nnarrative for each of the associated transformation functions. First here again\nare the family tree primitives.\n\n```\n'parents' :           upstream / first generation / replaces column / with offspring\n'siblings':           upstream / first generation / supplements column / with offspring\n'auntsuncles' :       upstream / first generation / replaces column / no offspring\n'cousins' :           upstream / first generation / supplements column / no offspring\n'children' :          downstream parents / offspring generations / replaces column / with offspring\n'niecesnephews' :     downstream siblings / offspring generations / supplements column / with offspring\n'coworkers' :         downstream auntsuncles / offspring generations / replaces column / no offspring\n'friends' :           downstream cousins / offspring generations / supplements column / no offspring\n```\n\nHere is a quick description of the transformation functions associated \nwith each key which can be assigned to a primitive (and not just used as \na root key). We're continuing to build out this library of transformations.\n\n* NArw: produces a column of boolean identifiers for rows in the source\ncolumn with missing or improperly formatted values.\n* nmbr/nbr2/nbr3: z-score normalization\n* MADn/MAD2: mean absolute deviation normalization, subtract set mean\n* MAD3: mean absolute deviation normalization, subtract set maximum\n* mnmx/mnm2/mnm5: vanilla min-max scaling\n* mnm3/mnm4: min-max scaling with outliers capped at 0.01 and 0.99 quantiles\n* mnm6: min-max scaling with test set capped at min/max of train set\n* bnry: converts sets with two values to boolean identifiers\n* text: converts categorical sets to one-hot encoded set of boolean identifiers\n* ordl/ord2: converts categorical sets to ordinally encoded set of integer identifiers\n* ord3/ord4: converts categorical sets to ordinally encoded set of integer identifiers\nsorted by frequency of category occurance\n* 1010: converts categorical sets to binary encoding (more efficent than one-hot encoding)\n* bxcx/bxc2/bxc3/bxc4: performs Box-Cox power law transformation\n* log0/log1: performs logarithmic transofrm (base 10)\n* pwrs: bins groupings by powers of 10\n* date/dat2: for datetime formatted data, segregates data by time scale to multiple\ncolumns (year/month/day/hour/minute/second) and then performs z-score normalization\n* wkdy: boolean identifier indicating whether a datetime object is a weekday\n* bshr: boolean identifier indicating whether a datetime object is a business\nhour (9-5, time zone unaware)\n* hldy: boolean identifier indicating whether a datetime object is a US Federal\nholiday\n* year/mnth/days/hour/mint/scnd: segregated by time scale and z-score normalization\n* mnsn/mncs/dysn/dycs/hrsn/hrcs/misn/mics/scsn/sccs: segregated by time scale and \ndual columns with sin and cos transformations for time scale period\n* mdsn/mdcs: similar sin/cos treatment, but for combined month/day\n* hmss/hmsc: similar sin/cos treatment, but for combined hour/minute/second\n* bins: for numerical sets, outputs a set of 6 columns indicating where a\nvalue fell with respect to number of standard deviations from the mean of the\nset (i.e. <-2, -2-1, -10, 01, 12, >2)\n* bint: comparable to bins except assumes that source data was already normalized\n* null: deletes source column\n* excl: passes source column un-altered\n* exc2: passes source column unaltered except for infill\n* eval: performs distribution property evaluation consistent with the automunge\n'powertransform' parameter to designated column\n\n\n\nAnd here arethe series of family trees currently built into the internal library.\n\n```\n    transform_dict.update({'nmbr' : {'parents' : ['nmbr'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : [], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : [bint]}})\n\n    transform_dict.update({'bnry' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['bnry'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'text' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['text'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'ordl' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['ordl'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'ord2' : {'parents' : ['ord2'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : [], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : ['mnmx'], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'ord3' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['ord3'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'ord4' : {'parents' : ['ord4'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : [], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : ['mnmx'], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'or10' : {'parents' : ['ord4'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['1010'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : ['mnmx'], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'om10' : {'parents' : ['ord4'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['1010', 'mnmx'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : ['mnmx'], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mmor' : {'parents' : ['ord4'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnmx'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'1010' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['1010'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'null' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['null'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'NArw' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : [NArw], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'rgrl' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['nmbr'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'nbr2' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['nmbr'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'nbr3' : {'parents' : ['nbr3'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : [], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : ['bint']}})\n\n    transform_dict.update({'MADn' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['MADn'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'MAD2' : {'parents' : ['MAD2'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : [], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : ['nmbr'], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'MAD3' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['MAD3'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnmx' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnmx'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnm2' : {'parents' : ['nmbr'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnmx'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnm3' : {'parents' : ['nmbr'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnm3'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnm4' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnm3'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnm5' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnmx'], \\\n                                     'cousins' : ['nmbr', NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnm6' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnm6'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnm7' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnmx', 'bins'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'date' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['year', 'mnth', 'days', 'hour', 'mint', 'scnd'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'dat2' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['bshr', 'wkdy', 'hldy'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'dat3' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['year', 'mnsn', 'mncs', 'dysn', 'dycs', 'hrsn', 'hrcs', 'misn', 'mics', 'scsn', 'sccs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'dat4' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['year', 'mdsn', 'mdcs', 'hmss', 'hmsc'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'dat5' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['year', 'mdsn', 'mdcs', 'dysn', 'dycs', 'hmss', 'hmsc'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'dat6' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['year', 'mdsn', 'mdcs', 'hmss', 'hmsc', 'bshr', 'wkdy', 'hldy'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'year' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['year'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'yea2' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['year', 'mdsn', 'mdcs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnth' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnth'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnt2' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnsn', 'mncs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnt3' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnsn', 'mncs', 'dysn', 'dycs', 'hrsn', 'hrcs', 'misn', 'mics', 'scsn', 'sccs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnt4' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mdsn', 'mdcs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnt5' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mdsn', 'mdcs', 'hmss', 'hmsc'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnt6' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mdsn', 'mdcs', 'dysn', 'dycs', 'hmss', 'hmsc'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnsn' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnsn'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mncs' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mncs'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mdsn' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mdsn'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mdcs' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mdcs'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'days' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['days'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'day2' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['dysn', 'dycs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'day3' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['dysn', 'dycs', 'hrsn', 'hrcs', 'misn', 'mics', 'scsn', 'sccs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'day4' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['dhms', 'dhmc'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'day5' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['dhms', 'dhmc', 'hmss', 'hmsc'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'dysn' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['dysn'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'dycs' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['dycs'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'dhms' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['dhms'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'dhmc' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['dhmc'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'hour' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['hour'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'hrs2' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['hrsn', 'hrcs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'hrs3' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['hrsn', 'hrcs', 'misn', 'mics', 'scsn', 'sccs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'hrs4' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['hmss', 'hmsc'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'hrsn' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['hrsn'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'hrcs' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['hrcs'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'hmss' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['hmss'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'hmsc' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['hmsc'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mint' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mint'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'min2' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['misn', 'mics'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'min3' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['misn', 'mics', 'scsn', 'sccs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'min4' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mssn', 'mscs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'misn' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['misn'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mics' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mics'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mssn' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mssn'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mscs' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mscs'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'scnd' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['scnd'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'scn2' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['scsn', 'sccs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'scsn' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['scsn'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'sccs' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['sccs'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'bxcx' : {'parents' : ['bxcx'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : [], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : ['nmbr'], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'bxc2' : {'parents' : ['bxc2'], \\\n                                     'siblings': ['nmbr'], \\\n                                     'auntsuncles' : [], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : ['nmbr'], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'bxc3' : {'parents' : ['bxc3'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : [], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : ['nmbr'], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'bxc4' : {'parents' : ['bxc4'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : [], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : ['nbr2'], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'pwrs' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['pwrs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'log0' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['log0'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'log1' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['log0', 'pwrs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'wkdy' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['wkdy'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'bshr' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['bshr'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'hldy' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['hldy'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'bins' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['bins'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'bint' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['bint'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'excl' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['excl'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'exc2' : {'parents' : ['exc2'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : [], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : ['bins'], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'exc3' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['exc2'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n```\n\n\n...\n\n## Custom Transformation Functions\n\nOk final item on the agenda, we're going to demonstrate methods to create custom\ntransformation functions, such that a user may customize the feature engineering\nwhile building on all of the extremely useful built in features of automunge such\nas infill methods including ML infill, feature importance, dimensionality reduction,\nand perhaps most importantly the simplest possible way for consistent processing \nof subsequently available data with just a single function call. The transformation\nfunctions will need to be channeled through pandas and incorproate a handful of \nsimple data structures, which we'll demonstrate below.\n\nLet's say we want to recreate the mm3 category which caps outliers at 0.01 and 0.99\nquantiles, but instead make it the 0.001 and 0.999 quantiles. Well we'll call this \ncateogry mnm8. So in order to pass a custom transformation function, first we'll need to \ndefine a new root category trasnformdict and a corresponding processdict.\n\n```\n#Let's creat ea really simple family tree for the new root category mnmn8 which\n#simply creates a column identifying any rows subject to infill (NArw), performs \n#a z-score normalization, and seperately performs a version of the new transform\n#mnm8 which we'll define below.\n\ntransformdict = {'mnm8' : {'parents' : [], \\\n                           'siblings': [], \\\n                           'auntsuncles' : ['mnm8', 'nmbr'], \\\n                           'cousins' : ['NArw'], \\\n                           'children' : [], \\\n                           'niecesnephews' : [], \\\n                           'coworkers' : [], \\\n                           'friends' : []}, \\\n\n#Note that since this mnm8 requires passing normalization parameters derived\n#from the train set to process the test set, we'll need to create twop sep[erate \n#trasnformations functions, the first a \"dualprocess\" function that processes\n#both the train and if available a test set swimultaneously, and the second\n#a \"postprocess\" that only processes the test set on it's own.\n\n#So what's being demosnrtated here is that we're passing the functions under\n#dualprocess and postprocess that we'll define below.\n\nprocessdict = {'mnm8' : {'dualprocess' : process_mnm8_class, \\\n                         'singleprocess' : None, \\\n                         'postprocess' : postprocess_mnm8_class, \\\n                         'NArowtype' : 'numeric', \\\n                         'MLinfilltype' : 'numeric', \\\n                         'labelctgy' : 'mnm8'}}\n\n#Now we have to define the custom processing functions which we are passing through\n#the processdict to automunge.\n\n#Insterad of demosntrating the full functions, I'll just demonstrate the\n#requirements\n\n\n#Here we'll define a \"dualprocess\" function intended to process both a train and\n#test set simulateously. We'll also need to create a seperate \"postprocess\"\n#function intended to just process the test set.\n\n#define the function\ndef process_mnm8_class(mdf_train, mdf_test, column, category, \\\n                       postprocess_dict):\n  #where\n  #mdf_train is the train data set (pandas dataframe)\n  #mdf_test is the consistently formatted test dataset (if no test data \n  #set is available a dummy set will be passed in it's place)\n  #column is the string identifying the column header\n  #category is the 4 charcter string category identifier, here is will be 'mnm8'\n  #postprocess_dict is an object we pass to share data between functions if needed\n\n  #create thee new column, using the catehgory key as a suffix identifier\n\n  #copy source column into new column\n  mdf_train[column + '_mnm8'] = mdf_train[column].copy()\n  mdf_test[column + '_mnm8'] = mdf_test[column].copy()\n\n\n  #perform an initial infill method, here we use mean as a plug, automunge\n  #will seperately perform a infill method per user specifications elsewhere\n  #convert all values to either numeric or NaN\n  mdf_train[column + '_mnm8'] = pd.to_numeric(mdf_train[column + '_mnm8'], errors='coerce')\n  mdf_test[column + '_mnm8'] = pd.to_numeric(mdf_test[column + '_mnm8'], errors='coerce')\n\n\n\n  #Now we do the specifics of the processing function, here we're demonstrating\n  #the min-max scaling method capping values at 0.001 and 0.999 quantiles\n\n  #get maximum value of training column\n  quantilemax = mdf_train[column + '_mnm8'].quantile(.999)\n\n  #get minimum value of training column\n  quantilemin = mdf_train[column + '_mnm8'].quantile(.001)\n\n  #replace values > quantilemax with quantilemax\n  mdf_train.loc[mdf_train[column + '_mnm8'] > quantilemax, (column + '_mnm8')] \\\n  = quantilemax\n  mdf_test.loc[mdf_train[column + '_mnm8'] > quantilemax, (column + '_mnm8')] \\\n  = quantilemax\n  #replace values < quantile10 with quantile10\n  mdf_train.loc[mdf_train[column + '_mnm8'] < quantilemin, (column + '_mnm8')] \\\n  = quantilemin\n  mdf_test.loc[mdf_train[column + '_mnm8'] < quantilemin, (column + '_mnm8')] \\\n  = quantilemin\n\n\n  #note the infill method is now completed after the quantile evaluation / replacement\n  #get mean of training data\n  mean = mdf_train[column + '_mnm8'].mean()    \n  #replace missing data with training set mean\n  mdf_train[column + '_mnm8'] = mdf_train[column + '_mnm8'].fillna(mean)\n  mdf_test[column + '_mnm8'] = mdf_test[column + '_mnm8'].fillna(mean)\n\n\n  #perform min-max scaling to train and test sets using values from train\n  mdf_train[column + '_mnm8'] = (mdf_train[column + '_mnm8'] - quantilemin) / \\\n                                (quantilemax - quantilemin)\n  mdf_test[column + '_mnm8'] = (mdf_test[column + '_mnm8'] - quantilemin) / \\\n                               (quantilemax - quantilemin)\n\n\n  #ok here's where we populate the data structures\n\n  #create list of columns (here it will only be one column returned)\n  nmbrcolumns = [column + '_mnm8']\n\n  #The normalization dictionary is how we pass values between the \"dualprocess\"\n  #function and the \"postprocess\" function\n\n  #Here we populate the normalization dictionary with any values derived from\n  #the train set that we'll need to process the test set.\n  nmbrnormalization_dict = {column + '_mnm8' : {'quantilemin' : quantilemin, \\\n                                                'quantilemax' : quantilemax, \\\n                                                'mean' : mean}}\n\n  #the column_dict_list is returned from the function call and supports the \n  #automunge methods. We populate it as follows:\n\n  #initialize\n  column_dict_list = []\n\n  #where we're storing following\n  #{'category' : 'mnm8', \\ -> identifier of the category fo transform applied\n  # 'origcategory' : category, \\ -> category of original column in train set, passed in function call\n  # 'normalization_dict' : nmbrnormalization_dict, \\ -> normalization parameters of train set\n  # 'origcolumn' : column, \\ -> ID of original column in train set\n  # 'columnslist' : nmbrcolumns, \\ -> a list of columns created in this transform, \n  #                                  later fleshed out to include all columns derived from same source column\n  # 'categorylist' : [nc], \\ -> a list of columns created in this transform\n  # 'infillmodel' : False, \\ -> populated elsewhere, for now enter False\n  # 'infillcomplete' : False, \\ -> populated elsewhere, for now enter False\n  # 'deletecolumn' : False}} -> populated elsewhere, for now enter False\n\n  for nc in nmbrcolumns:\n\n    if nc[-5:] == '_mnm8':\n\n      column_dict = { nc : {'category' : 'mnm8', \\\n                           'origcategory' : category, \\\n                           'normalization_dict' : nmbrnormalization_dict, \\\n                           'origcolumn' : column, \\\n                           'columnslist' : nmbrcolumns, \\\n                           'categorylist' : [nc], \\\n                           'infillmodel' : False, \\\n                           'infillcomplete' : False, \\\n                           'deletecolumn' : False}}\n\n      column_dict_list.append(column_dict.copy())\n\n\n\n  return mdf_train, mdf_test, column_dict_list\n\n  #where mdf_train and mdf_test now have the new column incorporated\n  #and column_dict_list carries the data structures supporting the operation \n  #of automunge. (If the original columkjn was intended for replacement it \n  #will be stricken elsewhere)\n\n\n#and then since this is a method that passes values between the train\n#and test sets, we'll need to define a corresponding \"postproces\" function\n#intended for use on just the test set\n\ndef postprocess_mnm3_class(mdf_test, column, postprocess_dict, columnkey):\n  #where mdf_test is a dataframe fo the test set\n  #column is the string of the column header\n  #postprocess_dict is how we carry packets of datra between the \n  #functions in automunge\n  #columnkey is a key used to access stuff in postprocess_dict if needed\n\n\n  #retrieve normalization parameters from postprocess_dict\n  normkey = column + '_mnm8'\n\n  mean = \\\n  postprocess_dict['column_dict'][normkey]['normalization_dict'][normkey]['mean']\n\n  quantilemin = \\\n  postprocess_dict['column_dict'][normkey]['normalization_dict'][normkey]['quantilemin']\n\n  quantilemax = \\\n  postprocess_dict['column_dict'][normkey]['normalization_dict'][normkey]['quantilemax']\n\n  #copy original column for implementation\n  mdf_test[column + '_mnm8'] = mdf_test[column].copy()\n\n\n  #convert all values to either numeric or NaN\n  mdf_test[column + '_mnm8'] = pd.to_numeric(mdf_test[column + '_mnm8'], errors='coerce')\n\n  #get mean of training data\n  mean = mean  \n\n  #replace missing data with training set mean\n  mdf_test[column + '_mnm8'] = mdf_test[column + '_mnm8'].fillna(mean)\n\n  #perform min-max scaling to test set using values from train\n  mdf_test[column + '_mnm8'] = (mdf_test[column + '_mnm8'] - quantilemin) / \\\n                               (quantilemax - quantilemin)\n\n\n  return mdf_test\n\n#Voila\n\n#One more demonstration, note that if we didn't need to pass any properties\n#between the train and test set, we could have just processed one at a time,\n#and in that case we wouldn't need to define seperate functions for \n#dualprocess and postprocess, we could just define what we call a singleprocess \n#function incorproating similar data strucures but without only a single dataframe \n#passed\n\n#Such as:\ndef process_mnm4_class(df, column, category, postprocess_dict):\n\n  #etc\n\n  return return df, column_dict_list\n\n#For a full demonstration check out my essay \n\"Automunge 1.79: An Open Source Platform for Feature Engineering\"\n\n\n```\n\nAnd there you have it, you now have all you need to wrangle data on the \nautomunge platform. Feedback is welcome.\n\n\n...\n\nAs a citation, please note that the Automunge package makes use of \nthe Pandas, Sciki-learn, and NumPy libraries.\n\nWes McKinney. Data Structures for Statistical Computing in Python,\nProceedings of the 9th Python in Science Conference, 51-56 (2010)\n[publisher\nlink](http://conference.scipy.org/proceedings/scipy2010/mckinney.html)\n\nFabian Pedregosa, Ga\u00ebl Varoquaux, Alexandre Gramfort, Vincent Michel,\nBertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer,\nRon Weiss, Vincent Dubourg, Jake Vanderplas, Alexandre Passos, David\nCournapeau, Matthieu Brucher, Matthieu Perrot, \u00c9douard Duchesnay.\nScikit-learn: Machine Learning in Python, Journal of Machine Learning\nResearch, 12, 2825-2830 (2011) [publisher\nlink](http://jmlr.org/papers/v12/pedregosa11a.html)\n\nSorry I don't know paper to cite, but Numpy website at:\nhttps://www.numpy.org/\n\n...\n\nHave fun munging!\n\n...\n\nYou can read more about the tool through the blog posts documenting the\ndevelopment on medium [here](https://medium.com/automunge) or for more\nwriting I recently completed my first collection of essays titled \"From\nthe Diaries of John Henry\" which is also available on Medium\n[turingsquared.com](https://turingsquared.com).\n\nThe AutoMunge website is helpfully located at URL\n[automunge.com](https://automunge.com).\n\n...\n\nPatent Pending, application 16552857\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Automunge/AutoMunge", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "AutoMunge-pkg", "package_url": "https://pypi.org/project/AutoMunge-pkg/", "platform": "", "project_url": "https://pypi.org/project/AutoMunge-pkg/", "project_urls": {"Homepage": "https://github.com/Automunge/AutoMunge"}, "release_url": "https://pypi.org/project/AutoMunge-pkg/2.54/", "requires_dist": null, "requires_python": "", "summary": "A tool for automated data wrangling", "version": "2.54", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Automunge Package</h1>\n<h1></h1>\n<p>Automunge is a tool for automating the final steps of data wrangling of\nstructured (tabular) data prior to the application of machine learning.\nThe automunge(.) function takes as input structured training data intended\nto train a machine learning model with any corresponding labels if available\nincluded in the set, and also if available consistently formatted test data\nthat can then be used to generate predictions from that trained model. When\nfed pandas dataframes or numpy arrays for these sets the function returns a\nseries of transformed numpy arrays or pandas dataframes per a selection which\nare numerically encoded and suitable for the direct application of machine\nlearning algorithms. A user has an option between default feature engineering\nbased on inferred properties of the data with feature transformations such as\nz score normalization, standard deviation bins for numerical sets, box-cox\npower law transform for all positive numerical sets, one-hot encoding for\ncategorical sets, and more (full documentation below), assigning specific\ncolumn feature engineering methods using a built in library of feature\nengineering transformations, or alternatively the passing of user-defined\ncustom transformation functions incorporating simple data structures such as\nto allow custom methods to each column while still making use of all of the\nbuilt-in features of the tool (such as ML infill, feature importance,\ndimensionality reduction, and most importantly the simplest way for the\nconsistent processing of subsequently available data using just a single\nfunction call of the postmunge(.) function). Missing data points in the sets\nare also available to be addressed by either assigning distinct methods to\neach column or alternatively by the automated \"ML infill\" method which\npredicts infill using machine learning models trained on the rest of the set\nin a fully generalized and automated fashion. automunge(.) returns a python\ndictionary which can be used as an input along with a subsequent test data\nset to the function postmunge(.) for  consistent processing of test data\nwhich wasn't available for the initial address.</p>\n<p>In addition to it's use for feature engineering transformations, automunge(.)\nalso can serve an evaluatory purpose by way of a feature importance evaluation\nthrough the derivation of two metrics which provide an indication for the\nimportance of original and derived features towards the accuracy of a\npredictive model.</p>\n<p>If elected, a user can also use the tool to perform a dimensionality reduction\nvia principle component analysis (a type of entity embedding via unsupervised\nlearning) of the data sets with the automunge(.) function or consistently for\nsubsequently available data with the postmunge(.) function.</p>\n<p>AutoMunge is now available for free pip install for your open source\npython data-wrangling</p>\n<pre><code>pip install AutoMunge-pkg\n</code></pre>\n<pre><code>#or to upgrade (we currently roll out upgrades pretty frequently)\npip install AutoMunge-pkg --upgrade\n</code></pre>\n<p>Once installed, run this in a local session to initialize:</p>\n<pre><code>from AutoMunge_pkg import AutoMunge\nam = AutoMunge.AutoMunge()\n</code></pre>\n<p>Where eg for train/test set processing run:</p>\n<pre><code>train, trainID, labels, \\\nvalidation1, validationID1, validationlabels1, \\\nvalidation2, validationID2, validationlabels2, \\\ntest, testID, testlabels, \\\ntestlabelsencoding_dict, finalcolumns_train, finalcolumns_test, \\\nfeatureimportance, postprocess_dict \\\n= am.automunge(df_train, df_test, etc)\n</code></pre>\n<p>or for subsequent consistant processing of test data, using the\ndictionary returned from original application of automunge(.), run:</p>\n<pre><code>test, testID, testlabels, \\\nlabelsencoding_dict, finalcolumns_test \\ =\nam.postmunge(postprocess_dict, df_test)\n</code></pre>\n<p>I find it helpful to pass these functions with the full range of arguments\nincluded for reference, thus a user may simply copy and past this form.</p>\n<pre><code>#for automunge(.) function on original train and test data\n\ntrain, trainID, labels, \\\nvalidation1, validationID1, validationlabels1, \\\nvalidation2, validationID2, validationlabels2, \\\ntest, testID, testlabels, \\\nlabelsencoding_dict, finalcolumns_train, finalcolumns_test, \\\nfeatureimportance, postprocess_dict = \\\nam.automunge(df_train, df_test = False, labels_column = False, trainID_column = False, \\\n            testID_column = False, valpercent1=0.0, valpercent2 = 0.0, floatprecision = 32, \\\n            shuffletrain = False, TrainLabelFreqLevel = False, powertransform = False, \\\n            binstransform = False, MLinfill = False, infilliterate=1, randomseed = 42, \\\n            numbercategoryheuristic = 15, pandasoutput = True, NArw_marker = True, \\\n            featureselection = False, featurepct = 1.0, featuremetric = .02, \\\n            featuremethod = 'default', PCAn_components = None, PCAexcl = [], \\\n            ML_cmnd = {'MLinfill_type':'default', \\\n                       'MLinfill_cmnd':{'RandomForestClassifier':{}, 'RandomForestRegressor':{}}, \\\n                       'PCA_type':'default', \\\n                       'PCA_cmnd':{}}, \\\n       \t    assigncat = {'mnmx':[], 'mnm2':[], 'mnm3':[], 'mnm4':[], 'mnm5':[], 'mnm6':[], \\\n\t\t         'nmbr':[], 'nbr2':[], 'nbr3':[], 'MADn':[], 'MAD2':[], 'MAD3':[], \\\n\t\t     \t 'bins':[], 'bint':[], \\\n\t\t         'bxcx':[], 'bxc2':[], 'bxc3':[], 'bxc4':[], \\\n\t\t         'log0':[], 'log1':[], 'pwrs':[], \\\n\t\t         'bnry':[], 'text':[], '1010':[], 'or10':[], 'om10':[], \\\n\t\t         'ordl':[], 'ord2':[], 'ord3':[], 'ord4':[], 'mmor':[], \\\n\t\t         'date':[], 'dat2':[], 'dat6':[], 'wkdy':[], 'bshr':[], 'hldy':[], \\\n\t\t         'yea2':[], 'mnt2':[], 'mnt6':[], 'day2':[], 'day5':[], \\\n\t\t         'hrs2':[], 'hrs4':[], 'min2':[], 'min4':[], 'scn2':[], \\\n\t\t         'excl':[], 'exc2':[], 'exc3':[], 'null':[], 'eval':[]}, \\\n            assigninfill = {'stdrdinfill':[], 'MLinfill':[], 'zeroinfill':[], 'oneinfill':[], \\\n                            'adjinfill':[], 'meaninfill':[], 'medianinfill':[], 'modeinfill':[]}, \\\n            transformdict = {}, processdict = {}, \\\n            printstatus = True)\n\n</code></pre>\n<p>Please remember to save the automunge(.) returned object postprocess_dict\nsuch as using pickle library, which can then be later passed to the postmunge(.)\nfunction to consistently process subsequently available data.</p>\n<pre><code>#for postmunge(.) function on subsequently available test data\n#using the postprocess_dict object returned from original automunge(.) application\n\ntest, testID, testlabels, \\\nlabelsencoding_dict, finalcolumns_test = \\\nam.postmunge(postprocess_dict, df_test, testID_column = False, \\\n             labelscolumn = False, pandasoutput=True, printstatus = True, \\\n             TrainLabelFreqLevel = False, featureeval = False)\n</code></pre>\n<p>The functions depend on pandas dataframe formatted train and test data\nor numpy arrays with consistent order of columns. The functions return\nnumpy arrays or pandas dataframes numerically encoded and normalized such\nas to make them suitable for direct application to a machine learning model\nin the framework of a user's choice, including sets for the various activities\nof a generic machine learning project such as training, hyperparameter tuning\nvalidation (validation1), final  validation (validation2), or data intended\nfor use in generation of predictions from the trained model (test set). The\nfunctions also return a few other sets such as labels, column headers,\nID sets, and etc if elected - a full list of returned arrays is below.</p>\n<p>When left to automation, the function works by inferring a category of\ndata based on properties of each column to select the type of processing\nfunction to apply, for example whether a column is a numerical, categorical,\nbinary, or time-series set. Alternately, a user can pass column header IDs to\nassign specific processing functions to distinct columns - which processing functions\nmay be pulled from the internal library of transformations or alternately user\ndefined. Normalization parameters from the initial automunge application are\nsaved to a returned dictionary for subsequent consistent processing of test data\nthat wasn't available at initial address with the postmunge(.) function.</p>\n<p>The feature engineering transformations are recorded with a series of suffixes\nappended to the column header title in the returned sets, for example the\napplication of z-score normalization returns a column with header origname + _ + nmbr.\nThe function allows feature engineering methods for the training data, test data,\nand any column designated for labels if included with the sets.</p>\n<p>In automation, for numerical data, the functions generate a series of derived\ntransformations resulting in multiple child columns. For numerical data, if the\npowertransform option is selected distribution properties are evaluated for\npotential application of z-score normalization, min-max scaling, power law transform\nvia box-cox method, or mean absolute deviation scaling. Otherwise numerical data\ndefaults to z-score, with z-score normalization options for standard\ndeviation bins for values in range &lt;-2, -2-1, -10, 01, 12, &gt;2 from the\nmean. For numerical sets with all positive values the functions also optionally can\nreturn a power-law transformed set using the box-cox method, along with\na corresponding set with z-score normalization applied. For time-series\ndata the model segregates the data by time-scale (year, month, day,\nhour, minute, second) and returns a set for each with z-score\nnormalization applied. For binary categorical data the functions\nreturn a single column with 1/0 designation. For multimodal categorical\ndata the functions return one-hot encoded sets using the naming\nconvention origname + _ + category. (I believe this automation of the\none-hot encoding method to be a particularily useful feature of the\ntool.) For all cases the functions generate a supplemental column (NArw)\nwith a boolean identifier for cells that were subject to infill due to\nmissing or improperly formatted data. (Please note that I don't\nconsider the current methods of numerical set distribution evaluation very\nsophisticated and have some work to do here).</p>\n<p>The functions also include a method we call 'ML infill' which if elected\npredicts infill for missing values in both the train and test sets using\nmachine learning models trained on the rest of the set in a fuly\ngeneralized and automated fashion. The ML infill works by initially\napplying infill using traditional methods such as mean for a numerical\nset, most common value for a binary set, and a boolean identifier for\ncategorical. The functions then generate a column specific set of\ntraining data, labels, and feature sets for the derivation of infill.\nThe column's trained model is included in the outputted dictionary for\napplication of the same model in the postmunge function. Alternately, a\nuser can pass column headers to assign different infill methods to distinct\ncolumns.</p>\n<p>The automunge(.) function also includes a method for feature importance\nevaluation, in which metrics are derived to measure the impact to predictive\naccuracy of original source columns as well as relative importance of\nderived columns using a permutation importance method. Permutation importance\nmethod was inspired by a fast.ai lecture and more information can be found in\nthe paper \"Beware Default Random Forest Importances\" by Terrence Parr, Kerem\nTurgutlu, Christopher Csiszar, and Jeremy Howard. This method currently makes\nuse of Scikit-Learns Random Forest predictors.</p>\n<p>The function also includes a method we call 'LabelFreqLevel' which\nif elected applies multiples of the feature sets associated with each\nlabel category in the returned training data so as to enable\noversampling of those labels which may be underrepresented in the\ntraining data. This method is available for categorical labels or also\nfor numerical labels when the label processing includes standard deviation\nbins. This method is expected to improve downstream model\naccuracy for training data with uneven distribution of labels. For more\non the class imbalance problem see \"A systematic study of the class imbalance\nproblem in convolutional neural networks\" - Buda, Maki, Mazurowski.</p>\n<p>The function also can perform dimensionality reduction of the sets via\nprinciple component analysis (PCA). The function automatically performs a\ntransformation when the number of features is more than 50% of the number\nof observations in the train set (this is a somewhat arbitrary heuristic).\nAlternately, the user can pass a desired number of features and their\npreference of type and parameters between linear PCA, Sparse PCA, or Kernel\nPCA - all currently implemented in Scikit-Learn.</p>\n<p>The application of the automunge and postmunge functions requires the\nassignment of the function to a series of named sets. We suggest using\nconsistent naming convention as follows:</p>\n<pre><code>train, trainID, labels, \\\nvalidation1, validationID1, validationlabels1, \\\nvalidation2, validationID2, validationlabels2, \\ \ntest, testID, testlabels, \\\nlabelsencoding_dict, finalcolumns_train, finalcolumns_test, \\\nfeatureimportance, postprocess_dict \\\n= am.automunge(df_train, ...)\n</code></pre>\n<p>The full set of arguments available to be passed are given here, with\nexplanations provided below:</p>\n<pre><code>train, trainID, labels, \\\nvalidation1, validationID1, validationlabels1, \\\nvalidation2, validationID2, validationlabels2, \\\ntest, testID, testlabels, \\\nlabelsencoding_dict, finalcolumns_train, finalcolumns_test, \\\nfeatureimportance, postprocess_dict = \\\nam.automunge(df_train, df_test = False, labels_column = False, trainID_column = False, \\\n            testID_column = False, valpercent1=0.0, valpercent2 = 0.0, floatprecision = 32, \\\n            shuffletrain = False, TrainLabelFreqLevel = False, powertransform = False, \\\n            binstransform = False, MLinfill = False, infilliterate=1, randomseed = 42, \\\n            numbercategoryheuristic = 15, pandasoutput = True, NArw_marker = True, \\\n            featureselection = False, featurepct = 1.0, featuremetric = .02, \\\n            featuremethod = 'default', PCAn_components = None, PCAexcl = [], \\\n            ML_cmnd = {'MLinfill_type':'default', \\\n                       'MLinfill_cmnd':{'RandomForestClassifier':{}, 'RandomForestRegressor':{}}, \\\n                       'PCA_type':'default', \\\n                       'PCA_cmnd':{}}, \\\n       \t    assigncat = {'mnmx':[], 'mnm2':[], 'mnm3':[], 'mnm4':[], 'mnm5':[], 'mnm6':[], \\\n\t\t         'nmbr':[], 'nbr2':[], 'nbr3':[], 'MADn':[], 'MAD2':[], 'MAD3':[], \\\n\t\t     \t 'bins':[], 'bint':[], \\\n\t\t         'bxcx':[], 'bxc2':[], 'bxc3':[], 'bxc4':[], \\\n\t\t         'log0':[], 'log1':[], 'pwrs':[], \\\n\t\t         'bnry':[], 'text':[], '1010':[], 'or10':[], 'om10':[], \\\n\t\t         'ordl':[], 'ord2':[], 'ord3':[], 'ord4':[], 'mmor':[], \\\n\t\t         'date':[], 'dat2':[], 'dat6':[], 'wkdy':[], 'bshr':[], 'hldy':[], \\\n\t\t         'yea2':[], 'mnt2':[], 'mnt6':[], 'day2':[], 'day5':[], \\\n\t\t         'hrs2':[], 'hrs4':[], 'min2':[], 'min4':[], 'scn2':[], \\\n\t\t         'excl':[], 'exc2':[], 'exc3':[], 'null':[], 'eval':[]}, \\\n            assigninfill = {'stdrdinfill':[], 'MLinfill':[], 'zeroinfill':[], 'oneinfill':[], \\\n                            'adjinfill':[], 'meaninfill':[], 'medianinfill':[], 'modeinfill':[]}, \\\n            transformdict = {}, processdict = {}, \\\n            printstatus = True)\n</code></pre>\n<p>Or for the postmunge function:</p>\n<pre><code>#for postmunge(.) function on subsequentlky available test data\n#using the postprocess_dict object returned from original automunge(.) application\n\ntest, testID, testlabels, \\\nlabelsencoding_dict, finalcolumns_test = \\\n</code></pre>\n<p>With the full set of arguments available to be passed as:</p>\n<pre><code>am.postmunge(postprocess_dict, df_test, testID_column = False, \\\n             labelscolumn = False, pandasoutput=True, printstatus = True, \\\n             TrainLabelFreqLevel = False):\n</code></pre>\n<p>Note that the only required argument to the automunge function is the\ntrain set dataframe, the other arguments all have default values if\nnothing is passed. The postmunge function requires as minimum the\npostprocess_dict object (a python dictionary returned from the application of\nautomunge) and a dataframe test set consistently formatted as those sets\nthat were originally applied to automunge.</p>\n<p>...</p>\n<p>Here now are descriptions for the returned sets from automunge, which\nwill be followed by descriptions of the arguments which can be passed to\nthe function, followed by similar treatment for postmunge returned sets\nand arguments.</p>\n<p>...</p>\n<h2>automunge returned sets:</h2>\n<ul>\n<li>\n<p>train: a numerically encoded set of data intended to be used to train a\ndownstream machine learning model in the framework of a user's choice</p>\n</li>\n<li>\n<p>trainID: the set of ID values corresponding to the train set if a ID\ncolumn(s) was passed to the function. This set may be useful if the shuffle\noption was applied.</p>\n</li>\n<li>\n<p>labels: a set of numerically encoded labels corresponding to the\ntrain set if a label column was passed. Note that the function\nassumes the label column is originally included in the train set. Note\nthat if the labels set is a single column a returned numpy array is\nflattened (e.g. [[1,2,3]] converted to [1,2,3] )</p>\n</li>\n<li>\n<p>validation1: a set of training data carved out from the train set\nthat is intended for use in hyperparameter tuning of a downstream model.</p>\n</li>\n<li>\n<p>validationID1: the set of ID values coresponding to the validation1\nset</p>\n</li>\n<li>\n<p>validationlabels1: the set of labels coresponding to the validation1\nset</p>\n</li>\n<li>\n<p>validation2: the set of training data carved out from the train set\nthat is intended for the final validation of a downstream model (this\nset should not be applied extensively for hyperparameter tuning).</p>\n</li>\n<li>\n<p>validationID2: the set of ID values coresponding to the validation2\nset.</p>\n</li>\n<li>\n<p>validationlabels2: the set of labels coresponding to the validation2\nset</p>\n</li>\n<li>\n<p>test: the set of features, consistently encoded and normalized as the\ntraining data, that can be used to generate predictions from a\ndownstream model trained with train. Note that if no test data is\navailable during initial address this processing will take place in the\npostmunge(.) function.</p>\n</li>\n<li>\n<p>testID: the set of ID values coresponding to the test set.</p>\n</li>\n<li>\n<p>testlabels: a set of numerically encoded labels corresponding to the\ntest set if a label column was passed. Note that the function\nassumes the label column is originally included in the train set.</p>\n</li>\n<li>\n<p>labelsencoding_dict: a dictionary that can be used to reverse encode\npredictions that were generated from a downstream model (such as to\nconvert a one-hot encoded set back to a single categorical set).</p>\n</li>\n<li>\n<p>finalcolumns_train: a list of the column headers corresponding to the\ntraining data. Note that the inclusion of suffix appenders is used to\nidentify which feature engineering transformations were applied to each\ncolumn.</p>\n</li>\n<li>\n<p>finalcolumns_test: a list of the column headers corresponding to the\ntest data. Note that the inclusion of suffix appenders is used to\nidentify which feature engineering transformations were applied to each\ncolumn. Note that this list should match the one preceeding.</p>\n</li>\n<li>\n<p>featureimportance: a dictionary containing summary of feature importance\nranking and metrics for each of the derived sets. Note that the metric\nvalue provides an indication of the importance of the original source\ncolumn such that larger value suggests greater importance, and the metric2\nvalue provides an indication of the relative importance of columns derived\nfrom the original source column such that smaller metric2 value suggests\ngreater relative importance. One can print the values here such as with\nthis code:</p>\n</li>\n</ul>\n<pre><code>#to inspect values returned in featureimportance object one could run\nfor keys,values in featureimportance.items():\n    print(keys)\n    print('metric = ', values['metric'])\n    print('metric2 = ', values['metric2'])\n    print()\n</code></pre>\n<ul>\n<li>postprocess_dict: a returned python dictionary that includes\nnormalization parameters and trained machine learning models used to\ngenerate consistent processing of test data that wasn't available at\ninitial address of automunge. It is recommended that this dictionary be\nsaved on each application used to train a downstream model so that it may\nbe passed to postmunge(.) to consistently process subsequently available\ntest data.</li>\n</ul>\n<p>...</p>\n<h2>automunge(.) passed arguments</h2>\n<pre><code>am.automunge(df_train, df_test = False, labels_column = False, trainID_column = False, \\\n            testID_column = False, valpercent1=0.0, valpercent2 = 0.0, floatprecision = 32, \\\n            shuffletrain = False, TrainLabelFreqLevel = False, powertransform = False, \\\n            binstransform = False, MLinfill = False, infilliterate=1, randomseed = 42, \\\n            numbercategoryheuristic = 15, pandasoutput = True, NArw_marker = True, \\\n            featureselection = False, featurepct = 1.0, featuremetric = .02, \\\n            featuremethod = 'default', PCAn_components = None, PCAexcl = [], \\\n            ML_cmnd = {'MLinfill_type':'default', \\\n                       'MLinfill_cmnd':{'RandomForestClassifier':{}, 'RandomForestRegressor':{}}, \\\n                       'PCA_type':'default', \\\n                       'PCA_cmnd':{}}, \\\n       \t    assigncat = {'mnmx':[], 'mnm2':[], 'mnm3':[], 'mnm4':[], 'mnm5':[], 'mnm6':[], \\\n\t\t         'nmbr':[], 'nbr2':[], 'nbr3':[], 'MADn':[], 'MAD2':[], 'MAD3':[], \\\n\t\t     \t 'bins':[], 'bint':[], \\\n\t\t         'bxcx':[], 'bxc2':[], 'bxc3':[], 'bxc4':[], \\\n\t\t         'log0':[], 'log1':[], 'pwrs':[], \\\n\t\t         'bnry':[], 'text':[], '1010':[], 'or10':[], 'om10':[], \\\n\t\t         'ordl':[], 'ord2':[], 'ord3':[], 'ord4':[], 'mmor':[], \\\n\t\t         'date':[], 'dat2':[], 'dat6':[], 'wkdy':[], 'bshr':[], 'hldy':[], \\\n\t\t         'yea2':[], 'mnt2':[], 'mnt6':[], 'day2':[], 'day5':[], \\\n\t\t         'hrs2':[], 'hrs4':[], 'min2':[], 'min4':[], 'scn2':[], \\\n\t\t         'excl':[], 'exc2':[], 'exc3':[], 'null':[], 'eval':[]}, \\\n            assigninfill = {'stdrdinfill':[], 'MLinfill':[], 'zeroinfill':[], 'oneinfill':[], \\\n                            'adjinfill':[], 'meaninfill':[], 'medianinfill':[], 'modeinfill':[]}, \\\n            transformdict = {}, processdict = {}, \\\n            printstatus = True)\n</code></pre>\n<ul>\n<li>\n<p>df_train: a pandas dataframe or numpy array containing a structured\ndataset intended for use to subsequently train a machine learning model.\nThe set at a minimum should be 'tidy' meaning a single column per feature\nand a single row per observation. If desired the set may include a row ID\ncolumn and a column intended to be used as labels for a downstream\ntraining operation. The tool supports the inclusion of non-index-range\ncolumn as index or multicolumn index (requires named index columns). Such\nindex types are added to the returned \"ID\" sets which are consistently\nshuffled and partitioned as the train and test sets.</p>\n</li>\n<li>\n<p>df_test: a pandas dataframe or numpy array containing a structured\ndataset intended for use to generate predictions from a downstream machine\nlearning model trained from the automunge returned sets. The set must be\nconsistantly formated as the train set with consistent column labels and/or\norder of columns. (This set may optionally contain a labels column if one\nwas included in the train set although it's inclusion is not required). If\ndesired the set may include a row ID column or a column intended for use as\nlabels. A user may pass False if this set not available. The tool supports\nthe inclusion of non-index-range column as index or multicolumn index\n(requires named index columns). Such index types are added to the returned\n\"ID\" sets which are consistently shuffled and partitioned as the train and\ntest sets.</p>\n</li>\n<li>\n<p>labels_column: a string of the column title for the column from the\ndf_train set intended for use as labels in training a downstream machine\nlearning model. The function defaults to False for cases where the\ntraining set does not include a label column. An integer column index may\nalso be passed such as if the source dataset was numpy array.</p>\n</li>\n<li>\n<p>trainID_column: a string of the column title for the column from the\ndf_train set intended for use as a row identifier value (such as could\nbe sequential numbers for instance). The function defaults to False for\ncases where the training set does not include an ID column. A user can\nalso pass a list of string columns titles such as to carve out multiple\ncolumns to be excluded from processing but consistently partitioned. An\ninteger column index or list of integer column indexes may also be passed\nsuch as if the source dataset was numpy array.</p>\n</li>\n<li>\n<p>testID_column: a string of the column title for the column from the\ndf_test set intended for use as a row identifier value (such as could be\nsequential numbers for instance). The function defaults to False for\ncases where the training set does not include an ID column. A user can\nalso pass a list of string columns titles such as to carve out multiple\ncolumns to be excluded from processing but consistently partitioned. An\ninteger column index or list of integer column indexes may also be passed\nsuch as if the source dataset was numpy array.</p>\n</li>\n<li>\n<p>valpercent1: a float value between 0 and 1 which designates the percent\nof the training data which will be set aside for the first validation\nset (generally used for hyperparameter tuning of a downstream model).\nThis value defaults to 0. (Previously the default here was set at 0.20 but\nthat is fairly an arbitrary value and a user may wish to deviate for\ndifferent size sets. Note that this value may be set to 0 if no validation\nset is needed (such as may be the case for k-means validation).)</p>\n</li>\n<li>\n<p>valpercent2: a float value between 0 and 1 which designates the percent\nof the training data which will be set aside for the second validation\nset (generally used for final validation of a model prior to release).\nThis value defaults to 0. (Previously the default was set at 0.10 but that\nis fairly an arbitrary value and a user may wish to deviate for different\nsize sets.)</p>\n</li>\n<li>\n<p>floatprecision: an integer with acceptable values of 16/32/64 designating\nthe memory precision for returned float values. (A tradeoff between memory\nusage and floating point precision, smaller for smaller footprint.)</p>\n</li>\n<li>\n<p>shuffletrain: a boolean identifier (True/False) which indicates if the\nrows in df_train will be shuffled prior to carving out the validation\nsets. Note that if this value is set to False then the validation sets\nwill be pulled from the bottom x% sequential rows of the dataframe.\n(Where x% is the sum of validation ratios.) Note that if this value is\nset to False although the validations will be pulled from sequential\nrows, the split between validaiton1 and validation2 sets will be\nrandomized. This value defaults to False.</p>\n</li>\n<li>\n<p>TrainLabelFreqLevel: a boolean identifier (True/False) which indicates\nif the TrainLabelFreqLevel method will be applied to oversample training\ndata associated with underrepresented labels. The method adds multiples\nto training data rows for those labels with lower frequency resulting in\nan (approximately) levelized frequency. This defaults to False. Note that\nthis feature may be applied to numerical label sets if the processing\napplied to the set includes standard deviation bins.</p>\n</li>\n<li>\n<p>powertransform: a boolean identifier (True/False) which indicates if an\nevaluation will be performed of distribution properties to select between\nbox-cox, z-score, min-max scaling, or mean absolute deviaiton scaling\nnormalization. Note that after application of box-cox transform child columns\nare generated for a subsequent z-score normalization as well as a set of bins\nassociated with number of standard deviations from the mean. Please note that\nI don't consider the current means of distribution property evaluation very\nsophisticated and we will continue to refine this method with further research\ngoing forward. This defaults to False.</p>\n</li>\n<li>\n<p>binstransform: a boolean identifier (True/False) which indicates if the\nnumerical sets will receive bin processing such as to generate child\ncolumns with boolean identifiers for number of standard deviations from\nthe mean, with groups for values &lt;-2, -2-1, -10, 01, 12, and &gt;2 . Note\nthat the bins and bint transformations are the same, only difference is\nthat the bint transform assumes the column has already been normalized\nwhile the bins transform does not. This value defaults to False.</p>\n</li>\n<li>\n<p>MLinfill: a boolean identifier (True/False) which indicates if the ML\ninfill method will be applied as a default to predict infill for missing\nor improperly formatted data using machine learning models trained on the\nrest of the set. This defaults to False.</p>\n</li>\n<li>\n<p>infilliterate: an integer indicating how many applications of the ML\ninfill processing are to be performed for purposes of predicting infill.\nThe assumption is that for sets with high frequency of missing values\nthat multiple applications of ML infill may improve accuracy although\nnote this is not an extensively tested hypothesis. This defaults to 1.</p>\n</li>\n<li>\n<p>randomseed: a postitive integer used as a seed for randomness in data\nset shuffling, ML infill, and fearture importance  algorithms. This\ndefaults to 42, a nice round number.</p>\n</li>\n<li>\n<p>forcetocategoricalcolumns: a list of string identifiers of column titles\nfor those columns which are to be treated as categorical to allow\none-hot encoding. This may be useful e.g. for numerically encoded\ncategorical sets such as like zip codes or phone numbers or something\nwhich would otherwise be evaluated as numerical and subject to\nnormalization. *update this aregument no longer supported, a user can\ninstead assign distinct methods to each column with assigncat per below,\nsuch as assigning a column to category 'text' for categorical.</p>\n</li>\n<li>\n<p>numbercategoryheuristic: an integer used as a heuristic. When a\ncategorical set has more unique values than this heuristic, it defaults\nto categorical treatment via ordinal processing. This defaults to 15.</p>\n</li>\n<li>\n<p>pandasoutput: a selector for format of returned sets. Defaults to False\nfor returned Numpy arrays. If set to True returns pandas dataframes\n(note that index is not preserved in the train/validation split, an ID\ncolumn may be passed for index identification).</p>\n</li>\n<li>\n<p>NArw_marker: a boolean identifier (True/False) which indicates if the\nreturned sets will include columns with markers for rows subject to\ninfill (columns with suffix 'NArw'). This value defaults to True.</p>\n</li>\n<li>\n<p>featureselection: a boolean identifier telling the function whether to\nperform a feature importance evaluation. If selected automunge will\nreturn a summary of feature importance findings in the featureimportance\nreturned dictionary. This also activates the trimming of derived sets\nthat did not meet the importance threshold if [featurepct &lt; 1.0 and\nfeaturemethod = 'pct'] or if [fesaturemetric &gt; 0.0 and featuremethod =\n'metric']. Note this defaults to False because it cannot operate without\na designated label column in the train set. Note that the user-specified\nsize of validationratios if passed are used in this method.</p>\n</li>\n<li>\n<p>featurepct: the percentage of derived sets that are kept in the output\nbased on the feature importance evaluation. Note that NArw columns are\nexcluded from the trimming for now (the inclusion of NArws in trimming\nwill likely be included in a future expansion). This item only used if\nfeaturemethod passed as 'pct' (the default).</p>\n</li>\n<li>\n<p>featuremetric: the feature importance metric below which derived sets\nare trimmed from the output. Note that this item only used if\nfeaturemethod passed as 'metric'.</p>\n</li>\n<li>\n<p>featuremethod: can be passed as either 'pct' or 'metric' to select which\nfeature importance method is used for trimming the derived sets. Or can pass\nas 'default' for ignoring the featurepct/featuremetric parameters or can\npass as 'report' to return the featureimportance results with no further\nprocessing (other returned sets are empty).</p>\n</li>\n<li>\n<p>PCAn_components: a user can pass an integer to define the number of PCA\nderived features for purposes of dimensionality reduction, such integer to\nbe less than the otherwise returned number of sets. Function will default\nto kernel PCA for all non-negative sets or otherwise Sparse PCA. Also if\nthis values passed as a float &lt;1.0 then linear PCA will be applied such\nthat the returned number of sets are the minimum number that can reproduce\nthat percent of the variance. Note this can also be passed in conjunction\nwith assigned PCA type or parameters in the ML_cmnd object.</p>\n</li>\n<li>\n<p>PCAexcl: a list of column headers for columns that are to be excluded from\nany application of PCA</p>\n</li>\n<li>\n<p>ML_cmnd:</p>\n</li>\n</ul>\n<pre><code>ML_cmnd = {'MLinfill_type':'default', \\\n           'MLinfill_cmnd':{'RandomForestClassifier':{}, 'RandomForestRegressor':{}}, \\\n           'PCA_type':'default', \\\n           'PCA_cmnd':{}}, \\\n</code></pre>\n<p>The ML_cmnd allows a user to pass parameters to the predictive algorithms\nused for ML infill and feature importance evaluation. Currently the only\noption for 'MLinfill_type' is default which uses Scikit-Learn's Random\nForest implementation, the intent is to add other options in a future extension.\nFor example, a user wishing to pass a custom parameter of max_depth for to the\nRandom Forest algorithms could pass:\n_</p>\n<pre><code>ML_cmnd = {'MLinfill_type':'default', \\\n           'MLinfill_cmnd':{'RandomForestClassifier':{'max_depth':4}, \\\n                            'RandomForestRegressor':{'max_depth':4}}, \\\n           'PCA_type':'default', \\\n           'PCA_cmnd':{}}, \\\n\n#(note that currently unable to pass RF parameters to criterion and n_jobs)\n</code></pre>\n<p>A user can also assign specific methods for PCA transforms. Current PCA_types\nsupported include 'PCA', 'SparsePCA', and 'KernelPCA', all via Scikit-Learn.\nNote that the n_components are passed seperately with the PCAn_components\nargument noted above. A user can also pass parameters to the PCA functions\nthrough the PCA_cmnd, for example one could pass a kernel type for KernelPCA\nas:</p>\n<pre><code>ML_cmnd = {'MLinfill_type':'default', \\\n           'MLinfill_cmnd':{'RandomForestClassifier':{}, \\\n                            'RandomForestRegressor':{}}, \\\n           'PCA_type':'KernelPCA', \\\n           'PCA_cmnd':{'kernel':'sigmoid'}}, \\\n\n#Also note that SparsePCA currenlty doesn't have available\n#n_jobs or normalize_components, and similarily KernelPCA \n#doesn't have available n_jobs.\n</code></pre>\n<p>Note that the PCA is currently defaulted to active for cases where the\ntrain set number of features is &gt;0.50 the number of rows. A user can\nchange this ratio by passing 'PCA_cmnd':{'col_row_ratio':0.22}} for\ninstance. Also a user can simply turn off default PCA transforms by\npassing 'PCA_cmnd':{'PCA_type':'off'}. A user can also exclude returned\nboolean (0/1) columns from any PCA application by passing\n'PCA_cmnd':{'bool_PCA_excl':True}\nor exclude returned boolean and ordinal columns from PCA application by\n'PCA_cmnd':{'bool_ordl_PCAexcl':True}\nsuch as could potentially result in memory savings.</p>\n<ul>\n<li>assigncat:</li>\n</ul>\n<pre><code>#Here are the current trasnformation options built into our library, which\n#we are continuing to build out. A user may also define their own.\n\n    assigncat = {'mnmx':[], 'mnm2':[], 'mnm3':[], 'mnm4':[], 'mnm5':[], 'mnm6':[], \\\n\t\t 'nmbr':[], 'nbr2':[], 'nbr3':[], 'MADn':[], 'MAD2':[], 'MAD3':[], \\\n\t\t 'bins':[], 'bint':[], \\\n\t\t 'bxcx':[], 'bxc2':[], 'bxc3':[], 'bxc4':[], \\\n\t\t 'log0':[], 'log1':[], 'pwrs':[], \\\n\t\t 'bnry':[], 'text':[], '1010':[], 'or10':[], 'om10':[], \\\n\t\t 'ordl':[], 'ord2':[], 'ord3':[], 'ord4':[], 'mmor':[], \\\n\t\t 'date':[], 'dat2':[], 'dat6':[], 'wkdy':[], 'bshr':[], 'hldy':[], \\\n\t\t 'yea2':[], 'mnt2':[], 'mnt6':[], 'day2':[], 'day5':[], \\\n\t\t 'hrs2':[], 'hrs4':[], 'min2':[], 'min4':[], 'scn2':[], \\\n\t\t 'excl':[], 'exc2':[], 'exc3':[], 'null':[], 'eval':[]}\n</code></pre>\n<p>A user may add column identifier strings to each\nof these lists to designate this specific processing approach. Note that\nthis processing category will serve as the \"root\" of the tree of\ntransforms as defined in the transformdict. Note that additional\ncategories may be passed if defined in the passed transformdict and\nprocessdict. An example of usage here could be if a user wanted to only\nprocess numerical columns 'nmbrcolumn1' and 'nmbrcolumn2' with z-score\nnormalization instead of the full range of numerical derivations they\ncould pass assigncat = {'nbr2':['nmbrcolumn1'], ...}. We'll provide\ndetails on each of the built-in library of transformations below.</p>\n<ul>\n<li>assigninfill</li>\n</ul>\n<pre><code>#Here are the current infill options built into our library, which\n#we are continuing to build out.\nassigninfill = {'stdrdinfill':[], 'MLinfill':[], 'zeroinfill':[], 'oneinfill':[], \\\n                'adjinfill':[], 'meaninfill':[], 'medianinfill':[], 'modeinfill':[]}, \\\n</code></pre>\n<p>A user may add column identifier strings to each of these lists to\ndesignate the column-specific infill approach for missing or\nimproperly formated values. Note that this infill category defaults to\nMLinfill if nothing assigned and the MLinfill argument to automunge is\nset to True. stdrdinfill means: mean for numeric sets, most common for\nbinary, and new column boolean for categorical. zeroinfill means inserting\nthe integer 0 to missing cells. oneinfill means inserting the integer 1.\nadjinfill means passing the value from the preceding row to missing cells.\nmeaninfill means inserting the mean derived from the train set to numeric\ncolumns. medianinfill means inserting the median derived from the train\nset to numeric columns. (Note currently boolean columns derived from\nnumeric are not supported for mean/median and for those cases default to\nthose infill from stdrdinfill.) modeinfill means inserting the most common\ncvalue for a set, note that modeinfill supports one-hot encoded sets.</p>\n<ul>\n<li>transformdict: allows a user to pass a custom tree of transformations.\nNote that a user may define their own 4 character string \"root\"\nidentifiers for a series of processing steps using the categories\nof processing already defibned in our library and then assign columns\nin assigncat, or for custom processing functions this method should\nbe combined with processdict which is only slightly more complex.\nFor example, a user wishing to define a new set of transformations\nfor numerical series 'newt' that combines NArows, min-max, box-cox, z-score,\nand standard deviation bins could do so by passing a trasnformdict as:</li>\n</ul>\n<pre><code>transformdict =  {'newt' : {'parents' : ['bxc4'], \\\n                            'siblings': [], \\\n                            'auntsuncles' : ['mnmx'], \\\n                            'cousins' : ['NArw'], \\\n                            'children' : [], \\\n                            'niecesnephews' : [], \\\n                            'coworkers' : [], \\\n                            'friends' : []}}\n\n#Where since bxc4 is passed as a parent, this will result in pulling\n#ofspring keys from the bxcx family tree, which has a nbr2 key as children.\n\n#from automunge library:\n    transform_dict.update({'bxc4' : {'parents' : ['bxcx'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : [], \\\n                                     'cousins' : ['NArw'], \\\n                                     'children' : ['nbr2'], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n#note that 'nmbr' is passed as a children primitize meaning if nbr2 key\n#has any offspring those will be produced as well.\n\n\n</code></pre>\n<p>Basically here 'newt' is the key and when passed to one of the family primitives\nthe corresponding process function is applied, and if it is passed to a family\nprimitive with downstream offspring then those offspring keys are pulled from\nthat key's family tree. For example, here mnmx is passed as an auntsuncles which\nmeans the mnmx processing function is applied with no downstream offspring. The\nbxcx key is passed as a parent which means the bxcx trasnform is applied coupled\nwith any downstream transforms from the bxcx key family tree, which we also show.\nNote the family primitives tree of transformations can be summarized as:</p>\n<pre><code>'parents' :           upstream / first generation / replaces column / with offspring\n'siblings':           upstream / first generation / supplements column / with offspring\n'auntsuncles' :       upstream / first generation / replaces column / no offspring\n'cousins' :           upstream / first generation / supplements column / no offspring\n'children' :          downstream parents / offspring generations / replaces column / with offspring\n'niecesnephews' :     downstream siblings / offspring generations / supplements column / with offspring\n'coworkers' :         downstream auntsuncles / offspring generations / replaces column / no offspring\n'friends' :           downstream cousins / offspring generations / supplements column / no offspring\n</code></pre>\n<p>Note that when we define a new transform such as 'newt' above, we also need\nto define a corresponding processdict entry for the new category, which we\ndemonstrate here:</p>\n<ul>\n<li>processdict: allows a user to define their own processing functions\ncorresponding to new transformdict keys. We'll describe the entries here:</li>\n</ul>\n<pre><code>#for example \nprocessdict =  {'newt' : {'dualprocess' : None, \\\n\t\t\t  'singleprocess' : None, \\\n\t\t\t  'postprocess' : None, \\\n        \t          'NArowtype' : 'numeric', \\\n      \t\t          'MLinfilltype' : 'numeric', \\\n           \t\t  'labelctgy' : 'mnmx'}}\n\n#A user should pass either a pair of processing functions to both \n#dualprocess and postprocess, or alternatively just a single processing\n#function to singleprocess, and pass None to those not used.\n#For now, if just using the category as a root key and not as a family primitive, \n#can simply pass None to all the processing slots. We'll demonstrate their \n#composition and data structures for custom processing functions later in this \n#document.\n\n#dualprocess: for passing a processing function in which normalization \n#             parameters are derived from properties of the training set\n#             and jointly process the train set and if available test set\n\n#singleprocess: for passing a processing function in which no normalization\n#               parameters are needed from the train set to process the\n#               test set, such that train and test sets processed seperately\n\n#postprocess: for passing a processing function in which normalization \n#             parameters originally derived from the train set are applied\n#             to seperately process a test set\n\n#NArowtype: can be entries of either 'numeric', 'justNaN', or 'exclude' where\n#\t\t\t'numeric' refers to columns where non-numeric entries are subject\n#\t\t\t\t\t  to infill\n#\t\t\t'justNaN' refers to columns where only NaN entries are subject\n#\t\t\t          to infill\n#\t\t\t'exclude' refers to columns where no infill will be performed\n\n#MLinfilltype: can be entries of 'numeric', 'singlct', 'multirt', 'exclude'\n#              'multisp', 'exclude', or 'label' where\n#\t\t\t   'numeric' refers to columns where predictive algorithms treat\n#\t\t\t   as a regression for numeric sets\n#\t\t\t   'singlect' refers to columns where category gives a single\n#\t\t\t   column where predictive algorithms treat as a boolean classifier\n#\t\t\t   'multirt' refers to category returning multiple columns where \n#\t\t\t   predictive algorithms treat as a multi modal classifier\n#\t\t\t   'exclude' refers to categories excluded from predcitive address\n#\t\t\t   'multisp' tbh I think this is just a duplicate of multirt, a\n#\t\t\t   future update may strike this one\n#\t\t\t   'label' refers to categories specifically intended for label\n#\t\t\t   processing\n\n</code></pre>\n<ul>\n<li>printstatus: user can pass True/False indicating whether the function will print\nstatus of processing during operation. Defaults to True.</li>\n</ul>\n<p>Ok well we'll demonstrate further below how to build custom processing functions,\nfor now this just gives you sufficient tools to build sets of processing using\nthe built in sets in the library.</p>\n<p>...</p>\n<h1>postmunge</h1>\n<p>The postmunge(.) function is intended to consistently process subsequently available\nand consistently formatted test data with just a single function call. It requires\npassing the postprocess_dict object returned from the original application of automunge\nand that the passed test data have consistent column header labeling as the original\ntrain set.</p>\n<pre><code>\n#for postmunge(.) function on subsequently available test data\n#using the postprocess_dict object returned from original automunge(.) application\n\n#Remember to initialize automunge\nfrom AutoMunge_pkg import AutoMunge\nam = AutoMunge.AutoMunge()\n\n\n#Then we can run postmunge function as:\n\ntest, testID, testlabels, \\\nlabelsencoding_dict, finalcolumns_test = \\\nam.postmunge(postprocess_dict, df_test, testID_column = False, \\\n             labelscolumn = False, pandasoutput=True, printstatus = True, \\\n             TrainLabelFreqLevel = False, featureeval = False):\n</code></pre>\n<h2>postmunge(.) returned sets:</h2>\n<p>Here now are descriptions for the returned sets from postmunge, which\nwill be followed by descriptions of the arguments which can be passed to\nthe function.</p>\n<ul>\n<li>\n<p>test: the set of features, consistently encoded and normalized as the\ntraining data, that can be used to generate predictions from a model\ntrained with the np_train set from automunge.</p>\n</li>\n<li>\n<p>testID: the set of ID values coresponding to the test set.</p>\n</li>\n<li>\n<p>testlabels: a set of numerically encoded labels corresponding to the\ntest set if a label column was passed. Note that the function\nassumes the label column is originally included in the train set. Note\nthat if the labels set is a single column a returned numpy array is\nflattened (e.g. [[1,2,3]] converted to [1,2,3] )</p>\n</li>\n<li>\n<p>labelsencoding_dict: this is the same labelsencoding_dict returned from\nautomunge, it's used in case one wants to reverse encode predicted labels</p>\n</li>\n<li>\n<p>finalcolumns_test: a list of the column headers corresponding to the\ntest data. Note that the inclusion of suffix appenders is used to\nidentify which feature engineering transformations were applied to each\ncolumn. Note that this list should match the one from automunge.</p>\n</li>\n</ul>\n<p>...</p>\n<h2>postmunge(.) passed arguments</h2>\n<pre><code>\n#for postmunge(.) function on subsequently available test data\n#using the postprocess_dict object returned from original automunge(.) application\n\n#Remember to initialize automunge\nfrom AutoMunge_pkg import AutoMunge\nam = AutoMunge.AutoMunge()\n\n\n#Then we can run postmunge function as:\n\ntest, testID, testlabels, \\\nlabelsencoding_dict, finalcolumns_test = \\\nam.postmunge(postprocess_dict, df_test, testID_column = False, \\\n             labelscolumn = False, pandasoutput=True, printstatus = True, \\\n             TrainLabelFreqLevel = False, featureeval = False)\n</code></pre>\n<ul>\n<li>\n<p>postprocess_dict: this is the dictionary returned from the initial\napplication of automunge which included normalization parameters to\nfacilitate consistent processing of test data to the original processing\nof the train set. This requires a user to remember to download the\ndictionary at the original application of automunge, otherwise if this\ndictionary is not available a user can feed this subsequent test data to\nthe automunge along with the original train data exactly as was used in\nthe original automunge call.</p>\n</li>\n<li>\n<p>df_test: a pandas dataframe or numpy array containing a structured\ndataset intended for use to generate predictions from a machine learning\nmodel trained from the automunge returned sets. The set must be consistantly\nformated as the train set with consistent order of columns and if labels are\nincluded consistent labels. If desired the set may include an ID column. The\ntool supports the inclusion of non-index-range column as index or multicolumn\nindex (requires named index columns). Such index types are added to the\nreturned \"ID\" sets which are consistently shuffled and partitioned as the\ntrain and test sets.</p>\n</li>\n<li>\n<p>testID_column: a string of the column title for the column from the\ndf_test set intended for use as a row identifier value (such as could be\nsequential numbers for instance). The function defaults to False for\ncases where the training set does not include an ID column. A user can\nalso pass a list of string columns titles such as to carve out multiple\ncolumns to be excluded from processing but consistently partitioned. An\ninteger column index or list of integer column indexes may also be passed\nsuch as if the source dataset was numpy array.</p>\n</li>\n<li>\n<p>labelscolumn: default to False indicates that a labels column is not\nincluded in the test set passed to postmunge. A user can either pass\nTrue or the string ID of the labels column, noting that it is a requirement\nthat the labels column header string must be consistent with that from\nthe original train set. An integer column index may also be passed such\nas if the source dataset was numpy array.</p>\n</li>\n<li>\n<p>pandasoutput: a selector for format of returned sets. Defaults to False\nfor returned Numpy arrays. If set to True returns pandas dataframes\n(note that index is not preserved, an ID column may be passed for index\nidentification).</p>\n</li>\n<li>\n<p>printstatus: user can pass True/False indicating whether the function\nwill print status of processing during operation. Defaults to True.</p>\n</li>\n<li>\n<p>TrainLabelFreqLevel: a boolean identifier (True/False) which indicates\nif the TrainLabelFreqLevel method will be applied to oversample test\ndata associated with underrepresented labels. The method adds multiples\nto test data rows for those labels with lower frequency resulting in\nan (approximately) levelized frequency. This defaults to False. Note that\nthis feature may be applied to numerical label sets if the processing\napplied to the set includes standard deviation bins.</p>\n</li>\n<li>\n<p>featureeval: a boolean identifier (True/False) to activate a feature\nimportance evaluation, comparable to one performed in automunge but based\non the test set passed to postmunge. Currently the results report is not\nreturned as an object, the results are printed in the output (for backward\ncompatibility).</p>\n</li>\n</ul>\n<p>...</p>\n<h2>Library of Transformations</h2>\n<p>Automunge has a built in library of transformations that can be passed for\nspecific columns with assigncat. A column if left unassigned will defer to\nthe automated default methods.  For example, a user can pass a min-max\nscaling method to a specific column 'col1' with:</p>\n<pre><code>assigncat = {'mnmx':['col1']}\n</code></pre>\n<p>When a user assigns a column to a specific category, that category is treated\nas the root category for the tree of transformations. Each key has an\nassociated transformation function, and that transformation function is only\napplied if the root key is also found in the tree of family primitives. The\ntree of family primitives, as introduced earlier, applies first the first\ngeneration transforms of greatgrandparents and grandparents specific to the\noriginal root key, and then any transforms for keys found in upstream primitives\ni.e. parents/siblings/auntsuncles/cousins. If a transform is applied for a\nprimitive that includes downstream offspring, such as parents/\nsiblings, then the family tree for that key with offspring is inspected to determine\ndownstream offspring categories, for example if we have a parents key of 'mnmx',\nthen any children/niecesnephews/coworkers/friends in the 'mnmx' family tree will\nbe applied as parents/siblings/auntsuncles/cousins, respectively. Note that the\ndesignation for supplements/replaces refers purely to the question of whether the\ncolumn to which the trasnform is being applied is kept in place or removed. Please\nnote that it is a quirck of the function that no original column can be left in\nplace without the application of some transformation such as to allow the building\nof the apppripriate data structures, thus at least one replacement primitive must\nalways be included. If a user does wish to leave a column in place unaltered, they\ncan simply assign that column to the 'excl' root category.</p>\n<p>Now we'll start here by listing again the family tree primitives for those root\ncategories built into the automunge library. After that we'll give a quick\nnarrative for each of the associated transformation functions. First here again\nare the family tree primitives.</p>\n<pre><code>'parents' :           upstream / first generation / replaces column / with offspring\n'siblings':           upstream / first generation / supplements column / with offspring\n'auntsuncles' :       upstream / first generation / replaces column / no offspring\n'cousins' :           upstream / first generation / supplements column / no offspring\n'children' :          downstream parents / offspring generations / replaces column / with offspring\n'niecesnephews' :     downstream siblings / offspring generations / supplements column / with offspring\n'coworkers' :         downstream auntsuncles / offspring generations / replaces column / no offspring\n'friends' :           downstream cousins / offspring generations / supplements column / no offspring\n</code></pre>\n<p>Here is a quick description of the transformation functions associated\nwith each key which can be assigned to a primitive (and not just used as\na root key). We're continuing to build out this library of transformations.</p>\n<ul>\n<li>NArw: produces a column of boolean identifiers for rows in the source\ncolumn with missing or improperly formatted values.</li>\n<li>nmbr/nbr2/nbr3: z-score normalization</li>\n<li>MADn/MAD2: mean absolute deviation normalization, subtract set mean</li>\n<li>MAD3: mean absolute deviation normalization, subtract set maximum</li>\n<li>mnmx/mnm2/mnm5: vanilla min-max scaling</li>\n<li>mnm3/mnm4: min-max scaling with outliers capped at 0.01 and 0.99 quantiles</li>\n<li>mnm6: min-max scaling with test set capped at min/max of train set</li>\n<li>bnry: converts sets with two values to boolean identifiers</li>\n<li>text: converts categorical sets to one-hot encoded set of boolean identifiers</li>\n<li>ordl/ord2: converts categorical sets to ordinally encoded set of integer identifiers</li>\n<li>ord3/ord4: converts categorical sets to ordinally encoded set of integer identifiers\nsorted by frequency of category occurance</li>\n<li>1010: converts categorical sets to binary encoding (more efficent than one-hot encoding)</li>\n<li>bxcx/bxc2/bxc3/bxc4: performs Box-Cox power law transformation</li>\n<li>log0/log1: performs logarithmic transofrm (base 10)</li>\n<li>pwrs: bins groupings by powers of 10</li>\n<li>date/dat2: for datetime formatted data, segregates data by time scale to multiple\ncolumns (year/month/day/hour/minute/second) and then performs z-score normalization</li>\n<li>wkdy: boolean identifier indicating whether a datetime object is a weekday</li>\n<li>bshr: boolean identifier indicating whether a datetime object is a business\nhour (9-5, time zone unaware)</li>\n<li>hldy: boolean identifier indicating whether a datetime object is a US Federal\nholiday</li>\n<li>year/mnth/days/hour/mint/scnd: segregated by time scale and z-score normalization</li>\n<li>mnsn/mncs/dysn/dycs/hrsn/hrcs/misn/mics/scsn/sccs: segregated by time scale and\ndual columns with sin and cos transformations for time scale period</li>\n<li>mdsn/mdcs: similar sin/cos treatment, but for combined month/day</li>\n<li>hmss/hmsc: similar sin/cos treatment, but for combined hour/minute/second</li>\n<li>bins: for numerical sets, outputs a set of 6 columns indicating where a\nvalue fell with respect to number of standard deviations from the mean of the\nset (i.e. &lt;-2, -2-1, -10, 01, 12, &gt;2)</li>\n<li>bint: comparable to bins except assumes that source data was already normalized</li>\n<li>null: deletes source column</li>\n<li>excl: passes source column un-altered</li>\n<li>exc2: passes source column unaltered except for infill</li>\n<li>eval: performs distribution property evaluation consistent with the automunge\n'powertransform' parameter to designated column</li>\n</ul>\n<p>And here arethe series of family trees currently built into the internal library.</p>\n<pre><code>    transform_dict.update({'nmbr' : {'parents' : ['nmbr'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : [], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : [bint]}})\n\n    transform_dict.update({'bnry' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['bnry'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'text' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['text'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'ordl' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['ordl'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'ord2' : {'parents' : ['ord2'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : [], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : ['mnmx'], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'ord3' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['ord3'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'ord4' : {'parents' : ['ord4'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : [], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : ['mnmx'], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'or10' : {'parents' : ['ord4'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['1010'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : ['mnmx'], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'om10' : {'parents' : ['ord4'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['1010', 'mnmx'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : ['mnmx'], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mmor' : {'parents' : ['ord4'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnmx'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'1010' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['1010'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'null' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['null'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'NArw' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : [NArw], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'rgrl' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['nmbr'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'nbr2' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['nmbr'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'nbr3' : {'parents' : ['nbr3'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : [], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : ['bint']}})\n\n    transform_dict.update({'MADn' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['MADn'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'MAD2' : {'parents' : ['MAD2'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : [], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : ['nmbr'], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'MAD3' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['MAD3'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnmx' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnmx'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnm2' : {'parents' : ['nmbr'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnmx'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnm3' : {'parents' : ['nmbr'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnm3'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnm4' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnm3'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnm5' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnmx'], \\\n                                     'cousins' : ['nmbr', NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnm6' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnm6'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnm7' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnmx', 'bins'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'date' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['year', 'mnth', 'days', 'hour', 'mint', 'scnd'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'dat2' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['bshr', 'wkdy', 'hldy'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'dat3' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['year', 'mnsn', 'mncs', 'dysn', 'dycs', 'hrsn', 'hrcs', 'misn', 'mics', 'scsn', 'sccs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'dat4' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['year', 'mdsn', 'mdcs', 'hmss', 'hmsc'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'dat5' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['year', 'mdsn', 'mdcs', 'dysn', 'dycs', 'hmss', 'hmsc'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'dat6' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['year', 'mdsn', 'mdcs', 'hmss', 'hmsc', 'bshr', 'wkdy', 'hldy'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'year' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['year'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'yea2' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['year', 'mdsn', 'mdcs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnth' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnth'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnt2' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnsn', 'mncs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnt3' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnsn', 'mncs', 'dysn', 'dycs', 'hrsn', 'hrcs', 'misn', 'mics', 'scsn', 'sccs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnt4' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mdsn', 'mdcs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnt5' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mdsn', 'mdcs', 'hmss', 'hmsc'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnt6' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mdsn', 'mdcs', 'dysn', 'dycs', 'hmss', 'hmsc'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mnsn' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mnsn'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mncs' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mncs'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mdsn' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mdsn'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mdcs' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mdcs'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'days' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['days'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'day2' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['dysn', 'dycs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'day3' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['dysn', 'dycs', 'hrsn', 'hrcs', 'misn', 'mics', 'scsn', 'sccs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'day4' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['dhms', 'dhmc'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'day5' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['dhms', 'dhmc', 'hmss', 'hmsc'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'dysn' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['dysn'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'dycs' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['dycs'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'dhms' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['dhms'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'dhmc' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['dhmc'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'hour' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['hour'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'hrs2' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['hrsn', 'hrcs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'hrs3' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['hrsn', 'hrcs', 'misn', 'mics', 'scsn', 'sccs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'hrs4' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['hmss', 'hmsc'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'hrsn' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['hrsn'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'hrcs' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['hrcs'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'hmss' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['hmss'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'hmsc' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['hmsc'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mint' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mint'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'min2' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['misn', 'mics'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'min3' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['misn', 'mics', 'scsn', 'sccs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'min4' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mssn', 'mscs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'misn' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['misn'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mics' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mics'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mssn' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mssn'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'mscs' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['mscs'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'scnd' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['scnd'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'scn2' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['scsn', 'sccs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'scsn' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['scsn'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'sccs' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['sccs'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'bxcx' : {'parents' : ['bxcx'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : [], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : ['nmbr'], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'bxc2' : {'parents' : ['bxc2'], \\\n                                     'siblings': ['nmbr'], \\\n                                     'auntsuncles' : [], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : ['nmbr'], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'bxc3' : {'parents' : ['bxc3'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : [], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : ['nmbr'], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'bxc4' : {'parents' : ['bxc4'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : [], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : ['nbr2'], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'pwrs' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['pwrs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'log0' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['log0'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'log1' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['log0', 'pwrs'], \\\n                                     'cousins' : [NArw], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'wkdy' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['wkdy'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'bshr' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['bshr'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'hldy' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['hldy'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'bins' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['bins'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'bint' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['bint'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'excl' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['excl'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'exc2' : {'parents' : ['exc2'], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : [], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : ['bins'], \\\n                                     'friends' : []}})\n\n    transform_dict.update({'exc3' : {'parents' : [], \\\n                                     'siblings': [], \\\n                                     'auntsuncles' : ['exc2'], \\\n                                     'cousins' : [], \\\n                                     'children' : [], \\\n                                     'niecesnephews' : [], \\\n                                     'coworkers' : [], \\\n                                     'friends' : []}})\n</code></pre>\n<p>...</p>\n<h2>Custom Transformation Functions</h2>\n<p>Ok final item on the agenda, we're going to demonstrate methods to create custom\ntransformation functions, such that a user may customize the feature engineering\nwhile building on all of the extremely useful built in features of automunge such\nas infill methods including ML infill, feature importance, dimensionality reduction,\nand perhaps most importantly the simplest possible way for consistent processing\nof subsequently available data with just a single function call. The transformation\nfunctions will need to be channeled through pandas and incorproate a handful of\nsimple data structures, which we'll demonstrate below.</p>\n<p>Let's say we want to recreate the mm3 category which caps outliers at 0.01 and 0.99\nquantiles, but instead make it the 0.001 and 0.999 quantiles. Well we'll call this\ncateogry mnm8. So in order to pass a custom transformation function, first we'll need to\ndefine a new root category trasnformdict and a corresponding processdict.</p>\n<pre><code>#Let's creat ea really simple family tree for the new root category mnmn8 which\n#simply creates a column identifying any rows subject to infill (NArw), performs \n#a z-score normalization, and seperately performs a version of the new transform\n#mnm8 which we'll define below.\n\ntransformdict = {'mnm8' : {'parents' : [], \\\n                           'siblings': [], \\\n                           'auntsuncles' : ['mnm8', 'nmbr'], \\\n                           'cousins' : ['NArw'], \\\n                           'children' : [], \\\n                           'niecesnephews' : [], \\\n                           'coworkers' : [], \\\n                           'friends' : []}, \\\n\n#Note that since this mnm8 requires passing normalization parameters derived\n#from the train set to process the test set, we'll need to create twop sep[erate \n#trasnformations functions, the first a \"dualprocess\" function that processes\n#both the train and if available a test set swimultaneously, and the second\n#a \"postprocess\" that only processes the test set on it's own.\n\n#So what's being demosnrtated here is that we're passing the functions under\n#dualprocess and postprocess that we'll define below.\n\nprocessdict = {'mnm8' : {'dualprocess' : process_mnm8_class, \\\n                         'singleprocess' : None, \\\n                         'postprocess' : postprocess_mnm8_class, \\\n                         'NArowtype' : 'numeric', \\\n                         'MLinfilltype' : 'numeric', \\\n                         'labelctgy' : 'mnm8'}}\n\n#Now we have to define the custom processing functions which we are passing through\n#the processdict to automunge.\n\n#Insterad of demosntrating the full functions, I'll just demonstrate the\n#requirements\n\n\n#Here we'll define a \"dualprocess\" function intended to process both a train and\n#test set simulateously. We'll also need to create a seperate \"postprocess\"\n#function intended to just process the test set.\n\n#define the function\ndef process_mnm8_class(mdf_train, mdf_test, column, category, \\\n                       postprocess_dict):\n  #where\n  #mdf_train is the train data set (pandas dataframe)\n  #mdf_test is the consistently formatted test dataset (if no test data \n  #set is available a dummy set will be passed in it's place)\n  #column is the string identifying the column header\n  #category is the 4 charcter string category identifier, here is will be 'mnm8'\n  #postprocess_dict is an object we pass to share data between functions if needed\n\n  #create thee new column, using the catehgory key as a suffix identifier\n\n  #copy source column into new column\n  mdf_train[column + '_mnm8'] = mdf_train[column].copy()\n  mdf_test[column + '_mnm8'] = mdf_test[column].copy()\n\n\n  #perform an initial infill method, here we use mean as a plug, automunge\n  #will seperately perform a infill method per user specifications elsewhere\n  #convert all values to either numeric or NaN\n  mdf_train[column + '_mnm8'] = pd.to_numeric(mdf_train[column + '_mnm8'], errors='coerce')\n  mdf_test[column + '_mnm8'] = pd.to_numeric(mdf_test[column + '_mnm8'], errors='coerce')\n\n\n\n  #Now we do the specifics of the processing function, here we're demonstrating\n  #the min-max scaling method capping values at 0.001 and 0.999 quantiles\n\n  #get maximum value of training column\n  quantilemax = mdf_train[column + '_mnm8'].quantile(.999)\n\n  #get minimum value of training column\n  quantilemin = mdf_train[column + '_mnm8'].quantile(.001)\n\n  #replace values &gt; quantilemax with quantilemax\n  mdf_train.loc[mdf_train[column + '_mnm8'] &gt; quantilemax, (column + '_mnm8')] \\\n  = quantilemax\n  mdf_test.loc[mdf_train[column + '_mnm8'] &gt; quantilemax, (column + '_mnm8')] \\\n  = quantilemax\n  #replace values &lt; quantile10 with quantile10\n  mdf_train.loc[mdf_train[column + '_mnm8'] &lt; quantilemin, (column + '_mnm8')] \\\n  = quantilemin\n  mdf_test.loc[mdf_train[column + '_mnm8'] &lt; quantilemin, (column + '_mnm8')] \\\n  = quantilemin\n\n\n  #note the infill method is now completed after the quantile evaluation / replacement\n  #get mean of training data\n  mean = mdf_train[column + '_mnm8'].mean()    \n  #replace missing data with training set mean\n  mdf_train[column + '_mnm8'] = mdf_train[column + '_mnm8'].fillna(mean)\n  mdf_test[column + '_mnm8'] = mdf_test[column + '_mnm8'].fillna(mean)\n\n\n  #perform min-max scaling to train and test sets using values from train\n  mdf_train[column + '_mnm8'] = (mdf_train[column + '_mnm8'] - quantilemin) / \\\n                                (quantilemax - quantilemin)\n  mdf_test[column + '_mnm8'] = (mdf_test[column + '_mnm8'] - quantilemin) / \\\n                               (quantilemax - quantilemin)\n\n\n  #ok here's where we populate the data structures\n\n  #create list of columns (here it will only be one column returned)\n  nmbrcolumns = [column + '_mnm8']\n\n  #The normalization dictionary is how we pass values between the \"dualprocess\"\n  #function and the \"postprocess\" function\n\n  #Here we populate the normalization dictionary with any values derived from\n  #the train set that we'll need to process the test set.\n  nmbrnormalization_dict = {column + '_mnm8' : {'quantilemin' : quantilemin, \\\n                                                'quantilemax' : quantilemax, \\\n                                                'mean' : mean}}\n\n  #the column_dict_list is returned from the function call and supports the \n  #automunge methods. We populate it as follows:\n\n  #initialize\n  column_dict_list = []\n\n  #where we're storing following\n  #{'category' : 'mnm8', \\ -&gt; identifier of the category fo transform applied\n  # 'origcategory' : category, \\ -&gt; category of original column in train set, passed in function call\n  # 'normalization_dict' : nmbrnormalization_dict, \\ -&gt; normalization parameters of train set\n  # 'origcolumn' : column, \\ -&gt; ID of original column in train set\n  # 'columnslist' : nmbrcolumns, \\ -&gt; a list of columns created in this transform, \n  #                                  later fleshed out to include all columns derived from same source column\n  # 'categorylist' : [nc], \\ -&gt; a list of columns created in this transform\n  # 'infillmodel' : False, \\ -&gt; populated elsewhere, for now enter False\n  # 'infillcomplete' : False, \\ -&gt; populated elsewhere, for now enter False\n  # 'deletecolumn' : False}} -&gt; populated elsewhere, for now enter False\n\n  for nc in nmbrcolumns:\n\n    if nc[-5:] == '_mnm8':\n\n      column_dict = { nc : {'category' : 'mnm8', \\\n                           'origcategory' : category, \\\n                           'normalization_dict' : nmbrnormalization_dict, \\\n                           'origcolumn' : column, \\\n                           'columnslist' : nmbrcolumns, \\\n                           'categorylist' : [nc], \\\n                           'infillmodel' : False, \\\n                           'infillcomplete' : False, \\\n                           'deletecolumn' : False}}\n\n      column_dict_list.append(column_dict.copy())\n\n\n\n  return mdf_train, mdf_test, column_dict_list\n\n  #where mdf_train and mdf_test now have the new column incorporated\n  #and column_dict_list carries the data structures supporting the operation \n  #of automunge. (If the original columkjn was intended for replacement it \n  #will be stricken elsewhere)\n\n\n#and then since this is a method that passes values between the train\n#and test sets, we'll need to define a corresponding \"postproces\" function\n#intended for use on just the test set\n\ndef postprocess_mnm3_class(mdf_test, column, postprocess_dict, columnkey):\n  #where mdf_test is a dataframe fo the test set\n  #column is the string of the column header\n  #postprocess_dict is how we carry packets of datra between the \n  #functions in automunge\n  #columnkey is a key used to access stuff in postprocess_dict if needed\n\n\n  #retrieve normalization parameters from postprocess_dict\n  normkey = column + '_mnm8'\n\n  mean = \\\n  postprocess_dict['column_dict'][normkey]['normalization_dict'][normkey]['mean']\n\n  quantilemin = \\\n  postprocess_dict['column_dict'][normkey]['normalization_dict'][normkey]['quantilemin']\n\n  quantilemax = \\\n  postprocess_dict['column_dict'][normkey]['normalization_dict'][normkey]['quantilemax']\n\n  #copy original column for implementation\n  mdf_test[column + '_mnm8'] = mdf_test[column].copy()\n\n\n  #convert all values to either numeric or NaN\n  mdf_test[column + '_mnm8'] = pd.to_numeric(mdf_test[column + '_mnm8'], errors='coerce')\n\n  #get mean of training data\n  mean = mean  \n\n  #replace missing data with training set mean\n  mdf_test[column + '_mnm8'] = mdf_test[column + '_mnm8'].fillna(mean)\n\n  #perform min-max scaling to test set using values from train\n  mdf_test[column + '_mnm8'] = (mdf_test[column + '_mnm8'] - quantilemin) / \\\n                               (quantilemax - quantilemin)\n\n\n  return mdf_test\n\n#Voila\n\n#One more demonstration, note that if we didn't need to pass any properties\n#between the train and test set, we could have just processed one at a time,\n#and in that case we wouldn't need to define seperate functions for \n#dualprocess and postprocess, we could just define what we call a singleprocess \n#function incorproating similar data strucures but without only a single dataframe \n#passed\n\n#Such as:\ndef process_mnm4_class(df, column, category, postprocess_dict):\n\n  #etc\n\n  return return df, column_dict_list\n\n#For a full demonstration check out my essay \n\"Automunge 1.79: An Open Source Platform for Feature Engineering\"\n\n\n</code></pre>\n<p>And there you have it, you now have all you need to wrangle data on the\nautomunge platform. Feedback is welcome.</p>\n<p>...</p>\n<p>As a citation, please note that the Automunge package makes use of\nthe Pandas, Sciki-learn, and NumPy libraries.</p>\n<p>Wes McKinney. Data Structures for Statistical Computing in Python,\nProceedings of the 9th Python in Science Conference, 51-56 (2010)\n<a href=\"http://conference.scipy.org/proceedings/scipy2010/mckinney.html\" rel=\"nofollow\">publisher\nlink</a></p>\n<p>Fabian Pedregosa, Ga\u00ebl Varoquaux, Alexandre Gramfort, Vincent Michel,\nBertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer,\nRon Weiss, Vincent Dubourg, Jake Vanderplas, Alexandre Passos, David\nCournapeau, Matthieu Brucher, Matthieu Perrot, \u00c9douard Duchesnay.\nScikit-learn: Machine Learning in Python, Journal of Machine Learning\nResearch, 12, 2825-2830 (2011) <a href=\"http://jmlr.org/papers/v12/pedregosa11a.html\" rel=\"nofollow\">publisher\nlink</a></p>\n<p>Sorry I don't know paper to cite, but Numpy website at:\n<a href=\"https://www.numpy.org/\" rel=\"nofollow\">https://www.numpy.org/</a></p>\n<p>...</p>\n<p>Have fun munging!</p>\n<p>...</p>\n<p>You can read more about the tool through the blog posts documenting the\ndevelopment on medium <a href=\"https://medium.com/automunge\" rel=\"nofollow\">here</a> or for more\nwriting I recently completed my first collection of essays titled \"From\nthe Diaries of John Henry\" which is also available on Medium\n<a href=\"https://turingsquared.com\" rel=\"nofollow\">turingsquared.com</a>.</p>\n<p>The AutoMunge website is helpfully located at URL\n<a href=\"https://automunge.com\" rel=\"nofollow\">automunge.com</a>.</p>\n<p>...</p>\n<p>Patent Pending, application 16552857</p>\n\n          </div>"}, "last_serial": 5867886, "releases": {"1.72": [{"comment_text": "", "digests": {"md5": "54898d1c5d473ba2cdb55363f02a8c15", "sha256": "0919cc2fb7c7f1486463ef2c6c43d4203c9efe746987d5ff82d22d4fb692cf20"}, "downloads": -1, "filename": "AutoMunge_pkg-1.72-py3-none-any.whl", "has_sig": false, "md5_digest": "54898d1c5d473ba2cdb55363f02a8c15", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 51402, "upload_time": "2018-12-03T02:31:19", "upload_time_iso_8601": "2018-12-03T02:31:19.339070Z", "url": "https://files.pythonhosted.org/packages/7a/d6/2a5317eac908c712688bfe7371023c0fd3a192f91d04414c2f98bc0ef359/AutoMunge_pkg-1.72-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2aeaee1a23771946cd6c5e5a5db163dd", "sha256": "5647d748e7a3bc835d0ec3a392d101e75ad29fffdf5da29f2706e5fa25d9de11"}, "downloads": -1, "filename": "AutoMunge_pkg-1.72.tar.gz", "has_sig": false, "md5_digest": "2aeaee1a23771946cd6c5e5a5db163dd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 39062, "upload_time": "2018-12-03T02:31:21", "upload_time_iso_8601": "2018-12-03T02:31:21.507113Z", "url": "https://files.pythonhosted.org/packages/97/2e/5393486c48f62369adba6ca6220fe74525ae9762c24a60beff940b964263/AutoMunge_pkg-1.72.tar.gz", "yanked": false}], "1.73": [{"comment_text": "", "digests": {"md5": "a358d259755b201e19f6a40ead1d494c", "sha256": "434ddc441615b0160b830a71383117c2807dcc3d6f2c92d87f64da696f4273d8"}, "downloads": -1, "filename": "AutoMunge_pkg-1.73-py3-none-any.whl", "has_sig": false, "md5_digest": "a358d259755b201e19f6a40ead1d494c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 56307, "upload_time": "2018-12-24T19:42:18", "upload_time_iso_8601": "2018-12-24T19:42:18.149104Z", "url": "https://files.pythonhosted.org/packages/94/e8/8cba5909a36b55e4bab6971544ef2758f15b7dd4f0ac89e1d8d74037925c/AutoMunge_pkg-1.73-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3f749423a5127ea40b4988093d757fcd", "sha256": "594c2d555b8af4d5c1d593a20ad887b96478c576fabfd0852d6bfe8055806a1e"}, "downloads": -1, "filename": "AutoMunge_pkg-1.73.tar.gz", "has_sig": false, "md5_digest": "3f749423a5127ea40b4988093d757fcd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 49518, "upload_time": "2018-12-24T19:42:22", "upload_time_iso_8601": "2018-12-24T19:42:22.076840Z", "url": "https://files.pythonhosted.org/packages/34/49/8d00d162f8ed691c7017324d93032100020a69ab7d917b317e12007c8dae/AutoMunge_pkg-1.73.tar.gz", "yanked": false}], "1.74": [{"comment_text": "", "digests": {"md5": "cae1c54f40d666e949d4ed6e4b389a28", "sha256": "59fa84418c256f1bc6851b4bad706331c1ffaa6e2c72aaef148b3248c1c2e2e3"}, "downloads": -1, "filename": "AutoMunge_pkg-1.74-py3-none-any.whl", "has_sig": false, "md5_digest": "cae1c54f40d666e949d4ed6e4b389a28", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 56665, "upload_time": "2019-01-01T19:42:14", "upload_time_iso_8601": "2019-01-01T19:42:14.637785Z", "url": "https://files.pythonhosted.org/packages/37/a8/f5c125a20aff14b3c12984fa791fe97b1a0cf26e5f5c3448070594ccc418/AutoMunge_pkg-1.74-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a0622a35170d29f67e4a32e63c295846", "sha256": "f6361021fba8eaa9307d1ac79c63c3b15b56e88b198204a87b9bf6cc0d41f3ed"}, "downloads": -1, "filename": "AutoMunge_pkg-1.74.tar.gz", "has_sig": false, "md5_digest": "a0622a35170d29f67e4a32e63c295846", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 49846, "upload_time": "2019-01-01T19:42:20", "upload_time_iso_8601": "2019-01-01T19:42:20.355600Z", "url": "https://files.pythonhosted.org/packages/44/5b/6bf840c046de74df8e471ff28846b0c920264c7c54796dd302cdbb11a07a/AutoMunge_pkg-1.74.tar.gz", "yanked": false}], "1.75": [{"comment_text": "", "digests": {"md5": "a4b5ebbcb8c8d1ae82ab11a25aa2178a", "sha256": "bccf2311f39106fcfd5d2f4d87f44e5d09bb722960474cf684e0be858fe20767"}, "downloads": -1, "filename": "AutoMunge_pkg-1.75-py3-none-any.whl", "has_sig": false, "md5_digest": "a4b5ebbcb8c8d1ae82ab11a25aa2178a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 56646, "upload_time": "2019-01-01T21:17:19", "upload_time_iso_8601": "2019-01-01T21:17:19.033833Z", "url": "https://files.pythonhosted.org/packages/11/08/b75f66d0c733360ff38d505c290ab42f24c115bd7448ab5a5af3ed638546/AutoMunge_pkg-1.75-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "59d8a236e5d7d4dc0b4882cb88d534ab", "sha256": "f5ac0824de36881e71bd0df1b02df523496421d0aaae674eb8b525c8535b616b"}, "downloads": -1, "filename": "AutoMunge_pkg-1.75.tar.gz", "has_sig": false, "md5_digest": "59d8a236e5d7d4dc0b4882cb88d534ab", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 49830, "upload_time": "2019-01-01T21:17:20", "upload_time_iso_8601": "2019-01-01T21:17:20.612722Z", "url": "https://files.pythonhosted.org/packages/02/4d/e4ece4e694f32c1f076da2ead3e98fb1313ab22498aa5d17c5db2fa6b691/AutoMunge_pkg-1.75.tar.gz", "yanked": false}], "1.76": [{"comment_text": "", "digests": {"md5": "17b8639fc9367e1f63fadbecb44a1f2a", "sha256": "7d921f512b30c9a43e8c68daf035919fa25e226180307f1bbaf19530dc085cb7"}, "downloads": -1, "filename": "AutoMunge_pkg-1.76-py3-none-any.whl", "has_sig": false, "md5_digest": "17b8639fc9367e1f63fadbecb44a1f2a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 57442, "upload_time": "2019-01-22T05:46:27", "upload_time_iso_8601": "2019-01-22T05:46:27.623855Z", "url": "https://files.pythonhosted.org/packages/2a/48/4c4d129666b9fff8dfd5913bd8ee2b445b865217a59f0353ab7d4101fa8f/AutoMunge_pkg-1.76-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f39fd3b1f56eb123dc27a4ff503075d4", "sha256": "6744f3733f9dde17d7ef42ce5fd4db2336ac80f52a3fbbac5510f91f8078b87d"}, "downloads": -1, "filename": "AutoMunge_pkg-1.76.tar.gz", "has_sig": false, "md5_digest": "f39fd3b1f56eb123dc27a4ff503075d4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 50800, "upload_time": "2019-01-22T05:46:29", "upload_time_iso_8601": "2019-01-22T05:46:29.385880Z", "url": "https://files.pythonhosted.org/packages/39/fd/fac38cb040ddc41003661c3f1e833f9de67b53110ae76ea65423c65b73fc/AutoMunge_pkg-1.76.tar.gz", "yanked": false}], "1.77": [{"comment_text": "", "digests": {"md5": "d962c4f8ee88a9d7d8053d8dfb89056a", "sha256": "434edf396e3448e2bb3a1a909375e7b5890dccc07f8fc1f9e68518c9c4ebeb4d"}, "downloads": -1, "filename": "AutoMunge_pkg-1.77-py3-none-any.whl", "has_sig": false, "md5_digest": "d962c4f8ee88a9d7d8053d8dfb89056a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 65551, "upload_time": "2019-04-16T22:14:31", "upload_time_iso_8601": "2019-04-16T22:14:31.213867Z", "url": "https://files.pythonhosted.org/packages/60/74/d4f444dcb67bb28d6ea3bff71f4701f8c2a3f5c985d10ff283ca387b13a1/AutoMunge_pkg-1.77-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "369fa4c48ab8ee35fe7359f0c02568d0", "sha256": "503b06d1550a3a5fc71697bd25759ad6c2ca89150cff37a2a41b09969c7047e7"}, "downloads": -1, "filename": "AutoMunge_pkg-1.77.tar.gz", "has_sig": false, "md5_digest": "369fa4c48ab8ee35fe7359f0c02568d0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 58930, "upload_time": "2019-04-16T22:14:33", "upload_time_iso_8601": "2019-04-16T22:14:33.281800Z", "url": "https://files.pythonhosted.org/packages/24/97/ca3431cfffc69751e351e78133e4b918ea1569339da7443b8677816eeb09/AutoMunge_pkg-1.77.tar.gz", "yanked": false}], "1.78": [{"comment_text": "", "digests": {"md5": "564053dd61730cd0b0f374abc2097421", "sha256": "57d00e3d2d79c893e73f80d6d18b5c78b39621cb65b366f4076728f78e5eaaf7"}, "downloads": -1, "filename": "AutoMunge_pkg-1.78-py3-none-any.whl", "has_sig": false, "md5_digest": "564053dd61730cd0b0f374abc2097421", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 67206, "upload_time": "2019-04-17T01:49:04", "upload_time_iso_8601": "2019-04-17T01:49:04.619893Z", "url": "https://files.pythonhosted.org/packages/4f/78/0d94d260532a5cfbe0e3866cda25bbaa4dfa596798478be5a4ee7c70e6f7/AutoMunge_pkg-1.78-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e8dbaea7e82a4f03207bca1ff98b5a62", "sha256": "462fa5a0b10bfbc1f36ca234d0205140a5136852d1749dd76efda2944238924c"}, "downloads": -1, "filename": "AutoMunge_pkg-1.78.tar.gz", "has_sig": false, "md5_digest": "e8dbaea7e82a4f03207bca1ff98b5a62", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 62024, "upload_time": "2019-04-17T01:49:06", "upload_time_iso_8601": "2019-04-17T01:49:06.218501Z", "url": "https://files.pythonhosted.org/packages/8d/6c/fdffe4a46ea1cddf28c5738e8bfb5d2167438cb7e8f4a92eaa524d9ff061/AutoMunge_pkg-1.78.tar.gz", "yanked": false}], "1.79": [{"comment_text": "", "digests": {"md5": "c36f5fa6d8156a081edb651642c9dad9", "sha256": "95762de1dac892be4b8eab0eacad17489cef4ce1e07b40f868081c201317cb96"}, "downloads": -1, "filename": "AutoMunge_pkg-1.79-py3-none-any.whl", "has_sig": false, "md5_digest": "c36f5fa6d8156a081edb651642c9dad9", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 68667, "upload_time": "2019-04-21T20:27:53", "upload_time_iso_8601": "2019-04-21T20:27:53.490355Z", "url": "https://files.pythonhosted.org/packages/9e/c5/80b38144aaa844e438f6fe03fc61df2e46cec91e3e2b60aa27e4170f5dc3/AutoMunge_pkg-1.79-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "676b2f2e02903a790f7f88cd621e4f03", "sha256": "1f17b9b21f814e20cc832719ccaf936d6b42c48869fdfb053667ac4a6a251a12"}, "downloads": -1, "filename": "AutoMunge_pkg-1.79.tar.gz", "has_sig": false, "md5_digest": "676b2f2e02903a790f7f88cd621e4f03", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 63320, "upload_time": "2019-04-21T20:27:57", "upload_time_iso_8601": "2019-04-21T20:27:57.921858Z", "url": "https://files.pythonhosted.org/packages/1a/fc/049644ba856df071f258926eb74c0bc3f9907762834d1f85f946b65a521a/AutoMunge_pkg-1.79.tar.gz", "yanked": false}], "1.799": [{"comment_text": "", "digests": {"md5": "d08626764307200034d5a8b4843a23b5", "sha256": "019c6e8b70bcfa57e5eb0e18170c9ca501a9f7e5ea11f6e43d4f05e19d0caa51"}, "downloads": -1, "filename": "AutoMunge_pkg-1.799-py3-none-any.whl", "has_sig": false, "md5_digest": "d08626764307200034d5a8b4843a23b5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 70342, "upload_time": "2019-04-27T01:55:46", "upload_time_iso_8601": "2019-04-27T01:55:46.570800Z", "url": "https://files.pythonhosted.org/packages/c2/c6/042723aae66382a86ffffeb013c2574f79a41de9ec2678c7d1b588492266/AutoMunge_pkg-1.799-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "71ea5f46728c1ab430c4314fc9275517", "sha256": "ae0a0c1632fddb5f5a7e6ae21ef7f1c50e99d7eb263bae1baec5da79c69d82f7"}, "downloads": -1, "filename": "AutoMunge_pkg-1.799.tar.gz", "has_sig": false, "md5_digest": "71ea5f46728c1ab430c4314fc9275517", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 65052, "upload_time": "2019-04-27T01:56:03", "upload_time_iso_8601": "2019-04-27T01:56:03.651017Z", "url": "https://files.pythonhosted.org/packages/b4/aa/36882c6872e644708e57ea654a68714858e053e06e776f50771270f540d0/AutoMunge_pkg-1.799.tar.gz", "yanked": false}], "1.8": [{"comment_text": "", "digests": {"md5": "71f6f8105dfbe3510b6f593428c4e41d", "sha256": "ef80593745152c3388634f18501366fbbcf30e964b3368be72ef3e65f2f6dee5"}, "downloads": -1, "filename": "AutoMunge_pkg-1.8-py3-none-any.whl", "has_sig": false, "md5_digest": "71f6f8105dfbe3510b6f593428c4e41d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 71191, "upload_time": "2019-05-04T22:48:39", "upload_time_iso_8601": "2019-05-04T22:48:39.594644Z", "url": "https://files.pythonhosted.org/packages/21/c4/3ac237945730dabde306f05547f6d9e0a5617a136a661bbbccc66686e860/AutoMunge_pkg-1.8-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e18d30140bbf56f7bc6fa8ab9de71ec6", "sha256": "e0a0902ebc8296ca381f53b41226a56f2cb9cd829e9859dfacaec1a61baffc58"}, "downloads": -1, "filename": "AutoMunge_pkg-1.8.tar.gz", "has_sig": false, "md5_digest": "e18d30140bbf56f7bc6fa8ab9de71ec6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 66010, "upload_time": "2019-05-04T22:48:41", "upload_time_iso_8601": "2019-05-04T22:48:41.230928Z", "url": "https://files.pythonhosted.org/packages/c5/89/f7a0923717f5a4f57119c0dc7132861eae344f515e62b669c256e79d6cea/AutoMunge_pkg-1.8.tar.gz", "yanked": false}], "1.80": [{"comment_text": "", "digests": {"md5": "1009f24b68b510f5f4a8ffd47fa90445", "sha256": "027e498ce465c7ceae3e0088d2db1bddee09caa26d6ef663649fe5b5b1346efd"}, "downloads": -1, "filename": "AutoMunge_pkg-1.80-py3-none-any.whl", "has_sig": false, "md5_digest": "1009f24b68b510f5f4a8ffd47fa90445", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 71206, "upload_time": "2019-05-05T21:37:41", "upload_time_iso_8601": "2019-05-05T21:37:41.001852Z", "url": "https://files.pythonhosted.org/packages/ee/8a/c430eb5e430cc6876a5fc5ef798e61fa0bba75aa74c87c63eab0e50a346f/AutoMunge_pkg-1.80-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "330bb6134be1cfb0609e037848c7332b", "sha256": "20d12cd330ffd7f2202e3d35b962a63074fcc4643044f569689a5b778497ade1"}, "downloads": -1, "filename": "AutoMunge_pkg-1.80.tar.gz", "has_sig": false, "md5_digest": "330bb6134be1cfb0609e037848c7332b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 66009, "upload_time": "2019-05-05T21:37:42", "upload_time_iso_8601": "2019-05-05T21:37:42.204941Z", "url": "https://files.pythonhosted.org/packages/c3/4f/2f3140ca7417f2d2ae58530a74c516dd33fb435d61ea2a073ac8cc9b89ff/AutoMunge_pkg-1.80.tar.gz", "yanked": false}], "1.800": [{"comment_text": "", "digests": {"md5": "624640bff3b0e2606bc8db08450f29a8", "sha256": "02577e290e4ead657a2229236a91dd687331ef4899b5d9756d6de54a491056fd"}, "downloads": -1, "filename": "AutoMunge_pkg-1.800-py3-none-any.whl", "has_sig": false, "md5_digest": "624640bff3b0e2606bc8db08450f29a8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 71219, "upload_time": "2019-05-05T22:08:13", "upload_time_iso_8601": "2019-05-05T22:08:13.845270Z", "url": "https://files.pythonhosted.org/packages/fe/70/5d740a7c57aa5d94233130abcae6471df83113d8a471eddd5c1869cecd1d/AutoMunge_pkg-1.800-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e1d24386c28f75d20134978c63329cd1", "sha256": "0d1dd6d2e4e7a52c6f7700c336ffd9122910cadffa147fd63b0f435cc3f3b44b"}, "downloads": -1, "filename": "AutoMunge_pkg-1.800.tar.gz", "has_sig": false, "md5_digest": "e1d24386c28f75d20134978c63329cd1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 66018, "upload_time": "2019-05-05T22:08:15", "upload_time_iso_8601": "2019-05-05T22:08:15.477581Z", "url": "https://files.pythonhosted.org/packages/09/7a/8fe50a4e810438d831c4cd932ef270a8357786ff598443b4347bf7a12644/AutoMunge_pkg-1.800.tar.gz", "yanked": false}], "1.801": [{"comment_text": "", "digests": {"md5": "b0a3a4818421276482751551b0f92bd3", "sha256": "ea97f9f65397075095edebe7aa32f253c03bbea59cf0d36553efb2086213ca3e"}, "downloads": -1, "filename": "AutoMunge_pkg-1.801-py3-none-any.whl", "has_sig": false, "md5_digest": "b0a3a4818421276482751551b0f92bd3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 71226, "upload_time": "2019-05-06T17:41:40", "upload_time_iso_8601": "2019-05-06T17:41:40.520046Z", "url": "https://files.pythonhosted.org/packages/13/69/615245b34cc25337718fcccd73efd865a1e3b332ab753ba62833caaacc53/AutoMunge_pkg-1.801-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "53d1fc4753be880cdbf4b7ec991c36a6", "sha256": "10e764fa094b5ecb3aa33995bc20790e36c8ba468b2a16087efd4a2b1634d0d9"}, "downloads": -1, "filename": "AutoMunge_pkg-1.801.tar.gz", "has_sig": false, "md5_digest": "53d1fc4753be880cdbf4b7ec991c36a6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 66021, "upload_time": "2019-05-06T17:41:42", "upload_time_iso_8601": "2019-05-06T17:41:42.627497Z", "url": "https://files.pythonhosted.org/packages/d3/52/5e3014b4d19eb770a62312191f0494496b4fde88d38ad93a99e6e41817d5/AutoMunge_pkg-1.801.tar.gz", "yanked": false}], "1.900": [{"comment_text": "", "digests": {"md5": "c10dd075212a33a8e182dd2e153ba92d", "sha256": "cbb63cb12121961b5a0840a758c9cb85d20caf72cf7cfed3ab55c58458d74352"}, "downloads": -1, "filename": "AutoMunge_pkg-1.900-py3-none-any.whl", "has_sig": false, "md5_digest": "c10dd075212a33a8e182dd2e153ba92d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 73716, "upload_time": "2019-05-10T02:52:23", "upload_time_iso_8601": "2019-05-10T02:52:23.008767Z", "url": "https://files.pythonhosted.org/packages/db/95/12a8ae8a3b49195a1c9a6540bbf763bb5f02198eb79352a6bee08be915e4/AutoMunge_pkg-1.900-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8536e37b7e62c1a01eb5aaeebc7134f4", "sha256": "4435a30cce6097ac0b5a338ddc43dbcd3e5b4dc2679d3822bdd2ece6321ccf5d"}, "downloads": -1, "filename": "AutoMunge_pkg-1.900.tar.gz", "has_sig": false, "md5_digest": "8536e37b7e62c1a01eb5aaeebc7134f4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 69857, "upload_time": "2019-05-10T02:52:24", "upload_time_iso_8601": "2019-05-10T02:52:24.861948Z", "url": "https://files.pythonhosted.org/packages/e5/c1/5ee74909a91580fdf37e32d8b2d143a17177a6e0cdfedd4ef6d1f4b24507/AutoMunge_pkg-1.900.tar.gz", "yanked": false}], "2.0": [{"comment_text": "", "digests": {"md5": "6ccee73297d3486ee3527d3220b6151e", "sha256": "9c56f3925ffa5c00c1e7cb103e4bfcc75f76eeaa2149123a73de772a13d56881"}, "downloads": -1, "filename": "AutoMunge_pkg-2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "6ccee73297d3486ee3527d3220b6151e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 81997, "upload_time": "2019-05-22T02:38:02", "upload_time_iso_8601": "2019-05-22T02:38:02.489886Z", "url": "https://files.pythonhosted.org/packages/69/fc/a2ba57ea2bcc113b1b82de268a8532178def2248aca01e10e9f5b1d96d27/AutoMunge_pkg-2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "78ff4b0e864de0b24852cccff2ec733f", "sha256": "c2b781050646ef0b6c4fec77fc80fc98d23e00887c0486190d6bc01cfdf9e232"}, "downloads": -1, "filename": "AutoMunge_pkg-2.0.tar.gz", "has_sig": false, "md5_digest": "78ff4b0e864de0b24852cccff2ec733f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 79199, "upload_time": "2019-05-22T02:38:04", "upload_time_iso_8601": "2019-05-22T02:38:04.281663Z", "url": "https://files.pythonhosted.org/packages/75/6e/387c8cd7b69c0e2790c4bbfe18b65ccf6558bfabb3f847ba8edc2f266078/AutoMunge_pkg-2.0.tar.gz", "yanked": false}], "2.1": [{"comment_text": "", "digests": {"md5": "da066ff7d03c0b73d681c737ebaee7ce", "sha256": "45ec2429f31e67d5dd29fc7430e2a15a61e80b187140aab651a499e2579a63e6"}, "downloads": -1, "filename": "AutoMunge_pkg-2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "da066ff7d03c0b73d681c737ebaee7ce", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 82176, "upload_time": "2019-05-27T03:11:47", "upload_time_iso_8601": "2019-05-27T03:11:47.620558Z", "url": "https://files.pythonhosted.org/packages/4e/c9/12f0c01b58889518bdbff4589f7e3c6bb9daafd9caeb273f2c7deb233570/AutoMunge_pkg-2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "84f300ae9bc3194cf8a1ae4d12d12ffd", "sha256": "e2c7edf5ef08adecc50ab26bd0c3f35a7db6256e8bac4dd6f6459945c90b752d"}, "downloads": -1, "filename": "AutoMunge_pkg-2.1.tar.gz", "has_sig": false, "md5_digest": "84f300ae9bc3194cf8a1ae4d12d12ffd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 79370, "upload_time": "2019-05-27T03:11:49", "upload_time_iso_8601": "2019-05-27T03:11:49.385504Z", "url": "https://files.pythonhosted.org/packages/43/ad/f40237aadfbad22f04bbf675441fc230144cf49ee6c050c54fb2e7306131/AutoMunge_pkg-2.1.tar.gz", "yanked": false}], "2.11": [{"comment_text": "", "digests": {"md5": "c09124bc2c7dfb78a27cadb41ffe715d", "sha256": "3a74c52e67678d90626b9007c96da52b12b6e331ba6d1919f8d0fd72dda9e804"}, "downloads": -1, "filename": "AutoMunge_pkg-2.11-py3-none-any.whl", "has_sig": false, "md5_digest": "c09124bc2c7dfb78a27cadb41ffe715d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 90615, "upload_time": "2019-06-08T02:58:08", "upload_time_iso_8601": "2019-06-08T02:58:08.386573Z", "url": "https://files.pythonhosted.org/packages/b3/6c/48d0ce20ff591c40fbc43c7a3325cdf7c79043b74c0876cfe0ad06b27dca/AutoMunge_pkg-2.11-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f203f12b24139023ee73dcdd5af21f20", "sha256": "1518a0c5a38df0e17c7d569f8f5146766d18d0d8cf5b2912aeed2303867a921a"}, "downloads": -1, "filename": "AutoMunge_pkg-2.11.tar.gz", "has_sig": false, "md5_digest": "f203f12b24139023ee73dcdd5af21f20", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 109394, "upload_time": "2019-06-08T02:58:10", "upload_time_iso_8601": "2019-06-08T02:58:10.439440Z", "url": "https://files.pythonhosted.org/packages/e0/9d/3db807f1b3b7d50e90e5353119c373cfa9a07ea3d5886f287e369128967d/AutoMunge_pkg-2.11.tar.gz", "yanked": false}], "2.12": [{"comment_text": "", "digests": {"md5": "ccd1d364bc4ff418627187b12c683dd4", "sha256": "20d1ac99092253e276312225a9e60d1312110ec048d1997f2d0bb4f4a385f9cf"}, "downloads": -1, "filename": "AutoMunge_pkg-2.12-py3-none-any.whl", "has_sig": false, "md5_digest": "ccd1d364bc4ff418627187b12c683dd4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 90722, "upload_time": "2019-06-23T02:11:26", "upload_time_iso_8601": "2019-06-23T02:11:26.043730Z", "url": "https://files.pythonhosted.org/packages/06/97/a2f49fb7d64c6af7688956508041b0d8a57391a034f67238f6cb10956e5e/AutoMunge_pkg-2.12-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8880667af2edda6357719a3dd1dc8311", "sha256": "dd19726cc6bf0c73375f0882de4ebcc1f5adf3fcc194b47f82a1dc6272449b8e"}, "downloads": -1, "filename": "AutoMunge_pkg-2.12.tar.gz", "has_sig": false, "md5_digest": "8880667af2edda6357719a3dd1dc8311", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 109616, "upload_time": "2019-06-23T02:11:28", "upload_time_iso_8601": "2019-06-23T02:11:28.350247Z", "url": "https://files.pythonhosted.org/packages/18/c5/684232702e306a7bbb83e0edeeb31d493dd9e3d662a2afe17844404b8aca/AutoMunge_pkg-2.12.tar.gz", "yanked": false}], "2.13": [{"comment_text": "", "digests": {"md5": "68d8ddde2a89da332c17729be28051b0", "sha256": "5fff07432ab26c6c342c783ffeed210e9565970d09f07e17ff7f37810120ba2b"}, "downloads": -1, "filename": "AutoMunge_pkg-2.13-py3-none-any.whl", "has_sig": false, "md5_digest": "68d8ddde2a89da332c17729be28051b0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 91490, "upload_time": "2019-06-30T21:56:46", "upload_time_iso_8601": "2019-06-30T21:56:46.470677Z", "url": "https://files.pythonhosted.org/packages/4a/72/1d5db947630536f5eb675ac90bc6681978b52d4e0f1c45c55f056ee23faf/AutoMunge_pkg-2.13-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "bcb3e365bbcbd409566d5e7e09fd527c", "sha256": "ffe170a3305577d412c3ca405ab6e2ddd17ca26a6a9035ad8375c1d64c4da1b7"}, "downloads": -1, "filename": "AutoMunge_pkg-2.13.tar.gz", "has_sig": false, "md5_digest": "bcb3e365bbcbd409566d5e7e09fd527c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 110362, "upload_time": "2019-06-30T21:56:48", "upload_time_iso_8601": "2019-06-30T21:56:48.535694Z", "url": "https://files.pythonhosted.org/packages/88/cb/841f61689220c5f0206cee227ea58f03e227e13e4590258940b0e14a16c6/AutoMunge_pkg-2.13.tar.gz", "yanked": false}], "2.14": [{"comment_text": "", "digests": {"md5": "1306ad070286459e57b574d8dab9cba6", "sha256": "c6a194bd3834e51b5cc6b712abf49f85406dd3c412dbb248aa960d6330cfb7cd"}, "downloads": -1, "filename": "AutoMunge_pkg-2.14-py3-none-any.whl", "has_sig": false, "md5_digest": "1306ad070286459e57b574d8dab9cba6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 91856, "upload_time": "2019-07-10T23:08:58", "upload_time_iso_8601": "2019-07-10T23:08:58.735632Z", "url": "https://files.pythonhosted.org/packages/36/67/0b365186f4ef328068e586e4148596b8a2c8a2fc8a650caf953b2aa00316/AutoMunge_pkg-2.14-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "191ac88e5b015a8295ed16c7adcbf26f", "sha256": "ab559cb8dc1ef00e0e54bda92c1295ff7b7b602ff4ca8cc6252a3f0d273faef1"}, "downloads": -1, "filename": "AutoMunge_pkg-2.14.tar.gz", "has_sig": false, "md5_digest": "191ac88e5b015a8295ed16c7adcbf26f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 111147, "upload_time": "2019-07-10T23:09:00", "upload_time_iso_8601": "2019-07-10T23:09:00.527343Z", "url": "https://files.pythonhosted.org/packages/77/5c/d61bfc9404b5daf6d8f8a41a843b9df51c9a9847f208c63c1f42fc61cd09/AutoMunge_pkg-2.14.tar.gz", "yanked": false}], "2.15": [{"comment_text": "", "digests": {"md5": "e3cb8d698bcc9b6a99c62c847a81743d", "sha256": "5559b4c68da3437f94562d4f69a726aa409b90194ffb3a25ce82f0854d25b3a9"}, "downloads": -1, "filename": "AutoMunge_pkg-2.15-py3-none-any.whl", "has_sig": false, "md5_digest": "e3cb8d698bcc9b6a99c62c847a81743d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 91894, "upload_time": "2019-07-10T23:32:49", "upload_time_iso_8601": "2019-07-10T23:32:49.736078Z", "url": "https://files.pythonhosted.org/packages/1d/86/9a60676fee3af697a3c12b003a75e7b44502c53ae41d966b4d5d2b7e5eed/AutoMunge_pkg-2.15-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f07d228cd52b9b3c2e5905ef76135505", "sha256": "28f4ff519c8618e20106d3edf36565dd9d2c19c7fcdc52726f3a3b8d1de2cf65"}, "downloads": -1, "filename": "AutoMunge_pkg-2.15.tar.gz", "has_sig": false, "md5_digest": "f07d228cd52b9b3c2e5905ef76135505", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 111178, "upload_time": "2019-07-10T23:32:51", "upload_time_iso_8601": "2019-07-10T23:32:51.569629Z", "url": "https://files.pythonhosted.org/packages/6a/8b/54f5795eaafd447e49b2a9a92e6f4519ad5825b647f7a24697c7799626a1/AutoMunge_pkg-2.15.tar.gz", "yanked": false}], "2.16": [{"comment_text": "", "digests": {"md5": "01b06aa337557a28ca22632a67624ecd", "sha256": "25647694a4f1ffb7e1660ae339e1dda638be61c8214a9af07d52658313165f53"}, "downloads": -1, "filename": "AutoMunge_pkg-2.16-py3-none-any.whl", "has_sig": false, "md5_digest": "01b06aa337557a28ca22632a67624ecd", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 93818, "upload_time": "2019-07-19T22:49:34", "upload_time_iso_8601": "2019-07-19T22:49:34.926976Z", "url": "https://files.pythonhosted.org/packages/75/a4/95d2a396a84dce079e909f20985a873f3706980f6697ef368d1f31f94b95/AutoMunge_pkg-2.16-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d90d4ab3eb610985ab54757f91f21c2d", "sha256": "2a5b735ce033ffd1cc3c979baeb4e2e8dbe9e969e3457bba683579b4c047817f"}, "downloads": -1, "filename": "AutoMunge_pkg-2.16.tar.gz", "has_sig": false, "md5_digest": "d90d4ab3eb610985ab54757f91f21c2d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 113111, "upload_time": "2019-07-19T22:49:36", "upload_time_iso_8601": "2019-07-19T22:49:36.944784Z", "url": "https://files.pythonhosted.org/packages/5c/71/9def3894b7fc23b7ea472aa9f7291e0aa6d6d7b79bd2f6392301fc7d2376/AutoMunge_pkg-2.16.tar.gz", "yanked": false}], "2.17": [{"comment_text": "", "digests": {"md5": "067f9742e2ba7ff38a0bc60a5d607f08", "sha256": "7ed7738594e49ba2b04f8c10cd0e24ba144f1426c7ff93ac9439a5e48800b092"}, "downloads": -1, "filename": "AutoMunge_pkg-2.17-py3-none-any.whl", "has_sig": false, "md5_digest": "067f9742e2ba7ff38a0bc60a5d607f08", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 94249, "upload_time": "2019-07-21T01:01:28", "upload_time_iso_8601": "2019-07-21T01:01:28.270805Z", "url": "https://files.pythonhosted.org/packages/ae/1f/90b277a614d91900805f91f76c79fc61b17055f1d473719847bfc6f24dd0/AutoMunge_pkg-2.17-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f5c60110572e1017ce4de9cc048900d3", "sha256": "35f3c5309b87466324c4930f1f981a977b819874c0715a1caacb19d246943923"}, "downloads": -1, "filename": "AutoMunge_pkg-2.17.tar.gz", "has_sig": false, "md5_digest": "f5c60110572e1017ce4de9cc048900d3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 113748, "upload_time": "2019-07-21T01:01:30", "upload_time_iso_8601": "2019-07-21T01:01:30.130540Z", "url": "https://files.pythonhosted.org/packages/8f/7b/7ae5d0f7cfbb9806967e9520677b12c01003d86ba62b4d4fcf7b00901421/AutoMunge_pkg-2.17.tar.gz", "yanked": false}], "2.18": [{"comment_text": "", "digests": {"md5": "cca5871f0abe3642e86e8ebefb57ec1d", "sha256": "5bc58f6ccdfba714df3d3a79412746af7bd9f93fbc95108846fac6ea83c5fe05"}, "downloads": -1, "filename": "AutoMunge_pkg-2.18-py3-none-any.whl", "has_sig": false, "md5_digest": "cca5871f0abe3642e86e8ebefb57ec1d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 92914, "upload_time": "2019-07-21T21:06:25", "upload_time_iso_8601": "2019-07-21T21:06:25.801706Z", "url": "https://files.pythonhosted.org/packages/15/91/18b652a52eaea741a60287fb287df8e0f49fd3929e3c13bbfc61748254fb/AutoMunge_pkg-2.18-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "65e763b878161ef03353cc217815837b", "sha256": "473f824c8555b1c625a8f3e543df3f77974177bc742ab7d8388dfc4fcaa97ee9"}, "downloads": -1, "filename": "AutoMunge_pkg-2.18.tar.gz", "has_sig": false, "md5_digest": "65e763b878161ef03353cc217815837b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 112841, "upload_time": "2019-07-21T21:06:28", "upload_time_iso_8601": "2019-07-21T21:06:28.114055Z", "url": "https://files.pythonhosted.org/packages/cd/79/0f3eabcbc92656c563e4cc45cd961ff6df2a7d008e45371deae0bf8c431b/AutoMunge_pkg-2.18.tar.gz", "yanked": false}], "2.19": [{"comment_text": "", "digests": {"md5": "b9434a8ad7dceb18f52d3d58037d2e74", "sha256": "d274cc2547c6e6b3710944f1cb8ba043cc310dd4465ec545e1eb50092920cc9e"}, "downloads": -1, "filename": "AutoMunge_pkg-2.19-py3-none-any.whl", "has_sig": false, "md5_digest": "b9434a8ad7dceb18f52d3d58037d2e74", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 93263, "upload_time": "2019-07-22T03:13:44", "upload_time_iso_8601": "2019-07-22T03:13:44.934649Z", "url": "https://files.pythonhosted.org/packages/e6/f5/c075ea75c481ac731bf5ab9267d8623509cba0376c8557ca78a405f5835b/AutoMunge_pkg-2.19-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "edebf7d0cbed155b1bbeca547227fdc6", "sha256": "23b28dfd46163f8a9e6b247970d976518a5d7e8c5c4e2de32e5fa3116326e91d"}, "downloads": -1, "filename": "AutoMunge_pkg-2.19.tar.gz", "has_sig": false, "md5_digest": "edebf7d0cbed155b1bbeca547227fdc6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 113149, "upload_time": "2019-07-22T03:13:46", "upload_time_iso_8601": "2019-07-22T03:13:46.632317Z", "url": "https://files.pythonhosted.org/packages/13/17/20929729a6bd6a5a3e00aa89122f251fca1e9e2720da1bb4cdfeb9bfb132/AutoMunge_pkg-2.19.tar.gz", "yanked": false}], "2.20": [{"comment_text": "", "digests": {"md5": "b41c7ba52a54b512fc68e020f2209c76", "sha256": "3b1d593c436fba1adeac6cee132a81fa7fdc56b08930a5fb656344961014fd6e"}, "downloads": -1, "filename": "AutoMunge_pkg-2.20-py3-none-any.whl", "has_sig": false, "md5_digest": "b41c7ba52a54b512fc68e020f2209c76", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 93285, "upload_time": "2019-07-24T03:36:38", "upload_time_iso_8601": "2019-07-24T03:36:38.576969Z", "url": "https://files.pythonhosted.org/packages/a2/1f/32aa76e42d04062397664ad546e7fe29432324306b34d5353ce49505a4c1/AutoMunge_pkg-2.20-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "afe03f7c357efdae0bdadd47c4a9f3b4", "sha256": "3a116217dd549aa82846cf146f9639cd3098df4db6cd84238c134dcd6004acd4"}, "downloads": -1, "filename": "AutoMunge_pkg-2.20.tar.gz", "has_sig": false, "md5_digest": "afe03f7c357efdae0bdadd47c4a9f3b4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 112750, "upload_time": "2019-07-24T03:36:40", "upload_time_iso_8601": "2019-07-24T03:36:40.415664Z", "url": "https://files.pythonhosted.org/packages/21/50/7375f810e8472b2aed4902111b36fc5d2f33f6426fb5a1fb3cc7597b5ebb/AutoMunge_pkg-2.20.tar.gz", "yanked": false}], "2.21": [{"comment_text": "", "digests": {"md5": "e539d04073f1f1a7346eacaf184b48fb", "sha256": "8eb7b9cfeb857ca622e4fc6362bbd94c1bc5ba2e4a47aa015914c88b931c18fc"}, "downloads": -1, "filename": "AutoMunge_pkg-2.21-py3-none-any.whl", "has_sig": false, "md5_digest": "e539d04073f1f1a7346eacaf184b48fb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 93283, "upload_time": "2019-07-24T03:52:00", "upload_time_iso_8601": "2019-07-24T03:52:00.926826Z", "url": "https://files.pythonhosted.org/packages/fa/6d/51af8aa0cc8678ac846008bd66f2e1ed37cb90b29f751cb706950a78dc6a/AutoMunge_pkg-2.21-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2ffbea050ed3e5a133beb546dc4555c8", "sha256": "5612cb5bae9a75b93504b941c92258746f95d9fb356e80135afab775948bb619"}, "downloads": -1, "filename": "AutoMunge_pkg-2.21.tar.gz", "has_sig": false, "md5_digest": "2ffbea050ed3e5a133beb546dc4555c8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 112747, "upload_time": "2019-07-24T03:52:02", "upload_time_iso_8601": "2019-07-24T03:52:02.739947Z", "url": "https://files.pythonhosted.org/packages/c5/9a/bab2d77d1973b3e1304d21e80714dbf49806cc94b7134582cd552205dacf/AutoMunge_pkg-2.21.tar.gz", "yanked": false}], "2.22": [{"comment_text": "", "digests": {"md5": "b3b98e9001cb682041bc8f93b8edb8d3", "sha256": "4875530f5d900c1e64c5df9e1f599f3125a34b0ec59ac18702cabdd7f3bd2e7f"}, "downloads": -1, "filename": "AutoMunge_pkg-2.22-py3-none-any.whl", "has_sig": false, "md5_digest": "b3b98e9001cb682041bc8f93b8edb8d3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 94603, "upload_time": "2019-07-25T01:34:49", "upload_time_iso_8601": "2019-07-25T01:34:49.886584Z", "url": "https://files.pythonhosted.org/packages/10/56/b4cbda1565b0b6dd382f38bfa1e49b4d31d2bbf9e9f12eff43b22b2e55d9/AutoMunge_pkg-2.22-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4259f338292ca46d0c08d7a3ee3c322b", "sha256": "5fa99d49b5b05e05e8b7b89ce99fa7f70f8d24ce432429cee7203e69ad0e010d"}, "downloads": -1, "filename": "AutoMunge_pkg-2.22.tar.gz", "has_sig": false, "md5_digest": "4259f338292ca46d0c08d7a3ee3c322b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 114542, "upload_time": "2019-07-25T01:34:53", "upload_time_iso_8601": "2019-07-25T01:34:53.101995Z", "url": "https://files.pythonhosted.org/packages/9b/ec/a705f8c810baeada980ce511ece64a90893b73a68bc79b51034495f74922/AutoMunge_pkg-2.22.tar.gz", "yanked": false}], "2.23": [{"comment_text": "", "digests": {"md5": "795d6a7e4f0c816c7ffa1f05c8f107b9", "sha256": "2661c5d6cb0f4375d895f50e82d9742a761fc89623cf8ab6ca540cb246a0163d"}, "downloads": -1, "filename": "AutoMunge_pkg-2.23-py3-none-any.whl", "has_sig": false, "md5_digest": "795d6a7e4f0c816c7ffa1f05c8f107b9", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 97774, "upload_time": "2019-07-29T15:55:51", "upload_time_iso_8601": "2019-07-29T15:55:51.653435Z", "url": "https://files.pythonhosted.org/packages/20/90/41d0c51058543e73bbaf6d3e4aa47c14b6d04fa96c633688065f5eb6b696/AutoMunge_pkg-2.23-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d6fac4eac16d0c543afc2d026de48b50", "sha256": "85db67ee1abb8b4a80cd87f2bca19df86934381b61f7c3207daf5f0329403034"}, "downloads": -1, "filename": "AutoMunge_pkg-2.23.tar.gz", "has_sig": false, "md5_digest": "d6fac4eac16d0c543afc2d026de48b50", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 117944, "upload_time": "2019-07-29T15:55:53", "upload_time_iso_8601": "2019-07-29T15:55:53.640606Z", "url": "https://files.pythonhosted.org/packages/56/c5/fb1f1423cb0e0c94ea0cbb2bc70a4f5569dafadc6fee94451174293b9987/AutoMunge_pkg-2.23.tar.gz", "yanked": false}], "2.25": [{"comment_text": "", "digests": {"md5": "a4bb30929c6eb61cae1ac5d75f62e393", "sha256": "b15f07ec6d848d9592687afa956a06d695a1ba614b34cce05bb652d836397e50"}, "downloads": -1, "filename": "AutoMunge_pkg-2.25-py3-none-any.whl", "has_sig": false, "md5_digest": "a4bb30929c6eb61cae1ac5d75f62e393", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 100100, "upload_time": "2019-08-03T23:47:13", "upload_time_iso_8601": "2019-08-03T23:47:13.830118Z", "url": "https://files.pythonhosted.org/packages/20/01/40d11f8d9d4445a0058182fc02f04bcf34dc28b82a4e5a3af2f5c0084d5c/AutoMunge_pkg-2.25-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a1a040ca154bf04359267462123e7b7c", "sha256": "a33a73e674beb1ae32c3a63ef26bd2853318c98cc33254aa424fd54b95573670"}, "downloads": -1, "filename": "AutoMunge_pkg-2.25.tar.gz", "has_sig": false, "md5_digest": "a1a040ca154bf04359267462123e7b7c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 120057, "upload_time": "2019-08-03T23:47:15", "upload_time_iso_8601": "2019-08-03T23:47:15.900954Z", "url": "https://files.pythonhosted.org/packages/75/08/45db1ddc488681678acae2938dca5b78fde2bbef9475a4da6ad4e984c0d0/AutoMunge_pkg-2.25.tar.gz", "yanked": false}], "2.26": [{"comment_text": "", "digests": {"md5": "1428603fa95c5ef22913e1f77f634f41", "sha256": "a9068c202bedf1dfdb00cd22c76c525c4de2cc4cc7c5b846b073c4884561ee4f"}, "downloads": -1, "filename": "AutoMunge_pkg-2.26-py3-none-any.whl", "has_sig": false, "md5_digest": "1428603fa95c5ef22913e1f77f634f41", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 100094, "upload_time": "2019-08-04T00:41:41", "upload_time_iso_8601": "2019-08-04T00:41:41.992323Z", "url": "https://files.pythonhosted.org/packages/bc/67/9c279f00f5290c01bc7783d5a0e63a63a865b214fea63a2e93f65925908b/AutoMunge_pkg-2.26-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a0857331fd41afb42b5a23233e92cd93", "sha256": "7b63ab3a5b57f284971564a3fa417750b22b81430a2f7e6982c9c42ed30058f5"}, "downloads": -1, "filename": "AutoMunge_pkg-2.26.tar.gz", "has_sig": false, "md5_digest": "a0857331fd41afb42b5a23233e92cd93", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 120072, "upload_time": "2019-08-04T00:41:43", "upload_time_iso_8601": "2019-08-04T00:41:43.905544Z", "url": "https://files.pythonhosted.org/packages/0f/d6/fc352c9742560dd73ea1c8a352559fc7f21795e40fbd830d76f266056c3a/AutoMunge_pkg-2.26.tar.gz", "yanked": false}], "2.27": [{"comment_text": "", "digests": {"md5": "d6a99709e43eb9a94ffc3ddd57c1f925", "sha256": "7f9107d53efd3f7504f38608a5de725e6d19a0df7e78172916ad634013a558b6"}, "downloads": -1, "filename": "AutoMunge_pkg-2.27-py3-none-any.whl", "has_sig": false, "md5_digest": "d6a99709e43eb9a94ffc3ddd57c1f925", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 100143, "upload_time": "2019-08-04T15:25:42", "upload_time_iso_8601": "2019-08-04T15:25:42.476535Z", "url": "https://files.pythonhosted.org/packages/88/f4/4eb735069fc335cbcae5475a900946381e36bca398c5797ae839b603f8cd/AutoMunge_pkg-2.27-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5648be9527d52e0b36f9a4c88b5b1b44", "sha256": "371b68997d5b0906e36c4b261f8be9e3d66d1f43658708c05d3e8cc4e436d548"}, "downloads": -1, "filename": "AutoMunge_pkg-2.27.tar.gz", "has_sig": false, "md5_digest": "5648be9527d52e0b36f9a4c88b5b1b44", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 120096, "upload_time": "2019-08-04T15:25:44", "upload_time_iso_8601": "2019-08-04T15:25:44.812055Z", "url": "https://files.pythonhosted.org/packages/9c/c1/2af2c486d2014d6b3aa89f37c46f22314623a148a91494e4e2e44305dbf4/AutoMunge_pkg-2.27.tar.gz", "yanked": false}], "2.28": [{"comment_text": "", "digests": {"md5": "94812e8effadfc9fb91743f125fd73aa", "sha256": "716377b7404b7b120e9ef0e41c18c12bb42c7f4cf5935da2aeb74173fc49eec3"}, "downloads": -1, "filename": "AutoMunge_pkg-2.28-py3-none-any.whl", "has_sig": false, "md5_digest": "94812e8effadfc9fb91743f125fd73aa", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 100030, "upload_time": "2019-08-05T01:57:55", "upload_time_iso_8601": "2019-08-05T01:57:55.230788Z", "url": "https://files.pythonhosted.org/packages/61/7a/d9da637ef334dd6a89458ca42ae8f8057ba8d8bbaa40975f9777f1354a38/AutoMunge_pkg-2.28-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c56399a3075d9be6f386a3e0fd512ac2", "sha256": "a3f61608031e0f19a60047092d0eb9d80f1e5a288cad3668ef12a5f74d50cdb9"}, "downloads": -1, "filename": "AutoMunge_pkg-2.28.tar.gz", "has_sig": false, "md5_digest": "c56399a3075d9be6f386a3e0fd512ac2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 120209, "upload_time": "2019-08-05T01:57:58", "upload_time_iso_8601": "2019-08-05T01:57:58.602288Z", "url": "https://files.pythonhosted.org/packages/af/f0/d9a9fdae3d961e72f763609f2d700c8e5a2444e4db42128b5e8e179ae183/AutoMunge_pkg-2.28.tar.gz", "yanked": false}], "2.29": [{"comment_text": "", "digests": {"md5": "ca9a0455f032316c978b38e24c5a77fb", "sha256": "ce05ab78424c0f5f48916a9cb0465d2c4ee1ff475331104970834a68c950968f"}, "downloads": -1, "filename": "AutoMunge_pkg-2.29-py3-none-any.whl", "has_sig": false, "md5_digest": "ca9a0455f032316c978b38e24c5a77fb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 100688, "upload_time": "2019-08-06T19:04:29", "upload_time_iso_8601": "2019-08-06T19:04:29.432708Z", "url": "https://files.pythonhosted.org/packages/60/73/86e61c3808dcedda6fa66d442f0fe0e6931cff6cc399f4aa63092c745176/AutoMunge_pkg-2.29-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "57be4d658c80a1b800839e1a1f57f632", "sha256": "07edb7a289116e9ffdc04ec152bfdad890efa3ca67c633923c3d2c0fba53aebf"}, "downloads": -1, "filename": "AutoMunge_pkg-2.29.tar.gz", "has_sig": false, "md5_digest": "57be4d658c80a1b800839e1a1f57f632", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 120836, "upload_time": "2019-08-06T19:04:31", "upload_time_iso_8601": "2019-08-06T19:04:31.334911Z", "url": "https://files.pythonhosted.org/packages/1c/28/38c4498529a46b73bf43d214808630f8ef956fc1c14f7e4defa35eff159a/AutoMunge_pkg-2.29.tar.gz", "yanked": false}], "2.30": [{"comment_text": "", "digests": {"md5": "6889d03c921990bcd56bd3e0210f254c", "sha256": "fbb0b4179957ecdeb0bc824ea6f5adea6a34885671b770ccb2c46d7a6b058cc5"}, "downloads": -1, "filename": "AutoMunge_pkg-2.30-py3-none-any.whl", "has_sig": false, "md5_digest": "6889d03c921990bcd56bd3e0210f254c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 101056, "upload_time": "2019-08-08T04:19:21", "upload_time_iso_8601": "2019-08-08T04:19:21.657183Z", "url": "https://files.pythonhosted.org/packages/f0/73/110871ec2c5fc45f9630003e10cb6fb8161b87b4032830beae85c2d62459/AutoMunge_pkg-2.30-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e644507771077b34a24710d9a8ab1042", "sha256": "0e145f20f269f29d59e8e2f9fa0f29ecf75e1f83e9cac149bae4528cb35fcb1c"}, "downloads": -1, "filename": "AutoMunge_pkg-2.30.tar.gz", "has_sig": false, "md5_digest": "e644507771077b34a24710d9a8ab1042", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 121250, "upload_time": "2019-08-08T04:19:23", "upload_time_iso_8601": "2019-08-08T04:19:23.877477Z", "url": "https://files.pythonhosted.org/packages/db/c5/a23e4f433053ddbc19c0f36d7aacabcac48bd799fe1cf50c6fc6029d0210/AutoMunge_pkg-2.30.tar.gz", "yanked": false}], "2.31": [{"comment_text": "", "digests": {"md5": "31fdaade3b29b97042ccf425714b15d2", "sha256": "1bd8594f5419032b511fffc8e995c30fa5ed2fb89b03509fc1cf4e1c22a5aa35"}, "downloads": -1, "filename": "AutoMunge_pkg-2.31-py3-none-any.whl", "has_sig": false, "md5_digest": "31fdaade3b29b97042ccf425714b15d2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 101240, "upload_time": "2019-08-08T16:48:15", "upload_time_iso_8601": "2019-08-08T16:48:15.628891Z", "url": "https://files.pythonhosted.org/packages/4b/9a/6dbc601d81f8bc309058f608f30cffad7057f595a74dd27d2d1200600792/AutoMunge_pkg-2.31-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4ad1748a2435c15822ac07ea8d468c1f", "sha256": "5d7ee6a4c05bf4f990e3775b204505b493f0a10f051e128e3e1ad1aaf0a60528"}, "downloads": -1, "filename": "AutoMunge_pkg-2.31.tar.gz", "has_sig": false, "md5_digest": "4ad1748a2435c15822ac07ea8d468c1f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 121606, "upload_time": "2019-08-08T16:48:17", "upload_time_iso_8601": "2019-08-08T16:48:17.532360Z", "url": "https://files.pythonhosted.org/packages/80/9b/0bb9e22121f8fd56244e841abe6e9e8f6f129ced1c5c8168da7f4848b4b2/AutoMunge_pkg-2.31.tar.gz", "yanked": false}], "2.32": [{"comment_text": "", "digests": {"md5": "8febeda7afa900454d7141da98d2a0e2", "sha256": "6957b014185bb7d09fa59747a5a2844a9a237c7f5e4e4c4f07c2eca87002205f"}, "downloads": -1, "filename": "AutoMunge_pkg-2.32-py3-none-any.whl", "has_sig": false, "md5_digest": "8febeda7afa900454d7141da98d2a0e2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 101328, "upload_time": "2019-08-09T03:35:14", "upload_time_iso_8601": "2019-08-09T03:35:14.096449Z", "url": "https://files.pythonhosted.org/packages/9b/2d/03b01e22dc04f2d7f32139c8811eed365665868f99cf4d3e365f8c3d9532/AutoMunge_pkg-2.32-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "568e03b7dbcd6a7feb1eb3bb7b91c0cd", "sha256": "0a82e5cac28b4612548cbcfc53780b38d011b9fcbc4d0ad60098c9988844c55f"}, "downloads": -1, "filename": "AutoMunge_pkg-2.32.tar.gz", "has_sig": false, "md5_digest": "568e03b7dbcd6a7feb1eb3bb7b91c0cd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 121709, "upload_time": "2019-08-09T03:35:16", "upload_time_iso_8601": "2019-08-09T03:35:16.302439Z", "url": "https://files.pythonhosted.org/packages/13/e0/d3f2b0d13f4ef051cf469a7c5c3ea6f594c9f1f3667ce2fa4cdf6b6ac67e/AutoMunge_pkg-2.32.tar.gz", "yanked": false}], "2.33": [{"comment_text": "", "digests": {"md5": "9326a7c502722aec866998d012f9edb8", "sha256": "a96cc4dd0d54f6e210df086f17d1fb636c24aeeb001fba6d802b418e2713fd3a"}, "downloads": -1, "filename": "AutoMunge_pkg-2.33-py3-none-any.whl", "has_sig": false, "md5_digest": "9326a7c502722aec866998d012f9edb8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 101266, "upload_time": "2019-08-10T22:38:11", "upload_time_iso_8601": "2019-08-10T22:38:11.796817Z", "url": "https://files.pythonhosted.org/packages/d2/2a/d48d0a9caf22b2c2655ab681bec0ac338807c7d502180d38e033e53cf3d4/AutoMunge_pkg-2.33-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "630812100ebac68d4ccb6b258f46840d", "sha256": "2d7fddb8460a662eafab3b52853e5dcdd5e45a144957a66bd9affaf75853ddab"}, "downloads": -1, "filename": "AutoMunge_pkg-2.33.tar.gz", "has_sig": false, "md5_digest": "630812100ebac68d4ccb6b258f46840d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 121426, "upload_time": "2019-08-10T22:38:14", "upload_time_iso_8601": "2019-08-10T22:38:14.082277Z", "url": "https://files.pythonhosted.org/packages/13/9d/a3702bb5e516896e6abd318c354db0f6f1569fa2ba754cdf1c6b8af7d7b7/AutoMunge_pkg-2.33.tar.gz", "yanked": false}], "2.34": [{"comment_text": "", "digests": {"md5": "39133047540cddb8901ca12265e850b2", "sha256": "76b102467fa2cc195b6538984905dffaf78442186b0ed5598fc576001e627813"}, "downloads": -1, "filename": "AutoMunge_pkg-2.34-py3-none-any.whl", "has_sig": false, "md5_digest": "39133047540cddb8901ca12265e850b2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 101333, "upload_time": "2019-08-11T01:52:49", "upload_time_iso_8601": "2019-08-11T01:52:49.223543Z", "url": "https://files.pythonhosted.org/packages/0a/6b/47be5311fdf32c7613c3ec346c46a0baf54278818e9abbfb0142c3775e3b/AutoMunge_pkg-2.34-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "662703fc15eb52a6512ae9e1ddbee6bc", "sha256": "5795d84ac8bc057587c38cf18119d9feae6409c9abc6051230d3e90fe3b4bc8d"}, "downloads": -1, "filename": "AutoMunge_pkg-2.34.tar.gz", "has_sig": false, "md5_digest": "662703fc15eb52a6512ae9e1ddbee6bc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 121470, "upload_time": "2019-08-11T01:52:51", "upload_time_iso_8601": "2019-08-11T01:52:51.143806Z", "url": "https://files.pythonhosted.org/packages/81/ab/f823df2b01b739602bd6c08d9674814a1dcf00d5bad15b127f3441e52a62/AutoMunge_pkg-2.34.tar.gz", "yanked": false}], "2.35": [{"comment_text": "", "digests": {"md5": "2e27c9c68480d8f98c93071b63239988", "sha256": "d4f9565101e38eeea511a4abf229fc9c1969e7c2e56d6c80eee9ff11e408c31a"}, "downloads": -1, "filename": "AutoMunge_pkg-2.35-py3-none-any.whl", "has_sig": false, "md5_digest": "2e27c9c68480d8f98c93071b63239988", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 101734, "upload_time": "2019-08-12T03:37:15", "upload_time_iso_8601": "2019-08-12T03:37:15.786486Z", "url": "https://files.pythonhosted.org/packages/b7/e6/0789ca2d5626f1fb3b40f675ab63779a7687dbfaa00fb05ec5c66a38b554/AutoMunge_pkg-2.35-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "484c5d9fdca9b592b1ad1d3e0e8873b2", "sha256": "3984069f889073439bdfeadc5e471790a48a920862c7a94e7a8a25d6d61d10c2"}, "downloads": -1, "filename": "AutoMunge_pkg-2.35.tar.gz", "has_sig": false, "md5_digest": "484c5d9fdca9b592b1ad1d3e0e8873b2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 121963, "upload_time": "2019-08-12T03:37:17", "upload_time_iso_8601": "2019-08-12T03:37:17.877472Z", "url": "https://files.pythonhosted.org/packages/ca/c7/7658822b36584d38e15efbb55c000873862a4ecb6d0974ac6f6788ae2b2c/AutoMunge_pkg-2.35.tar.gz", "yanked": false}], "2.36": [{"comment_text": "", "digests": {"md5": "89fc45ccd60803e4205ce5725ef511ed", "sha256": "4d179d60bf39f9a2bd84b5d1cf18f7a09ed1d1b12c8e3e9ab34615062b5b334e"}, "downloads": -1, "filename": "AutoMunge_pkg-2.36-py3-none-any.whl", "has_sig": false, "md5_digest": "89fc45ccd60803e4205ce5725ef511ed", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 102817, "upload_time": "2019-08-14T03:17:38", "upload_time_iso_8601": "2019-08-14T03:17:38.554947Z", "url": "https://files.pythonhosted.org/packages/2c/a8/94a63467d67d593b005acfedae7b8bbb975e1721ca55154d15c56437c898/AutoMunge_pkg-2.36-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b1daed670688a1b01e6b43fef3d43b64", "sha256": "8c531d63a1a535f434bcc211a7b6adf236a8b5e21a16e426d6f356159930d7ea"}, "downloads": -1, "filename": "AutoMunge_pkg-2.36.tar.gz", "has_sig": false, "md5_digest": "b1daed670688a1b01e6b43fef3d43b64", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 123216, "upload_time": "2019-08-14T03:17:40", "upload_time_iso_8601": "2019-08-14T03:17:40.852593Z", "url": "https://files.pythonhosted.org/packages/48/09/7f1ff3cafdf87a8aea57d552faaef2df7b5f486004d8a9515b3f4349ca56/AutoMunge_pkg-2.36.tar.gz", "yanked": false}], "2.37": [{"comment_text": "", "digests": {"md5": "bd0781554fdd9a7c14ceecf67ce48d74", "sha256": "25518b21ef6876a901432fe10093fbb1f45073846fbbbc6405466d9d54a4e8fb"}, "downloads": -1, "filename": "AutoMunge_pkg-2.37-py3-none-any.whl", "has_sig": false, "md5_digest": "bd0781554fdd9a7c14ceecf67ce48d74", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 102814, "upload_time": "2019-08-14T03:37:48", "upload_time_iso_8601": "2019-08-14T03:37:48.424961Z", "url": "https://files.pythonhosted.org/packages/d3/3f/18ade45dfb71bd62b0c58bf732635999593463ab20949e86e79c3d194fdc/AutoMunge_pkg-2.37-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "076e806c945fddba11d1310e6769c285", "sha256": "a0d6f200c1b31cf6b20812ad8034fbcaf61859cd2d52bb81e64a724da93aa7bf"}, "downloads": -1, "filename": "AutoMunge_pkg-2.37.tar.gz", "has_sig": false, "md5_digest": "076e806c945fddba11d1310e6769c285", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 123219, "upload_time": "2019-08-14T03:37:50", "upload_time_iso_8601": "2019-08-14T03:37:50.519832Z", "url": "https://files.pythonhosted.org/packages/e6/54/98fae8e60367471a4689952e50d085a3ae5c88afcff5fe8aeb341b5d0c92/AutoMunge_pkg-2.37.tar.gz", "yanked": false}], "2.38": [{"comment_text": "", "digests": {"md5": "8bd016336a314a39b10c012fe2f2cc5c", "sha256": "27f00b85ff8a64904ed4d071811a68366d3414fe673372fa90164b99f7bb8547"}, "downloads": -1, "filename": "AutoMunge_pkg-2.38-py3-none-any.whl", "has_sig": false, "md5_digest": "8bd016336a314a39b10c012fe2f2cc5c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 102913, "upload_time": "2019-08-15T01:53:50", "upload_time_iso_8601": "2019-08-15T01:53:50.424985Z", "url": "https://files.pythonhosted.org/packages/27/2c/d91226c0b5c61ef8108dff3c4826035b06c65c13a04b6152b2481cfd9e0d/AutoMunge_pkg-2.38-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5a2a0fd72e8e5585d1b21d8f2418629f", "sha256": "be1e9d8269900c6e56ab8db8d6658306b801232f6a2bcca9b86968162a35be8e"}, "downloads": -1, "filename": "AutoMunge_pkg-2.38.tar.gz", "has_sig": false, "md5_digest": "5a2a0fd72e8e5585d1b21d8f2418629f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 123302, "upload_time": "2019-08-15T01:53:53", "upload_time_iso_8601": "2019-08-15T01:53:53.937758Z", "url": "https://files.pythonhosted.org/packages/87/61/4a84cdca76d06873ae405b21ca135e03ffbd0697d33571c50af9eb72f4e6/AutoMunge_pkg-2.38.tar.gz", "yanked": false}], "2.39": [{"comment_text": "", "digests": {"md5": "a8f8770097afe8ec9f3f96e18e4985ef", "sha256": "991599d31010326d2cc1af6d316a09d3fb570e2784e501a1f8a38c488edd72c5"}, "downloads": -1, "filename": "AutoMunge_pkg-2.39-py3-none-any.whl", "has_sig": false, "md5_digest": "a8f8770097afe8ec9f3f96e18e4985ef", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 103105, "upload_time": "2019-08-16T03:47:27", "upload_time_iso_8601": "2019-08-16T03:47:27.404956Z", "url": "https://files.pythonhosted.org/packages/f9/ca/b8fcc8e948c1e72ae1198b4a81d9bb8fb40159c1f70644a87a1b723854df/AutoMunge_pkg-2.39-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1987e9ca58c25c53c0cf65ba8e184411", "sha256": "a511e55a58dd26890a1354934fee30b593785e85b8904054d0e08d68fc8a9764"}, "downloads": -1, "filename": "AutoMunge_pkg-2.39.tar.gz", "has_sig": false, "md5_digest": "1987e9ca58c25c53c0cf65ba8e184411", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 123495, "upload_time": "2019-08-16T03:47:29", "upload_time_iso_8601": "2019-08-16T03:47:29.105023Z", "url": "https://files.pythonhosted.org/packages/6c/22/723cf6bdd6498dccbddf417f57d7c89564ba2c16c8594de8cd0843525098/AutoMunge_pkg-2.39.tar.gz", "yanked": false}], "2.40": [{"comment_text": "", "digests": {"md5": "1d7d7aab6c28d6e88c604d6cff24f54e", "sha256": "94d81ee216bc314854869a6770562ed1f42d7ccd443240b004e0b865d8062e76"}, "downloads": -1, "filename": "AutoMunge_pkg-2.40-py3-none-any.whl", "has_sig": false, "md5_digest": "1d7d7aab6c28d6e88c604d6cff24f54e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 103480, "upload_time": "2019-08-26T19:44:19", "upload_time_iso_8601": "2019-08-26T19:44:19.802235Z", "url": "https://files.pythonhosted.org/packages/09/43/4bb645259bd2af00c3dc2d82c8be9fe88da2291c179d5a123239030f81a0/AutoMunge_pkg-2.40-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5314ec0f0955c08eb0b354d6ab7e1301", "sha256": "1e46ebca04ea97ddb6c0481f3cf4282250bbb8a11801ca35934a063a377fea8e"}, "downloads": -1, "filename": "AutoMunge_pkg-2.40.tar.gz", "has_sig": false, "md5_digest": "5314ec0f0955c08eb0b354d6ab7e1301", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 123944, "upload_time": "2019-08-26T19:44:23", "upload_time_iso_8601": "2019-08-26T19:44:23.718682Z", "url": "https://files.pythonhosted.org/packages/52/86/252621907f29719fd4038689bcabe5ac8a55ba0bc9491ad6adb0249e43c0/AutoMunge_pkg-2.40.tar.gz", "yanked": false}], "2.41": [{"comment_text": "", "digests": {"md5": "34667f811d5d8d0b7cbc5395ac7401be", "sha256": "1e7c9de9ede0a83cafbd345624c4fe608ac2f1ccc327ea0bcab5fbb5dad980b8"}, "downloads": -1, "filename": "AutoMunge_pkg-2.41-py3-none-any.whl", "has_sig": false, "md5_digest": "34667f811d5d8d0b7cbc5395ac7401be", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 106648, "upload_time": "2019-08-27T19:49:09", "upload_time_iso_8601": "2019-08-27T19:49:09.447376Z", "url": "https://files.pythonhosted.org/packages/8c/6e/bddba8dd75deb683cf989f420f3ca3b6a53d28d091af8dd702c575bc7119/AutoMunge_pkg-2.41-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1cb2c61d3abb23da34f49bfa64cd3284", "sha256": "5eaf07a0b84efccf739c413d7dd5a194ef30e7634f691c9760209ce2aac95182"}, "downloads": -1, "filename": "AutoMunge_pkg-2.41.tar.gz", "has_sig": false, "md5_digest": "1cb2c61d3abb23da34f49bfa64cd3284", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 127295, "upload_time": "2019-08-27T19:49:12", "upload_time_iso_8601": "2019-08-27T19:49:12.154927Z", "url": "https://files.pythonhosted.org/packages/11/28/d4f40be5990f674e8635cfa99ed9369488a81a0468fa4122777e71aa5de9/AutoMunge_pkg-2.41.tar.gz", "yanked": false}], "2.42": [{"comment_text": "", "digests": {"md5": "2e220f05b962708108c404839c00520e", "sha256": "d6793ba4068d6e38fcfa2da368bc22fb5887bfa552ca4ca375b69fa15a381e6a"}, "downloads": -1, "filename": "AutoMunge_pkg-2.42-py3-none-any.whl", "has_sig": false, "md5_digest": "2e220f05b962708108c404839c00520e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 106638, "upload_time": "2019-08-29T16:31:46", "upload_time_iso_8601": "2019-08-29T16:31:46.561564Z", "url": "https://files.pythonhosted.org/packages/95/55/c767b702aefc97f65f498cb8a51e1494d527ae9abc1413a411f3203b25bd/AutoMunge_pkg-2.42-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2d765c42f7e0c993d07557c0015b26a4", "sha256": "3362b4ebcb8cab0ccb63e52fccd88798da0572fed58b101e1e3ed132706c5e02"}, "downloads": -1, "filename": "AutoMunge_pkg-2.42.tar.gz", "has_sig": false, "md5_digest": "2d765c42f7e0c993d07557c0015b26a4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 127286, "upload_time": "2019-08-29T16:31:58", "upload_time_iso_8601": "2019-08-29T16:31:58.022283Z", "url": "https://files.pythonhosted.org/packages/5b/55/6018d40a552e98a8987dd085c9345f35785a005c2b56ad9ab12fb439f53c/AutoMunge_pkg-2.42.tar.gz", "yanked": false}], "2.43": [{"comment_text": "", "digests": {"md5": "58ea27e69806639d66538eb9ee40bb73", "sha256": "984e62bd0edea33bd2d3b0ea2e740fff5d2d0572d29f6f89348759c493d9497b"}, "downloads": -1, "filename": "AutoMunge_pkg-2.43-py3-none-any.whl", "has_sig": false, "md5_digest": "58ea27e69806639d66538eb9ee40bb73", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 106617, "upload_time": "2019-09-02T20:25:56", "upload_time_iso_8601": "2019-09-02T20:25:56.232885Z", "url": "https://files.pythonhosted.org/packages/6a/76/2b40e35bdd03134defb793c696db41f7fafd1b18b099f0d016e22672e632/AutoMunge_pkg-2.43-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "be6f9c1092570ce38806489cb5e2ca5a", "sha256": "e1eac6e16b6d40af42f28e2a1e80b35f7b5f4d45aabe1c8a846266e1cf117c85"}, "downloads": -1, "filename": "AutoMunge_pkg-2.43.tar.gz", "has_sig": false, "md5_digest": "be6f9c1092570ce38806489cb5e2ca5a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 127290, "upload_time": "2019-09-02T20:25:58", "upload_time_iso_8601": "2019-09-02T20:25:58.318816Z", "url": "https://files.pythonhosted.org/packages/79/74/bcc9b619eecf6a7abbd7ec0f1337f1c610bbf57647890aca9f30d04a8178/AutoMunge_pkg-2.43.tar.gz", "yanked": false}], "2.44": [{"comment_text": "", "digests": {"md5": "3f430121f5f78cd248b2d8fa24291646", "sha256": "172ae02bd85460930c79a9f8f1ffeaa85f1d63ed6863cad6cd950298cc53e178"}, "downloads": -1, "filename": "AutoMunge_pkg-2.44-py3-none-any.whl", "has_sig": false, "md5_digest": "3f430121f5f78cd248b2d8fa24291646", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 106628, "upload_time": "2019-09-02T21:32:27", "upload_time_iso_8601": "2019-09-02T21:32:27.350676Z", "url": "https://files.pythonhosted.org/packages/74/96/12faee71d17fcc8b3b3b6614d4459ef5dbca176d9605e10e0efd4976d70d/AutoMunge_pkg-2.44-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "920fc601c2dca6b1e6b4966bbc50fb4a", "sha256": "c749ca68bba0fcd105e09155a07d86672b90d523bbf39694ad901f948cc64ba3"}, "downloads": -1, "filename": "AutoMunge_pkg-2.44.tar.gz", "has_sig": false, "md5_digest": "920fc601c2dca6b1e6b4966bbc50fb4a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 127305, "upload_time": "2019-09-02T21:32:29", "upload_time_iso_8601": "2019-09-02T21:32:29.404234Z", "url": "https://files.pythonhosted.org/packages/45/a4/1a257632c413d2466f630b5e88cd7f8b6ad544810c9630cfe367bbb6ce46/AutoMunge_pkg-2.44.tar.gz", "yanked": false}], "2.45": [{"comment_text": "", "digests": {"md5": "1a8c5063354debbc74dbb471a5e76289", "sha256": "827f4c10acee32c195f1678d77c32ab0d8c59aeccd9b68b2dc1d7fc45786ca87"}, "downloads": -1, "filename": "AutoMunge_pkg-2.45-py3-none-any.whl", "has_sig": false, "md5_digest": "1a8c5063354debbc74dbb471a5e76289", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 106615, "upload_time": "2019-09-03T01:03:48", "upload_time_iso_8601": "2019-09-03T01:03:48.534375Z", "url": "https://files.pythonhosted.org/packages/61/1c/879cef6bb73f2d44b5ce134179e7ed3067d437732fbafe6fc2891a62e197/AutoMunge_pkg-2.45-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fe70972c50665145553e30f0a64ddbe9", "sha256": "3250d323764ccf5d0728575bd790d77a4836df0cfae8db35f3060893c2f9ff8d"}, "downloads": -1, "filename": "AutoMunge_pkg-2.45.tar.gz", "has_sig": false, "md5_digest": "fe70972c50665145553e30f0a64ddbe9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 127286, "upload_time": "2019-09-03T01:03:50", "upload_time_iso_8601": "2019-09-03T01:03:50.406042Z", "url": "https://files.pythonhosted.org/packages/3d/b4/cae7be2f871cabdf0d177818daf6d4c7eff4801b638a1c8a598b365add85/AutoMunge_pkg-2.45.tar.gz", "yanked": false}], "2.46": [{"comment_text": "", "digests": {"md5": "572614acbebeca401228ee3775482a81", "sha256": "0b10ea8c2c378240d3609b6900b63cf052e155b694f573c8517ea49415aa7fe3"}, "downloads": -1, "filename": "AutoMunge_pkg-2.46-py3-none-any.whl", "has_sig": false, "md5_digest": "572614acbebeca401228ee3775482a81", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 104551, "upload_time": "2019-09-05T01:05:42", "upload_time_iso_8601": "2019-09-05T01:05:42.746804Z", "url": "https://files.pythonhosted.org/packages/5d/95/0bbb49f76877ca413525bf72ef7d4b189ffa89d2782a0756751365115207/AutoMunge_pkg-2.46-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0fbcdb0fc281a71604dd416ba7ddfd43", "sha256": "e75f1c47735f07159fc6204f9b0eb52a384de20859d7d3fc43bc633ef925da81"}, "downloads": -1, "filename": "AutoMunge_pkg-2.46.tar.gz", "has_sig": false, "md5_digest": "0fbcdb0fc281a71604dd416ba7ddfd43", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 125490, "upload_time": "2019-09-05T01:05:44", "upload_time_iso_8601": "2019-09-05T01:05:44.374713Z", "url": "https://files.pythonhosted.org/packages/67/6c/0ade95fe7454c866d70b3bf36c12b29765e61660b69cf069606c6535033c/AutoMunge_pkg-2.46.tar.gz", "yanked": false}], "2.47": [{"comment_text": "", "digests": {"md5": "47a8c71e09cfe4424978e3fc2e8be7a7", "sha256": "9c12c6c101eb725bdae441daf66b9b0ebcb396ba1d3fb8369c31a0fbd3aa5d89"}, "downloads": -1, "filename": "AutoMunge_pkg-2.47-py3-none-any.whl", "has_sig": false, "md5_digest": "47a8c71e09cfe4424978e3fc2e8be7a7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 116444, "upload_time": "2019-09-06T04:04:09", "upload_time_iso_8601": "2019-09-06T04:04:09.903013Z", "url": "https://files.pythonhosted.org/packages/37/e7/a24a7e3f3740afa4c9217d4aed29616c5219ebdff1e946978ccdc34a4234/AutoMunge_pkg-2.47-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "784e6a8393c7a137dd176bf1b4ef3d7a", "sha256": "728c6efe70d4ec0ec2ca463d00678979a36c33337cccd808fc67da3e2e8c0f9c"}, "downloads": -1, "filename": "AutoMunge_pkg-2.47.tar.gz", "has_sig": false, "md5_digest": "784e6a8393c7a137dd176bf1b4ef3d7a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 139664, "upload_time": "2019-09-06T04:04:12", "upload_time_iso_8601": "2019-09-06T04:04:12.491424Z", "url": "https://files.pythonhosted.org/packages/29/c1/37e55671008d164d6fcc0c2f57f39399793ef13ba41942a92e1fe490d224/AutoMunge_pkg-2.47.tar.gz", "yanked": false}], "2.48": [{"comment_text": "", "digests": {"md5": "0d9a9280f4038d201159e52dcd870d3c", "sha256": "7dbcd93b32060a4c115a672352d2d472d76155559d9ac4904a4e26faa9080941"}, "downloads": -1, "filename": "AutoMunge_pkg-2.48-py3-none-any.whl", "has_sig": false, "md5_digest": "0d9a9280f4038d201159e52dcd870d3c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 118272, "upload_time": "2019-09-09T21:18:10", "upload_time_iso_8601": "2019-09-09T21:18:10.197635Z", "url": "https://files.pythonhosted.org/packages/61/e6/a1d8d41d76d3965e0ddff22d83125c51f3bfe730cd7a1ff364711034f6a6/AutoMunge_pkg-2.48-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "819730525d4b8e34302a6ace25a62bc8", "sha256": "91ae82db1e24ef62b4398860da9d9d145e30f245a963213647d1f46c800c8bf3"}, "downloads": -1, "filename": "AutoMunge_pkg-2.48.tar.gz", "has_sig": false, "md5_digest": "819730525d4b8e34302a6ace25a62bc8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 141714, "upload_time": "2019-09-09T21:18:12", "upload_time_iso_8601": "2019-09-09T21:18:12.562797Z", "url": "https://files.pythonhosted.org/packages/f5/15/31c6528b5c1cddb549abcb463b30fc0ee996490f2443a3a5dcb9a52d547a/AutoMunge_pkg-2.48.tar.gz", "yanked": false}], "2.49": [{"comment_text": "", "digests": {"md5": "c8fc63af0fae126e981b20f85ee5e701", "sha256": "0e0853943433a091af523a0bc854ec3d42e1e05531c8b9501d8192a9454d150a"}, "downloads": -1, "filename": "AutoMunge_pkg-2.49-py3-none-any.whl", "has_sig": false, "md5_digest": "c8fc63af0fae126e981b20f85ee5e701", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 118277, "upload_time": "2019-09-11T00:21:40", "upload_time_iso_8601": "2019-09-11T00:21:40.499122Z", "url": "https://files.pythonhosted.org/packages/17/33/c803cb1df0d4d9b1a3692adbd4fc9a2159ea32447c65a170537afd53e39a/AutoMunge_pkg-2.49-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b0fef210a1e52dff6362ad76ceff17cc", "sha256": "aabd616ff1c00bd1ecf7b363192dcde7b464570e0ade6b73558ddd90d3fd4c0f"}, "downloads": -1, "filename": "AutoMunge_pkg-2.49.tar.gz", "has_sig": false, "md5_digest": "b0fef210a1e52dff6362ad76ceff17cc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 141699, "upload_time": "2019-09-11T00:21:42", "upload_time_iso_8601": "2019-09-11T00:21:42.649061Z", "url": "https://files.pythonhosted.org/packages/6d/cc/f6910fdc10e1cccf6a6573621a11605a93a81868259fc1b3d142728ae176/AutoMunge_pkg-2.49.tar.gz", "yanked": false}], "2.50": [{"comment_text": "", "digests": {"md5": "fd2fc3162776e42e9db8becb2ec69c5e", "sha256": "d5886a2be2032d33d7ba4d4c4e6b2b144be82834f68ebad13562ddf716d5f8aa"}, "downloads": -1, "filename": "AutoMunge_pkg-2.50-py3-none-any.whl", "has_sig": false, "md5_digest": "fd2fc3162776e42e9db8becb2ec69c5e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 119263, "upload_time": "2019-09-13T04:40:19", "upload_time_iso_8601": "2019-09-13T04:40:19.972553Z", "url": "https://files.pythonhosted.org/packages/32/c9/cd413975399c6bb8bfd62281584c2bfb6ec967e23c64cf44cefee819ec0a/AutoMunge_pkg-2.50-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "99226cb5a4d0636dd6b93ed06ec941b9", "sha256": "082043ab40de6e295baf59071f091b41046092badce5729d3c37a8cc96b8d389"}, "downloads": -1, "filename": "AutoMunge_pkg-2.50.tar.gz", "has_sig": false, "md5_digest": "99226cb5a4d0636dd6b93ed06ec941b9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 142796, "upload_time": "2019-09-13T04:40:21", "upload_time_iso_8601": "2019-09-13T04:40:21.818506Z", "url": "https://files.pythonhosted.org/packages/43/f7/1034558b597b7f5115cc5174ccb987de78aacfbba2b62aef415159b4f8d7/AutoMunge_pkg-2.50.tar.gz", "yanked": false}], "2.51": [{"comment_text": "", "digests": {"md5": "5a34dc2b8b9392a7e51ac9816c0be4ae", "sha256": "4d0cc0d4d299ed23955c6cf31f0efab61d45dc5189ff04ce1dbb23fa9883a65f"}, "downloads": -1, "filename": "AutoMunge_pkg-2.51-py3-none-any.whl", "has_sig": false, "md5_digest": "5a34dc2b8b9392a7e51ac9816c0be4ae", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 120328, "upload_time": "2019-09-19T22:21:02", "upload_time_iso_8601": "2019-09-19T22:21:02.939877Z", "url": "https://files.pythonhosted.org/packages/f6/04/f349132b7136bf75aadbf623cad564fd7a531a44c23c3be87ecced8fc17d/AutoMunge_pkg-2.51-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "36dd6f7088137542e79d8366a0866188", "sha256": "91137d47b64c908fd48fe00c52db04051dfd20e760b36261a13357f11868273f"}, "downloads": -1, "filename": "AutoMunge_pkg-2.51.tar.gz", "has_sig": false, "md5_digest": "36dd6f7088137542e79d8366a0866188", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 144144, "upload_time": "2019-09-19T22:21:05", "upload_time_iso_8601": "2019-09-19T22:21:05.332347Z", "url": "https://files.pythonhosted.org/packages/96/a6/5c912c9006fe87eedc958a59a1da2e828b2a9146848e3c6f7e3aaa668110/AutoMunge_pkg-2.51.tar.gz", "yanked": false}], "2.52": [{"comment_text": "", "digests": {"md5": "5201d144fe7f854d320ba3aa36dce641", "sha256": "df6f6305e1db02e9013a402f1449df68460d3e4db70fdc8fabb1aae2f58905bd"}, "downloads": -1, "filename": "AutoMunge_pkg-2.52-py3-none-any.whl", "has_sig": false, "md5_digest": "5201d144fe7f854d320ba3aa36dce641", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 120348, "upload_time": "2019-09-20T14:42:40", "upload_time_iso_8601": "2019-09-20T14:42:40.655432Z", "url": "https://files.pythonhosted.org/packages/ab/9a/194ffe248300a93abdb91554c829d69b2166ad6f0b93c99efa1df030c088/AutoMunge_pkg-2.52-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "43c4a64af0efe219b93a5910c1f3fcf9", "sha256": "4f1e9eaa3d081d7a6eb6c48ed04832842e5d609b81156b4f0cdf2bffd35d937c"}, "downloads": -1, "filename": "AutoMunge_pkg-2.52.tar.gz", "has_sig": false, "md5_digest": "43c4a64af0efe219b93a5910c1f3fcf9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 144167, "upload_time": "2019-09-20T14:42:42", "upload_time_iso_8601": "2019-09-20T14:42:42.931062Z", "url": "https://files.pythonhosted.org/packages/26/04/aed6c862061d6a2558b0c002c31eab4fb817e30bd64a927793bd17e4b34c/AutoMunge_pkg-2.52.tar.gz", "yanked": false}], "2.53": [{"comment_text": "", "digests": {"md5": "96801e43395a9ffafefc503d94d7b4ab", "sha256": "f4942602aa496f6b203c7ebd1f20c910facb2a79265ada0c0b7c5422781c8ebe"}, "downloads": -1, "filename": "AutoMunge_pkg-2.53-py3-none-any.whl", "has_sig": false, "md5_digest": "96801e43395a9ffafefc503d94d7b4ab", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 120387, "upload_time": "2019-09-20T16:59:30", "upload_time_iso_8601": "2019-09-20T16:59:30.254792Z", "url": "https://files.pythonhosted.org/packages/6f/b0/7230cad981c4b730ae5e39ba8f3bc4ee043415b3a76034a48b0384a1eb88/AutoMunge_pkg-2.53-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5bcc7ff31092d8bf9a77f261ad11d425", "sha256": "52d2c464a5bd07fb46f351a107e9005867249a5327a55d6e70b107ac038b7543"}, "downloads": -1, "filename": "AutoMunge_pkg-2.53.tar.gz", "has_sig": false, "md5_digest": "5bcc7ff31092d8bf9a77f261ad11d425", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 144290, "upload_time": "2019-09-20T16:59:32", "upload_time_iso_8601": "2019-09-20T16:59:32.599680Z", "url": "https://files.pythonhosted.org/packages/bf/43/de88c3c437a39568952def14e289bbcd39340b5504b1a6b8f02fe888f948/AutoMunge_pkg-2.53.tar.gz", "yanked": false}], "2.54": [{"comment_text": "", "digests": {"md5": "502ba0191a091b031eda8404c8a5fac1", "sha256": "2c4decdbe2ccc2f7ec698d8f27b28cc389ea8f588e7b04cb4a14c4bba4863f2a"}, "downloads": -1, "filename": "AutoMunge_pkg-2.54-py3-none-any.whl", "has_sig": false, "md5_digest": "502ba0191a091b031eda8404c8a5fac1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 120626, "upload_time": "2019-09-20T22:16:50", "upload_time_iso_8601": "2019-09-20T22:16:50.231206Z", "url": "https://files.pythonhosted.org/packages/f6/9e/c111fff88ed23929ab097d46423e8a6fa3fab1d005908da9578583c8fdb3/AutoMunge_pkg-2.54-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "456ad3856bbf1e8a00653a310b03728b", "sha256": "8220874c99aec7c570f9a76fd1471a9cc3df20212be9ecf96de78b5be1b8e44a"}, "downloads": -1, "filename": "AutoMunge_pkg-2.54.tar.gz", "has_sig": false, "md5_digest": "456ad3856bbf1e8a00653a310b03728b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 144564, "upload_time": "2019-09-20T22:16:52", "upload_time_iso_8601": "2019-09-20T22:16:52.298472Z", "url": "https://files.pythonhosted.org/packages/fb/4f/595b5535bbd856d7eba077b56d27a9ae8f26459c634bc4f05f68edeed4bb/AutoMunge_pkg-2.54.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "502ba0191a091b031eda8404c8a5fac1", "sha256": "2c4decdbe2ccc2f7ec698d8f27b28cc389ea8f588e7b04cb4a14c4bba4863f2a"}, "downloads": -1, "filename": "AutoMunge_pkg-2.54-py3-none-any.whl", "has_sig": false, "md5_digest": "502ba0191a091b031eda8404c8a5fac1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 120626, "upload_time": "2019-09-20T22:16:50", "upload_time_iso_8601": "2019-09-20T22:16:50.231206Z", "url": "https://files.pythonhosted.org/packages/f6/9e/c111fff88ed23929ab097d46423e8a6fa3fab1d005908da9578583c8fdb3/AutoMunge_pkg-2.54-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "456ad3856bbf1e8a00653a310b03728b", "sha256": "8220874c99aec7c570f9a76fd1471a9cc3df20212be9ecf96de78b5be1b8e44a"}, "downloads": -1, "filename": "AutoMunge_pkg-2.54.tar.gz", "has_sig": false, "md5_digest": "456ad3856bbf1e8a00653a310b03728b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 144564, "upload_time": "2019-09-20T22:16:52", "upload_time_iso_8601": "2019-09-20T22:16:52.298472Z", "url": "https://files.pythonhosted.org/packages/fb/4f/595b5535bbd856d7eba077b56d27a9ae8f26459c634bc4f05f68edeed4bb/AutoMunge_pkg-2.54.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:16:12 2020"}