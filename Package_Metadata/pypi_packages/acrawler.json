{"info": {"author": "wooddance", "author_email": "zireael.me@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "aCrawler\n========\n\n\n.. image:: https://img.shields.io/pypi/v/acrawler.svg\n   :target: https://pypi.org/project/acrawler/\n   :alt: PyPI\n.. image:: https://readthedocs.org/projects/acrawler/badge/?version=latest\n    :target: https://acrawler.readthedocs.io/en/latest/?badge=latest\n    :alt: Documentation Status\n\n\ud83d\udd0d A powerful web-crawling framework, based on aiohttp.\n\n\n\nFeature\n-------\n\n\n* Write your crawler in one Python script with asyncio\n* Schedule task with priority, fingerprint, exetime, recrawl...\n* Middleware: add handlers before or after task's execution\n* Simple shortcuts to speed up scripting\n* Parse html conveniently with `Parsel <https://parsel.readthedocs.io/en/latest/>`_\n* Parse with rules and chained processors\n* Support JavaScript/browser-automation with `pyppeteer <https://github.com/miyakogi/pyppeteer>`_\n* Stop and Resume: crawl periodically and persistently\n* Distributed work support with Redis\n\nInstallation\n------------\n\nTo install, simply use pip:\n\n.. code-block:: bash\n\n   $ pip install acrawler\n\n   (Optional)\n   $ pip install uvloop      #(only Linux/macOS, for faster asyncio event loop)\n   $ pip install aioredis    #(if you need Redis support)\n   $ pip install motor       #(if you need MongoDB support)\n   $ pip install aiofiles    #(if you need FileRequest)\n\nDocumentation\n-------------\nDocumentation and tutorial are available online at https://acrawler.readthedocs.io/ and in the ``docs``\ndirectory.\n\nSample Code\n-----------\n\n\n\nScrape imdb.com\n^^^^^^^^^^^^^^^\n\n.. code-block:: python\n\n   from acrawler import Crawler, Request, ParselItem, Handler, register, get_logger\n\n\n   class MovieItem(ParselItem):\n      log = True\n      css = {\n         # just some normal css rules\n         # see Parsel for detailed information\n         \"date\": \".subtext a[href*=releaseinfo]::text\",\n         \"time\": \".subtext time::text\",\n         \"rating\": \"span[itemprop=ratingValue]::text\",\n         \"rating_count\": \"span[itemprop=ratingCount]::text\",\n         \"metascore\": \".metacriticScore span::text\",\n\n         # if you provide a list with additional functions,\n         # they are considered as field processor function\n         \"title\": [\"h1::text\", str.strip],\n\n         # the following four fules is for getting all matching values\n         # the rule starts with [ and ends with ] comparing to normal rules\n         \"genres\": \"[.subtext a[href*=genres]::text]\",\n         \"director\": \"[h4:contains(Director) ~ a[href*=name]::text]\",\n         \"writers\": \"[h4:contains(Writer) ~ a[href*=name]::text]\",\n         \"stars\": \"[h4:contains(Star) ~ a[href*=name]::text]\",\n      }\n\n\n   class IMDBCrawler(Crawler):\n      config = {\"MAX_REQUESTS\": 4, \"DOWNLOAD_DELAY\": 1}\n\n      async def start_requests(self):\n         yield Request(\"https://www.imdb.com/chart/moviemeter\", callback=self.parse)\n\n      def parse(self, response):\n         yield from response.follow(\n               \".lister-list tr .titleColumn a::attr(href)\", callback=self.parse_movie\n         )\n\n      def parse_movie(self, response):\n         url = response.url_str\n         yield MovieItem(response.sel, extra={\"url\": url.split(\"?\")[0]})\n\n\n   @register()\n   class HorrorHandler(Handler):\n      family = \"MovieItem\"\n      logger = get_logger(\"horrorlog\")\n\n      async def handle_after(self, item):\n         if item[\"genres\"] and \"Horror\" in item[\"genres\"]:\n               self.logger.warning(f\"({item['title']}) is a horror movie!!!!\")\n\n\n   @MovieItem.bind()\n   def process_time(value):\n      # a self-defined field processing function\n      # process time to minutes\n      # '3h 1min' -> 181\n      if value:\n         res = 0\n         segs = value.split(\" \")\n         for seg in segs:\n               if seg.endswith(\"min\"):\n                  res += int(seg.replace(\"min\", \"\"))\n               elif seg.endswith(\"h\"):\n                  res += 60 * int(seg.replace(\"h\", \"\"))\n         return res\n      return value\n\n\n   if __name__ == \"__main__\":\n      IMDBCrawler().run()\n\n\n\nScrape quotes.toscrape.com\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n.. code-block:: python\n\n   # Scrape quotes from http://quotes.toscrape.com/\n   from acrawler import Parser, Crawler, ParselItem, Request\n\n\n   logger = get_logger(\"quotes\")\n\n\n   class QuoteItem(ParselItem):\n      log = True\n      default = {\"type\": \"quote\"}\n      css = {\"author\": \"small.author::text\"}\n      xpath = {\"text\": ['.//span[@class=\"text\"]/text()', lambda s: s.strip(\"\u201c\")[:20]]}\n\n\n   class AuthorItem(ParselItem):\n      log = True\n      default = {\"type\": \"author\"}\n      css = {\"name\": \"h3.author-title::text\", \"born\": \"span.author-born-date::text\"}\n\n   class QuoteCrawler(Crawler):\n\n      main_page = r\"quotes.toscrape.com/page/\\d+\"\n      author_page = r\"quotes.toscrape.com/author/.*\"\n      parsers = [\n         Parser(\n               in_pattern=main_page,\n               follow_patterns=[main_page, author_page],\n               item_type=QuoteItem,\n               css_divider=\".quote\",\n         ),\n         Parser(in_pattern=author_page, item_type=AuthorItem),\n      ]\n\n      async def start_requests(self):\n         yield Request(url=\"http://quotes.toscrape.com/page/1/\")\n\n\n   if __name__ == \"__main__\":\n      QuoteCrawler().run()\n\n\nSee `examples <examples/>`_.\n\n\nTodo\n----\n\n* Replace parsel with parselx\n* clean redundant handlers\n* Cralwer's name for distinguishing\n* Use dynaconf as configuration manager\n* Add delta_key support for request\n* Monitor all crawlers in web\n* Write detailed Documentation\n* Testing", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/wooddance/aCrawler", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "acrawler", "package_url": "https://pypi.org/project/acrawler/", "platform": "", "project_url": "https://pypi.org/project/acrawler/", "project_urls": {"Homepage": "https://github.com/wooddance/aCrawler"}, "release_url": "https://pypi.org/project/acrawler/0.1.6/", "requires_dist": null, "requires_python": ">=3.6.0", "summary": "A simple web-crawling framework, based on aiohttp.", "version": "0.1.6", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://pypi.org/project/acrawler/\" rel=\"nofollow\"><img alt=\"PyPI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/96721be40f7d077d8d03308c184a3f4b81c03426/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f61637261776c65722e737667\"></a>\n<a href=\"https://acrawler.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9c3e8f35b9ce34e775867b5bef17f81a9c9ba3f3/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f61637261776c65722f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<p>\ud83d\udd0d A powerful web-crawling framework, based on aiohttp.</p>\n<div id=\"feature\">\n<h2>Feature</h2>\n<ul>\n<li>Write your crawler in one Python script with asyncio</li>\n<li>Schedule task with priority, fingerprint, exetime, recrawl\u2026</li>\n<li>Middleware: add handlers before or after task\u2019s execution</li>\n<li>Simple shortcuts to speed up scripting</li>\n<li>Parse html conveniently with <a href=\"https://parsel.readthedocs.io/en/latest/\" rel=\"nofollow\">Parsel</a></li>\n<li>Parse with rules and chained processors</li>\n<li>Support JavaScript/browser-automation with <a href=\"https://github.com/miyakogi/pyppeteer\" rel=\"nofollow\">pyppeteer</a></li>\n<li>Stop and Resume: crawl periodically and persistently</li>\n<li>Distributed work support with Redis</li>\n</ul>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>To install, simply use pip:</p>\n<pre>$ pip install acrawler\n\n<span class=\"o\">(</span>Optional<span class=\"o\">)</span>\n$ pip install uvloop      <span class=\"c1\">#(only Linux/macOS, for faster asyncio event loop)\n</span>$ pip install aioredis    <span class=\"c1\">#(if you need Redis support)\n</span>$ pip install motor       <span class=\"c1\">#(if you need MongoDB support)\n</span>$ pip install aiofiles    <span class=\"c1\">#(if you need FileRequest)</span>\n</pre>\n</div>\n<div id=\"documentation\">\n<h2>Documentation</h2>\n<p>Documentation and tutorial are available online at <a href=\"https://acrawler.readthedocs.io/\" rel=\"nofollow\">https://acrawler.readthedocs.io/</a> and in the <tt>docs</tt>\ndirectory.</p>\n</div>\n<div id=\"sample-code\">\n<h2>Sample Code</h2>\n<div id=\"scrape-imdb-com\">\n<h3>Scrape imdb.com</h3>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">acrawler</span> <span class=\"kn\">import</span> <span class=\"n\">Crawler</span><span class=\"p\">,</span> <span class=\"n\">Request</span><span class=\"p\">,</span> <span class=\"n\">ParselItem</span><span class=\"p\">,</span> <span class=\"n\">Handler</span><span class=\"p\">,</span> <span class=\"n\">register</span><span class=\"p\">,</span> <span class=\"n\">get_logger</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">MovieItem</span><span class=\"p\">(</span><span class=\"n\">ParselItem</span><span class=\"p\">):</span>\n   <span class=\"n\">log</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n   <span class=\"n\">css</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n      <span class=\"c1\"># just some normal css rules</span>\n      <span class=\"c1\"># see Parsel for detailed information</span>\n      <span class=\"s2\">\"date\"</span><span class=\"p\">:</span> <span class=\"s2\">\".subtext a[href*=releaseinfo]::text\"</span><span class=\"p\">,</span>\n      <span class=\"s2\">\"time\"</span><span class=\"p\">:</span> <span class=\"s2\">\".subtext time::text\"</span><span class=\"p\">,</span>\n      <span class=\"s2\">\"rating\"</span><span class=\"p\">:</span> <span class=\"s2\">\"span[itemprop=ratingValue]::text\"</span><span class=\"p\">,</span>\n      <span class=\"s2\">\"rating_count\"</span><span class=\"p\">:</span> <span class=\"s2\">\"span[itemprop=ratingCount]::text\"</span><span class=\"p\">,</span>\n      <span class=\"s2\">\"metascore\"</span><span class=\"p\">:</span> <span class=\"s2\">\".metacriticScore span::text\"</span><span class=\"p\">,</span>\n\n      <span class=\"c1\"># if you provide a list with additional functions,</span>\n      <span class=\"c1\"># they are considered as field processor function</span>\n      <span class=\"s2\">\"title\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"h1::text\"</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"o\">.</span><span class=\"n\">strip</span><span class=\"p\">],</span>\n\n      <span class=\"c1\"># the following four fules is for getting all matching values</span>\n      <span class=\"c1\"># the rule starts with [ and ends with ] comparing to normal rules</span>\n      <span class=\"s2\">\"genres\"</span><span class=\"p\">:</span> <span class=\"s2\">\"[.subtext a[href*=genres]::text]\"</span><span class=\"p\">,</span>\n      <span class=\"s2\">\"director\"</span><span class=\"p\">:</span> <span class=\"s2\">\"[h4:contains(Director) ~ a[href*=name]::text]\"</span><span class=\"p\">,</span>\n      <span class=\"s2\">\"writers\"</span><span class=\"p\">:</span> <span class=\"s2\">\"[h4:contains(Writer) ~ a[href*=name]::text]\"</span><span class=\"p\">,</span>\n      <span class=\"s2\">\"stars\"</span><span class=\"p\">:</span> <span class=\"s2\">\"[h4:contains(Star) ~ a[href*=name]::text]\"</span><span class=\"p\">,</span>\n   <span class=\"p\">}</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">IMDBCrawler</span><span class=\"p\">(</span><span class=\"n\">Crawler</span><span class=\"p\">):</span>\n   <span class=\"n\">config</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">\"MAX_REQUESTS\"</span><span class=\"p\">:</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"s2\">\"DOWNLOAD_DELAY\"</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">}</span>\n\n   <span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n      <span class=\"k\">yield</span> <span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"s2\">\"https://www.imdb.com/chart/moviemeter\"</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n\n   <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n      <span class=\"k\">yield from</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow</span><span class=\"p\">(</span>\n            <span class=\"s2\">\".lister-list tr .titleColumn a::attr(href)\"</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_movie</span>\n      <span class=\"p\">)</span>\n\n   <span class=\"k\">def</span> <span class=\"nf\">parse_movie</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n      <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url_str</span>\n      <span class=\"k\">yield</span> <span class=\"n\">MovieItem</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">sel</span><span class=\"p\">,</span> <span class=\"n\">extra</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s2\">\"url\"</span><span class=\"p\">:</span> <span class=\"n\">url</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s2\">\"?\"</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]})</span>\n\n\n<span class=\"nd\">@register</span><span class=\"p\">()</span>\n<span class=\"k\">class</span> <span class=\"nc\">HorrorHandler</span><span class=\"p\">(</span><span class=\"n\">Handler</span><span class=\"p\">):</span>\n   <span class=\"n\">family</span> <span class=\"o\">=</span> <span class=\"s2\">\"MovieItem\"</span>\n   <span class=\"n\">logger</span> <span class=\"o\">=</span> <span class=\"n\">get_logger</span><span class=\"p\">(</span><span class=\"s2\">\"horrorlog\"</span><span class=\"p\">)</span>\n\n   <span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">handle_after</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">):</span>\n      <span class=\"k\">if</span> <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s2\">\"genres\"</span><span class=\"p\">]</span> <span class=\"ow\">and</span> <span class=\"s2\">\"Horror\"</span> <span class=\"ow\">in</span> <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s2\">\"genres\"</span><span class=\"p\">]:</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">warning</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">\"(</span><span class=\"si\">{</span><span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'title'</span><span class=\"p\">]</span><span class=\"si\">}</span><span class=\"s2\">) is a horror movie!!!!\"</span><span class=\"p\">)</span>\n\n\n<span class=\"nd\">@MovieItem</span><span class=\"o\">.</span><span class=\"n\">bind</span><span class=\"p\">()</span>\n<span class=\"k\">def</span> <span class=\"nf\">process_time</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">):</span>\n   <span class=\"c1\"># a self-defined field processing function</span>\n   <span class=\"c1\"># process time to minutes</span>\n   <span class=\"c1\"># '3h 1min' -&gt; 181</span>\n   <span class=\"k\">if</span> <span class=\"n\">value</span><span class=\"p\">:</span>\n      <span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n      <span class=\"n\">segs</span> <span class=\"o\">=</span> <span class=\"n\">value</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s2\">\" \"</span><span class=\"p\">)</span>\n      <span class=\"k\">for</span> <span class=\"n\">seg</span> <span class=\"ow\">in</span> <span class=\"n\">segs</span><span class=\"p\">:</span>\n            <span class=\"k\">if</span> <span class=\"n\">seg</span><span class=\"o\">.</span><span class=\"n\">endswith</span><span class=\"p\">(</span><span class=\"s2\">\"min\"</span><span class=\"p\">):</span>\n               <span class=\"n\">res</span> <span class=\"o\">+=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">seg</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"s2\">\"min\"</span><span class=\"p\">,</span> <span class=\"s2\">\"\"</span><span class=\"p\">))</span>\n            <span class=\"k\">elif</span> <span class=\"n\">seg</span><span class=\"o\">.</span><span class=\"n\">endswith</span><span class=\"p\">(</span><span class=\"s2\">\"h\"</span><span class=\"p\">):</span>\n               <span class=\"n\">res</span> <span class=\"o\">+=</span> <span class=\"mi\">60</span> <span class=\"o\">*</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">seg</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"s2\">\"h\"</span><span class=\"p\">,</span> <span class=\"s2\">\"\"</span><span class=\"p\">))</span>\n      <span class=\"k\">return</span> <span class=\"n\">res</span>\n   <span class=\"k\">return</span> <span class=\"n\">value</span>\n\n\n<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s2\">\"__main__\"</span><span class=\"p\">:</span>\n   <span class=\"n\">IMDBCrawler</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">()</span>\n</pre>\n</div>\n<div id=\"scrape-quotes-toscrape-com\">\n<h3>Scrape quotes.toscrape.com</h3>\n<pre><span class=\"c1\"># Scrape quotes from http://quotes.toscrape.com/</span>\n<span class=\"kn\">from</span> <span class=\"nn\">acrawler</span> <span class=\"kn\">import</span> <span class=\"n\">Parser</span><span class=\"p\">,</span> <span class=\"n\">Crawler</span><span class=\"p\">,</span> <span class=\"n\">ParselItem</span><span class=\"p\">,</span> <span class=\"n\">Request</span>\n\n\n<span class=\"n\">logger</span> <span class=\"o\">=</span> <span class=\"n\">get_logger</span><span class=\"p\">(</span><span class=\"s2\">\"quotes\"</span><span class=\"p\">)</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuoteItem</span><span class=\"p\">(</span><span class=\"n\">ParselItem</span><span class=\"p\">):</span>\n   <span class=\"n\">log</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n   <span class=\"n\">default</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">\"type\"</span><span class=\"p\">:</span> <span class=\"s2\">\"quote\"</span><span class=\"p\">}</span>\n   <span class=\"n\">css</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">\"author\"</span><span class=\"p\">:</span> <span class=\"s2\">\"small.author::text\"</span><span class=\"p\">}</span>\n   <span class=\"n\">xpath</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">\"text\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'.//span[@class=\"text\"]/text()'</span><span class=\"p\">,</span> <span class=\"k\">lambda</span> <span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">s</span><span class=\"o\">.</span><span class=\"n\">strip</span><span class=\"p\">(</span><span class=\"s2\">\"\u201c\"</span><span class=\"p\">)[:</span><span class=\"mi\">20</span><span class=\"p\">]]}</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">AuthorItem</span><span class=\"p\">(</span><span class=\"n\">ParselItem</span><span class=\"p\">):</span>\n   <span class=\"n\">log</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n   <span class=\"n\">default</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">\"type\"</span><span class=\"p\">:</span> <span class=\"s2\">\"author\"</span><span class=\"p\">}</span>\n   <span class=\"n\">css</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">\"name\"</span><span class=\"p\">:</span> <span class=\"s2\">\"h3.author-title::text\"</span><span class=\"p\">,</span> <span class=\"s2\">\"born\"</span><span class=\"p\">:</span> <span class=\"s2\">\"span.author-born-date::text\"</span><span class=\"p\">}</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">QuoteCrawler</span><span class=\"p\">(</span><span class=\"n\">Crawler</span><span class=\"p\">):</span>\n\n   <span class=\"n\">main_page</span> <span class=\"o\">=</span> <span class=\"sa\">r</span><span class=\"s2\">\"quotes.toscrape.com/page/\\d+\"</span>\n   <span class=\"n\">author_page</span> <span class=\"o\">=</span> <span class=\"sa\">r</span><span class=\"s2\">\"quotes.toscrape.com/author/.*\"</span>\n   <span class=\"n\">parsers</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n      <span class=\"n\">Parser</span><span class=\"p\">(</span>\n            <span class=\"n\">in_pattern</span><span class=\"o\">=</span><span class=\"n\">main_page</span><span class=\"p\">,</span>\n            <span class=\"n\">follow_patterns</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">main_page</span><span class=\"p\">,</span> <span class=\"n\">author_page</span><span class=\"p\">],</span>\n            <span class=\"n\">item_type</span><span class=\"o\">=</span><span class=\"n\">QuoteItem</span><span class=\"p\">,</span>\n            <span class=\"n\">css_divider</span><span class=\"o\">=</span><span class=\"s2\">\".quote\"</span><span class=\"p\">,</span>\n      <span class=\"p\">),</span>\n      <span class=\"n\">Parser</span><span class=\"p\">(</span><span class=\"n\">in_pattern</span><span class=\"o\">=</span><span class=\"n\">author_page</span><span class=\"p\">,</span> <span class=\"n\">item_type</span><span class=\"o\">=</span><span class=\"n\">AuthorItem</span><span class=\"p\">),</span>\n   <span class=\"p\">]</span>\n\n   <span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n      <span class=\"k\">yield</span> <span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s2\">\"http://quotes.toscrape.com/page/1/\"</span><span class=\"p\">)</span>\n\n\n<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s2\">\"__main__\"</span><span class=\"p\">:</span>\n   <span class=\"n\">QuoteCrawler</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">()</span>\n</pre>\n<p>See <a href=\"examples/\" rel=\"nofollow\">examples</a>.</p>\n</div>\n</div>\n<div id=\"todo\">\n<h2>Todo</h2>\n<ul>\n<li>Replace parsel with parselx</li>\n<li>clean redundant handlers</li>\n<li>Cralwer\u2019s name for distinguishing</li>\n<li>Use dynaconf as configuration manager</li>\n<li>Add delta_key support for request</li>\n<li>Monitor all crawlers in web</li>\n<li>Write detailed Documentation</li>\n<li>Testing</li>\n</ul>\n</div>\n\n          </div>"}, "last_serial": 6152689, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "e1427f8880abe4c8b51659329917bb53", "sha256": "57633919a4c4b9727961a812110f54036e1f48acae102047a1ff90636ce36766"}, "downloads": -1, "filename": "acrawler-0.0.1-py3.6.egg", "has_sig": false, "md5_digest": "e1427f8880abe4c8b51659329917bb53", "packagetype": "bdist_egg", "python_version": "3.6", "requires_python": ">=3.6.0", "size": 42445, "upload_time": "2019-05-09T11:33:19", "upload_time_iso_8601": "2019-05-09T11:33:19.676357Z", "url": "https://files.pythonhosted.org/packages/18/39/c3aa20065749e98f0f902bc3e4ff570e7373140e10d5c37376ee5452a984/acrawler-0.0.1-py3.6.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "763476ffc7a2c7441137916ea7269576", "sha256": "0a3f2023408049c6e5dfd7986e45996b19626fa60c792eddc341a8b7df167305"}, "downloads": -1, "filename": "acrawler-0.0.1.tar.gz", "has_sig": false, "md5_digest": "763476ffc7a2c7441137916ea7269576", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 12525, "upload_time": "2019-05-09T11:33:21", "upload_time_iso_8601": "2019-05-09T11:33:21.945383Z", "url": "https://files.pythonhosted.org/packages/18/5a/66b9561bc1586df10c844f3736e5a93ac4cc846c936c98ba0c64a3261eaa/acrawler-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "73ed3f9c2fef122c5fe9fba84aba3fb7", "sha256": "0b6b4cae062046144a84c616bc47fbd0434826a0c3ed5192131c8a0c6e0c7cf5"}, "downloads": -1, "filename": "acrawler-0.0.2.tar.gz", "has_sig": false, "md5_digest": "73ed3f9c2fef122c5fe9fba84aba3fb7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 13108, "upload_time": "2019-05-15T05:09:28", "upload_time_iso_8601": "2019-05-15T05:09:28.130782Z", "url": "https://files.pythonhosted.org/packages/3c/2a/e5671215ca46a6c52dcee3b8df5fbb8ae1bfc0e6ceef3ff1ac489ce8b6b1/acrawler-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "271e4b445564312f253b7afdc031a5c7", "sha256": "1668a40dfa627cb8637aa734ca6bce7a5b8e90cbcbd4807279a33333181a12a6"}, "downloads": -1, "filename": "acrawler-0.0.3.tar.gz", "has_sig": false, "md5_digest": "271e4b445564312f253b7afdc031a5c7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 14726, "upload_time": "2019-05-18T13:38:11", "upload_time_iso_8601": "2019-05-18T13:38:11.508568Z", "url": "https://files.pythonhosted.org/packages/ba/04/3756feab81c212e07ca0187b22d4256fc70bcb108fe565dba7f9e8984d60/acrawler-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "de50c642c28b5a205f1cb7e2bb26fe74", "sha256": "be14004d7af54d8d4005810d2b5a61f89a6c16c4670c5530f022ccbffd419757"}, "downloads": -1, "filename": "acrawler-0.0.4.tar.gz", "has_sig": false, "md5_digest": "de50c642c28b5a205f1cb7e2bb26fe74", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 17082, "upload_time": "2019-05-20T05:04:03", "upload_time_iso_8601": "2019-05-20T05:04:03.394071Z", "url": "https://files.pythonhosted.org/packages/b9/c7/f67ce556913396f972f1b64e59aa221f6e7030c5291b29bc5ed34f12e4c8/acrawler-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "db875db2a96aee5208abbca8789ff493", "sha256": "b2c17426209f6edc93d8c6240d1b3d1fd6570c25e7ec3ef8ada98ef7cd89684b"}, "downloads": -1, "filename": "acrawler-0.0.5.tar.gz", "has_sig": false, "md5_digest": "db875db2a96aee5208abbca8789ff493", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 17940, "upload_time": "2019-05-21T01:53:46", "upload_time_iso_8601": "2019-05-21T01:53:46.877304Z", "url": "https://files.pythonhosted.org/packages/78/07/031e7c257e34bbf208d12e29cb9bd5f0e393a67bd629acaaa84d0104556f/acrawler-0.0.5.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "36784ebbc8e005dd5b3411d2107cc966", "sha256": "18c425d7ba3f40908e87d33b0a3c9b7ab6f773c74249cb1cda0a279bbae0c09d"}, "downloads": -1, "filename": "acrawler-0.0.6.tar.gz", "has_sig": false, "md5_digest": "36784ebbc8e005dd5b3411d2107cc966", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 20616, "upload_time": "2019-05-27T13:10:07", "upload_time_iso_8601": "2019-05-27T13:10:07.305981Z", "url": "https://files.pythonhosted.org/packages/32/82/2355db01960e5cf0d32d54d569a3719faca8d2198718e2358f4c0c1f98f1/acrawler-0.0.6.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "897ec46e4f6671594e59256dd9ee2d7d", "sha256": "b4344187ca2eb5aa0bca5fc87430b5157ebea2d73ec19ce6745fa7cd7c96d15a"}, "downloads": -1, "filename": "acrawler-0.0.7.tar.gz", "has_sig": false, "md5_digest": "897ec46e4f6671594e59256dd9ee2d7d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 23916, "upload_time": "2019-06-04T16:45:25", "upload_time_iso_8601": "2019-06-04T16:45:25.061066Z", "url": "https://files.pythonhosted.org/packages/40/08/6319c2bd806a283808fc5264080cf367861d2297999817e7f1fd7bccd7b5/acrawler-0.0.7.tar.gz", "yanked": false}], "0.0.8": [{"comment_text": "", "digests": {"md5": "c42f843bdc4e4d5c1411e5fab358700f", "sha256": "7bde5175a8076007f09ed6c0cad0fbb9eaba768746884203b87edc67bde2b325"}, "downloads": -1, "filename": "acrawler-0.0.8.tar.gz", "has_sig": false, "md5_digest": "c42f843bdc4e4d5c1411e5fab358700f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 26262, "upload_time": "2019-07-02T05:00:03", "upload_time_iso_8601": "2019-07-02T05:00:03.277317Z", "url": "https://files.pythonhosted.org/packages/8f/ab/882ac59b458a9c5c48d907a94291e6af28a55a1111037cb27e64076747a2/acrawler-0.0.8.tar.gz", "yanked": false}], "0.0.9": [{"comment_text": "", "digests": {"md5": "b74a5f932b8cf79026bdf3d03996d491", "sha256": "1205be9685f5cf06de5220ef24e1a981e09ffd2f652311e838a6df3105324ee1"}, "downloads": -1, "filename": "acrawler-0.0.9.tar.gz", "has_sig": false, "md5_digest": "b74a5f932b8cf79026bdf3d03996d491", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 31055, "upload_time": "2019-07-28T01:59:00", "upload_time_iso_8601": "2019-07-28T01:59:00.595784Z", "url": "https://files.pythonhosted.org/packages/e5/55/d8464e912b74c0908c30b48d713fdd4dc811d05ee59a846ce5e1258d6c7d/acrawler-0.0.9.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "f8051d89314a48346a0a875ba683fd01", "sha256": "b5849835f8ee22daece371ae500b465ae5878529c01fc8598be38d82ea7661bb"}, "downloads": -1, "filename": "acrawler-0.1.0-py3.6.egg", "has_sig": false, "md5_digest": "f8051d89314a48346a0a875ba683fd01", "packagetype": "bdist_egg", "python_version": "3.6", "requires_python": ">=3.6.0", "size": 88396, "upload_time": "2019-08-23T12:53:34", "upload_time_iso_8601": "2019-08-23T12:53:34.481689Z", "url": "https://files.pythonhosted.org/packages/6e/82/f55ccb5c4c9d707dc9bf5d5764e3a4e507bad3618695782889039326021a/acrawler-0.1.0-py3.6.egg", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "4b23a3071002704a70decb847bdcb08f", "sha256": "02ee6f49406f34bb573b5e06b92c64272f395ee242e692dc356513116643ad55"}, "downloads": -1, "filename": "acrawler-0.1.1.tar.gz", "has_sig": false, "md5_digest": "4b23a3071002704a70decb847bdcb08f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 32376, "upload_time": "2019-08-23T23:44:36", "upload_time_iso_8601": "2019-08-23T23:44:36.823342Z", "url": "https://files.pythonhosted.org/packages/5b/3d/ef3a07b081c511c7161ca73e28239748c0b30520d0c6e4308d7b6077a685/acrawler-0.1.1.tar.gz", "yanked": false}], "0.1.2a0": [{"comment_text": "", "digests": {"md5": "18ac0a28f04911dc112cfee8254ea69f", "sha256": "a748dd582cf0ac6436beadf8fe2123229fe3ae47a24ae7b4491486868ec4ca5d"}, "downloads": -1, "filename": "acrawler-0.1.2a0.tar.gz", "has_sig": false, "md5_digest": "18ac0a28f04911dc112cfee8254ea69f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 32364, "upload_time": "2019-08-24T00:34:54", "upload_time_iso_8601": "2019-08-24T00:34:54.538380Z", "url": "https://files.pythonhosted.org/packages/b2/dd/bd4f4ddb5d3375e1f8d194689dd0eff463a759479304ab94ddb3eb5a5c73/acrawler-0.1.2a0.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "b9f6b2a7a7423f179e57f91bf38e0547", "sha256": "d5a5b0244ad567336cea665275db464ad2a22c2e843e772b0956d18b20270dc7"}, "downloads": -1, "filename": "acrawler-0.1.3.tar.gz", "has_sig": false, "md5_digest": "b9f6b2a7a7423f179e57f91bf38e0547", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 32372, "upload_time": "2019-08-24T00:39:03", "upload_time_iso_8601": "2019-08-24T00:39:03.971686Z", "url": "https://files.pythonhosted.org/packages/e0/63/15471255b49d989a23b3fa7c9ffd42772d4cb52de2e286135ec04ac7b7e6/acrawler-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "fcd5b2d2cb8ea02f688a02b6f3cafd71", "sha256": "acceeea2e613bdc5798b995af1b791e4ca51389f575546e694ebcae7bbee858b"}, "downloads": -1, "filename": "acrawler-0.1.4.tar.gz", "has_sig": false, "md5_digest": "fcd5b2d2cb8ea02f688a02b6f3cafd71", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 32249, "upload_time": "2019-09-17T08:41:00", "upload_time_iso_8601": "2019-09-17T08:41:00.532638Z", "url": "https://files.pythonhosted.org/packages/64/60/5a35bf86254b76ba516d864d9aef9cbacab9fe589cf499f6aa1b39b12694/acrawler-0.1.4.tar.gz", "yanked": false}], "0.1.5": [{"comment_text": "", "digests": {"md5": "7465729ccee573d962206e4267c4cafd", "sha256": "64376e21b8afb8808b3a557e80aa9efe1ed23a31372c1eefe415c634f9f06e5a"}, "downloads": -1, "filename": "acrawler-0.1.5.tar.gz", "has_sig": false, "md5_digest": "7465729ccee573d962206e4267c4cafd", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 35392, "upload_time": "2019-11-07T14:19:42", "upload_time_iso_8601": "2019-11-07T14:19:42.706756Z", "url": "https://files.pythonhosted.org/packages/15/8d/3de82a756ea1aa3213a2358f3391c1292cf71ee2cb31ed3d894951f8e447/acrawler-0.1.5.tar.gz", "yanked": false}], "0.1.6": [{"comment_text": "", "digests": {"md5": "227654f5656c81c5ca962f6a30716337", "sha256": "d4e84995dea10f9712e83ced38075a4348e178131617f3ac4d5a0b5d9d20d5f8"}, "downloads": -1, "filename": "acrawler-0.1.6.tar.gz", "has_sig": false, "md5_digest": "227654f5656c81c5ca962f6a30716337", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 34912, "upload_time": "2019-11-18T02:01:37", "upload_time_iso_8601": "2019-11-18T02:01:37.159081Z", "url": "https://files.pythonhosted.org/packages/03/5f/2cbe817db7c6faaeae1dd51bec7498af0192dac56b37f53da960848dfbc6/acrawler-0.1.6.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "227654f5656c81c5ca962f6a30716337", "sha256": "d4e84995dea10f9712e83ced38075a4348e178131617f3ac4d5a0b5d9d20d5f8"}, "downloads": -1, "filename": "acrawler-0.1.6.tar.gz", "has_sig": false, "md5_digest": "227654f5656c81c5ca962f6a30716337", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 34912, "upload_time": "2019-11-18T02:01:37", "upload_time_iso_8601": "2019-11-18T02:01:37.159081Z", "url": "https://files.pythonhosted.org/packages/03/5f/2cbe817db7c6faaeae1dd51bec7498af0192dac56b37f53da960848dfbc6/acrawler-0.1.6.tar.gz", "yanked": false}], "timestamp": "Thu May  7 16:24:27 2020"}