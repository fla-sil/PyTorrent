{"info": {"author": "Explosion", "author_email": "contact@explosion.ai", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Environment :: Console", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Operating System :: MacOS :: MacOS X", "Operating System :: Microsoft :: Windows", "Operating System :: POSIX :: Linux", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8", "Topic :: Scientific/Engineering"], "description": "<a href=\"https://explosion.ai\"><img src=\"https://explosion.ai/assets/img/logo.svg\" width=\"125\" height=\"125\" align=\"right\" /></a>\n\n# sense2vec: Contextually-keyed word vectors\n\nsense2vec ([Trask et. al](https://arxiv.org/abs/1511.06388), 2015) is a nice\ntwist on [word2vec](https://en.wikipedia.org/wiki/Word2vec) that lets you learn\nmore interesting and detailed word vectors. This library is a simple Python\nimplementation for loading, querying and training sense2vec models. For more\ndetails, check out\n[our blog post](https://explosion.ai/blog/sense2vec-reloaded). To explore the\nsemantic similarities across all Reddit comments of 2015 and 2019, see the\n[interactive demo](https://demos.explosion.ai/sense2vec).\n\n\ud83e\udd86 **Version 1.0 out now!**\n[Read the release notes here.](https://github.com/explosion/sense2vec/releases/)\n\n[![Azure Pipelines](https://img.shields.io/azure-devops/build/explosion-ai/public/12/master.svg?logo=azure-pipelines&style=flat-square&label=build)](https://dev.azure.com/explosion-ai/public/_build?definitionId=12)\n[![Current Release Version](https://img.shields.io/github/v/release/explosion/sense2vec.svg?style=flat-square&logo=github)](https://github.com/explosion/sense2vec/releases)\n[![pypi Version](https://img.shields.io/pypi/v/sense2vec.svg?style=flat-square&logo=pypi&logoColor=white)](https://pypi.org/project/sense2vec/)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg?style=flat-square)](https://github.com/ambv/black)\n\n## \u2728 Features\n\n![](https://user-images.githubusercontent.com/13643239/69330759-d3981600-0c53-11ea-8f64-e5c075f7ea10.jpg)\n\n- Query **vectors for multi-word phrases** based on part-of-speech tags and\n  entity labels.\n- spaCy **pipeline component** and **extension attributes**.\n- Fully **serializable** so you can easily ship your sense2vec vectors with your\n  spaCy model packages.\n- Optional **caching of nearest neighbors** for super fast \"most similar\"\n  queries.\n- **Train your own vectors** using a pretrained spaCy model, raw text and\n  [GloVe](https://github.com/stanfordnlp/GloVe) or Word2Vec via\n  [fastText](https://github.com/facebookresearch/fastText)\n  ([details](#-training-your-own-sense2vec-vectors)).\n- [Prodigy](https://prodi.gy) **annotation recipes** for evaluating models,\n  creating lists of similar multi-word phrases and converting them to match\n  patterns, e.g. for rule-based NER or to boostrap NER annotation\n  ([details & examples](#-prodigy-recipes)).\n\n## \ud83d\ude80 Quickstart\n\n### Standalone usage\n\n```python\nfrom sense2vec import Sense2Vec\n\ns2v = Sense2Vec().from_disk(\"/path/to/s2v_reddit_2015_md\")\nquery = \"natural_language_processing|NOUN\"\nassert query in s2v\nvector = s2v[query]\nfreq = s2v.get_freq(query)\nmost_similar = s2v.most_similar(query, n=3)\n# [('machine_learning|NOUN', 0.8986967),\n#  ('computer_vision|NOUN', 0.8636297),\n#  ('deep_learning|NOUN', 0.8573361)]\n```\n\n### Usage as a spaCy pipeline component\n\n```python\nimport spacy\nfrom sense2vec import Sense2VecComponent\n\nnlp = spacy.load(\"en_core_web_sm\")\ns2v = Sense2VecComponent(nlp.vocab).from_disk(\"/path/to/s2v_reddit_2015_md\")\nnlp.add_pipe(s2v)\n\ndoc = nlp(\"A sentence about natural language processing.\")\nassert doc[3:6].text == \"natural language processing\"\nfreq = doc[3:6]._.s2v_freq\nvector = doc[3:6]._.s2v_vec\nmost_similar = doc[3:6]._.s2v_most_similar(3)\n# [(('machine learning', 'NOUN'), 0.8986967),\n#  (('computer vision', 'NOUN'), 0.8636297),\n#  (('deep learning', 'NOUN'), 0.8573361)]\n```\n\n### Interactive demos\n\n<img width=\"34%\" src=\"https://user-images.githubusercontent.com/13643239/68093565-1bb6ea80-fe97-11e9-8192-e293acc290fe.png\" align=\"right\" />\n\nTo try out our pretrained vectors trained on Reddit comments, check out the\n[interactive sense2vec demo](https://explosion.ai/demos/sense2vec).\n\nThis repo also includes a [Streamlit](https://streamlit.io) demo script for\nexploring vectors and the most similar phrases. After installing `streamlit`,\nyou can run the script with `streamlit run` and **one or more paths to\npretrained vectors** as **positional arguments** on the command line. For\nexample:\n\n```bash\npip install streamlit\nstreamlit run https://raw.githubusercontent.com/explosion/sense2vec/master/scripts/streamlit_sense2vec.py /path/to/vectors\n```\n\n### Pretrained vectors\n\nTo use the vectors, download the archive(s) and pass the extracted directory to\n`Sense2Vec.from_disk` or `Sense2VecComponent.from_disk`. The vector files are\n**attached to the GitHub release**. Large files have been split into multi-part\ndownloads.\n\n| Vectors              |   Size | Description                  | \ud83d\udce5 Download (zipped)                                                                                                                                                                                                                                                                                                      |\n| -------------------- | -----: | ---------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `s2v_reddit_2019_lg` |   4 GB | Reddit comments 2019 (01-07) | [part 1](https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2019_lg.tar.gz.001), [part 2](https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2019_lg.tar.gz.002), [part 3](https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2019_lg.tar.gz.003) |\n| `s2v_reddit_2015_md` | 573 MB | Reddit comments 2015         | [part 1](https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz)                                                                                                                                                                                                                       |\n\nTo merge the multi-part archives, you can run the following:\n\n```bash\ncat s2v_reddit_2019_lg.tar.gz.* > s2v_reddit_2019_lg.tar.gz\n```\n\n## \u23f3 Installation & Setup\n\nsense2vec releases are available on pip:\n\n```bash\npip install sense2vec\n```\n\nTo use pretrained vectors, download\n[one of the vector packages](#pretrained-vectors), unpack the `.tar.gz` archive\nand point `from_disk` to the extracted data directory:\n\n```python\nfrom sense2vec import Sense2Vec\ns2v = Sense2Vec().from_disk(\"/path/to/s2v_reddit_2015_md\")\n```\n\n## \ud83d\udc69\u200d\ud83d\udcbb Usage\n\n### Usage with spaCy v2.2+\n\nThe easiest way to use the library and vectors is to plug it into your spaCy\npipeline. The `sense2vec` package exposes a `Sense2VecComponent`, which can be\ninitialised with the shared vocab and added to your spaCy pipeline as a\n[custom pipeline component](https://spacy.io/usage/processing-pipelines#custom-components).\nBy default, components are added to the _end of the pipeline_, which is the\nrecommended position for this component, since it needs access to the dependency\nparse and, if available, named entities.\n\n```python\nimport spacy\nfrom sense2vec import Sense2VecComponent\n\nnlp = spacy.load(\"en_core_web_sm\")\ns2v = Sense2VecComponent(nlp.vocab).from_disk(\"/path/to/s2v_reddit_2015_md\")\nnlp.add_pipe(s2v)\n```\n\nThe component will add serveral\n[extension attributes and methods](https://spacy.io/usage/processing-pipelines#custom-components-attributes)\nto spaCy's `Token` and `Span` objects that let you retrieve vectors and\nfrequencies, as well as most similar terms.\n\n```python\ndoc = nlp(\"A sentence about natural language processing.\")\nassert doc[3:6].text == \"natural language processing\"\nfreq = doc[3:6]._.s2v_freq\nvector = doc[3:6]._.s2v_vec\nmost_similar = doc[3:6]._.s2v_most_similar(3)\n```\n\nFor entities, the entity labels are used as the \"sense\" (instead of the token's\npart-of-speech tag):\n\n```python\ndoc = nlp(\"A sentence about Facebook and Google.\")\nfor ent in doc.ents:\n    assert ent._.in_s2v\n    most_similar = ent._.s2v_most_similar(3)\n```\n\n#### Available attributes\n\nThe following extension attributes are exposed on the `Doc` object via the `._`\nproperty:\n\n| Name          | Attribute Type | Type | Description                                                                         |\n| ------------- | -------------- | ---- | ----------------------------------------------------------------------------------- |\n| `s2v_phrases` | property       | list | All sense2vec-compatible phrases in the given `Doc` (noun phrases, named entities). |\n\nThe following attributes are available via the `._` property of `Token` and\n`Span` objects \u2013 for example `token._.in_s2v`:\n\n| Name               | Attribute Type | Return Type        | Description                                                                        |\n| ------------------ | -------------- | ------------------ | ---------------------------------------------------------------------------------- |\n| `in_s2v`           | property       | bool               | Whether a key exists in the vector map.                                            |\n| `s2v_key`          | property       | unicode            | The sense2vec key of the given object, e.g. `\"duck|NOUN\"`.                         |\n| `s2v_vec`          | property       | `ndarray[float32]` | The vector of the given key.                                                       |\n| `s2v_freq`         | property       | int                | The frequency of the given key.                                                    |\n| `s2v_other_senses` | property       | list               | Available other senses, e.g. `\"duck|VERB\"` for `\"duck|NOUN\"`.                      |\n| `s2v_most_similar` | method         | list               | Get the `n` most similar terms. Returns a list of `((word, sense), score)` tuples. |\n| `s2v_similarity`   | method         | float              | Get the similarity to another `Token` or `Span`.                                   |\n\n> \u26a0\ufe0f **A note on span attributes:** Under the hood, entities in `doc.ents` are\n> `Span` objects. This is why the pipeline component also adds attributes and\n> methods to spans and not just tokens. However, it's not recommended to use the\n> sense2vec attributes on arbitrary slices of the document, since the model\n> likely won't have a key for the respective text. `Span` objects also don't\n> have a part-of-speech tag, so if no entity label is present, the \"sense\"\n> defaults to the root's part-of-speech tag.\n\n### Standalone usage\n\nYou can also use the underlying `Sense2Vec` class directly and load in the\nvectors using the `from_disk` method. See below for the available API methods.\n\n```python\nfrom sense2vec import Sense2Vec\ns2v = Sense2Vec().from_disk(\"/path/to/reddit_vectors-1.1.0\")\nmost_similar = s2v.most_similar(\"natural_language_processing|NOUN\", n=10)\n```\n\n> \u26a0\ufe0f **Important note:** To look up entries in the vectors table, the keys need\n> to follow the scheme of `phrase_text|SENSE` (note the `_` instead of spaces\n> and the `|` before the tag or label) \u2013 for example, `machine_learning|NOUN`.\n> Also note that the underlying vector table is case-sensitive.\n\n## \ud83c\udf9b API\n\n### <kbd>class</kbd> `Sense2Vec`\n\nThe standalone `Sense2Vec` object that holds the vectors, strings and\nfrequencies.\n\n#### <kbd>method</kbd> `Sense2Vec.__init__`\n\nInitialize the `Sense2Vec` object.\n\n| Argument       | Type                        | Description                                                                                                            |\n| -------------- | --------------------------- | ---------------------------------------------------------------------------------------------------------------------- |\n| `shape`        | tuple                       | The vector shape. Defaults to `(1000, 128)`.                                                                           |\n| `strings`      | `spacy.strings.StringStore` | Optional string store. Will be created if it doesn't exist.                                                            |\n| `senses`       | list                        | Optional list of all available senses. Used in methods that generate the best sense or other senses.                   |\n| `vectors_name` | unicode                     | Optional name to assign to the `Vectors` table, to prevent clashes. Defaults to `\"sense2vec\"`.                         |\n| `overrides`    | dict                        | Optional custom functions to use, mapped to names registered via the registry, e.g. `{\"make_key\": \"custom_make_key\"}`. |\n| **RETURNS**    | `Sense2Vec`                 | The newly constructed object.                                                                                          |\n\n```python\ns2v = Sense2Vec(shape=(300, 128), senses=[\"VERB\", \"NOUN\"])\n```\n\n#### <kbd>method</kbd> `Sense2Vec.__len__`\n\nThe number of rows in the vectors table.\n\n| Argument    | Type | Description                              |\n| ----------- | ---- | ---------------------------------------- |\n| **RETURNS** | int  | The number of rows in the vectors table. |\n\n```python\ns2v = Sense2Vec(shape=(300, 128))\nassert len(s2v) == 300\n```\n\n#### <kbd>method</kbd> `Sense2Vec.__contains__`\n\nCheck if a key is in the vectors table.\n\n| Argument    | Type          | Description                      |\n| ----------- | ------------- | -------------------------------- |\n| `key`       | unicode / int | The key to look up.              |\n| **RETURNS** | bool          | Whether the key is in the table. |\n\n```python\ns2v = Sense2Vec(shape=(10, 4))\ns2v.add(\"avocado|NOUN\", numpy.asarray([4, 2, 2, 2], dtype=numpy.float32))\nassert \"avocado|NOUN\" in s2v\nassert \"avocado|VERB\" not in s2v\n```\n\n#### <kbd>method</kbd> `Sense2Vec.__getitem__`\n\nRetrieve a vector for a given key. Returns None if the key is not in the table.\n\n| Argument    | Type            | Description           |\n| ----------- | --------------- | --------------------- |\n| `key`       | unicode / int   | The key to look up.   |\n| **RETURNS** | `numpy.ndarray` | The vector or `None`. |\n\n```python\nvec = s2v[\"avocado|NOUN\"]\n```\n\n#### <kbd>method</kbd> `Sense2Vec.__setitem__`\n\nSet a vector for a given key. Will raise an error if the key doesn't exist. To\nadd a new entry, use `Sense2Vec.add`.\n\n| Argument | Type            | Description        |\n| -------- | --------------- | ------------------ |\n| `key`    | unicode / int   | The key.           |\n| `vector` | `numpy.ndarray` | The vector to set. |\n\n```python\nvec = s2v[\"avocado|NOUN\"]\ns2v[\"avacado|NOUN\"] = vec\n```\n\n#### <kbd>method</kbd> `Sense2Vec.add`\n\nAdd a new vector to the table.\n\n| Argument | Type            | Description                                                  |\n| -------- | --------------- | ------------------------------------------------------------ |\n| `key`    | unicode / int   | The key to add.                                              |\n| `vector` | `numpy.ndarray` | The vector to add.                                           |\n| `freq`   | int             | Optional frequency count. Used to find best matching senses. |\n\n```python\nvec = s2v[\"avocado|NOUN\"]\ns2v.add(\"\ud83e\udd51|NOUN\", vec, 1234)\n```\n\n#### <kbd>method</kbd> `Sense2Vec.get_freq`\n\nGet the frequency count for a given key.\n\n| Argument    | Type          | Description                                       |\n| ----------- | ------------- | ------------------------------------------------- |\n| `key`       | unicode / int | The key to look up.                               |\n| `default`   | -             | Default value to return if no frequency is found. |\n| **RETURNS** | int           | The frequency count.                              |\n\n```python\nvec = s2v[\"avocado|NOUN\"]\ns2v.add(\"\ud83e\udd51|NOUN\", vec, 1234)\nassert s2v.get_freq(\"\ud83e\udd51|NOUN\") == 1234\n```\n\n#### <kbd>method</kbd> `Sense2Vec.set_freq`\n\nSet a frequency count for a given key.\n\n| Argument | Type          | Description                   |\n| -------- | ------------- | ----------------------------- |\n| `key`    | unicode / int | The key to set the count for. |\n| `freq`   | int           | The frequency count.          |\n\n```python\ns2v.set_freq(\"avocado|NOUN\", 104294)\n```\n\n#### <kbd>method</kbd> `Sense2Vec.__iter__`, `Sense2Vec.items`\n\nIterate over the entries in the vectors table.\n\n| Argument   | Type  | Description                               |\n| ---------- | ----- | ----------------------------------------- |\n| **YIELDS** | tuple | String key and vector pairs in the table. |\n\n```python\nfor key, vec in s2v:\n    print(key, vec)\n\nfor key, vec in s2v.items():\n    print(key, vec)\n```\n\n#### <kbd>method</kbd> `Sense2Vec.keys`\n\nIterate over the keys in the table.\n\n| Argument   | Type    | Description                   |\n| ---------- | ------- | ----------------------------- |\n| **YIELDS** | unicode | The string keys in the table. |\n\n```python\nall_keys = list(s2v.keys())\n```\n\n#### <kbd>method</kbd> `Sense2Vec.values`\n\nIterate over the vectors in the table.\n\n| Argument   | Type            | Description               |\n| ---------- | --------------- | ------------------------- |\n| **YIELDS** | `numpy.ndarray` | The vectors in the table. |\n\n```python\nall_vecs = list(s2v.values())\n```\n\n#### <kbd>property</kbd> `Sense2Vec.senses`\n\nThe available senses in the table, e.g. `\"NOUN\"` or `\"VERB\"` (added at\ninitialization).\n\n| Argument    | Type | Description           |\n| ----------- | ---- | --------------------- |\n| **RETURNS** | list | The available senses. |\n\n```python\ns2v = Sense2Vec(senses=[\"VERB\", \"NOUN\"])\nassert \"VERB\" in s2v.senses\n```\n\n#### <kbd>property</kbd> `Sense2vec.frequencies`\n\nThe frequencies of they keys in the table, in descending order.\n\n| Argument    | Type | Description                                        |\n| ----------- | ---- | -------------------------------------------------- |\n| **RETURNS** | list | The `(key, freq)` tuples by frequency, descending. |\n\n```python\nmost_frequent = s2v.frequencies[:10]\nkey, score = s2v.frequencies[0]\n```\n\n#### <kbd>method</kbd> `Sense2vec.similarity`\n\nMake a semantic similarity estimate of two keys or two sets of keys. The default\nestimate is cosine similarity using an average of vectors.\n\n| Argument    | Type                     | Description                         |\n| ----------- | ------------------------ | ----------------------------------- |\n| `keys_a`    | unicode / int / iterable | The string or integer key(s).       |\n| `keys_b`    | unicode / int / iterable | The other string or integer key(s). |\n| **RETURNS** | float                    | The similarity score.               |\n\n```python\nkeys_a = [\"machine_learning|NOUN\", \"natural_language_processing|NOUN\"]\nkeys_b = [\"computer_vision|NOUN\", \"object_detection|NOUN\"]\nprint(s2v.similarity(keys_a, keys_b))\nassert s2v.similarity(\"machine_learning|NOUN\", \"machine_learning|NOUN\") == 1.0\n```\n\n#### <kbd>method</kbd> `Sense2Vec.most_similar`\n\nGet the most similar entries in the table. If more than one key is provided, the\naverage of the vectors is used. To make this method faster, see the\n[script for precomputing a cache](scripts/06_precompute_cache.py) of the nearest\nneighbors.\n\n| Argument     | Type                      | Description                                             |\n| ------------ | ------------------------- | ------------------------------------------------------- |\n| `keys`       | unicode / int / iterable\u00a0 | The string or integer key(s) to compare to.             |\n| `n`          | int                       | The number of similar keys to return. Defaults to `10`. |\n| `batch_size` | int                       | The batch size to use. Defaults to `16`.                |\n| **RETURNS**  | list                      | The `(key, score)` tuples of the most similar vectors.  |\n\n```python\nmost_similar = s2v.most_similar(\"natural_language_processing|NOUN\", n=3)\n# [('machine_learning|NOUN', 0.8986967),\n#  ('computer_vision|NOUN', 0.8636297),\n#  ('deep_learning|NOUN', 0.8573361)]\n```\n\n#### <kbd>method</kbd> `Sense2Vec.get_other_senses`\n\nFind other entries for the same word with a different sense, e.g. `\"duck|VERB\"`\nfor `\"duck|NOUN\"`.\n\n| Argument      | Type          | Description                                                       |\n| ------------- | ------------- | ----------------------------------------------------------------- |\n| `key`         | unicode / int | The key to check.                                                 |\n| `ignore_case` | bool          | Check for uppercase, lowercase and titlecase. Defaults to `True`. |\n| **RETURNS**   | list          | The string keys of other entries with different senses.           |\n\n```python\nother_senses = s2v.get_other_senses(\"duck|NOUN\")\n# ['duck|VERB', 'Duck|ORG', 'Duck|VERB', 'Duck|PERSON', 'Duck|ADJ']\n```\n\n#### <kbd>method</kbd> `Sense2Vec.get_best_sense`\n\nFind the best-matching sense for a given word based on the available senses and\nfrequency counts. Returns `None` if no match is found.\n\n| Argument      | Type    | Description                                                                                             |\n| ------------- | ------- | ------------------------------------------------------------------------------------------------------- |\n| `word`        | unicode | The word to check.                                                                                      |\n| `senses`      | list    | Optional list of senses to limit the search to. If not set / empty, all senses in the vectors are used. |\n| `ignore_case` | bool    | Check for uppercase, lowercase and titlecase. Defaults to `True`.                                       |\n| **RETURNS**   | unicode | The best-matching key or None.                                                                          |\n\n```python\nassert s2v.get_best_sense(\"duck\") == \"duck|NOUN\"\nassert s2v.get_best_sense(\"duck\", [\"VERB\", \"ADJ\"]) == \"duck|VERB\"\n```\n\n#### <kbd>method</kbd> `Sense2Vec.to_bytes`\n\nSerialize a `Sense2Vec` object to a bytestring.\n\n| Argument    | Type  | Description                               |\n| ----------- | ----- | ----------------------------------------- |\n| `exclude`   | list  | Names of serialization fields to exclude. |\n| **RETURNS** | bytes | The serialized `Sense2Vec` object.        |\n\n```python\ns2v_bytes = s2v.to_bytes()\n```\n\n#### <kbd>method</kbd> `Sense2Vec.from_bytes`\n\nLoad a `Sense2Vec` object from a bytestring.\n\n| Argument     | Type        | Description                               |\n| ------------ | ----------- | ----------------------------------------- |\n| `bytes_data` | bytes       | The data to load.                         |\n| `exclude`    | list        | Names of serialization fields to exclude. |\n| **RETURNS**  | `Sense2Vec` | The loaded object.                        |\n\n```python\ns2v_bytes = s2v.to_bytes()\nnew_s2v = Sense2Vec().from_bytes(s2v_bytes)\n```\n\n#### <kbd>method</kbd> `Sense2Vec.to_disk`\n\nSerialize a `Sense2Vec` object to a directory.\n\n| Argument  | Type             | Description                               |\n| --------- | ---------------- | ----------------------------------------- |\n| `path`    | unicode / `Path` | The path.                                 |\n| `exclude` | list             | Names of serialization fields to exclude. |\n\n```python\ns2v.to_disk(\"/path/to/sense2vec\")\n```\n\n#### <kbd>method</kbd> `Sense2Vec.from_disk`\n\nLoad a `Sense2Vec` object from a directory.\n\n| Argument    | Type             | Description                               |\n| ----------- | ---------------- | ----------------------------------------- |\n| `path`      | unicode / `Path` | The path to load from                     |\n| `exclude`   | list             | Names of serialization fields to exclude. |\n| **RETURNS** | `Sense2Vec`      | The loaded object.                        |\n\n```python\ns2v.to_disk(\"/path/to/sense2vec\")\nnew_s2v = Sense2Vec().from_disk(\"/path/to/sense2vec\")\n```\n\n---\n\n### <kbd>class</kbd> `Sense2VecComponent`\n\nThe pipeline component to add sense2vec to spaCy pipelines.\n\n#### <kbd>method</kbd> `Sense2VecComponent.__init__`\n\nInitialize the pipeline component.\n\n| Argument        | Type                                                                                                                  | Description                                                                                                 |\n| --------------- | --------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------- |\n| `vocab`         | `Vocab`                                                                                                               | The shared `Vocab`. Mostly used for the shared `StringStore`.                                               |\n| `shape`         | tuple                                                                                                                 | The vector shape.                                                                                           |\n| `merge_phrases` | bool                                                                                                                  | Whether to merge sense2vec phrases into one token. Defaults to `False`.                                     |\n| `lemmatize`     | bool                                                                                                                  | Always look up lemmas if available in the vectors, otherwise default to original word. Defaults to `False`. |\n| `overrides`     | Optional custom functions to use, mapped to names registred via the registry, e.g. `{\"make_key\": \"custom_make_key\"}`. |\n| **RETURNS**     | `Sense2VecComponent`                                                                                                  | The newly constructed object.                                                                               |\n\n```python\ns2v = Sense2VecComponent(nlp.vocab)\n```\n\n#### <kbd>classmethod</kbd> `Sense2VecComponent.from_nlp`\n\nInitialize the component from an nlp object. Mostly used as the component\nfactory for the entry point (see setup.cfg) and to auto-register via the\n`@spacy.component` decorator.\n\n| Argument    | Type                 | Description                   |\n| ----------- | -------------------- | ----------------------------- |\n| `nlp`       | `Language`           | The `nlp` object.             |\n| `**cfg`     | -                    | Optional config parameters.   |\n| **RETURNS** | `Sense2VecComponent` | The newly constructed object. |\n\n```python\ns2v = Sense2VecComponent.from_nlp(nlp)\n```\n\n#### <kbd>method</kbd> `Sense2VecComponent.__call__`\n\nProcess a `Doc` object with the component. Typically only called as part of the\nspaCy pipeline and not directly.\n\n| Argument    | Type  | Description              |\n| ----------- | ----- | ------------------------ |\n| `doc`       | `Doc` | The document to process. |\n| **RETURNS** | `Doc` | the processed document.  |\n\n#### <kbd>method</kbd> `Sense2Vec.init_component`\n\nRegister the component-specific extension attributes here and only if the\ncomponent is added to the pipeline and used \u2013 otherwise, tokens will still get\nthe attributes even if the component is only created and not added.\n\n#### <kbd>method</kbd> `Sense2VecComponent.to_bytes`\n\nSerialize the component to a bytestring. Also called when the component is added\nto the pipeline and you run `nlp.to_bytes`.\n\n| Argument    | Type  | Description               |\n| ----------- | ----- | ------------------------- |\n| **RETURNS** | bytes | The serialized component. |\n\n#### <kbd>method</kbd> `Sense2VecComponent.from_bytes`\n\nLoad a component from a bytestring. Also called when you run `nlp.from_bytes`.\n\n| Argument     | Type                 | Description        |\n| ------------ | -------------------- | ------------------ |\n| `bytes_data` | bytes                | The data to load.  |\n| **RETURNS**  | `Sense2VecComponent` | The loaded object. |\n\n#### <kbd>method</kbd> `Sense2VecComponent.to_disk`\n\nSerialize the component to a directory. Also called when the component is added\nto the pipeline and you run `nlp.to_disk`.\n\n| Argument | Type             | Description |\n| -------- | ---------------- | ----------- |\n| `path`   | unicode / `Path` | The path.   |\n\n#### <kbd>method</kbd> `Sense2VecComponent.from_disk`\n\nLoad a `Sense2Vec` object from a directory. Also called when you run\n`nlp.from_disk`.\n\n| Argument    | Type                 | Description           |\n| ----------- | -------------------- | --------------------- |\n| `path`      | unicode / `Path`     | The path to load from |\n| **RETURNS** | `Sense2VecComponent` | The loaded object.    |\n\n---\n\n### <kbd>class</kbd> `registry`\n\nFunction registry (powered by\n[`catalogue`](https://github.com/explosion/catalogue)) to easily customize the\nfunctions used to generate keys and phrases. Allows you to decorate and name\ncustom functions, swap them out and serialize the custom names when you save out\nthe model. The following registry options are available:\n\n| Name                      | Description                                                                                                                                                                                                                                        |\n| ------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `registry.make_key`       | Given a `word` and `sense`, return a string of the key, e.g. `\"word|sense\".`                                                                                                                                                                       |\n| `registry.split_key`      | Given a string key, return a `(word, sense)` tuple.                                                                                                                                                                                                |\n| `registry.make_spacy_key` | Given a spaCy object (`Token` or `Span`) and a boolean `prefer_ents` keyword argument (whether to prefer the entity label for single tokens), return a `(word, sense)` tuple. Used in extension attributes to generate a key for tokens and spans. |  |\n| `registry.get_phrases`    | Given a spaCy `Doc`, return a list of `Span` objects used for sense2vec phrases (typically noun phrases and named entities).                                                                                                                       |\n| `registry.merge_phrases`  | Given a spaCy `Doc`, get all sense2vec phrases and merge them into single tokens.\u00a0                                                                                                                                                                 |\n\nEach registry has a `register` method that can be used as a function decorator\nand takes one argument, the name of the custom function.\n\n```python\nfrom sense2vec import registry\n\n@registry.make_key.register(\"custom\")\ndef custom_make_key(word, sense):\n    return f\"{word}###{sense}\"\n\n@registry.split_key.register(\"custom\")\ndef custom_split_key(key):\n    word, sense = key.split(\"###\")\n    return word, sense\n```\n\nWhen initializing the `Sense2Vec` object, you can now pass in a dictionary of\noverrides with the names of your custom registered functions.\n\n```python\noverrides = {\"make_key\": \"custom\", \"split_key\": \"custom\"}\ns2v = Sense2Vec(overrides=overrides)\n```\n\nThis makes it easy to experiment with different strategies and serializing the\nstrategies as plain strings (instead of having to pass around and/or pickle the\nfunctions themselves).\n\n## \ud83d\ude82 Training your own sense2vec vectors\n\nThe [`/scripts`](/scripts) directory contains command line utilities for\npreprocessing text and training your own vectors.\n\n### Requirements\n\nTo train your own sense2vec vectors, you'll need the following:\n\n- A **very large** source of raw text (ideally more than you'd use for word2vec,\n  since the senses make the vocabulary more sparse). We recommend at least 1\n  billion words.\n- A [pretrained spaCy model](https://spacy.io/models) that assigns\n  part-of-speech tags, dependencies and named entities, and populates the\n  `doc.noun_chunks`. If the language you need doesn't provide a built in\n  [syntax iterator for noun phrases](https://spacy.io/usage/adding-languages#syntax-iterators),\n  you'll need to write your own. (The `doc.noun_chunks` and `doc.ents` are what\n  sense2vec uses to determine what's a phrase.)\n- [GloVe](https://github.com/stanfordnlp/GloVe) or\n  [fastText](https://github.com/facebookresearch/fastText) installed and built.\n  You should be able to clone the repo and run `make` in the respective\n  directory.\n\n### Step-by-step process\n\nThe training process is split up into several steps to allow you to resume at\nany given point. Processing scripts are designed to operate on single files,\nmaking it easy to paralellize the work. The scripts in this repo require either\n[Glove](https://github.com/stanfordnlp/GloVe) or\n[fastText](https://github.com/facebookresearch/fastText), which you need to\nclone and `make`.\n\n|        | Script                                                                                                                                       | Description                                                                                                                                                                                 |\n| ------ | -------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **1.** | [`01_parse.py`](scripts/01_parse.py)                                                                                                         | Use spaCy to parse the raw text and output binary collections of `Doc` objects (see [`DocBin`](https://spacy.io/api/docbin)).                                                               |\n| **2.** | [`02_preprocess.py`](scripts/02_preprocess.py)                                                                                               | Load a collection of parsed `Doc` objects produced in the previous step and output text files in the sense2vec format (one sentence per line and merged phrases with senses).               |\n| **3.** | [`03_glove_build_counts.py`](scripts/03_glove_build_counts.py)                                                                               | Use [GloVe](https://github.com/stanfordnlp/GloVe) to build the vocabulary and counts. Skip this step if you're using Word2Vec via [FastText](https://github.com/facebookresearch/fastText). |\n| **4.** | [`04_glove_train_vectors.py`](scripts/04_glove_train_vectors.py)<br />[`04_fasttext_train_vectors.py`](scripts/04_fasttext_train_vectors.py) | Use [GloVe](https://github.com/stanfordnlp/GloVe) or [FastText](https://github.com/facebookresearch/fastText) to train vectors.                                                             |\n| **5.** | [`05_export.py`](scripts/05_export.py)                                                                                                       | Load the vectors and frequencies and output a sense2vec component that can be loaded via `Sense2Vec.from_disk`.                                                                             |\n| **6.** | [`06_precompute_cache.py`](scripts/06_precompute_cache.py)                                                                                   | **Optional:** Precompute nearest-neighbor queries for every entry in the vocab to make `Sense2Vec.most_similar` faster.                                                                     |\n\nFor more detailed documentation of the scripts, check out the source or run them\nwith `--help`. For example, `python scripts/01_parse.py --help`.\n\n## \ud83c\udf73 Prodigy recipes\n\nThis package also seamlessly integrates with the [Prodigy](https://prodi.gy)\nannotation tool and exposes recipes for using sense2vec vectors to quickly\ngenerate lists of multi-word phrases and bootstrap NER annotations. To use a\nrecipe, `sense2vec` needs to be installed in the same environment as Prodigy.\nFor an example of a real-world use case, check out this\n[NER project](https://github.com/explosion/projects/tree/master/ner-fashion-brands)\nwith downloadable datasets.\n\nThe following recipes are available \u2013 see below for more detailed docs.\n\n| Recipe                                                              | Description                                                          |\n| ------------------------------------------------------------------- | -------------------------------------------------------------------- |\n| [`sense2vec.teach`](#recipe-sense2vecteach)                         | Bootstrap a terminology list using sense2vec.                        |\n| [`sense2vec.to-patterns`](#recipe-sense2vecto-patterns)             | Convert phrases dataset to token-based match patterns.               |\n| [`sense2vec.eval`](#recipe-sense2veceval)                           | Evaluate a sense2vec model by asking about phrase triples.           |\n| [`sense2vec.eval-most-similar`](#recipe-sense2veceval-most-similar) | Evaluate a sense2vec model by correcting the most similar entries.   |\n| [`sense2vec.eval-ab`](#recipe-sense2veceval-ab)                     | Perform an A/B evaluation of two pretrained sense2vec vector models. |\n\n### <kbd>recipe</kbd> `sense2vec.teach`\n\nBootstrap a terminology list using sense2vec. Prodigy will suggest similar terms\nbased on the the most similar phrases from sense2vec, and the suggestions will\nbe adjusted as you annotate and accept similar phrases. For each seed term, the\nbest matching sense according to the sense2vec vectors will be used.\n\n```bash\nprodigy sense2vec.teach [dataset] [vectors_path] [--seeds] [--threshold]\n[--n-similar] [--batch-size] [--resume]\n```\n\n| Argument             | Type       | Description                               |\n| -------------------- | ---------- | ----------------------------------------- |\n| `dataset`            | positional | Dataset to save annotations to.           |\n| `vectors_path`       | positional | Path to pretrained sense2vec vectors.     |\n| `--seeds`, `-s`      | option     | One or more comma-separated seed phrases. |\n| `--threshold`, `-t`  | option     | Similarity threshold. Defaults to `0.85`. |\n| `--n-similar`, `-n`  | option     | Number of similar items to get at once.   |\n| `--batch-size`, `-b` | option     | Batch size for submitting annotations.    |\n| `--resume`, `-R`     | flag       | Resume from an existing phrases dataset.  |\n\n#### Example\n\n```bash\nprodigy sense2vec.teach tech_phrases /path/to/s2v_reddit_2015_md\n--seeds \"natural language processing, machine learning, artificial intelligence\"\n```\n\n### <kbd>recipe</kbd> `sense2vec.to-patterns`\n\nConvert a dataset of phrases collected with `sense2vec.teach` to token-based\nmatch patterns that can be used with\n[spaCy's `EntityRuler`](https://spacy.io/usage/rule-based-matching#entityruler)\nor recipes like `ner.match`. If no output file is specified, the patterns are\nwritten to stdout. The examples are tokenized so that multi-token terms are\nrepresented correctly, e.g.:\n`{\"label\": \"SHOE_BRAND\", \"pattern\": [{ \"LOWER\": \"new\" }, { \"LOWER\": \"balance\" }]}`.\n\n```bash\nprodigy sense2vec.to-patterns [dataset] [spacy_model] [label] [--output-file]\n[--case-sensitive] [--dry]\n```\n\n| Argument                  | Type       | Description                                  |\n| ------------------------- | ---------- | -------------------------------------------- |\n| `dataset`                 | positional | Phrase dataset to convert.                   |\n| `spacy_model`             | positional | spaCy model for tokenization.                |\n| `label`                   | positional | Label to apply to all patterns.              |\n| `--output-file`, `-o`     | option     | Optional output file. Defaults to stdout.    |\n| `--case-sensitive`, `-CS` | flag       | Make patterns case-sensitive.                |\n| `--dry`, `-D`             | flag       | Perform a dry run and don't output anything. |\n\n#### Example\n\n```bash\nprodigy sense2vec.to-patterns tech_phrases en_core_web_sm TECHNOLOGY\n--output-file /path/to/patterns.jsonl\n```\n\n### <kbd>recipe</kbd> `sense2vec.eval`\n\nEvaluate a sense2vec model by asking about phrase triples: is word A more\nsimilar to word B, or to word C? If the human mostly agrees with the model, the\nvectors model is good. The recipe will only ask about vectors with the same\nsense and supports different example selection strategies.\n\n```bash\nprodigy sense2vec.eval [dataset] [vectors_path] [--strategy] [--senses]\n[--exclude-senses] [--n-freq] [--threshold] [--batch-size] [--eval-whole]\n[--eval-only] [--show-scores]\n```\n\n| Argument                  | Type       | Description                                                                                                   |\n| ------------------------- | ---------- | ------------------------------------------------------------------------------------------------------------- |\n| `dataset`                 | positional | Dataset to save annotations to.                                                                               |\n| `vectors_path`            | positional | Path to pretrained sense2vec vectors.                                                                         |\n| `--strategy`, `-st`       | option     | Example selection strategy. `most similar` (default) or `random`.                                             |\n| `--senses`, `-s`          | option     | Comma-separated list of senses to limit the selection to. If not set, all senses in the vectors will be used. |\n| `--exclude-senses`, `-es` | option     | Comma-separated list of senses to exclude. See `prodigy_recipes.EVAL_EXCLUDE_SENSES` fro the defaults.        |\n| `--n-freq`, `-f`          | option     | Number of most frequent entries to limit to.                                                                  |\n| `--threshold`, `-t`       | option     | Minimum similarity threshold to consider examples.                                                            |\n| `--batch-size`, `-b`      | option     | Batch size to use.                                                                                            |\n| `--eval-whole`, `-E`      | flag       | Evaluate the whole dataset instead of the current session.                                                    |\n| `--eval-only`, `-O`       | flag       | Don't annotate, only evaluate the current dataset.                                                            |\n| `--show-scores`, `-S`     | flag       | Show all scores for debugging.                                                                                |\n\n#### Strategies\n\n| Name                 | Description                                                                                                                                                           |\n| -------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `most_similar`       | Pick a random word from a random sense and get its most similar entries of the same sense. Ask about the similarity to the last and middle entry from that selection. |\n| `most_least_similar` | Pick a random word from a random sense and get the least similar entry from its most similar entries, and then the last most similar entry of that.                   |\n| `random`             | Pick a random sample of 3 words from the same random sense.                                                                                                           |\n\n#### Example\n\n```bash\nprodigy sense2vec.eval vectors_eval /path/to/s2v_reddit_2015_md\n--senses NOUN,ORG,PRODUCT --threshold 0.5\n```\n\n![UI preview of sense2vec.eval](https://user-images.githubusercontent.com/13643239/67994212-668cf400-fc44-11e9-8fe2-bf264ae32b0a.png)\n\n### <kbd>recipe</kbd> `sense2vec.eval-most-similar`\n\nEvaluate a vectors model by looking at the most similar entries it returns for a\nrandom phrase and unselecting the mistakes.\n\n```bash\nprodigy sense2vec.eval [dataset] [vectors_path] [--senses] [--exclude-senses]\n[--n-freq] [--n-similar] [--batch-size] [--eval-whole] [--eval-only]\n[--show-scores]\n```\n\n| Argument                  | Type       | Description                                                                                                   |\n| ------------------------- | ---------- | ------------------------------------------------------------------------------------------------------------- |\n| `dataset`                 | positional | Dataset to save annotations to.                                                                               |\n| `vectors_path`            | positional | Path to pretrained sense2vec vectors.                                                                         |\n| `--senses`, `-s`          | option     | Comma-separated list of senses to limit the selection to. If not set, all senses in the vectors will be used. |\n| `--exclude-senses`, `-es` | option     | Comma-separated list of senses to exclude. See `prodigy_recipes.EVAL_EXCLUDE_SENSES` fro the defaults.        |\n| `--n-freq`, `-f`          | option     | Number of most frequent entries to limit to.                                                                  |\n| `--n-similar`, `-n`       | option     | Number of similar items to check. Defaults to `10`.                                                           |\n| `--batch-size`, `-b`      | option     | Batch size to use.                                                                                            |\n| `--eval-whole`, `-E`      | flag       | Evaluate the whole dataset instead of the current session.                                                    |\n| `--eval-only`, `-O`       | flag       | Don't annotate, only evaluate the current dataset.                                                            |\n| `--show-scores`, `-S`     | flag       | Show all scores for debugging.                                                                                |\n\n```bash\nprodigy sense2vec.eval-most-similar vectors_eval_sim /path/to/s2v_reddit_2015_md\n--senses NOUN,ORG,PRODUCT\n```\n\n### <kbd>recipe</kbd> `sense2vec.eval-ab`\n\nPerform an A/B evaluation of two pretrained sense2vec vector models by comparing\nthe most similar entries they return for a random phrase. The UI shows two\nrandomized options with the most similar entries of each model and highlights\nthe phrases that differ. At the end of the annotation session the overall stats\nand preferred model are shown.\n\n```bash\nprodigy sense2vec.eval [dataset] [vectors_path_a] [vectors_path_b] [--senses]\n[--exclude-senses] [--n-freq] [--n-similar] [--batch-size] [--eval-whole]\n[--eval-only] [--show-mapping]\n```\n\n| Argument                  | Type       | Description                                                                                                   |\n| ------------------------- | ---------- | ------------------------------------------------------------------------------------------------------------- |\n| `dataset`                 | positional | Dataset to save annotations to.                                                                               |\n| `vectors_path_a`          | positional | Path to pretrained sense2vec vectors.                                                                         |\n| `vectors_path_b`          | positional | Path to pretrained sense2vec vectors.                                                                         |\n| `--senses`, `-s`          | option     | Comma-separated list of senses to limit the selection to. If not set, all senses in the vectors will be used. |\n| `--exclude-senses`, `-es` | option     | Comma-separated list of senses to exclude. See `prodigy_recipes.EVAL_EXCLUDE_SENSES` fro the defaults.        |\n| `--n-freq`, `-f`          | option     | Number of most frequent entries to limit to.                                                                  |\n| `--n-similar`, `-n`       | option     | Number of similar items to check. Defaults to `10`.                                                           |\n| `--batch-size`, `-b`      | option     | Batch size to use.                                                                                            |\n| `--eval-whole`, `-E`      | flag       | Evaluate the whole dataset instead of the current session.                                                    |\n| `--eval-only`, `-O`       | flag       | Don't annotate, only evaluate the current dataset.                                                            |\n| `--show-mapping`, `-S`    | flag       | Show which models are option 1 and option 2 in the UI (for debugging).                                        |\n\n```bash\nprodigy sense2vec.eval-ab vectors_eval_sim /path/to/s2v_reddit_2015_md /path/to/s2v_reddit_2019_md --senses NOUN,ORG,PRODUCT\n```\n\n![UI preview of sense2vec.eval-ab](https://user-images.githubusercontent.com/13643239/68088514-46d21780-fe60-11e9-9b29-fe313bb2154d.png)\n\n## Pretrained vectors\n\nThe pretrained Reddit vectors support the following \"senses\", either\npart-of-speech tags or entity labels. For more details, see spaCy's\n[annotation scheme overview](https://spacy.io/api/annotation).\n\n| Tag     | Description               | Examples                             |\n| ------- | ------------------------- | ------------------------------------ |\n| `ADJ`   | adjective                 | big, old, green                      |\n| `ADP`   | adposition                | in, to, during                       |\n| `ADV`   | adverb                    | very, tomorrow, down, where          |\n| `AUX`   | auxiliary\u00a0                | is, has (done), will (do)            |\n| `CONJ`  | conjunction               | and, or, but                         |\n| `DET`   | determiner                | a, an, the                           |\n| `INTJ`  | interjection              | psst, ouch, bravo, hello             |\n| `NOUN`  | noun                      | girl, cat, tree, air, beauty         |\n| `NUM`   | numeral                   | 1, 2017, one, seventy-seven, MMXIV   |\n| `PART`  | particle                  | 's, not                              |\n| `PRON`  | pronoun                   | I, you, he, she, myself, somebody    |\n| `PROPN` | proper noun               | Mary, John, London, NATO, HBO        |\n| `PUNCT` | punctuation               | , ? ( )                              |\n| `SCONJ` | subordinating conjunction | if, while, that                      |\n| `SYM`   | symbol                    | \\$, %, =, :), \ud83d\ude1d                     |\n| `VERB`  | verb                      | run, runs, running, eat, ate, eating |\n\n| Entity Label  | Description                                          |\n| ------------- | ---------------------------------------------------- |\n| `PERSON`      | People, including fictional.                         |\n| `NORP`        | Nationalities or religious or political groups.      |\n| `FACILITY`    | Buildings, airports, highways, bridges, etc.         |\n| `ORG`         | Companies, agencies, institutions, etc.              |\n| `GPE`         | Countries, cities, states.                           |\n| `LOC`         | Non-GPE locations, mountain ranges, bodies of water. |\n| `PRODUCT`     | Objects, vehicles, foods, etc. (Not services.)       |\n| `EVENT`       | Named hurricanes, battles, wars, sports events, etc. |\n| `WORK_OF_ART` | Titles of books, songs, etc.                         |\n| `LANGUAGE`    | Any named language.                                  |", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/explosion/sense2vec", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "sense2vec", "package_url": "https://pypi.org/project/sense2vec/", "platform": "", "project_url": "https://pypi.org/project/sense2vec/", "project_urls": {"Homepage": "https://github.com/explosion/sense2vec"}, "release_url": "https://pypi.org/project/sense2vec/1.0.2/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Contextually-keyed word vectors", "version": "1.0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://explosion.ai\" rel=\"nofollow\"><img align=\"right\" height=\"125\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/657dbf4006ad44b146bd59acc7f61d67177af1a5/68747470733a2f2f6578706c6f73696f6e2e61692f6173736574732f696d672f6c6f676f2e737667\" width=\"125\"></a></p>\n<h1>sense2vec: Contextually-keyed word vectors</h1>\n<p>sense2vec (<a href=\"https://arxiv.org/abs/1511.06388\" rel=\"nofollow\">Trask et. al</a>, 2015) is a nice\ntwist on <a href=\"https://en.wikipedia.org/wiki/Word2vec\" rel=\"nofollow\">word2vec</a> that lets you learn\nmore interesting and detailed word vectors. This library is a simple Python\nimplementation for loading, querying and training sense2vec models. For more\ndetails, check out\n<a href=\"https://explosion.ai/blog/sense2vec-reloaded\" rel=\"nofollow\">our blog post</a>. To explore the\nsemantic similarities across all Reddit comments of 2015 and 2019, see the\n<a href=\"https://demos.explosion.ai/sense2vec\" rel=\"nofollow\">interactive demo</a>.</p>\n<p>\ud83e\udd86 <strong>Version 1.0 out now!</strong>\n<a href=\"https://github.com/explosion/sense2vec/releases/\" rel=\"nofollow\">Read the release notes here.</a></p>\n<p><a href=\"https://dev.azure.com/explosion-ai/public/_build?definitionId=12\" rel=\"nofollow\"><img alt=\"Azure Pipelines\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/69ea1634e10232de1c7d0e48453b4f6a8856c01e/68747470733a2f2f696d672e736869656c64732e696f2f617a7572652d6465766f70732f6275696c642f6578706c6f73696f6e2d61692f7075626c69632f31322f6d61737465722e7376673f6c6f676f3d617a7572652d706970656c696e6573267374796c653d666c61742d737175617265266c6162656c3d6275696c64\"></a>\n<a href=\"https://github.com/explosion/sense2vec/releases\" rel=\"nofollow\"><img alt=\"Current Release Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bd0985d89166bf22c6d1bcdf66ef4a89d23f7bf9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f6578706c6f73696f6e2f73656e7365327665632e7376673f7374796c653d666c61742d737175617265266c6f676f3d676974687562\"></a>\n<a href=\"https://pypi.org/project/sense2vec/\" rel=\"nofollow\"><img alt=\"pypi Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d38c709b82442f80c0d866d08b12309a861405e2/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f73656e7365327665632e7376673f7374796c653d666c61742d737175617265266c6f676f3d70797069266c6f676f436f6c6f723d7768697465\"></a>\n<a href=\"https://github.com/ambv/black\" rel=\"nofollow\"><img alt=\"Code style: black\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1c326c58e924b9f3508f32a8ac6b3ee91f40b090/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e7376673f7374796c653d666c61742d737175617265\"></a></p>\n<h2>\u2728 Features</h2>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/00de261edeaa1c176a4ec0e8d8727ecbfc7574e1/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31333634333233392f36393333303735392d64333938313630302d306335332d313165612d386636342d6535633037356637656131302e6a7067\"></p>\n<ul>\n<li>Query <strong>vectors for multi-word phrases</strong> based on part-of-speech tags and\nentity labels.</li>\n<li>spaCy <strong>pipeline component</strong> and <strong>extension attributes</strong>.</li>\n<li>Fully <strong>serializable</strong> so you can easily ship your sense2vec vectors with your\nspaCy model packages.</li>\n<li>Optional <strong>caching of nearest neighbors</strong> for super fast \"most similar\"\nqueries.</li>\n<li><strong>Train your own vectors</strong> using a pretrained spaCy model, raw text and\n<a href=\"https://github.com/stanfordnlp/GloVe\" rel=\"nofollow\">GloVe</a> or Word2Vec via\n<a href=\"https://github.com/facebookresearch/fastText\" rel=\"nofollow\">fastText</a>\n(<a href=\"#-training-your-own-sense2vec-vectors\" rel=\"nofollow\">details</a>).</li>\n<li><a href=\"https://prodi.gy\" rel=\"nofollow\">Prodigy</a> <strong>annotation recipes</strong> for evaluating models,\ncreating lists of similar multi-word phrases and converting them to match\npatterns, e.g. for rule-based NER or to boostrap NER annotation\n(<a href=\"#-prodigy-recipes\" rel=\"nofollow\">details &amp; examples</a>).</li>\n</ul>\n<h2>\ud83d\ude80 Quickstart</h2>\n<h3>Standalone usage</h3>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">sense2vec</span> <span class=\"kn\">import</span> <span class=\"n\">Sense2Vec</span>\n\n<span class=\"n\">s2v</span> <span class=\"o\">=</span> <span class=\"n\">Sense2Vec</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">from_disk</span><span class=\"p\">(</span><span class=\"s2\">\"/path/to/s2v_reddit_2015_md\"</span><span class=\"p\">)</span>\n<span class=\"n\">query</span> <span class=\"o\">=</span> <span class=\"s2\">\"natural_language_processing|NOUN\"</span>\n<span class=\"k\">assert</span> <span class=\"n\">query</span> <span class=\"ow\">in</span> <span class=\"n\">s2v</span>\n<span class=\"n\">vector</span> <span class=\"o\">=</span> <span class=\"n\">s2v</span><span class=\"p\">[</span><span class=\"n\">query</span><span class=\"p\">]</span>\n<span class=\"n\">freq</span> <span class=\"o\">=</span> <span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">get_freq</span><span class=\"p\">(</span><span class=\"n\">query</span><span class=\"p\">)</span>\n<span class=\"n\">most_similar</span> <span class=\"o\">=</span> <span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">most_similar</span><span class=\"p\">(</span><span class=\"n\">query</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n<span class=\"c1\"># [('machine_learning|NOUN', 0.8986967),</span>\n<span class=\"c1\">#  ('computer_vision|NOUN', 0.8636297),</span>\n<span class=\"c1\">#  ('deep_learning|NOUN', 0.8573361)]</span>\n</pre>\n<h3>Usage as a spaCy pipeline component</h3>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">spacy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sense2vec</span> <span class=\"kn\">import</span> <span class=\"n\">Sense2VecComponent</span>\n\n<span class=\"n\">nlp</span> <span class=\"o\">=</span> <span class=\"n\">spacy</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s2\">\"en_core_web_sm\"</span><span class=\"p\">)</span>\n<span class=\"n\">s2v</span> <span class=\"o\">=</span> <span class=\"n\">Sense2VecComponent</span><span class=\"p\">(</span><span class=\"n\">nlp</span><span class=\"o\">.</span><span class=\"n\">vocab</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">from_disk</span><span class=\"p\">(</span><span class=\"s2\">\"/path/to/s2v_reddit_2015_md\"</span><span class=\"p\">)</span>\n<span class=\"n\">nlp</span><span class=\"o\">.</span><span class=\"n\">add_pipe</span><span class=\"p\">(</span><span class=\"n\">s2v</span><span class=\"p\">)</span>\n\n<span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"n\">nlp</span><span class=\"p\">(</span><span class=\"s2\">\"A sentence about natural language processing.\"</span><span class=\"p\">)</span>\n<span class=\"k\">assert</span> <span class=\"n\">doc</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">:</span><span class=\"mi\">6</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">text</span> <span class=\"o\">==</span> <span class=\"s2\">\"natural language processing\"</span>\n<span class=\"n\">freq</span> <span class=\"o\">=</span> <span class=\"n\">doc</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">:</span><span class=\"mi\">6</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">_</span><span class=\"o\">.</span><span class=\"n\">s2v_freq</span>\n<span class=\"n\">vector</span> <span class=\"o\">=</span> <span class=\"n\">doc</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">:</span><span class=\"mi\">6</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">_</span><span class=\"o\">.</span><span class=\"n\">s2v_vec</span>\n<span class=\"n\">most_similar</span> <span class=\"o\">=</span> <span class=\"n\">doc</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">:</span><span class=\"mi\">6</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">_</span><span class=\"o\">.</span><span class=\"n\">s2v_most_similar</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n<span class=\"c1\"># [(('machine learning', 'NOUN'), 0.8986967),</span>\n<span class=\"c1\">#  (('computer vision', 'NOUN'), 0.8636297),</span>\n<span class=\"c1\">#  (('deep learning', 'NOUN'), 0.8573361)]</span>\n</pre>\n<h3>Interactive demos</h3>\n<img align=\"right\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c7f3bb5a7177cae2e4ac38f1e195861ac947649b/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31333634333233392f36383039333536352d31626236656138302d666539372d313165392d383139322d6532393361636332393066652e706e67\" width=\"34%\">\n<p>To try out our pretrained vectors trained on Reddit comments, check out the\n<a href=\"https://explosion.ai/demos/sense2vec\" rel=\"nofollow\">interactive sense2vec demo</a>.</p>\n<p>This repo also includes a <a href=\"https://streamlit.io\" rel=\"nofollow\">Streamlit</a> demo script for\nexploring vectors and the most similar phrases. After installing <code>streamlit</code>,\nyou can run the script with <code>streamlit run</code> and <strong>one or more paths to\npretrained vectors</strong> as <strong>positional arguments</strong> on the command line. For\nexample:</p>\n<pre>pip install streamlit\nstreamlit run https://raw.githubusercontent.com/explosion/sense2vec/master/scripts/streamlit_sense2vec.py /path/to/vectors\n</pre>\n<h3>Pretrained vectors</h3>\n<p>To use the vectors, download the archive(s) and pass the extracted directory to\n<code>Sense2Vec.from_disk</code> or <code>Sense2VecComponent.from_disk</code>. The vector files are\n<strong>attached to the GitHub release</strong>. Large files have been split into multi-part\ndownloads.</p>\n<table>\n<thead>\n<tr>\n<th>Vectors</th>\n<th align=\"right\">Size</th>\n<th>Description</th>\n<th>\ud83d\udce5 Download (zipped)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>s2v_reddit_2019_lg</code></td>\n<td align=\"right\">4 GB</td>\n<td>Reddit comments 2019 (01-07)</td>\n<td><a href=\"https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2019_lg.tar.gz.001\" rel=\"nofollow\">part 1</a>, <a href=\"https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2019_lg.tar.gz.002\" rel=\"nofollow\">part 2</a>, <a href=\"https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2019_lg.tar.gz.003\" rel=\"nofollow\">part 3</a></td>\n</tr>\n<tr>\n<td><code>s2v_reddit_2015_md</code></td>\n<td align=\"right\">573 MB</td>\n<td>Reddit comments 2015</td>\n<td><a href=\"https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\" rel=\"nofollow\">part 1</a></td>\n</tr></tbody></table>\n<p>To merge the multi-part archives, you can run the following:</p>\n<pre>cat s2v_reddit_2019_lg.tar.gz.* &gt; s2v_reddit_2019_lg.tar.gz\n</pre>\n<h2>\u23f3 Installation &amp; Setup</h2>\n<p>sense2vec releases are available on pip:</p>\n<pre>pip install sense2vec\n</pre>\n<p>To use pretrained vectors, download\n<a href=\"#pretrained-vectors\" rel=\"nofollow\">one of the vector packages</a>, unpack the <code>.tar.gz</code> archive\nand point <code>from_disk</code> to the extracted data directory:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">sense2vec</span> <span class=\"kn\">import</span> <span class=\"n\">Sense2Vec</span>\n<span class=\"n\">s2v</span> <span class=\"o\">=</span> <span class=\"n\">Sense2Vec</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">from_disk</span><span class=\"p\">(</span><span class=\"s2\">\"/path/to/s2v_reddit_2015_md\"</span><span class=\"p\">)</span>\n</pre>\n<h2>\ud83d\udc69\u200d\ud83d\udcbb Usage</h2>\n<h3>Usage with spaCy v2.2+</h3>\n<p>The easiest way to use the library and vectors is to plug it into your spaCy\npipeline. The <code>sense2vec</code> package exposes a <code>Sense2VecComponent</code>, which can be\ninitialised with the shared vocab and added to your spaCy pipeline as a\n<a href=\"https://spacy.io/usage/processing-pipelines#custom-components\" rel=\"nofollow\">custom pipeline component</a>.\nBy default, components are added to the <em>end of the pipeline</em>, which is the\nrecommended position for this component, since it needs access to the dependency\nparse and, if available, named entities.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">spacy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sense2vec</span> <span class=\"kn\">import</span> <span class=\"n\">Sense2VecComponent</span>\n\n<span class=\"n\">nlp</span> <span class=\"o\">=</span> <span class=\"n\">spacy</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s2\">\"en_core_web_sm\"</span><span class=\"p\">)</span>\n<span class=\"n\">s2v</span> <span class=\"o\">=</span> <span class=\"n\">Sense2VecComponent</span><span class=\"p\">(</span><span class=\"n\">nlp</span><span class=\"o\">.</span><span class=\"n\">vocab</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">from_disk</span><span class=\"p\">(</span><span class=\"s2\">\"/path/to/s2v_reddit_2015_md\"</span><span class=\"p\">)</span>\n<span class=\"n\">nlp</span><span class=\"o\">.</span><span class=\"n\">add_pipe</span><span class=\"p\">(</span><span class=\"n\">s2v</span><span class=\"p\">)</span>\n</pre>\n<p>The component will add serveral\n<a href=\"https://spacy.io/usage/processing-pipelines#custom-components-attributes\" rel=\"nofollow\">extension attributes and methods</a>\nto spaCy's <code>Token</code> and <code>Span</code> objects that let you retrieve vectors and\nfrequencies, as well as most similar terms.</p>\n<pre><span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"n\">nlp</span><span class=\"p\">(</span><span class=\"s2\">\"A sentence about natural language processing.\"</span><span class=\"p\">)</span>\n<span class=\"k\">assert</span> <span class=\"n\">doc</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">:</span><span class=\"mi\">6</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">text</span> <span class=\"o\">==</span> <span class=\"s2\">\"natural language processing\"</span>\n<span class=\"n\">freq</span> <span class=\"o\">=</span> <span class=\"n\">doc</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">:</span><span class=\"mi\">6</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">_</span><span class=\"o\">.</span><span class=\"n\">s2v_freq</span>\n<span class=\"n\">vector</span> <span class=\"o\">=</span> <span class=\"n\">doc</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">:</span><span class=\"mi\">6</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">_</span><span class=\"o\">.</span><span class=\"n\">s2v_vec</span>\n<span class=\"n\">most_similar</span> <span class=\"o\">=</span> <span class=\"n\">doc</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">:</span><span class=\"mi\">6</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">_</span><span class=\"o\">.</span><span class=\"n\">s2v_most_similar</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n</pre>\n<p>For entities, the entity labels are used as the \"sense\" (instead of the token's\npart-of-speech tag):</p>\n<pre><span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"n\">nlp</span><span class=\"p\">(</span><span class=\"s2\">\"A sentence about Facebook and Google.\"</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">ent</span> <span class=\"ow\">in</span> <span class=\"n\">doc</span><span class=\"o\">.</span><span class=\"n\">ents</span><span class=\"p\">:</span>\n    <span class=\"k\">assert</span> <span class=\"n\">ent</span><span class=\"o\">.</span><span class=\"n\">_</span><span class=\"o\">.</span><span class=\"n\">in_s2v</span>\n    <span class=\"n\">most_similar</span> <span class=\"o\">=</span> <span class=\"n\">ent</span><span class=\"o\">.</span><span class=\"n\">_</span><span class=\"o\">.</span><span class=\"n\">s2v_most_similar</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n</pre>\n<h4>Available attributes</h4>\n<p>The following extension attributes are exposed on the <code>Doc</code> object via the <code>._</code>\nproperty:</p>\n<table>\n<thead>\n<tr>\n<th>Name</th>\n<th>Attribute Type</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>s2v_phrases</code></td>\n<td>property</td>\n<td>list</td>\n<td>All sense2vec-compatible phrases in the given <code>Doc</code> (noun phrases, named entities).</td>\n</tr></tbody></table>\n<p>The following attributes are available via the <code>._</code> property of <code>Token</code> and\n<code>Span</code> objects \u2013 for example <code>token._.in_s2v</code>:</p>\n<table>\n<thead>\n<tr>\n<th>Name</th>\n<th>Attribute Type</th>\n<th>Return Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>in_s2v</code></td>\n<td>property</td>\n<td>bool</td>\n<td>Whether a key exists in the vector map.</td>\n</tr>\n<tr>\n<td><code>s2v_key</code></td>\n<td>property</td>\n<td>unicode</td>\n<td>The sense2vec key of the given object, e.g. `\"duck</td>\n</tr>\n<tr>\n<td><code>s2v_vec</code></td>\n<td>property</td>\n<td><code>ndarray[float32]</code></td>\n<td>The vector of the given key.</td>\n</tr>\n<tr>\n<td><code>s2v_freq</code></td>\n<td>property</td>\n<td>int</td>\n<td>The frequency of the given key.</td>\n</tr>\n<tr>\n<td><code>s2v_other_senses</code></td>\n<td>property</td>\n<td>list</td>\n<td>Available other senses, e.g. `\"duck</td>\n</tr>\n<tr>\n<td><code>s2v_most_similar</code></td>\n<td>method</td>\n<td>list</td>\n<td>Get the <code>n</code> most similar terms. Returns a list of <code>((word, sense), score)</code> tuples.</td>\n</tr>\n<tr>\n<td><code>s2v_similarity</code></td>\n<td>method</td>\n<td>float</td>\n<td>Get the similarity to another <code>Token</code> or <code>Span</code>.</td>\n</tr></tbody></table>\n<blockquote>\n<p>\u26a0\ufe0f <strong>A note on span attributes:</strong> Under the hood, entities in <code>doc.ents</code> are\n<code>Span</code> objects. This is why the pipeline component also adds attributes and\nmethods to spans and not just tokens. However, it's not recommended to use the\nsense2vec attributes on arbitrary slices of the document, since the model\nlikely won't have a key for the respective text. <code>Span</code> objects also don't\nhave a part-of-speech tag, so if no entity label is present, the \"sense\"\ndefaults to the root's part-of-speech tag.</p>\n</blockquote>\n<h3>Standalone usage</h3>\n<p>You can also use the underlying <code>Sense2Vec</code> class directly and load in the\nvectors using the <code>from_disk</code> method. See below for the available API methods.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">sense2vec</span> <span class=\"kn\">import</span> <span class=\"n\">Sense2Vec</span>\n<span class=\"n\">s2v</span> <span class=\"o\">=</span> <span class=\"n\">Sense2Vec</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">from_disk</span><span class=\"p\">(</span><span class=\"s2\">\"/path/to/reddit_vectors-1.1.0\"</span><span class=\"p\">)</span>\n<span class=\"n\">most_similar</span> <span class=\"o\">=</span> <span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">most_similar</span><span class=\"p\">(</span><span class=\"s2\">\"natural_language_processing|NOUN\"</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n</pre>\n<blockquote>\n<p>\u26a0\ufe0f <strong>Important note:</strong> To look up entries in the vectors table, the keys need\nto follow the scheme of <code>phrase_text|SENSE</code> (note the <code>_</code> instead of spaces\nand the <code>|</code> before the tag or label) \u2013 for example, <code>machine_learning|NOUN</code>.\nAlso note that the underlying vector table is case-sensitive.</p>\n</blockquote>\n<h2>\ud83c\udf9b API</h2>\n<h3><kbd>class</kbd> <code>Sense2Vec</code></h3>\n<p>The standalone <code>Sense2Vec</code> object that holds the vectors, strings and\nfrequencies.</p>\n<h4><kbd>method</kbd> <code>Sense2Vec.__init__</code></h4>\n<p>Initialize the <code>Sense2Vec</code> object.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>shape</code></td>\n<td>tuple</td>\n<td>The vector shape. Defaults to <code>(1000, 128)</code>.</td>\n</tr>\n<tr>\n<td><code>strings</code></td>\n<td><code>spacy.strings.StringStore</code></td>\n<td>Optional string store. Will be created if it doesn't exist.</td>\n</tr>\n<tr>\n<td><code>senses</code></td>\n<td>list</td>\n<td>Optional list of all available senses. Used in methods that generate the best sense or other senses.</td>\n</tr>\n<tr>\n<td><code>vectors_name</code></td>\n<td>unicode</td>\n<td>Optional name to assign to the <code>Vectors</code> table, to prevent clashes. Defaults to <code>\"sense2vec\"</code>.</td>\n</tr>\n<tr>\n<td><code>overrides</code></td>\n<td>dict</td>\n<td>Optional custom functions to use, mapped to names registered via the registry, e.g. <code>{\"make_key\": \"custom_make_key\"}</code>.</td>\n</tr>\n<tr>\n<td><strong>RETURNS</strong></td>\n<td><code>Sense2Vec</code></td>\n<td>The newly constructed object.</td>\n</tr></tbody></table>\n<pre><span class=\"n\">s2v</span> <span class=\"o\">=</span> <span class=\"n\">Sense2Vec</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">300</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"n\">senses</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"VERB\"</span><span class=\"p\">,</span> <span class=\"s2\">\"NOUN\"</span><span class=\"p\">])</span>\n</pre>\n<h4><kbd>method</kbd> <code>Sense2Vec.__len__</code></h4>\n<p>The number of rows in the vectors table.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>RETURNS</strong></td>\n<td>int</td>\n<td>The number of rows in the vectors table.</td>\n</tr></tbody></table>\n<pre><span class=\"n\">s2v</span> <span class=\"o\">=</span> <span class=\"n\">Sense2Vec</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">300</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">))</span>\n<span class=\"k\">assert</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">s2v</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"mi\">300</span>\n</pre>\n<h4><kbd>method</kbd> <code>Sense2Vec.__contains__</code></h4>\n<p>Check if a key is in the vectors table.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>key</code></td>\n<td>unicode / int</td>\n<td>The key to look up.</td>\n</tr>\n<tr>\n<td><strong>RETURNS</strong></td>\n<td>bool</td>\n<td>Whether the key is in the table.</td>\n</tr></tbody></table>\n<pre><span class=\"n\">s2v</span> <span class=\"o\">=</span> <span class=\"n\">Sense2Vec</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">))</span>\n<span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"s2\">\"avocado|NOUN\"</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">asarray</span><span class=\"p\">([</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">))</span>\n<span class=\"k\">assert</span> <span class=\"s2\">\"avocado|NOUN\"</span> <span class=\"ow\">in</span> <span class=\"n\">s2v</span>\n<span class=\"k\">assert</span> <span class=\"s2\">\"avocado|VERB\"</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"n\">s2v</span>\n</pre>\n<h4><kbd>method</kbd> <code>Sense2Vec.__getitem__</code></h4>\n<p>Retrieve a vector for a given key. Returns None if the key is not in the table.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>key</code></td>\n<td>unicode / int</td>\n<td>The key to look up.</td>\n</tr>\n<tr>\n<td><strong>RETURNS</strong></td>\n<td><code>numpy.ndarray</code></td>\n<td>The vector or <code>None</code>.</td>\n</tr></tbody></table>\n<pre><span class=\"n\">vec</span> <span class=\"o\">=</span> <span class=\"n\">s2v</span><span class=\"p\">[</span><span class=\"s2\">\"avocado|NOUN\"</span><span class=\"p\">]</span>\n</pre>\n<h4><kbd>method</kbd> <code>Sense2Vec.__setitem__</code></h4>\n<p>Set a vector for a given key. Will raise an error if the key doesn't exist. To\nadd a new entry, use <code>Sense2Vec.add</code>.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>key</code></td>\n<td>unicode / int</td>\n<td>The key.</td>\n</tr>\n<tr>\n<td><code>vector</code></td>\n<td><code>numpy.ndarray</code></td>\n<td>The vector to set.</td>\n</tr></tbody></table>\n<pre><span class=\"n\">vec</span> <span class=\"o\">=</span> <span class=\"n\">s2v</span><span class=\"p\">[</span><span class=\"s2\">\"avocado|NOUN\"</span><span class=\"p\">]</span>\n<span class=\"n\">s2v</span><span class=\"p\">[</span><span class=\"s2\">\"avacado|NOUN\"</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">vec</span>\n</pre>\n<h4><kbd>method</kbd> <code>Sense2Vec.add</code></h4>\n<p>Add a new vector to the table.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>key</code></td>\n<td>unicode / int</td>\n<td>The key to add.</td>\n</tr>\n<tr>\n<td><code>vector</code></td>\n<td><code>numpy.ndarray</code></td>\n<td>The vector to add.</td>\n</tr>\n<tr>\n<td><code>freq</code></td>\n<td>int</td>\n<td>Optional frequency count. Used to find best matching senses.</td>\n</tr></tbody></table>\n<pre><span class=\"n\">vec</span> <span class=\"o\">=</span> <span class=\"n\">s2v</span><span class=\"p\">[</span><span class=\"s2\">\"avocado|NOUN\"</span><span class=\"p\">]</span>\n<span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"s2\">\"\ud83e\udd51|NOUN\"</span><span class=\"p\">,</span> <span class=\"n\">vec</span><span class=\"p\">,</span> <span class=\"mi\">1234</span><span class=\"p\">)</span>\n</pre>\n<h4><kbd>method</kbd> <code>Sense2Vec.get_freq</code></h4>\n<p>Get the frequency count for a given key.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>key</code></td>\n<td>unicode / int</td>\n<td>The key to look up.</td>\n</tr>\n<tr>\n<td><code>default</code></td>\n<td>-</td>\n<td>Default value to return if no frequency is found.</td>\n</tr>\n<tr>\n<td><strong>RETURNS</strong></td>\n<td>int</td>\n<td>The frequency count.</td>\n</tr></tbody></table>\n<pre><span class=\"n\">vec</span> <span class=\"o\">=</span> <span class=\"n\">s2v</span><span class=\"p\">[</span><span class=\"s2\">\"avocado|NOUN\"</span><span class=\"p\">]</span>\n<span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"s2\">\"\ud83e\udd51|NOUN\"</span><span class=\"p\">,</span> <span class=\"n\">vec</span><span class=\"p\">,</span> <span class=\"mi\">1234</span><span class=\"p\">)</span>\n<span class=\"k\">assert</span> <span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">get_freq</span><span class=\"p\">(</span><span class=\"s2\">\"\ud83e\udd51|NOUN\"</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"mi\">1234</span>\n</pre>\n<h4><kbd>method</kbd> <code>Sense2Vec.set_freq</code></h4>\n<p>Set a frequency count for a given key.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>key</code></td>\n<td>unicode / int</td>\n<td>The key to set the count for.</td>\n</tr>\n<tr>\n<td><code>freq</code></td>\n<td>int</td>\n<td>The frequency count.</td>\n</tr></tbody></table>\n<pre><span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">set_freq</span><span class=\"p\">(</span><span class=\"s2\">\"avocado|NOUN\"</span><span class=\"p\">,</span> <span class=\"mi\">104294</span><span class=\"p\">)</span>\n</pre>\n<h4><kbd>method</kbd> <code>Sense2Vec.__iter__</code>, <code>Sense2Vec.items</code></h4>\n<p>Iterate over the entries in the vectors table.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>YIELDS</strong></td>\n<td>tuple</td>\n<td>String key and vector pairs in the table.</td>\n</tr></tbody></table>\n<pre><span class=\"k\">for</span> <span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">vec</span> <span class=\"ow\">in</span> <span class=\"n\">s2v</span><span class=\"p\">:</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">vec</span><span class=\"p\">)</span>\n\n<span class=\"k\">for</span> <span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">vec</span> <span class=\"ow\">in</span> <span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">():</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">vec</span><span class=\"p\">)</span>\n</pre>\n<h4><kbd>method</kbd> <code>Sense2Vec.keys</code></h4>\n<p>Iterate over the keys in the table.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>YIELDS</strong></td>\n<td>unicode</td>\n<td>The string keys in the table.</td>\n</tr></tbody></table>\n<pre><span class=\"n\">all_keys</span> <span class=\"o\">=</span> <span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">keys</span><span class=\"p\">())</span>\n</pre>\n<h4><kbd>method</kbd> <code>Sense2Vec.values</code></h4>\n<p>Iterate over the vectors in the table.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>YIELDS</strong></td>\n<td><code>numpy.ndarray</code></td>\n<td>The vectors in the table.</td>\n</tr></tbody></table>\n<pre><span class=\"n\">all_vecs</span> <span class=\"o\">=</span> <span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">values</span><span class=\"p\">())</span>\n</pre>\n<h4><kbd>property</kbd> <code>Sense2Vec.senses</code></h4>\n<p>The available senses in the table, e.g. <code>\"NOUN\"</code> or <code>\"VERB\"</code> (added at\ninitialization).</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>RETURNS</strong></td>\n<td>list</td>\n<td>The available senses.</td>\n</tr></tbody></table>\n<pre><span class=\"n\">s2v</span> <span class=\"o\">=</span> <span class=\"n\">Sense2Vec</span><span class=\"p\">(</span><span class=\"n\">senses</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"VERB\"</span><span class=\"p\">,</span> <span class=\"s2\">\"NOUN\"</span><span class=\"p\">])</span>\n<span class=\"k\">assert</span> <span class=\"s2\">\"VERB\"</span> <span class=\"ow\">in</span> <span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">senses</span>\n</pre>\n<h4><kbd>property</kbd> <code>Sense2vec.frequencies</code></h4>\n<p>The frequencies of they keys in the table, in descending order.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>RETURNS</strong></td>\n<td>list</td>\n<td>The <code>(key, freq)</code> tuples by frequency, descending.</td>\n</tr></tbody></table>\n<pre><span class=\"n\">most_frequent</span> <span class=\"o\">=</span> <span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">frequencies</span><span class=\"p\">[:</span><span class=\"mi\">10</span><span class=\"p\">]</span>\n<span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">score</span> <span class=\"o\">=</span> <span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">frequencies</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n</pre>\n<h4><kbd>method</kbd> <code>Sense2vec.similarity</code></h4>\n<p>Make a semantic similarity estimate of two keys or two sets of keys. The default\nestimate is cosine similarity using an average of vectors.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>keys_a</code></td>\n<td>unicode / int / iterable</td>\n<td>The string or integer key(s).</td>\n</tr>\n<tr>\n<td><code>keys_b</code></td>\n<td>unicode / int / iterable</td>\n<td>The other string or integer key(s).</td>\n</tr>\n<tr>\n<td><strong>RETURNS</strong></td>\n<td>float</td>\n<td>The similarity score.</td>\n</tr></tbody></table>\n<pre><span class=\"n\">keys_a</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">\"machine_learning|NOUN\"</span><span class=\"p\">,</span> <span class=\"s2\">\"natural_language_processing|NOUN\"</span><span class=\"p\">]</span>\n<span class=\"n\">keys_b</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">\"computer_vision|NOUN\"</span><span class=\"p\">,</span> <span class=\"s2\">\"object_detection|NOUN\"</span><span class=\"p\">]</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">similarity</span><span class=\"p\">(</span><span class=\"n\">keys_a</span><span class=\"p\">,</span> <span class=\"n\">keys_b</span><span class=\"p\">))</span>\n<span class=\"k\">assert</span> <span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">similarity</span><span class=\"p\">(</span><span class=\"s2\">\"machine_learning|NOUN\"</span><span class=\"p\">,</span> <span class=\"s2\">\"machine_learning|NOUN\"</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"mf\">1.0</span>\n</pre>\n<h4><kbd>method</kbd> <code>Sense2Vec.most_similar</code></h4>\n<p>Get the most similar entries in the table. If more than one key is provided, the\naverage of the vectors is used. To make this method faster, see the\n<a href=\"scripts/06_precompute_cache.py\" rel=\"nofollow\">script for precomputing a cache</a> of the nearest\nneighbors.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>keys</code></td>\n<td>unicode / int / iterable\u00a0</td>\n<td>The string or integer key(s) to compare to.</td>\n</tr>\n<tr>\n<td><code>n</code></td>\n<td>int</td>\n<td>The number of similar keys to return. Defaults to <code>10</code>.</td>\n</tr>\n<tr>\n<td><code>batch_size</code></td>\n<td>int</td>\n<td>The batch size to use. Defaults to <code>16</code>.</td>\n</tr>\n<tr>\n<td><strong>RETURNS</strong></td>\n<td>list</td>\n<td>The <code>(key, score)</code> tuples of the most similar vectors.</td>\n</tr></tbody></table>\n<pre><span class=\"n\">most_similar</span> <span class=\"o\">=</span> <span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">most_similar</span><span class=\"p\">(</span><span class=\"s2\">\"natural_language_processing|NOUN\"</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n<span class=\"c1\"># [('machine_learning|NOUN', 0.8986967),</span>\n<span class=\"c1\">#  ('computer_vision|NOUN', 0.8636297),</span>\n<span class=\"c1\">#  ('deep_learning|NOUN', 0.8573361)]</span>\n</pre>\n<h4><kbd>method</kbd> <code>Sense2Vec.get_other_senses</code></h4>\n<p>Find other entries for the same word with a different sense, e.g. <code>\"duck|VERB\"</code>\nfor <code>\"duck|NOUN\"</code>.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>key</code></td>\n<td>unicode / int</td>\n<td>The key to check.</td>\n</tr>\n<tr>\n<td><code>ignore_case</code></td>\n<td>bool</td>\n<td>Check for uppercase, lowercase and titlecase. Defaults to <code>True</code>.</td>\n</tr>\n<tr>\n<td><strong>RETURNS</strong></td>\n<td>list</td>\n<td>The string keys of other entries with different senses.</td>\n</tr></tbody></table>\n<pre><span class=\"n\">other_senses</span> <span class=\"o\">=</span> <span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">get_other_senses</span><span class=\"p\">(</span><span class=\"s2\">\"duck|NOUN\"</span><span class=\"p\">)</span>\n<span class=\"c1\"># ['duck|VERB', 'Duck|ORG', 'Duck|VERB', 'Duck|PERSON', 'Duck|ADJ']</span>\n</pre>\n<h4><kbd>method</kbd> <code>Sense2Vec.get_best_sense</code></h4>\n<p>Find the best-matching sense for a given word based on the available senses and\nfrequency counts. Returns <code>None</code> if no match is found.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>word</code></td>\n<td>unicode</td>\n<td>The word to check.</td>\n</tr>\n<tr>\n<td><code>senses</code></td>\n<td>list</td>\n<td>Optional list of senses to limit the search to. If not set / empty, all senses in the vectors are used.</td>\n</tr>\n<tr>\n<td><code>ignore_case</code></td>\n<td>bool</td>\n<td>Check for uppercase, lowercase and titlecase. Defaults to <code>True</code>.</td>\n</tr>\n<tr>\n<td><strong>RETURNS</strong></td>\n<td>unicode</td>\n<td>The best-matching key or None.</td>\n</tr></tbody></table>\n<pre><span class=\"k\">assert</span> <span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">get_best_sense</span><span class=\"p\">(</span><span class=\"s2\">\"duck\"</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"s2\">\"duck|NOUN\"</span>\n<span class=\"k\">assert</span> <span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">get_best_sense</span><span class=\"p\">(</span><span class=\"s2\">\"duck\"</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s2\">\"VERB\"</span><span class=\"p\">,</span> <span class=\"s2\">\"ADJ\"</span><span class=\"p\">])</span> <span class=\"o\">==</span> <span class=\"s2\">\"duck|VERB\"</span>\n</pre>\n<h4><kbd>method</kbd> <code>Sense2Vec.to_bytes</code></h4>\n<p>Serialize a <code>Sense2Vec</code> object to a bytestring.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>exclude</code></td>\n<td>list</td>\n<td>Names of serialization fields to exclude.</td>\n</tr>\n<tr>\n<td><strong>RETURNS</strong></td>\n<td>bytes</td>\n<td>The serialized <code>Sense2Vec</code> object.</td>\n</tr></tbody></table>\n<pre><span class=\"n\">s2v_bytes</span> <span class=\"o\">=</span> <span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">to_bytes</span><span class=\"p\">()</span>\n</pre>\n<h4><kbd>method</kbd> <code>Sense2Vec.from_bytes</code></h4>\n<p>Load a <code>Sense2Vec</code> object from a bytestring.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>bytes_data</code></td>\n<td>bytes</td>\n<td>The data to load.</td>\n</tr>\n<tr>\n<td><code>exclude</code></td>\n<td>list</td>\n<td>Names of serialization fields to exclude.</td>\n</tr>\n<tr>\n<td><strong>RETURNS</strong></td>\n<td><code>Sense2Vec</code></td>\n<td>The loaded object.</td>\n</tr></tbody></table>\n<pre><span class=\"n\">s2v_bytes</span> <span class=\"o\">=</span> <span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">to_bytes</span><span class=\"p\">()</span>\n<span class=\"n\">new_s2v</span> <span class=\"o\">=</span> <span class=\"n\">Sense2Vec</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">from_bytes</span><span class=\"p\">(</span><span class=\"n\">s2v_bytes</span><span class=\"p\">)</span>\n</pre>\n<h4><kbd>method</kbd> <code>Sense2Vec.to_disk</code></h4>\n<p>Serialize a <code>Sense2Vec</code> object to a directory.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>path</code></td>\n<td>unicode / <code>Path</code></td>\n<td>The path.</td>\n</tr>\n<tr>\n<td><code>exclude</code></td>\n<td>list</td>\n<td>Names of serialization fields to exclude.</td>\n</tr></tbody></table>\n<pre><span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">to_disk</span><span class=\"p\">(</span><span class=\"s2\">\"/path/to/sense2vec\"</span><span class=\"p\">)</span>\n</pre>\n<h4><kbd>method</kbd> <code>Sense2Vec.from_disk</code></h4>\n<p>Load a <code>Sense2Vec</code> object from a directory.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>path</code></td>\n<td>unicode / <code>Path</code></td>\n<td>The path to load from</td>\n</tr>\n<tr>\n<td><code>exclude</code></td>\n<td>list</td>\n<td>Names of serialization fields to exclude.</td>\n</tr>\n<tr>\n<td><strong>RETURNS</strong></td>\n<td><code>Sense2Vec</code></td>\n<td>The loaded object.</td>\n</tr></tbody></table>\n<pre><span class=\"n\">s2v</span><span class=\"o\">.</span><span class=\"n\">to_disk</span><span class=\"p\">(</span><span class=\"s2\">\"/path/to/sense2vec\"</span><span class=\"p\">)</span>\n<span class=\"n\">new_s2v</span> <span class=\"o\">=</span> <span class=\"n\">Sense2Vec</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">from_disk</span><span class=\"p\">(</span><span class=\"s2\">\"/path/to/sense2vec\"</span><span class=\"p\">)</span>\n</pre>\n<hr>\n<h3><kbd>class</kbd> <code>Sense2VecComponent</code></h3>\n<p>The pipeline component to add sense2vec to spaCy pipelines.</p>\n<h4><kbd>method</kbd> <code>Sense2VecComponent.__init__</code></h4>\n<p>Initialize the pipeline component.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>vocab</code></td>\n<td><code>Vocab</code></td>\n<td>The shared <code>Vocab</code>. Mostly used for the shared <code>StringStore</code>.</td>\n</tr>\n<tr>\n<td><code>shape</code></td>\n<td>tuple</td>\n<td>The vector shape.</td>\n</tr>\n<tr>\n<td><code>merge_phrases</code></td>\n<td>bool</td>\n<td>Whether to merge sense2vec phrases into one token. Defaults to <code>False</code>.</td>\n</tr>\n<tr>\n<td><code>lemmatize</code></td>\n<td>bool</td>\n<td>Always look up lemmas if available in the vectors, otherwise default to original word. Defaults to <code>False</code>.</td>\n</tr>\n<tr>\n<td><code>overrides</code></td>\n<td>Optional custom functions to use, mapped to names registred via the registry, e.g. <code>{\"make_key\": \"custom_make_key\"}</code>.</td>\n<td></td>\n</tr>\n<tr>\n<td><strong>RETURNS</strong></td>\n<td><code>Sense2VecComponent</code></td>\n<td>The newly constructed object.</td>\n</tr></tbody></table>\n<pre><span class=\"n\">s2v</span> <span class=\"o\">=</span> <span class=\"n\">Sense2VecComponent</span><span class=\"p\">(</span><span class=\"n\">nlp</span><span class=\"o\">.</span><span class=\"n\">vocab</span><span class=\"p\">)</span>\n</pre>\n<h4><kbd>classmethod</kbd> <code>Sense2VecComponent.from_nlp</code></h4>\n<p>Initialize the component from an nlp object. Mostly used as the component\nfactory for the entry point (see setup.cfg) and to auto-register via the\n<code>@spacy.component</code> decorator.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>nlp</code></td>\n<td><code>Language</code></td>\n<td>The <code>nlp</code> object.</td>\n</tr>\n<tr>\n<td><code>**cfg</code></td>\n<td>-</td>\n<td>Optional config parameters.</td>\n</tr>\n<tr>\n<td><strong>RETURNS</strong></td>\n<td><code>Sense2VecComponent</code></td>\n<td>The newly constructed object.</td>\n</tr></tbody></table>\n<pre><span class=\"n\">s2v</span> <span class=\"o\">=</span> <span class=\"n\">Sense2VecComponent</span><span class=\"o\">.</span><span class=\"n\">from_nlp</span><span class=\"p\">(</span><span class=\"n\">nlp</span><span class=\"p\">)</span>\n</pre>\n<h4><kbd>method</kbd> <code>Sense2VecComponent.__call__</code></h4>\n<p>Process a <code>Doc</code> object with the component. Typically only called as part of the\nspaCy pipeline and not directly.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>doc</code></td>\n<td><code>Doc</code></td>\n<td>The document to process.</td>\n</tr>\n<tr>\n<td><strong>RETURNS</strong></td>\n<td><code>Doc</code></td>\n<td>the processed document.</td>\n</tr></tbody></table>\n<h4><kbd>method</kbd> <code>Sense2Vec.init_component</code></h4>\n<p>Register the component-specific extension attributes here and only if the\ncomponent is added to the pipeline and used \u2013 otherwise, tokens will still get\nthe attributes even if the component is only created and not added.</p>\n<h4><kbd>method</kbd> <code>Sense2VecComponent.to_bytes</code></h4>\n<p>Serialize the component to a bytestring. Also called when the component is added\nto the pipeline and you run <code>nlp.to_bytes</code>.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>RETURNS</strong></td>\n<td>bytes</td>\n<td>The serialized component.</td>\n</tr></tbody></table>\n<h4><kbd>method</kbd> <code>Sense2VecComponent.from_bytes</code></h4>\n<p>Load a component from a bytestring. Also called when you run <code>nlp.from_bytes</code>.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>bytes_data</code></td>\n<td>bytes</td>\n<td>The data to load.</td>\n</tr>\n<tr>\n<td><strong>RETURNS</strong></td>\n<td><code>Sense2VecComponent</code></td>\n<td>The loaded object.</td>\n</tr></tbody></table>\n<h4><kbd>method</kbd> <code>Sense2VecComponent.to_disk</code></h4>\n<p>Serialize the component to a directory. Also called when the component is added\nto the pipeline and you run <code>nlp.to_disk</code>.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>path</code></td>\n<td>unicode / <code>Path</code></td>\n<td>The path.</td>\n</tr></tbody></table>\n<h4><kbd>method</kbd> <code>Sense2VecComponent.from_disk</code></h4>\n<p>Load a <code>Sense2Vec</code> object from a directory. Also called when you run\n<code>nlp.from_disk</code>.</p>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>path</code></td>\n<td>unicode / <code>Path</code></td>\n<td>The path to load from</td>\n</tr>\n<tr>\n<td><strong>RETURNS</strong></td>\n<td><code>Sense2VecComponent</code></td>\n<td>The loaded object.</td>\n</tr></tbody></table>\n<hr>\n<h3><kbd>class</kbd> <code>registry</code></h3>\n<p>Function registry (powered by\n<a href=\"https://github.com/explosion/catalogue\" rel=\"nofollow\"><code>catalogue</code></a>) to easily customize the\nfunctions used to generate keys and phrases. Allows you to decorate and name\ncustom functions, swap them out and serialize the custom names when you save out\nthe model. The following registry options are available:</p>\n<table>\n<thead>\n<tr>\n<th>Name</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>registry.make_key</code></td>\n<td>Given a <code>word</code> and <code>sense</code>, return a string of the key, e.g. `\"word</td>\n</tr>\n<tr>\n<td><code>registry.split_key</code></td>\n<td>Given a string key, return a <code>(word, sense)</code> tuple.</td>\n</tr>\n<tr>\n<td><code>registry.make_spacy_key</code></td>\n<td>Given a spaCy object (<code>Token</code> or <code>Span</code>) and a boolean <code>prefer_ents</code> keyword argument (whether to prefer the entity label for single tokens), return a <code>(word, sense)</code> tuple. Used in extension attributes to generate a key for tokens and spans.</td>\n</tr>\n<tr>\n<td><code>registry.get_phrases</code></td>\n<td>Given a spaCy <code>Doc</code>, return a list of <code>Span</code> objects used for sense2vec phrases (typically noun phrases and named entities).</td>\n</tr>\n<tr>\n<td><code>registry.merge_phrases</code></td>\n<td>Given a spaCy <code>Doc</code>, get all sense2vec phrases and merge them into single tokens.\u00a0</td>\n</tr></tbody></table>\n<p>Each registry has a <code>register</code> method that can be used as a function decorator\nand takes one argument, the name of the custom function.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">sense2vec</span> <span class=\"kn\">import</span> <span class=\"n\">registry</span>\n\n<span class=\"nd\">@registry</span><span class=\"o\">.</span><span class=\"n\">make_key</span><span class=\"o\">.</span><span class=\"n\">register</span><span class=\"p\">(</span><span class=\"s2\">\"custom\"</span><span class=\"p\">)</span>\n<span class=\"k\">def</span> <span class=\"nf\">custom_make_key</span><span class=\"p\">(</span><span class=\"n\">word</span><span class=\"p\">,</span> <span class=\"n\">sense</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"sa\">f</span><span class=\"s2\">\"</span><span class=\"si\">{</span><span class=\"n\">word</span><span class=\"si\">}</span><span class=\"s2\">###</span><span class=\"si\">{</span><span class=\"n\">sense</span><span class=\"si\">}</span><span class=\"s2\">\"</span>\n\n<span class=\"nd\">@registry</span><span class=\"o\">.</span><span class=\"n\">split_key</span><span class=\"o\">.</span><span class=\"n\">register</span><span class=\"p\">(</span><span class=\"s2\">\"custom\"</span><span class=\"p\">)</span>\n<span class=\"k\">def</span> <span class=\"nf\">custom_split_key</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">):</span>\n    <span class=\"n\">word</span><span class=\"p\">,</span> <span class=\"n\">sense</span> <span class=\"o\">=</span> <span class=\"n\">key</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s2\">\"###\"</span><span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"n\">word</span><span class=\"p\">,</span> <span class=\"n\">sense</span>\n</pre>\n<p>When initializing the <code>Sense2Vec</code> object, you can now pass in a dictionary of\noverrides with the names of your custom registered functions.</p>\n<pre><span class=\"n\">overrides</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">\"make_key\"</span><span class=\"p\">:</span> <span class=\"s2\">\"custom\"</span><span class=\"p\">,</span> <span class=\"s2\">\"split_key\"</span><span class=\"p\">:</span> <span class=\"s2\">\"custom\"</span><span class=\"p\">}</span>\n<span class=\"n\">s2v</span> <span class=\"o\">=</span> <span class=\"n\">Sense2Vec</span><span class=\"p\">(</span><span class=\"n\">overrides</span><span class=\"o\">=</span><span class=\"n\">overrides</span><span class=\"p\">)</span>\n</pre>\n<p>This makes it easy to experiment with different strategies and serializing the\nstrategies as plain strings (instead of having to pass around and/or pickle the\nfunctions themselves).</p>\n<h2>\ud83d\ude82 Training your own sense2vec vectors</h2>\n<p>The <a href=\"/scripts\" rel=\"nofollow\"><code>/scripts</code></a> directory contains command line utilities for\npreprocessing text and training your own vectors.</p>\n<h3>Requirements</h3>\n<p>To train your own sense2vec vectors, you'll need the following:</p>\n<ul>\n<li>A <strong>very large</strong> source of raw text (ideally more than you'd use for word2vec,\nsince the senses make the vocabulary more sparse). We recommend at least 1\nbillion words.</li>\n<li>A <a href=\"https://spacy.io/models\" rel=\"nofollow\">pretrained spaCy model</a> that assigns\npart-of-speech tags, dependencies and named entities, and populates the\n<code>doc.noun_chunks</code>. If the language you need doesn't provide a built in\n<a href=\"https://spacy.io/usage/adding-languages#syntax-iterators\" rel=\"nofollow\">syntax iterator for noun phrases</a>,\nyou'll need to write your own. (The <code>doc.noun_chunks</code> and <code>doc.ents</code> are what\nsense2vec uses to determine what's a phrase.)</li>\n<li><a href=\"https://github.com/stanfordnlp/GloVe\" rel=\"nofollow\">GloVe</a> or\n<a href=\"https://github.com/facebookresearch/fastText\" rel=\"nofollow\">fastText</a> installed and built.\nYou should be able to clone the repo and run <code>make</code> in the respective\ndirectory.</li>\n</ul>\n<h3>Step-by-step process</h3>\n<p>The training process is split up into several steps to allow you to resume at\nany given point. Processing scripts are designed to operate on single files,\nmaking it easy to paralellize the work. The scripts in this repo require either\n<a href=\"https://github.com/stanfordnlp/GloVe\" rel=\"nofollow\">Glove</a> or\n<a href=\"https://github.com/facebookresearch/fastText\" rel=\"nofollow\">fastText</a>, which you need to\nclone and <code>make</code>.</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Script</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>1.</strong></td>\n<td><a href=\"scripts/01_parse.py\" rel=\"nofollow\"><code>01_parse.py</code></a></td>\n<td>Use spaCy to parse the raw text and output binary collections of <code>Doc</code> objects (see <a href=\"https://spacy.io/api/docbin\" rel=\"nofollow\"><code>DocBin</code></a>).</td>\n</tr>\n<tr>\n<td><strong>2.</strong></td>\n<td><a href=\"scripts/02_preprocess.py\" rel=\"nofollow\"><code>02_preprocess.py</code></a></td>\n<td>Load a collection of parsed <code>Doc</code> objects produced in the previous step and output text files in the sense2vec format (one sentence per line and merged phrases with senses).</td>\n</tr>\n<tr>\n<td><strong>3.</strong></td>\n<td><a href=\"scripts/03_glove_build_counts.py\" rel=\"nofollow\"><code>03_glove_build_counts.py</code></a></td>\n<td>Use <a href=\"https://github.com/stanfordnlp/GloVe\" rel=\"nofollow\">GloVe</a> to build the vocabulary and counts. Skip this step if you're using Word2Vec via <a href=\"https://github.com/facebookresearch/fastText\" rel=\"nofollow\">FastText</a>.</td>\n</tr>\n<tr>\n<td><strong>4.</strong></td>\n<td><a href=\"scripts/04_glove_train_vectors.py\" rel=\"nofollow\"><code>04_glove_train_vectors.py</code></a><br><a href=\"scripts/04_fasttext_train_vectors.py\" rel=\"nofollow\"><code>04_fasttext_train_vectors.py</code></a></td>\n<td>Use <a href=\"https://github.com/stanfordnlp/GloVe\" rel=\"nofollow\">GloVe</a> or <a href=\"https://github.com/facebookresearch/fastText\" rel=\"nofollow\">FastText</a> to train vectors.</td>\n</tr>\n<tr>\n<td><strong>5.</strong></td>\n<td><a href=\"scripts/05_export.py\" rel=\"nofollow\"><code>05_export.py</code></a></td>\n<td>Load the vectors and frequencies and output a sense2vec component that can be loaded via <code>Sense2Vec.from_disk</code>.</td>\n</tr>\n<tr>\n<td><strong>6.</strong></td>\n<td><a href=\"scripts/06_precompute_cache.py\" rel=\"nofollow\"><code>06_precompute_cache.py</code></a></td>\n<td><strong>Optional:</strong> Precompute nearest-neighbor queries for every entry in the vocab to make <code>Sense2Vec.most_similar</code> faster.</td>\n</tr></tbody></table>\n<p>For more detailed documentation of the scripts, check out the source or run them\nwith <code>--help</code>. For example, <code>python scripts/01_parse.py --help</code>.</p>\n<h2>\ud83c\udf73 Prodigy recipes</h2>\n<p>This package also seamlessly integrates with the <a href=\"https://prodi.gy\" rel=\"nofollow\">Prodigy</a>\nannotation tool and exposes recipes for using sense2vec vectors to quickly\ngenerate lists of multi-word phrases and bootstrap NER annotations. To use a\nrecipe, <code>sense2vec</code> needs to be installed in the same environment as Prodigy.\nFor an example of a real-world use case, check out this\n<a href=\"https://github.com/explosion/projects/tree/master/ner-fashion-brands\" rel=\"nofollow\">NER project</a>\nwith downloadable datasets.</p>\n<p>The following recipes are available \u2013 see below for more detailed docs.</p>\n<table>\n<thead>\n<tr>\n<th>Recipe</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><a href=\"#recipe-sense2vecteach\" rel=\"nofollow\"><code>sense2vec.teach</code></a></td>\n<td>Bootstrap a terminology list using sense2vec.</td>\n</tr>\n<tr>\n<td><a href=\"#recipe-sense2vecto-patterns\" rel=\"nofollow\"><code>sense2vec.to-patterns</code></a></td>\n<td>Convert phrases dataset to token-based match patterns.</td>\n</tr>\n<tr>\n<td><a href=\"#recipe-sense2veceval\" rel=\"nofollow\"><code>sense2vec.eval</code></a></td>\n<td>Evaluate a sense2vec model by asking about phrase triples.</td>\n</tr>\n<tr>\n<td><a href=\"#recipe-sense2veceval-most-similar\" rel=\"nofollow\"><code>sense2vec.eval-most-similar</code></a></td>\n<td>Evaluate a sense2vec model by correcting the most similar entries.</td>\n</tr>\n<tr>\n<td><a href=\"#recipe-sense2veceval-ab\" rel=\"nofollow\"><code>sense2vec.eval-ab</code></a></td>\n<td>Perform an A/B evaluation of two pretrained sense2vec vector models.</td>\n</tr></tbody></table>\n<h3><kbd>recipe</kbd> <code>sense2vec.teach</code></h3>\n<p>Bootstrap a terminology list using sense2vec. Prodigy will suggest similar terms\nbased on the the most similar phrases from sense2vec, and the suggestions will\nbe adjusted as you annotate and accept similar phrases. For each seed term, the\nbest matching sense according to the sense2vec vectors will be used.</p>\n<pre>prodigy sense2vec.teach <span class=\"o\">[</span>dataset<span class=\"o\">]</span> <span class=\"o\">[</span>vectors_path<span class=\"o\">]</span> <span class=\"o\">[</span>--seeds<span class=\"o\">]</span> <span class=\"o\">[</span>--threshold<span class=\"o\">]</span>\n<span class=\"o\">[</span>--n-similar<span class=\"o\">]</span> <span class=\"o\">[</span>--batch-size<span class=\"o\">]</span> <span class=\"o\">[</span>--resume<span class=\"o\">]</span>\n</pre>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>dataset</code></td>\n<td>positional</td>\n<td>Dataset to save annotations to.</td>\n</tr>\n<tr>\n<td><code>vectors_path</code></td>\n<td>positional</td>\n<td>Path to pretrained sense2vec vectors.</td>\n</tr>\n<tr>\n<td><code>--seeds</code>, <code>-s</code></td>\n<td>option</td>\n<td>One or more comma-separated seed phrases.</td>\n</tr>\n<tr>\n<td><code>--threshold</code>, <code>-t</code></td>\n<td>option</td>\n<td>Similarity threshold. Defaults to <code>0.85</code>.</td>\n</tr>\n<tr>\n<td><code>--n-similar</code>, <code>-n</code></td>\n<td>option</td>\n<td>Number of similar items to get at once.</td>\n</tr>\n<tr>\n<td><code>--batch-size</code>, <code>-b</code></td>\n<td>option</td>\n<td>Batch size for submitting annotations.</td>\n</tr>\n<tr>\n<td><code>--resume</code>, <code>-R</code></td>\n<td>flag</td>\n<td>Resume from an existing phrases dataset.</td>\n</tr></tbody></table>\n<h4>Example</h4>\n<pre>prodigy sense2vec.teach tech_phrases /path/to/s2v_reddit_2015_md\n--seeds <span class=\"s2\">\"natural language processing, machine learning, artificial intelligence\"</span>\n</pre>\n<h3><kbd>recipe</kbd> <code>sense2vec.to-patterns</code></h3>\n<p>Convert a dataset of phrases collected with <code>sense2vec.teach</code> to token-based\nmatch patterns that can be used with\n<a href=\"https://spacy.io/usage/rule-based-matching#entityruler\" rel=\"nofollow\">spaCy's <code>EntityRuler</code></a>\nor recipes like <code>ner.match</code>. If no output file is specified, the patterns are\nwritten to stdout. The examples are tokenized so that multi-token terms are\nrepresented correctly, e.g.:\n<code>{\"label\": \"SHOE_BRAND\", \"pattern\": [{ \"LOWER\": \"new\" }, { \"LOWER\": \"balance\" }]}</code>.</p>\n<pre>prodigy sense2vec.to-patterns <span class=\"o\">[</span>dataset<span class=\"o\">]</span> <span class=\"o\">[</span>spacy_model<span class=\"o\">]</span> <span class=\"o\">[</span>label<span class=\"o\">]</span> <span class=\"o\">[</span>--output-file<span class=\"o\">]</span>\n<span class=\"o\">[</span>--case-sensitive<span class=\"o\">]</span> <span class=\"o\">[</span>--dry<span class=\"o\">]</span>\n</pre>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>dataset</code></td>\n<td>positional</td>\n<td>Phrase dataset to convert.</td>\n</tr>\n<tr>\n<td><code>spacy_model</code></td>\n<td>positional</td>\n<td>spaCy model for tokenization.</td>\n</tr>\n<tr>\n<td><code>label</code></td>\n<td>positional</td>\n<td>Label to apply to all patterns.</td>\n</tr>\n<tr>\n<td><code>--output-file</code>, <code>-o</code></td>\n<td>option</td>\n<td>Optional output file. Defaults to stdout.</td>\n</tr>\n<tr>\n<td><code>--case-sensitive</code>, <code>-CS</code></td>\n<td>flag</td>\n<td>Make patterns case-sensitive.</td>\n</tr>\n<tr>\n<td><code>--dry</code>, <code>-D</code></td>\n<td>flag</td>\n<td>Perform a dry run and don't output anything.</td>\n</tr></tbody></table>\n<h4>Example</h4>\n<pre>prodigy sense2vec.to-patterns tech_phrases en_core_web_sm TECHNOLOGY\n--output-file /path/to/patterns.jsonl\n</pre>\n<h3><kbd>recipe</kbd> <code>sense2vec.eval</code></h3>\n<p>Evaluate a sense2vec model by asking about phrase triples: is word A more\nsimilar to word B, or to word C? If the human mostly agrees with the model, the\nvectors model is good. The recipe will only ask about vectors with the same\nsense and supports different example selection strategies.</p>\n<pre>prodigy sense2vec.eval <span class=\"o\">[</span>dataset<span class=\"o\">]</span> <span class=\"o\">[</span>vectors_path<span class=\"o\">]</span> <span class=\"o\">[</span>--strategy<span class=\"o\">]</span> <span class=\"o\">[</span>--senses<span class=\"o\">]</span>\n<span class=\"o\">[</span>--exclude-senses<span class=\"o\">]</span> <span class=\"o\">[</span>--n-freq<span class=\"o\">]</span> <span class=\"o\">[</span>--threshold<span class=\"o\">]</span> <span class=\"o\">[</span>--batch-size<span class=\"o\">]</span> <span class=\"o\">[</span>--eval-whole<span class=\"o\">]</span>\n<span class=\"o\">[</span>--eval-only<span class=\"o\">]</span> <span class=\"o\">[</span>--show-scores<span class=\"o\">]</span>\n</pre>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>dataset</code></td>\n<td>positional</td>\n<td>Dataset to save annotations to.</td>\n</tr>\n<tr>\n<td><code>vectors_path</code></td>\n<td>positional</td>\n<td>Path to pretrained sense2vec vectors.</td>\n</tr>\n<tr>\n<td><code>--strategy</code>, <code>-st</code></td>\n<td>option</td>\n<td>Example selection strategy. <code>most similar</code> (default) or <code>random</code>.</td>\n</tr>\n<tr>\n<td><code>--senses</code>, <code>-s</code></td>\n<td>option</td>\n<td>Comma-separated list of senses to limit the selection to. If not set, all senses in the vectors will be used.</td>\n</tr>\n<tr>\n<td><code>--exclude-senses</code>, <code>-es</code></td>\n<td>option</td>\n<td>Comma-separated list of senses to exclude. See <code>prodigy_recipes.EVAL_EXCLUDE_SENSES</code> fro the defaults.</td>\n</tr>\n<tr>\n<td><code>--n-freq</code>, <code>-f</code></td>\n<td>option</td>\n<td>Number of most frequent entries to limit to.</td>\n</tr>\n<tr>\n<td><code>--threshold</code>, <code>-t</code></td>\n<td>option</td>\n<td>Minimum similarity threshold to consider examples.</td>\n</tr>\n<tr>\n<td><code>--batch-size</code>, <code>-b</code></td>\n<td>option</td>\n<td>Batch size to use.</td>\n</tr>\n<tr>\n<td><code>--eval-whole</code>, <code>-E</code></td>\n<td>flag</td>\n<td>Evaluate the whole dataset instead of the current session.</td>\n</tr>\n<tr>\n<td><code>--eval-only</code>, <code>-O</code></td>\n<td>flag</td>\n<td>Don't annotate, only evaluate the current dataset.</td>\n</tr>\n<tr>\n<td><code>--show-scores</code>, <code>-S</code></td>\n<td>flag</td>\n<td>Show all scores for debugging.</td>\n</tr></tbody></table>\n<h4>Strategies</h4>\n<table>\n<thead>\n<tr>\n<th>Name</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>most_similar</code></td>\n<td>Pick a random word from a random sense and get its most similar entries of the same sense. Ask about the similarity to the last and middle entry from that selection.</td>\n</tr>\n<tr>\n<td><code>most_least_similar</code></td>\n<td>Pick a random word from a random sense and get the least similar entry from its most similar entries, and then the last most similar entry of that.</td>\n</tr>\n<tr>\n<td><code>random</code></td>\n<td>Pick a random sample of 3 words from the same random sense.</td>\n</tr></tbody></table>\n<h4>Example</h4>\n<pre>prodigy sense2vec.eval vectors_eval /path/to/s2v_reddit_2015_md\n--senses NOUN,ORG,PRODUCT --threshold <span class=\"m\">0</span>.5\n</pre>\n<p><img alt=\"UI preview of sense2vec.eval\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/319b1e2b23aead5263dfb03be58121bb57cebbc3/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31333634333233392f36373939343231322d36363863663430302d666334342d313165392d386665322d6266323634616533326230612e706e67\"></p>\n<h3><kbd>recipe</kbd> <code>sense2vec.eval-most-similar</code></h3>\n<p>Evaluate a vectors model by looking at the most similar entries it returns for a\nrandom phrase and unselecting the mistakes.</p>\n<pre>prodigy sense2vec.eval <span class=\"o\">[</span>dataset<span class=\"o\">]</span> <span class=\"o\">[</span>vectors_path<span class=\"o\">]</span> <span class=\"o\">[</span>--senses<span class=\"o\">]</span> <span class=\"o\">[</span>--exclude-senses<span class=\"o\">]</span>\n<span class=\"o\">[</span>--n-freq<span class=\"o\">]</span> <span class=\"o\">[</span>--n-similar<span class=\"o\">]</span> <span class=\"o\">[</span>--batch-size<span class=\"o\">]</span> <span class=\"o\">[</span>--eval-whole<span class=\"o\">]</span> <span class=\"o\">[</span>--eval-only<span class=\"o\">]</span>\n<span class=\"o\">[</span>--show-scores<span class=\"o\">]</span>\n</pre>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>dataset</code></td>\n<td>positional</td>\n<td>Dataset to save annotations to.</td>\n</tr>\n<tr>\n<td><code>vectors_path</code></td>\n<td>positional</td>\n<td>Path to pretrained sense2vec vectors.</td>\n</tr>\n<tr>\n<td><code>--senses</code>, <code>-s</code></td>\n<td>option</td>\n<td>Comma-separated list of senses to limit the selection to. If not set, all senses in the vectors will be used.</td>\n</tr>\n<tr>\n<td><code>--exclude-senses</code>, <code>-es</code></td>\n<td>option</td>\n<td>Comma-separated list of senses to exclude. See <code>prodigy_recipes.EVAL_EXCLUDE_SENSES</code> fro the defaults.</td>\n</tr>\n<tr>\n<td><code>--n-freq</code>, <code>-f</code></td>\n<td>option</td>\n<td>Number of most frequent entries to limit to.</td>\n</tr>\n<tr>\n<td><code>--n-similar</code>, <code>-n</code></td>\n<td>option</td>\n<td>Number of similar items to check. Defaults to <code>10</code>.</td>\n</tr>\n<tr>\n<td><code>--batch-size</code>, <code>-b</code></td>\n<td>option</td>\n<td>Batch size to use.</td>\n</tr>\n<tr>\n<td><code>--eval-whole</code>, <code>-E</code></td>\n<td>flag</td>\n<td>Evaluate the whole dataset instead of the current session.</td>\n</tr>\n<tr>\n<td><code>--eval-only</code>, <code>-O</code></td>\n<td>flag</td>\n<td>Don't annotate, only evaluate the current dataset.</td>\n</tr>\n<tr>\n<td><code>--show-scores</code>, <code>-S</code></td>\n<td>flag</td>\n<td>Show all scores for debugging.</td>\n</tr></tbody></table>\n<pre>prodigy sense2vec.eval-most-similar vectors_eval_sim /path/to/s2v_reddit_2015_md\n--senses NOUN,ORG,PRODUCT\n</pre>\n<h3><kbd>recipe</kbd> <code>sense2vec.eval-ab</code></h3>\n<p>Perform an A/B evaluation of two pretrained sense2vec vector models by comparing\nthe most similar entries they return for a random phrase. The UI shows two\nrandomized options with the most similar entries of each model and highlights\nthe phrases that differ. At the end of the annotation session the overall stats\nand preferred model are shown.</p>\n<pre>prodigy sense2vec.eval <span class=\"o\">[</span>dataset<span class=\"o\">]</span> <span class=\"o\">[</span>vectors_path_a<span class=\"o\">]</span> <span class=\"o\">[</span>vectors_path_b<span class=\"o\">]</span> <span class=\"o\">[</span>--senses<span class=\"o\">]</span>\n<span class=\"o\">[</span>--exclude-senses<span class=\"o\">]</span> <span class=\"o\">[</span>--n-freq<span class=\"o\">]</span> <span class=\"o\">[</span>--n-similar<span class=\"o\">]</span> <span class=\"o\">[</span>--batch-size<span class=\"o\">]</span> <span class=\"o\">[</span>--eval-whole<span class=\"o\">]</span>\n<span class=\"o\">[</span>--eval-only<span class=\"o\">]</span> <span class=\"o\">[</span>--show-mapping<span class=\"o\">]</span>\n</pre>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>dataset</code></td>\n<td>positional</td>\n<td>Dataset to save annotations to.</td>\n</tr>\n<tr>\n<td><code>vectors_path_a</code></td>\n<td>positional</td>\n<td>Path to pretrained sense2vec vectors.</td>\n</tr>\n<tr>\n<td><code>vectors_path_b</code></td>\n<td>positional</td>\n<td>Path to pretrained sense2vec vectors.</td>\n</tr>\n<tr>\n<td><code>--senses</code>, <code>-s</code></td>\n<td>option</td>\n<td>Comma-separated list of senses to limit the selection to. If not set, all senses in the vectors will be used.</td>\n</tr>\n<tr>\n<td><code>--exclude-senses</code>, <code>-es</code></td>\n<td>option</td>\n<td>Comma-separated list of senses to exclude. See <code>prodigy_recipes.EVAL_EXCLUDE_SENSES</code> fro the defaults.</td>\n</tr>\n<tr>\n<td><code>--n-freq</code>, <code>-f</code></td>\n<td>option</td>\n<td>Number of most frequent entries to limit to.</td>\n</tr>\n<tr>\n<td><code>--n-similar</code>, <code>-n</code></td>\n<td>option</td>\n<td>Number of similar items to check. Defaults to <code>10</code>.</td>\n</tr>\n<tr>\n<td><code>--batch-size</code>, <code>-b</code></td>\n<td>option</td>\n<td>Batch size to use.</td>\n</tr>\n<tr>\n<td><code>--eval-whole</code>, <code>-E</code></td>\n<td>flag</td>\n<td>Evaluate the whole dataset instead of the current session.</td>\n</tr>\n<tr>\n<td><code>--eval-only</code>, <code>-O</code></td>\n<td>flag</td>\n<td>Don't annotate, only evaluate the current dataset.</td>\n</tr>\n<tr>\n<td><code>--show-mapping</code>, <code>-S</code></td>\n<td>flag</td>\n<td>Show which models are option 1 and option 2 in the UI (for debugging).</td>\n</tr></tbody></table>\n<pre>prodigy sense2vec.eval-ab vectors_eval_sim /path/to/s2v_reddit_2015_md /path/to/s2v_reddit_2019_md --senses NOUN,ORG,PRODUCT\n</pre>\n<p><img alt=\"UI preview of sense2vec.eval-ab\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1d9c0a0cd3400bfb6e5c594659536557bcf5008d/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31333634333233392f36383038383531342d34366432313738302d666536302d313165392d396232392d6665333133626232313534642e706e67\"></p>\n<h2>Pretrained vectors</h2>\n<p>The pretrained Reddit vectors support the following \"senses\", either\npart-of-speech tags or entity labels. For more details, see spaCy's\n<a href=\"https://spacy.io/api/annotation\" rel=\"nofollow\">annotation scheme overview</a>.</p>\n<table>\n<thead>\n<tr>\n<th>Tag</th>\n<th>Description</th>\n<th>Examples</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>ADJ</code></td>\n<td>adjective</td>\n<td>big, old, green</td>\n</tr>\n<tr>\n<td><code>ADP</code></td>\n<td>adposition</td>\n<td>in, to, during</td>\n</tr>\n<tr>\n<td><code>ADV</code></td>\n<td>adverb</td>\n<td>very, tomorrow, down, where</td>\n</tr>\n<tr>\n<td><code>AUX</code></td>\n<td>auxiliary\u00a0</td>\n<td>is, has (done), will (do)</td>\n</tr>\n<tr>\n<td><code>CONJ</code></td>\n<td>conjunction</td>\n<td>and, or, but</td>\n</tr>\n<tr>\n<td><code>DET</code></td>\n<td>determiner</td>\n<td>a, an, the</td>\n</tr>\n<tr>\n<td><code>INTJ</code></td>\n<td>interjection</td>\n<td>psst, ouch, bravo, hello</td>\n</tr>\n<tr>\n<td><code>NOUN</code></td>\n<td>noun</td>\n<td>girl, cat, tree, air, beauty</td>\n</tr>\n<tr>\n<td><code>NUM</code></td>\n<td>numeral</td>\n<td>1, 2017, one, seventy-seven, MMXIV</td>\n</tr>\n<tr>\n<td><code>PART</code></td>\n<td>particle</td>\n<td>'s, not</td>\n</tr>\n<tr>\n<td><code>PRON</code></td>\n<td>pronoun</td>\n<td>I, you, he, she, myself, somebody</td>\n</tr>\n<tr>\n<td><code>PROPN</code></td>\n<td>proper noun</td>\n<td>Mary, John, London, NATO, HBO</td>\n</tr>\n<tr>\n<td><code>PUNCT</code></td>\n<td>punctuation</td>\n<td>, ? ( )</td>\n</tr>\n<tr>\n<td><code>SCONJ</code></td>\n<td>subordinating conjunction</td>\n<td>if, while, that</td>\n</tr>\n<tr>\n<td><code>SYM</code></td>\n<td>symbol</td>\n<td>$, %, =, :), \ud83d\ude1d</td>\n</tr>\n<tr>\n<td><code>VERB</code></td>\n<td>verb</td>\n<td>run, runs, running, eat, ate, eating</td>\n</tr></tbody></table>\n<table>\n<thead>\n<tr>\n<th>Entity Label</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>PERSON</code></td>\n<td>People, including fictional.</td>\n</tr>\n<tr>\n<td><code>NORP</code></td>\n<td>Nationalities or religious or political groups.</td>\n</tr>\n<tr>\n<td><code>FACILITY</code></td>\n<td>Buildings, airports, highways, bridges, etc.</td>\n</tr>\n<tr>\n<td><code>ORG</code></td>\n<td>Companies, agencies, institutions, etc.</td>\n</tr>\n<tr>\n<td><code>GPE</code></td>\n<td>Countries, cities, states.</td>\n</tr>\n<tr>\n<td><code>LOC</code></td>\n<td>Non-GPE locations, mountain ranges, bodies of water.</td>\n</tr>\n<tr>\n<td><code>PRODUCT</code></td>\n<td>Objects, vehicles, foods, etc. (Not services.)</td>\n</tr>\n<tr>\n<td><code>EVENT</code></td>\n<td>Named hurricanes, battles, wars, sports events, etc.</td>\n</tr>\n<tr>\n<td><code>WORK_OF_ART</code></td>\n<td>Titles of books, songs, etc.</td>\n</tr>\n<tr>\n<td><code>LANGUAGE</code></td>\n<td>Any named language.</td>\n</tr></tbody></table>\n\n          </div>"}, "last_serial": 6182600, "releases": {"0.1.0": [], "0.3.0": [{"comment_text": "", "digests": {"md5": "309d533d6d3d1e72e283a178d689ecbf", "sha256": "5a93601c986d31b6a792b587b319a7be1e7c6149e62c838ff5c4d5d0b0ed4a6b"}, "downloads": -1, "filename": "sense2vec-0.3.0.tar.gz", "has_sig": false, "md5_digest": "309d533d6d3d1e72e283a178d689ecbf", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 198417, "upload_time": "2016-09-22T16:42:04", "upload_time_iso_8601": "2016-09-22T16:42:04.963702Z", "url": "https://files.pythonhosted.org/packages/95/9a/045e3eda78665e550044079956e93ac012111d2a50bbd0733c2e3dcc10d5/sense2vec-0.3.0.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "d98e3a543e22c9aef55db87305dc137f", "sha256": "7172cdd6454e705444182a9b134af3b7d55284da735b98a03c7b666927567ab9"}, "downloads": -1, "filename": "sense2vec-0.4.0.tar.gz", "has_sig": false, "md5_digest": "d98e3a543e22c9aef55db87305dc137f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 208010, "upload_time": "2016-09-22T19:15:44", "upload_time_iso_8601": "2016-09-22T19:15:44.601426Z", "url": "https://files.pythonhosted.org/packages/ad/13/3497c7b0121f6c17c3163cf1c3bfb5614682381d35d8efe0865316f9f628/sense2vec-0.4.0.tar.gz", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "008c538288f0d19ace559f10655e6016", "sha256": "1d04abd4cf41ae8ab2caac545e16d7c2a9f57f8043457219f8eacd700e332536"}, "downloads": -1, "filename": "sense2vec-0.5.0.tar.gz", "has_sig": false, "md5_digest": "008c538288f0d19ace559f10655e6016", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 211919, "upload_time": "2016-09-22T22:02:08", "upload_time_iso_8601": "2016-09-22T22:02:08.026727Z", "url": "https://files.pythonhosted.org/packages/da/92/b238116c128db1af9078e5f68a10562039f32aaa8eef4860060af5ce15e9/sense2vec-0.5.0.tar.gz", "yanked": false}], "0.6.0": [{"comment_text": "", "digests": {"md5": "6f6b6526bafdf2355c6a501daa3c513b", "sha256": "ae7973adb9d970bd2aea5c430c19023e2fbd950735e6e148490b1f14ee2a7bbd"}, "downloads": -1, "filename": "sense2vec-0.6.0.tar.gz", "has_sig": false, "md5_digest": "6f6b6526bafdf2355c6a501daa3c513b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 210692, "upload_time": "2016-09-29T20:06:26", "upload_time_iso_8601": "2016-09-29T20:06:26.922187Z", "url": "https://files.pythonhosted.org/packages/96/d6/0c11500a9606b11b1f0660a32f5d3d912417dbf5ced62fc71506fa9302b1/sense2vec-0.6.0.tar.gz", "yanked": false}], "1.0.0": [{"comment_text": "", "digests": {"md5": "7befc7e57cde9b8528e1d25e1ac2d3ae", "sha256": "09804fe847c73cff685f4a46b179a362a4334e2d44df89ee91bea47ba747c93b"}, "downloads": -1, "filename": "sense2vec-1.0.0.tar.gz", "has_sig": false, "md5_digest": "7befc7e57cde9b8528e1d25e1ac2d3ae", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 54667, "upload_time": "2019-11-22T15:07:13", "upload_time_iso_8601": "2019-11-22T15:07:13.820567Z", "url": "https://files.pythonhosted.org/packages/2e/bb/cc59c832871cc2feffb4e20733854120f8d1340b6fc7e4359afab1d1ef47/sense2vec-1.0.0.tar.gz", "yanked": false}], "1.0.0a0": [{"comment_text": "", "digests": {"md5": "66d265c7439f4ee84803f259a93f5a12", "sha256": "cca1fe7292f634b7b9d2a2416b982242e0ef2fabadacdf75e5fe2d47b4d6b928"}, "downloads": -1, "filename": "sense2vec-1.0.0a0.tar.gz", "has_sig": false, "md5_digest": "66d265c7439f4ee84803f259a93f5a12", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 311784, "upload_time": "2018-04-08T15:30:37", "upload_time_iso_8601": "2018-04-08T15:30:37.561177Z", "url": "https://files.pythonhosted.org/packages/28/4a/a1d9a28545adc839789c1442e7314cb0c70b8657a885f9e5b287fade7814/sense2vec-1.0.0a0.tar.gz", "yanked": false}], "1.0.0a1": [{"comment_text": "", "digests": {"md5": "f679d6f10f7daa6be679964c12210c53", "sha256": "d68bc79d9d17da0ddf03ad4a4c8ca1728711e39fc420a249de1fb8bc87b1d2f3"}, "downloads": -1, "filename": "sense2vec-1.0.0a1.tar.gz", "has_sig": false, "md5_digest": "f679d6f10f7daa6be679964c12210c53", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 335351, "upload_time": "2019-09-12T14:12:18", "upload_time_iso_8601": "2019-09-12T14:12:18.025060Z", "url": "https://files.pythonhosted.org/packages/15/93/4a694a6ac301d81fa209f9039303e9f58d45af4d9ab0f99359bd41c123fa/sense2vec-1.0.0a1.tar.gz", "yanked": false}], "1.0.0a10": [{"comment_text": "", "digests": {"md5": "1652d38490c9f33feee703d31e13471b", "sha256": "781508f83de196a6b800fb739216307f3db0635c0e68af9c5b428a597e4ced7a"}, "downloads": -1, "filename": "sense2vec-1.0.0a10.tar.gz", "has_sig": false, "md5_digest": "1652d38490c9f33feee703d31e13471b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 53794, "upload_time": "2019-11-21T20:00:26", "upload_time_iso_8601": "2019-11-21T20:00:26.075118Z", "url": "https://files.pythonhosted.org/packages/a2/7f/f9db62b71d8dc85dff3c7f2848f086e4ddc4f9add1bc2f6bb8ce0578c7f3/sense2vec-1.0.0a10.tar.gz", "yanked": false}], "1.0.0a2": [{"comment_text": "", "digests": {"md5": "8639b26782c2dbf3af488b9ac6a4560f", "sha256": "36ff440be4cd8accd0f2ce84331c7607467207701ec9427520678acee8f1a099"}, "downloads": -1, "filename": "sense2vec-1.0.0a2.tar.gz", "has_sig": false, "md5_digest": "8639b26782c2dbf3af488b9ac6a4560f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 32126, "upload_time": "2019-10-31T21:00:22", "upload_time_iso_8601": "2019-10-31T21:00:22.584553Z", "url": "https://files.pythonhosted.org/packages/43/2d/2e194f4ad8470ee0a52e16a2668b25cef06f02899bea0173ee2b58ce148e/sense2vec-1.0.0a2.tar.gz", "yanked": false}], "1.0.0a3": [{"comment_text": "", "digests": {"md5": "d3353726ba5a42058fda99dcacf3a7e3", "sha256": "c20427d32e00a9fe2ffe29c27b9a5526d3f3782caa684870412fac1a22ed5bb8"}, "downloads": -1, "filename": "sense2vec-1.0.0a3.tar.gz", "has_sig": false, "md5_digest": "d3353726ba5a42058fda99dcacf3a7e3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 32769, "upload_time": "2019-11-01T13:10:46", "upload_time_iso_8601": "2019-11-01T13:10:46.094049Z", "url": "https://files.pythonhosted.org/packages/45/e0/c73231b39ddf94480129fda90595916176fe3dd1cc9d5d497e6967e77f63/sense2vec-1.0.0a3.tar.gz", "yanked": false}], "1.0.0a4": [{"comment_text": "", "digests": {"md5": "98a72f5ef4bd3d0e098167471a1d9a90", "sha256": "9232c80e42a35307bdfb4cb54253a2f958bde33e833f73facb9c990016cd2d92"}, "downloads": -1, "filename": "sense2vec-1.0.0a4.tar.gz", "has_sig": false, "md5_digest": "98a72f5ef4bd3d0e098167471a1d9a90", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 40229, "upload_time": "2019-11-02T15:30:32", "upload_time_iso_8601": "2019-11-02T15:30:32.948236Z", "url": "https://files.pythonhosted.org/packages/45/9f/b871258b4c1019eed369453ecc87a225c6f4faf688ab5c7122d427da4dac/sense2vec-1.0.0a4.tar.gz", "yanked": false}], "1.0.0a5": [{"comment_text": "", "digests": {"md5": "82ac1fea96256a13e553d3e246748f69", "sha256": "866ce6c3f2a1968db022a8632a6a01df2b24f73737e3c437a32b11d3acc6b85d"}, "downloads": -1, "filename": "sense2vec-1.0.0a5.tar.gz", "has_sig": false, "md5_digest": "82ac1fea96256a13e553d3e246748f69", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 40626, "upload_time": "2019-11-02T16:42:11", "upload_time_iso_8601": "2019-11-02T16:42:11.267769Z", "url": "https://files.pythonhosted.org/packages/07/6a/881116721b85172863696caad15359c2636b6a665563157a298117fab4f3/sense2vec-1.0.0a5.tar.gz", "yanked": false}], "1.0.0a6": [{"comment_text": "", "digests": {"md5": "e2b3994af912f9678f11dcc8893ce1cc", "sha256": "81cff09ae1b41fb7fe224443ae9e67137f3d529a4780359754d2b6036a14091d"}, "downloads": -1, "filename": "sense2vec-1.0.0a6.tar.gz", "has_sig": false, "md5_digest": "e2b3994af912f9678f11dcc8893ce1cc", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 49108, "upload_time": "2019-11-03T17:17:00", "upload_time_iso_8601": "2019-11-03T17:17:00.979213Z", "url": "https://files.pythonhosted.org/packages/d7/74/a898d2db09c2892f7a1ee2e89f9afae7c258962cff5e36762adf36cac9a9/sense2vec-1.0.0a6.tar.gz", "yanked": false}], "1.0.0a7": [{"comment_text": "", "digests": {"md5": "37fd4eb1cfee5c51f4e6b04d4a62bcf8", "sha256": "bbf9fba71950148a11b6b8ba089c726e2afa3e00f1e80084014c65b6fdc76804"}, "downloads": -1, "filename": "sense2vec-1.0.0a7.tar.gz", "has_sig": false, "md5_digest": "37fd4eb1cfee5c51f4e6b04d4a62bcf8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 52531, "upload_time": "2019-11-19T14:45:14", "upload_time_iso_8601": "2019-11-19T14:45:14.995724Z", "url": "https://files.pythonhosted.org/packages/3d/28/474218ae0b7b2e789df7bb74eb6a6e4d6bb1ea5a219cfad93e4e6b0b3369/sense2vec-1.0.0a7.tar.gz", "yanked": false}], "1.0.0a8": [{"comment_text": "", "digests": {"md5": "12a631276b5ee4f03497267f4e6f1530", "sha256": "8ae77e79f2b732cb2513e373174a42afe729022d59c83117996c9ccc75635ff6"}, "downloads": -1, "filename": "sense2vec-1.0.0a8.tar.gz", "has_sig": false, "md5_digest": "12a631276b5ee4f03497267f4e6f1530", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 52782, "upload_time": "2019-11-19T15:49:00", "upload_time_iso_8601": "2019-11-19T15:49:00.972823Z", "url": "https://files.pythonhosted.org/packages/5c/30/30baec264b6d33769d24810e5a19a1fbf73e78ee0425b856b47de6aa35bd/sense2vec-1.0.0a8.tar.gz", "yanked": false}], "1.0.0a9": [{"comment_text": "", "digests": {"md5": "de713ad2f0fa5c26e04e705a35c1556c", "sha256": "88f934464fc951a716e93beda5183db624aaa1969fa92740ae5b3f9ffebab1a4"}, "downloads": -1, "filename": "sense2vec-1.0.0a9.tar.gz", "has_sig": false, "md5_digest": "de713ad2f0fa5c26e04e705a35c1556c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 53709, "upload_time": "2019-11-21T01:57:33", "upload_time_iso_8601": "2019-11-21T01:57:33.219300Z", "url": "https://files.pythonhosted.org/packages/59/1c/2e2da48edbee0ce0a7c593a5903918833973bc2d1fb163d0374376b8d1cc/sense2vec-1.0.0a9.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "2f609a74fd9c53620bb5bf2443ce6107", "sha256": "df811ba95f9c3e07cb741bbf205fa702aaf64a2384cfe4962d3e10628363a547"}, "downloads": -1, "filename": "sense2vec-1.0.1.tar.gz", "has_sig": false, "md5_digest": "2f609a74fd9c53620bb5bf2443ce6107", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 54689, "upload_time": "2019-11-22T15:49:11", "upload_time_iso_8601": "2019-11-22T15:49:11.616924Z", "url": "https://files.pythonhosted.org/packages/65/32/e23507e1b48ee7135df031d3162e76709e486cb27dda7e0d3ccfd47ccbb8/sense2vec-1.0.1.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "0f8902971d528a67a8c82d5d8ee9325f", "sha256": "78d1533e82ce1a93428eebf6dd96905151d4865810047f9824c2fe8531ae8436"}, "downloads": -1, "filename": "sense2vec-1.0.2.tar.gz", "has_sig": false, "md5_digest": "0f8902971d528a67a8c82d5d8ee9325f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 54681, "upload_time": "2019-11-22T17:40:36", "upload_time_iso_8601": "2019-11-22T17:40:36.507687Z", "url": "https://files.pythonhosted.org/packages/52/bf/5b776ad825e30e6fa5e86a74711caa84bde65b22047868e588290367253f/sense2vec-1.0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "0f8902971d528a67a8c82d5d8ee9325f", "sha256": "78d1533e82ce1a93428eebf6dd96905151d4865810047f9824c2fe8531ae8436"}, "downloads": -1, "filename": "sense2vec-1.0.2.tar.gz", "has_sig": false, "md5_digest": "0f8902971d528a67a8c82d5d8ee9325f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 54681, "upload_time": "2019-11-22T17:40:36", "upload_time_iso_8601": "2019-11-22T17:40:36.507687Z", "url": "https://files.pythonhosted.org/packages/52/bf/5b776ad825e30e6fa5e86a74711caa84bde65b22047868e588290367253f/sense2vec-1.0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:55:12 2020"}