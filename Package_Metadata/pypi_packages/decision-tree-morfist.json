{"info": {"author": "Andr\u00e9s Rever\u00f3n Molina", "author_email": "andres@reveronmolina.me", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.8"], "description": "# morfist: mixed-output-rf\nMulti-target Random Forest implementation that can mix both classification and regression tasks.\n\nMorfist implements the Random Forest algorithm (Breiman, 2001)\nwith support for mixed-task multi-task learning, i.e., it is possible to train the model on any number\nof classification tasks and regression tasks, simultaneously. Morfist's mixed multi-task learning implementation follows that proposed by Linusson (2013). \n\n* [Breiman, L. (2001). Random forests. Machine learning, 45(1), 5-32](https://link.springer.com/article/10.1023%2FA%3A1010933404324).\n* [Linusson, H. (2013). Multi-output random forests](https://pdfs.semanticscholar.org/4219/f87ed41c558d43cf78f63976cf87bcd7ebb0.pdf).\n\n## Usage\n\n### Initialising the model\n\n- Similarly to a scikit-learn [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), a MixedRandomForest can be initialised in this way:\n```\nmrf = MixedRandomForest(\n    n_estimators=n_trees,\n    min_samples_leaf=1,\n    classification_targets=[0]\n)\n```\n- The available parameters are:\n    - **n_estimators(int)**: the number of trees in the forest. Optional. Default value: 10.\n\n    - **max_features(int | float | str)**: the number of features to consider when looking for the best split. Optional. Default value: 'sqrt'.\n        - If int, then consider max_features features at each split.\n        - If float, then max_features is a fraction and int(max_features * n_features) features are considered at each split.\n        - If \u201csqrt\u201d, then max_features=sqrt(n_features) (same as \u201cauto\u201d).\n        - If \u201clog2\u201d, then max_features=log2(n_features).\n        - If None, then max_features=n_features.\n\n        Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features.\n\n    - **min_samples_leaf(int)**: the minimum number of samples required to be at a leaf node. Optional. Default value: 5.\n\n        Note: A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.\n\n    - **choose_split(str)**: method used to find the best split. Optional. Default value: 'mean'.\n\n        By default, the mean information gain will be used.\n\n        - Possible values:\n            - 'mean': the mean information gain is used.\n            - 'max': the maximum information gain is used.\n\n    - **classification_targets(int[])**: features that are part of the classification task. Optional. Default value: None.\n\n        If no classification_targets are specified, the random forest will treat all variables as regression variables.\n\n### Training the model\n\n- Once the model is initialised, it can be fitted like this:\n    ```\n    mrf.fit(X, y)\n    ```\n    Where X are the training examples and Y are their respective labels(if they are categorical) or values(if they are numerical)\n\n### Prediction\n\n- The model can be now used to predict new instances.\n    - Class/value:\n    ```\n    mrf.predict(x)\n    ```\n    - Probability:\n    ```\n    mrf.predict_proba(x)\n    ```\n\n## TODO:\n* Speed up the learning algorithm implementation (morfist is currently **much** slower than the Random Forest implementation available in scikit-learn) \n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/systemallica/morfist", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "decision-tree-morfist", "package_url": "https://pypi.org/project/decision-tree-morfist/", "platform": "", "project_url": "https://pypi.org/project/decision-tree-morfist/", "project_urls": {"Homepage": "https://github.com/systemallica/morfist"}, "release_url": "https://pypi.org/project/decision-tree-morfist/0.1.0/", "requires_dist": ["numpy", "numba", "scipy"], "requires_python": "", "summary": "Multi-target Random Forest implementation that can mix both classification and regression tasks.", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>morfist: mixed-output-rf</h1>\n<p>Multi-target Random Forest implementation that can mix both classification and regression tasks.</p>\n<p>Morfist implements the Random Forest algorithm (Breiman, 2001)\nwith support for mixed-task multi-task learning, i.e., it is possible to train the model on any number\nof classification tasks and regression tasks, simultaneously. Morfist's mixed multi-task learning implementation follows that proposed by Linusson (2013).</p>\n<ul>\n<li><a href=\"https://link.springer.com/article/10.1023%2FA%3A1010933404324\" rel=\"nofollow\">Breiman, L. (2001). Random forests. Machine learning, 45(1), 5-32</a>.</li>\n<li><a href=\"https://pdfs.semanticscholar.org/4219/f87ed41c558d43cf78f63976cf87bcd7ebb0.pdf\" rel=\"nofollow\">Linusson, H. (2013). Multi-output random forests</a>.</li>\n</ul>\n<h2>Usage</h2>\n<h3>Initialising the model</h3>\n<ul>\n<li>Similarly to a scikit-learn <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\" rel=\"nofollow\">RandomForestClassifier</a>, a MixedRandomForest can be initialised in this way:</li>\n</ul>\n<pre><code>mrf = MixedRandomForest(\n    n_estimators=n_trees,\n    min_samples_leaf=1,\n    classification_targets=[0]\n)\n</code></pre>\n<ul>\n<li>The available parameters are:\n<ul>\n<li>\n<p><strong>n_estimators(int)</strong>: the number of trees in the forest. Optional. Default value: 10.</p>\n</li>\n<li>\n<p><strong>max_features(int | float | str)</strong>: the number of features to consider when looking for the best split. Optional. Default value: 'sqrt'.</p>\n<ul>\n<li>If int, then consider max_features features at each split.</li>\n<li>If float, then max_features is a fraction and int(max_features * n_features) features are considered at each split.</li>\n<li>If \u201csqrt\u201d, then max_features=sqrt(n_features) (same as \u201cauto\u201d).</li>\n<li>If \u201clog2\u201d, then max_features=log2(n_features).</li>\n<li>If None, then max_features=n_features.</li>\n</ul>\n<p>Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features.</p>\n</li>\n<li>\n<p><strong>min_samples_leaf(int)</strong>: the minimum number of samples required to be at a leaf node. Optional. Default value: 5.</p>\n<p>Note: A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.</p>\n</li>\n<li>\n<p><strong>choose_split(str)</strong>: method used to find the best split. Optional. Default value: 'mean'.</p>\n<p>By default, the mean information gain will be used.</p>\n<ul>\n<li>Possible values:\n<ul>\n<li>'mean': the mean information gain is used.</li>\n<li>'max': the maximum information gain is used.</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>classification_targets(int[])</strong>: features that are part of the classification task. Optional. Default value: None.</p>\n<p>If no classification_targets are specified, the random forest will treat all variables as regression variables.</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3>Training the model</h3>\n<ul>\n<li>Once the model is initialised, it can be fitted like this:\n<pre><code>mrf.fit(X, y)\n</code></pre>\nWhere X are the training examples and Y are their respective labels(if they are categorical) or values(if they are numerical)</li>\n</ul>\n<h3>Prediction</h3>\n<ul>\n<li>The model can be now used to predict new instances.\n<ul>\n<li>Class/value:</li>\n</ul>\n<pre><code>mrf.predict(x)\n</code></pre>\n<ul>\n<li>Probability:</li>\n</ul>\n<pre><code>mrf.predict_proba(x)\n</code></pre>\n</li>\n</ul>\n<h2>TODO:</h2>\n<ul>\n<li>Speed up the learning algorithm implementation (morfist is currently <strong>much</strong> slower than the Random Forest implementation available in scikit-learn)</li>\n</ul>\n\n          </div>"}, "last_serial": 7103720, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "429577a7b08a2e9da24bd2bb07ebbe28", "sha256": "7cee2d75ddd6c98e28be21ea71b0603cfd5972d73269c3439b10dc85ae74f4b8"}, "downloads": -1, "filename": "decision_tree_morfist-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "429577a7b08a2e9da24bd2bb07ebbe28", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7717, "upload_time": "2020-04-26T08:59:21", "upload_time_iso_8601": "2020-04-26T08:59:21.726349Z", "url": "https://files.pythonhosted.org/packages/e3/72/1166f609263d6af926a53ecfc30ddd13653c1ca0d5f2911302d0afb184f3/decision_tree_morfist-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "44b25bf986847c45fb6bff5fa4efbeda", "sha256": "8c51daa4c8d25007ea0228f02d8c098c81d3a936c78cf82be409e49e9eb9b470"}, "downloads": -1, "filename": "decision-tree-morfist-0.1.0.tar.gz", "has_sig": false, "md5_digest": "44b25bf986847c45fb6bff5fa4efbeda", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7465, "upload_time": "2020-04-26T08:59:23", "upload_time_iso_8601": "2020-04-26T08:59:23.829345Z", "url": "https://files.pythonhosted.org/packages/75/a4/83c999c2824deb0d0e7d053057a2950ebc516fda61def1560a1a4783a603/decision-tree-morfist-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "429577a7b08a2e9da24bd2bb07ebbe28", "sha256": "7cee2d75ddd6c98e28be21ea71b0603cfd5972d73269c3439b10dc85ae74f4b8"}, "downloads": -1, "filename": "decision_tree_morfist-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "429577a7b08a2e9da24bd2bb07ebbe28", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7717, "upload_time": "2020-04-26T08:59:21", "upload_time_iso_8601": "2020-04-26T08:59:21.726349Z", "url": "https://files.pythonhosted.org/packages/e3/72/1166f609263d6af926a53ecfc30ddd13653c1ca0d5f2911302d0afb184f3/decision_tree_morfist-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "44b25bf986847c45fb6bff5fa4efbeda", "sha256": "8c51daa4c8d25007ea0228f02d8c098c81d3a936c78cf82be409e49e9eb9b470"}, "downloads": -1, "filename": "decision-tree-morfist-0.1.0.tar.gz", "has_sig": false, "md5_digest": "44b25bf986847c45fb6bff5fa4efbeda", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7465, "upload_time": "2020-04-26T08:59:23", "upload_time_iso_8601": "2020-04-26T08:59:23.829345Z", "url": "https://files.pythonhosted.org/packages/75/a4/83c999c2824deb0d0e7d053057a2950ebc516fda61def1560a1a4783a603/decision-tree-morfist-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:39:36 2020"}