{"info": {"author": "Hannes Luidalepp", "author_email": "luidale@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Console", "Intended Audience :: Science/Research", "License :: OSI Approved :: GNU General Public License v3 (GPLv3)", "Operating System :: Unix", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: Implementation :: PyPy", "Topic :: Scientific/Engineering", "Topic :: Scientific/Engineering :: Bio-Informatics"], "description": "starpa\n======\n\n.. image:: https://img.shields.io/pypi/v/starpa.svg\n    :target: https://pypi.python.org/pypi/starpa\n    :alt: Latest PyPI version\n\n.. image:: https://travis-ci.org/luidale/starpa.png\n   :target: https://travis-ci.org/luidale/starpa\n   :alt: Latest Travis CI build status\n\n**Stable RNA processing product analyzer**\n\nTool to predict, quantify and characterize stable RNA processing products\nfrom RNA-seq data.\n\nOverview\n--------\nStarpa workflow is divided into multiple consecutive tasks which can be executed separately, \nas a freely chosen successive subsets or all tasks at once in sequential order.\nThis adds flexibility to the tool to use as an input RNA-seq data in various state of processing.\nFor example Starpa can handle raw data in FastQ format, but also trimmed reads (FastQ format)\nor aligned reads in SAM format.\n\nBoth paired-end (PE) and single-end (SE) sequencing reads are accepted as an input.\n\nIn addition, the tool is highly configurable and can handle multiple libraries in parallel manner (multiprocessing).\n\n**Tasks are following:**\n\n- *trim*\n\nCutadapt is used to trim low quality 3' end of the reads followed by adapter removal from 3' end \nof the reads. \n\nIn case of SE, the reads where 3' adapter was not trimmed are excluded. \nThis ensures that 3' end of the read is stable RNA processing products is estimated with higher \nconfidence.\n\n- *align*\n\nBowtie2 is used to align reads to the genome. All matches to the genome are recorded.\n\n- *sam_sort*\n\nFrom aligned reads the unmapped and discordantly mapped reads are discarded. In addition, only the reads belonging to \nbest stratum (class of alignment score) are retained while alignments with lower alignments score \nare excluded.\n\n- *pseudoSE*\n\nAlignments with too many mismatches and reads with too many genomic alignments are discarded.\nAll other reads get NH tag (if not present) describing the number of reported alignments. \nSequence and quality fields of secondary alignments are filled with sequence and quality data.\nIn the end the PE reads are converted to pseudo SE reads to ease subsequent analysis steps. \n\n- *identify*\n\nFlaimapper2 is used to predict stable RNA processing products. To ensure prediction of all\nprocessing products which share start or end positions, the reads are fractionated according \nto their length. Subsequently, Flaimmper2 is run on each fraction of reads separately and \nthe predicted processing products are filtered by the read count (estimation by \nFlaimapper-2) exceeding threshold set. The filtered predicted processing products are quantified \nmore precisely via bedtools intersect.\n\n- *cluster*\n\nQuantified processing products are filtered once again by the read counts (bedtools intersect)\nexceeding threshold and by relative coverage (average coverage of reads assigned to processing products \ndivided by average coverage of all reads aligned to the positions of processing products).\nNext, the processing products from all libraries analysed are combined (identifying unique species) \nand clustered.\n\nClustering is two step process:\n\na) clustering by overlap.\n\nAs the prediction of processing products by Flaimapper-2 is probabilistic, the predicted ends \nof the processing products in different libraries might slightly vary, as also the true ends. \nTherefore, the predicted processing products which do largely overlap and have some bases \n(adjustable) not overlapping are clustered and representative processing products for clusters \nare selected.\n\nb) clustering by sequence\n\nAs a majority of genomes contain repeating regions (repeat regions, rRNA operons, some tRNA genes etc)\nreads can be mapped to multiple positions resulting multiple processing products consisting \nfrom the same or similar set of reads.\nTo reduce the number of identical processing products they are clustered by sequence identity \nvia CDI-HIT-EST. Still the genomic matches of particular reads can be in genomic regions with different surrounding\nsequence/context (eg. different genes) therefore clustering solely based on sequence identity can result \nloss of information.\nTo avoid it the predicted processing products which cluster by sequence identity has to be supported by the \nclustering (again via CDI-HIT-EST) of the contigs they overlap with and representative processing product for the \nclusters are selected.\n\nIn addition, the contigs are identified and wig formatted files (containing coverage data of \nindividual libraries) are created.\n\n- *quantify*\n\nRepresentative processing products will be quantified using bedtools intersect in every library.\nAdditional characteristics will be gathered (relative coverage, coverage at single position level, \nconsensus sequence, quality of consensus sequence, genomic sequence, uniqueness). Quantification data\nis also converted to read per million of mapped reads (RPM), RPM of biotype and RPM of biotype groups.\n\nInstallation\n------------\n::\n\n pip install --user starpa\n\n\nRequirements\n^^^^^^^^^^^^\nStarpa is depending on following tools which have to be installed in your system:\n\n`Python3.4+ <https://www.python.org/>`_,\n`cutadapt <https://github.com/marcelm/cutadapt>`_,\n`bowtie2 <http://bowtie-bio.sourceforge.net/bowtie2/index.shtml>`_,\n`samtools <http://www.htslib.org/doc/samtools.html>`_,\n`Flaimapper-2 <hhttps://github.com/yhoogstrate/flaimapper>`_,\n`bedtools <http://bedtools.readthedocs.io/en/latest/#>`_,\n`CDI-HIT-EST <http://weizhongli-lab.org/cd-hit/>`_.\n\nPython3 requires following packages which will be installed (if missing) during \nthe installation of starpa:\n\npyfaidx, docopt, schema\n\nCompatibility\n-------------\n**OS:**\n\nStarpa is compatible with UNIX like operating systems.\n\n**Input:**\n\n1) Colorspace reads are not supported.\n\n2) Both paired-end (PE) and single-end (SE) reads are supported.\n\nUsage\n-----\nUsage of starpa is as follows::\n\n Usage:\n     starpa      [-hv]\n     starpa -s <start_task> -e <end_task> -c <parameter_file> -i <input> \n     -o <output>\n\n Arguments:\n\n     <start_task>        task to start with\n     <end_task>          tast to end with\n     <config_file>       configuration file\n     <input>             input folder\n     <output>            output folder\n Options:\n     -v, --version\n     -h, --help\n     -s <start_task>, --start=<start_task>\n     -e <end_task>, --end=<end_task>\n     -c <config_file>, --config=<config_file>\n     -i <input_folder>, --input=<input_folder>\n     -o <output_folder>, --output=<output_folder>\n\n|\n\n**Tasks**\n\nStarpa work-flow is divided into multiple consecutive tasks which can be executed:\n\n- separately\n- as a freely chosen successive subsets \n- all at once in sequential order\n\nTasks in sequential order:\n\n\ttrim, align, sam_sort, pseudoSE, identify, cluster, quantify\n\n**Configuration file**\n\n`Configuration file <https://raw.githubusercontent.com/luidale/starpa/master/src/starpa/data/config.txt>`_ \nis used to set various parameters which allow to adjust the \nperformance of the work-flow according to the user needs and input data.\nThe description of each parameter is given in the file itself.\n\nConfiguration file states also the location of following files:\n\nadapter files - adapter sequencies in fasta format\n\ngenome file - genome sequence in fasta format\n\nannotation file - in GFF or GFF3 format.\n\n`\"flaimapper parameter file\" <https://raw.githubusercontent.com/luidale/starpa/master/src/starpa/data/flaimapper_parameters/parameters.dev-2-100-2.txt>`_  -\ndescribed in more deteil `here <https://github.com/yhoogstrate/flaimapper#the---parameters-argument>`_. Given Flaimapper-2 parameters file is adjusted to be suitable to predict processing products with rather defined ends.\n\n`\"library_file\" <https://raw.githubusercontent.com/luidale/starpa/master/src/starpa/data/libraries.txt>`_ - \ndescribing libraries to be analysed.\n\n\"library_file\" is a tabular file containing:\n 1) the name of the libraries\n\n 2) conditions they are derived from and \n\n 3) identifier of replicate \n\n(note that all three columns are separated by tab)\n\n::\n\n #Library number\tSample\tReplicate\n library1\tLB OD 0.4\tI\n library2\tLB OD 0.4\tII\n\n| \n\n`Configuration file <https://raw.githubusercontent.com/luidale/starpa/master/src/starpa/data/config.txt>`_,\n`\"flaimapper parameter file\" <https://raw.githubusercontent.com/luidale/starpa/master/src/starpa/data/flaimapper_parameters/parameters.dev-2-100-2.txt>`_ and\n`\"library_file\" <https://raw.githubusercontent.com/luidale/starpa/master/src/starpa/data/libraries.txt>`_ are available in:\n\n::\n\n src/starpa/data\n\n|\n\n\n**Input folder**\n\nWhile running a single or multiple tasks, the input folder has to contain specific data \nrequired for the first task. \nFor the following task the preceding tasks will prepare proper data.\n\nEach task has different requirements for the input data:\n\n- *trim*\n\n| Sequencing data in `FastQ format <https://en.wikipedia.org/wiki/FASTQ_format>`_.\n| Can be in PE or SE format which has to be indicated in \n `configuration file <https://raw.githubusercontent.com/luidale/starpa/master/src/starpa/data/config.txt>`_ .\n| FastQ files can be compressed as \".gz\", \".bz2\" or \".xz\".\n\n\n- *align*\n\n| Trimmed and cleaned reads in `FastQ format <https://en.wikipedia.org/wiki/FASTQ_format>`_.\n| Can be in PE or SE format which has to be indicated in \n `configuration file <https://raw.githubusercontent.com/luidale/starpa/master/src/starpa/data/config.txt>`_ .\n| FastQ files can be compressed as \".gz\" (requires bowtie2.3.1+)\n\n\n- *sam_sort*\n\n| Aligned reads in SAM format. \n| Can be in PE or SE format which has to be indicated in \n `configuration file <https://raw.githubusercontent.com/luidale/starpa/master/src/starpa/data/config.txt>`_ .\n\n| BAM format is not currently supported.\n\n\n- *pseudoSE*\n\n| Aligned reads in SAM format. \n| Can be in PE or SE format which has to be indicated in \n `configuration file <https://raw.githubusercontent.com/luidale/starpa/master/src/starpa/data/config.txt>`_ .\n| File can not be sorted by position.\n\n| BAM format is not currently supported.\n\n\n- *identify*\n\n| Aligned SE or pseudoSE reads in SAM format. \n| Reads require NH tag to describe the number of reported alignments.\n\n| BAM format currently not supported.\n\n\n- *cluster*\n\n| Identified and quantified predicted processing products in BED format \n| (quantification at column #6).\n\n|  folder bam:\n| \tAligned SE or pseudoSE reads in BAM format.\n| \tReads require NH tag to describe the number of reported alignments.\n\n| If task \"quantify\" will be also executed:\n| \tAdditional input folder (given by parameter \"quantify_sam_file_location\"):\n| \t\tAligned SE or pseudoSE reads in SAM format \n| \t\t(BAM format currently not supported).\n| \t\tReads require NH tag to describe the number of reported alignments.\n\n\n- *quantify*\n\n| Predicted processing products in BED format (preferentially representatives form clustering).\n\n| Additional input folder (given by parameter \"quantify_sam_file_location\"):\n|\tAligned SE or pseudoSE reads in SAM format (BAM format currently not supported).\n|\tReads require NH tag to describe the number of reported alignments.\n\n\n**Output folder**\n\nOutput folder will contain parameter folder:\n\n::\n\n parameters/\n\teg. config.txt\t\t\t-\tcopy of configuration file\n\targuments.txt\t\t\t-\tcommand line arguments\n\teg. libraries.txt\t\t-\tcopy of library file\n\teg. parameters.dev-2-100-2.txt\t-\tcopy of Flaimapper-2 parameter file\n \n\nEach task creates a subfolder with its name containing specific output \nof the task.\n\n| XXX - library name\n| strand - For or Rev\n| Y -\torder number of fragmented read group\n\n\n- *trim*\n\n::\n\n trim_info/\n\tXXX_triminfo.log\t-\tlog of task\n\tXXX_triminfo.error\t-\tcollected errors during trimming\n\n PE:\n discard/\n\tXXX_1_short.fq\t\t-\tforward reads discared while being too short after\n\t\t\t\t\ttrimming\n\tXXX_2_short.fq\t\t-\treverse reads discared while being too short after\n\t\t\t\t\ttrimming\n\t\t\t\t\t\t\t\n XXX_trim_1.fq\t\t\t-\ttrimmed forward reads\n XXX_trim_2.fq\t\t\t-\ttrimmed reverse reads\n\n SE:\n discard/\n\tXXX_short.fq\t\t-\treads discarded while being too short after \n\t\t\t\t\ttrimming\n\tXXX_untrimmed.fq\t-\treads discarded while having no adapter trimmed\n\t\n XXX_trim.fq\t\t\t-\ttrimmed reads\n\n- *align*\n\n::\n\n align_info/\n\tXXX_aligninfo.log\t-\tlog of task\n\t\n XXX.sam\t\t\t-\taligned reads\n\n- *sam_sort*\n\n::\n\n sort_info/\n\tXXX_sortinfo.log\t-\tlog of task\n\t\n XXX_unmapped.sam\t\t-\tunmapped reads\n XXX_sort.sam\t\t\t-\tprocessed reads\n\n- *pseudoSE*\n\n::\n\n pseudoSE_info/\n\tXXX_pseudoSEinfo.log\t\t-\tlog of task\n\t\n mismatched/\n\tXXX_pseudoSE_mismatch.sam\t-\treads discarded while having too many\n\t\t\t\t\t\tmismatches\n\t\t\t\t\t\t\t\t\t\t\n too_many_matches/\n\tXXX_pseudoSE_multimatch.sam\t-\treads discarded while haveing too many\n\t\t\t\t\t\tgenomic matches\n\t\t\t\t\t\t\t\t\t\t\n XXX_pseudoSE.sam\t\t\t-\tprocessed reads\n\t\n If oligoA allowed:\n oligoA/\n\tXXX-oligoA-mm_pseudoSE.sam\t-\treads with 3' oligoA (non-genome \n\t\t\t\t\t\tencoded) which would have otherwise \n\t\t\t\t\t\tdiscarded\n\tXXX-oligoA-pseudoSE.sam\t\t-\treads with 3' oligoA (non-genome\n\t\t\t\t\t\tencoded)\n\t\n- *identify*\n\n::\n\n flaimapper/\t\t\t\t\t\t\n\tflaimapper_info/\n\t\tXXX/\n\t\t\tXXX_strand_Y_flaimapper.information\t-\tlog of flaimapper\n\t\t\t\n\tflaimapper_temp/\n\t\tXXX/\n\t\t\tXXX_strand_Y_flaimapper.tab\t\t-\tflaimapper predicitons\n\t\t\t\n bam/\n\tXXX_strand.bam\t\t\t\t\t\t-\tstrand-wise sorted reads \n\t\t\t\t\t\t\t\t\tfrom input\n\tXXX_strand.bam.bai\t\t\t\t\t-\tindex of of bam file\n\tXXX_strand.sam \t\t\t\t\t\t-\tNOT NEEDED\n\t\n identify_info/\n\t XXX_strand_identifyinfo.log\t\t\t\t-\tlog of task\n\t \n XXX_strand_pp.BED\t\t\t\t\t\t-\tNOT NEEDED\n XXX_strand_pp_counted.BED\t\t\t\t\t-\tpredicted processing \n\t\t\t\t\t\t\t\t\tproducts with \n\t\t\t\t\t\t\t\t\tquantification\n\n\t\t\t\n- *cluster*\n\n::\n\n cd_hit_est/\n\tpp_cd_hit_est.info\t\t-\tlog of sequence identity based clustering \n\t\t\t\t\t\tof combined and overlap clustered predicted\n\t\t\t\t\t\tprocessing products via CD-HIT-EST\n\tpp_combined.cdhit\t\t-\tgenomic sequence of combined and overlap \n\t\t\t\t\t\tclustered predicted processing products\n\tpp_combined.cdhit.clstr\t\t-\tclusters of combined and overlap clustered\n\t\t\t\t\t\tpredicted processing products created via\n\t\t\t\t\t\tCD-HIT-EST\n\t\t\t\t\t\t\t\t\t\n contigs/\n\tXXX_contigs.BED\t\t\t-\tlist of contigs identified\n\tXXX/\n\t\tcontig_name.fasta\t-\tsequences of all reads belonging to the\n\t\t\t\t\t\tcorresponding contigs\n\t\tcontig_name.sam\t\t-\tall reads belonging to the\n\t\t\t\t\t\tcorresponding contigs\n\t\t\t\t\t\t\t\t\t\n contigs_meta/\n\tcombined_contigs_meta.BED\t-\tcombined contigs to be used to create \n\t\t\t\t\t\tmetacontigs from all libraries\n\tXXX_contigs_meta.BED\t\t-\tlist of contigs to be used to created\n\t\t\t\t\t\tmetacontigs\n\tmetacontig_cd_hit_est.info\t-\tlog of sequence identity based clustering \n\t\t\t\t\t\tof metacontigs via CD-HIT-EST\n\tmetacontigs.cdhit\t\t-\tgenomic sequence of metacontigs\n\tmetacontigs.cdhit.clstr\t\t-\tclusters of metacontigs created via\n\t\t\t\t\t\tCD-HIT-EST\n\tmetacontigs.BED\t\t\t-\tlist of metacontigs in bed format\n\tpp_to_metacontig.BED\t\t-\tcombined and overlap clustered predicted\n\t\t\t\t\t\tprocessing product match with metacontigs\n\t\t\t\t\t\tin BED-like format\n\t\t\t\t\t\t\t\t\t\n mpileup/\n\tXXX_strand_mpileup.info\t\t-\tlog of bedtools mpileup\n\t\n wig/\n\tXXX_strand.wig\t\t\t-\tstrand specific absolute read coverage\n\tXXX_strand_RPM.wig\t\t-\tstrand specific relative read coverage\n\t\t\t\t\t\tas read per million mapped reads (RPM)\n\t\t\t\t\t\t\t\t\t\n pp_clusterinfo.log\t\t\t-\tlog of task\n pp_unique.library_info\t\t\t-\tcombined predicted processing \n\t\t\t\t\t\tproducts and the origins of libraries\n pp_combined.BED\t\t\t-\trepresentatives of combined and overlap \n\t\t\t\t\t\tclustered predicted processing products \n\t\t\t\t\t\tin BED format\n pp_combined.cluster\t\t\t-\toverlap clusters of combined predicted \n\t\t\t\t\t\tprocessing products\n pp_combined.library_info\t\t-\trepresentatives of combined and overlap \n\t\t\t\t\t\tclustered predicted processing \n\t\t\t\t\t\tproducts and the origins of libraries\n pp_metacontig.BED\t\t\t-\trepresentatives of predicted processing\n\t\t\t\t\t\tproducts from pp_combined.BED clustered\n\t\t\t\t\t\tby sequence identity supported by \n\t\t\t\t\t\tmetacontig clustering in BED format\n pp_metacontig.cluster\t\t\t-\tsequence identity clusters of predicted \n\t\t\t\t\t\tprocessing products from pp_combined.BED\n\t\t\t\t\t\tsupported by metacontig clustering\n\n- *quantify*\n\n::\n\n libraries/\t\t\t\t\t-\tdata in library wise\n\tXXX.biotype_annotation.statistics\t-\tread alignement statistics\n\t\t\t\t\t\t\tby annotation biotypes\n\tXXX.gene_annotation.statistics\t\t-\tread alignement statistics\n\t\t\t\t\t\t\tby genes\n\tpp_metacontig_XXX_counted.BED\t\t-\tabsolute quantification of \n\t\t\t\t\t\t\tpredicted processing products \n\t\t\t\t\t\t\tin BED format\n\t\t\t\t\t\t\t\t\t\t\t\t\t\n collected.annotation2.statistics \t\t-\tcombined alignement\tstatistics\n\t\t\t\t\t\t\tby annotation biotypes\n pp_metacontig_biotype.BED\t\t\t-\tpredicted processing products\n\t\t\t\t\t\t\twith biotype in BED-like format\n pp_metacontig_biotype_match.BED\t\t-\tpredicted processing products\n\t\t\t\t\t\t\tmatch with genes in BED-like \n\t\t\t\t\t\t\tformat\n pp_metacontig_counts_total.tsv\t\t\t-\tabsolute quantification of \n\t\t\t\t\t\t\tpredicted processing products \n\t\t\t\t\t\t\tin BED format\n pp_metacontig_counts_RPM.tsv\t\t\t-\trelative quantification of \n\t\t\t\t\t\t\tpredicted processing products\n\t\t\t\t\t\t\tas read per million mapped reads\n\t\t\t\t\t\t\t(RPM) in BED format\n pp_metacontig_counts_biotype_RPM.tsv\t\t-\trelative quantification of \n\t\t\t\t\t\t\tpredicted processing products\n\t\t\t\t\t\t\tas RPM of biotype in BED format\n pp_metacontig_counts_groupped_biotype_RPM.tsv\t-\trelative quantification of \n\t\t\t\t\t\t\tpredicted processing products\n\t\t\t\t\t\t\tas RPM of biotype groups in BED \n\t\t\t\t\t\t\tformat\n pp_metacontig_cons_qual.tsv\t\t\t-\tquality of consensus sequence \n \t\t\t\t\t\t\tof predicted processing products\n\t\t\t\t\t\t\texpressed as frequency of the most\n\t\t\t\t\t\t\tabundant base in a given position\n pp_metacontig_cons_seq.tsv\t\t\t-\tconsensus sequence of predicted \n\t\t\t\t\t\t\tprocessing products\n pp_metacontig_coverage.tsv\t\t\t-\tcoverage of reads assigned to \n\t\t\t\t\t\t\tpredicted processing products \n\t\t\t\t\t\t\tat single position level\n pp_metacontig_genomic_seq.tsv\t\t\t-\tgenomic sequence of predicted \n\t\t\t\t\t\t\tprocessing products \n pp_metacontig_rel_cov.tsv\t\t\t-\trelative coverage of predicted \n\t\t\t\t\t\t\tprocessing products\n pp_metacontig_uniqness.tsv\t\t\t-\tmean number of genomic genomic \n\t\t\t\t\t\t\tmatches of reads assigned\n\t\t\t\t\t\t\tto the predicted processing \n\t\t\t\t\t\t\tproducts\n\nTo do\n-------------\n\nLicence\n-------\n`GNU General Public License v3.0 <https://github.com/luidale/starpa/blob/master/LICENSE>`_\n\nAuthors\n-------\n`starpa` was written by `Hannes Luidalepp <luidale@gmail.com>`_", "description_content_type": "", "docs_url": null, "download_url": "https://github.com/luidale/starpa/archive/v0.3.0.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/luidale/starpa", "keywords": "", "license": "The GNU General Public License v3.0 (GPL3) - http://www.gnu.org/copyleft/gpl.html", "maintainer": "", "maintainer_email": "", "name": "starpa", "package_url": "https://pypi.org/project/starpa/", "platform": "", "project_url": "https://pypi.org/project/starpa/", "project_urls": {"Download": "https://github.com/luidale/starpa/archive/v0.3.0.tar.gz", "Homepage": "https://github.com/luidale/starpa"}, "release_url": "https://pypi.org/project/starpa/0.3.0/", "requires_dist": null, "requires_python": "", "summary": "Stable RNA processing product analyzer", "version": "0.3.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://pypi.python.org/pypi/starpa\" rel=\"nofollow\"><img alt=\"Latest PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ae6013d074083f5042a869963d6bba6db5e4a0c5/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f7374617270612e737667\"></a>\n<a href=\"https://travis-ci.org/luidale/starpa\" rel=\"nofollow\"><img alt=\"Latest Travis CI build status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/72392abf9bfff307c3f9581e95f65e29d9470182/68747470733a2f2f7472617669732d63692e6f72672f6c756964616c652f7374617270612e706e67\"></a>\n<p><strong>Stable RNA processing product analyzer</strong></p>\n<p>Tool to predict, quantify and characterize stable RNA processing products\nfrom RNA-seq data.</p>\n<div id=\"overview\">\n<h2>Overview</h2>\n<p>Starpa workflow is divided into multiple consecutive tasks which can be executed separately,\nas a freely chosen successive subsets or all tasks at once in sequential order.\nThis adds flexibility to the tool to use as an input RNA-seq data in various state of processing.\nFor example Starpa can handle raw data in FastQ format, but also trimmed reads (FastQ format)\nor aligned reads in SAM format.</p>\n<p>Both paired-end (PE) and single-end (SE) sequencing reads are accepted as an input.</p>\n<p>In addition, the tool is highly configurable and can handle multiple libraries in parallel manner (multiprocessing).</p>\n<p><strong>Tasks are following:</strong></p>\n<ul>\n<li><em>trim</em></li>\n</ul>\n<p>Cutadapt is used to trim low quality 3\u2019 end of the reads followed by adapter removal from 3\u2019 end\nof the reads.</p>\n<p>In case of SE, the reads where 3\u2019 adapter was not trimmed are excluded.\nThis ensures that 3\u2019 end of the read is stable RNA processing products is estimated with higher\nconfidence.</p>\n<ul>\n<li><em>align</em></li>\n</ul>\n<p>Bowtie2 is used to align reads to the genome. All matches to the genome are recorded.</p>\n<ul>\n<li><em>sam_sort</em></li>\n</ul>\n<p>From aligned reads the unmapped and discordantly mapped reads are discarded. In addition, only the reads belonging to\nbest stratum (class of alignment score) are retained while alignments with lower alignments score\nare excluded.</p>\n<ul>\n<li><em>pseudoSE</em></li>\n</ul>\n<p>Alignments with too many mismatches and reads with too many genomic alignments are discarded.\nAll other reads get NH tag (if not present) describing the number of reported alignments.\nSequence and quality fields of secondary alignments are filled with sequence and quality data.\nIn the end the PE reads are converted to pseudo SE reads to ease subsequent analysis steps.</p>\n<ul>\n<li><em>identify</em></li>\n</ul>\n<p>Flaimapper2 is used to predict stable RNA processing products. To ensure prediction of all\nprocessing products which share start or end positions, the reads are fractionated according\nto their length. Subsequently, Flaimmper2 is run on each fraction of reads separately and\nthe predicted processing products are filtered by the read count (estimation by\nFlaimapper-2) exceeding threshold set. The filtered predicted processing products are quantified\nmore precisely via bedtools intersect.</p>\n<ul>\n<li><em>cluster</em></li>\n</ul>\n<p>Quantified processing products are filtered once again by the read counts (bedtools intersect)\nexceeding threshold and by relative coverage (average coverage of reads assigned to processing products\ndivided by average coverage of all reads aligned to the positions of processing products).\nNext, the processing products from all libraries analysed are combined (identifying unique species)\nand clustered.</p>\n<p>Clustering is two step process:</p>\n<ol>\n<li>clustering by overlap.</li>\n</ol>\n<p>As the prediction of processing products by Flaimapper-2 is probabilistic, the predicted ends\nof the processing products in different libraries might slightly vary, as also the true ends.\nTherefore, the predicted processing products which do largely overlap and have some bases\n(adjustable) not overlapping are clustered and representative processing products for clusters\nare selected.</p>\n<ol>\n<li>clustering by sequence</li>\n</ol>\n<p>As a majority of genomes contain repeating regions (repeat regions, rRNA operons, some tRNA genes etc)\nreads can be mapped to multiple positions resulting multiple processing products consisting\nfrom the same or similar set of reads.\nTo reduce the number of identical processing products they are clustered by sequence identity\nvia CDI-HIT-EST. Still the genomic matches of particular reads can be in genomic regions with different surrounding\nsequence/context (eg. different genes) therefore clustering solely based on sequence identity can result\nloss of information.\nTo avoid it the predicted processing products which cluster by sequence identity has to be supported by the\nclustering (again via CDI-HIT-EST) of the contigs they overlap with and representative processing product for the\nclusters are selected.</p>\n<p>In addition, the contigs are identified and wig formatted files (containing coverage data of\nindividual libraries) are created.</p>\n<ul>\n<li><em>quantify</em></li>\n</ul>\n<p>Representative processing products will be quantified using bedtools intersect in every library.\nAdditional characteristics will be gathered (relative coverage, coverage at single position level,\nconsensus sequence, quality of consensus sequence, genomic sequence, uniqueness). Quantification data\nis also converted to read per million of mapped reads (RPM), RPM of biotype and RPM of biotype groups.</p>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<pre>pip install --user starpa\n</pre>\n<div id=\"requirements\">\n<h3>Requirements</h3>\n<p>Starpa is depending on following tools which have to be installed in your system:</p>\n<p><a href=\"https://www.python.org/\" rel=\"nofollow\">Python3.4+</a>,\n<a href=\"https://github.com/marcelm/cutadapt\" rel=\"nofollow\">cutadapt</a>,\n<a href=\"http://bowtie-bio.sourceforge.net/bowtie2/index.shtml\" rel=\"nofollow\">bowtie2</a>,\n<a href=\"http://www.htslib.org/doc/samtools.html\" rel=\"nofollow\">samtools</a>,\n<a>Flaimapper-2</a>,\n<a href=\"http://bedtools.readthedocs.io/en/latest/#\" rel=\"nofollow\">bedtools</a>,\n<a href=\"http://weizhongli-lab.org/cd-hit/\" rel=\"nofollow\">CDI-HIT-EST</a>.</p>\n<p>Python3 requires following packages which will be installed (if missing) during\nthe installation of starpa:</p>\n<p>pyfaidx, docopt, schema</p>\n</div>\n</div>\n<div id=\"compatibility\">\n<h2>Compatibility</h2>\n<p><strong>OS:</strong></p>\n<p>Starpa is compatible with UNIX like operating systems.</p>\n<p><strong>Input:</strong></p>\n<ol>\n<li>Colorspace reads are not supported.</li>\n<li>Both paired-end (PE) and single-end (SE) reads are supported.</li>\n</ol>\n</div>\n<div id=\"usage\">\n<h2>Usage</h2>\n<p>Usage of starpa is as follows:</p>\n<pre>Usage:\n    starpa      [-hv]\n    starpa -s &lt;start_task&gt; -e &lt;end_task&gt; -c &lt;parameter_file&gt; -i &lt;input&gt;\n    -o &lt;output&gt;\n\nArguments:\n\n    &lt;start_task&gt;        task to start with\n    &lt;end_task&gt;          tast to end with\n    &lt;config_file&gt;       configuration file\n    &lt;input&gt;             input folder\n    &lt;output&gt;            output folder\nOptions:\n    -v, --version\n    -h, --help\n    -s &lt;start_task&gt;, --start=&lt;start_task&gt;\n    -e &lt;end_task&gt;, --end=&lt;end_task&gt;\n    -c &lt;config_file&gt;, --config=&lt;config_file&gt;\n    -i &lt;input_folder&gt;, --input=&lt;input_folder&gt;\n    -o &lt;output_folder&gt;, --output=&lt;output_folder&gt;\n</pre>\n<div>\n<div><br></div>\n</div>\n<p><strong>Tasks</strong></p>\n<p>Starpa work-flow is divided into multiple consecutive tasks which can be executed:</p>\n<ul>\n<li>separately</li>\n<li>as a freely chosen successive subsets</li>\n<li>all at once in sequential order</li>\n</ul>\n<p>Tasks in sequential order:</p>\n<blockquote>\ntrim, align, sam_sort, pseudoSE, identify, cluster, quantify</blockquote>\n<p><strong>Configuration file</strong></p>\n<p><a href=\"https://raw.githubusercontent.com/luidale/starpa/master/src/starpa/data/config.txt\" rel=\"nofollow\">Configuration file</a>\nis used to set various parameters which allow to adjust the\nperformance of the work-flow according to the user needs and input data.\nThe description of each parameter is given in the file itself.</p>\n<p>Configuration file states also the location of following files:</p>\n<p>adapter files - adapter sequencies in fasta format</p>\n<p>genome file - genome sequence in fasta format</p>\n<p>annotation file - in GFF or GFF3 format.</p>\n<p><a href=\"https://raw.githubusercontent.com/luidale/starpa/master/src/starpa/data/flaimapper_parameters/parameters.dev-2-100-2.txt\" rel=\"nofollow\">\u201cflaimapper parameter file\u201d</a>  -\ndescribed in more deteil <a href=\"https://github.com/yhoogstrate/flaimapper#the---parameters-argument\" rel=\"nofollow\">here</a>. Given Flaimapper-2 parameters file is adjusted to be suitable to predict processing products with rather defined ends.</p>\n<p><a href=\"https://raw.githubusercontent.com/luidale/starpa/master/src/starpa/data/libraries.txt\" rel=\"nofollow\">\u201clibrary_file\u201d</a> -\ndescribing libraries to be analysed.</p>\n<dl>\n<dt>\u201clibrary_file\u201d is a tabular file containing:</dt>\n<dd><ol>\n<li>the name of the libraries</li>\n<li>conditions they are derived from and</li>\n<li>identifier of replicate</li>\n</ol>\n</dd>\n</dl>\n<p>(note that all three columns are separated by tab)</p>\n<pre>#Library number        Sample  Replicate\nlibrary1       LB OD 0.4       I\nlibrary2       LB OD 0.4       II\n</pre>\n<div>\n<div><br></div>\n</div>\n<p><a href=\"https://raw.githubusercontent.com/luidale/starpa/master/src/starpa/data/config.txt\" rel=\"nofollow\">Configuration file</a>,\n<a href=\"https://raw.githubusercontent.com/luidale/starpa/master/src/starpa/data/flaimapper_parameters/parameters.dev-2-100-2.txt\" rel=\"nofollow\">\u201cflaimapper parameter file\u201d</a> and\n<a href=\"https://raw.githubusercontent.com/luidale/starpa/master/src/starpa/data/libraries.txt\" rel=\"nofollow\">\u201clibrary_file\u201d</a> are available in:</p>\n<pre>src/starpa/data\n</pre>\n<div>\n<div><br></div>\n</div>\n<p><strong>Input folder</strong></p>\n<p>While running a single or multiple tasks, the input folder has to contain specific data\nrequired for the first task.\nFor the following task the preceding tasks will prepare proper data.</p>\n<p>Each task has different requirements for the input data:</p>\n<ul>\n<li><em>trim</em></li>\n</ul>\n<div>\n<div>Sequencing data in <a href=\"https://en.wikipedia.org/wiki/FASTQ_format\" rel=\"nofollow\">FastQ format</a>.</div>\n<div>Can be in PE or SE format which has to be indicated in\n<a href=\"https://raw.githubusercontent.com/luidale/starpa/master/src/starpa/data/config.txt\" rel=\"nofollow\">configuration file</a> .</div>\n<div>FastQ files can be compressed as \u201c.gz\u201d, \u201c.bz2\u201d or \u201c.xz\u201d.</div>\n</div>\n<ul>\n<li><em>align</em></li>\n</ul>\n<div>\n<div>Trimmed and cleaned reads in <a href=\"https://en.wikipedia.org/wiki/FASTQ_format\" rel=\"nofollow\">FastQ format</a>.</div>\n<div>Can be in PE or SE format which has to be indicated in\n<a href=\"https://raw.githubusercontent.com/luidale/starpa/master/src/starpa/data/config.txt\" rel=\"nofollow\">configuration file</a> .</div>\n<div>FastQ files can be compressed as \u201c.gz\u201d (requires bowtie2.3.1+)</div>\n</div>\n<ul>\n<li><em>sam_sort</em></li>\n</ul>\n<div>\n<div>Aligned reads in SAM format.</div>\n<div>Can be in PE or SE format which has to be indicated in\n<a href=\"https://raw.githubusercontent.com/luidale/starpa/master/src/starpa/data/config.txt\" rel=\"nofollow\">configuration file</a> .</div>\n</div>\n<div>\n<div>BAM format is not currently supported.</div>\n</div>\n<ul>\n<li><em>pseudoSE</em></li>\n</ul>\n<div>\n<div>Aligned reads in SAM format.</div>\n<div>Can be in PE or SE format which has to be indicated in\n<a href=\"https://raw.githubusercontent.com/luidale/starpa/master/src/starpa/data/config.txt\" rel=\"nofollow\">configuration file</a> .</div>\n<div>File can not be sorted by position.</div>\n</div>\n<div>\n<div>BAM format is not currently supported.</div>\n</div>\n<ul>\n<li><em>identify</em></li>\n</ul>\n<div>\n<div>Aligned SE or pseudoSE reads in SAM format.</div>\n<div>Reads require NH tag to describe the number of reported alignments.</div>\n</div>\n<div>\n<div>BAM format currently not supported.</div>\n</div>\n<ul>\n<li><em>cluster</em></li>\n</ul>\n<div>\n<div>Identified and quantified predicted processing products in BED format</div>\n<div>(quantification at column #6).</div>\n</div>\n<div>\n<div>folder bam:</div>\n<div>\n<div>Aligned SE or pseudoSE reads in BAM format.</div>\n<div>Reads require NH tag to describe the number of reported alignments.</div>\n</div>\n</div>\n<div>\n<div>If task \u201cquantify\u201d will be also executed:</div>\n<div>\n<div>Additional input folder (given by parameter \u201cquantify_sam_file_location\u201d):</div>\n<div>\n<div>Aligned SE or pseudoSE reads in SAM format</div>\n<div>(BAM format currently not supported).</div>\n<div>Reads require NH tag to describe the number of reported alignments.</div>\n</div>\n</div>\n</div>\n<ul>\n<li><em>quantify</em></li>\n</ul>\n<div>\n<div>Predicted processing products in BED format (preferentially representatives form clustering).</div>\n</div>\n<div>\n<div>Additional input folder (given by parameter \u201cquantify_sam_file_location\u201d):</div>\n<div>\n<div>Aligned SE or pseudoSE reads in SAM format (BAM format currently not supported).</div>\n<div>Reads require NH tag to describe the number of reported alignments.</div>\n</div>\n</div>\n<p><strong>Output folder</strong></p>\n<p>Output folder will contain parameter folder:</p>\n<pre>parameters/\n       eg. config.txt                  -       copy of configuration file\n       arguments.txt                   -       command line arguments\n       eg. libraries.txt               -       copy of library file\n       eg. parameters.dev-2-100-2.txt  -       copy of Flaimapper-2 parameter file\n</pre>\n<p>Each task creates a subfolder with its name containing specific output\nof the task.</p>\n<div>\n<div>XXX - library name</div>\n<div>strand - For or Rev</div>\n<div>Y -   order number of fragmented read group</div>\n</div>\n<ul>\n<li><em>trim</em></li>\n</ul>\n<pre>trim_info/\n       XXX_triminfo.log        -       log of task\n       XXX_triminfo.error      -       collected errors during trimming\n\nPE:\ndiscard/\n       XXX_1_short.fq          -       forward reads discared while being too short after\n                                       trimming\n       XXX_2_short.fq          -       reverse reads discared while being too short after\n                                       trimming\n\nXXX_trim_1.fq                  -       trimmed forward reads\nXXX_trim_2.fq                  -       trimmed reverse reads\n\nSE:\ndiscard/\n       XXX_short.fq            -       reads discarded while being too short after\n                                       trimming\n       XXX_untrimmed.fq        -       reads discarded while having no adapter trimmed\n\nXXX_trim.fq                    -       trimmed reads\n</pre>\n<ul>\n<li><em>align</em></li>\n</ul>\n<pre>align_info/\n       XXX_aligninfo.log       -       log of task\n\nXXX.sam                        -       aligned reads\n</pre>\n<ul>\n<li><em>sam_sort</em></li>\n</ul>\n<pre>sort_info/\n       XXX_sortinfo.log        -       log of task\n\nXXX_unmapped.sam               -       unmapped reads\nXXX_sort.sam                   -       processed reads\n</pre>\n<ul>\n<li><em>pseudoSE</em></li>\n</ul>\n<pre>pseudoSE_info/\n       XXX_pseudoSEinfo.log            -       log of task\n\nmismatched/\n       XXX_pseudoSE_mismatch.sam       -       reads discarded while having too many\n                                               mismatches\n\ntoo_many_matches/\n       XXX_pseudoSE_multimatch.sam     -       reads discarded while haveing too many\n                                               genomic matches\n\nXXX_pseudoSE.sam                       -       processed reads\n\nIf oligoA allowed:\noligoA/\n       XXX-oligoA-mm_pseudoSE.sam      -       reads with 3' oligoA (non-genome\n                                               encoded) which would have otherwise\n                                               discarded\n       XXX-oligoA-pseudoSE.sam         -       reads with 3' oligoA (non-genome\n                                               encoded)\n</pre>\n<ul>\n<li><em>identify</em></li>\n</ul>\n<pre>flaimapper/\n       flaimapper_info/\n               XXX/\n                       XXX_strand_Y_flaimapper.information     -       log of flaimapper\n\n       flaimapper_temp/\n               XXX/\n                       XXX_strand_Y_flaimapper.tab             -       flaimapper predicitons\n\nbam/\n       XXX_strand.bam                                          -       strand-wise sorted reads\n                                                                       from input\n       XXX_strand.bam.bai                                      -       index of of bam file\n       XXX_strand.sam                                          -       NOT NEEDED\n\nidentify_info/\n        XXX_strand_identifyinfo.log                            -       log of task\n\nXXX_strand_pp.BED                                              -       NOT NEEDED\nXXX_strand_pp_counted.BED                                      -       predicted processing\n                                                                       products with\n                                                                       quantification\n</pre>\n<ul>\n<li><em>cluster</em></li>\n</ul>\n<pre>cd_hit_est/\n       pp_cd_hit_est.info              -       log of sequence identity based clustering\n                                               of combined and overlap clustered predicted\n                                               processing products via CD-HIT-EST\n       pp_combined.cdhit               -       genomic sequence of combined and overlap\n                                               clustered predicted processing products\n       pp_combined.cdhit.clstr         -       clusters of combined and overlap clustered\n                                               predicted processing products created via\n                                               CD-HIT-EST\n\ncontigs/\n       XXX_contigs.BED                 -       list of contigs identified\n       XXX/\n               contig_name.fasta       -       sequences of all reads belonging to the\n                                               corresponding contigs\n               contig_name.sam         -       all reads belonging to the\n                                               corresponding contigs\n\ncontigs_meta/\n       combined_contigs_meta.BED       -       combined contigs to be used to create\n                                               metacontigs from all libraries\n       XXX_contigs_meta.BED            -       list of contigs to be used to created\n                                               metacontigs\n       metacontig_cd_hit_est.info      -       log of sequence identity based clustering\n                                               of metacontigs via CD-HIT-EST\n       metacontigs.cdhit               -       genomic sequence of metacontigs\n       metacontigs.cdhit.clstr         -       clusters of metacontigs created via\n                                               CD-HIT-EST\n       metacontigs.BED                 -       list of metacontigs in bed format\n       pp_to_metacontig.BED            -       combined and overlap clustered predicted\n                                               processing product match with metacontigs\n                                               in BED-like format\n\nmpileup/\n       XXX_strand_mpileup.info         -       log of bedtools mpileup\n\nwig/\n       XXX_strand.wig                  -       strand specific absolute read coverage\n       XXX_strand_RPM.wig              -       strand specific relative read coverage\n                                               as read per million mapped reads (RPM)\n\npp_clusterinfo.log                     -       log of task\npp_unique.library_info                 -       combined predicted processing\n                                               products and the origins of libraries\npp_combined.BED                        -       representatives of combined and overlap\n                                               clustered predicted processing products\n                                               in BED format\npp_combined.cluster                    -       overlap clusters of combined predicted\n                                               processing products\npp_combined.library_info               -       representatives of combined and overlap\n                                               clustered predicted processing\n                                               products and the origins of libraries\npp_metacontig.BED                      -       representatives of predicted processing\n                                               products from pp_combined.BED clustered\n                                               by sequence identity supported by\n                                               metacontig clustering in BED format\npp_metacontig.cluster                  -       sequence identity clusters of predicted\n                                               processing products from pp_combined.BED\n                                               supported by metacontig clustering\n</pre>\n<ul>\n<li><em>quantify</em></li>\n</ul>\n<pre>libraries/                                     -       data in library wise\n       XXX.biotype_annotation.statistics       -       read alignement statistics\n                                                       by annotation biotypes\n       XXX.gene_annotation.statistics          -       read alignement statistics\n                                                       by genes\n       pp_metacontig_XXX_counted.BED           -       absolute quantification of\n                                                       predicted processing products\n                                                       in BED format\n\ncollected.annotation2.statistics               -       combined alignement     statistics\n                                                       by annotation biotypes\npp_metacontig_biotype.BED                      -       predicted processing products\n                                                       with biotype in BED-like format\npp_metacontig_biotype_match.BED                -       predicted processing products\n                                                       match with genes in BED-like\n                                                       format\npp_metacontig_counts_total.tsv                 -       absolute quantification of\n                                                       predicted processing products\n                                                       in BED format\npp_metacontig_counts_RPM.tsv                   -       relative quantification of\n                                                       predicted processing products\n                                                       as read per million mapped reads\n                                                       (RPM) in BED format\npp_metacontig_counts_biotype_RPM.tsv           -       relative quantification of\n                                                       predicted processing products\n                                                       as RPM of biotype in BED format\npp_metacontig_counts_groupped_biotype_RPM.tsv  -       relative quantification of\n                                                       predicted processing products\n                                                       as RPM of biotype groups in BED\n                                                       format\npp_metacontig_cons_qual.tsv                    -       quality of consensus sequence\n                                                       of predicted processing products\n                                                       expressed as frequency of the most\n                                                       abundant base in a given position\npp_metacontig_cons_seq.tsv                     -       consensus sequence of predicted\n                                                       processing products\npp_metacontig_coverage.tsv                     -       coverage of reads assigned to\n                                                       predicted processing products\n                                                       at single position level\npp_metacontig_genomic_seq.tsv                  -       genomic sequence of predicted\n                                                       processing products\npp_metacontig_rel_cov.tsv                      -       relative coverage of predicted\n                                                       processing products\npp_metacontig_uniqness.tsv                     -       mean number of genomic genomic\n                                                       matches of reads assigned\n                                                       to the predicted processing\n                                                       products\n</pre>\n</div>\n<div id=\"to-do\">\n<h2>To do</h2>\n</div>\n<div id=\"licence\">\n<h2>Licence</h2>\n<p><a href=\"https://github.com/luidale/starpa/blob/master/LICENSE\" rel=\"nofollow\">GNU General Public License v3.0</a></p>\n</div>\n<div id=\"authors\">\n<h2>Authors</h2>\n<p><cite>starpa</cite> was written by <a href=\"mailto:luidale%40gmail.com\">Hannes Luidalepp</a></p>\n</div>\n\n          </div>"}, "last_serial": 3835555, "releases": {"0.2.1": [{"comment_text": "", "digests": {"md5": "da9a07166d7d5d17dbf9a164709b0581", "sha256": "bd625187f7b9d4cd45537dfa1bdc753e20c91a2af01a0658f110e612d186a292"}, "downloads": -1, "filename": "starpa-0.2.1.tar.gz", "has_sig": false, "md5_digest": "da9a07166d7d5d17dbf9a164709b0581", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 66890, "upload_time": "2018-03-23T01:15:47", "upload_time_iso_8601": "2018-03-23T01:15:47.851500Z", "url": "https://files.pythonhosted.org/packages/6d/14/eb427760e36c125a0aa3eb34507485ad1e09bf320f9f5218178768982687/starpa-0.2.1.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "3de9d93c0bd08cba60c716ddafea329f", "sha256": "c8e7d7b5f7ddd8b569b3a378cc752c08b7a234ece018472fc2804a361deae675"}, "downloads": -1, "filename": "starpa-0.3.0.tar.gz", "has_sig": false, "md5_digest": "3de9d93c0bd08cba60c716ddafea329f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 69014, "upload_time": "2018-05-04T20:06:31", "upload_time_iso_8601": "2018-05-04T20:06:31.462013Z", "url": "https://files.pythonhosted.org/packages/00/bc/8094ec1d23f3c00d12f44aa753d742e7d48e993e0f0c16cdfb20634ca853/starpa-0.3.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "3de9d93c0bd08cba60c716ddafea329f", "sha256": "c8e7d7b5f7ddd8b569b3a378cc752c08b7a234ece018472fc2804a361deae675"}, "downloads": -1, "filename": "starpa-0.3.0.tar.gz", "has_sig": false, "md5_digest": "3de9d93c0bd08cba60c716ddafea329f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 69014, "upload_time": "2018-05-04T20:06:31", "upload_time_iso_8601": "2018-05-04T20:06:31.462013Z", "url": "https://files.pythonhosted.org/packages/00/bc/8094ec1d23f3c00d12f44aa753d742e7d48e993e0f0c16cdfb20634ca853/starpa-0.3.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:02:34 2020"}