{"info": {"author": "Adam Griffiths", "author_email": "UNKNOWN", "bugtrack_url": null, "classifiers": [], "description": "==============\nAmazon Scraper\n==============\n\nA Hybrid Web scraper / API client. Supplements the standard Amazon API with web\nscraping functionality to get extra data. Specifically, product reviews.\n\nUses the `Amazon Simple Product API <https://pypi.python.org/pypi/python-amazon-simple-product-api/>`_\nto provide API accessible data. API search functions are imported directly into\nthe amazon_scraper module.\n\nParameters are in the same style as the Amazon Simple Product API, which in\nturn uses Bottlenose style parameters. Hence the non-Pythonic parameter names (ItemId).\n\n\nThe AmazonScraper constructor will pass 'args' and 'kwargs' to `Bottlenose <https://github.com/lionheart/bottlenose>`_ (via Amazon Simple Product API).\nBottlenose supports AWS regions, queries per second limiting, query caching and other nice features. Please view Bottlenose' API for more information on this.\n\nThe latest version of python-amazon-simple-product-api (1.5.0 at time of writing), doesn't support these arguemnts, only Region.\nIf you require these, please use the latest code from their repository with the following command::\n\n    pip install git+https://github.com/yoavaviram/python-amazon-simple-product-api.git#egg=python-amazon-simple-product-api\n\n\nCaveat\n======\n\nAmazon continually try and keep scrapers from working, they do this by:\n\n* A/B testing (randomly receive different HTML).\n* Huge numbers of HTML layouts for the same product categories.\n* Changing HTML layouts.\n* Moving content inside iFrames.\n\nAmazon have resorted to moving more and more content into iFrames which this scraper can't handle.\nI envisage a time where most data will be inaccessible without more complex logic.\n\nI've spent a long time trying to get these scrapers working and it's a never ending battle.\nI don't have the time to continually keep up the pace with Amazon.\nIf you are interested in improving Amazon Scraper, please let me know (creating an issue is fine).\nAny help is appreciated.\n\n\nInstallation\n============\n\n::\n\n    pip install amazon_scraper\n\n\nDependencies\n============\n\n* `python-amazon-simple-product-api <https://pypi.python.org/pypi/python-amazon-simple-product-api/>`_\n* `requests <http://docs.python-requests.org/en/latest/>`_\n* `beautifulsoup4 <http://www.crummy.com/software/BeautifulSoup/>`_\n* `xmltodict <https://github.com/martinblech/xmltodict>`_\n* `python-dateutil <https://dateutil.readthedocs.org/en/latest/>`_\n\n\nExamples\n========\n\nAll Products All The Time\n~~~~~~~~~~~~~~~~~~~~~~~~~\nCreate an API instance::\n\n    >>> from amazon_scraper import AmazonScraper\n    >>> amzn = AmazonScraper(\"put your access key\", \"secret key\", \"and associate tag here\")\n\n\nThe creation function accepts 'kwargs' which are passed to 'bottlenose.Amazon' constructor::\n\n    >>> from amazon_scraper import AmazonScraper\n    >>> amzn = AmazonScraper(\"put your access key\", \"secret key\", \"and associate tag here\", Region='UK', MaxQPS=0.9, Timeout=5.0)\n\n\nSearch::\n\n    >>> from __future__ import print_function\n    >>> import itertools\n    >>> for p in itertools.islice(amzn.search(Keywords='python', SearchIndex='Books'), 5):\n    >>>     print(p.title)\n    Learning Python, 5th Edition\n    Python Programming: An Introduction to Computer Science 2nd Edition\n    Python In A Day: Learn The Basics, Learn It Quick, Start Coding Fast (In A Day Books) (Volume 1)\n    Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython\n    Python Cookbook\n\n\nLookup by ASIN/ItemId::\n\n    >>> p = amzn.lookup(ItemId='B00FLIJJSA')\n    >>> p.title\n    Kindle, Wi-Fi, 6\" E Ink Display - for international shipment\n    >>> p.url\n    http://www.amazon.com/Kindle-Wi-Fi-Ink-Display-international/dp/B0051QVF7A/ref=cm_cr_pr_product_top\n\n\nBatch Lookups::\n\n    >>> for p in amzn.lookup(ItemId='B0051QVF7A,B007HCCNJU,B00BTI6HBS'):\n    >>>     print(p.title)\n    Kindle, Wi-Fi, 6\" E Ink Display - for international shipment\n    Kindle, 6\" E Ink Display, Wi-Fi - Includes Special Offers (Black)\n    Kindle Paperwhite 3G, 6\" High Resolution Display with Next-Gen Built-in Light, Free 3G + Wi-Fi - Includes Special Offers\n\n\nBy URL::\n\n    >>> p = amzn.lookup(URL='http://www.amazon.com/Kindle-Wi-Fi-Ink-Display-international/dp/B0051QVF7A/ref=cm_cr_pr_product_top')\n    >>> p.title\n    Kindle, Wi-Fi, 6\" E Ink Display - for international shipment\n    >>> p.asin\n    B0051QVF7A\n\n\nProduct Ratings::\n\n    >>> p = amzn.lookup(ItemId='B00FLIJJSA')\n    >>> p.ratings\n    [8, 4, 6, 4, 13]\n\n\nAlternative Bindings::\n\n    >>> p = amzn.lookup(ItemId='B000GRFTPS')\n    >>> p.alternatives\n    ['B00IVM5X7E', '9163192993', '0899669433', 'B00IPXPQ9O', '1482998742', '0441444814', '1497344824']\n    >>> for asin in p.alternatives:\n    >>>     alt = amzn.lookup(ItemId=asin)\n    >>>     print(alt.title, alt.binding)\n    The King in Yellow Kindle Edition\n    The King in Yellow Unknown Binding\n    King in Yellow Hardcover\n    The Yellow Sign Audible Audio Edition\n    The King in Yellow MP3 CD\n    THE KING IN YELLOW Mass Market Paperback\n    The King in Yellow Paperback\n\n\nSupplemental text not available via the API::\n\n    >>> p = amzn.lookup(ItemId='0441016685')\n    >>> p.supplemental_text\n    [u\"Bob Howard is a computer-hacker desk jockey ... \", u\"Lovecraft\\'s Cthulhu meets Len Deighton\\'s spies ... \", u\"This dark, funny blend of SF and ... \"]\n\n\nReview API\n~~~~~~~~~~\nView lists of reviews::\n\n    >>> p = amzn.lookup(ItemId='B0051QVF7A')\n    >>> rs = p.reviews()\n    >>> rs.asin\n    B0051QVF7A\n    >>> # print the reviews on this first page\n    >>> rs.ids\n    ['R3MF0NIRI3BT1E', 'R3N2XPJT4I1XTI', 'RWG7OQ5NMGUMW', 'R1FKKJWTJC4EAP', 'RR8NWZ0IXWX7K', 'R32AU655LW6HPU', 'R33XK7OO7TO68E', 'R3NJRC6XH88RBR', 'R21JS32BNNQ82O', 'R2C9KPSEH78IF7']\n    >>> rs.url\n    http://www.amazon.com/product-reviews/B0051QVF7A/ref=cm_cr_pr_top_sort_recent?&sortBy=bySubmissionDateDescending\n    >>> # iterate over reviews on this page only\n    >>> for r in rs.brief_reviews:\n    >>>     print(r.id)\n    'R3MF0NIRI3BT1E'\n    'R3N2XPJT4I1XTI'\n    'RWG7OQ5NMGUMW'\n    ...\n    >>> # iterate over all brief reviews on all pages\n    >>> for r in rs:\n    >>>     print(r.id)\n    'R3MF0NIRI3BT1E'\n    'R3N2XPJT4I1XTI'\n    'RWG7OQ5NMGUMW'\n    ...\n\nView detailed reviews::\n\n    >>> rs = amzn.reviews(ItemId='B0051QVF7A')\n    >>> # this will iterate over all reviews on all pages\n    >>> # each review will require a download as it is on a seperate page\n    >>> for r in rs.full_reviews():\n    >>>     print(r.id)\n    'R3MF0NIRI3BT1E'\n    'R3N2XPJT4I1XTI'\n    'RWG7OQ5NMGUMW'\n    ...\n    \nConvert a brief review to a full review::\n\n    >>> rs = amzn.reviews(ItemId='B0051QVF7A')\n    >>> # this will iterate over all reviews on all pages\n    >>> # each review will require a download as it is on a seperate page\n    >>> for r in rs:\n    >>>     print(r.id)\n    >>>     fr = r.full_review()\n    >>>     print(fr.id)\n\nQuickly get a list of all reviews on a review page using the `all_reviews` property.\nThis uses the brief reviews provided on the review page to avoid downloading each review separately. As such, some information\nmay not be accessible::\n\n    >>> p = amzn.lookup(ItemId='B0051QVF7A')\n    >>> rs = p.reviews()\n    >>> all_reviews_on_page = list(rs)\n    >>> len(all_reviews_on_page)\n    10\n    >>> r = all_reviews_on_page[0]\n    >>> r.title\n    'Fantastic device - pick your Kindle!'\n    >>> fr = r.full_review()\n    >>> fr.title\n    'Fantastic device - pick your Kindle!'\n\nBy ASIN/ItemId::\n\n    >>> rs = amzn.reviews(ItemId='B0051QVF7A')\n    >>> rs.asin\n    B0051QVF7A\n    >>> rs.ids\n    ['R3MF0NIRI3BT1E', 'R3N2XPJT4I1XTI', 'RWG7OQ5NMGUMW', 'R1FKKJWTJC4EAP', 'RR8NWZ0IXWX7K', 'R32AU655LW6HPU', 'R33XK7OO7TO68E', 'R3NJRC6XH88RBR', 'R21JS32BNNQ82O', 'R2C9KPSEH78IF7']\n\n\nFor individual reviews use the `review` method::\n\n    >>> review_id = 'R3MF0NIRI3BT1E'\n    >>> r = amzn.review(Id=review_id)\n    >>> r.id\n    R3MF0NIRI3BT1E\n    >>> r.asin\n    B00492CIC8\n    >>> r.url\n    http://www.amazon.com/review/R3MF0NIRI3BT1E\n    >>> r.date\n    2011-09-29 18:27:14+00:00\n    >>> r.author\n    FreeSpirit\n    >>> r.text\n    Having been a little overwhelmed by the choices between all the new Kindles ... <snip>\n\n\nBy URL::\n\n    >>> r = amzn.review(URL='http://www.amazon.com/review/R3MF0NIRI3BT1E')\n    >>> r.id\n    R3MF0NIRI3BT1E\n\n\nUser Reviews API\n~~~~~~~~~~~~~~~~~~\nThis package also supports getting reviews written by a specific user.\n\nGet reviews that a single author has created::\n\n    >>> ur = amzn.user_reviews(Id=\"A2W0GY64CJSV5D\")\n    >>> ur.brief_reviews\n    >>> ur.name\n    >>> fr = list(ur.brief_reviews)[0].full_review()\n\n\nGet reviews for a user, from a review object\n\n    >>> r = amzn.review(Id=\"R3MF0NIRI3BT1E\")\n    >>> # we can get the reviews directly, or via the API with a URL or ID\n    >>> ur = r.user_reviews()\n    >>> ur = amzn.user_reviews(URL=r.author_reviews_url)\n    >>> ur = amzn.user_reviews(Id=r.author_id)\n    >>> ur.brief_reviews\n    >>> ur.name\n\n\nIterate over the current page's reviews::\n\n    >>> ur = amzn.user_reviews(Id=\"A2W0GY64CJSV5D\")\n    >>> for r in ur.brief_reviews:\n    >>>     print(r.id)\n\n\nIterate over all author reviews::\n\n    >>> ur = amzn.user_reviews(Id=\"A2W0GY64CJSV5D\")\n    >>> for r in ur:\n    >>>     print(r.id)\n\n\n\nAuthors\n=======\n\n * `Adam Griffiths <https://github.com/adamlwgriffiths>`_\n * `Greg Rehm <https://github.com/hahnicity>`_", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/adamlwgriffiths/amazon_scraper", "keywords": null, "license": "BSD", "maintainer": null, "maintainer_email": null, "name": "amazon_scraper", "package_url": "https://pypi.org/project/amazon_scraper/", "platform": "any", "project_url": "https://pypi.org/project/amazon_scraper/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/adamlwgriffiths/amazon_scraper"}, "release_url": "https://pypi.org/project/amazon_scraper/0.3.3/", "requires_dist": null, "requires_python": null, "summary": "Provides content not accessible through the standard Amazon API", "version": "0.3.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>A Hybrid Web scraper / API client. Supplements the standard Amazon API with web\nscraping functionality to get extra data. Specifically, product reviews.</p>\n<p>Uses the <a href=\"https://pypi.python.org/pypi/python-amazon-simple-product-api/\" rel=\"nofollow\">Amazon Simple Product API</a>\nto provide API accessible data. API search functions are imported directly into\nthe amazon_scraper module.</p>\n<p>Parameters are in the same style as the Amazon Simple Product API, which in\nturn uses Bottlenose style parameters. Hence the non-Pythonic parameter names (ItemId).</p>\n<p>The AmazonScraper constructor will pass \u2018args\u2019 and \u2018kwargs\u2019 to <a href=\"https://github.com/lionheart/bottlenose\" rel=\"nofollow\">Bottlenose</a> (via Amazon Simple Product API).\nBottlenose supports AWS regions, queries per second limiting, query caching and other nice features. Please view Bottlenose\u2019 API for more information on this.</p>\n<p>The latest version of python-amazon-simple-product-api (1.5.0 at time of writing), doesn\u2019t support these arguemnts, only Region.\nIf you require these, please use the latest code from their repository with the following command:</p>\n<pre>pip install git+https://github.com/yoavaviram/python-amazon-simple-product-api.git#egg=python-amazon-simple-product-api\n</pre>\n<div id=\"caveat\">\n<h2>Caveat</h2>\n<p>Amazon continually try and keep scrapers from working, they do this by:</p>\n<ul>\n<li>A/B testing (randomly receive different HTML).</li>\n<li>Huge numbers of HTML layouts for the same product categories.</li>\n<li>Changing HTML layouts.</li>\n<li>Moving content inside iFrames.</li>\n</ul>\n<p>Amazon have resorted to moving more and more content into iFrames which this scraper can\u2019t handle.\nI envisage a time where most data will be inaccessible without more complex logic.</p>\n<p>I\u2019ve spent a long time trying to get these scrapers working and it\u2019s a never ending battle.\nI don\u2019t have the time to continually keep up the pace with Amazon.\nIf you are interested in improving Amazon Scraper, please let me know (creating an issue is fine).\nAny help is appreciated.</p>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<pre>pip install amazon_scraper\n</pre>\n</div>\n<div id=\"dependencies\">\n<h2>Dependencies</h2>\n<ul>\n<li><a href=\"https://pypi.python.org/pypi/python-amazon-simple-product-api/\" rel=\"nofollow\">python-amazon-simple-product-api</a></li>\n<li><a href=\"http://docs.python-requests.org/en/latest/\" rel=\"nofollow\">requests</a></li>\n<li><a href=\"http://www.crummy.com/software/BeautifulSoup/\" rel=\"nofollow\">beautifulsoup4</a></li>\n<li><a href=\"https://github.com/martinblech/xmltodict\" rel=\"nofollow\">xmltodict</a></li>\n<li><a href=\"https://dateutil.readthedocs.org/en/latest/\" rel=\"nofollow\">python-dateutil</a></li>\n</ul>\n</div>\n<div id=\"examples\">\n<h2>Examples</h2>\n<div id=\"all-products-all-the-time\">\n<h3>All Products All The Time</h3>\n<p>Create an API instance:</p>\n<pre>&gt;&gt;&gt; from amazon_scraper import AmazonScraper\n&gt;&gt;&gt; amzn = AmazonScraper(\"put your access key\", \"secret key\", \"and associate tag here\")\n</pre>\n<p>The creation function accepts \u2018kwargs\u2019 which are passed to \u2018bottlenose.Amazon\u2019 constructor:</p>\n<pre>&gt;&gt;&gt; from amazon_scraper import AmazonScraper\n&gt;&gt;&gt; amzn = AmazonScraper(\"put your access key\", \"secret key\", \"and associate tag here\", Region='UK', MaxQPS=0.9, Timeout=5.0)\n</pre>\n<p>Search:</p>\n<pre>&gt;&gt;&gt; from __future__ import print_function\n&gt;&gt;&gt; import itertools\n&gt;&gt;&gt; for p in itertools.islice(amzn.search(Keywords='python', SearchIndex='Books'), 5):\n&gt;&gt;&gt;     print(p.title)\nLearning Python, 5th Edition\nPython Programming: An Introduction to Computer Science 2nd Edition\nPython In A Day: Learn The Basics, Learn It Quick, Start Coding Fast (In A Day Books) (Volume 1)\nPython for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython\nPython Cookbook\n</pre>\n<p>Lookup by ASIN/ItemId:</p>\n<pre>&gt;&gt;&gt; p = amzn.lookup(ItemId='B00FLIJJSA')\n&gt;&gt;&gt; p.title\nKindle, Wi-Fi, 6\" E Ink Display - for international shipment\n&gt;&gt;&gt; p.url\nhttp://www.amazon.com/Kindle-Wi-Fi-Ink-Display-international/dp/B0051QVF7A/ref=cm_cr_pr_product_top\n</pre>\n<p>Batch Lookups:</p>\n<pre>&gt;&gt;&gt; for p in amzn.lookup(ItemId='B0051QVF7A,B007HCCNJU,B00BTI6HBS'):\n&gt;&gt;&gt;     print(p.title)\nKindle, Wi-Fi, 6\" E Ink Display - for international shipment\nKindle, 6\" E Ink Display, Wi-Fi - Includes Special Offers (Black)\nKindle Paperwhite 3G, 6\" High Resolution Display with Next-Gen Built-in Light, Free 3G + Wi-Fi - Includes Special Offers\n</pre>\n<p>By URL:</p>\n<pre>&gt;&gt;&gt; p = amzn.lookup(URL='http://www.amazon.com/Kindle-Wi-Fi-Ink-Display-international/dp/B0051QVF7A/ref=cm_cr_pr_product_top')\n&gt;&gt;&gt; p.title\nKindle, Wi-Fi, 6\" E Ink Display - for international shipment\n&gt;&gt;&gt; p.asin\nB0051QVF7A\n</pre>\n<p>Product Ratings:</p>\n<pre>&gt;&gt;&gt; p = amzn.lookup(ItemId='B00FLIJJSA')\n&gt;&gt;&gt; p.ratings\n[8, 4, 6, 4, 13]\n</pre>\n<p>Alternative Bindings:</p>\n<pre>&gt;&gt;&gt; p = amzn.lookup(ItemId='B000GRFTPS')\n&gt;&gt;&gt; p.alternatives\n['B00IVM5X7E', '9163192993', '0899669433', 'B00IPXPQ9O', '1482998742', '0441444814', '1497344824']\n&gt;&gt;&gt; for asin in p.alternatives:\n&gt;&gt;&gt;     alt = amzn.lookup(ItemId=asin)\n&gt;&gt;&gt;     print(alt.title, alt.binding)\nThe King in Yellow Kindle Edition\nThe King in Yellow Unknown Binding\nKing in Yellow Hardcover\nThe Yellow Sign Audible Audio Edition\nThe King in Yellow MP3 CD\nTHE KING IN YELLOW Mass Market Paperback\nThe King in Yellow Paperback\n</pre>\n<p>Supplemental text not available via the API:</p>\n<pre>&gt;&gt;&gt; p = amzn.lookup(ItemId='0441016685')\n&gt;&gt;&gt; p.supplemental_text\n[u\"Bob Howard is a computer-hacker desk jockey ... \", u\"Lovecraft\\'s Cthulhu meets Len Deighton\\'s spies ... \", u\"This dark, funny blend of SF and ... \"]\n</pre>\n</div>\n<div id=\"review-api\">\n<h3>Review API</h3>\n<p>View lists of reviews:</p>\n<pre>&gt;&gt;&gt; p = amzn.lookup(ItemId='B0051QVF7A')\n&gt;&gt;&gt; rs = p.reviews()\n&gt;&gt;&gt; rs.asin\nB0051QVF7A\n&gt;&gt;&gt; # print the reviews on this first page\n&gt;&gt;&gt; rs.ids\n['R3MF0NIRI3BT1E', 'R3N2XPJT4I1XTI', 'RWG7OQ5NMGUMW', 'R1FKKJWTJC4EAP', 'RR8NWZ0IXWX7K', 'R32AU655LW6HPU', 'R33XK7OO7TO68E', 'R3NJRC6XH88RBR', 'R21JS32BNNQ82O', 'R2C9KPSEH78IF7']\n&gt;&gt;&gt; rs.url\nhttp://www.amazon.com/product-reviews/B0051QVF7A/ref=cm_cr_pr_top_sort_recent?&amp;sortBy=bySubmissionDateDescending\n&gt;&gt;&gt; # iterate over reviews on this page only\n&gt;&gt;&gt; for r in rs.brief_reviews:\n&gt;&gt;&gt;     print(r.id)\n'R3MF0NIRI3BT1E'\n'R3N2XPJT4I1XTI'\n'RWG7OQ5NMGUMW'\n...\n&gt;&gt;&gt; # iterate over all brief reviews on all pages\n&gt;&gt;&gt; for r in rs:\n&gt;&gt;&gt;     print(r.id)\n'R3MF0NIRI3BT1E'\n'R3N2XPJT4I1XTI'\n'RWG7OQ5NMGUMW'\n...\n</pre>\n<p>View detailed reviews:</p>\n<pre>&gt;&gt;&gt; rs = amzn.reviews(ItemId='B0051QVF7A')\n&gt;&gt;&gt; # this will iterate over all reviews on all pages\n&gt;&gt;&gt; # each review will require a download as it is on a seperate page\n&gt;&gt;&gt; for r in rs.full_reviews():\n&gt;&gt;&gt;     print(r.id)\n'R3MF0NIRI3BT1E'\n'R3N2XPJT4I1XTI'\n'RWG7OQ5NMGUMW'\n...\n</pre>\n<p>Convert a brief review to a full review:</p>\n<pre>&gt;&gt;&gt; rs = amzn.reviews(ItemId='B0051QVF7A')\n&gt;&gt;&gt; # this will iterate over all reviews on all pages\n&gt;&gt;&gt; # each review will require a download as it is on a seperate page\n&gt;&gt;&gt; for r in rs:\n&gt;&gt;&gt;     print(r.id)\n&gt;&gt;&gt;     fr = r.full_review()\n&gt;&gt;&gt;     print(fr.id)\n</pre>\n<p>Quickly get a list of all reviews on a review page using the <cite>all_reviews</cite> property.\nThis uses the brief reviews provided on the review page to avoid downloading each review separately. As such, some information\nmay not be accessible:</p>\n<pre>&gt;&gt;&gt; p = amzn.lookup(ItemId='B0051QVF7A')\n&gt;&gt;&gt; rs = p.reviews()\n&gt;&gt;&gt; all_reviews_on_page = list(rs)\n&gt;&gt;&gt; len(all_reviews_on_page)\n10\n&gt;&gt;&gt; r = all_reviews_on_page[0]\n&gt;&gt;&gt; r.title\n'Fantastic device - pick your Kindle!'\n&gt;&gt;&gt; fr = r.full_review()\n&gt;&gt;&gt; fr.title\n'Fantastic device - pick your Kindle!'\n</pre>\n<p>By ASIN/ItemId:</p>\n<pre>&gt;&gt;&gt; rs = amzn.reviews(ItemId='B0051QVF7A')\n&gt;&gt;&gt; rs.asin\nB0051QVF7A\n&gt;&gt;&gt; rs.ids\n['R3MF0NIRI3BT1E', 'R3N2XPJT4I1XTI', 'RWG7OQ5NMGUMW', 'R1FKKJWTJC4EAP', 'RR8NWZ0IXWX7K', 'R32AU655LW6HPU', 'R33XK7OO7TO68E', 'R3NJRC6XH88RBR', 'R21JS32BNNQ82O', 'R2C9KPSEH78IF7']\n</pre>\n<p>For individual reviews use the <cite>review</cite> method:</p>\n<pre>&gt;&gt;&gt; review_id = 'R3MF0NIRI3BT1E'\n&gt;&gt;&gt; r = amzn.review(Id=review_id)\n&gt;&gt;&gt; r.id\nR3MF0NIRI3BT1E\n&gt;&gt;&gt; r.asin\nB00492CIC8\n&gt;&gt;&gt; r.url\nhttp://www.amazon.com/review/R3MF0NIRI3BT1E\n&gt;&gt;&gt; r.date\n2011-09-29 18:27:14+00:00\n&gt;&gt;&gt; r.author\nFreeSpirit\n&gt;&gt;&gt; r.text\nHaving been a little overwhelmed by the choices between all the new Kindles ... &lt;snip&gt;\n</pre>\n<p>By URL:</p>\n<pre>&gt;&gt;&gt; r = amzn.review(URL='http://www.amazon.com/review/R3MF0NIRI3BT1E')\n&gt;&gt;&gt; r.id\nR3MF0NIRI3BT1E\n</pre>\n</div>\n<div id=\"user-reviews-api\">\n<h3>User Reviews API</h3>\n<p>This package also supports getting reviews written by a specific user.</p>\n<p>Get reviews that a single author has created:</p>\n<pre>&gt;&gt;&gt; ur = amzn.user_reviews(Id=\"A2W0GY64CJSV5D\")\n&gt;&gt;&gt; ur.brief_reviews\n&gt;&gt;&gt; ur.name\n&gt;&gt;&gt; fr = list(ur.brief_reviews)[0].full_review()\n</pre>\n<p>Get reviews for a user, from a review object</p>\n<blockquote>\n<pre>&gt;&gt;&gt; r = amzn.review(Id=\"R3MF0NIRI3BT1E\")\n&gt;&gt;&gt; # we can get the reviews directly, or via the API with a URL or ID\n&gt;&gt;&gt; ur = r.user_reviews()\n&gt;&gt;&gt; ur = amzn.user_reviews(URL=r.author_reviews_url)\n&gt;&gt;&gt; ur = amzn.user_reviews(Id=r.author_id)\n&gt;&gt;&gt; ur.brief_reviews\n&gt;&gt;&gt; ur.name\n</pre>\n</blockquote>\n<p>Iterate over the current page\u2019s reviews:</p>\n<pre>&gt;&gt;&gt; ur = amzn.user_reviews(Id=\"A2W0GY64CJSV5D\")\n&gt;&gt;&gt; for r in ur.brief_reviews:\n&gt;&gt;&gt;     print(r.id)\n</pre>\n<p>Iterate over all author reviews:</p>\n<pre>&gt;&gt;&gt; ur = amzn.user_reviews(Id=\"A2W0GY64CJSV5D\")\n&gt;&gt;&gt; for r in ur:\n&gt;&gt;&gt;     print(r.id)\n</pre>\n</div>\n</div>\n<div id=\"authors\">\n<h2>Authors</h2>\n<blockquote>\n<ul>\n<li><a href=\"https://github.com/adamlwgriffiths\" rel=\"nofollow\">Adam Griffiths</a></li>\n<li><a href=\"https://github.com/hahnicity\" rel=\"nofollow\">Greg Rehm</a></li>\n</ul>\n</blockquote>\n</div>\n\n          </div>"}, "last_serial": 4711206, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "cb1cfa7b7f1b24cf7ec5cb044c60a3d1", "sha256": "ef767adb1a43f7672a8350c8d8c108743ef8d019d3bb1b227bb694d028056313"}, "downloads": -1, "filename": "amazon_scraper-0.1.0.tar.gz", "has_sig": false, "md5_digest": "cb1cfa7b7f1b24cf7ec5cb044c60a3d1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6145, "upload_time": "2014-05-09T02:59:32", "upload_time_iso_8601": "2014-05-09T02:59:32.110144Z", "url": "https://files.pythonhosted.org/packages/0d/8e/d585ba6e90696ae56f1a8ef5c6f16963253da3328c4e5c5048409465b778/amazon_scraper-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "1e936b5b1c90d72113e3a1b45a1c47ad", "sha256": "dad787521c06378499aea41a255dd07bee21dbd708644583f9a79c1713b92aaa"}, "downloads": -1, "filename": "amazon_scraper-0.1.1.tar.gz", "has_sig": false, "md5_digest": "1e936b5b1c90d72113e3a1b45a1c47ad", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6151, "upload_time": "2014-05-09T03:18:57", "upload_time_iso_8601": "2014-05-09T03:18:57.141295Z", "url": "https://files.pythonhosted.org/packages/52/27/1fced36ee41ab5f008aba78c44a72f38cb17933b640bea0bedff40ba2f94/amazon_scraper-0.1.1.tar.gz", "yanked": false}], "0.1.10": [{"comment_text": "", "digests": {"md5": "e80fc11045bf20546ef73367036ebe60", "sha256": "69085f21a697509bff80bc682966e05ce327ff54f9d03e4a1abc9a23166c6896"}, "downloads": -1, "filename": "amazon_scraper-0.1.10.tar.gz", "has_sig": false, "md5_digest": "e80fc11045bf20546ef73367036ebe60", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8354, "upload_time": "2014-05-30T06:40:18", "upload_time_iso_8601": "2014-05-30T06:40:18.875267Z", "url": "https://files.pythonhosted.org/packages/af/8b/8faa957381055c8b4512f2d9bb329e6f86c31478cf905763c1a026f76dd0/amazon_scraper-0.1.10.tar.gz", "yanked": false}], "0.1.11": [{"comment_text": "", "digests": {"md5": "e86a5f621a3da8985795e7a2f2e79ac3", "sha256": "fd6993bba963fdf8f3dce6d7640eaa1aeb0743fe9ff6b80260798fa3eb89a86a"}, "downloads": -1, "filename": "amazon_scraper-0.1.11.tar.gz", "has_sig": false, "md5_digest": "e86a5f621a3da8985795e7a2f2e79ac3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8353, "upload_time": "2014-05-30T07:00:14", "upload_time_iso_8601": "2014-05-30T07:00:14.951915Z", "url": "https://files.pythonhosted.org/packages/6e/cf/d7aba031651cf6e509a0f1d60616e663e2dab80abdaffe2914e78bf7e1da/amazon_scraper-0.1.11.tar.gz", "yanked": false}], "0.1.12": [{"comment_text": "", "digests": {"md5": "5b6eceb4afaae089d2859a21e986d869", "sha256": "3bd5f2e332274cb44cdb03a4d0ddf0c2ae062926783c8bfde73089c199c6bb7a"}, "downloads": -1, "filename": "amazon_scraper-0.1.12.tar.gz", "has_sig": false, "md5_digest": "5b6eceb4afaae089d2859a21e986d869", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8461, "upload_time": "2014-05-30T07:20:22", "upload_time_iso_8601": "2014-05-30T07:20:22.785507Z", "url": "https://files.pythonhosted.org/packages/40/fc/8a670b0c5f5f78a7b0c7a1261936caa2f36cdf2ff1a75bc5579fab5bf280/amazon_scraper-0.1.12.tar.gz", "yanked": false}], "0.1.13": [{"comment_text": "", "digests": {"md5": "d501602e19774137d81b4cbd56021fa2", "sha256": "a3a8b51e2f105bb650d5546a7a2a2be1e7be460d1fb8d9b5a19c890594f2b870"}, "downloads": -1, "filename": "amazon_scraper-0.1.13.tar.gz", "has_sig": false, "md5_digest": "d501602e19774137d81b4cbd56021fa2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8460, "upload_time": "2014-05-30T07:24:39", "upload_time_iso_8601": "2014-05-30T07:24:39.805748Z", "url": "https://files.pythonhosted.org/packages/3c/82/f4f60f89c48eac0f84ab80f45483f02f5e4554b4bbbc063fbc34f14de61f/amazon_scraper-0.1.13.tar.gz", "yanked": false}], "0.1.14": [{"comment_text": "", "digests": {"md5": "702bcc2fc357c7644eae51b29c7cd70a", "sha256": "c558affe402e3e4c1915572b8c23291aac199cd200be8e8c6338a91b07d0fcd9"}, "downloads": -1, "filename": "amazon_scraper-0.1.14.tar.gz", "has_sig": false, "md5_digest": "702bcc2fc357c7644eae51b29c7cd70a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8474, "upload_time": "2014-05-30T07:44:05", "upload_time_iso_8601": "2014-05-30T07:44:05.741248Z", "url": "https://files.pythonhosted.org/packages/11/29/4cd6ee4be833d34bee2ac0054ea7521957bb3b8c1f8b7bcbafe7e02d531e/amazon_scraper-0.1.14.tar.gz", "yanked": false}], "0.1.16": [{"comment_text": "", "digests": {"md5": "55d6dc01e14d25e0b3043b6ef4117c7e", "sha256": "67ebb3bff1d4deb379b4480c4ef5febb4804bebc91e4a20506f75d8ea99e5f9b"}, "downloads": -1, "filename": "amazon_scraper-0.1.16.tar.gz", "has_sig": false, "md5_digest": "55d6dc01e14d25e0b3043b6ef4117c7e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8769, "upload_time": "2014-06-04T16:11:08", "upload_time_iso_8601": "2014-06-04T16:11:08.628771Z", "url": "https://files.pythonhosted.org/packages/5c/31/ad30de1e9a7ed40fb48d3d704b94572dd9004f7f2dbfe348fae674cf3d76/amazon_scraper-0.1.16.tar.gz", "yanked": false}], "0.1.17": [{"comment_text": "", "digests": {"md5": "68a3965e328a36ad528579318355df78", "sha256": "a6f33f8bd58e2044b057ca2ee5fecea3afa59ca39ab464cb167742645afbe131"}, "downloads": -1, "filename": "amazon_scraper-0.1.17.tar.gz", "has_sig": false, "md5_digest": "68a3965e328a36ad528579318355df78", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8945, "upload_time": "2014-09-11T06:54:51", "upload_time_iso_8601": "2014-09-11T06:54:51.853369Z", "url": "https://files.pythonhosted.org/packages/c2/29/f00c836ccd9e20c02d8574f94894031d97fe7acdcaa5eeb980bb63430e67/amazon_scraper-0.1.17.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "0a6f034102f26f1120092a48af42b39e", "sha256": "85d320ff4980282c92072c3f3ed512ba1cdb61f05e92d3fe76e6169d945675bc"}, "downloads": -1, "filename": "amazon_scraper-0.1.2.tar.gz", "has_sig": false, "md5_digest": "0a6f034102f26f1120092a48af42b39e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6752, "upload_time": "2014-05-09T09:17:37", "upload_time_iso_8601": "2014-05-09T09:17:37.902255Z", "url": "https://files.pythonhosted.org/packages/39/8d/57f6731ae8528c56b50a5270ccb8c3d5296f2430d1c35094237cbc84e16a/amazon_scraper-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "b45a1902d989dd294ad3669b6479a02c", "sha256": "c678f7b06720b7481d22809da40699d7f4077c5aaa9c82b564ca54bfe6b0970e"}, "downloads": -1, "filename": "amazon_scraper-0.1.3.tar.gz", "has_sig": false, "md5_digest": "b45a1902d989dd294ad3669b6479a02c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6784, "upload_time": "2014-05-10T06:26:29", "upload_time_iso_8601": "2014-05-10T06:26:29.024932Z", "url": "https://files.pythonhosted.org/packages/e2/c1/fc627a692c3bbfab75baa2d58cba2cf805ad9f6de485e5ea34f8ee4d5941/amazon_scraper-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "68ebfa18ecd6c10c7ab942535e1e84cb", "sha256": "f0e3608715ae08b74cf3326fcc3a1627f6578b9a5770ee5babf5a49f781932b0"}, "downloads": -1, "filename": "amazon_scraper-0.1.4.tar.gz", "has_sig": false, "md5_digest": "68ebfa18ecd6c10c7ab942535e1e84cb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6903, "upload_time": "2014-05-12T03:47:31", "upload_time_iso_8601": "2014-05-12T03:47:31.307609Z", "url": "https://files.pythonhosted.org/packages/a4/7f/70657972fc47cad07d3563a060fcc327c166307c6ed44d3ee04632293617/amazon_scraper-0.1.4.tar.gz", "yanked": false}], "0.1.5": [{"comment_text": "", "digests": {"md5": "ddff59c1044d8edb70862a8239f61768", "sha256": "74ec6d766e7be669a9eba54df71d3e8312c288ef18eaef212d15e37bcd434bc6"}, "downloads": -1, "filename": "amazon_scraper-0.1.5.tar.gz", "has_sig": false, "md5_digest": "ddff59c1044d8edb70862a8239f61768", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7041, "upload_time": "2014-05-16T03:07:21", "upload_time_iso_8601": "2014-05-16T03:07:21.974588Z", "url": "https://files.pythonhosted.org/packages/37/c0/5e2ca0862cc5109e12c88a9d6147c082b236e8f0fe3f241ff7777ed1e481/amazon_scraper-0.1.5.tar.gz", "yanked": false}], "0.1.6": [{"comment_text": "", "digests": {"md5": "17bc9c9a758f73bbe1709491b5acc684", "sha256": "f4d856dbc27400282f75b59c475ad639a406e0c3fda52dee47a7c43ba15cf730"}, "downloads": -1, "filename": "amazon_scraper-0.1.6.tar.gz", "has_sig": false, "md5_digest": "17bc9c9a758f73bbe1709491b5acc684", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7453, "upload_time": "2014-05-19T05:39:03", "upload_time_iso_8601": "2014-05-19T05:39:03.540632Z", "url": "https://files.pythonhosted.org/packages/b5/24/0bb936b1f7e1ee0923ec75b1f77685a049d9a7371851cc114087d16174da/amazon_scraper-0.1.6.tar.gz", "yanked": false}], "0.1.7": [{"comment_text": "", "digests": {"md5": "96223446f9de7878729ef7e318442696", "sha256": "bb6ce7c43fa7359a8be87073dd2831905ea96bf0cfd37cd1484418bb2bcac825"}, "downloads": -1, "filename": "amazon_scraper-0.1.7.tar.gz", "has_sig": false, "md5_digest": "96223446f9de7878729ef7e318442696", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8084, "upload_time": "2014-05-20T07:06:07", "upload_time_iso_8601": "2014-05-20T07:06:07.326387Z", "url": "https://files.pythonhosted.org/packages/ed/b1/62da08e4de3ca0f9933643856fe354ff0a6f168af5fe5b7d3b06e0e77ce0/amazon_scraper-0.1.7.tar.gz", "yanked": false}], "0.1.8": [{"comment_text": "", "digests": {"md5": "b9f9d60f2dbf2172a0e9f5fee1aef0c4", "sha256": "9aea265efe81e515fcf14a08cdd3443e30544d64d4fd8bdbcbe6ad69edc686c9"}, "downloads": -1, "filename": "amazon_scraper-0.1.8.tar.gz", "has_sig": false, "md5_digest": "b9f9d60f2dbf2172a0e9f5fee1aef0c4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8067, "upload_time": "2014-05-30T04:23:34", "upload_time_iso_8601": "2014-05-30T04:23:34.644718Z", "url": "https://files.pythonhosted.org/packages/ab/72/84146567db95bb4cbf0f91877ce2426aac12faa1360bfb6caf73e40a625d/amazon_scraper-0.1.8.tar.gz", "yanked": false}], "0.1.9": [{"comment_text": "", "digests": {"md5": "8c46ad5a2c460c1de3ec0544e5ce28bc", "sha256": "dd7dc341d17a10c5e813fd37fd20898c58a8c6c42eabac5af51f12114172a721"}, "downloads": -1, "filename": "amazon_scraper-0.1.9.tar.gz", "has_sig": false, "md5_digest": "8c46ad5a2c460c1de3ec0544e5ce28bc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8341, "upload_time": "2014-05-30T04:44:17", "upload_time_iso_8601": "2014-05-30T04:44:17.660760Z", "url": "https://files.pythonhosted.org/packages/b1/e3/2809a2319fed6c58451a30af9b2417c6c59775ca443eb7d6413f73311fd3/amazon_scraper-0.1.9.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "65d724f7f9fe8dd749827ff0cb40cc58", "sha256": "37c23dee05c25ce249c6087c977bd3306e67bb9f4c978e97015971d13706c9fa"}, "downloads": -1, "filename": "amazon_scraper-0.2.tar.gz", "has_sig": true, "md5_digest": "65d724f7f9fe8dd749827ff0cb40cc58", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12818, "upload_time": "2015-05-13T09:25:08", "upload_time_iso_8601": "2015-05-13T09:25:08.171290Z", "url": "https://files.pythonhosted.org/packages/ed/63/9779a99fa09e34d0b7393647a3034cd415bb21e36cc915347d4211274821/amazon_scraper-0.2.tar.gz", "yanked": false}], "0.3.0": [], "0.3.1": [{"comment_text": "", "digests": {"md5": "42f4ecb59d590eebc9adcd3cd9af2d1e", "sha256": "e18009433b1f8d69f3a159793687f8b5468c7cae5c276492d82cdce5d2f7fe48"}, "downloads": -1, "filename": "amazon_scraper-0.3.1.tar.gz", "has_sig": false, "md5_digest": "42f4ecb59d590eebc9adcd3cd9af2d1e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12695, "upload_time": "2015-09-30T07:14:53", "upload_time_iso_8601": "2015-09-30T07:14:53.290165Z", "url": "https://files.pythonhosted.org/packages/c2/e9/90f7c846c803dacf8f38b0d8e7286c82ff45a4ce271687b488cc9fa1a2f3/amazon_scraper-0.3.1.tar.gz", "yanked": false}], "0.3.2": [{"comment_text": "", "digests": {"md5": "2c058932c2ee01a1f9b8cc28aa27dba5", "sha256": "0386540b74e28da5d9510e49af863a463905d1166957b4f38a2ab2936c23afc3"}, "downloads": -1, "filename": "amazon_scraper-0.3.2.tar.gz", "has_sig": false, "md5_digest": "2c058932c2ee01a1f9b8cc28aa27dba5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12977, "upload_time": "2015-11-30T22:42:42", "upload_time_iso_8601": "2015-11-30T22:42:42.994200Z", "url": "https://files.pythonhosted.org/packages/5b/cc/7bcb9b7b96304ca23548e03bf59bb94af8ea82a28d692e6502425998246c/amazon_scraper-0.3.2.tar.gz", "yanked": false}], "0.3.3": [{"comment_text": "", "digests": {"md5": "d315a942711635cbe49aa0cceca3b041", "sha256": "db97edda0cd07da6756b81ad1c335582be7be783406fdcec7affee19d86006dd"}, "downloads": -1, "filename": "amazon_scraper-0.3.3.tar.gz", "has_sig": false, "md5_digest": "d315a942711635cbe49aa0cceca3b041", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13012, "upload_time": "2016-01-19T23:32:14", "upload_time_iso_8601": "2016-01-19T23:32:14.038707Z", "url": "https://files.pythonhosted.org/packages/20/cd/5224dcc16309ad7396e0cb447af30c3ca60b2fa91965e235800635ff401a/amazon_scraper-0.3.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "d315a942711635cbe49aa0cceca3b041", "sha256": "db97edda0cd07da6756b81ad1c335582be7be783406fdcec7affee19d86006dd"}, "downloads": -1, "filename": "amazon_scraper-0.3.3.tar.gz", "has_sig": false, "md5_digest": "d315a942711635cbe49aa0cceca3b041", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13012, "upload_time": "2016-01-19T23:32:14", "upload_time_iso_8601": "2016-01-19T23:32:14.038707Z", "url": "https://files.pythonhosted.org/packages/20/cd/5224dcc16309ad7396e0cb447af30c3ca60b2fa91965e235800635ff401a/amazon_scraper-0.3.3.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:18:24 2020"}