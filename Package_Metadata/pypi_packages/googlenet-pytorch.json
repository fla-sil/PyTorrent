{"info": {"author": "Liu Changyu", "author_email": "liuchangyu1111@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "\n# GoogLeNet-PyTorch\n\n### Update (Feb 17, 2020)\n\nThe update is for ease of use and deployment.\n\n * [Example: Export to ONNX](#example-export-to-onnx)\n * [Example: Extract features](#example-feature-extraction)\n * [Example: Visual](#example-visual)\n\nIt is also now incredibly simple to load a pretrained model with a new number of classes for transfer learning:\n\n```python\nfrom googlenet_pytorch import GoogLeNet \nmodel = GoogLeNet.from_pretrained('googlenet')\n```\n\n### Overview\nThis repository contains an op-for-op PyTorch reimplementation of [Going Deeper with Convolutions](https://arxiv.org/pdf/1409.4842.pdf).\n\nThe goal of this implementation is to be simple, highly extensible, and easy to integrate into your own projects. This implementation is a work in progress -- new features are currently being implemented.  \n\nAt the moment, you can easily:  \n * Load pretrained GoogLeNet models \n * Use VGGNet models for classification or feature extraction \n\n_Upcoming features_: In the next few days, you will be able to:\n * Quickly finetune an GoogLeNet on your own dataset\n * Export GoogLeNet models for production\n\n### Table of contents\n1. [About GoogLeNet](#about-googlenet)\n2. [Installation](#installation)\n3. [Usage](#usage)\n    * [Load pretrained models](#loading-pretrained-models)\n    * [Example: Classify](#example-classification)\n    * [Example: Extract features](#example-feature-extraction)\n    * [Example: Export to ONNX](#example-export-to-onnx)\n    * [Example: Visual](#example-visual)\n4. [Contributing](#contributing) \n\n### About GoogLeNet\n\nIf you're new to GoogLeNet, here is an explanation straight from the official PyTorch implementation: \n\nWe propose a deep convolutional neural network architecture codenamed \"Inception\", \nwhich was responsible for setting the new state of the art for classification and \ndetection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014). \nThe main hallmark of this architecture is the improved utilization of the computing \nresources inside the network. This was achieved by a carefully crafted design that allows \nfor increasing the depth and width of the network while keeping the computational budget \nconstant. To optimize quality, the architectural decisions were based on the Hebbian \nprinciple and the intuition of multi-scale processing. One particular incarnation used \nin our submission for ILSVRC 2014 is called GoogLeNet, a 22 layers deep network, the quality \nof which is assessed in the context of classification and detection.\n\n### Installation\n\nInstall from pypi:\n```bash\n$ pip install googlenet_pytorch\n```\n\nInstall from source:\n```bash\n$ git clone https://github.com/Lornatang/GoogLeNet-PyTorch.git\n$ cd GoogLeNet-PyTorch\n$ pip install -e .\n``` \n\n### Usage\n\n#### Loading pretrained models\n\nLoad a pretrained GoogLeNet: \n```python\nfrom googlenet_pytorch import GoogLeNet\nmodel = GoogLeNet.from_pretrained(\"googlenet\")\n```\n\nTheir 1-crop error rates on imagenet dataset with pretrained models are listed below.\n\n| Model structure | Top-1 error | Top-5 error |\n| --------------- | ----------- | ----------- |\n|  googlenet\t  |  30.22\t    |  10.47      |\n\n#### Example: Classification\n\nWe assume that in your current directory, there is a `img.jpg` file and a `labels_map.txt` file (ImageNet class names). These are both included in `examples/simple`. \n\nAll pre-trained models expect input images normalized in the same way,\ni.e. mini-batches of 3-channel RGB images of shape `(3 x H x W)`, where `H` and `W` are expected to be at least `224`.\nThe images have to be loaded in to a range of `[0, 1]` and then normalized using `mean = [0.485, 0.456, 0.406]`\nand `std = [0.229, 0.224, 0.225]`.\n\nHere's a sample execution.\n\n```python\nimport json\n\nimport torch\nimport torchvision.transforms as transforms\nfrom PIL import Image\n\nfrom googlenet_pytorch import GoogLeNet \n\n# Open image\ninput_image = Image.open(\"img.jpg\")\n\n# Preprocess image\npreprocess = transforms.Compose([\n  transforms.Resize(256),\n  transforms.CenterCrop(224),\n  transforms.ToTensor(),\n  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\ninput_tensor = preprocess(input_image)\ninput_batch = input_tensor.unsqueeze(0)  # create a mini-batch as expected by the model\n\n# Load class names\nlabels_map = json.load(open(\"labels_map.txt\"))\nlabels_map = [labels_map[str(i)] for i in range(1000)]\n\n# Classify with GoogLeNet\nmodel = GoogLeNet.from_pretrained(\"googlenet\")\nmodel.eval()\n\n# move the input and model to GPU for speed if available\nif torch.cuda.is_available():\n  input_batch = input_batch.to(\"cuda\")\n  model.to(\"cuda\")\n\nwith torch.no_grad():\n  logits = model(input_batch)\npreds = torch.topk(logits, k=5).indices.squeeze(0).tolist()\n\nprint(\"-----\")\nfor idx in preds:\n  label = labels_map[idx]\n  prob = torch.softmax(logits, dim=1)[0, idx].item()\n  print(f\"{label:<75} ({prob * 100:.2f}%)\")\n```\n\n#### Example: Feature Extraction \n\nYou can easily extract features with `model.extract_features`:\n```python\nimport torch\nfrom googlenet_pytorch import GoogLeNet \nmodel = GoogLeNet.from_pretrained('googlenet')\n\n# ... image preprocessing as in the classification example ...\ninputs = torch.randn(1, 3, 224, 224)\nprint(inputs.shape) # torch.Size([1, 3, 224, 224])\n\nfeatures = model.extract_features(inputs)\nprint(features.shape) # torch.Size([1, 1024, 7, 7])\n```\n\n#### Example: Export to ONNX  \n\nExporting to ONNX for deploying to production is now simple: \n```python\nimport torch \nfrom googlenet_pytorch import GoogLeNet \n\nmodel = GoogLeNet.from_pretrained('googlenet')\ndummy_input = torch.randn(16, 3, 224, 224)\n\ntorch.onnx.export(model, dummy_input, \"demo.onnx\", verbose=True)\n```\n\n#### Example: Visual\n\n```text\ncd $REPO$/framework\nsh start.sh\n```\n\nThen open the browser and type in the browser address [http://127.0.0.1:10002/](http://127.0.0.1:10002/).\n\nEnjoy it.\n\n#### ImageNet\n\nSee `examples/imagenet` for details about evaluating on ImageNet.\n\nFor more datasets result. Please see `research/README.md`.\n\n### Contributing\n\nIf you find a bug, create a GitHub issue, or even better, submit a pull request. Similarly, if you have questions, simply post them as GitHub issues.   \n\nI look forward to seeing what the community does with these models! \n\n### Credit\n\n#### Going Deeper with Convolutions\n\n*Christian Szegedy1, Wei Liu2, Yangqing Jia1, Pierre Sermanet1, Scott Reed3, Dragomir Anguelov1, Dumitru Erhan1, Vincent Vanhoucke1, Andrew Rabinovich4*\n\n##### Abstract\n\nWe propose a deep convolutional neural network architecture codenamed Inception that achieves the new\nstate of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014\n(ILSVRC14). The main hallmark of this architecture is the\nimproved utilization of the computing resources inside the\nnetwork. By a carefully crafted design, we increased the\ndepth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and\nthe intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called\nGoogLeNet, a 22 layers deep network, the quality of which\nis assessed in the context of classification and detection.\n\n[paper](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43022.pdf)\n\n```text\n@article{AlexNet,\ntitle:{Going Deeper with Convolutions},\nauthor:{Christian Szegedy1, Wei Liu2, Yangqing Jia1, Pierre Sermanet1, Scott Reed3, Dragomir Anguelov1, Dumitru Erhan1, Vincent Vanhoucke1, Andrew Rabinovich4},\njournal={cvpr},\nyear={2015}\n}\n```\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Lornatang/GoogLeNet-PyTorch", "keywords": "", "license": "Apache", "maintainer": "", "maintainer_email": "", "name": "googlenet-pytorch", "package_url": "https://pypi.org/project/googlenet-pytorch/", "platform": "", "project_url": "https://pypi.org/project/googlenet-pytorch/", "project_urls": {"Homepage": "https://github.com/Lornatang/GoogLeNet-PyTorch"}, "release_url": "https://pypi.org/project/googlenet-pytorch/0.3.0/", "requires_dist": ["torch"], "requires_python": ">=3.6.0", "summary": "Restore the official code 100% and improve it to make it easier to use.", "version": "0.3.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>GoogLeNet-PyTorch</h1>\n<h3>Update (Feb 17, 2020)</h3>\n<p>The update is for ease of use and deployment.</p>\n<ul>\n<li><a href=\"#example-export-to-onnx\" rel=\"nofollow\">Example: Export to ONNX</a></li>\n<li><a href=\"#example-feature-extraction\" rel=\"nofollow\">Example: Extract features</a></li>\n<li><a href=\"#example-visual\" rel=\"nofollow\">Example: Visual</a></li>\n</ul>\n<p>It is also now incredibly simple to load a pretrained model with a new number of classes for transfer learning:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">googlenet_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">GoogLeNet</span> \n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">GoogLeNet</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span><span class=\"s1\">'googlenet'</span><span class=\"p\">)</span>\n</pre>\n<h3>Overview</h3>\n<p>This repository contains an op-for-op PyTorch reimplementation of <a href=\"https://arxiv.org/pdf/1409.4842.pdf\" rel=\"nofollow\">Going Deeper with Convolutions</a>.</p>\n<p>The goal of this implementation is to be simple, highly extensible, and easy to integrate into your own projects. This implementation is a work in progress -- new features are currently being implemented.</p>\n<p>At the moment, you can easily:</p>\n<ul>\n<li>Load pretrained GoogLeNet models</li>\n<li>Use VGGNet models for classification or feature extraction</li>\n</ul>\n<p><em>Upcoming features</em>: In the next few days, you will be able to:</p>\n<ul>\n<li>Quickly finetune an GoogLeNet on your own dataset</li>\n<li>Export GoogLeNet models for production</li>\n</ul>\n<h3>Table of contents</h3>\n<ol>\n<li><a href=\"#about-googlenet\" rel=\"nofollow\">About GoogLeNet</a></li>\n<li><a href=\"#installation\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#usage\" rel=\"nofollow\">Usage</a>\n<ul>\n<li><a href=\"#loading-pretrained-models\" rel=\"nofollow\">Load pretrained models</a></li>\n<li><a href=\"#example-classification\" rel=\"nofollow\">Example: Classify</a></li>\n<li><a href=\"#example-feature-extraction\" rel=\"nofollow\">Example: Extract features</a></li>\n<li><a href=\"#example-export-to-onnx\" rel=\"nofollow\">Example: Export to ONNX</a></li>\n<li><a href=\"#example-visual\" rel=\"nofollow\">Example: Visual</a></li>\n</ul>\n</li>\n<li><a href=\"#contributing\" rel=\"nofollow\">Contributing</a></li>\n</ol>\n<h3>About GoogLeNet</h3>\n<p>If you're new to GoogLeNet, here is an explanation straight from the official PyTorch implementation:</p>\n<p>We propose a deep convolutional neural network architecture codenamed \"Inception\",\nwhich was responsible for setting the new state of the art for classification and\ndetection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014).\nThe main hallmark of this architecture is the improved utilization of the computing\nresources inside the network. This was achieved by a carefully crafted design that allows\nfor increasing the depth and width of the network while keeping the computational budget\nconstant. To optimize quality, the architectural decisions were based on the Hebbian\nprinciple and the intuition of multi-scale processing. One particular incarnation used\nin our submission for ILSVRC 2014 is called GoogLeNet, a 22 layers deep network, the quality\nof which is assessed in the context of classification and detection.</p>\n<h3>Installation</h3>\n<p>Install from pypi:</p>\n<pre>$ pip install googlenet_pytorch\n</pre>\n<p>Install from source:</p>\n<pre>$ git clone https://github.com/Lornatang/GoogLeNet-PyTorch.git\n$ <span class=\"nb\">cd</span> GoogLeNet-PyTorch\n$ pip install -e .\n</pre>\n<h3>Usage</h3>\n<h4>Loading pretrained models</h4>\n<p>Load a pretrained GoogLeNet:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">googlenet_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">GoogLeNet</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">GoogLeNet</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span><span class=\"s2\">\"googlenet\"</span><span class=\"p\">)</span>\n</pre>\n<p>Their 1-crop error rates on imagenet dataset with pretrained models are listed below.</p>\n<table>\n<thead>\n<tr>\n<th>Model structure</th>\n<th>Top-1 error</th>\n<th>Top-5 error</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>googlenet</td>\n<td>30.22</td>\n<td>10.47</td>\n</tr></tbody></table>\n<h4>Example: Classification</h4>\n<p>We assume that in your current directory, there is a <code>img.jpg</code> file and a <code>labels_map.txt</code> file (ImageNet class names). These are both included in <code>examples/simple</code>.</p>\n<p>All pre-trained models expect input images normalized in the same way,\ni.e. mini-batches of 3-channel RGB images of shape <code>(3 x H x W)</code>, where <code>H</code> and <code>W</code> are expected to be at least <code>224</code>.\nThe images have to be loaded in to a range of <code>[0, 1]</code> and then normalized using <code>mean = [0.485, 0.456, 0.406]</code>\nand <code>std = [0.229, 0.224, 0.225]</code>.</p>\n<p>Here's a sample execution.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">json</span>\n\n<span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torchvision.transforms</span> <span class=\"k\">as</span> <span class=\"nn\">transforms</span>\n<span class=\"kn\">from</span> <span class=\"nn\">PIL</span> <span class=\"kn\">import</span> <span class=\"n\">Image</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">googlenet_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">GoogLeNet</span> \n\n<span class=\"c1\"># Open image</span>\n<span class=\"n\">input_image</span> <span class=\"o\">=</span> <span class=\"n\">Image</span><span class=\"o\">.</span><span class=\"n\">open</span><span class=\"p\">(</span><span class=\"s2\">\"img.jpg\"</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Preprocess image</span>\n<span class=\"n\">preprocess</span> <span class=\"o\">=</span> <span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Compose</span><span class=\"p\">([</span>\n  <span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Resize</span><span class=\"p\">(</span><span class=\"mi\">256</span><span class=\"p\">),</span>\n  <span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">CenterCrop</span><span class=\"p\">(</span><span class=\"mi\">224</span><span class=\"p\">),</span>\n  <span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">ToTensor</span><span class=\"p\">(),</span>\n  <span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Normalize</span><span class=\"p\">(</span><span class=\"n\">mean</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mf\">0.485</span><span class=\"p\">,</span> <span class=\"mf\">0.456</span><span class=\"p\">,</span> <span class=\"mf\">0.406</span><span class=\"p\">],</span> <span class=\"n\">std</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mf\">0.229</span><span class=\"p\">,</span> <span class=\"mf\">0.224</span><span class=\"p\">,</span> <span class=\"mf\">0.225</span><span class=\"p\">]),</span>\n<span class=\"p\">])</span>\n<span class=\"n\">input_tensor</span> <span class=\"o\">=</span> <span class=\"n\">preprocess</span><span class=\"p\">(</span><span class=\"n\">input_image</span><span class=\"p\">)</span>\n<span class=\"n\">input_batch</span> <span class=\"o\">=</span> <span class=\"n\">input_tensor</span><span class=\"o\">.</span><span class=\"n\">unsqueeze</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>  <span class=\"c1\"># create a mini-batch as expected by the model</span>\n\n<span class=\"c1\"># Load class names</span>\n<span class=\"n\">labels_map</span> <span class=\"o\">=</span> <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s2\">\"labels_map.txt\"</span><span class=\"p\">))</span>\n<span class=\"n\">labels_map</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">labels_map</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">)]</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">1000</span><span class=\"p\">)]</span>\n\n<span class=\"c1\"># Classify with GoogLeNet</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">GoogLeNet</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span><span class=\"s2\">\"googlenet\"</span><span class=\"p\">)</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">eval</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># move the input and model to GPU for speed if available</span>\n<span class=\"k\">if</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"o\">.</span><span class=\"n\">is_available</span><span class=\"p\">():</span>\n  <span class=\"n\">input_batch</span> <span class=\"o\">=</span> <span class=\"n\">input_batch</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"s2\">\"cuda\"</span><span class=\"p\">)</span>\n  <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"s2\">\"cuda\"</span><span class=\"p\">)</span>\n\n<span class=\"k\">with</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">no_grad</span><span class=\"p\">():</span>\n  <span class=\"n\">logits</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">input_batch</span><span class=\"p\">)</span>\n<span class=\"n\">preds</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">topk</span><span class=\"p\">(</span><span class=\"n\">logits</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">indices</span><span class=\"o\">.</span><span class=\"n\">squeeze</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">()</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"-----\"</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">idx</span> <span class=\"ow\">in</span> <span class=\"n\">preds</span><span class=\"p\">:</span>\n  <span class=\"n\">label</span> <span class=\"o\">=</span> <span class=\"n\">labels_map</span><span class=\"p\">[</span><span class=\"n\">idx</span><span class=\"p\">]</span>\n  <span class=\"n\">prob</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">softmax</span><span class=\"p\">(</span><span class=\"n\">logits</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">idx</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">()</span>\n  <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">\"</span><span class=\"si\">{</span><span class=\"n\">label</span><span class=\"si\">:</span><span class=\"s2\">&lt;75</span><span class=\"si\">}</span><span class=\"s2\"> (</span><span class=\"si\">{</span><span class=\"n\">prob</span> <span class=\"o\">*</span> <span class=\"mi\">100</span><span class=\"si\">:</span><span class=\"s2\">.2f</span><span class=\"si\">}</span><span class=\"s2\">%)\"</span><span class=\"p\">)</span>\n</pre>\n<h4>Example: Feature Extraction</h4>\n<p>You can easily extract features with <code>model.extract_features</code>:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">googlenet_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">GoogLeNet</span> \n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">GoogLeNet</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span><span class=\"s1\">'googlenet'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># ... image preprocessing as in the classification example ...</span>\n<span class=\"n\">inputs</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">224</span><span class=\"p\">,</span> <span class=\"mi\">224</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">)</span> <span class=\"c1\"># torch.Size([1, 3, 224, 224])</span>\n\n<span class=\"n\">features</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">extract_features</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">)</span> <span class=\"c1\"># torch.Size([1, 1024, 7, 7])</span>\n</pre>\n<h4>Example: Export to ONNX</h4>\n<p>Exporting to ONNX for deploying to production is now simple:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch</span> \n<span class=\"kn\">from</span> <span class=\"nn\">googlenet_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">GoogLeNet</span> \n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">GoogLeNet</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span><span class=\"s1\">'googlenet'</span><span class=\"p\">)</span>\n<span class=\"n\">dummy_input</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">224</span><span class=\"p\">,</span> <span class=\"mi\">224</span><span class=\"p\">)</span>\n\n<span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">onnx</span><span class=\"o\">.</span><span class=\"n\">export</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">dummy_input</span><span class=\"p\">,</span> <span class=\"s2\">\"demo.onnx\"</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<h4>Example: Visual</h4>\n<pre>cd $REPO$/framework\nsh start.sh\n</pre>\n<p>Then open the browser and type in the browser address <a href=\"http://127.0.0.1:10002/\" rel=\"nofollow\">http://127.0.0.1:10002/</a>.</p>\n<p>Enjoy it.</p>\n<h4>ImageNet</h4>\n<p>See <code>examples/imagenet</code> for details about evaluating on ImageNet.</p>\n<p>For more datasets result. Please see <code>research/README.md</code>.</p>\n<h3>Contributing</h3>\n<p>If you find a bug, create a GitHub issue, or even better, submit a pull request. Similarly, if you have questions, simply post them as GitHub issues.</p>\n<p>I look forward to seeing what the community does with these models!</p>\n<h3>Credit</h3>\n<h4>Going Deeper with Convolutions</h4>\n<p><em>Christian Szegedy1, Wei Liu2, Yangqing Jia1, Pierre Sermanet1, Scott Reed3, Dragomir Anguelov1, Dumitru Erhan1, Vincent Vanhoucke1, Andrew Rabinovich4</em></p>\n<h5>Abstract</h5>\n<p>We propose a deep convolutional neural network architecture codenamed Inception that achieves the new\nstate of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014\n(ILSVRC14). The main hallmark of this architecture is the\nimproved utilization of the computing resources inside the\nnetwork. By a carefully crafted design, we increased the\ndepth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and\nthe intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called\nGoogLeNet, a 22 layers deep network, the quality of which\nis assessed in the context of classification and detection.</p>\n<p><a href=\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43022.pdf\" rel=\"nofollow\">paper</a></p>\n<pre>@article{AlexNet,\ntitle:{Going Deeper with Convolutions},\nauthor:{Christian Szegedy1, Wei Liu2, Yangqing Jia1, Pierre Sermanet1, Scott Reed3, Dragomir Anguelov1, Dumitru Erhan1, Vincent Vanhoucke1, Andrew Rabinovich4},\njournal={cvpr},\nyear={2015}\n}\n</pre>\n\n          </div>"}, "last_serial": 6818958, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "06b602c122e4133f7ce5e663fe16b9ed", "sha256": "544b66d1996c848dcd4691ba14b53abc76c144e09e18d1db86a10a87bf17bd0a"}, "downloads": -1, "filename": "googlenet_pytorch-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "06b602c122e4133f7ce5e663fe16b9ed", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.5.0", "size": 13089, "upload_time": "2020-02-17T07:10:36", "upload_time_iso_8601": "2020-02-17T07:10:36.295617Z", "url": "https://files.pythonhosted.org/packages/4e/6c/6d002523135838c5d88c53735b1c038f8e837faeb510a24060792161d1e9/googlenet_pytorch-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "47a75f5192540a8262bae019cce614f0", "sha256": "4734a34d97fdd1d54d0737fb9dfe2239c99e64de50c55f6c8ad82709a4148b53"}, "downloads": -1, "filename": "googlenet_pytorch-0.1.0.tar.gz", "has_sig": false, "md5_digest": "47a75f5192540a8262bae019cce614f0", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 8906, "upload_time": "2020-02-17T07:10:39", "upload_time_iso_8601": "2020-02-17T07:10:39.369322Z", "url": "https://files.pythonhosted.org/packages/6f/1b/e351747a040c7aa5fe4ed5726e61b359a2ce8dd561837592ad44ea2f5798/googlenet_pytorch-0.1.0.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "e9685263bfa76e518a78006feab28f5b", "sha256": "6e4368bdd6ef65d3f198c853eb44b929d814531349d92ddd155c4d4805b696cd"}, "downloads": -1, "filename": "googlenet_pytorch-0.1.3-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e9685263bfa76e518a78006feab28f5b", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.5.0", "size": 12995, "upload_time": "2020-02-17T08:44:08", "upload_time_iso_8601": "2020-02-17T08:44:08.872773Z", "url": "https://files.pythonhosted.org/packages/78/d4/a6db21cb017f0eb93a8e12117ac6e0f6cbf5e71f94584153b3d2e5576eeb/googlenet_pytorch-0.1.3-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "847e1e02569d97ac486066ab757d74c0", "sha256": "3b96c6d372381be10584305778a83160a2b8cade3a9fc2db5859e0c5bc48b940"}, "downloads": -1, "filename": "googlenet_pytorch-0.1.3.tar.gz", "has_sig": false, "md5_digest": "847e1e02569d97ac486066ab757d74c0", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 9818, "upload_time": "2020-02-17T08:44:12", "upload_time_iso_8601": "2020-02-17T08:44:12.294791Z", "url": "https://files.pythonhosted.org/packages/11/e5/b267a9eb90491f5e04f0657b029ae92b9233a175046e5e711d19483d4cf3/googlenet_pytorch-0.1.3.tar.gz", "yanked": false}], "0.1.5": [{"comment_text": "", "digests": {"md5": "dd59e404a0b71562fe6058640279924f", "sha256": "fda04ab57f8dcd5346058a3001ae8a476d7a25420feaa06bde2d43751d7765f7"}, "downloads": -1, "filename": "googlenet_pytorch-0.1.5-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "dd59e404a0b71562fe6058640279924f", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.5.0", "size": 13668, "upload_time": "2020-02-17T11:27:41", "upload_time_iso_8601": "2020-02-17T11:27:41.406424Z", "url": "https://files.pythonhosted.org/packages/7d/c2/5bde574aed0eb0e49f45b8246885bd18feef7bc0faa29157a88a5b5a2f80/googlenet_pytorch-0.1.5-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "568b88bcfcad1a48d67aa3b5c949dd12", "sha256": "0ff71f5fd1f2081d90ecbd78ffbe45b30ddbd3f7ad1003d13425897d693a2083"}, "downloads": -1, "filename": "googlenet_pytorch-0.1.5.tar.gz", "has_sig": false, "md5_digest": "568b88bcfcad1a48d67aa3b5c949dd12", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 10237, "upload_time": "2020-02-17T11:27:55", "upload_time_iso_8601": "2020-02-17T11:27:55.933391Z", "url": "https://files.pythonhosted.org/packages/e0/3e/41adeffffbb5ed6af6a68c23d6f6c989e410e16dff1c7354503f3c9f9e4b/googlenet_pytorch-0.1.5.tar.gz", "yanked": false}], "0.1.7": [{"comment_text": "", "digests": {"md5": "a106258291ce34fb9bfab820eed5e25d", "sha256": "603369d7bbe2139eecde8ed8e4b0da00a015bc0c8095febfc75c1635a2578d86"}, "downloads": -1, "filename": "googlenet_pytorch-0.1.7-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "a106258291ce34fb9bfab820eed5e25d", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.5.0", "size": 13660, "upload_time": "2020-02-17T11:58:41", "upload_time_iso_8601": "2020-02-17T11:58:41.920417Z", "url": "https://files.pythonhosted.org/packages/26/aa/c86045114b6bb24e74dbad0bd2df72c8eb51fb7498f16f03a8c377cc5894/googlenet_pytorch-0.1.7-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "58a86afa8511fd5bdaa74c26de46cfd3", "sha256": "8fb0f1b3f346743f347328a0206cff01816a8b6e4b581b0f13c4132881f6d3d0"}, "downloads": -1, "filename": "googlenet_pytorch-0.1.7.tar.gz", "has_sig": false, "md5_digest": "58a86afa8511fd5bdaa74c26de46cfd3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 10232, "upload_time": "2020-02-17T11:58:43", "upload_time_iso_8601": "2020-02-17T11:58:43.633583Z", "url": "https://files.pythonhosted.org/packages/ef/28/00911075a74b8cc953d16381228f970154bad22a4180dc2703a9e2678089/googlenet_pytorch-0.1.7.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "72e37094334932ed0e8d1e6cd1e6bf80", "sha256": "b6ad51ed85394893d6ef01570e8020e07fb8090988390a405abea9a231b61aff"}, "downloads": -1, "filename": "googlenet_pytorch-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "72e37094334932ed0e8d1e6cd1e6bf80", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.5.0", "size": 13658, "upload_time": "2020-02-17T13:44:32", "upload_time_iso_8601": "2020-02-17T13:44:32.019235Z", "url": "https://files.pythonhosted.org/packages/ec/54/669ab3316e53c3b08d63904f0b66a68d5ec270d16398e6c1b7c07af81da6/googlenet_pytorch-0.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1eb531ba1f07b0748103ec06e4b20731", "sha256": "d09456baaf19e1eeecb1237032e0d9a0c841f9323545904e566ee3c7b9e239fd"}, "downloads": -1, "filename": "googlenet_pytorch-0.2.0.tar.gz", "has_sig": false, "md5_digest": "1eb531ba1f07b0748103ec06e4b20731", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 10237, "upload_time": "2020-02-17T13:44:34", "upload_time_iso_8601": "2020-02-17T13:44:34.205452Z", "url": "https://files.pythonhosted.org/packages/b6/8e/e7f21ee0b34c8f05a907196d08bdc8636ea9db1dc076b0b8c71f8e892344/googlenet_pytorch-0.2.0.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "e99f2eb6f8f2b3c0da738f5b0fb15f8e", "sha256": "a969560577e212e151557b23da6a9a4801c01ab7d79bef416b11ba8138b4dbb7"}, "downloads": -1, "filename": "googlenet_pytorch-0.3.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e99f2eb6f8f2b3c0da738f5b0fb15f8e", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6.0", "size": 13730, "upload_time": "2020-03-16T06:22:12", "upload_time_iso_8601": "2020-03-16T06:22:12.305517Z", "url": "https://files.pythonhosted.org/packages/1d/f5/fae02c760929c3bd9974f570907fd3e13787c0857fa83316c6e8e3cf9bb1/googlenet_pytorch-0.3.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4b52d625cc09c908fddeebb49fe33645", "sha256": "2ac6a278733e433b55913c996dbc4bf55663592d3181303d7f0450b151741e39"}, "downloads": -1, "filename": "googlenet_pytorch-0.3.0.tar.gz", "has_sig": false, "md5_digest": "4b52d625cc09c908fddeebb49fe33645", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 11617, "upload_time": "2020-03-16T06:22:14", "upload_time_iso_8601": "2020-03-16T06:22:14.263488Z", "url": "https://files.pythonhosted.org/packages/08/7a/eca1ebed966a2ee353513c807f7a828a84129318e46ece0d25b71d675964/googlenet_pytorch-0.3.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "e99f2eb6f8f2b3c0da738f5b0fb15f8e", "sha256": "a969560577e212e151557b23da6a9a4801c01ab7d79bef416b11ba8138b4dbb7"}, "downloads": -1, "filename": "googlenet_pytorch-0.3.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e99f2eb6f8f2b3c0da738f5b0fb15f8e", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6.0", "size": 13730, "upload_time": "2020-03-16T06:22:12", "upload_time_iso_8601": "2020-03-16T06:22:12.305517Z", "url": "https://files.pythonhosted.org/packages/1d/f5/fae02c760929c3bd9974f570907fd3e13787c0857fa83316c6e8e3cf9bb1/googlenet_pytorch-0.3.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4b52d625cc09c908fddeebb49fe33645", "sha256": "2ac6a278733e433b55913c996dbc4bf55663592d3181303d7f0450b151741e39"}, "downloads": -1, "filename": "googlenet_pytorch-0.3.0.tar.gz", "has_sig": false, "md5_digest": "4b52d625cc09c908fddeebb49fe33645", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 11617, "upload_time": "2020-03-16T06:22:14", "upload_time_iso_8601": "2020-03-16T06:22:14.263488Z", "url": "https://files.pythonhosted.org/packages/08/7a/eca1ebed966a2ee353513c807f7a828a84129318e46ece0d25b71d675964/googlenet_pytorch-0.3.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:55:36 2020"}