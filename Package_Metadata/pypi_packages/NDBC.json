{"info": {"author": "C. Ryan Manzer", "author_email": "ryan@gensci.org", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# NDBC\n![alt text](http://www.ndbc.noaa.gov/images/nws/noaaleft.jpg \"NOAA\") ![alt text](http://www.ndbc.noaa.gov/images/nws/ndbc_title.jpg \"NDBC\")\n\nThis repository represents my attempts to build out Python class(es)\nto facilitate the acquisition, analysis, and visualization of National\nData Buoy Center (NDBC) data.  The goal is to develop a set of APIs to \nfacilitate rapid discovery of data resources, exploratory data analysis,\nand allow integration into automated data workflows.\n\n## NDBC.py\nThis file defines the DataBuoy class.  The purpose of this class is to\nallow a user to define a specific data buoy they wish to gather data\nfrom and provide the user with methods to collect and analyze this data.\n \nDependencies are listed in `requirements.txt`\n   \n## Usage\n\n#### Installation\n\nInstall using pip from PyPI\n```\npip install NDBC\n```\nThen you are ready to start using this module in exploratory data analyses and scripted workflows.\n\n#### Methods of DataBuoy Class\n`.set_station_id`\n\nIf a DataBuoy class has been instantiated without any `station_id` argument, this method allows for setting a station id\n```\nfrom NDBC.NDBC import DataBuoy\nDB = DataBuoy()\nDB.set_station_id('46042') # <- Either strings or numbers are acceptable\n```\n\n\n`.get_station_metadata()`\n\nPerform a scrape of the public webpage for a specified data station and save a dictionary of available metadata to the `.station_info` property.  This is only available if a DataBuoy has a valid `station_id` set (either during class instantiation or using \nthe `set_station_id` method).\n```\nfrom NDBC.NDBC import DataBuoy\nDB = DataBuoy(46042)\nDB.get_station_metadata()\nDB.station_info\n{   'Air temp height': '4 m above site elevation',\n    'Anemometer height': '5 m above site elevation',\n    'Barometer elevation': 'sea level',\n    'Sea temp depth': '0.6 m below water line',\n    'Site elevation': 'sea level',\n    'Watch circle radius': '1789 yards',\n    'Water depth': '1645.9 m',\n    'lat': '36.785 N',\n    'lon': '122.398 W'}\n```\n\n* `.get_stdmet(datetime_index=False)`\n\nAfter importing, the DataBuoy class is instantiated with the ID of the \nstation from which historical data is sought.  Then data may be gathered for \nthe years and months specified.  If no time period is specified, the most recent\nfull month available is retrieved.\n\nThe default behavior is to append datetime values built from date part columns (YY, MM, DD, etc.) to a column 'datetime'. If value `True` is passed as the `datetime_index` argument, the datetime values will be used as index values for the returned dataframe.  In some cases this is advantageous for time series analyses.  \n```\nfrom NDBC.NDBC import DataBuoy\n\nn42 = DataBuoy(46042)  # <- String or numeric station ids are valid\n\nn42.get_stdmet(datetime_index=True)  # <- no year, month argumets so latest full month is retrieved.\n\nOct not available.   # <- Where data is missing, messages are returned to the terminal via a logger.warning() call \nSep not available.   \n\nn42.data  # <- anticipating additional data collection methods, the .data property returns a dictionary.  Indiviudual\n               data products are returned as pandas DataFrame objects\n\n# Datetime objects are compiled from individual year, month, day, hour, minute columns and used as the index to support\n# slicing data by time frames. \n\n{'stdmet':          WDIR WSPD  GST  WVHT    DPD   APD  MWD    PRES  ATMP  WTMP   DEWP   VIS   TIDE\n2019-07-31 23:50:00  298  3.6  5.2  1.25   7.69  5.37  303  1015.1  13.4  15.2  999.0  99.0  99.00\n2019-08-01 00:50:00  301  5.7  7.2  1.26   7.14  5.42  306  1014.8  13.4  15.3  999.0  99.0  99.00\n2019-08-01 01:50:00  323  6.6  8.3  1.33   7.14  5.47  312  1014.5  13.2  15.1  999.0  99.0  99.00\n2019-08-01 02:50:00  347  5.8  7.7  1.32   7.69  5.15  319  1014.5  12.7  15.1  999.0  99.0  99.00\n2019-08-01 03:50:00  353  5.6  7.2  1.26   7.69  5.31  325  1014.9  12.6  15.0  999.0  99.0  99.00\n...                  ...  ...  ...   ...    ...   ...  ...     ...   ...   ...    ...   ...    ...\n2019-08-31 18:50:00  999  6.2  7.4  0.87  13.79  4.67  186  1014.6  17.0  17.2  999.0  99.0  99.00\n2019-08-31 19:50:00  999  6.8  8.3  0.83  13.79  4.56  178  1014.2  17.2  17.3  999.0  99.0  99.00\n2019-08-31 20:50:00  999  6.5  7.8  0.89  13.79  4.38  195  1013.8  17.5  17.4  999.0  99.0  99.00\n2019-08-31 21:50:00  999  7.5  8.9  0.95  13.79  4.52  190  1013.1  17.5  17.3  999.0  99.0  99.00\n2019-08-31 22:50:00  999  8.0  9.4  0.95  13.79  4.09  171  1012.7  17.7  17.1  999.0  99.0  99.00\n\n[741 rows x 13 columns]}\n```\nUsing the pandas DataFrame to store the returned data provides access to the wide array of methods the pandas package \nprovides.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/GenSci/NDBC", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "NDBC", "package_url": "https://pypi.org/project/NDBC/", "platform": "", "project_url": "https://pypi.org/project/NDBC/", "project_urls": {"Homepage": "https://github.com/GenSci/NDBC"}, "release_url": "https://pypi.org/project/NDBC/0.1.1/", "requires_dist": null, "requires_python": "", "summary": "A package to automate the loading of NDBC data to a custom object.", "version": "0.1.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>NDBC</h1>\n<p><img alt=\"alt text\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bd7964895d3132712616320d1b972551759b028f/687474703a2f2f7777772e6e6462632e6e6f61612e676f762f696d616765732f6e77732f6e6f61616c6566742e6a7067\"> <img alt=\"alt text\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e5f3106da7c00457e166aeaba30dcc0064f560cc/687474703a2f2f7777772e6e6462632e6e6f61612e676f762f696d616765732f6e77732f6e6462635f7469746c652e6a7067\"></p>\n<p>This repository represents my attempts to build out Python class(es)\nto facilitate the acquisition, analysis, and visualization of National\nData Buoy Center (NDBC) data.  The goal is to develop a set of APIs to\nfacilitate rapid discovery of data resources, exploratory data analysis,\nand allow integration into automated data workflows.</p>\n<h2>NDBC.py</h2>\n<p>This file defines the DataBuoy class.  The purpose of this class is to\nallow a user to define a specific data buoy they wish to gather data\nfrom and provide the user with methods to collect and analyze this data.</p>\n<p>Dependencies are listed in <code>requirements.txt</code></p>\n<h2>Usage</h2>\n<h4>Installation</h4>\n<p>Install using pip from PyPI</p>\n<pre><code>pip install NDBC\n</code></pre>\n<p>Then you are ready to start using this module in exploratory data analyses and scripted workflows.</p>\n<h4>Methods of DataBuoy Class</h4>\n<p><code>.set_station_id</code></p>\n<p>If a DataBuoy class has been instantiated without any <code>station_id</code> argument, this method allows for setting a station id</p>\n<pre><code>from NDBC.NDBC import DataBuoy\nDB = DataBuoy()\nDB.set_station_id('46042') # &lt;- Either strings or numbers are acceptable\n</code></pre>\n<p><code>.get_station_metadata()</code></p>\n<p>Perform a scrape of the public webpage for a specified data station and save a dictionary of available metadata to the <code>.station_info</code> property.  This is only available if a DataBuoy has a valid <code>station_id</code> set (either during class instantiation or using\nthe <code>set_station_id</code> method).</p>\n<pre><code>from NDBC.NDBC import DataBuoy\nDB = DataBuoy(46042)\nDB.get_station_metadata()\nDB.station_info\n{   'Air temp height': '4 m above site elevation',\n    'Anemometer height': '5 m above site elevation',\n    'Barometer elevation': 'sea level',\n    'Sea temp depth': '0.6 m below water line',\n    'Site elevation': 'sea level',\n    'Watch circle radius': '1789 yards',\n    'Water depth': '1645.9 m',\n    'lat': '36.785 N',\n    'lon': '122.398 W'}\n</code></pre>\n<ul>\n<li><code>.get_stdmet(datetime_index=False)</code></li>\n</ul>\n<p>After importing, the DataBuoy class is instantiated with the ID of the\nstation from which historical data is sought.  Then data may be gathered for\nthe years and months specified.  If no time period is specified, the most recent\nfull month available is retrieved.</p>\n<p>The default behavior is to append datetime values built from date part columns (YY, MM, DD, etc.) to a column 'datetime'. If value <code>True</code> is passed as the <code>datetime_index</code> argument, the datetime values will be used as index values for the returned dataframe.  In some cases this is advantageous for time series analyses.</p>\n<pre><code>from NDBC.NDBC import DataBuoy\n\nn42 = DataBuoy(46042)  # &lt;- String or numeric station ids are valid\n\nn42.get_stdmet(datetime_index=True)  # &lt;- no year, month argumets so latest full month is retrieved.\n\nOct not available.   # &lt;- Where data is missing, messages are returned to the terminal via a logger.warning() call \nSep not available.   \n\nn42.data  # &lt;- anticipating additional data collection methods, the .data property returns a dictionary.  Indiviudual\n               data products are returned as pandas DataFrame objects\n\n# Datetime objects are compiled from individual year, month, day, hour, minute columns and used as the index to support\n# slicing data by time frames. \n\n{'stdmet':          WDIR WSPD  GST  WVHT    DPD   APD  MWD    PRES  ATMP  WTMP   DEWP   VIS   TIDE\n2019-07-31 23:50:00  298  3.6  5.2  1.25   7.69  5.37  303  1015.1  13.4  15.2  999.0  99.0  99.00\n2019-08-01 00:50:00  301  5.7  7.2  1.26   7.14  5.42  306  1014.8  13.4  15.3  999.0  99.0  99.00\n2019-08-01 01:50:00  323  6.6  8.3  1.33   7.14  5.47  312  1014.5  13.2  15.1  999.0  99.0  99.00\n2019-08-01 02:50:00  347  5.8  7.7  1.32   7.69  5.15  319  1014.5  12.7  15.1  999.0  99.0  99.00\n2019-08-01 03:50:00  353  5.6  7.2  1.26   7.69  5.31  325  1014.9  12.6  15.0  999.0  99.0  99.00\n...                  ...  ...  ...   ...    ...   ...  ...     ...   ...   ...    ...   ...    ...\n2019-08-31 18:50:00  999  6.2  7.4  0.87  13.79  4.67  186  1014.6  17.0  17.2  999.0  99.0  99.00\n2019-08-31 19:50:00  999  6.8  8.3  0.83  13.79  4.56  178  1014.2  17.2  17.3  999.0  99.0  99.00\n2019-08-31 20:50:00  999  6.5  7.8  0.89  13.79  4.38  195  1013.8  17.5  17.4  999.0  99.0  99.00\n2019-08-31 21:50:00  999  7.5  8.9  0.95  13.79  4.52  190  1013.1  17.5  17.3  999.0  99.0  99.00\n2019-08-31 22:50:00  999  8.0  9.4  0.95  13.79  4.09  171  1012.7  17.7  17.1  999.0  99.0  99.00\n\n[741 rows x 13 columns]}\n</code></pre>\n<p>Using the pandas DataFrame to store the returned data provides access to the wide array of methods the pandas package\nprovides.</p>\n\n          </div>"}, "last_serial": 6222534, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "e1b90e99736a7d5d62b265357b994af3", "sha256": "869f6b439e2696cb3a024a5ac5abd683fa175a0749707b2576e2e1488c968542"}, "downloads": -1, "filename": "NDBC-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "e1b90e99736a7d5d62b265357b994af3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 5355, "upload_time": "2018-06-17T00:37:41", "upload_time_iso_8601": "2018-06-17T00:37:41.169370Z", "url": "https://files.pythonhosted.org/packages/a8/b2/77499abd1fce9b23e4c5b32b90c8e689d9be3b7a751eced09913df0f66a3/NDBC-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1dabceec74795348a709bc3196ec73f3", "sha256": "9e6af4186fc1c25872b6f4e79986b47ed987e14d0856ce6835413f98d9df2c73"}, "downloads": -1, "filename": "NDBC-0.0.1.tar.gz", "has_sig": false, "md5_digest": "1dabceec74795348a709bc3196ec73f3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4892, "upload_time": "2018-06-17T00:37:42", "upload_time_iso_8601": "2018-06-17T00:37:42.490832Z", "url": "https://files.pythonhosted.org/packages/c2/9a/f7c5d728f1a224dddbf6faf6377b0b7ca5c446fd575eb40467384ea66a78/NDBC-0.0.1.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "92f7641c29876fb20c63a149e1ebda53", "sha256": "120ddecb2548c894345a1b9f79ec9bc8d75accf86a36d5cc6ae13d0c8c3c031a"}, "downloads": -1, "filename": "NDBC-0.1.0.tar.gz", "has_sig": false, "md5_digest": "92f7641c29876fb20c63a149e1ebda53", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7520, "upload_time": "2019-10-27T21:15:24", "upload_time_iso_8601": "2019-10-27T21:15:24.157836Z", "url": "https://files.pythonhosted.org/packages/e7/54/e0c1adcc014453e70f6c6803aac0b33ac524ef81b370e7e2f36a838e82ff/NDBC-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "6f9686cb73d0160548524e7761b8508a", "sha256": "df7510d1691be26e3ffb0d1349ad8a87783ce56fe5b158171534573656b42771"}, "downloads": -1, "filename": "NDBC-0.1.1.tar.gz", "has_sig": false, "md5_digest": "6f9686cb73d0160548524e7761b8508a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8202, "upload_time": "2019-11-30T21:01:26", "upload_time_iso_8601": "2019-11-30T21:01:26.946978Z", "url": "https://files.pythonhosted.org/packages/41/22/9e17318a2cd8ca31d75e92709483a6200d0c31918f20fe0f7e719d044d53/NDBC-0.1.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "6f9686cb73d0160548524e7761b8508a", "sha256": "df7510d1691be26e3ffb0d1349ad8a87783ce56fe5b158171534573656b42771"}, "downloads": -1, "filename": "NDBC-0.1.1.tar.gz", "has_sig": false, "md5_digest": "6f9686cb73d0160548524e7761b8508a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8202, "upload_time": "2019-11-30T21:01:26", "upload_time_iso_8601": "2019-11-30T21:01:26.946978Z", "url": "https://files.pythonhosted.org/packages/41/22/9e17318a2cd8ca31d75e92709483a6200d0c31918f20fe0f7e719d044d53/NDBC-0.1.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:46:45 2020"}