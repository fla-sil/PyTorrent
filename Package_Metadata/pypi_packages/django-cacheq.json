{"info": {"author": "Andr\u00e9s Bucchi", "author_email": "afbucchi@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "Framework :: Django", "Intended Audience :: Developers", "License :: OSI Approved :: BSD License", "Natural Language :: English", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.6", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.3"], "description": "=============================\ndjango-cacheq\n=============================\n\nBackground tasks using django's cache framework.\n\n\nQuickstart\n----------\n\nInstall django-cacheq::\n\n    pip install django-cacheq\n\nRequirements\n\n- django>=1.5.1\n- jsonfield>=1.0.3\n- lockfile>=0.10.2\n\nAdd it to your installed apps::\n\n    INSTALLED_APPS = (\n        ...\n        'cacheq',\n    )\n\nAnd that's it with setup. You can add some basic settings too, but they are not really required.::\n    \n    CACHES = {\n        'default: ...,\n        'cacheq': ...,\n        'other': ...\n    }\n    \n    CACHEQ = {\n        'CACHE': 'cacheq',                      # which cache to use, defaults to 'default'\n                                                # note that dummybackend is *not* supported\n        'LOCKFILE': '/var/tmp/mycacheq.lock',   # lock file to use if cache is filebased, \n                                                # defaults to '/var/tmp/cacheq.lock'\n        # these settings are only for testing\n        'MEMCACHED_TESTS_USING': 'memcached',   # which cache to use for running memcached \n                                                # backend tests, only for development\n        'REDIS_TESTS_USING': 'redis',           # which cache to use for running redis \n                                                # backend tests, only for development\n    }\n\nThen use it in your project::\n\n    import operator\n    from cacheq import CacheQ\n    \n    cq = CacheQ(name='myqueue', using='cacheq') # as in get_cache('cacheq')\n    \n    # either enqueue one job\n    job = cq.enqueue(operator.add, 1, 2)\n    \n    # or several at a time. note that both the args=[...] and kwargs={...}\n    # arguments are required in this case, even if empty\n    tasks = [(operator.add, [1,2], {}), (operator.div, [], {'a': 2, 'b': 2})]\n    job = cq.enqueue_many(tasks) # job with many tasks\n    \n    # or you can use the @cq.job decorator\n    @cq.job\n    def myfunc(a,b):\n        return a+b\n    \n    job = myfunc.delay(1,b=2)\n    \n    # then wait for results\n    job.ready() # False\n    job.ready() # True\n    job.result # 3\n    \n    # calling job.ready() or job.result will not hit the database\n    # it will look for result and status in cache. once it's ready \n    # it will update job in database.\n\nRunning the worker::\n\n    python manage.py cqworker --using=cacheq --queue=myqueue --name=worker123 --pulse=0.1\n\nThis will run a cqworker with name \"worker123\" in foreground listening to queue \"myqueue\" using the cache backend under get_cache('cacheq'). The 'pulse' option is not really necessary, but it will accept any value between 0.0 and 1.0, which will be the time that the worker will wait to look for a new job again. I don't know if this is really helpful, as it would still be only one connection to memcached / redis, and time.sleep is blocking.\n\nThese are the default values\n\n- using: 'default'\n- queue: 'default'\n- name: 'worker'\n- pulse: 1.0\n\nWhen running tests it's helpful to run the worker and exit when jobs are done. You can do this by either calling the cqworker command with the --burst option or by using the worker.run method.::\n\n    python manage.py cqworker --using=cacheq --queue=myqueue --burst\n    \n    # or programatically\n    from cacheq import get_worker\n    \n    worker = get_worker(queue_name='myqueue', using='cacheq')\n    worker.run(burst=True)\n\n\ndjango-cacheq uses django ORM as a backend for job results. This is only something that fitted specific needs I had at the time I wrote this package, but I guess it would be wise to remove it at some point and replace it by a cache backend too, or maybe adding a setting that allows other database to be used specifically as a results backend.\n\nAnyways, for now you can clear jobs by using the cqclear command::\n\n    python manage.py cqclear <done failed pending all> [--no-input]\n    \nIn the case you want to delete pending jobs, you will have to confirm the action if you do not provide the --no-input option. So have this in mind if you wish to use a cronjob to clear jobs periodically.\n\n\n\n\n\nHistory\n-------\n\n0.1.0 (2015-07-25)\n++++++++++++++++++\n\n* First release on PyPI.", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/misterte/django-cacheq", "keywords": "django-cacheq", "license": "BSD", "maintainer": null, "maintainer_email": null, "name": "django-cacheq", "package_url": "https://pypi.org/project/django-cacheq/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/django-cacheq/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/misterte/django-cacheq"}, "release_url": "https://pypi.org/project/django-cacheq/0.1.1/", "requires_dist": null, "requires_python": null, "summary": "Background tasks using django's cache framework.", "version": "0.1.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>Background tasks using django\u2019s cache framework.</p>\n<div id=\"quickstart\">\n<h2>Quickstart</h2>\n<p>Install django-cacheq:</p>\n<pre>pip install django-cacheq\n</pre>\n<p>Requirements</p>\n<ul>\n<li>django&gt;=1.5.1</li>\n<li>jsonfield&gt;=1.0.3</li>\n<li>lockfile&gt;=0.10.2</li>\n</ul>\n<p>Add it to your installed apps:</p>\n<pre>INSTALLED_APPS = (\n    ...\n    'cacheq',\n)\n</pre>\n<p>And that\u2019s it with setup. You can add some basic settings too, but they are not really required.:</p>\n<pre>CACHES = {\n    'default: ...,\n    'cacheq': ...,\n    'other': ...\n}\n\nCACHEQ = {\n    'CACHE': 'cacheq',                      # which cache to use, defaults to 'default'\n                                            # note that dummybackend is *not* supported\n    'LOCKFILE': '/var/tmp/mycacheq.lock',   # lock file to use if cache is filebased,\n                                            # defaults to '/var/tmp/cacheq.lock'\n    # these settings are only for testing\n    'MEMCACHED_TESTS_USING': 'memcached',   # which cache to use for running memcached\n                                            # backend tests, only for development\n    'REDIS_TESTS_USING': 'redis',           # which cache to use for running redis\n                                            # backend tests, only for development\n}\n</pre>\n<p>Then use it in your project:</p>\n<pre>import operator\nfrom cacheq import CacheQ\n\ncq = CacheQ(name='myqueue', using='cacheq') # as in get_cache('cacheq')\n\n# either enqueue one job\njob = cq.enqueue(operator.add, 1, 2)\n\n# or several at a time. note that both the args=[...] and kwargs={...}\n# arguments are required in this case, even if empty\ntasks = [(operator.add, [1,2], {}), (operator.div, [], {'a': 2, 'b': 2})]\njob = cq.enqueue_many(tasks) # job with many tasks\n\n# or you can use the @cq.job decorator\n@cq.job\ndef myfunc(a,b):\n    return a+b\n\njob = myfunc.delay(1,b=2)\n\n# then wait for results\njob.ready() # False\njob.ready() # True\njob.result # 3\n\n# calling job.ready() or job.result will not hit the database\n# it will look for result and status in cache. once it's ready\n# it will update job in database.\n</pre>\n<p>Running the worker:</p>\n<pre>python manage.py cqworker --using=cacheq --queue=myqueue --name=worker123 --pulse=0.1\n</pre>\n<p>This will run a cqworker with name \u201cworker123\u201d in foreground listening to queue \u201cmyqueue\u201d using the cache backend under get_cache(\u2018cacheq\u2019). The \u2018pulse\u2019 option is not really necessary, but it will accept any value between 0.0 and 1.0, which will be the time that the worker will wait to look for a new job again. I don\u2019t know if this is really helpful, as it would still be only one connection to memcached / redis, and time.sleep is blocking.</p>\n<p>These are the default values</p>\n<ul>\n<li>using: \u2018default\u2019</li>\n<li>queue: \u2018default\u2019</li>\n<li>name: \u2018worker\u2019</li>\n<li>pulse: 1.0</li>\n</ul>\n<p>When running tests it\u2019s helpful to run the worker and exit when jobs are done. You can do this by either calling the cqworker command with the \u2013burst option or by using the worker.run method.:</p>\n<pre>python manage.py cqworker --using=cacheq --queue=myqueue --burst\n\n# or programatically\nfrom cacheq import get_worker\n\nworker = get_worker(queue_name='myqueue', using='cacheq')\nworker.run(burst=True)\n</pre>\n<p>django-cacheq uses django ORM as a backend for job results. This is only something that fitted specific needs I had at the time I wrote this package, but I guess it would be wise to remove it at some point and replace it by a cache backend too, or maybe adding a setting that allows other database to be used specifically as a results backend.</p>\n<p>Anyways, for now you can clear jobs by using the cqclear command:</p>\n<pre>python manage.py cqclear &lt;done failed pending all&gt; [--no-input]\n</pre>\n<p>In the case you want to delete pending jobs, you will have to confirm the action if you do not provide the \u2013no-input option. So have this in mind if you wish to use a cronjob to clear jobs periodically.</p>\n</div>\n<div id=\"history\">\n<h2>History</h2>\n<h2 id=\"id1\"><span class=\"section-subtitle\">0.1.0 (2015-07-25)</span></h2>\n<ul>\n<li>First release on PyPI.</li>\n</ul>\n</div>\n\n          </div>"}, "last_serial": 1652502, "releases": {"0.1.1": [{"comment_text": "", "digests": {"md5": "6558ba82c1b82edf92a681b51ad644a2", "sha256": "33ed8a7b2f5d9511a24e5400c91d7ebe3f67db160354ccd19fedac7daa3dcc06"}, "downloads": -1, "filename": "django-cacheq-0.1.1.tar.gz", "has_sig": false, "md5_digest": "6558ba82c1b82edf92a681b51ad644a2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14015, "upload_time": "2015-07-28T01:00:37", "upload_time_iso_8601": "2015-07-28T01:00:37.066086Z", "url": "https://files.pythonhosted.org/packages/8f/bb/70ff73a0bbaa67fb67e7057a91d834badfe84add6445bfdb8ed783f1a004/django-cacheq-0.1.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "6558ba82c1b82edf92a681b51ad644a2", "sha256": "33ed8a7b2f5d9511a24e5400c91d7ebe3f67db160354ccd19fedac7daa3dcc06"}, "downloads": -1, "filename": "django-cacheq-0.1.1.tar.gz", "has_sig": false, "md5_digest": "6558ba82c1b82edf92a681b51ad644a2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14015, "upload_time": "2015-07-28T01:00:37", "upload_time_iso_8601": "2015-07-28T01:00:37.066086Z", "url": "https://files.pythonhosted.org/packages/8f/bb/70ff73a0bbaa67fb67e7057a91d834badfe84add6445bfdb8ed783f1a004/django-cacheq-0.1.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:37:17 2020"}