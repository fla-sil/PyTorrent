{"info": {"author": "Meet Pragnesh Shah", "author_email": "meetshah1995@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 2.7", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "pytorch-semseg\n==============\n\n|license|\n\nSemantic Segmentation Algorithms Implemented in PyTorch\n-------------------------------------------------------\n\nThis repository aims at mirroring popular semantic segmentation\narchitectures in PyTorch.\n\n.. raw:: html\n\n   <p align=\"center\">\n\n.. raw:: html\n\n   </p>\n\nNetworks implemented\n~~~~~~~~~~~~~~~~~~~~\n\n-  `PSPNet <https://arxiv.org/abs/1612.01105>`__ - With support for\n   loading pretrained models w/o caffe dependency\n-  `FRRN <https://arxiv.org/abs/1611.08323>`__ - Model A and B\n-  `FCN <https://arxiv.org/abs/1411.4038>`__ - All 1 (FCN32s), 2\n   (FCN16s) and 3 (FCN8s) stream variants\n-  `U-Net <https://arxiv.org/abs/1505.04597>`__ - With optional\n   deconvolution and batchnorm\n-  `Link-Net <https://codeac29.github.io/projects/linknet/>`__ - With\n   multiple resnet backends\n-  `Segnet <https://arxiv.org/abs/1511.00561>`__ - With Unpooling using\n   Maxpool indices\n\nUpcoming\n^^^^^^^^\n\n-  `E-Net <https://arxiv.org/abs/1606.02147>`__\n-  `RefineNet <https://arxiv.org/abs/1611.06612>`__\n\nDataLoaders implemented\n~~~~~~~~~~~~~~~~~~~~~~~\n\n-  `CamVid <http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/>`__\n-  `Pascal\n   VOC <http://host.robots.ox.ac.uk/pascal/VOC/voc2012/segexamples/index.html>`__\n-  `ADE20K <http://groups.csail.mit.edu/vision/datasets/ADE20K/>`__\n-  `MIT Scene Parsing\n   Benchmark <http://data.csail.mit.edu/places/ADEchallenge/ADEChallengeData2016.zip>`__\n-  `Cityscapes <https://www.cityscapes-dataset.com/>`__\n\nUpcoming\n^^^^^^^^\n\n-  `NYUDv2 <http://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html>`__\n-  `Sun-RGBD <http://rgbd.cs.princeton.edu/>`__\n-  `MS COCO <http://mscoco.org/>`__\n\nRequirements\n~~~~~~~~~~~~\n\n-  pytorch >=0.3.0\n-  torchvision ==0.2.0\n-  visdom >=1.0.1 (for loss and results visualization)\n-  scipy\n-  tqdm\n\nOne-line installation\n^^^^^^^^^^^^^^^^^^^^^\n\n``pip install -r requirements.txt``\n\nData\n~~~~\n\n-  Download data for desired dataset(s) from list of URLs\n   `here <https://meetshah1995.github.io/semantic-segmentation/deep-learning/pytorch/visdom/2017/06/01/semantic-segmentation-over-the-years.html#sec_datasets>`__.\n-  Extract the zip / tar and modify the path appropriately in\n   ``config.json``\n\nUsage\n~~~~~\n\nLaunch `visdom <https://github.com/facebookresearch/visdom#launch>`__ by\nrunning (in a separate terminal window)\n\n::\n\n    python -m visdom.server\n\n**To train the model :**\n\n::\n\n    python train.py [-h] [--arch [ARCH]] [--dataset [DATASET]]\n                    [--img_rows [IMG_ROWS]] [--img_cols [IMG_COLS]]\n                    [--n_epoch [N_EPOCH]] [--batch_size [BATCH_SIZE]]\n                    [--l_rate [L_RATE]] [--feature_scale [FEATURE_SCALE]]\n                    [--visdom [VISDOM]]\n\n      --arch           Architecture to use ['fcn8s, unet, segnet etc']\n      --dataset        Dataset to use ['pascal, camvid, ade20k etc']\n      --img_rows       Height of the input image\n      --img_cols       Width of the input image\n      --n_epoch        # of the epochs\n      --batch_size     Batch Size\n      --l_rate         Learning Rate\n      --feature_scale  Divider for # of features to use\n      --visdom         Show visualization(s) on visdom | False by default\n\n**To validate the model :**\n\n::\n\n    python validate.py [-h] [--model_path [MODEL_PATH]] [--dataset [DATASET]]\n                       [--img_rows [IMG_ROWS]] [--img_cols [IMG_COLS]]\n                       [--batch_size [BATCH_SIZE]] [--split [SPLIT]]\n\n      --model_path   Path to the saved model\n      --dataset      Dataset to use ['pascal, camvid, ade20k etc']\n      --img_rows     Height of the input image\n      --img_cols     Width of the input image\n      --batch_size   Batch Size\n      --split        Split of dataset to validate on\n\n**To test the model w.r.t. a dataset on custom images(s):**\n\n::\n\n    python test.py [-h] [--model_path [MODEL_PATH]] [--dataset [DATASET]]\n                   [--dcrf [DCRF]] [--img_path [IMG_PATH]] [--out_path [OUT_PATH]]\n     \n      --model_path          Path to the saved model\n      --dataset             Dataset to use ['pascal, camvid, ade20k etc']\n      --dcrf                Enable DenseCRF based post-processing\n      --img_path            Path of the input image\n      --out_path            Path of the output segmap\n\n.. |license| image:: https://img.shields.io/github/license/mashape/apistatus.svg\n   :target: https://github.com/meetshah1995/pytorch-semseg/blob/master/LICENSE", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/meetshah1995/pytorch-semseg", "keywords": "semantic-segmentation,fully-convolutional-networks,deep-learning,pytorch", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "pytorch-semseg", "package_url": "https://pypi.org/project/pytorch-semseg/", "platform": "", "project_url": "https://pypi.org/project/pytorch-semseg/", "project_urls": {"Homepage": "https://github.com/meetshah1995/pytorch-semseg"}, "release_url": "https://pypi.org/project/pytorch-semseg/0.1.2/", "requires_dist": null, "requires_python": "", "summary": "Semantic Segmentation Architectures implemented in PyTorch", "version": "0.1.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            pytorch-semseg<br>==============<br><br>|license|<br><br>Semantic Segmentation Algorithms Implemented in PyTorch<br>-------------------------------------------------------<br><br>This repository aims at mirroring popular semantic segmentation<br>architectures in PyTorch.<br><br>.. raw:: html<br><br>   &lt;p align=\"center\"&gt;<br><br>.. raw:: html<br><br>   &lt;/p&gt;<br><br>Networks implemented<br>~~~~~~~~~~~~~~~~~~~~<br><br>-  `PSPNet &lt;https://arxiv.org/abs/1612.01105&gt;`__ - With support for<br>   loading pretrained models w/o caffe dependency<br>-  `FRRN &lt;https://arxiv.org/abs/1611.08323&gt;`__ - Model A and B<br>-  `FCN &lt;https://arxiv.org/abs/1411.4038&gt;`__ - All 1 (FCN32s), 2<br>   (FCN16s) and 3 (FCN8s) stream variants<br>-  `U-Net &lt;https://arxiv.org/abs/1505.04597&gt;`__ - With optional<br>   deconvolution and batchnorm<br>-  `Link-Net &lt;https://codeac29.github.io/projects/linknet/&gt;`__ - With<br>   multiple resnet backends<br>-  `Segnet &lt;https://arxiv.org/abs/1511.00561&gt;`__ - With Unpooling using<br>   Maxpool indices<br><br>Upcoming<br>^^^^^^^^<br><br>-  `E-Net &lt;https://arxiv.org/abs/1606.02147&gt;`__<br>-  `RefineNet &lt;https://arxiv.org/abs/1611.06612&gt;`__<br><br>DataLoaders implemented<br>~~~~~~~~~~~~~~~~~~~~~~~<br><br>-  `CamVid &lt;http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/&gt;`__<br>-  `Pascal<br>   VOC &lt;http://host.robots.ox.ac.uk/pascal/VOC/voc2012/segexamples/index.html&gt;`__<br>-  `ADE20K &lt;http://groups.csail.mit.edu/vision/datasets/ADE20K/&gt;`__<br>-  `MIT Scene Parsing<br>   Benchmark &lt;http://data.csail.mit.edu/places/ADEchallenge/ADEChallengeData2016.zip&gt;`__<br>-  `Cityscapes &lt;https://www.cityscapes-dataset.com/&gt;`__<br><br>Upcoming<br>^^^^^^^^<br><br>-  `NYUDv2 &lt;http://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html&gt;`__<br>-  `Sun-RGBD &lt;http://rgbd.cs.princeton.edu/&gt;`__<br>-  `MS COCO &lt;http://mscoco.org/&gt;`__<br><br>Requirements<br>~~~~~~~~~~~~<br><br>-  pytorch &gt;=0.3.0<br>-  torchvision ==0.2.0<br>-  visdom &gt;=1.0.1 (for loss and results visualization)<br>-  scipy<br>-  tqdm<br><br>One-line installation<br>^^^^^^^^^^^^^^^^^^^^^<br><br>``pip install -r requirements.txt``<br><br>Data<br>~~~~<br><br>-  Download data for desired dataset(s) from list of URLs<br>   `here &lt;https://meetshah1995.github.io/semantic-segmentation/deep-learning/pytorch/visdom/2017/06/01/semantic-segmentation-over-the-years.html#sec_datasets&gt;`__.<br>-  Extract the zip / tar and modify the path appropriately in<br>   ``config.json``<br><br>Usage<br>~~~~~<br><br>Launch `visdom &lt;https://github.com/facebookresearch/visdom#launch&gt;`__ by<br>running (in a separate terminal window)<br><br>::<br><br>    python -m visdom.server<br><br>**To train the model :**<br><br>::<br><br>    python train.py [-h] [--arch [ARCH]] [--dataset [DATASET]]<br>                    [--img_rows [IMG_ROWS]] [--img_cols [IMG_COLS]]<br>                    [--n_epoch [N_EPOCH]] [--batch_size [BATCH_SIZE]]<br>                    [--l_rate [L_RATE]] [--feature_scale [FEATURE_SCALE]]<br>                    [--visdom [VISDOM]]<br><br>      --arch           Architecture to use ['fcn8s, unet, segnet etc']<br>      --dataset        Dataset to use ['pascal, camvid, ade20k etc']<br>      --img_rows       Height of the input image<br>      --img_cols       Width of the input image<br>      --n_epoch        # of the epochs<br>      --batch_size     Batch Size<br>      --l_rate         Learning Rate<br>      --feature_scale  Divider for # of features to use<br>      --visdom         Show visualization(s) on visdom | False by default<br><br>**To validate the model :**<br><br>::<br><br>    python validate.py [-h] [--model_path [MODEL_PATH]] [--dataset [DATASET]]<br>                       [--img_rows [IMG_ROWS]] [--img_cols [IMG_COLS]]<br>                       [--batch_size [BATCH_SIZE]] [--split [SPLIT]]<br><br>      --model_path   Path to the saved model<br>      --dataset      Dataset to use ['pascal, camvid, ade20k etc']<br>      --img_rows     Height of the input image<br>      --img_cols     Width of the input image<br>      --batch_size   Batch Size<br>      --split        Split of dataset to validate on<br><br>**To test the model w.r.t. a dataset on custom images(s):**<br><br>::<br><br>    python test.py [-h] [--model_path [MODEL_PATH]] [--dataset [DATASET]]<br>                   [--dcrf [DCRF]] [--img_path [IMG_PATH]] [--out_path [OUT_PATH]]<br>     <br>      --model_path          Path to the saved model<br>      --dataset             Dataset to use ['pascal, camvid, ade20k etc']<br>      --dcrf                Enable DenseCRF based post-processing<br>      --img_path            Path of the input image<br>      --out_path            Path of the output segmap<br><br>.. |license| image:: https://img.shields.io/github/license/mashape/apistatus.svg<br>   :target: https://github.com/meetshah1995/pytorch-semseg/blob/master/LICENSE\n          </div>"}, "last_serial": 3565725, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "3b935b6e61c7b10de3db93db596175bc", "sha256": "ba41ef16d1a5fefd311518f7176bf9ee58b2f1eb2f51aee2f89b7d643444fe7c"}, "downloads": -1, "filename": "pytorch-semseg-0.1.tar.gz", "has_sig": false, "md5_digest": "3b935b6e61c7b10de3db93db596175bc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 30042, "upload_time": "2018-02-09T00:19:25", "upload_time_iso_8601": "2018-02-09T00:19:25.509141Z", "url": "https://files.pythonhosted.org/packages/a3/2e/1876447e32fc8e4e9bc3c4af0c6cdb96660ea713043dc7b41d13f6d4fcf0/pytorch-semseg-0.1.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "7dfd9a676fa8cab713a6dc74f44febb4", "sha256": "c90991be4bb13501077df2f58274b80fced5dfb89a13accc912f7db1a00dc5b0"}, "downloads": -1, "filename": "pytorch-semseg-0.1.1.tar.gz", "has_sig": false, "md5_digest": "7dfd9a676fa8cab713a6dc74f44febb4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 32197, "upload_time": "2018-02-09T00:26:43", "upload_time_iso_8601": "2018-02-09T00:26:43.998305Z", "url": "https://files.pythonhosted.org/packages/dd/2b/ad48be17d47d35e7f960ab0b03e1387d7f7c6d246c52b4931f36c1ad5729/pytorch-semseg-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "4d1e4e9bab756e85b39a2443b11506e7", "sha256": "2df65b7a17ff4a100c8d1e0d0e90af26897d4fdedcb123fe2bc402e5ea89a41c"}, "downloads": -1, "filename": "pytorch-semseg-0.1.2.tar.gz", "has_sig": false, "md5_digest": "4d1e4e9bab756e85b39a2443b11506e7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 32425, "upload_time": "2018-02-09T00:28:18", "upload_time_iso_8601": "2018-02-09T00:28:18.329248Z", "url": "https://files.pythonhosted.org/packages/f3/6a/c70e875a14b3cc9839a3d27431f471e62a111c47e9e14ce88e273954f383/pytorch-semseg-0.1.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "4d1e4e9bab756e85b39a2443b11506e7", "sha256": "2df65b7a17ff4a100c8d1e0d0e90af26897d4fdedcb123fe2bc402e5ea89a41c"}, "downloads": -1, "filename": "pytorch-semseg-0.1.2.tar.gz", "has_sig": false, "md5_digest": "4d1e4e9bab756e85b39a2443b11506e7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 32425, "upload_time": "2018-02-09T00:28:18", "upload_time_iso_8601": "2018-02-09T00:28:18.329248Z", "url": "https://files.pythonhosted.org/packages/f3/6a/c70e875a14b3cc9839a3d27431f471e62a111c47e9e14ce88e273954f383/pytorch-semseg-0.1.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:13:44 2020"}