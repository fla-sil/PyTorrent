{"info": {"author": "Marcel Rieger", "author_email": "UNKNOWN", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "Intended Audience :: Information Technology", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 2", "Programming Language :: Python :: 3", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "|Build Status| |Documentation Status| |Package Status|\n\nDeploy `tensorflow <https://www.tensorflow.org>`__ graphs for *fast*\nevaluation and export to *tensorflow-less* environments running\n`numpy <http://www.numpy.org>`__.\n\n**Now with tensorflow 1.0 support.**\n\nEvaluation usage\n''''''''''''''''\n\n.. code:: python\n\n    import tfdeploy as td\n    import numpy as np\n\n    model = td.Model(\"/path/to/model.pkl\")\n    inp, outp = model.get(\"input\", \"output\")\n\n    batch = np.random.rand(10000, 784)\n    result = outp.eval({inp: batch})\n\nInstallation and dependencies\n'''''''''''''''''''''''''''''\n\nVia `pip <https://pypi.python.org/pypi/tfdeploy>`__\n\n.. code:: bash\n\n    pip install tfdeploy\n\nor by simply copying the file into your project.\n\nNumpy \u2265 1.10 should be installed on your system.\n`Scipy <http://www.scipy.org/>`__ is optional. See\n`optimization <#optimization>`__ for more info on optional packages.\n\nBy design, tensorflow is required when creating a model. All versions \u2265\n1.0.1 are supported.\n\nContent\n~~~~~~~\n\n-  `Why? <#why>`__\n-  `How? <#how>`__\n\n   -  `Convert your graph <#convert-your-graph>`__\n   -  `Load the model and evaluate <#load-the-model-and-evaluate>`__\n   -  `Write your own operation <#write-your-own-operation>`__\n\n-  `Ensembles <#ensembles>`__\n-  `Optimization <#optimization>`__\n-  `Performance <#performance>`__\n-  `Contributing <#contributing>`__\n-  `Development <#development>`__\n-  `Authors <#authors>`__\n-  `License <#license>`__\n\nWhy?\n----\n\nWorking with tensorflow is awesome. Model definition and training is\nsimple yet powerful, and the range of built-in features is just\nstriking.\n\nHowever, when it comes down to model deployment and evaluation, things\nget a bit more cumbersome than they should be. You either export your\ngraph to a new file *and* `save your trained\nvariables <https://www.tensorflow.org/versions/master/how_tos/variables/index.html#saving-variables>`__\nin a separate file, or you make use of tensorflow's `serving\nsystem <https://www.tensorflow.org/versions/master/tutorials/tfserve/index.html>`__.\nWouldn't it be great if you could just export your model to a simple\nnumpy-based callable? Of course it would. And this is exactly what\ntfdeploy does for you.\n\nTo boil it down, tfdeploy\n\n-  is lightweight. A single file with < 150 lines of core code. Just\n   copy it to your project.\n-  `faster <#performance>`__ than using tensorflow's ``Tensor.eval``.\n-  **does not need tensorflow** during evaluation.\n-  only depends on numpy.\n-  can load one or more models from a single file.\n-  does not support GPUs (maybe\n   `gnumpy <http://www.cs.toronto.edu/~tijmen/gnumpy.html>`__ is worth a\n   try here).\n\nHow?\n----\n\nThe central class is ``tfdeploy.Model``. The following two examples\ndemonstrate how a model can be created from a tensorflow graph, saved to\nand loaded from disk, and eventually evaluated.\n\nConvert your graph\n''''''''''''''''''\n\n.. code:: python\n\n    import tensorflow as tf\n    import tfdeploy as td\n\n    # setup tfdeploy (only when creating models)\n    td.setup(tf)\n\n    # build your graph\n    sess = tf.Session()\n\n    # use names for input and output layers\n    x = tf.placeholder(\"float\", shape=[None, 784], name=\"input\")\n    W = tf.Variable(tf.truncated_normal([784, 100], stddev=0.05))\n    b = tf.Variable(tf.zeros([100]))\n    y = tf.nn.softmax(tf.matmul(x, W) + b, name=\"output\")\n\n    sess.run(tf.global_variables_initializer())\n\n    # ... training ...\n\n    # create a tfdeploy model and save it to disk\n    model = td.Model()\n    model.add(y, sess) # y and all its ops and related tensors are added recursively\n    model.save(\"model.pkl\")\n\nLoad the model and evaluate\n'''''''''''''''''''''''''''\n\n.. code:: python\n\n    import numpy as np\n    import tfdeploy as td\n\n    model = td.Model(\"model.pkl\")\n\n    # shorthand to x and y\n    x, y = model.get(\"input\", \"output\")\n\n    # evaluate\n    batch = np.random.rand(10000, 784)\n    result = y.eval({x: batch})\n\nWrite your own ``Operation``\n''''''''''''''''''''''''''''\n\ntfdeploy supports most of the ``Operation``'s `implemented in\ntensorflow <https://www.tensorflow.org/versions/master/api_docs/python/math_ops.html>`__.\nHowever, if you miss one (in that case, submit a PR or an issue ;) ) or\nif you're using custom ops, you might want to extend tfdeploy by\ndefining a new class op that inherits from ``tfdeploy.Operation``:\n\n.. code:: python\n\n    import tensorflow as tf\n    import tfdeploy as td\n    import numpy as np\n\n    # setup tfdeploy (only when creating models)\n    td.setup(tf)\n\n    # ... write you model here ...\n\n    # let's assume your final tensor \"y\" relies on an op of type \"InvertedSoftmax\"\n    # before creating the td.Model, you should add that op to tfdeploy\n\n    class InvertedSoftmax(td.Operation):\n        @staticmethod\n        def func(a):\n            e = np.exp(-a)\n            # ops should return a tuple\n            return np.divide(e, np.sum(e, axis=-1, keepdims=True)),\n\n    # this is equivalent to\n    # @td.Operation.factory\n    # def InvertedSoftmax(a):\n    #     e = np.exp(-a)\n    #     return np.divide(e, np.sum(e, axis=-1, keepdims=True)),\n\n    # now we're good to go\n    model = td.Model()\n    model.add(y, sess)\n    model.save(\"model.pkl\")\n\nWhen writing new ops, three things are important:\n\n-  Try to avoid loops, prefer numpy vectorization.\n-  Return a tuple.\n-  Don't change incoming tensors/arrays in-place, always work on and\n   return copies.\n\nEnsembles\n---------\n\ntfdeploy provides a helper class to evaluate an ensemble of models:\n``Ensemble``. It can load multiple models, evaluate them and combine\ntheir output values using different methods.\n\n.. code:: python\n\n    # create the ensemble\n    ensemble = td.Ensemble([\"model1.pkl\", \"model2.pkl\", ...], method=td.METHOD_MEAN)\n\n    # get input and output tensors (which actually are TensorEnsemble instances)\n    input, output = ensemble.get(\"input\", \"output\")\n\n    # evaluate the ensemble just like a normal model\n    batch = ...\n    value = output.eval({input: batch})\n\nThe return value of ``get()`` is a ``TensorEnsemble`` istance. It is\nbasically a wrapper around multiple tensors and should be used as keys\nin the ``feed_dict`` of the ``eval()`` call.\n\nYou can choose between ``METHOD_MEAN`` (the default), ``METHOD_MAX`` and\n``METHOD_MIN``. If you want to use a custom ensembling method, use\n``METHOD_CUSTOM`` and overwrite the static ``func_custom()`` method of\nthe ``TensorEnsemble`` instance.\n\nOptimization\n------------\n\nMost ops are written using pure numpy. However, multiple implementations\nof the same op are allowed that may use additional third-party Python\npackages providing even faster functionality for some situations.\n\nFor example, numpy does not provide a vectorized *lgamma* function.\nThus, the standard ``tfdeploy.Lgamma`` op uses ``math.lgamma`` that was\npreviously vectorized using ``numpy.vectorize``. For these situations,\nadditional implementations of the same op are possible (the *lgamma*\nexample is quite academic, but this definitely makes sense for more\nsophisticated ops like pooling). We can simply tell the op to use its\nscipy implementation instead:\n\n.. code:: python\n\n    td.Lgamma.use_impl(td.IMPL_SCIPY)\n\nCurrently, allowed implementation types are numpy (``IMPL_NUMPY``, the\ndefault) and scipy (``IMPL_SCIPY``).\n\nAdding additional implementations\n'''''''''''''''''''''''''''''''''\n\nAdditional implementations can be added by setting the ``impl``\nattribute of the op factory or by using the ``add_impl`` decorator of\nexisting operations. The first registered implementation will be the\ndefault one.\n\n.. code:: python\n\n    # create the default lgamma op with numpy implementation\n    lgamma_vec = np.vectorize(math.lgamma)\n\n    @td.Operation.factory\n    # equivalent to\n    # @td.Operation.factory(impl=td.IMPL_NUMPY)\n    def Lgamma(a):\n        return lgamma_vec(a),\n\n    # add a scipy-based implementation\n    @Lgamma.add_impl(td.IMPL_SCIPY)\n    def Lgamma(a):\n        return sp.special.gammaln(a),\n\nAuto-optimization\n'''''''''''''''''\n\nIf scipy is available on your system, it is reasonable to use all ops in\ntheir scipy implementation (if it exists, of course). This should be\nconfigured before you create any model from tensorflow objects using the\nsecond argument of the ``setup`` function:\n\n.. code:: python\n\n    td.setup(tf, td.IMPL_SCIPY)\n\nOps that do not implement ``IMPL_SCIPY`` stick with the numpy version\n(``IMPL_NUMPY``).\n\nPerformance\n-----------\n\ntfdeploy is lightweight (1 file, < 150 lines of core code) and fast.\nInternal evaluation calls have only very few overhead and tensor\noperations use numpy vectorization. The actual performance depends on\nthe ops in your graph. While most of the tensorflow ops have a numpy\nequivalent or can be constructed from numpy functions, a few ops require\nadditional Python-based loops (e.g. ``BatchMatMul``). But in many cases\nit's potentially faster than using tensorflow's ``Tensor.eval``.\n\nThis is a comparison for a basic graph where all ops are vectorized\n(basically ``Add``, ``MatMul`` and ``Softmax``):\n\n.. code:: bash\n\n    > ipython -i tests/perf/simple.py\n\n    In [1]: %timeit -n 100 test_tf()\n    100 loops, best of 3: 109 ms per loop\n\n    In [2]: %timeit -n 100 test_td()\n    100 loops, best of 3: 60.5 ms per loop\n\nContributing\n------------\n\nIf you want to contribute with new ops and features, I'm happy to\nreceive pull requests. Just make sure to add a new test case to\n``tests/core.py`` or ``tests/ops.py`` and run them via:\n\n.. code:: bash\n\n    > python -m unittest tests\n\nTest grid\n'''''''''\n\nIn general, tests should be run for different environments:\n\n+----------------------+-------------+\n| Variation            | Values      |\n+======================+=============+\n| tensorflow version   | ``1.0.1``   |\n+----------------------+-------------+\n| python version       | 2, 3        |\n+----------------------+-------------+\n| ``TD_TEST_SCIPY``    | 0, 1        |\n+----------------------+-------------+\n| ``TD_TEST_GPU``      | 0, 1        |\n+----------------------+-------------+\n\nDocker\n''''''\n\nFor testing purposes, it is convenient to use docker. Fortunately, the\nofficial `tensorflow\nimages <https://hub.docker.com/r/tensorflow/tensorflow/>`__ contain all\nwe need:\n\n.. code:: bash\n\n    git clone https://github.com/riga/tfdeploy.git\n    cd tfdeploy\n\n    docker run --rm -v `pwd`:/root/tfdeploy -w /root/tfdeploy -e \"TD_TEST_SCIPY=1\" tensorflow/tensorflow:1.0.1 python -m unittest tests\n\nDevelopment\n-----------\n\n-  Source hosted at `GitHub <https://github.com/riga/tfdeploy>`__\n-  Report issues, questions, feature requests on `GitHub\n   Issues <https://github.com/riga/tfdeploy/issues>`__\n\nAuthors\n-------\n\n-  `Marcel R. <https://github.com/riga>`__\n-  `Benjamin F. <https://github.com/bfis>`__\n\nLicense\n-------\n\nThe MIT License (MIT)\n\nCopyright (c) 2017 Marcel R.\n\nPermission is hereby granted, free of charge, to any person obtaining a\ncopy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be included\nin all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\nOR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\nCLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\nTORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\nSOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n.. |Build Status| image:: https://travis-ci.org/riga/tfdeploy.svg?branch=master\n   :target: https://travis-ci.org/riga/tfdeploy\n.. |Documentation Status| image:: https://readthedocs.org/projects/tfdeploy/badge/?version=latest\n   :target: http://tfdeploy.readthedocs.org/en/latest/?badge=latest\n.. |Package Status| image:: https://badge.fury.io/py/tfdeploy.svg\n   :target: https://badge.fury.io/py/tfdeploy", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/riga/tfdeploy", "keywords": "tensorflow,deploy,export,dump,numpy,model,predict,evaluate,function,method", "license": "MIT", "maintainer": null, "maintainer_email": null, "name": "tfdeploy", "package_url": "https://pypi.org/project/tfdeploy/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/tfdeploy/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/riga/tfdeploy"}, "release_url": "https://pypi.org/project/tfdeploy/0.4.2/", "requires_dist": null, "requires_python": null, "summary": "Deploy tensorflow graphs for fast evaluation and export to tensorflow-less environments running\nnumpy.", "version": "0.4.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            |Build Status| |Documentation Status| |Package Status|<br><br>Deploy `tensorflow &lt;https://www.tensorflow.org&gt;`__ graphs for *fast*<br>evaluation and export to *tensorflow-less* environments running<br>`numpy &lt;http://www.numpy.org&gt;`__.<br><br>**Now with tensorflow 1.0 support.**<br><br>Evaluation usage<br>''''''''''''''''<br><br>.. code:: python<br><br>    import tfdeploy as td<br>    import numpy as np<br><br>    model = td.Model(\"/path/to/model.pkl\")<br>    inp, outp = model.get(\"input\", \"output\")<br><br>    batch = np.random.rand(10000, 784)<br>    result = outp.eval({inp: batch})<br><br>Installation and dependencies<br>'''''''''''''''''''''''''''''<br><br>Via `pip &lt;https://pypi.python.org/pypi/tfdeploy&gt;`__<br><br>.. code:: bash<br><br>    pip install tfdeploy<br><br>or by simply copying the file into your project.<br><br>Numpy \u2265 1.10 should be installed on your system.<br>`Scipy &lt;http://www.scipy.org/&gt;`__ is optional. See<br>`optimization &lt;#optimization&gt;`__ for more info on optional packages.<br><br>By design, tensorflow is required when creating a model. All versions \u2265<br>1.0.1 are supported.<br><br>Content<br>~~~~~~~<br><br>-  `Why? &lt;#why&gt;`__<br>-  `How? &lt;#how&gt;`__<br><br>   -  `Convert your graph &lt;#convert-your-graph&gt;`__<br>   -  `Load the model and evaluate &lt;#load-the-model-and-evaluate&gt;`__<br>   -  `Write your own operation &lt;#write-your-own-operation&gt;`__<br><br>-  `Ensembles &lt;#ensembles&gt;`__<br>-  `Optimization &lt;#optimization&gt;`__<br>-  `Performance &lt;#performance&gt;`__<br>-  `Contributing &lt;#contributing&gt;`__<br>-  `Development &lt;#development&gt;`__<br>-  `Authors &lt;#authors&gt;`__<br>-  `License &lt;#license&gt;`__<br><br>Why?<br>----<br><br>Working with tensorflow is awesome. Model definition and training is<br>simple yet powerful, and the range of built-in features is just<br>striking.<br><br>However, when it comes down to model deployment and evaluation, things<br>get a bit more cumbersome than they should be. You either export your<br>graph to a new file *and* `save your trained<br>variables &lt;https://www.tensorflow.org/versions/master/how_tos/variables/index.html#saving-variables&gt;`__<br>in a separate file, or you make use of tensorflow's `serving<br>system &lt;https://www.tensorflow.org/versions/master/tutorials/tfserve/index.html&gt;`__.<br>Wouldn't it be great if you could just export your model to a simple<br>numpy-based callable? Of course it would. And this is exactly what<br>tfdeploy does for you.<br><br>To boil it down, tfdeploy<br><br>-  is lightweight. A single file with &lt; 150 lines of core code. Just<br>   copy it to your project.<br>-  `faster &lt;#performance&gt;`__ than using tensorflow's ``Tensor.eval``.<br>-  **does not need tensorflow** during evaluation.<br>-  only depends on numpy.<br>-  can load one or more models from a single file.<br>-  does not support GPUs (maybe<br>   `gnumpy &lt;http://www.cs.toronto.edu/~tijmen/gnumpy.html&gt;`__ is worth a<br>   try here).<br><br>How?<br>----<br><br>The central class is ``tfdeploy.Model``. The following two examples<br>demonstrate how a model can be created from a tensorflow graph, saved to<br>and loaded from disk, and eventually evaluated.<br><br>Convert your graph<br>''''''''''''''''''<br><br>.. code:: python<br><br>    import tensorflow as tf<br>    import tfdeploy as td<br><br>    # setup tfdeploy (only when creating models)<br>    td.setup(tf)<br><br>    # build your graph<br>    sess = tf.Session()<br><br>    # use names for input and output layers<br>    x = tf.placeholder(\"float\", shape=[None, 784], name=\"input\")<br>    W = tf.Variable(tf.truncated_normal([784, 100], stddev=0.05))<br>    b = tf.Variable(tf.zeros([100]))<br>    y = tf.nn.softmax(tf.matmul(x, W) + b, name=\"output\")<br><br>    sess.run(tf.global_variables_initializer())<br><br>    # ... training ...<br><br>    # create a tfdeploy model and save it to disk<br>    model = td.Model()<br>    model.add(y, sess) # y and all its ops and related tensors are added recursively<br>    model.save(\"model.pkl\")<br><br>Load the model and evaluate<br>'''''''''''''''''''''''''''<br><br>.. code:: python<br><br>    import numpy as np<br>    import tfdeploy as td<br><br>    model = td.Model(\"model.pkl\")<br><br>    # shorthand to x and y<br>    x, y = model.get(\"input\", \"output\")<br><br>    # evaluate<br>    batch = np.random.rand(10000, 784)<br>    result = y.eval({x: batch})<br><br>Write your own ``Operation``<br>''''''''''''''''''''''''''''<br><br>tfdeploy supports most of the ``Operation``'s `implemented in<br>tensorflow &lt;https://www.tensorflow.org/versions/master/api_docs/python/math_ops.html&gt;`__.<br>However, if you miss one (in that case, submit a PR or an issue ;) ) or<br>if you're using custom ops, you might want to extend tfdeploy by<br>defining a new class op that inherits from ``tfdeploy.Operation``:<br><br>.. code:: python<br><br>    import tensorflow as tf<br>    import tfdeploy as td<br>    import numpy as np<br><br>    # setup tfdeploy (only when creating models)<br>    td.setup(tf)<br><br>    # ... write you model here ...<br><br>    # let's assume your final tensor \"y\" relies on an op of type \"InvertedSoftmax\"<br>    # before creating the td.Model, you should add that op to tfdeploy<br><br>    class InvertedSoftmax(td.Operation):<br>        @staticmethod<br>        def func(a):<br>            e = np.exp(-a)<br>            # ops should return a tuple<br>            return np.divide(e, np.sum(e, axis=-1, keepdims=True)),<br><br>    # this is equivalent to<br>    # @td.Operation.factory<br>    # def InvertedSoftmax(a):<br>    #     e = np.exp(-a)<br>    #     return np.divide(e, np.sum(e, axis=-1, keepdims=True)),<br><br>    # now we're good to go<br>    model = td.Model()<br>    model.add(y, sess)<br>    model.save(\"model.pkl\")<br><br>When writing new ops, three things are important:<br><br>-  Try to avoid loops, prefer numpy vectorization.<br>-  Return a tuple.<br>-  Don't change incoming tensors/arrays in-place, always work on and<br>   return copies.<br><br>Ensembles<br>---------<br><br>tfdeploy provides a helper class to evaluate an ensemble of models:<br>``Ensemble``. It can load multiple models, evaluate them and combine<br>their output values using different methods.<br><br>.. code:: python<br><br>    # create the ensemble<br>    ensemble = td.Ensemble([\"model1.pkl\", \"model2.pkl\", ...], method=td.METHOD_MEAN)<br><br>    # get input and output tensors (which actually are TensorEnsemble instances)<br>    input, output = ensemble.get(\"input\", \"output\")<br><br>    # evaluate the ensemble just like a normal model<br>    batch = ...<br>    value = output.eval({input: batch})<br><br>The return value of ``get()`` is a ``TensorEnsemble`` istance. It is<br>basically a wrapper around multiple tensors and should be used as keys<br>in the ``feed_dict`` of the ``eval()`` call.<br><br>You can choose between ``METHOD_MEAN`` (the default), ``METHOD_MAX`` and<br>``METHOD_MIN``. If you want to use a custom ensembling method, use<br>``METHOD_CUSTOM`` and overwrite the static ``func_custom()`` method of<br>the ``TensorEnsemble`` instance.<br><br>Optimization<br>------------<br><br>Most ops are written using pure numpy. However, multiple implementations<br>of the same op are allowed that may use additional third-party Python<br>packages providing even faster functionality for some situations.<br><br>For example, numpy does not provide a vectorized *lgamma* function.<br>Thus, the standard ``tfdeploy.Lgamma`` op uses ``math.lgamma`` that was<br>previously vectorized using ``numpy.vectorize``. For these situations,<br>additional implementations of the same op are possible (the *lgamma*<br>example is quite academic, but this definitely makes sense for more<br>sophisticated ops like pooling). We can simply tell the op to use its<br>scipy implementation instead:<br><br>.. code:: python<br><br>    td.Lgamma.use_impl(td.IMPL_SCIPY)<br><br>Currently, allowed implementation types are numpy (``IMPL_NUMPY``, the<br>default) and scipy (``IMPL_SCIPY``).<br><br>Adding additional implementations<br>'''''''''''''''''''''''''''''''''<br><br>Additional implementations can be added by setting the ``impl``<br>attribute of the op factory or by using the ``add_impl`` decorator of<br>existing operations. The first registered implementation will be the<br>default one.<br><br>.. code:: python<br><br>    # create the default lgamma op with numpy implementation<br>    lgamma_vec = np.vectorize(math.lgamma)<br><br>    @td.Operation.factory<br>    # equivalent to<br>    # @td.Operation.factory(impl=td.IMPL_NUMPY)<br>    def Lgamma(a):<br>        return lgamma_vec(a),<br><br>    # add a scipy-based implementation<br>    @Lgamma.add_impl(td.IMPL_SCIPY)<br>    def Lgamma(a):<br>        return sp.special.gammaln(a),<br><br>Auto-optimization<br>'''''''''''''''''<br><br>If scipy is available on your system, it is reasonable to use all ops in<br>their scipy implementation (if it exists, of course). This should be<br>configured before you create any model from tensorflow objects using the<br>second argument of the ``setup`` function:<br><br>.. code:: python<br><br>    td.setup(tf, td.IMPL_SCIPY)<br><br>Ops that do not implement ``IMPL_SCIPY`` stick with the numpy version<br>(``IMPL_NUMPY``).<br><br>Performance<br>-----------<br><br>tfdeploy is lightweight (1 file, &lt; 150 lines of core code) and fast.<br>Internal evaluation calls have only very few overhead and tensor<br>operations use numpy vectorization. The actual performance depends on<br>the ops in your graph. While most of the tensorflow ops have a numpy<br>equivalent or can be constructed from numpy functions, a few ops require<br>additional Python-based loops (e.g. ``BatchMatMul``). But in many cases<br>it's potentially faster than using tensorflow's ``Tensor.eval``.<br><br>This is a comparison for a basic graph where all ops are vectorized<br>(basically ``Add``, ``MatMul`` and ``Softmax``):<br><br>.. code:: bash<br><br>    &gt; ipython -i tests/perf/simple.py<br><br>    In [1]: %timeit -n 100 test_tf()<br>    100 loops, best of 3: 109 ms per loop<br><br>    In [2]: %timeit -n 100 test_td()<br>    100 loops, best of 3: 60.5 ms per loop<br><br>Contributing<br>------------<br><br>If you want to contribute with new ops and features, I'm happy to<br>receive pull requests. Just make sure to add a new test case to<br>``tests/core.py`` or ``tests/ops.py`` and run them via:<br><br>.. code:: bash<br><br>    &gt; python -m unittest tests<br><br>Test grid<br>'''''''''<br><br>In general, tests should be run for different environments:<br><br>+----------------------+-------------+<br>| Variation            | Values      |<br>+======================+=============+<br>| tensorflow version   | ``1.0.1``   |<br>+----------------------+-------------+<br>| python version       | 2, 3        |<br>+----------------------+-------------+<br>| ``TD_TEST_SCIPY``    | 0, 1        |<br>+----------------------+-------------+<br>| ``TD_TEST_GPU``      | 0, 1        |<br>+----------------------+-------------+<br><br>Docker<br>''''''<br><br>For testing purposes, it is convenient to use docker. Fortunately, the<br>official `tensorflow<br>images &lt;https://hub.docker.com/r/tensorflow/tensorflow/&gt;`__ contain all<br>we need:<br><br>.. code:: bash<br><br>    git clone https://github.com/riga/tfdeploy.git<br>    cd tfdeploy<br><br>    docker run --rm -v `pwd`:/root/tfdeploy -w /root/tfdeploy -e \"TD_TEST_SCIPY=1\" tensorflow/tensorflow:1.0.1 python -m unittest tests<br><br>Development<br>-----------<br><br>-  Source hosted at `GitHub &lt;https://github.com/riga/tfdeploy&gt;`__<br>-  Report issues, questions, feature requests on `GitHub<br>   Issues &lt;https://github.com/riga/tfdeploy/issues&gt;`__<br><br>Authors<br>-------<br><br>-  `Marcel R. &lt;https://github.com/riga&gt;`__<br>-  `Benjamin F. &lt;https://github.com/bfis&gt;`__<br><br>License<br>-------<br><br>The MIT License (MIT)<br><br>Copyright (c) 2017 Marcel R.<br><br>Permission is hereby granted, free of charge, to any person obtaining a<br>copy of this software and associated documentation files (the<br>\"Software\"), to deal in the Software without restriction, including<br>without limitation the rights to use, copy, modify, merge, publish,<br>distribute, sublicense, and/or sell copies of the Software, and to<br>permit persons to whom the Software is furnished to do so, subject to<br>the following conditions:<br><br>The above copyright notice and this permission notice shall be included<br>in all copies or substantial portions of the Software.<br><br>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS<br>OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF<br>MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.<br>IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY<br>CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,<br>TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE<br>SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.<br><br>.. |Build Status| image:: https://travis-ci.org/riga/tfdeploy.svg?branch=master<br>   :target: https://travis-ci.org/riga/tfdeploy<br>.. |Documentation Status| image:: https://readthedocs.org/projects/tfdeploy/badge/?version=latest<br>   :target: http://tfdeploy.readthedocs.org/en/latest/?badge=latest<br>.. |Package Status| image:: https://badge.fury.io/py/tfdeploy.svg<br>   :target: https://badge.fury.io/py/tfdeploy\n          </div>"}, "last_serial": 2740959, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "4365c8ec2735d0ddad718f0a64fc4123", "sha256": "7f6b78657db41829c26e26daa87e9e97315a98752154723db6b454a5d67a7444"}, "downloads": -1, "filename": "tfdeploy-0.1.0.tar.gz", "has_sig": false, "md5_digest": "4365c8ec2735d0ddad718f0a64fc4123", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2579, "upload_time": "2016-03-08T15:10:41", "upload_time_iso_8601": "2016-03-08T15:10:41.175198Z", "url": "https://files.pythonhosted.org/packages/4e/51/afec6de7e4c325d9e204dd0ee2da1e38b44a8a6250263bab3d401b1246c8/tfdeploy-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "2a23636a7e3105f82495265ce3bd3f88", "sha256": "918f138e044cac241aef060f668da1335fd10825cdda290580ebdefc2b55ac6e"}, "downloads": -1, "filename": "tfdeploy-0.1.1.tar.gz", "has_sig": false, "md5_digest": "2a23636a7e3105f82495265ce3bd3f88", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3828, "upload_time": "2016-03-08T17:08:06", "upload_time_iso_8601": "2016-03-08T17:08:06.012760Z", "url": "https://files.pythonhosted.org/packages/34/13/0b330e799450259d40d2ec309194647db6fbd084430909c4e84f96f306da/tfdeploy-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "94f3054b84a77509c339c01230bd6c02", "sha256": "3c82c67be74909e5feef22c74c851e327437d3ff2ea4b6a7c125bee9cf9a9a4b"}, "downloads": -1, "filename": "tfdeploy-0.1.2.tar.gz", "has_sig": false, "md5_digest": "94f3054b84a77509c339c01230bd6c02", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3965, "upload_time": "2016-03-08T17:17:21", "upload_time_iso_8601": "2016-03-08T17:17:21.262344Z", "url": "https://files.pythonhosted.org/packages/25/be/a067337ab047a3ac9b0610129104c290d8968002afd1343e170c3aef1434/tfdeploy-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "58e7739c36daddd94d99b06094462b85", "sha256": "49e890fc97fa57314da0009f1f76adcc805a1eb1509a540418d821d07241f3f8"}, "downloads": -1, "filename": "tfdeploy-0.1.3.tar.gz", "has_sig": false, "md5_digest": "58e7739c36daddd94d99b06094462b85", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4008, "upload_time": "2016-03-08T17:31:15", "upload_time_iso_8601": "2016-03-08T17:31:15.986623Z", "url": "https://files.pythonhosted.org/packages/57/b9/49180a8640e149375a806c22ac3c1967b85517101edce4d4e44171642660/tfdeploy-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "312f4ac0bbe8b84d40122ebefee21758", "sha256": "6545b0c8d2c7208ccb727c0b7ad930b962a0eeaf5d1040d95e7f5053a866f5b8"}, "downloads": -1, "filename": "tfdeploy-0.1.4.tar.gz", "has_sig": false, "md5_digest": "312f4ac0bbe8b84d40122ebefee21758", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4097, "upload_time": "2016-03-08T17:46:48", "upload_time_iso_8601": "2016-03-08T17:46:48.938020Z", "url": "https://files.pythonhosted.org/packages/fd/30/cb104773584b39f7d97ec0c81980765b1f8643568c8c8454a205543e813a/tfdeploy-0.1.4.tar.gz", "yanked": false}], "0.1.5": [{"comment_text": "", "digests": {"md5": "4b1d0140926a7fd25053a553a628c901", "sha256": "f7c87dc08e463511515e8cf8d5ad3ce81dadf84995c19740fd5a551fa422a64f"}, "downloads": -1, "filename": "tfdeploy-0.1.5.tar.gz", "has_sig": false, "md5_digest": "4b1d0140926a7fd25053a553a628c901", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4243, "upload_time": "2016-03-08T22:14:24", "upload_time_iso_8601": "2016-03-08T22:14:24.336229Z", "url": "https://files.pythonhosted.org/packages/a4/8e/f5edacea41418a5cf86b24dec487282bdf8e2168685cd0962409e95e6828/tfdeploy-0.1.5.tar.gz", "yanked": false}], "0.1.6": [{"comment_text": "", "digests": {"md5": "89f4606dd53a078d087d7530f55589f9", "sha256": "56f7e553842e5b67ed85af2063afb73d44d033c0fc86d5bbe23da52bd3e87c99"}, "downloads": -1, "filename": "tfdeploy-0.1.6.tar.gz", "has_sig": false, "md5_digest": "89f4606dd53a078d087d7530f55589f9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8234, "upload_time": "2016-03-10T10:48:27", "upload_time_iso_8601": "2016-03-10T10:48:27.648391Z", "url": "https://files.pythonhosted.org/packages/d4/fb/cfc2596f31c485220b75b27606d7a043eb10e358bfdc2babe51dbb659411/tfdeploy-0.1.6.tar.gz", "yanked": false}], "0.1.7": [{"comment_text": "", "digests": {"md5": "70b3d0b8135e7752b811a1897d799bf9", "sha256": "d519b95178cda302cbdb62d4de00fbbd0400ce64f681eb58cbc0a2a2421dd30f"}, "downloads": -1, "filename": "tfdeploy-0.1.7.tar.gz", "has_sig": false, "md5_digest": "70b3d0b8135e7752b811a1897d799bf9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9408, "upload_time": "2016-03-11T17:24:07", "upload_time_iso_8601": "2016-03-11T17:24:07.918488Z", "url": "https://files.pythonhosted.org/packages/31/c7/8a3aa1a474abd5884efd60e62bf4ab6f96120e8e34d44eaff839b9527e44/tfdeploy-0.1.7.tar.gz", "yanked": false}], "0.1.8": [{"comment_text": "", "digests": {"md5": "026854eaa5a5b1fe6026e9718da95b3d", "sha256": "03b9f39bc2aa143d390e23789dd5dbdfaac673a8b109bc8b7b9dd3bee113d370"}, "downloads": -1, "filename": "tfdeploy-0.1.8.tar.gz", "has_sig": false, "md5_digest": "026854eaa5a5b1fe6026e9718da95b3d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11880, "upload_time": "2016-03-14T12:00:13", "upload_time_iso_8601": "2016-03-14T12:00:13.946199Z", "url": "https://files.pythonhosted.org/packages/7d/1e/90f4f7ccea6e8e3812c352dee33904b03c0e453d2a4c105f6e65353dd48c/tfdeploy-0.1.8.tar.gz", "yanked": false}], "0.1.9": [{"comment_text": "", "digests": {"md5": "bfd1ff0a93e2c645705e30a9ba726222", "sha256": "f1a2623bc9039ad2d817a7db6b1cff9e5274acf39e75444c85cbf2bc3305409f"}, "downloads": -1, "filename": "tfdeploy-0.1.9.tar.gz", "has_sig": false, "md5_digest": "bfd1ff0a93e2c645705e30a9ba726222", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11917, "upload_time": "2016-03-14T13:00:14", "upload_time_iso_8601": "2016-03-14T13:00:14.203368Z", "url": "https://files.pythonhosted.org/packages/5b/8f/02182c3e29df82c7ac599655e84c06b1b83552f363c8959a5321a2a2fe5a/tfdeploy-0.1.9.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "a9f1d29911cb1b2bc2e186034a80973b", "sha256": "21fc2670224971b74fa9531c6ed100185abc54e6e1db5f748c1117c198fc5a6a"}, "downloads": -1, "filename": "tfdeploy-0.2.0.tar.gz", "has_sig": false, "md5_digest": "a9f1d29911cb1b2bc2e186034a80973b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14039, "upload_time": "2016-05-20T23:39:14", "upload_time_iso_8601": "2016-05-20T23:39:14.722594Z", "url": "https://files.pythonhosted.org/packages/d2/45/d3c8b5b2422f3e66e87512001642e248d7301df39c7487f5f43a8b1b5c0f/tfdeploy-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "9ad08bdf94da351ab317498a5b86a0b7", "sha256": "943e216db6b8471e8b661ee6f714ea36bd11c73937d52591a7ecc8aacdddf5ed"}, "downloads": -1, "filename": "tfdeploy-0.2.1.tar.gz", "has_sig": false, "md5_digest": "9ad08bdf94da351ab317498a5b86a0b7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14084, "upload_time": "2016-06-08T18:30:43", "upload_time_iso_8601": "2016-06-08T18:30:43.217164Z", "url": "https://files.pythonhosted.org/packages/21/3c/ae6f0852bd46de4173625eeff8e0a412b1007f02297f611260e91a792d1c/tfdeploy-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "7aae2f542b882a4db5c23967e86d8380", "sha256": "9dab4a4d61a879d37c231e852f645a4eec361e75627215a4e5dd71b2a6c8b5e4"}, "downloads": -1, "filename": "tfdeploy-0.2.2.tar.gz", "has_sig": false, "md5_digest": "7aae2f542b882a4db5c23967e86d8380", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14137, "upload_time": "2016-06-21T18:51:08", "upload_time_iso_8601": "2016-06-21T18:51:08.470149Z", "url": "https://files.pythonhosted.org/packages/a2/e2/92f2d53ca66ce782ca41e4b54b142b0a92d70bd02ef78c98eaf7b1b02659/tfdeploy-0.2.2.tar.gz", "yanked": false}], "0.2.3": [{"comment_text": "", "digests": {"md5": "5932082224002d7450dd58af7cec5c1d", "sha256": "ef310c04a22b344c9bfb8b16a791573550da55dd03ff8242b4b981bd4c665eb9"}, "downloads": -1, "filename": "tfdeploy-0.2.3.tar.gz", "has_sig": false, "md5_digest": "5932082224002d7450dd58af7cec5c1d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15834, "upload_time": "2016-06-25T11:47:54", "upload_time_iso_8601": "2016-06-25T11:47:54.347828Z", "url": "https://files.pythonhosted.org/packages/08/73/3aa8d939457cc169f91a76cb805a0b3f97c9bdea62d2874b4c2bb90459b8/tfdeploy-0.2.3.tar.gz", "yanked": false}], "0.2.4": [{"comment_text": "", "digests": {"md5": "1e53734e23d43638ad7212a0d81c0ef4", "sha256": "39b6abf35450d6988174759873ce7ec284616193b683f7e9593e6d0289b5a0a3"}, "downloads": -1, "filename": "tfdeploy-0.2.4.tar.gz", "has_sig": false, "md5_digest": "1e53734e23d43638ad7212a0d81c0ef4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15825, "upload_time": "2016-06-28T10:57:37", "upload_time_iso_8601": "2016-06-28T10:57:37.477998Z", "url": "https://files.pythonhosted.org/packages/1b/13/d22dd43661f6e4866a80f628f7a15a485269040fc67e9b995f99eb98d413/tfdeploy-0.2.4.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "7ca808da61ee8568a318df4ab01b5359", "sha256": "57d8a1ff90423e562a42476f92623e9345708426134c4c7f89d108afc7987aef"}, "downloads": -1, "filename": "tfdeploy-0.3.0.tar.gz", "has_sig": false, "md5_digest": "7ca808da61ee8568a318df4ab01b5359", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18665, "upload_time": "2016-12-13T00:06:23", "upload_time_iso_8601": "2016-12-13T00:06:23.187895Z", "url": "https://files.pythonhosted.org/packages/39/ae/cadbc1052cd6f4845428aa352f14d7817e4a1cbe1a838ee9afd9e405d827/tfdeploy-0.3.0.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "88eaea8cca3030fc880a03d1fe7175c5", "sha256": "fdae45782bec028c4f3d3aa0cbf14bd2121e0a99a3809d049ee97cb2429a5243"}, "downloads": -1, "filename": "tfdeploy-0.3.1.tar.gz", "has_sig": false, "md5_digest": "88eaea8cca3030fc880a03d1fe7175c5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18420, "upload_time": "2016-12-13T10:29:26", "upload_time_iso_8601": "2016-12-13T10:29:26.180095Z", "url": "https://files.pythonhosted.org/packages/11/c3/42fd0ff5053728d0d9bc212f1d1195d83d8be215816f4e8d5c54e579620b/tfdeploy-0.3.1.tar.gz", "yanked": false}], "0.3.2": [{"comment_text": "", "digests": {"md5": "b5627ce9b4434fc09754b47369240cf8", "sha256": "39ae1151c30d59a6e473b4c8c7b61e3792acb60534d6ba13bc429783c31c81c5"}, "downloads": -1, "filename": "tfdeploy-0.3.2.tar.gz", "has_sig": false, "md5_digest": "b5627ce9b4434fc09754b47369240cf8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18477, "upload_time": "2016-12-21T23:08:08", "upload_time_iso_8601": "2016-12-21T23:08:08.851103Z", "url": "https://files.pythonhosted.org/packages/a3/e8/bb3886e8a201441b995fb22335a249e5631f9be6121b3495eb6d7a272d42/tfdeploy-0.3.2.tar.gz", "yanked": false}], "0.3.3": [{"comment_text": "", "digests": {"md5": "2ff8d1842eab9cda396a3b73c34848c8", "sha256": "89111b4ac4b69e33e5e80fd523ae536683ca727360c364100846462404080e5e"}, "downloads": -1, "filename": "tfdeploy-0.3.3.tar.gz", "has_sig": false, "md5_digest": "2ff8d1842eab9cda396a3b73c34848c8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18527, "upload_time": "2016-12-23T10:44:44", "upload_time_iso_8601": "2016-12-23T10:44:44.166984Z", "url": "https://files.pythonhosted.org/packages/7c/69/cd878f0bb89ad8e53c197b365bca2bbaaaed2b342485321dd84f840b980a/tfdeploy-0.3.3.tar.gz", "yanked": false}], "0.4.0": [], "0.4.1": [{"comment_text": "", "digests": {"md5": "e2cfc3b6f7902926468d4e43b378aa12", "sha256": "844f64b2ab973897e42482d5dd088ce522855204d484d41ae8af4ddcef905936"}, "downloads": -1, "filename": "tfdeploy-0.4.1.tar.gz", "has_sig": false, "md5_digest": "e2cfc3b6f7902926468d4e43b378aa12", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18570, "upload_time": "2017-03-30T10:09:28", "upload_time_iso_8601": "2017-03-30T10:09:28.925538Z", "url": "https://files.pythonhosted.org/packages/47/e7/67898f334efd3af68eeecef0d408ddb1c46701e15c0b82c6a2a6de7d1e61/tfdeploy-0.4.1.tar.gz", "yanked": false}], "0.4.2": [{"comment_text": "", "digests": {"md5": "4c037673dd7884fb2187061dd7a121fa", "sha256": "96006dfb2d37f8b0f0450c40114883e20285ae5f270ae3e01a6da7953191a7fd"}, "downloads": -1, "filename": "tfdeploy-0.4.2.tar.gz", "has_sig": false, "md5_digest": "4c037673dd7884fb2187061dd7a121fa", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18526, "upload_time": "2017-03-30T10:51:26", "upload_time_iso_8601": "2017-03-30T10:51:26.623697Z", "url": "https://files.pythonhosted.org/packages/e0/f1/bb4f876c9fc083584e8b6dc512ffbb27420be5f207ca4f5545385d86e708/tfdeploy-0.4.2.tar.gz", "yanked": false}], "0.4.2rc1": [{"comment_text": "", "digests": {"md5": "6f190b7dd18c0300f261b5c6a20df650", "sha256": "726acca941d1b92a663191118706b9bfa8e848f11ff90c8466400993036663e5"}, "downloads": -1, "filename": "tfdeploy-0.4.2rc1.tar.gz", "has_sig": false, "md5_digest": "6f190b7dd18c0300f261b5c6a20df650", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14249, "upload_time": "2017-03-30T10:10:18", "upload_time_iso_8601": "2017-03-30T10:10:18.928489Z", "url": "https://files.pythonhosted.org/packages/93/d1/43c4d33408e0efaf22bdbb3b79e3f53b281318300ac86fa1a94a95ff2816/tfdeploy-0.4.2rc1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "4c037673dd7884fb2187061dd7a121fa", "sha256": "96006dfb2d37f8b0f0450c40114883e20285ae5f270ae3e01a6da7953191a7fd"}, "downloads": -1, "filename": "tfdeploy-0.4.2.tar.gz", "has_sig": false, "md5_digest": "4c037673dd7884fb2187061dd7a121fa", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18526, "upload_time": "2017-03-30T10:51:26", "upload_time_iso_8601": "2017-03-30T10:51:26.623697Z", "url": "https://files.pythonhosted.org/packages/e0/f1/bb4f876c9fc083584e8b6dc512ffbb27420be5f207ca4f5545385d86e708/tfdeploy-0.4.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:54:40 2020"}