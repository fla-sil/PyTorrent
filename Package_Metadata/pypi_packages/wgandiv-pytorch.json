{"info": {"author": "Liu Changyu", "author_email": "liuchangyu1111@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: Apache Software License", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.7"], "description": "\n# WassersteinGAN_DIV-PyTorch\n\n### Update (Feb 22, 2020)\n\nThe mnist and fmnist models are now available. Their usage is identical to the other models: \n```python\nfrom wgandiv_pytorch import Generator\nmodel = Generator.from_pretrained('g-mnist') \n```\n\n### Overview\nThis repository contains an op-for-op PyTorch reimplementation of [Wasserstein Divergence for GANs](http://xxx.itp.ac.cn/pdf/1712.01026).\n\nThe goal of this implementation is to be simple, highly extensible, and easy to integrate into your own projects. This implementation is a work in progress -- new features are currently being implemented.  \n\nAt the moment, you can easily:  \n * Load pretrained Generate models \n * Use Generate models for extended dataset\n\n_Upcoming features_: In the next few days, you will be able to:\n * Quickly finetune an Generate on your own dataset\n * Export Generate models for production\n\n### Table of contents\n1. [About Wasserstein GAN DIV](#about-wasserstein-gan-div)\n2. [Model Description](#model-description)\n3. [Installation](#installation)\n4. [Usage](#usage)\n    * [Load pretrained models](#loading-pretrained-models)\n    * [Example: Extended dataset](#example-extended-dataset)\n    * [Example: Visual](#example-visual)\n5. [Contributing](#contributing) \n\n### About Wasserstein GAN DIV\n\nIf you're new to Wasserstein GAN DIV, here's an abstract straight from the paper:\n\nIn many domains of computer vision, generative adversarial networks (GANs) have achieved great success, among which the fam- ily of Wasserstein GANs (WGANs) is considered to be state-of-the-art due to the theoretical contributions and competitive qualitative performance. However, it is very challenging to approximate the k-Lipschitz constraint required by the Wasserstein-1 metric (W-met). In this paper, we propose a novel Wasserstein divergence (W-div), which is a relaxed version of W-met and does not require the k-Lipschitz constraint.As a concrete application, we introduce a Wasserstein divergence objective for GANs (WGAN-div), which can faithfully approximate W-div through optimization. Under various settings, including progressive growing training, we demonstrate the stability of the proposed WGAN-div owing to its theoretical and practical advantages over WGANs. Also, we study the quantitative and visual performance of WGAN-div on standard image synthesis benchmarks, showing the superior performance of WGAN-div compared to the state-of-the-art methods.\n### Model Description\n\nWe have two networks, G (Generator) and D (Discriminator).The Generator is a network for generating images. It receives a random noise z and generates images from this noise, which is called G(z).Discriminator is a discriminant network that discriminates whether an image is real. The input is x, x is a picture, and the output is D of x is the probability that x is a real picture, and if it's 1, it's 100% real, and if it's 0, it's not real.\n\n### Installation\n\nInstall from pypi:\n```bash\npip install wgandiv_pytorch\n```\n\nInstall from source:\n```bash\ngit clone https://github.com/Lornatang/WassersteinGAN_DIV-PyTorch.git\ncd WassersteinGAN_DIV-PyTorch\npip install -e .\n``` \n\n### Usage\n\n#### Loading pretrained models\n\nLoad an Wasserstein GAN DIV:\n```python\nfrom wgandiv_pytorch import Generator\nmodel = Generator.from_name(\"g-mnist\")\n```\n\nLoad a pretrained Wasserstein GAN DIV:\n```python\nfrom wgandiv_pytorch import Generator\nmodel = Generator.from_pretrained(\"g-mnist\")\n```\n\n#### Example: Extended dataset\n\nAs mentioned in the example, if you load the pre-trained weights of the MNIST dataset, it will create a new `imgs` directory and generate 64 random images in the `imgs` directory.\n\n```python\nimport os\nimport torch\nimport torchvision.utils as vutils\nfrom wgandiv_pytorch import Generator\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = Generator.from_pretrained(\"g-mnist\")\nmodel.to(device)\n# switch to evaluate mode\nmodel.eval()\n\ntry:\n    os.makedirs(\"./imgs\")\nexcept OSError:\n    pass\n\nwith torch.no_grad():\n    for i in range(64):\n        noise = torch.randn(64, 100, device=device)\n        fake = model(noise)\n        vutils.save_image(fake.detach(), f\"./imgs/fake_{i:04d}.png\", normalize=True)\n    print(\"The fake image has been generated!\")\n```\n\n#### Example: Visual\n\n```text\ncd $REPO$/framework\nsh start.sh\n```\n\nThen open the browser and type in the browser address [http://127.0.0.1:10004/](http://127.0.0.1:10004/).\nEnjoy it.\n\n### Contributing\n\nIf you find a bug, create a GitHub issue, or even better, submit a pull request. Similarly, if you have questions, simply post them as GitHub issues.   \n\nI look forward to seeing what the community does with these models! \n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Lornatang/WassersteinGAN_DIV-PyTorch", "keywords": "", "license": "Apache", "maintainer": "", "maintainer_email": "", "name": "wgandiv-pytorch", "package_url": "https://pypi.org/project/wgandiv-pytorch/", "platform": "", "project_url": "https://pypi.org/project/wgandiv-pytorch/", "project_urls": {"Homepage": "https://github.com/Lornatang/WassersteinGAN_DIV-PyTorch"}, "release_url": "https://pypi.org/project/wgandiv-pytorch/0.1.2/", "requires_dist": ["torch"], "requires_python": ">=3.5.0", "summary": "In many domains of computer vision, generative adversarial networks (GANs) have achieved great success, among which the fam- ily of Wasserstein GANs (WGANs) is considered to be state-of-the-art due to the theoretical contributions and competitive qualitative performance", "version": "0.1.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>WassersteinGAN_DIV-PyTorch</h1>\n<h3>Update (Feb 22, 2020)</h3>\n<p>The mnist and fmnist models are now available. Their usage is identical to the other models:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">wgandiv_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">Generator</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Generator</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span><span class=\"s1\">'g-mnist'</span><span class=\"p\">)</span> \n</pre>\n<h3>Overview</h3>\n<p>This repository contains an op-for-op PyTorch reimplementation of <a href=\"http://xxx.itp.ac.cn/pdf/1712.01026\" rel=\"nofollow\">Wasserstein Divergence for GANs</a>.</p>\n<p>The goal of this implementation is to be simple, highly extensible, and easy to integrate into your own projects. This implementation is a work in progress -- new features are currently being implemented.</p>\n<p>At the moment, you can easily:</p>\n<ul>\n<li>Load pretrained Generate models</li>\n<li>Use Generate models for extended dataset</li>\n</ul>\n<p><em>Upcoming features</em>: In the next few days, you will be able to:</p>\n<ul>\n<li>Quickly finetune an Generate on your own dataset</li>\n<li>Export Generate models for production</li>\n</ul>\n<h3>Table of contents</h3>\n<ol>\n<li><a href=\"#about-wasserstein-gan-div\" rel=\"nofollow\">About Wasserstein GAN DIV</a></li>\n<li><a href=\"#model-description\" rel=\"nofollow\">Model Description</a></li>\n<li><a href=\"#installation\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#usage\" rel=\"nofollow\">Usage</a>\n<ul>\n<li><a href=\"#loading-pretrained-models\" rel=\"nofollow\">Load pretrained models</a></li>\n<li><a href=\"#example-extended-dataset\" rel=\"nofollow\">Example: Extended dataset</a></li>\n<li><a href=\"#example-visual\" rel=\"nofollow\">Example: Visual</a></li>\n</ul>\n</li>\n<li><a href=\"#contributing\" rel=\"nofollow\">Contributing</a></li>\n</ol>\n<h3>About Wasserstein GAN DIV</h3>\n<p>If you're new to Wasserstein GAN DIV, here's an abstract straight from the paper:</p>\n<p>In many domains of computer vision, generative adversarial networks (GANs) have achieved great success, among which the fam- ily of Wasserstein GANs (WGANs) is considered to be state-of-the-art due to the theoretical contributions and competitive qualitative performance. However, it is very challenging to approximate the k-Lipschitz constraint required by the Wasserstein-1 metric (W-met). In this paper, we propose a novel Wasserstein divergence (W-div), which is a relaxed version of W-met and does not require the k-Lipschitz constraint.As a concrete application, we introduce a Wasserstein divergence objective for GANs (WGAN-div), which can faithfully approximate W-div through optimization. Under various settings, including progressive growing training, we demonstrate the stability of the proposed WGAN-div owing to its theoretical and practical advantages over WGANs. Also, we study the quantitative and visual performance of WGAN-div on standard image synthesis benchmarks, showing the superior performance of WGAN-div compared to the state-of-the-art methods.</p>\n<h3>Model Description</h3>\n<p>We have two networks, G (Generator) and D (Discriminator).The Generator is a network for generating images. It receives a random noise z and generates images from this noise, which is called G(z).Discriminator is a discriminant network that discriminates whether an image is real. The input is x, x is a picture, and the output is D of x is the probability that x is a real picture, and if it's 1, it's 100% real, and if it's 0, it's not real.</p>\n<h3>Installation</h3>\n<p>Install from pypi:</p>\n<pre>pip install wgandiv_pytorch\n</pre>\n<p>Install from source:</p>\n<pre>git clone https://github.com/Lornatang/WassersteinGAN_DIV-PyTorch.git\n<span class=\"nb\">cd</span> WassersteinGAN_DIV-PyTorch\npip install -e .\n</pre>\n<h3>Usage</h3>\n<h4>Loading pretrained models</h4>\n<p>Load an Wasserstein GAN DIV:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">wgandiv_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">Generator</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Generator</span><span class=\"o\">.</span><span class=\"n\">from_name</span><span class=\"p\">(</span><span class=\"s2\">\"g-mnist\"</span><span class=\"p\">)</span>\n</pre>\n<p>Load a pretrained Wasserstein GAN DIV:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">wgandiv_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">Generator</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Generator</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span><span class=\"s2\">\"g-mnist\"</span><span class=\"p\">)</span>\n</pre>\n<h4>Example: Extended dataset</h4>\n<p>As mentioned in the example, if you load the pre-trained weights of the MNIST dataset, it will create a new <code>imgs</code> directory and generate 64 random images in the <code>imgs</code> directory.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">os</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torchvision.utils</span> <span class=\"k\">as</span> <span class=\"nn\">vutils</span>\n<span class=\"kn\">from</span> <span class=\"nn\">wgandiv_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">Generator</span>\n\n<span class=\"n\">device</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">(</span><span class=\"s2\">\"cuda:0\"</span> <span class=\"k\">if</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"o\">.</span><span class=\"n\">is_available</span><span class=\"p\">()</span> <span class=\"k\">else</span> <span class=\"s2\">\"cpu\"</span><span class=\"p\">)</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Generator</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span><span class=\"s2\">\"g-mnist\"</span><span class=\"p\">)</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">)</span>\n<span class=\"c1\"># switch to evaluate mode</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">eval</span><span class=\"p\">()</span>\n\n<span class=\"k\">try</span><span class=\"p\">:</span>\n    <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">makedirs</span><span class=\"p\">(</span><span class=\"s2\">\"./imgs\"</span><span class=\"p\">)</span>\n<span class=\"k\">except</span> <span class=\"ne\">OSError</span><span class=\"p\">:</span>\n    <span class=\"k\">pass</span>\n\n<span class=\"k\">with</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">no_grad</span><span class=\"p\">():</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">):</span>\n        <span class=\"n\">noise</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"n\">device</span><span class=\"p\">)</span>\n        <span class=\"n\">fake</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">noise</span><span class=\"p\">)</span>\n        <span class=\"n\">vutils</span><span class=\"o\">.</span><span class=\"n\">save_image</span><span class=\"p\">(</span><span class=\"n\">fake</span><span class=\"o\">.</span><span class=\"n\">detach</span><span class=\"p\">(),</span> <span class=\"sa\">f</span><span class=\"s2\">\"./imgs/fake_</span><span class=\"si\">{</span><span class=\"n\">i</span><span class=\"si\">:</span><span class=\"s2\">04d</span><span class=\"si\">}</span><span class=\"s2\">.png\"</span><span class=\"p\">,</span> <span class=\"n\">normalize</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"The fake image has been generated!\"</span><span class=\"p\">)</span>\n</pre>\n<h4>Example: Visual</h4>\n<pre>cd $REPO$/framework\nsh start.sh\n</pre>\n<p>Then open the browser and type in the browser address <a href=\"http://127.0.0.1:10004/\" rel=\"nofollow\">http://127.0.0.1:10004/</a>.\nEnjoy it.</p>\n<h3>Contributing</h3>\n<p>If you find a bug, create a GitHub issue, or even better, submit a pull request. Similarly, if you have questions, simply post them as GitHub issues.</p>\n<p>I look forward to seeing what the community does with these models!</p>\n\n          </div>"}, "last_serial": 6679518, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "82f8bc4828155848d0552b2964602546", "sha256": "910250041458cb87f298501dd17e29e2d32a089823380a4b9d5e7630f2fa1dad"}, "downloads": -1, "filename": "wgandiv_pytorch-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "82f8bc4828155848d0552b2964602546", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.5.0", "size": 11326, "upload_time": "2020-02-22T02:46:59", "upload_time_iso_8601": "2020-02-22T02:46:59.981901Z", "url": "https://files.pythonhosted.org/packages/2b/a5/6c24442a45e3e259587ffc1e76bb74e556a26473e770f644ebcb8f2e2572/wgandiv_pytorch-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8896dfc35b5e08fa9f6034c4e008e8f2", "sha256": "6d08f3f6d57ddffab3f168ce4ca592a615ddfcd4cb44c7ecfbc2d9cfdf81c9da"}, "downloads": -1, "filename": "wgandiv_pytorch-0.1.0.tar.gz", "has_sig": false, "md5_digest": "8896dfc35b5e08fa9f6034c4e008e8f2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 7042, "upload_time": "2020-02-22T02:47:02", "upload_time_iso_8601": "2020-02-22T02:47:02.872671Z", "url": "https://files.pythonhosted.org/packages/17/d1/31adc6541c981727a1c5e383084a10c163ac6cfb921e469b988adf6e946a/wgandiv_pytorch-0.1.0.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "876e797344b3fd9b2d937f7077c14592", "sha256": "e6d57f650e7cd2e29e59e30f8b2bb47782a6c0f82bbd4c509089bbe7d26af2cd"}, "downloads": -1, "filename": "wgandiv_pytorch-0.1.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "876e797344b3fd9b2d937f7077c14592", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.5.0", "size": 11649, "upload_time": "2020-02-22T04:57:31", "upload_time_iso_8601": "2020-02-22T04:57:31.424581Z", "url": "https://files.pythonhosted.org/packages/ca/5f/10bcb5ba6fcc79750cf8bf087f61593a6a68f1f5a20373de72a0f84e81e4/wgandiv_pytorch-0.1.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "331c11788ccac55a2618a2fa94180e93", "sha256": "6926f4a076df08bee0c6f7b71058eb8c46d195bae7a0a84f35e5bba48698a17e"}, "downloads": -1, "filename": "wgandiv_pytorch-0.1.2.tar.gz", "has_sig": false, "md5_digest": "331c11788ccac55a2618a2fa94180e93", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 7835, "upload_time": "2020-02-22T04:57:33", "upload_time_iso_8601": "2020-02-22T04:57:33.356024Z", "url": "https://files.pythonhosted.org/packages/b6/06/04b86bb9d165fda07bb6aabade58eaf2d841d3b5f74f03fc11c191d2894b/wgandiv_pytorch-0.1.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "876e797344b3fd9b2d937f7077c14592", "sha256": "e6d57f650e7cd2e29e59e30f8b2bb47782a6c0f82bbd4c509089bbe7d26af2cd"}, "downloads": -1, "filename": "wgandiv_pytorch-0.1.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "876e797344b3fd9b2d937f7077c14592", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.5.0", "size": 11649, "upload_time": "2020-02-22T04:57:31", "upload_time_iso_8601": "2020-02-22T04:57:31.424581Z", "url": "https://files.pythonhosted.org/packages/ca/5f/10bcb5ba6fcc79750cf8bf087f61593a6a68f1f5a20373de72a0f84e81e4/wgandiv_pytorch-0.1.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "331c11788ccac55a2618a2fa94180e93", "sha256": "6926f4a076df08bee0c6f7b71058eb8c46d195bae7a0a84f35e5bba48698a17e"}, "downloads": -1, "filename": "wgandiv_pytorch-0.1.2.tar.gz", "has_sig": false, "md5_digest": "331c11788ccac55a2618a2fa94180e93", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 7835, "upload_time": "2020-02-22T04:57:33", "upload_time_iso_8601": "2020-02-22T04:57:33.356024Z", "url": "https://files.pythonhosted.org/packages/b6/06/04b86bb9d165fda07bb6aabade58eaf2d841d3b5f74f03fc11c191d2894b/wgandiv_pytorch-0.1.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:30:04 2020"}