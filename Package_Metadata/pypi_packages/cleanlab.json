{"info": {"author": "Curtis G. Northcutt", "author_email": "cgn@mit.edu", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Operating System :: MacOS", "Operating System :: Microsoft :: Windows", "Operating System :: POSIX", "Operating System :: Unix", "Programming Language :: Python", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Scientific/Engineering", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Scientific/Engineering :: Mathematics", "Topic :: Software Development", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules"], "description": ".. figure:: https://raw.githubusercontent.com/cgnorthcutt/cleanlab/master/img/cleanlab_logo.png\n   :target: https://github.com/cgnorthcutt/cleanlab/\n   :align: center\n   :alt: cleanlab \n\n|  \n\n``cleanlab`` is a machine learning python package for **learning with noisy labels** and **finding label errors in datasets**. ``cleanlab`` CLEANs LABels. It is powered by the theory of **confident learning**, published in  `this paper <https://arxiv.org/abs/1911.00068>`__ and explained in  `this blog <https://l7.curtisnorthcutt.com/confident-learning>`__. Using the `confidentlearning-reproduce <https://github.com/cgnorthcutt/confidentlearning-reproduce>`__ repo, ``cleanlab`` v0.1.0 reproduces results in `the CL paper <https://arxiv.org/abs/1911.00068>`__.\n\n\n|pypi| |os| |py_versions| |build_status| |coverage|\n\n.. |pypi| image:: https://img.shields.io/pypi/v/cleanlab.svg\n    :target: https://pypi.org/pypi/cleanlab/\n.. |os| image:: https://img.shields.io/badge/platform-windows%20%7C%20macos%20%7C%20linux-lightgrey\n    :target: https://pypi.org/pypi/cleanlab/\n.. |py_versions| image:: https://img.shields.io/pypi/pyversions/cleanlab.svg\n    :target: https://pypi.org/pypi/cleanlab/\n.. |build_status| image:: https://travis-ci.com/cgnorthcutt/cleanlab.svg?branch=master\n    :target: https://travis-ci.com/cgnorthcutt/cleanlab\n.. |coverage| image:: https://codecov.io/gh/cgnorthcutt/cleanlab/branch/master/graph/badge.svg\n    :target: https://codecov.io/gh/cgnorthcutt/cleanlab\n\n``cleanlab`` **documentation** is available in `this blog post <https://l7.curtisnorthcutt.com/cleanlab-python-package>`__.\n\nPast release notes and **future features planned**  is available `here <https://l7.curtisnorthcutt.com/cleanlab-python-package>`__.\n\nSo fresh, so ``cleanlab`` \n=========================\n\n``cleanlab`` finds and cleans label errors in any dataset using `state-of-the-art algorithms <https://arxiv.org/abs/1911.00068>`__ to find label errors, characterize noise, and learn in spite of it. ``cleanlab`` is fast: its built on optimized algorithms and parallelized across CPU threads automatically. ``cleanlab`` is powered by `provable guarantees <https://arxiv.org/abs/1911.00068>`__ of exact noise estimation and label error finding in realistic cases when model output probabilities are erroneous. ``cleanlab`` supports multi-label, multiclass, sparse matrices, etc. By default, ``cleanlab`` requires no hyper-parameters.\n\n``cleanlab`` finds and cleans label errors in any dataset using state-of-the-art algorithms for learning with noisy labels by characterizing label noise. ``cleanlab`` is fast: its built on optimized algorithms and parallelized across CPU threads automatically. ``cleanlab`` implements the family of theory and algorithms called `confident learning <https://arxiv.org/abs/1911.00068>`__ with provable guarantees of exact noise estimation and label error finding (even when model output probabilities are noisy/imperfect). \n\n**How does confident learning work?** See:  `TUTORIAL: confident learning with just numpy and for-loops <https://github.com/cgnorthcutt/cleanlab/blob/master/examples/simplifying_confident_learning_tutorial.ipynb>`__.\n\n``cleanlab`` supports multi-label, multiclass, sparse matrices, and more. \n\n``cleanlab`` is:\n\n1. fast - Single-shot, non-iterative, parallelized algorithms (e.g. < 1 second to find label errors in ImageNet)\n2. robust - Provable generalization and risk minimimzation guarantees, including imperfect probability estimation.\n3. general - Works with any probablistic classifier: PyTorch, Tensorflow, MxNet, Caffe2, scikit-learn, etc.\n4. unique - The only package for multiclass learning with noisy labels or finding label errors for any dataset / classifier.\n\n\nFind label errors with PyTorch, Tensorflow, MXNet, etc. in 1 line of code.\n==========================================================================\n\n.. code:: python\n\n   # Compute psx (n x m matrix of predicted probabilities) on your own, with any classifier.\n   # Be sure you compute probs in a holdout/out-of-sample manner (e.g. cross-validation)\n   # Now getting label errors is trivial with cleanlab... its one line of code.\n   # Label errors are ordered by likelihood of being an error. First index is most likely error.\n   from cleanlab.pruning import get_noise_indices\n\n   ordered_label_errors = get_noise_indices(\n       s=numpy_array_of_noisy_labels,\n       psx=numpy_array_of_predicted_probabilities,\n       sorted_index_method='normalized_margin', # Orders label errors\n    )\n\nPre-computed out-of-sample predicted probabilities for CIFAR-10 train set are available here: [`LINK <https://github.com/cgnorthcutt/confidentlearning-reproduce/blob/master/README.md#need-out-of-sample-predicted-probabilities-for-cifar-10-train-set>`__].\n\nLearning with noisy labels in 3 lines of code!\n==============================================\n\n.. code:: python\n\n   from cleanlab.classification import LearningWithNoisyLabels\n   from sklearn.linear_model import LogisticRegression\n\n   # Wrap around any classifier. Yup, you can use sklearn/pyTorch/Tensorflow/FastText/etc.\n   lnl = LearningWithNoisyLabels(clf=LogisticRegression()) \n   lnl.fit(X=X_train_data, s=train_noisy_labels) \n   # Estimate the predictions you would have gotten by training with *no* label errors.\n   predicted_test_labels = lnl.predict(X_test)\n\n\nCheck out these `examples <https://github.com/cgnorthcutt/cleanlab/tree/master/examples>`__ and `tests <https://github.com/cgnorthcutt/cleanlab/tree/master/tests>`__ (includes how to use pyTorch, FastText, etc.).\n\n\n\nInstallation\n============\n\nPython 2.7, 3.4, 3.5, and 3.6 are supported.\n\nStable release:\n\n.. code-block:: bash\n\n   $ pip install cleanlab\n\nDeveloper (unstable) release:\n\n.. code-block:: bash\n\n   $ pip install git+https://github.com/cgnorthcutt/cleanlab.git\n\nTo install the codebase (enabling you to make modifications):\n\n.. code-block:: bash\n\n   $ conda update pip # if you use conda\n   $ git clone https://github.com/cgnorthcutt/cleanlab.git\n   $ cd cleanlab\n   $ pip install -e .\n\n\nCitations and Related Publications\n==================================\n\nIf you use this package in your work, please cite the `confident learning paper <https://arxiv.org/abs/1911.00068>`__:\n\n::\n\n   @misc{northcutt2019confidentlearning,\n     title={Confident Learning: Estimating Uncertainty in Dataset Labels},\n     author={Curtis G. Northcutt and Lu Jiang and Isaac L. Chuang},\n     year={2019},\n     eprint={1911.00068},\n     archivePrefix={arXiv},\n     primaryClass={stat.ML}\n }\n\nand the cleanlab code base here:\n\n::\n\n   @misc{northcutt2019cleanlab,\n     author = {Curtis Northcutt},\n     title = {Clean Lab},\n     year = {2019},\n     howpublished = {\\url{https://github.com/cgnorthcutt/cleanlab}},\n     note = {commit xxxxxxx, version xxxx}\n   }\n\nIf used for binary classification, cleanlab also implements `this paper <https://arxiv.org/abs/1705.01936>`__:\n\n::\n\n   @inproceedings{northcutt2017rankpruning,\n    author={Northcutt, Curtis G. and Wu, Tailin and Chuang, Isaac L.},\n    title={Learning with Confident Examples: Rank Pruning for Robust Classification with Noisy Labels},\n    booktitle = {Proceedings of the Thirty-Third Conference on Uncertainty in Artificial Intelligence},\n    series = {UAI'17},\n    year = {2017},\n    location = {Sydney, Australia},\n    numpages = {10},\n    url = {http://auai.org/uai2017/proceedings/papers/35.pdf},\n    publisher = {AUAI Press},\n   } \n\nReproducing Results in  `confident learning paper <https://arxiv.org/abs/1911.00068>`__ \n=======================================================================================\n\nSee `cleanlab/examples <https://github.com/cgnorthcutt/cleanlab/tree/master/examples>`__. You'll need to ``git clone`` `confidentlearning-reproduce <https://github.com/cgnorthcutt/confidentlearning-reproduce>`__  which contains the data and files needed to reproduce the CIFAR-10 results.\n\n\n``cleanlab``: Find Label Errors in ImageNet\n-------------------------------------------\n\nUse ``cleanlab`` to identify ~100,000 label errors in the 2012 ImageNet training dataset. \n\n.. figure:: https://raw.githubusercontent.com/cgnorthcutt/cleanlab/master/img/imagenet_train_label_errors_32.jpg\n   :align: center\n   :alt: Image depicting label errors in ImageNet train set \n\nTop label issues in the 2012 ILSVRC ImageNet train set identified using ``cleanlab``. Label Errors are boxed in red. Ontological issues in green. Multi-label images in blue.\n\n``cleanlab``: Find Label Errors in MNIST\n----------------------------------------\n\nUse ``cleanlab`` to identify ~50 label errors in the MNIST dataset. \n\n.. figure:: https://raw.githubusercontent.com/cgnorthcutt/cleanlab/master/img/mnist_training_label_errors24_prune_by_noise_rate.png\n   :align: center\n   :alt: Image depicting label errors in MNIST train set \n\nLabel errors of the original MNIST **train** dataset identified algorithmically using cleanlab. Depicts the 24 least confident labels, ordered left-right, top-down by increasing self-confidence (probability of belonging to the given label), denoted conf in teal. The label with the largest predicted probability is in green. Overt errors are in red.\n\n\n``cleanlab`` Generality: View performance across 4 distributions and 9 classifiers.\n-----------------------------------------------------------------------------------\n\nUse ``cleanlab`` to learn with noisy labels regardless of dataset distribution or classifier. \n\n.. figure:: https://raw.githubusercontent.com/cgnorthcutt/cleanlab/master/img/demo_cleanlab_across_datasets_and_classifiers.png\n   :align: center\n   :alt: Image depicting generality of cleanlab across datasets and classifiers \n\nEach sub-figure in the figure above depicts the decision boundary learned using ``cleanlab.classification.LearningWithNoisyLabels`` in the presence of extreme (\\~35%) label errors. Label errors are circled in green. Label noise is class-conditional (not simply uniformly random). Columns are organized by the classifier used, except the left-most column which depicts the ground-truth dataset distribution. Rows are organized by dataset used.\n\nThe code to reproduce this figure is available `here <https://github.com/cgnorthcutt/cleanlab/blob/master/examples/classifier_comparison.ipynb>`__.\n\nEach figure depicts accuracy scores on a test set as decimal values: \n\n1. LEFT (in black): The classifier test accuracy trained with perfect labels (no label errors). \n2. MIDDLE (in blue): The classifier test accuracy trained with noisy labels using ``cleanlab``. \n3. RIGHT (in white): The baseline classifier test accuracy trained with noisy labels.\n\nAs an example, this is the noise matrix (noisy channel) *P(s \\| y)* characterizing the label noise for the first dataset row in the figure. *s* represents the observed noisy labels and *y* represents the latent, true labels. The trace of this matrix is 2.6. A trace of 4 implies no label noise. A cell in this matrix is read like, \"A random 38% of '3' labels were flipped to '2' labels.\"\n\n======  ====  ====  ====  ==== \np(s|y)   y=0   y=1   y=2   y=3\n======  ====  ====  ====  ==== \ns=0     0.55  0.01  0.07  0.06\ns=1     0.22  0.87  0.24  0.02\ns=2     0.12  0.04  0.64  0.38\ns=3     0.11  0.08  0.05  0.54\n======  ====  ====  ====  ====\n\n\nGet started with easy, quick examples.\n======================================\n\nNew to **cleanlab**? Start with:\n\n1. `Visualizing confident\n   learning <https://github.com/cgnorthcutt/cleanlab/blob/master/examples/visualizing_confident_learning.ipynb>`__\n2. `A simple example of learning with noisy labels on the multiclass\n   Iris dataset <https://github.com/cgnorthcutt/cleanlab/blob/master/examples/iris_simple_example.ipynb>`__.\n\nThese examples show how easy it is to characterize label noise in\ndatasets, learn with noisy labels, identify label errors, estimate\nlatent priors and noisy channels, and more.\n\n.. ..\n\n   <!---\n\n\n\n   ![Image depicting label errors in MNIST test set.](https://raw.githubusercontent.com/cgnorthcutt/cleanlab/master/img/mnist_test_label_errors8.png)\n    Selected label errors in the MNIST **test** dataset ordered by increasing self-confidence (in teal).\n\n   ## Automatically identify ~5k (of 50k) validation set label errors in ImageNet. [[link]](examples/finding_ImageNet_label_errors).\n   ![Image depicting label errors in ImageNet validation set.](https://raw.githubusercontent.com/cgnorthcutt/cleanlab/master/img/imagenet_validation_label_errors_96_prune_by_noise_rate.jpg)\n   Label errors in the 2012 ImageNet validation dataset identified automatically with cleanlab using a pre-trained resnet18. Displayed are the 96 least confident labels. We see that ImageNet contains numerous multi-label images, although it is used widely by the machine learning and vision communities as a single-label benchmark dataset.\n\n   --->\n\nUse ``cleanlab`` with any model (Tensorflow, caffe2, PyTorch, etc.)\n-------------------------------------------------------------------\n\nAll of the features of the ``cleanlab`` package work with **any model**.\nYes, any model. Feel free to use PyTorch, Tensorflow, caffe2,\nscikit-learn, mxnet, etc. If you use a scikit-learn classifier, all\n``cleanlab`` methods will work out-of-the-box. It\u2019s also easy to use\nyour favorite model from a non-scikit-learn package, just wrap your\nmodel into a Python class that inherits the\n``sklearn.base.BaseEstimator``:\n\n.. code:: python\n\n   from sklearn.base import BaseEstimator\n   class YourFavoriteModel(BaseEstimator): # Inherits sklearn base classifier\n       def __init__(self, ):\n           pass\n       def fit(self, X, y, sample_weight=None):\n           pass\n       def predict(self, X):\n           pass\n       def predict_proba(self, X):\n           pass\n       def score(self, X, y, sample_weight=None):\n           pass\n\n   # Now you can use your model with `cleanlab`. Here's one example:\n   from cleanlab.classification import LearningWithNoisyLabels\n   lnl = LearningWithNoisyLabels(clf=YourFavoriteModel())\n   lnl.fit(train_data, train_labels_with_errors)\n\nWant to see a working example? `Here\u2019s a compliant PyTorch MNIST CNN class <https://github.com/cgnorthcutt/cleanlab/blob/master/cleanlab/models/mnist_pytorch.py#L28>`__\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nAs you can see\n`here <https://github.com/cgnorthcutt/cleanlab/blob/master/cleanlab/models/mnist_pytorch.py#L28>`__,\ntechnically you don\u2019t actually need to inherit from\n``sklearn.base.BaseEstimator``, as you can just create a class that\ndefines .fit(), .predict(), and .predict_proba(), but inheriting makes\ndownstream scikit-learn applications like hyper-parameter optimization\nwork seamlessly. For example, the `LearningWithNoisyLabels()\nmodel <https://github.com/cgnorthcutt/cleanlab/blob/master/cleanlab/classification.py#L48>`__\nis fully compliant.\n\nNote, some libraries exists to do this for you. For pyTorch, check out\nthe ``skorch`` Python library which will wrap your ``pytorch`` model\ninto a ``scikit-learn`` compliant model.\n\n\nDocumentation by Example\n========================\n\n``cleanlab`` Core Package Components\n------------------------------------\n\n1. **cleanlab/classification.py** - The LearningWithNoisyLabels() class for learning with noisy labels.\n2. **cleanlab/latent_algebra.py** -\tEqualities when noise information is known.\n3. **cleanlab/latent_estimation.py** -\tEstimates and fully characterizes all variants of label noise.\n4. **cleanlab/noise_generation.py** - Generate mathematically valid synthetic noise matrices.\n5. **cleanlab/polyplex.py** -\tCharacterizes joint distribution of label noise EXACTLY from noisy channel.\n6. **cleanlab/pruning.py** - Finds the indices of the examples with label errors in a dataset.\n\nMany of these methods have default parameters that won\u2019t be covered\nhere. Check out the method docstrings for full documentation.\n\n\nEstimate the confident joint, the latent noisy channel matrix, *P(s \\| y)* and inverse, *P(y \\| s)*, the latent prior of the unobserved, actual true labels, *p(y)*, and the predicted probabilities.\n------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\n*s* denotes a random variable that represents the observed, noisy\nlabel and *y* denotes a random variable representing the hidden, actual\nlabels. Both *s* and *y* take any of the m classes as values. The\n``cleanlab`` package supports different levels of granularity for\ncomputation depending on the needs of the user. Because of this, we\nsupport multiple alternatives, all no more than a few lines, to estimate\nthese latent distribution arrays, enabling the user to reduce\ncomputation time by only computing what they need to compute, as seen in\nthe examples below.\n\nThroughout these examples, you\u2019ll see a variable called\n*confident_joint*. The confident joint is an m x m matrix (m is the\nnumber of classes) that counts, for every observed, noisy class, the\nnumber of examples that confidently belong to every latent, hidden\nclass. It counts the number of examples that we are confident are\nlabeled correctly or incorrectly for every pair of obseved and\nunobserved classes. The confident joint is an unnormalized estimate of\nthe complete-information latent joint distribution, *Ps,y*. Most of the\nmethods in the **cleanlab** package start by first estimating the\n*confident_joint*. You can learn more about this in the `confident learning paper <https://arxiv.org/abs/1911.00068>`__.\n\nOption 1: Compute the confident joint and predicted probs first. Stop if that\u2019s all you need.\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n.. code:: python\n\n   from cleanlab.latent_estimation import estimate_latent\n   from cleanlab.latent_estimation import estimate_confident_joint_and_cv_pred_proba\n\n   # Compute the confident joint and the n x m predicted probabilities matrix (psx),\n   # for n examples, m classes. Stop here if all you need is the confident joint.\n   confident_joint, psx = estimate_confident_joint_and_cv_pred_proba(\n       X=X_train, \n       s=train_labels_with_errors,\n       clf=logreg(), # default, you can use any classifier\n   )\n\n   # Estimate latent distributions: p(y) as est_py, P(s|y) as est_nm, and P(y|s) as est_inv\n   est_py, est_nm, est_inv = estimate_latent(confident_joint, s=train_labels_with_errors)\n\nOption 2: Estimate the latent distribution matrices in a single line of code.\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n.. code:: python\n\n   from cleanlab.latent_estimation import estimate_py_noise_matrices_and_cv_pred_proba\n   est_py, est_nm, est_inv, confident_joint, psx = estimate_py_noise_matrices_and_cv_pred_proba(\n       X=X_train,\n       s=train_labels_with_errors,\n   )\n\nOption 3: Skip computing the predicted probabilities if you already have them.\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n.. code:: python\n\n   # Already have psx? (n x m matrix of predicted probabilities)\n   # For example, you might get them from a pre-trained model (like resnet on ImageNet)\n   # With the cleanlab package, you estimate directly with psx.\n   from cleanlab.latent_estimation import estimate_py_and_noise_matrices_from_probabilities\n   est_py, est_nm, est_inv, confident_joint = estimate_py_and_noise_matrices_from_probabilities(\n       s=train_labels_with_errors, \n       psx=psx,\n   )\n\n\nCompletely characterize label noise in a dataset:\n-------------------------------------------------\n\nThe joint probability distribution of noisy and true labels, *P(s,y)*, completely characterizes label noise with a class-conditional *m x m* matrix. \n\n.. code:: python\n\n    from cleanlab.latent_estimation import estimate_joint\n    joint = compute_confident_joint(\n        s=noisy_labels,\n        psx=probabilities,\n        confident_joint=None,  # Provide if you have it already\n    )\n\n\nMethods to Standardize Research with Noisy Labels\n-------------------------------------------------\n\n``cleanlab`` supports a number of functions to generate noise for benchmarking and standardization in research. This next example shows how to generate valid, class-conditional, unformly random noisy channel matrices:\n\n.. code:: python\n\n    # Generate a valid (necessary conditions for learnability are met) noise matrix for any trace > 1\n    from cleanlab.noise_generation import generate_noise_matrix_from_trace\n    noise_matrix=generate_noise_matrix_from_trace(\n        K=number_of_classes, \n        trace=float_value_greater_than_1_and_leq_K,\n        py=prior_of_y_actual_labels_which_is_just_an_array_of_length_K,\n        frac_zero_noise_rates=float_from_0_to_1_controlling_sparsity,\n    )\n\n    # Check if a noise matrix is valid (necessary conditions for learnability are met)\n    from cleanlab.noise_generation import noise_matrix_is_valid\n    is_valid=noise_matrix_is_valid(noise_matrix, prior_of_y_which_is_just_an_array_of_length_K)\n\nFor a given noise matrix, this example shows how to generate noisy labels. Methods can be seeded for reproducibility.\n\n.. code:: python\n\n    # Generate noisy labels using the noise_marix. Guarantees exact amount of noise in labels.\n    from cleanlab.noise_generation import generate_noisy_labels\n    s_noisy_labels = generate_noisy_labels(y_hidden_actual_labels, noise_matrix)\n\n    # This package is a full of other useful methods for learning with noisy labels.\n    # The tutorial stops here, but you don't have to. Inspect method docstrings for full docs.\n\n\nThe Polyplex\n------------\n\nThe key to learning in the presence of label errors is estimating the joint distribution between the actual, hidden labels \u2018*y*\u2019 and the observed, noisy labels \u2018*s*\u2019. Using ``cleanlab`` and the theory of confident learning, we can completely characterize the trace of the latent joint distribution, *trace(P(s,y))*, given *p(y)*, for any fraction of label errors, i.e.\u00a0for any trace of the noisy channel, *trace(P(s|y))*.\n\nYou can check out how to do this yourself here: 1. `Drawing\nPolyplices <https://github.com/cgnorthcutt/cleanlab/blob/master/examples/drawing_polyplices.ipynb>`__ 2. `Computing\nPolyplices <https://github.com/cgnorthcutt/cleanlab/blob/master/cleanlab/polyplex.py>`__\n\nLicense\n-------\n\nCopyright (c) 2017-2019 Curtis Northcutt. Released under the MIT License. See `LICENSE <https://github.com/cgnorthcutt/cleanlab/blob/master/LICENSE>`__ for details.\n\n\n", "description_content_type": "text/x-rst", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/cgnorthcutt/cleanlab", "keywords": "machine_learning denoising classification weak_supervision learning_with_noisy_labels unsupervised_learning", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "cleanlab", "package_url": "https://pypi.org/project/cleanlab/", "platform": "", "project_url": "https://pypi.org/project/cleanlab/", "project_urls": {"Homepage": "https://github.com/cgnorthcutt/cleanlab"}, "release_url": "https://pypi.org/project/cleanlab/0.1.1/", "requires_dist": ["numpy (>=1.11.3)", "scikit-learn (>=0.18)", "scipy (>=1.1.0)"], "requires_python": "", "summary": "Find label errors in datasets, weak supervision, and learning with noisy labels. Works for all datasets and models.", "version": "0.1.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div>\n<a href=\"https://github.com/cgnorthcutt/cleanlab/\" rel=\"nofollow\"><img alt=\"cleanlab\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c95ef2bc91b60e2e30f79b259294610bfa3f26a2/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f63676e6f727468637574742f636c65616e6c61622f6d61737465722f696d672f636c65616e6c61625f6c6f676f2e706e67\"></a>\n</div>\n<div>\n<div><br></div>\n</div>\n<p><tt>cleanlab</tt> is a machine learning python package for <strong>learning with noisy labels</strong> and <strong>finding label errors in datasets</strong>. <tt>cleanlab</tt> CLEANs LABels. It is powered by the theory of <strong>confident learning</strong>, published in  <a href=\"https://arxiv.org/abs/1911.00068\" rel=\"nofollow\">this paper</a> and explained in  <a href=\"https://l7.curtisnorthcutt.com/confident-learning\" rel=\"nofollow\">this blog</a>. Using the <a href=\"https://github.com/cgnorthcutt/confidentlearning-reproduce\" rel=\"nofollow\">confidentlearning-reproduce</a> repo, <tt>cleanlab</tt> v0.1.0 reproduces results in <a href=\"https://arxiv.org/abs/1911.00068\" rel=\"nofollow\">the CL paper</a>.</p>\n<p><a href=\"https://pypi.org/pypi/cleanlab/\" rel=\"nofollow\"><img alt=\"pypi\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ebc110476783199cbdef259335734624e3f49ca5/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f636c65616e6c61622e737667\"></a> <a href=\"https://pypi.org/pypi/cleanlab/\" rel=\"nofollow\"><img alt=\"os\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/14bd4b83ae79679e32c5b49bbb913bab2d4d0f62/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d2d77696e646f77732532302537432532306d61636f732532302537432532306c696e75782d6c6967687467726579\"></a> <a href=\"https://pypi.org/pypi/cleanlab/\" rel=\"nofollow\"><img alt=\"py_versions\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/51e31ecf2cb9c1e1643d15c91553ea4e4dd2add8/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f636c65616e6c61622e737667\"></a> <a href=\"https://travis-ci.com/cgnorthcutt/cleanlab\" rel=\"nofollow\"><img alt=\"build_status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/64d538cbeaff9ee76f19ecd4a07c5628add3887f/68747470733a2f2f7472617669732d63692e636f6d2f63676e6f727468637574742f636c65616e6c61622e7376673f6272616e63683d6d6173746572\"></a> <a href=\"https://codecov.io/gh/cgnorthcutt/cleanlab\" rel=\"nofollow\"><img alt=\"coverage\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/36665f0af59e3389c115c45b856773c3ca8ef7ea/68747470733a2f2f636f6465636f762e696f2f67682f63676e6f727468637574742f636c65616e6c61622f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a></p>\n<p><tt>cleanlab</tt> <strong>documentation</strong> is available in <a href=\"https://l7.curtisnorthcutt.com/cleanlab-python-package\" rel=\"nofollow\">this blog post</a>.</p>\n<p>Past release notes and <strong>future features planned</strong>  is available <a href=\"https://l7.curtisnorthcutt.com/cleanlab-python-package\" rel=\"nofollow\">here</a>.</p>\n<div id=\"so-fresh-so-cleanlab\">\n<h2>So fresh, so <tt>cleanlab</tt></h2>\n<p><tt>cleanlab</tt> finds and cleans label errors in any dataset using <a href=\"https://arxiv.org/abs/1911.00068\" rel=\"nofollow\">state-of-the-art algorithms</a> to find label errors, characterize noise, and learn in spite of it. <tt>cleanlab</tt> is fast: its built on optimized algorithms and parallelized across CPU threads automatically. <tt>cleanlab</tt> is powered by <a href=\"https://arxiv.org/abs/1911.00068\" rel=\"nofollow\">provable guarantees</a> of exact noise estimation and label error finding in realistic cases when model output probabilities are erroneous. <tt>cleanlab</tt> supports multi-label, multiclass, sparse matrices, etc. By default, <tt>cleanlab</tt> requires no hyper-parameters.</p>\n<p><tt>cleanlab</tt> finds and cleans label errors in any dataset using state-of-the-art algorithms for learning with noisy labels by characterizing label noise. <tt>cleanlab</tt> is fast: its built on optimized algorithms and parallelized across CPU threads automatically. <tt>cleanlab</tt> implements the family of theory and algorithms called <a href=\"https://arxiv.org/abs/1911.00068\" rel=\"nofollow\">confident learning</a> with provable guarantees of exact noise estimation and label error finding (even when model output probabilities are noisy/imperfect).</p>\n<p><strong>How does confident learning work?</strong> See:  <a href=\"https://github.com/cgnorthcutt/cleanlab/blob/master/examples/simplifying_confident_learning_tutorial.ipynb\" rel=\"nofollow\">TUTORIAL: confident learning with just numpy and for-loops</a>.</p>\n<p><tt>cleanlab</tt> supports multi-label, multiclass, sparse matrices, and more.</p>\n<p><tt>cleanlab</tt> is:</p>\n<ol>\n<li>fast - Single-shot, non-iterative, parallelized algorithms (e.g. &lt; 1 second to find label errors in ImageNet)</li>\n<li>robust - Provable generalization and risk minimimzation guarantees, including imperfect probability estimation.</li>\n<li>general - Works with any probablistic classifier: PyTorch, Tensorflow, MxNet, Caffe2, scikit-learn, etc.</li>\n<li>unique - The only package for multiclass learning with noisy labels or finding label errors for any dataset / classifier.</li>\n</ol>\n</div>\n<div id=\"find-label-errors-with-pytorch-tensorflow-mxnet-etc-in-1-line-of-code\">\n<h2>Find label errors with PyTorch, Tensorflow, MXNet, etc. in 1 line of code.</h2>\n<pre><span class=\"c1\"># Compute psx (n x m matrix of predicted probabilities) on your own, with any classifier.</span>\n<span class=\"c1\"># Be sure you compute probs in a holdout/out-of-sample manner (e.g. cross-validation)</span>\n<span class=\"c1\"># Now getting label errors is trivial with cleanlab... its one line of code.</span>\n<span class=\"c1\"># Label errors are ordered by likelihood of being an error. First index is most likely error.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">cleanlab.pruning</span> <span class=\"kn\">import</span> <span class=\"n\">get_noise_indices</span>\n\n<span class=\"n\">ordered_label_errors</span> <span class=\"o\">=</span> <span class=\"n\">get_noise_indices</span><span class=\"p\">(</span>\n    <span class=\"n\">s</span><span class=\"o\">=</span><span class=\"n\">numpy_array_of_noisy_labels</span><span class=\"p\">,</span>\n    <span class=\"n\">psx</span><span class=\"o\">=</span><span class=\"n\">numpy_array_of_predicted_probabilities</span><span class=\"p\">,</span>\n    <span class=\"n\">sorted_index_method</span><span class=\"o\">=</span><span class=\"s1\">'normalized_margin'</span><span class=\"p\">,</span> <span class=\"c1\"># Orders label errors</span>\n <span class=\"p\">)</span>\n</pre>\n<p>Pre-computed out-of-sample predicted probabilities for CIFAR-10 train set are available here: [<a href=\"https://github.com/cgnorthcutt/confidentlearning-reproduce/blob/master/README.md#need-out-of-sample-predicted-probabilities-for-cifar-10-train-set\" rel=\"nofollow\">LINK</a>].</p>\n</div>\n<div id=\"learning-with-noisy-labels-in-3-lines-of-code\">\n<h2>Learning with noisy labels in 3 lines of code!</h2>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">cleanlab.classification</span> <span class=\"kn\">import</span> <span class=\"n\">LearningWithNoisyLabels</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.linear_model</span> <span class=\"kn\">import</span> <span class=\"n\">LogisticRegression</span>\n\n<span class=\"c1\"># Wrap around any classifier. Yup, you can use sklearn/pyTorch/Tensorflow/FastText/etc.</span>\n<span class=\"n\">lnl</span> <span class=\"o\">=</span> <span class=\"n\">LearningWithNoisyLabels</span><span class=\"p\">(</span><span class=\"n\">clf</span><span class=\"o\">=</span><span class=\"n\">LogisticRegression</span><span class=\"p\">())</span>\n<span class=\"n\">lnl</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"o\">=</span><span class=\"n\">X_train_data</span><span class=\"p\">,</span> <span class=\"n\">s</span><span class=\"o\">=</span><span class=\"n\">train_noisy_labels</span><span class=\"p\">)</span>\n<span class=\"c1\"># Estimate the predictions you would have gotten by training with *no* label errors.</span>\n<span class=\"n\">predicted_test_labels</span> <span class=\"o\">=</span> <span class=\"n\">lnl</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"p\">)</span>\n</pre>\n<p>Check out these <a href=\"https://github.com/cgnorthcutt/cleanlab/tree/master/examples\" rel=\"nofollow\">examples</a> and <a href=\"https://github.com/cgnorthcutt/cleanlab/tree/master/tests\" rel=\"nofollow\">tests</a> (includes how to use pyTorch, FastText, etc.).</p>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>Python 2.7, 3.4, 3.5, and 3.6 are supported.</p>\n<p>Stable release:</p>\n<pre>$ pip install cleanlab\n</pre>\n<p>Developer (unstable) release:</p>\n<pre>$ pip install git+https://github.com/cgnorthcutt/cleanlab.git\n</pre>\n<p>To install the codebase (enabling you to make modifications):</p>\n<pre>$ conda update pip <span class=\"c1\"># if you use conda\n</span>$ git clone https://github.com/cgnorthcutt/cleanlab.git\n$ <span class=\"nb\">cd</span> cleanlab\n$ pip install -e .\n</pre>\n</div>\n<div id=\"citations-and-related-publications\">\n<h2>Citations and Related Publications</h2>\n<p>If you use this package in your work, please cite the <a href=\"https://arxiv.org/abs/1911.00068\" rel=\"nofollow\">confident learning paper</a>:</p>\n<pre>  @misc{northcutt2019confidentlearning,\n    title={Confident Learning: Estimating Uncertainty in Dataset Labels},\n    author={Curtis G. Northcutt and Lu Jiang and Isaac L. Chuang},\n    year={2019},\n    eprint={1911.00068},\n    archivePrefix={arXiv},\n    primaryClass={stat.ML}\n}\n</pre>\n<p>and the cleanlab code base here:</p>\n<pre>@misc{northcutt2019cleanlab,\n  author = {Curtis Northcutt},\n  title = {Clean Lab},\n  year = {2019},\n  howpublished = {\\url{https://github.com/cgnorthcutt/cleanlab}},\n  note = {commit xxxxxxx, version xxxx}\n}\n</pre>\n<p>If used for binary classification, cleanlab also implements <a href=\"https://arxiv.org/abs/1705.01936\" rel=\"nofollow\">this paper</a>:</p>\n<pre>@inproceedings{northcutt2017rankpruning,\n author={Northcutt, Curtis G. and Wu, Tailin and Chuang, Isaac L.},\n title={Learning with Confident Examples: Rank Pruning for Robust Classification with Noisy Labels},\n booktitle = {Proceedings of the Thirty-Third Conference on Uncertainty in Artificial Intelligence},\n series = {UAI'17},\n year = {2017},\n location = {Sydney, Australia},\n numpages = {10},\n url = {http://auai.org/uai2017/proceedings/papers/35.pdf},\n publisher = {AUAI Press},\n}\n</pre>\n</div>\n<div id=\"reproducing-results-in-confident-learning-paper\">\n<h2>Reproducing Results in  <a href=\"https://arxiv.org/abs/1911.00068\" rel=\"nofollow\">confident learning paper</a></h2>\n<p>See <a href=\"https://github.com/cgnorthcutt/cleanlab/tree/master/examples\" rel=\"nofollow\">cleanlab/examples</a>. You\u2019ll need to <tt>git clone</tt> <a href=\"https://github.com/cgnorthcutt/confidentlearning-reproduce\" rel=\"nofollow\">confidentlearning-reproduce</a>  which contains the data and files needed to reproduce the CIFAR-10 results.</p>\n<div id=\"cleanlab-find-label-errors-in-imagenet\">\n<h3><tt>cleanlab</tt>: Find Label Errors in ImageNet</h3>\n<p>Use <tt>cleanlab</tt> to identify ~100,000 label errors in the 2012 ImageNet training dataset.</p>\n<div>\n<img alt=\"Image depicting label errors in ImageNet train set\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/38818e33d4bf625148a02de8ebdf73ededa373de/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f63676e6f727468637574742f636c65616e6c61622f6d61737465722f696d672f696d6167656e65745f747261696e5f6c6162656c5f6572726f72735f33322e6a7067\">\n</div>\n<p>Top label issues in the 2012 ILSVRC ImageNet train set identified using <tt>cleanlab</tt>. Label Errors are boxed in red. Ontological issues in green. Multi-label images in blue.</p>\n</div>\n<div id=\"cleanlab-find-label-errors-in-mnist\">\n<h3><tt>cleanlab</tt>: Find Label Errors in MNIST</h3>\n<p>Use <tt>cleanlab</tt> to identify ~50 label errors in the MNIST dataset.</p>\n<div>\n<img alt=\"Image depicting label errors in MNIST train set\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e2c313826fe35e5565706be3ee190a22b725d8ae/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f63676e6f727468637574742f636c65616e6c61622f6d61737465722f696d672f6d6e6973745f747261696e696e675f6c6162656c5f6572726f727332345f7072756e655f62795f6e6f6973655f726174652e706e67\">\n</div>\n<p>Label errors of the original MNIST <strong>train</strong> dataset identified algorithmically using cleanlab. Depicts the 24 least confident labels, ordered left-right, top-down by increasing self-confidence (probability of belonging to the given label), denoted conf in teal. The label with the largest predicted probability is in green. Overt errors are in red.</p>\n</div>\n<div id=\"cleanlab-generality-view-performance-across-4-distributions-and-9-classifiers\">\n<h3><tt>cleanlab</tt> Generality: View performance across 4 distributions and 9 classifiers.</h3>\n<p>Use <tt>cleanlab</tt> to learn with noisy labels regardless of dataset distribution or classifier.</p>\n<div>\n<img alt=\"Image depicting generality of cleanlab across datasets and classifiers\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/45d0658c7da557c07919993b011388bf66747311/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f63676e6f727468637574742f636c65616e6c61622f6d61737465722f696d672f64656d6f5f636c65616e6c61625f6163726f73735f64617461736574735f616e645f636c6173736966696572732e706e67\">\n</div>\n<p>Each sub-figure in the figure above depicts the decision boundary learned using <tt>cleanlab.classification.LearningWithNoisyLabels</tt> in the presence of extreme (~35%) label errors. Label errors are circled in green. Label noise is class-conditional (not simply uniformly random). Columns are organized by the classifier used, except the left-most column which depicts the ground-truth dataset distribution. Rows are organized by dataset used.</p>\n<p>The code to reproduce this figure is available <a href=\"https://github.com/cgnorthcutt/cleanlab/blob/master/examples/classifier_comparison.ipynb\" rel=\"nofollow\">here</a>.</p>\n<p>Each figure depicts accuracy scores on a test set as decimal values:</p>\n<ol>\n<li>LEFT (in black): The classifier test accuracy trained with perfect labels (no label errors).</li>\n<li>MIDDLE (in blue): The classifier test accuracy trained with noisy labels using <tt>cleanlab</tt>.</li>\n<li>RIGHT (in white): The baseline classifier test accuracy trained with noisy labels.</li>\n</ol>\n<p>As an example, this is the noise matrix (noisy channel) <em>P(s | y)</em> characterizing the label noise for the first dataset row in the figure. <em>s</em> represents the observed noisy labels and <em>y</em> represents the latent, true labels. The trace of this matrix is 2.6. A trace of 4 implies no label noise. A cell in this matrix is read like, \u201cA random 38% of \u20183\u2019 labels were flipped to \u20182\u2019 labels.\u201d</p>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>p(s|y)</th>\n<th>y=0</th>\n<th>y=1</th>\n<th>y=2</th>\n<th>y=3</th>\n</tr>\n</thead>\n<tbody>\n<tr><td>s=0</td>\n<td>0.55</td>\n<td>0.01</td>\n<td>0.07</td>\n<td>0.06</td>\n</tr>\n<tr><td>s=1</td>\n<td>0.22</td>\n<td>0.87</td>\n<td>0.24</td>\n<td>0.02</td>\n</tr>\n<tr><td>s=2</td>\n<td>0.12</td>\n<td>0.04</td>\n<td>0.64</td>\n<td>0.38</td>\n</tr>\n<tr><td>s=3</td>\n<td>0.11</td>\n<td>0.08</td>\n<td>0.05</td>\n<td>0.54</td>\n</tr>\n</tbody>\n</table>\n</div>\n</div>\n<div id=\"get-started-with-easy-quick-examples\">\n<h2>Get started with easy, quick examples.</h2>\n<p>New to <strong>cleanlab</strong>? Start with:</p>\n<ol>\n<li><a href=\"https://github.com/cgnorthcutt/cleanlab/blob/master/examples/visualizing_confident_learning.ipynb\" rel=\"nofollow\">Visualizing confident\nlearning</a></li>\n<li><a href=\"https://github.com/cgnorthcutt/cleanlab/blob/master/examples/iris_simple_example.ipynb\" rel=\"nofollow\">A simple example of learning with noisy labels on the multiclass\nIris dataset</a>.</li>\n</ol>\n<p>These examples show how easy it is to characterize label noise in\ndatasets, learn with noisy labels, identify label errors, estimate\nlatent priors and noisy channels, and more.</p>\n<div id=\"use-cleanlab-with-any-model-tensorflow-caffe2-pytorch-etc\">\n<h3>Use <tt>cleanlab</tt> with any model (Tensorflow, caffe2, PyTorch, etc.)</h3>\n<p>All of the features of the <tt>cleanlab</tt> package work with <strong>any model</strong>.\nYes, any model. Feel free to use PyTorch, Tensorflow, caffe2,\nscikit-learn, mxnet, etc. If you use a scikit-learn classifier, all\n<tt>cleanlab</tt> methods will work out-of-the-box. It\u2019s also easy to use\nyour favorite model from a non-scikit-learn package, just wrap your\nmodel into a Python class that inherits the\n<tt>sklearn.base.BaseEstimator</tt>:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">sklearn.base</span> <span class=\"kn\">import</span> <span class=\"n\">BaseEstimator</span>\n<span class=\"k\">class</span> <span class=\"nc\">YourFavoriteModel</span><span class=\"p\">(</span><span class=\"n\">BaseEstimator</span><span class=\"p\">):</span> <span class=\"c1\"># Inherits sklearn base classifier</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"p\">):</span>\n        <span class=\"k\">pass</span>\n    <span class=\"k\">def</span> <span class=\"nf\">fit</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">sample_weight</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span>\n    <span class=\"k\">def</span> <span class=\"nf\">predict</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">X</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span>\n    <span class=\"k\">def</span> <span class=\"nf\">predict_proba</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">X</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span>\n    <span class=\"k\">def</span> <span class=\"nf\">score</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">sample_weight</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span>\n\n<span class=\"c1\"># Now you can use your model with `cleanlab`. Here's one example:</span>\n<span class=\"kn\">from</span> <span class=\"nn\">cleanlab.classification</span> <span class=\"kn\">import</span> <span class=\"n\">LearningWithNoisyLabels</span>\n<span class=\"n\">lnl</span> <span class=\"o\">=</span> <span class=\"n\">LearningWithNoisyLabels</span><span class=\"p\">(</span><span class=\"n\">clf</span><span class=\"o\">=</span><span class=\"n\">YourFavoriteModel</span><span class=\"p\">())</span>\n<span class=\"n\">lnl</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">train_data</span><span class=\"p\">,</span> <span class=\"n\">train_labels_with_errors</span><span class=\"p\">)</span>\n</pre>\n<div id=\"want-to-see-a-working-example-heres-a-compliant-pytorch-mnist-cnn-class\">\n<h4>Want to see a working example? <a href=\"https://github.com/cgnorthcutt/cleanlab/blob/master/cleanlab/models/mnist_pytorch.py#L28\" rel=\"nofollow\">Here\u2019s a compliant PyTorch MNIST CNN class</a></h4>\n<p>As you can see\n<a href=\"https://github.com/cgnorthcutt/cleanlab/blob/master/cleanlab/models/mnist_pytorch.py#L28\" rel=\"nofollow\">here</a>,\ntechnically you don\u2019t actually need to inherit from\n<tt>sklearn.base.BaseEstimator</tt>, as you can just create a class that\ndefines .fit(), .predict(), and .predict_proba(), but inheriting makes\ndownstream scikit-learn applications like hyper-parameter optimization\nwork seamlessly. For example, the <a href=\"https://github.com/cgnorthcutt/cleanlab/blob/master/cleanlab/classification.py#L48\" rel=\"nofollow\">LearningWithNoisyLabels()\nmodel</a>\nis fully compliant.</p>\n<p>Note, some libraries exists to do this for you. For pyTorch, check out\nthe <tt>skorch</tt> Python library which will wrap your <tt>pytorch</tt> model\ninto a <tt><span class=\"pre\">scikit-learn</span></tt> compliant model.</p>\n</div>\n</div>\n</div>\n<div id=\"documentation-by-example\">\n<h2>Documentation by Example</h2>\n<div id=\"cleanlab-core-package-components\">\n<h3><tt>cleanlab</tt> Core Package Components</h3>\n<ol>\n<li><strong>cleanlab/classification.py</strong> - The LearningWithNoisyLabels() class for learning with noisy labels.</li>\n<li><strong>cleanlab/latent_algebra.py</strong> -     Equalities when noise information is known.</li>\n<li><strong>cleanlab/latent_estimation.py</strong> -  Estimates and fully characterizes all variants of label noise.</li>\n<li><strong>cleanlab/noise_generation.py</strong> - Generate mathematically valid synthetic noise matrices.</li>\n<li><strong>cleanlab/polyplex.py</strong> -   Characterizes joint distribution of label noise EXACTLY from noisy channel.</li>\n<li><strong>cleanlab/pruning.py</strong> - Finds the indices of the examples with label errors in a dataset.</li>\n</ol>\n<p>Many of these methods have default parameters that won\u2019t be covered\nhere. Check out the method docstrings for full documentation.</p>\n</div>\n<div id=\"estimate-the-confident-joint-the-latent-noisy-channel-matrix-p-s-y-and-inverse-p-y-s-the-latent-prior-of-the-unobserved-actual-true-labels-p-y-and-the-predicted-probabilities\">\n<h3>Estimate the confident joint, the latent noisy channel matrix, <em>P(s | y)</em> and inverse, <em>P(y | s)</em>, the latent prior of the unobserved, actual true labels, <em>p(y)</em>, and the predicted probabilities.</h3>\n<p><em>s</em> denotes a random variable that represents the observed, noisy\nlabel and <em>y</em> denotes a random variable representing the hidden, actual\nlabels. Both <em>s</em> and <em>y</em> take any of the m classes as values. The\n<tt>cleanlab</tt> package supports different levels of granularity for\ncomputation depending on the needs of the user. Because of this, we\nsupport multiple alternatives, all no more than a few lines, to estimate\nthese latent distribution arrays, enabling the user to reduce\ncomputation time by only computing what they need to compute, as seen in\nthe examples below.</p>\n<p>Throughout these examples, you\u2019ll see a variable called\n<em>confident_joint</em>. The confident joint is an m x m matrix (m is the\nnumber of classes) that counts, for every observed, noisy class, the\nnumber of examples that confidently belong to every latent, hidden\nclass. It counts the number of examples that we are confident are\nlabeled correctly or incorrectly for every pair of obseved and\nunobserved classes. The confident joint is an unnormalized estimate of\nthe complete-information latent joint distribution, <em>Ps,y</em>. Most of the\nmethods in the <strong>cleanlab</strong> package start by first estimating the\n<em>confident_joint</em>. You can learn more about this in the <a href=\"https://arxiv.org/abs/1911.00068\" rel=\"nofollow\">confident learning paper</a>.</p>\n<div id=\"option-1-compute-the-confident-joint-and-predicted-probs-first-stop-if-thats-all-you-need\">\n<h4>Option 1: Compute the confident joint and predicted probs first. Stop if that\u2019s all you need.</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">cleanlab.latent_estimation</span> <span class=\"kn\">import</span> <span class=\"n\">estimate_latent</span>\n<span class=\"kn\">from</span> <span class=\"nn\">cleanlab.latent_estimation</span> <span class=\"kn\">import</span> <span class=\"n\">estimate_confident_joint_and_cv_pred_proba</span>\n\n<span class=\"c1\"># Compute the confident joint and the n x m predicted probabilities matrix (psx),</span>\n<span class=\"c1\"># for n examples, m classes. Stop here if all you need is the confident joint.</span>\n<span class=\"n\">confident_joint</span><span class=\"p\">,</span> <span class=\"n\">psx</span> <span class=\"o\">=</span> <span class=\"n\">estimate_confident_joint_and_cv_pred_proba</span><span class=\"p\">(</span>\n    <span class=\"n\">X</span><span class=\"o\">=</span><span class=\"n\">X_train</span><span class=\"p\">,</span>\n    <span class=\"n\">s</span><span class=\"o\">=</span><span class=\"n\">train_labels_with_errors</span><span class=\"p\">,</span>\n    <span class=\"n\">clf</span><span class=\"o\">=</span><span class=\"n\">logreg</span><span class=\"p\">(),</span> <span class=\"c1\"># default, you can use any classifier</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\"># Estimate latent distributions: p(y) as est_py, P(s|y) as est_nm, and P(y|s) as est_inv</span>\n<span class=\"n\">est_py</span><span class=\"p\">,</span> <span class=\"n\">est_nm</span><span class=\"p\">,</span> <span class=\"n\">est_inv</span> <span class=\"o\">=</span> <span class=\"n\">estimate_latent</span><span class=\"p\">(</span><span class=\"n\">confident_joint</span><span class=\"p\">,</span> <span class=\"n\">s</span><span class=\"o\">=</span><span class=\"n\">train_labels_with_errors</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"option-2-estimate-the-latent-distribution-matrices-in-a-single-line-of-code\">\n<h4>Option 2: Estimate the latent distribution matrices in a single line of code.</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">cleanlab.latent_estimation</span> <span class=\"kn\">import</span> <span class=\"n\">estimate_py_noise_matrices_and_cv_pred_proba</span>\n<span class=\"n\">est_py</span><span class=\"p\">,</span> <span class=\"n\">est_nm</span><span class=\"p\">,</span> <span class=\"n\">est_inv</span><span class=\"p\">,</span> <span class=\"n\">confident_joint</span><span class=\"p\">,</span> <span class=\"n\">psx</span> <span class=\"o\">=</span> <span class=\"n\">estimate_py_noise_matrices_and_cv_pred_proba</span><span class=\"p\">(</span>\n    <span class=\"n\">X</span><span class=\"o\">=</span><span class=\"n\">X_train</span><span class=\"p\">,</span>\n    <span class=\"n\">s</span><span class=\"o\">=</span><span class=\"n\">train_labels_with_errors</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"option-3-skip-computing-the-predicted-probabilities-if-you-already-have-them\">\n<h4>Option 3: Skip computing the predicted probabilities if you already have them.</h4>\n<pre><span class=\"c1\"># Already have psx? (n x m matrix of predicted probabilities)</span>\n<span class=\"c1\"># For example, you might get them from a pre-trained model (like resnet on ImageNet)</span>\n<span class=\"c1\"># With the cleanlab package, you estimate directly with psx.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">cleanlab.latent_estimation</span> <span class=\"kn\">import</span> <span class=\"n\">estimate_py_and_noise_matrices_from_probabilities</span>\n<span class=\"n\">est_py</span><span class=\"p\">,</span> <span class=\"n\">est_nm</span><span class=\"p\">,</span> <span class=\"n\">est_inv</span><span class=\"p\">,</span> <span class=\"n\">confident_joint</span> <span class=\"o\">=</span> <span class=\"n\">estimate_py_and_noise_matrices_from_probabilities</span><span class=\"p\">(</span>\n    <span class=\"n\">s</span><span class=\"o\">=</span><span class=\"n\">train_labels_with_errors</span><span class=\"p\">,</span>\n    <span class=\"n\">psx</span><span class=\"o\">=</span><span class=\"n\">psx</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n</pre>\n</div>\n</div>\n<div id=\"completely-characterize-label-noise-in-a-dataset\">\n<h3>Completely characterize label noise in a dataset:</h3>\n<p>The joint probability distribution of noisy and true labels, <em>P(s,y)</em>, completely characterizes label noise with a class-conditional <em>m x m</em> matrix.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">cleanlab.latent_estimation</span> <span class=\"kn\">import</span> <span class=\"n\">estimate_joint</span>\n<span class=\"n\">joint</span> <span class=\"o\">=</span> <span class=\"n\">compute_confident_joint</span><span class=\"p\">(</span>\n    <span class=\"n\">s</span><span class=\"o\">=</span><span class=\"n\">noisy_labels</span><span class=\"p\">,</span>\n    <span class=\"n\">psx</span><span class=\"o\">=</span><span class=\"n\">probabilities</span><span class=\"p\">,</span>\n    <span class=\"n\">confident_joint</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>  <span class=\"c1\"># Provide if you have it already</span>\n<span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"methods-to-standardize-research-with-noisy-labels\">\n<h3>Methods to Standardize Research with Noisy Labels</h3>\n<p><tt>cleanlab</tt> supports a number of functions to generate noise for benchmarking and standardization in research. This next example shows how to generate valid, class-conditional, unformly random noisy channel matrices:</p>\n<pre><span class=\"c1\"># Generate a valid (necessary conditions for learnability are met) noise matrix for any trace &gt; 1</span>\n<span class=\"kn\">from</span> <span class=\"nn\">cleanlab.noise_generation</span> <span class=\"kn\">import</span> <span class=\"n\">generate_noise_matrix_from_trace</span>\n<span class=\"n\">noise_matrix</span><span class=\"o\">=</span><span class=\"n\">generate_noise_matrix_from_trace</span><span class=\"p\">(</span>\n    <span class=\"n\">K</span><span class=\"o\">=</span><span class=\"n\">number_of_classes</span><span class=\"p\">,</span>\n    <span class=\"n\">trace</span><span class=\"o\">=</span><span class=\"n\">float_value_greater_than_1_and_leq_K</span><span class=\"p\">,</span>\n    <span class=\"n\">py</span><span class=\"o\">=</span><span class=\"n\">prior_of_y_actual_labels_which_is_just_an_array_of_length_K</span><span class=\"p\">,</span>\n    <span class=\"n\">frac_zero_noise_rates</span><span class=\"o\">=</span><span class=\"n\">float_from_0_to_1_controlling_sparsity</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\"># Check if a noise matrix is valid (necessary conditions for learnability are met)</span>\n<span class=\"kn\">from</span> <span class=\"nn\">cleanlab.noise_generation</span> <span class=\"kn\">import</span> <span class=\"n\">noise_matrix_is_valid</span>\n<span class=\"n\">is_valid</span><span class=\"o\">=</span><span class=\"n\">noise_matrix_is_valid</span><span class=\"p\">(</span><span class=\"n\">noise_matrix</span><span class=\"p\">,</span> <span class=\"n\">prior_of_y_which_is_just_an_array_of_length_K</span><span class=\"p\">)</span>\n</pre>\n<p>For a given noise matrix, this example shows how to generate noisy labels. Methods can be seeded for reproducibility.</p>\n<pre><span class=\"c1\"># Generate noisy labels using the noise_marix. Guarantees exact amount of noise in labels.</span>\n<span class=\"kn\">from</span> <span class=\"nn\">cleanlab.noise_generation</span> <span class=\"kn\">import</span> <span class=\"n\">generate_noisy_labels</span>\n<span class=\"n\">s_noisy_labels</span> <span class=\"o\">=</span> <span class=\"n\">generate_noisy_labels</span><span class=\"p\">(</span><span class=\"n\">y_hidden_actual_labels</span><span class=\"p\">,</span> <span class=\"n\">noise_matrix</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># This package is a full of other useful methods for learning with noisy labels.</span>\n<span class=\"c1\"># The tutorial stops here, but you don't have to. Inspect method docstrings for full docs.</span>\n</pre>\n</div>\n<div id=\"the-polyplex\">\n<h3>The Polyplex</h3>\n<p>The key to learning in the presence of label errors is estimating the joint distribution between the actual, hidden labels \u2018<em>y</em>\u2019 and the observed, noisy labels \u2018<em>s</em>\u2019. Using <tt>cleanlab</tt> and the theory of confident learning, we can completely characterize the trace of the latent joint distribution, <em>trace(P(s,y))</em>, given <em>p(y)</em>, for any fraction of label errors, i.e.\u00a0for any trace of the noisy channel, <em>trace(P(s|y))</em>.</p>\n<p>You can check out how to do this yourself here: 1. <a href=\"https://github.com/cgnorthcutt/cleanlab/blob/master/examples/drawing_polyplices.ipynb\" rel=\"nofollow\">Drawing\nPolyplices</a> 2. <a href=\"https://github.com/cgnorthcutt/cleanlab/blob/master/cleanlab/polyplex.py\" rel=\"nofollow\">Computing\nPolyplices</a></p>\n</div>\n<div id=\"license\">\n<h3>License</h3>\n<p>Copyright (c) 2017-2019 Curtis Northcutt. Released under the MIT License. See <a href=\"https://github.com/cgnorthcutt/cleanlab/blob/master/LICENSE\" rel=\"nofollow\">LICENSE</a> for details.</p>\n</div>\n</div>\n\n          </div>"}, "last_serial": 6644428, "releases": {"0.0.10": [{"comment_text": "", "digests": {"md5": "5a2b7f83c5213e8da2af9ae40492d61e", "sha256": "9a73b8206c4413c52532cf92ecfbb1d0106e4b78d0d2bc8c53c29c27c66dca6b"}, "downloads": -1, "filename": "cleanlab-0.0.10-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "5a2b7f83c5213e8da2af9ae40492d61e", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 57242, "upload_time": "2019-07-28T14:55:35", "upload_time_iso_8601": "2019-07-28T14:55:35.128698Z", "url": "https://files.pythonhosted.org/packages/9a/e8/648f6c08ae7c09e65137c473ee0efee5f4fb17a8d929aa8d34c76b30157b/cleanlab-0.0.10-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e50cc2924f37ebcad13a0d4f264b1732", "sha256": "6b7f2e3610cc9a96019f07bb3e402c246703d5a637ca5079156d149715b8ab4d"}, "downloads": -1, "filename": "cleanlab-0.0.10.tar.gz", "has_sig": false, "md5_digest": "e50cc2924f37ebcad13a0d4f264b1732", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 55946, "upload_time": "2019-07-28T14:55:37", "upload_time_iso_8601": "2019-07-28T14:55:37.175881Z", "url": "https://files.pythonhosted.org/packages/00/2a/2122a0b8e7b46efe7b7643c4540d8cb28ce0aabf708e6e31c3561ba5e595/cleanlab-0.0.10.tar.gz", "yanked": false}], "0.0.11": [{"comment_text": "", "digests": {"md5": "d87fd5b97930764357b9a1befc67e565", "sha256": "b275cc82bd4177291544e4632f02eb5cb61885771748eacfbf1a1e402a29c1da"}, "downloads": -1, "filename": "cleanlab-0.0.11-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "d87fd5b97930764357b9a1befc67e565", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 50155, "upload_time": "2019-07-30T01:18:02", "upload_time_iso_8601": "2019-07-30T01:18:02.651540Z", "url": "https://files.pythonhosted.org/packages/6b/ee/ffc47a5dcb250a6e4817e1dd410cee78b24b8337e4e0b580e7f902347dfd/cleanlab-0.0.11-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8f8a963b26d88a7f7a920c19c8125475", "sha256": "f8160af85ac5a5e25c870a8308348f897f34afdb17917014c403fb9629adf427"}, "downloads": -1, "filename": "cleanlab-0.0.11.tar.gz", "has_sig": false, "md5_digest": "8f8a963b26d88a7f7a920c19c8125475", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 50636, "upload_time": "2019-07-30T01:18:05", "upload_time_iso_8601": "2019-07-30T01:18:05.014691Z", "url": "https://files.pythonhosted.org/packages/e8/de/40b5b64995a0d71f2fdacf177100d86927355b7ed8926331effa6c30c7d1/cleanlab-0.0.11.tar.gz", "yanked": false}], "0.0.12": [{"comment_text": "", "digests": {"md5": "b4bd9bf7a8b4bfd43e8d2df15af80ac9", "sha256": "a24f2c9701b41ab31b8a7ab4131f5f69c497635a313836e2f915260fd9f4ec97"}, "downloads": -1, "filename": "cleanlab-0.0.12-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "b4bd9bf7a8b4bfd43e8d2df15af80ac9", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 50158, "upload_time": "2019-08-19T22:26:11", "upload_time_iso_8601": "2019-08-19T22:26:11.062927Z", "url": "https://files.pythonhosted.org/packages/28/ce/2f9905c75b6852cb6085130a2df53fb2ef4c9892c647378cfdc28bf8085d/cleanlab-0.0.12-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1f96a4b420e0eda7b84f09f85c11fef5", "sha256": "9cb8003d2fb706cd9d04fdac66fcbca3067720929622ddc7b017cb5e6493dd89"}, "downloads": -1, "filename": "cleanlab-0.0.12.tar.gz", "has_sig": false, "md5_digest": "1f96a4b420e0eda7b84f09f85c11fef5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 50650, "upload_time": "2019-08-19T22:26:12", "upload_time_iso_8601": "2019-08-19T22:26:12.968206Z", "url": "https://files.pythonhosted.org/packages/31/1f/fcbde46ddd7314d18cddd2187cafb1e859f52fcd266cbdadb606e23ad30e/cleanlab-0.0.12.tar.gz", "yanked": false}], "0.0.13": [{"comment_text": "", "digests": {"md5": "6182830879292ad0fde873cc9a0b0eb6", "sha256": "559e50e41ff2dd6c60e66e85fd0f72d7bc7d0876eba028091dcbfff52919ece2"}, "downloads": -1, "filename": "cleanlab-0.0.13-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "6182830879292ad0fde873cc9a0b0eb6", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 51853, "upload_time": "2019-09-27T15:50:54", "upload_time_iso_8601": "2019-09-27T15:50:54.399692Z", "url": "https://files.pythonhosted.org/packages/aa/73/69661f5d41601efa6168ed1d8912716648e5742ecd112ec9ded58704dee1/cleanlab-0.0.13-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5ea4adef18b23b823aed2f545f3749b2", "sha256": "d5f924245b1a614a674ddf65b23351160e0af0929d04a708a6ac8287f41fe7f0"}, "downloads": -1, "filename": "cleanlab-0.0.13.tar.gz", "has_sig": false, "md5_digest": "5ea4adef18b23b823aed2f545f3749b2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 52049, "upload_time": "2019-09-27T15:50:56", "upload_time_iso_8601": "2019-09-27T15:50:56.439864Z", "url": "https://files.pythonhosted.org/packages/13/47/6035694b598971fa871a0f0f300c29a8f7f01fc7e4dc1b953bd0f62a1f3c/cleanlab-0.0.13.tar.gz", "yanked": false}], "0.0.14": [{"comment_text": "", "digests": {"md5": "fc27cc6919520e5bae0daaf61c82ff4f", "sha256": "6ce360bef72db2ef435cf2de43c2f68de5326401f8f169b102e4e9fe401b8668"}, "downloads": -1, "filename": "cleanlab-0.0.14-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "fc27cc6919520e5bae0daaf61c82ff4f", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 51874, "upload_time": "2019-09-28T13:21:57", "upload_time_iso_8601": "2019-09-28T13:21:57.003420Z", "url": "https://files.pythonhosted.org/packages/6f/8b/88d8e5cd8119b07c5cdd9efa1619b0f6a111fe8aacd50a0ce4c6942486b9/cleanlab-0.0.14-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "303e7dbde7d858074f56584293568108", "sha256": "28ea1167c76fa9e44463b4ae5d2e582afe4e20047112aae6a1794bf4e0f00ee8"}, "downloads": -1, "filename": "cleanlab-0.0.14.tar.gz", "has_sig": false, "md5_digest": "303e7dbde7d858074f56584293568108", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 45549, "upload_time": "2019-09-28T13:21:58", "upload_time_iso_8601": "2019-09-28T13:21:58.997262Z", "url": "https://files.pythonhosted.org/packages/63/f0/bbeee2ce7484980728096b9e071faa4e278b4b11220cb8c779fbf49aacf5/cleanlab-0.0.14.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "ee77d32de781616175e78ac1be37c4b9", "sha256": "4bd0dfa7a634335d16d5589b5cc40f29c166fd0cac6cdde4dc1087365c9f2a83"}, "downloads": -1, "filename": "cleanlab-0.0.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "ee77d32de781616175e78ac1be37c4b9", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 47742, "upload_time": "2018-11-22T21:40:36", "upload_time_iso_8601": "2018-11-22T21:40:36.087853Z", "url": "https://files.pythonhosted.org/packages/15/be/60f6e25fb7098cfd49b8ba727df365f655a58a5aa24671fd7ddadc98e99c/cleanlab-0.0.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ab78dec5b7820324df446074609316a9", "sha256": "0e86af32372e883f783615fbd336804454b91b49a3578545c917663cbda81ad2"}, "downloads": -1, "filename": "cleanlab-0.0.2.tar.gz", "has_sig": false, "md5_digest": "ab78dec5b7820324df446074609316a9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 42880, "upload_time": "2018-11-22T21:40:39", "upload_time_iso_8601": "2018-11-22T21:40:39.100987Z", "url": "https://files.pythonhosted.org/packages/8f/07/4d0d6860eef88b44a2eeaddeb26364d3808796fe555d1108f06fea5f116b/cleanlab-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "c3a2972830b632063a3deb1c5bc0f9fe", "sha256": "22a9ab854068243cf60bfa7fa88fbd25571e4b096cde34e1a759d3494e9992c2"}, "downloads": -1, "filename": "cleanlab-0.0.3-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "c3a2972830b632063a3deb1c5bc0f9fe", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 47845, "upload_time": "2018-11-22T21:46:14", "upload_time_iso_8601": "2018-11-22T21:46:14.846082Z", "url": "https://files.pythonhosted.org/packages/bc/38/27e6e40ddd7abf9b2e646252f24851adc96f8d1a9f5118ed9520705cb50f/cleanlab-0.0.3-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2b4e517ed2252fba4c2a695549451866", "sha256": "3451233db618aa1e26cba972916fcef8df3469c05ff50d90ded6a73b8a10a050"}, "downloads": -1, "filename": "cleanlab-0.0.3.tar.gz", "has_sig": false, "md5_digest": "2b4e517ed2252fba4c2a695549451866", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 42948, "upload_time": "2018-11-22T21:46:16", "upload_time_iso_8601": "2018-11-22T21:46:16.942432Z", "url": "https://files.pythonhosted.org/packages/ef/22/10e9ef5c44c37be1995421f2a4d66e03db8287bcd4909e94b314236e1c96/cleanlab-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "1c54217eba65cbc1386b65dc4bb29ad7", "sha256": "c54211a1532b41f20f6b6eebad86052683f1b31d42da0c34bf7f5edb101d78e8"}, "downloads": -1, "filename": "cleanlab-0.0.4-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "1c54217eba65cbc1386b65dc4bb29ad7", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 47640, "upload_time": "2018-11-26T03:50:01", "upload_time_iso_8601": "2018-11-26T03:50:01.586770Z", "url": "https://files.pythonhosted.org/packages/d5/2f/6d66353a643f40c608b0e32fadd05be086ef973016c1f7fd22b52358f5ac/cleanlab-0.0.4-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "19d3f32c1b8ab3614f5cb876511db8d5", "sha256": "276a4075e07ac9e37b7d431f618a6b18af64cc69b90d2d6ae7a724599659fd87"}, "downloads": -1, "filename": "cleanlab-0.0.4.tar.gz", "has_sig": false, "md5_digest": "19d3f32c1b8ab3614f5cb876511db8d5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 42845, "upload_time": "2018-11-26T03:50:03", "upload_time_iso_8601": "2018-11-26T03:50:03.564760Z", "url": "https://files.pythonhosted.org/packages/36/e9/0f703f9171fb21939fd5b977135024fba259d5ae3aad1300a25f2a0b53f1/cleanlab-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "e50f49f545a2ddcd67d04766818d0cf4", "sha256": "2a410ad54317b3f4cb570ecf431154fbe04febd0cd17655c5738a2bf5dbe97d0"}, "downloads": -1, "filename": "cleanlab-0.0.5-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e50f49f545a2ddcd67d04766818d0cf4", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 48204, "upload_time": "2018-12-08T08:53:30", "upload_time_iso_8601": "2018-12-08T08:53:30.009469Z", "url": "https://files.pythonhosted.org/packages/29/e6/54bd3e5793a738102ae2b30ce5b089938fff4533d6142df15d55093c6ae3/cleanlab-0.0.5-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "626a00d3c1723ef1ee8f6d955940a3f1", "sha256": "02b9c426e133b8b765d74e4d94a508cdd53e87c6204a7f957d9378d6b9b8268f"}, "downloads": -1, "filename": "cleanlab-0.0.5.tar.gz", "has_sig": false, "md5_digest": "626a00d3c1723ef1ee8f6d955940a3f1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 45584, "upload_time": "2018-12-08T08:53:31", "upload_time_iso_8601": "2018-12-08T08:53:31.288287Z", "url": "https://files.pythonhosted.org/packages/0f/d1/f45593dee75a45809b21563283d5968eb9f6f717e1ab1cd19b671f255ec0/cleanlab-0.0.5.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "178bed746ca0a7f83b0d5506aa8ebea6", "sha256": "5138e993d5ba3dc891ad87bb5957f61fdc27826a3d8e2eb7c0757becdad58849"}, "downloads": -1, "filename": "cleanlab-0.0.6-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "178bed746ca0a7f83b0d5506aa8ebea6", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 41812, "upload_time": "2018-12-12T06:39:59", "upload_time_iso_8601": "2018-12-12T06:39:59.786507Z", "url": "https://files.pythonhosted.org/packages/f2/eb/4e3164613bf570162a09f46b91524ff5933ed0506151f6b3d34233bdcc9c/cleanlab-0.0.6-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "05f4dfd98014813e08ccfc781b14ff78", "sha256": "647bd605007fb5228dd1b0262f36728834edc2ebef1e84ef8b36fff87b8fe9e7"}, "downloads": -1, "filename": "cleanlab-0.0.6.tar.gz", "has_sig": false, "md5_digest": "05f4dfd98014813e08ccfc781b14ff78", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 42915, "upload_time": "2018-12-12T06:40:01", "upload_time_iso_8601": "2018-12-12T06:40:01.207608Z", "url": "https://files.pythonhosted.org/packages/c3/9f/0cdd22d2548c84fc5a8e5d83b8240aa4c666c8a0ecfd06ca68a7a2f25d1f/cleanlab-0.0.6.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "84c8fac46a9c88766670f16d0d5a35e7", "sha256": "5dcedd6bf076c421672914edfd687a06e89efb17b2e0ff666791893a0a586f63"}, "downloads": -1, "filename": "cleanlab-0.0.7-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "84c8fac46a9c88766670f16d0d5a35e7", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 44974, "upload_time": "2019-01-06T06:08:01", "upload_time_iso_8601": "2019-01-06T06:08:01.202280Z", "url": "https://files.pythonhosted.org/packages/1f/2a/a198ca939d0398e66571957321408c50244392761f473b846297e91fea71/cleanlab-0.0.7-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9bb0860730914059ca269823c9ddeec1", "sha256": "7138bc13e685e4b9b0218acb207bf7f9cfda8f329ddc6cdc6c158593835324b3"}, "downloads": -1, "filename": "cleanlab-0.0.7.tar.gz", "has_sig": false, "md5_digest": "9bb0860730914059ca269823c9ddeec1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 46166, "upload_time": "2019-01-06T06:08:03", "upload_time_iso_8601": "2019-01-06T06:08:03.051830Z", "url": "https://files.pythonhosted.org/packages/2d/4a/6c578dd1118361075f2eba69299c03f6dfc30a2ec67a8cd4a26356a07d84/cleanlab-0.0.7.tar.gz", "yanked": false}], "0.0.8": [{"comment_text": "", "digests": {"md5": "38167ebbfe6170b4908b74f1c3100026", "sha256": "443eacf4783b4abcc86e3dc4296df378c5325abc473b1797c2fdb669270bed0c"}, "downloads": -1, "filename": "cleanlab-0.0.8-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "38167ebbfe6170b4908b74f1c3100026", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 46644, "upload_time": "2019-02-18T01:28:43", "upload_time_iso_8601": "2019-02-18T01:28:43.084616Z", "url": "https://files.pythonhosted.org/packages/fb/e6/19ee3809f6b252b5f36004df32a43a2db12cd73f20e14adcbd3cace8d5a6/cleanlab-0.0.8-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4a5599c03d622cff628323b6c0f10bd7", "sha256": "9e5bc92df7a47db3f9d4a9402c467c5a8874bcba01f079638de5a34e0597c5c4"}, "downloads": -1, "filename": "cleanlab-0.0.8.tar.gz", "has_sig": false, "md5_digest": "4a5599c03d622cff628323b6c0f10bd7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 47897, "upload_time": "2019-02-18T01:28:45", "upload_time_iso_8601": "2019-02-18T01:28:45.300239Z", "url": "https://files.pythonhosted.org/packages/fe/3f/e45e1e72d886180f9d7dedd125de20768e8aa5372a564edcacded79640ab/cleanlab-0.0.8.tar.gz", "yanked": false}], "0.0.9": [{"comment_text": "", "digests": {"md5": "84d84e75d7a7f2bead0c21acf30d0991", "sha256": "e4bb6265937d35fed9b737b00e88ffdc1741929ee069cfbeb3839cf84f99ee6d"}, "downloads": -1, "filename": "cleanlab-0.0.9-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "84d84e75d7a7f2bead0c21acf30d0991", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 57190, "upload_time": "2019-07-28T14:45:53", "upload_time_iso_8601": "2019-07-28T14:45:53.069326Z", "url": "https://files.pythonhosted.org/packages/b4/74/59d0cf550faac0242591d2362a3fac1e743b218ca3344e22e5ce3d10e7ba/cleanlab-0.0.9-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "53154f39440d4e1a8f62062dbfdac0b7", "sha256": "d2b5db17face78d6dceebea158ca52225c2a18519efca84ad3d4e84a45c74df2"}, "downloads": -1, "filename": "cleanlab-0.0.9.tar.gz", "has_sig": false, "md5_digest": "53154f39440d4e1a8f62062dbfdac0b7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 55917, "upload_time": "2019-07-28T14:45:55", "upload_time_iso_8601": "2019-07-28T14:45:55.874758Z", "url": "https://files.pythonhosted.org/packages/63/db/cac94e81d3a78ef37695074912961d4f8691e9b1c1c60984d39c6c5b7e58/cleanlab-0.0.9.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "1aad5392fadf5faa0e35ee48622f60a8", "sha256": "f151689bcc7d882c6ebd8f35da60399be6decfd0328e2f9ffcc29a832c6cef0a"}, "downloads": -1, "filename": "cleanlab-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "1aad5392fadf5faa0e35ee48622f60a8", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 52406, "upload_time": "2019-11-08T08:54:56", "upload_time_iso_8601": "2019-11-08T08:54:56.007016Z", "url": "https://files.pythonhosted.org/packages/62/3c/4dd5d6a1f7e6e87d101e7596dd4b7a269f2e6fe95a94d5bd9cc795e47208/cleanlab-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fb5e61c98083efc577c3a47fbc7a443d", "sha256": "e9d5622f0fab8f2def5435eb5f335912f7e7b950626717db5b94037bf08a3fe5"}, "downloads": -1, "filename": "cleanlab-0.1.0.tar.gz", "has_sig": false, "md5_digest": "fb5e61c98083efc577c3a47fbc7a443d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 52959, "upload_time": "2019-11-08T08:54:58", "upload_time_iso_8601": "2019-11-08T08:54:58.097777Z", "url": "https://files.pythonhosted.org/packages/46/9b/2b8ae63a4c52c18e55579dde1fd845d80a050c8afa60a9789c5d0ae4caf2/cleanlab-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "e2ab59d6e2dee3c74881bc671241d380", "sha256": "ed93019d0e25c221307acacf30d11f2d048f8092bcc2b3613e917bcbb3578359"}, "downloads": -1, "filename": "cleanlab-0.1.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e2ab59d6e2dee3c74881bc671241d380", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 58772, "upload_time": "2020-02-17T07:33:06", "upload_time_iso_8601": "2020-02-17T07:33:06.658786Z", "url": "https://files.pythonhosted.org/packages/99/a6/980c7e765ee40222b35171e4364ef0bdb1d9c6b99a478d797d7843cf31e9/cleanlab-0.1.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b361c6122afa95062ec094e748e18f58", "sha256": "f32b95ff2167368609abf1c68f3ec735658c053dd5e87cb7fac4e3aab614d913"}, "downloads": -1, "filename": "cleanlab-0.1.1.tar.gz", "has_sig": false, "md5_digest": "b361c6122afa95062ec094e748e18f58", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 58434, "upload_time": "2020-02-17T07:33:08", "upload_time_iso_8601": "2020-02-17T07:33:08.533994Z", "url": "https://files.pythonhosted.org/packages/3e/cd/52b0df96b4f67db8286ca8e62be4219a17a7cb4fdff78ac5b6b5091ef846/cleanlab-0.1.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "e2ab59d6e2dee3c74881bc671241d380", "sha256": "ed93019d0e25c221307acacf30d11f2d048f8092bcc2b3613e917bcbb3578359"}, "downloads": -1, "filename": "cleanlab-0.1.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e2ab59d6e2dee3c74881bc671241d380", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 58772, "upload_time": "2020-02-17T07:33:06", "upload_time_iso_8601": "2020-02-17T07:33:06.658786Z", "url": "https://files.pythonhosted.org/packages/99/a6/980c7e765ee40222b35171e4364ef0bdb1d9c6b99a478d797d7843cf31e9/cleanlab-0.1.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b361c6122afa95062ec094e748e18f58", "sha256": "f32b95ff2167368609abf1c68f3ec735658c053dd5e87cb7fac4e3aab614d913"}, "downloads": -1, "filename": "cleanlab-0.1.1.tar.gz", "has_sig": false, "md5_digest": "b361c6122afa95062ec094e748e18f58", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 58434, "upload_time": "2020-02-17T07:33:08", "upload_time_iso_8601": "2020-02-17T07:33:08.533994Z", "url": "https://files.pythonhosted.org/packages/3e/cd/52b0df96b4f67db8286ca8e62be4219a17a7cb4fdff78ac5b6b5091ef846/cleanlab-0.1.1.tar.gz", "yanked": false}], "timestamp": "Thu May  7 22:19:05 2020"}