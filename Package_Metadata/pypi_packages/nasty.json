{"info": {"author": "Lukas Schmelzeisen", "author_email": "me@lschmelzeisen.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Console", "Intended Audience :: Science/Research", "License :: OSI Approved :: Apache Software License", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8", "Programming Language :: Python :: 3 :: Only", "Programming Language :: Python :: Implementation :: PyPy", "Topic :: Internet", "Topic :: Scientific/Engineering", "Topic :: Sociology", "Typing :: Typed"], "description": "========================================================================================\nNASTY Advanced Search Tweet Yielder\n========================================================================================\n\n.. image:: https://raw.githubusercontent.com/lschmelzeisen/nasty/master/assets/textlogo.png\n    :alt: Logo\n    :width: 420\n    :height: 200\n    :align: center\n\n|\n\n**NASTY** is a tool/library for retrieving Tweets via the Twitter Web UI.\nInstead of using the `Twitter Developer API <https://developer.twitter.com/>`_ it\nworks by acting like a normal web browser accessing Twitter.\nThat is, it sends AJAX requests and parses Twitter's JSON responses.\nThis approach makes it substantially different from the\n`other <https://github.com/bisguzar/twitter-scraper>`_\n`popular <https://github.com/Jefferson-Henrique/GetOldTweets-python>`_\n`crawlers <https://github.com/jonbakerfish/TweetScraper>`_ and allows for the following\nfeatures:\n\n* Search for Tweets by keyword (and filter by latest/top/photos/videos, date of\n  authorship, and language).\n* Retrieve all direct replies to a Tweet.\n* Retrieve all Tweets threaded under a Tweet.\n* Return fully-hydrated JSON-objects of Tweets that exactly match the `extended mode of\n  the developer API <https://developer.twitter.com/en/docs/tweets/tweet-updates>`_\n* Operate in batch mode to execute a large set of requests, abort at any time, and rerun\n  both uncompleted and failed requests.\n* Transform collected Tweets into sets of Tweet-IDs for publishing datasets.\n  Automatically download full Tweet information from sets of Tweet-IDs.\n* Written in tested, linted, and fully type-checked Python code.\n\nInstallation\n========================================================================================\n\n**Python 3.6**, **3.7**, **3.8** and **PyPy** are currently supported.\nInstall via::\n\n    $ pip install nasty\n\nCommand Line Interface\n========================================================================================\n\nTo get help for the command line interface use the ``--help`` option::\n\n    $ nasty --help\n    usage: nasty [-h] [-v] [search|replies|thread|batch|idify|unidify] ...\n\n    NASTY Advanced Search Tweet Yielder.\n\n    Commands:\n      The following commands (and abbreviations) are available, each supporting\n      the help option. For example, try out `nasty search --help`.\n\n      <COMMAND>\n        search (s)         Retrieve Tweets using the Twitter advanced search.\n        replies (r)        Retrieve all directly replying Tweets to a Tweet.\n        thread (t)         Retrieve all Tweets threaded under a Tweet.\n        batch (b)          Execute previously created batch of requests.\n        idify (i, id)      Reduce Tweet-collection to Tweet-IDs (for publishing).\n        unidify (u, unid)  Collect full Tweet information from Tweet-IDs (via\n                           official Twitter API).\n\n    General Arguments:\n      -h, --help           Show this help message and exit.\n      -v, --version        Show program's version number and exit.\n      --log-level <LEVEL>  Logging level (DEBUG, INFO, WARN, ERROR.)\n\nYou can also get help for the individual sub commands.\nFor example, try out ``nasty search --help``.\n\nsearch\n----------------------------------------------------------------------------------------\n\nYou can search for Tweets about \"climate change\"::\n\n    $ nasty search --query \"climate change\"\n\nNASTY's output are lines of JSON objects, one per retrieved Tweet.\nEach Tweet-JSON has the following format (pretty-printed and abbreviated for clarity,\nmany other interesting features are also available, such as referenced entities, etc.)::\n\n    {\n        \"created_at\": \"Wed Jan 11 04:52:08 +0000 2017\",\n        \"id_str\": \"8190441963...\",\n        \"full_text\": Thank you for everything...\"\n        \"retweet_count\": 795...,\n        \"favorite_count\": 1744...,\n        \"reply_count\": 22...,\n        \"lang\": \"en\",\n        \"user\": {\n            \"id_str\": \"15367...\",\n            \"name\": \"Presi...\",\n            \"screen_name\": \"POTUS...\",\n            \"location\": \"Washing...\",\n            \"description\": \"This is an archive...\",\n            ...\n        },\n        ...\n    }\n\nBy default this returns ``TOP`` Tweets according to Twitter's own ranking rules.\nAlternatively you can also request the very ``LATEST`` Tweets via::\n\n    $ nasty search --query \"climate change\" --filter LATEST\n\nOther possible values for ``--filter`` are ``PHOTOS`` and ``VIDEOS``.\n\nBy default only English Tweets are found.\nFor example, to instead search for German Tweets::\n\n    $ nasty search --query \"climate change\" --lang \"de\"\n\nAdditionally, you can specifically search for Tweets created after and/or before\nspecific dates::\n\n    $ nasty search --query \"climate change\" --since 2019-01-01 --until 2019-01-31\n\nreplies\n----------------------------------------------------------------------------------------\n\nYou can fetch all direct replies to the `Tweet with ID 332308211321425920\n<https://twitter.com/realDonaldTrump/status/332308211321425920>`_::\n\n    $ nasty replies --tweet-id 332308211321425920\n\nthread\n----------------------------------------------------------------------------------------\n\nYou can fetch all Tweets threaded under the `Tweet with ID 332308211321425920\n<https://twitter.com/realDonaldTrump/status/332308211321425920>`_::\n\n    $ nasty thread --tweet-id 332308211321425920\n\nbatch\n----------------------------------------------------------------------------------------\n\nNASTY supports appending requests to a batch file instead of executing them\nimmediately, so that they can executed in batch mode later.\nThe benefits of this include being able to track the progress of a large set of\nrequests, aborting at any time, and rerunning both completed and failed requests.\n\nTo append a request to a batch file, use the ``--to-batch`` argument on any of\nthe above requests, for example::\n\n    $ nasty search --query \"climate change\" --to-batch batch.jsonl\n\nTo run all files stored in a jobs file and write the output to directory ``out/``::\n\n    $ nasty batch --batch-file batch.jsonl --results-dir out/\n\nWhen this command finished a tally of successful, skippend, and failed requests is\nprinted.\nIf any request failed, you may retry execution with the same command.\nRequests that succeeded will automatically be skipped.\n\nidify / unidify\n----------------------------------------------------------------------------------------\n\nThe `Twitter Developer Policy\n<https://developer.twitter.com/en/developer-terms/agreement-and-policy#id8>`_ states\nthat for sharing collected Tweets with others, only Tweet-IDs may be (publicly)\ndistributed (see `Legal and Moral Considerations`_ for more information).\n\nTo transform lines of Tweet-JSON-objects into lines of Tweet-IDs, use ``nasty idify``.\nFor example::\n\n    $ nasty search --query \"climate change\" | nasty idify > climate-change-tweet-ids.txt\n\nTo perform the reverse, that is getting full Tweet information from just Tweet-IDs, use\n``nasty unidify``::\n\n    $ cat climate-change-tweet-ids.txt | nasty unidify\n\nNote that ``unidify`` is implemented using the `Twitter Developer API\n<https://developer.twitter.com/>`_, since for this specific case, the available free API\ncovers all needed functionality and rate-limits are not to limiting.\nAdditionally, this means, that this specific functionality is officially supported by\nTwitter, meaning the API should be stable over time (thus making it ideal for\nreproducing shared datasets of Tweets).\n\nThe downside is that you need to apply for API keys from Twitter (see `Twitter\nDevelopers: Getting Started\n<https://developer.twitter.com/en/docs/basics/getting-started>`_).\nAfter you have optained your keys, provide them to NASTY via the environment variables\n``NASTY_CONSUMER_KEY`` and ``NASTY_CONSUMER_SECRET``.\nFor convenience, you may use the ``config.example.sh`` shell script to do this::\n\n    $ cp config.example.sh config.sh\n    $ # Edit config.sh to contain your consumer key and secret\n    $ source config.sh\n\nIdify/unidify also support operating on batch results (and keep meta information, that\nis which Tweets were the results of which requests).\nTo idify batch results in directory ``out/``::\n\n    $ nasty idify --in-dir out/ --out-dir out-idified/\n\nTo do the reverse::\n\n    $ nasty unidify --in-dir out-idified/ --out-dir out/\n\nPython API\n========================================================================================\n\nTo fetch all Tweets about \"climate change\" written after 14 January 2019 in German::\n\n    import nasty\n    from datetime import datetime\n\n    tweet_stream = nasty.Search(\"climate change\",\n                                until=datetime(2019, 1, 14),\n                                lang=\"de\").request()\n    for tweet in tweet_stream:\n        print(tweet.created_at, tweet.text)\n\nSimilar functionality is available in the ``nasty.Replies`` and ``nasty.Thread``\nclasses.\nThe returned ``tweet_stream`` is an `Iterable\n<https://docs.python.org/3/library/typing.html#typing.Iterable>`_ of ``nasty.Tweet``\\ s.\n\nThe batch functionality is available in the ``nasty.Batch`` class.\nTo read the output of a batch execution (for example, from ``nasty batch``) written\nto directory ``out/``::\n\n    import nasty\n    from pathlib import Path\n\n    results = nasty.BatchResults(Path(\"out/\"))\n    for entry in results:\n        print(\"Tweets that matched query '{}' (completed at {}):\"\n              .format(entry.request.query, entry.completed_at))\n        for tweet in results.tweets(entry):\n            print(\"-\", tweet)\n\nA comprehensive Python API documentation is coming in the future.\nFor now, the existing code should be relatively easy to understand.\n\nLegal and Moral Considerations\n========================================================================================\n\nAt the time of writing, the\n`Twitter Terms of Service (TOS) <https://twitter.com/en/tos>`_ specify the following of\nrelevance to this project:\n\n    You may not do any of the following while accessing or using the Services: [...]\n    access or search or attempt to access or search the Services by any means\n    (automated or otherwise) other than through our currently available, published\n    interfaces that are provided by Twitter (and only pursuant to the applicable terms\n    and conditions), unless you have been specifically allowed to do so in a separate\n    agreement with Twitter (NOTE: crawling the Services is permissible if done in\n    accordance with the provisions of the robots.txt file, however, scraping the\n    Services without the prior consent of Twitter is expressly prohibited)\n\nThe text does not detail what separates *crawling* from *scraping* but states that\nobeying the ``robots.txt`` is a necessity.\nThese are, for the subdomains we access:\n\n* https://mobile.twitter.com/robots.txt\n* https://api.twitter.com/robots.txt\n\nFor ``mobile.twitter.com`` the URLs NASTY accesses are allowed for any user-agent but\nrequire waiting a delay of one second between successive requests.\nFor ``api.twitter.com`` accessing any URL is forbidden for any user-agent, except the\n``Googlebot``, who may access everything.\nNo crawl delay is specified here.\nNASTY implements a one second delay between any URL requests (even those to\n``api.twitter.com``), but because it does automatically request URLs from the latter\nsubdomain and because it is not the ``Googlebot``, NASTY does technically violate the\n``robots.txt``.\nTherefore, **NASTY does violate the Twitter TOS**.\n\nThis of course begs the question of whether it is morally justified to allow one of the\nworld's most wealthy companies (here, Google) to automatically retrieve all of your web\nsite's user-generated content while simultaneously disallowing anyone else from doing the\nsame thing.\nKeep in mind, that Twitter is not any web site, but among other things hosts much of the\nworld's political discussion\n(`example <https://twitter.com/realdonaldtrump/status/1213919480574812160>`_) to which,\nnaturally, every citizen should have free and unfiltered access.\n\nLuckily, using NASTY is still perfectly legal in many cases:\n\n* It is unclear (and dependent on jurisdiction) to whom the TOS apply.\n  Since using NASTY does not require signing into Twitter or opening it manually in\n  a web browser, a court may decide that the user never agreed to the TOS and is\n  therefore not bound to its conditions.\n\n* A jurisdiction may guarantee certain rights that can not be overruled by TOS.\n  Especially common are laws that allow to for web scraping in academic and personal\n  contexts.\n\n  For example, in Germany up to 75% of any publicly accessible database (here, Twitter)\n  may copied for academic research.\n  For more details, see `Klawonn, T. (2019). \"Urheberrechtliche Grenzen des Web Scrapings\n  (Web Scraping under German Copyright Law)\". Available at SSRN 3491192.\n  <https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3491192>`_\n\n  Also in the United States, `some courts have affirmed the right to scrape publicly\n  available information\n  <http://cdn.ca9.uscourts.gov/datastore/opinions/2019/09/09/17-16783.pdf>`_.\n\nNote, that the above does not imply that it is legal or moral to publicly share a\ndataset that you created using NASTY.\nSpecifically, the `Twitter Developer Policy\n<https://developer.twitter.com/en/developer-terms/agreement-and-policy#id8>`_ state:\n\n    If you provide Twitter Content to third parties, including downloadable datasets of\n    Twitter Content or an API that returns Twitter Content, you will only distribute or\n    allow download of Tweet IDs, Direct Message IDs, and/or User IDs.\n\nUse the ``nasty idify`` command on retrieved Tweets, before sharing them publicly.\n\nLast, it should be mentioned that NASTY is a tool specifically created for personal and\nacademic contexts, where the funds to pay for enterprise access to the Twitter API are\nusually not available.\nIf you operate in a commercial context, you should `pay for the services where possible\n<https://developer.twitter.com/en/products/products-overview>`_.\n\nFor more discussion on the topic, see `Perry Stephenson (2018). \"Is it okay to scrape\nTwitter?\" <https://perrystephenson.me/2018/08/11/is-it-okay-to-scrape-twitter/>`_\n\nContributing\n========================================================================================\n\nPlease feel free to submit\n`bug reports <https://github.com/lschmelzeisen/nasty/issues>`_ and\n`pull requests <https://github.com/lschmelzeisen/nasty/pulls>`_!\n\nThere are the ``Makefile``-helpers to run the plethora of auxiliary development tools.\nSee ``make help`` for detailed descriptions.\nThe most important commands are::\n\n    usage: make <target>\n\n    Targets:\n      help        Show this help message.\n      devinstall  Install NASTY in editable mode with all test and dev dependencies (in the currently active environment).\n      test        Run all tests and report test coverage.\n      check       Run linters and perform static type-checking.\n      format      Auto format all code.\n      publish     Build and check source and binary distributions.\n      clean       Remove all created cache/build files, test/coverage reports, and virtual environments.\n\nAcknowledgements\n========================================================================================\n\n* `Raphael Menges <https://github.com/raphaelmenges>`_ designed the NASTY-bird logo.\n* `Steffen J\u00fcnger <https://github.com/sjuenger>`_ and `Matthias Wellstein\n  <https://github.com/mwellstein>`_ wrote the initial still HTML-based crawler\n  prototype.\n\nLicense\n========================================================================================\n\nCopyright 2019-2020 Lukas Schmelzeisen.\nLicensed under the\n`Apache License, Version 2.0 <https://www.apache.org/licenses/LICENSE-2.0>`_.\n\n\n\n", "description_content_type": "text/x-rst", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "python,twitter,crawler", "license": "Apache License, Version 2.0", "maintainer": "", "maintainer_email": "", "name": "nasty", "package_url": "https://pypi.org/project/nasty/", "platform": "", "project_url": "https://pypi.org/project/nasty/", "project_urls": {"Issue Tracker": "https://github.com/lschmelzeisen/nasty/issues", "Repository": "https://github.com/lschmelzeisen/nasty"}, "release_url": "https://pypi.org/project/nasty/0.2.2/", "requires_dist": ["more-itertools (~=8.1)", "overrides (~=2.5)", "requests (~=2.22)", "tweepy (~=3.8)", "typing-extensions (~=3.7)", "autoflake (~=1.3) ; extra == 'dev'", "black (==19.10b0) ; extra == 'dev'", "flake8 (~=3.7) ; extra == 'dev'", "flake8-bandit (~=2.1) ; extra == 'dev'", "flake8-bugbear (~=19.8) ; extra == 'dev'", "flake8-builtins (~=1.4) ; extra == 'dev'", "flake8-comprehensions (~=3.1) ; extra == 'dev'", "flake8-eradicate (~=0.2) ; extra == 'dev'", "flake8-print (~=3.1) ; extra == 'dev'", "flake8-pyi (~=19.3) ; extra == 'dev'", "isort[pyproject] (~=4.3) ; extra == 'dev'", "licenseheaders (~=0.8) ; extra == 'dev'", "mypy (~=0.750) ; extra == 'dev'", "pep8-naming (~=0.9) ; extra == 'dev'", "tox (~=3.14) ; extra == 'dev'", "twine (~=3.1) ; extra == 'dev'", "vulture (~=1.2) ; extra == 'dev'", "coverage[toml] (~=5.0) ; extra == 'test'", "pytest (~=5.3) ; extra == 'test'", "pytest-cov (~=2.8) ; extra == 'test'", "pytest-html (~=2.0) ; extra == 'test'", "responses (~=0.10) ; extra == 'test'"], "requires_python": ">=3.6", "summary": "NASTY Advanced Search Tweet Yielder", "version": "0.2.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <img alt=\"Logo\" class=\"align-center\" height=\"200\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/25c07728f3ab16f1a164c7bf7368c1636356b03f/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6c7363686d656c7a656973656e2f6e617374792f6d61737465722f6173736574732f746578746c6f676f2e706e67\" width=\"420\">\n<div>\n<div><br></div>\n</div>\n<p><strong>NASTY</strong> is a tool/library for retrieving Tweets via the Twitter Web UI.\nInstead of using the <a href=\"https://developer.twitter.com/\" rel=\"nofollow\">Twitter Developer API</a> it\nworks by acting like a normal web browser accessing Twitter.\nThat is, it sends AJAX requests and parses Twitter\u2019s JSON responses.\nThis approach makes it substantially different from the\n<a href=\"https://github.com/bisguzar/twitter-scraper\" rel=\"nofollow\">other</a>\n<a href=\"https://github.com/Jefferson-Henrique/GetOldTweets-python\" rel=\"nofollow\">popular</a>\n<a href=\"https://github.com/jonbakerfish/TweetScraper\" rel=\"nofollow\">crawlers</a> and allows for the following\nfeatures:</p>\n<ul>\n<li>Search for Tweets by keyword (and filter by latest/top/photos/videos, date of\nauthorship, and language).</li>\n<li>Retrieve all direct replies to a Tweet.</li>\n<li>Retrieve all Tweets threaded under a Tweet.</li>\n<li>Return fully-hydrated JSON-objects of Tweets that exactly match the <a href=\"https://developer.twitter.com/en/docs/tweets/tweet-updates\" rel=\"nofollow\">extended mode of\nthe developer API</a></li>\n<li>Operate in batch mode to execute a large set of requests, abort at any time, and rerun\nboth uncompleted and failed requests.</li>\n<li>Transform collected Tweets into sets of Tweet-IDs for publishing datasets.\nAutomatically download full Tweet information from sets of Tweet-IDs.</li>\n<li>Written in tested, linted, and fully type-checked Python code.</li>\n</ul>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p><strong>Python 3.6</strong>, <strong>3.7</strong>, <strong>3.8</strong> and <strong>PyPy</strong> are currently supported.\nInstall via:</p>\n<pre>$ pip install nasty\n</pre>\n</div>\n<div id=\"command-line-interface\">\n<h2>Command Line Interface</h2>\n<p>To get help for the command line interface use the <tt><span class=\"pre\">--help</span></tt> option:</p>\n<pre>$ nasty --help\nusage: nasty [-h] [-v] [search|replies|thread|batch|idify|unidify] ...\n\nNASTY Advanced Search Tweet Yielder.\n\nCommands:\n  The following commands (and abbreviations) are available, each supporting\n  the help option. For example, try out `nasty search --help`.\n\n  &lt;COMMAND&gt;\n    search (s)         Retrieve Tweets using the Twitter advanced search.\n    replies (r)        Retrieve all directly replying Tweets to a Tweet.\n    thread (t)         Retrieve all Tweets threaded under a Tweet.\n    batch (b)          Execute previously created batch of requests.\n    idify (i, id)      Reduce Tweet-collection to Tweet-IDs (for publishing).\n    unidify (u, unid)  Collect full Tweet information from Tweet-IDs (via\n                       official Twitter API).\n\nGeneral Arguments:\n  -h, --help           Show this help message and exit.\n  -v, --version        Show program's version number and exit.\n  --log-level &lt;LEVEL&gt;  Logging level (DEBUG, INFO, WARN, ERROR.)\n</pre>\n<p>You can also get help for the individual sub commands.\nFor example, try out <tt>nasty search <span class=\"pre\">--help</span></tt>.</p>\n<div id=\"search\">\n<h3>search</h3>\n<p>You can search for Tweets about \u201cclimate change\u201d:</p>\n<pre>$ nasty search --query \"climate change\"\n</pre>\n<p>NASTY\u2019s output are lines of JSON objects, one per retrieved Tweet.\nEach Tweet-JSON has the following format (pretty-printed and abbreviated for clarity,\nmany other interesting features are also available, such as referenced entities, etc.):</p>\n<pre>{\n    \"created_at\": \"Wed Jan 11 04:52:08 +0000 2017\",\n    \"id_str\": \"8190441963...\",\n    \"full_text\": Thank you for everything...\"\n    \"retweet_count\": 795...,\n    \"favorite_count\": 1744...,\n    \"reply_count\": 22...,\n    \"lang\": \"en\",\n    \"user\": {\n        \"id_str\": \"15367...\",\n        \"name\": \"Presi...\",\n        \"screen_name\": \"POTUS...\",\n        \"location\": \"Washing...\",\n        \"description\": \"This is an archive...\",\n        ...\n    },\n    ...\n}\n</pre>\n<p>By default this returns <tt>TOP</tt> Tweets according to Twitter\u2019s own ranking rules.\nAlternatively you can also request the very <tt>LATEST</tt> Tweets via:</p>\n<pre>$ nasty search --query \"climate change\" --filter LATEST\n</pre>\n<p>Other possible values for <tt><span class=\"pre\">--filter</span></tt> are <tt>PHOTOS</tt> and <tt>VIDEOS</tt>.</p>\n<p>By default only English Tweets are found.\nFor example, to instead search for German Tweets:</p>\n<pre>$ nasty search --query \"climate change\" --lang \"de\"\n</pre>\n<p>Additionally, you can specifically search for Tweets created after and/or before\nspecific dates:</p>\n<pre>$ nasty search --query \"climate change\" --since 2019-01-01 --until 2019-01-31\n</pre>\n</div>\n<div id=\"replies\">\n<h3>replies</h3>\n<p>You can fetch all direct replies to the <a href=\"https://twitter.com/realDonaldTrump/status/332308211321425920\" rel=\"nofollow\">Tweet with ID 332308211321425920</a>:</p>\n<pre>$ nasty replies --tweet-id 332308211321425920\n</pre>\n</div>\n<div id=\"thread\">\n<h3>thread</h3>\n<p>You can fetch all Tweets threaded under the <a href=\"https://twitter.com/realDonaldTrump/status/332308211321425920\" rel=\"nofollow\">Tweet with ID 332308211321425920</a>:</p>\n<pre>$ nasty thread --tweet-id 332308211321425920\n</pre>\n</div>\n<div id=\"batch\">\n<h3>batch</h3>\n<p>NASTY supports appending requests to a batch file instead of executing them\nimmediately, so that they can executed in batch mode later.\nThe benefits of this include being able to track the progress of a large set of\nrequests, aborting at any time, and rerunning both completed and failed requests.</p>\n<p>To append a request to a batch file, use the <tt><span class=\"pre\">--to-batch</span></tt> argument on any of\nthe above requests, for example:</p>\n<pre>$ nasty search --query \"climate change\" --to-batch batch.jsonl\n</pre>\n<p>To run all files stored in a jobs file and write the output to directory <tt>out/</tt>:</p>\n<pre>$ nasty batch --batch-file batch.jsonl --results-dir out/\n</pre>\n<p>When this command finished a tally of successful, skippend, and failed requests is\nprinted.\nIf any request failed, you may retry execution with the same command.\nRequests that succeeded will automatically be skipped.</p>\n</div>\n<div id=\"idify-unidify\">\n<h3>idify / unidify</h3>\n<p>The <a href=\"https://developer.twitter.com/en/developer-terms/agreement-and-policy#id8\" rel=\"nofollow\">Twitter Developer Policy</a> states\nthat for sharing collected Tweets with others, only Tweet-IDs may be (publicly)\ndistributed (see <a href=\"#legal-and-moral-considerations\" rel=\"nofollow\">Legal and Moral Considerations</a> for more information).</p>\n<p>To transform lines of Tweet-JSON-objects into lines of Tweet-IDs, use <tt>nasty idify</tt>.\nFor example:</p>\n<pre>$ nasty search --query \"climate change\" | nasty idify &gt; climate-change-tweet-ids.txt\n</pre>\n<p>To perform the reverse, that is getting full Tweet information from just Tweet-IDs, use\n<tt>nasty unidify</tt>:</p>\n<pre>$ cat climate-change-tweet-ids.txt | nasty unidify\n</pre>\n<p>Note that <tt>unidify</tt> is implemented using the <a href=\"https://developer.twitter.com/\" rel=\"nofollow\">Twitter Developer API</a>, since for this specific case, the available free API\ncovers all needed functionality and rate-limits are not to limiting.\nAdditionally, this means, that this specific functionality is officially supported by\nTwitter, meaning the API should be stable over time (thus making it ideal for\nreproducing shared datasets of Tweets).</p>\n<p>The downside is that you need to apply for API keys from Twitter (see <a href=\"https://developer.twitter.com/en/docs/basics/getting-started\" rel=\"nofollow\">Twitter\nDevelopers: Getting Started</a>).\nAfter you have optained your keys, provide them to NASTY via the environment variables\n<tt>NASTY_CONSUMER_KEY</tt> and <tt>NASTY_CONSUMER_SECRET</tt>.\nFor convenience, you may use the <tt>config.example.sh</tt> shell script to do this:</p>\n<pre>$ cp config.example.sh config.sh\n$ # Edit config.sh to contain your consumer key and secret\n$ source config.sh\n</pre>\n<p>Idify/unidify also support operating on batch results (and keep meta information, that\nis which Tweets were the results of which requests).\nTo idify batch results in directory <tt>out/</tt>:</p>\n<pre>$ nasty idify --in-dir out/ --out-dir out-idified/\n</pre>\n<p>To do the reverse:</p>\n<pre>$ nasty unidify --in-dir out-idified/ --out-dir out/\n</pre>\n</div>\n</div>\n<div id=\"python-api\">\n<h2>Python API</h2>\n<p>To fetch all Tweets about \u201cclimate change\u201d written after 14 January 2019 in German:</p>\n<pre>import nasty\nfrom datetime import datetime\n\ntweet_stream = nasty.Search(\"climate change\",\n                            until=datetime(2019, 1, 14),\n                            lang=\"de\").request()\nfor tweet in tweet_stream:\n    print(tweet.created_at, tweet.text)\n</pre>\n<p>Similar functionality is available in the <tt>nasty.Replies</tt> and <tt>nasty.Thread</tt>\nclasses.\nThe returned <tt>tweet_stream</tt> is an <a href=\"https://docs.python.org/3/library/typing.html#typing.Iterable\" rel=\"nofollow\">Iterable</a> of <tt>nasty.Tweet</tt>s.</p>\n<p>The batch functionality is available in the <tt>nasty.Batch</tt> class.\nTo read the output of a batch execution (for example, from <tt>nasty batch</tt>) written\nto directory <tt>out/</tt>:</p>\n<pre>import nasty\nfrom pathlib import Path\n\nresults = nasty.BatchResults(Path(\"out/\"))\nfor entry in results:\n    print(\"Tweets that matched query '{}' (completed at {}):\"\n          .format(entry.request.query, entry.completed_at))\n    for tweet in results.tweets(entry):\n        print(\"-\", tweet)\n</pre>\n<p>A comprehensive Python API documentation is coming in the future.\nFor now, the existing code should be relatively easy to understand.</p>\n</div>\n<div id=\"legal-and-moral-considerations\">\n<h2>Legal and Moral Considerations</h2>\n<p>At the time of writing, the\n<a href=\"https://twitter.com/en/tos\" rel=\"nofollow\">Twitter Terms of Service (TOS)</a> specify the following of\nrelevance to this project:</p>\n<blockquote>\nYou may not do any of the following while accessing or using the Services: [\u2026]\naccess or search or attempt to access or search the Services by any means\n(automated or otherwise) other than through our currently available, published\ninterfaces that are provided by Twitter (and only pursuant to the applicable terms\nand conditions), unless you have been specifically allowed to do so in a separate\nagreement with Twitter (NOTE: crawling the Services is permissible if done in\naccordance with the provisions of the robots.txt file, however, scraping the\nServices without the prior consent of Twitter is expressly prohibited)</blockquote>\n<p>The text does not detail what separates <em>crawling</em> from <em>scraping</em> but states that\nobeying the <tt>robots.txt</tt> is a necessity.\nThese are, for the subdomains we access:</p>\n<ul>\n<li><a href=\"https://mobile.twitter.com/robots.txt\" rel=\"nofollow\">https://mobile.twitter.com/robots.txt</a></li>\n<li><a href=\"https://api.twitter.com/robots.txt\" rel=\"nofollow\">https://api.twitter.com/robots.txt</a></li>\n</ul>\n<p>For <tt>mobile.twitter.com</tt> the URLs NASTY accesses are allowed for any user-agent but\nrequire waiting a delay of one second between successive requests.\nFor <tt>api.twitter.com</tt> accessing any URL is forbidden for any user-agent, except the\n<tt>Googlebot</tt>, who may access everything.\nNo crawl delay is specified here.\nNASTY implements a one second delay between any URL requests (even those to\n<tt>api.twitter.com</tt>), but because it does automatically request URLs from the latter\nsubdomain and because it is not the <tt>Googlebot</tt>, NASTY does technically violate the\n<tt>robots.txt</tt>.\nTherefore, <strong>NASTY does violate the Twitter TOS</strong>.</p>\n<p>This of course begs the question of whether it is morally justified to allow one of the\nworld\u2019s most wealthy companies (here, Google) to automatically retrieve all of your web\nsite\u2019s user-generated content while simultaneously disallowing anyone else from doing the\nsame thing.\nKeep in mind, that Twitter is not any web site, but among other things hosts much of the\nworld\u2019s political discussion\n(<a href=\"https://twitter.com/realdonaldtrump/status/1213919480574812160\" rel=\"nofollow\">example</a>) to which,\nnaturally, every citizen should have free and unfiltered access.</p>\n<p>Luckily, using NASTY is still perfectly legal in many cases:</p>\n<ul>\n<li><p>It is unclear (and dependent on jurisdiction) to whom the TOS apply.\nSince using NASTY does not require signing into Twitter or opening it manually in\na web browser, a court may decide that the user never agreed to the TOS and is\ntherefore not bound to its conditions.</p>\n</li>\n<li><p>A jurisdiction may guarantee certain rights that can not be overruled by TOS.\nEspecially common are laws that allow to for web scraping in academic and personal\ncontexts.</p>\n<p>For example, in Germany up to 75% of any publicly accessible database (here, Twitter)\nmay copied for academic research.\nFor more details, see <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3491192\" rel=\"nofollow\">Klawonn, T. (2019). \u201cUrheberrechtliche Grenzen des Web Scrapings\n(Web Scraping under German Copyright Law)\u201d. Available at SSRN 3491192.</a></p>\n<p>Also in the United States, <a href=\"http://cdn.ca9.uscourts.gov/datastore/opinions/2019/09/09/17-16783.pdf\" rel=\"nofollow\">some courts have affirmed the right to scrape publicly\navailable information</a>.</p>\n</li>\n</ul>\n<p>Note, that the above does not imply that it is legal or moral to publicly share a\ndataset that you created using NASTY.\nSpecifically, the <a href=\"https://developer.twitter.com/en/developer-terms/agreement-and-policy#id8\" rel=\"nofollow\">Twitter Developer Policy</a> state:</p>\n<blockquote>\nIf you provide Twitter Content to third parties, including downloadable datasets of\nTwitter Content or an API that returns Twitter Content, you will only distribute or\nallow download of Tweet IDs, Direct Message IDs, and/or User IDs.</blockquote>\n<p>Use the <tt>nasty idify</tt> command on retrieved Tweets, before sharing them publicly.</p>\n<p>Last, it should be mentioned that NASTY is a tool specifically created for personal and\nacademic contexts, where the funds to pay for enterprise access to the Twitter API are\nusually not available.\nIf you operate in a commercial context, you should <a href=\"https://developer.twitter.com/en/products/products-overview\" rel=\"nofollow\">pay for the services where possible</a>.</p>\n<p>For more discussion on the topic, see <a href=\"https://perrystephenson.me/2018/08/11/is-it-okay-to-scrape-twitter/\" rel=\"nofollow\">Perry Stephenson (2018). \u201cIs it okay to scrape\nTwitter?\u201d</a></p>\n</div>\n<div id=\"contributing\">\n<h2>Contributing</h2>\n<p>Please feel free to submit\n<a href=\"https://github.com/lschmelzeisen/nasty/issues\" rel=\"nofollow\">bug reports</a> and\n<a href=\"https://github.com/lschmelzeisen/nasty/pulls\" rel=\"nofollow\">pull requests</a>!</p>\n<p>There are the <tt>Makefile</tt>-helpers to run the plethora of auxiliary development tools.\nSee <tt>make help</tt> for detailed descriptions.\nThe most important commands are:</p>\n<pre>usage: make &lt;target&gt;\n\nTargets:\n  help        Show this help message.\n  devinstall  Install NASTY in editable mode with all test and dev dependencies (in the currently active environment).\n  test        Run all tests and report test coverage.\n  check       Run linters and perform static type-checking.\n  format      Auto format all code.\n  publish     Build and check source and binary distributions.\n  clean       Remove all created cache/build files, test/coverage reports, and virtual environments.\n</pre>\n</div>\n<div id=\"acknowledgements\">\n<h2>Acknowledgements</h2>\n<ul>\n<li><a href=\"https://github.com/raphaelmenges\" rel=\"nofollow\">Raphael Menges</a> designed the NASTY-bird logo.</li>\n<li><a href=\"https://github.com/sjuenger\" rel=\"nofollow\">Steffen J\u00fcnger</a> and <a href=\"https://github.com/mwellstein\" rel=\"nofollow\">Matthias Wellstein</a> wrote the initial still HTML-based crawler\nprototype.</li>\n</ul>\n</div>\n<div id=\"license\">\n<h2>License</h2>\n<p>Copyright 2019-2020 Lukas Schmelzeisen.\nLicensed under the\n<a href=\"https://www.apache.org/licenses/LICENSE-2.0\" rel=\"nofollow\">Apache License, Version 2.0</a>.</p>\n</div>\n\n          </div>"}, "last_serial": 7038672, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "a36a7ec7980e0b17248a18b484e928a2", "sha256": "621a56ce9ac51646fbd75821519d21589c64b04d43f0ff5df00762c0e25d1881"}, "downloads": -1, "filename": "nasty-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "a36a7ec7980e0b17248a18b484e928a2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 54151, "upload_time": "2019-12-06T03:24:06", "upload_time_iso_8601": "2019-12-06T03:24:06.887749Z", "url": "https://files.pythonhosted.org/packages/fd/38/b8804658aa39d4c1a7942e8d44a8b14f411da934cbadfba6d0b033c3cac5/nasty-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2a5ac8bff404ca2bebc5291f02b6429c", "sha256": "d43938ad3ac05a9ecde3e0edf4f9af526439a442ffbfb3efd6e493430a02783b"}, "downloads": -1, "filename": "nasty-0.1.0.tar.gz", "has_sig": false, "md5_digest": "2a5ac8bff404ca2bebc5291f02b6429c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 97371, "upload_time": "2019-12-06T03:24:09", "upload_time_iso_8601": "2019-12-06T03:24:09.695745Z", "url": "https://files.pythonhosted.org/packages/a2/c9/7eb533652301da66848b7c1e08a510d763121a29a506eadcbf13510fc0a3/nasty-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "583ef2de91eb0876be507a87fdafc5e8", "sha256": "86156577947273b99186d90b970b3670652fe396e4120a3c66fb2b2aa038f2be"}, "downloads": -1, "filename": "nasty-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "583ef2de91eb0876be507a87fdafc5e8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 54230, "upload_time": "2019-12-12T13:28:51", "upload_time_iso_8601": "2019-12-12T13:28:51.648715Z", "url": "https://files.pythonhosted.org/packages/3c/29/16b9690b90b4cc3f7994fdfb278fc0a6e0652215afed8cc3066b7cb8ddaf/nasty-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "13ae909b0df1138be74b86c0f801b4ac", "sha256": "cf7942436bc1d0300137bfe90014e814852ce066f9e94144d23be3447c18e817"}, "downloads": -1, "filename": "nasty-0.1.1.tar.gz", "has_sig": false, "md5_digest": "13ae909b0df1138be74b86c0f801b4ac", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 97827, "upload_time": "2019-12-12T13:28:53", "upload_time_iso_8601": "2019-12-12T13:28:53.866803Z", "url": "https://files.pythonhosted.org/packages/f0/1c/92f6dbb38db031cc70ec91f18154b29dfb3b7d3117cebe338c3b3736a907/nasty-0.1.1.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "ee040b6686e6f27bbc5320a44cae02f4", "sha256": "c3bc5f0837b7e58a93a338bac02733d442e878a4b59b367a2e56a91934c929de"}, "downloads": -1, "filename": "nasty-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "ee040b6686e6f27bbc5320a44cae02f4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 67368, "upload_time": "2020-02-05T14:58:07", "upload_time_iso_8601": "2020-02-05T14:58:07.929043Z", "url": "https://files.pythonhosted.org/packages/9f/61/a61b104bba57b2b753f1a5f6a57f7038fdac66a37380f93ebe9198f78adc/nasty-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "341d46d26abfd71d0249d1f38bb93f2a", "sha256": "b7b3011ed887301ccd848796f35a0c8a700c782684649b3f335703ea2b2eec95"}, "downloads": -1, "filename": "nasty-0.2.0.tar.gz", "has_sig": false, "md5_digest": "341d46d26abfd71d0249d1f38bb93f2a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 102921, "upload_time": "2020-02-05T14:58:10", "upload_time_iso_8601": "2020-02-05T14:58:10.106446Z", "url": "https://files.pythonhosted.org/packages/e2/a8/f63ae428b58803123907cca94413fd3daf170ce3180e5849fe0ea3c858ad/nasty-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "d2daa7aba3860e11083be083607a6fee", "sha256": "a2e18b8ac82fcbadd77d09e07dd95e23bec71eff1f1f51d1fedbc63fd93d18a2"}, "downloads": -1, "filename": "nasty-0.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "d2daa7aba3860e11083be083607a6fee", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 67534, "upload_time": "2020-03-09T21:50:46", "upload_time_iso_8601": "2020-03-09T21:50:46.110781Z", "url": "https://files.pythonhosted.org/packages/de/54/8f4617d8b4a6fb015556a0abe343ff86e0e58271ebe0a25f60b7e37c1ff2/nasty-0.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b5df1a4358bcd810bf020205252b1382", "sha256": "cb30534a0213beb03e6d373ae86b74864ba7dc686f1eaea6c502d33566b363f0"}, "downloads": -1, "filename": "nasty-0.2.1.tar.gz", "has_sig": false, "md5_digest": "b5df1a4358bcd810bf020205252b1382", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 103908, "upload_time": "2020-03-09T21:50:47", "upload_time_iso_8601": "2020-03-09T21:50:47.803130Z", "url": "https://files.pythonhosted.org/packages/57/6e/ac70f2e6cd15a4ad6c4acfdf473ac5c70a44607f3f3f5caa74722bd64f5d/nasty-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "35e3013e2fcdaa7c21d5c951e0a3f07a", "sha256": "85ddad3074dc7634a334fc5072219ee48bd6c4d76a7cba138922e92bfa91c02d"}, "downloads": -1, "filename": "nasty-0.2.2-py3-none-any.whl", "has_sig": false, "md5_digest": "35e3013e2fcdaa7c21d5c951e0a3f07a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 67554, "upload_time": "2020-04-17T08:41:31", "upload_time_iso_8601": "2020-04-17T08:41:31.120815Z", "url": "https://files.pythonhosted.org/packages/4a/34/f54f050018ad237bba08739d5896b4e8e0faaf9fe5cd092250f79d650a6c/nasty-0.2.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "90fbf8b1302d0c8d0fcff6fee95f4dd2", "sha256": "db47adb32dbc0069e7ede6c623909804fe4305ccee513dedca3a8bbb7289e860"}, "downloads": -1, "filename": "nasty-0.2.2.tar.gz", "has_sig": false, "md5_digest": "90fbf8b1302d0c8d0fcff6fee95f4dd2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 103959, "upload_time": "2020-04-17T08:41:32", "upload_time_iso_8601": "2020-04-17T08:41:32.933217Z", "url": "https://files.pythonhosted.org/packages/64/57/4433dae798381b0af65c286f78f158a334b7142b987a66729ce1e4fe9ad8/nasty-0.2.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "35e3013e2fcdaa7c21d5c951e0a3f07a", "sha256": "85ddad3074dc7634a334fc5072219ee48bd6c4d76a7cba138922e92bfa91c02d"}, "downloads": -1, "filename": "nasty-0.2.2-py3-none-any.whl", "has_sig": false, "md5_digest": "35e3013e2fcdaa7c21d5c951e0a3f07a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 67554, "upload_time": "2020-04-17T08:41:31", "upload_time_iso_8601": "2020-04-17T08:41:31.120815Z", "url": "https://files.pythonhosted.org/packages/4a/34/f54f050018ad237bba08739d5896b4e8e0faaf9fe5cd092250f79d650a6c/nasty-0.2.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "90fbf8b1302d0c8d0fcff6fee95f4dd2", "sha256": "db47adb32dbc0069e7ede6c623909804fe4305ccee513dedca3a8bbb7289e860"}, "downloads": -1, "filename": "nasty-0.2.2.tar.gz", "has_sig": false, "md5_digest": "90fbf8b1302d0c8d0fcff6fee95f4dd2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 103959, "upload_time": "2020-04-17T08:41:32", "upload_time_iso_8601": "2020-04-17T08:41:32.933217Z", "url": "https://files.pythonhosted.org/packages/64/57/4433dae798381b0af65c286f78f158a334b7142b987a66729ce1e4fe9ad8/nasty-0.2.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:47:24 2020"}