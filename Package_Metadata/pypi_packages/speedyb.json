{"info": {"author": "Asher Blum", "author_email": "asher@wildsparx.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Environment :: Other Environment", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Operating System :: Unix", "Programming Language :: C", "Programming Language :: Python", "Topic :: Database", "Topic :: Database :: Database Engines/Servers", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "Introduction\n============\n\nspeedyb lets you create and read constant databases.\n\n  * fast lookups\n  * database cannot be modified\n  * database can be shared by multiple processes without using more memory\n  * fast startup time\n\nLet's say you have a dict like this:\n\n::\n\n    d = {\n      'Alice': '26 Pine Street',\n      'Bob':   '54 Oak Drive'\n    }\n\nYou can write this to a database file:\nspeedyb_writer.dict_to_file(d, 'my.db')\n\nCopyright\n=========\nCopyright 2012 Asher Blum <asher@wildsparx.com>.\nSpeedyb is licensed under the BSD license.\n\nQuestions\n=========\n**Q:** Why not store the dict in a JSON or pickle file and read into a\npython dict?\n\n**A:** First, each process that loads the dict would allocate separate\nmemory, while speedyb shares the memory.  Second, for a large db the load\ntime can be significant, while with speedyb it is essentially instant.\n\n**Q:** How does speedyb compare to Berkeley DB, LevelDB, etc?\n\n**A:** It is significantly faster because it's constant.  \n\n\nInstallation\n============\n\nCheckout the source and run ``python setup.py install``.\n\nUsing speedyb\n=============\n\nCreating a DB\n-------------\n\n::\n\n  import speedyb_writer\n  d = { ... } # data to store\n  speedyb_writer.dict_to_file(d, 'new.db')\n\nThis creates a new database file containing d.  It may be slow.  File\ncreation time goes up linearly with number of keys in d.\n\nReading a DB\n------------\n\n::\n\n  from speedyb_reader import speedyb_reader\n  db = speedyb_reader('tiny.tmp') # open file\n  res = db.get('Alice') # lookup a key\n\nIf the key is not present, res is None.\n\n$Id: README.rst,v 1.2 2012-06-04 04:59:31 asher Exp $", "description_content_type": null, "docs_url": null, "download_url": "http://wildsparx.com/speedyb/speedyb-0.1.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://wildsparx.com/speedyb/", "keywords": null, "license": "UNKNOWN", "maintainer": null, "maintainer_email": null, "name": "speedyb", "package_url": "https://pypi.org/project/speedyb/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/speedyb/", "project_urls": {"Download": "http://wildsparx.com/speedyb/speedyb-0.1.tar.gz", "Homepage": "http://wildsparx.com/speedyb/"}, "release_url": "https://pypi.org/project/speedyb/0.1/", "requires_dist": null, "requires_python": null, "summary": "Create and read fast constant databases", "version": "0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"introduction\">\n<h2>Introduction</h2>\n<p>speedyb lets you create and read constant databases.</p>\n<blockquote>\n<ul>\n<li>fast lookups</li>\n<li>database cannot be modified</li>\n<li>database can be shared by multiple processes without using more memory</li>\n<li>fast startup time</li>\n</ul>\n</blockquote>\n<p>Let\u2019s say you have a dict like this:</p>\n<pre>d = {\n  'Alice': '26 Pine Street',\n  'Bob':   '54 Oak Drive'\n}\n</pre>\n<p>You can write this to a database file:\nspeedyb_writer.dict_to_file(d, \u2018my.db\u2019)</p>\n</div>\n<div id=\"copyright\">\n<h2>Copyright</h2>\n<p>Copyright 2012 Asher Blum &lt;<a href=\"mailto:asher%40wildsparx.com\">asher<span>@</span>wildsparx<span>.</span>com</a>&gt;.\nSpeedyb is licensed under the BSD license.</p>\n</div>\n<div id=\"questions\">\n<h2>Questions</h2>\n<p><strong>Q:</strong> Why not store the dict in a JSON or pickle file and read into a\npython dict?</p>\n<p><strong>A:</strong> First, each process that loads the dict would allocate separate\nmemory, while speedyb shares the memory.  Second, for a large db the load\ntime can be significant, while with speedyb it is essentially instant.</p>\n<p><strong>Q:</strong> How does speedyb compare to Berkeley DB, LevelDB, etc?</p>\n<p><strong>A:</strong> It is significantly faster because it\u2019s constant.</p>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>Checkout the source and run <tt>python setup.py install</tt>.</p>\n</div>\n<div id=\"using-speedyb\">\n<h2>Using speedyb</h2>\n<div id=\"creating-a-db\">\n<h3>Creating a DB</h3>\n<pre>import speedyb_writer\nd = { ... } # data to store\nspeedyb_writer.dict_to_file(d, 'new.db')\n</pre>\n<p>This creates a new database file containing d.  It may be slow.  File\ncreation time goes up linearly with number of keys in d.</p>\n</div>\n<div id=\"reading-a-db\">\n<h3>Reading a DB</h3>\n<pre>from speedyb_reader import speedyb_reader\ndb = speedyb_reader('tiny.tmp') # open file\nres = db.get('Alice') # lookup a key\n</pre>\n<p>If the key is not present, res is None.</p>\n<p>$Id: README.rst,v 1.2 2012-06-04 04:59:31 asher Exp $</p>\n</div>\n</div>\n\n          </div>"}, "last_serial": 803352, "releases": {"0.1": []}, "urls": [], "timestamp": "Fri May  8 03:05:33 2020"}